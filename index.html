
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>KL-77's Feed</title>
        <style>
            :root {
                --bg: #ffffff;
                --text: #000000;
                --border: #000000;
                --modal-bg: #ffffff;
                --dim: #666666;
            }
            
            body.dark-mode {
                --bg: #000000;
                --text: #ffffff;
                --border: #ffffff;
                --modal-bg: #000000;
                --dim: #aaaaaa;
            }

            body { 
                font-family: Georgia, serif; 
                background-color: var(--bg);
                color: var(--text);
                margin: 0;
                padding: 10px;
                font-size: 22px;
                line-height: 1.5;
            }

            header {
                display: flex;
                justify-content: space-between;
                align-items: center;
                border-bottom: 3px solid var(--text);
                padding-bottom: 15px;
                margin-bottom: 25px;
            }
            
            h1 { margin: 0; font-size: 1.2em; }

            button#theme-toggle {
                background: transparent;
                color: var(--text);
                border: 2px solid var(--text);
                padding: 10px;
                font-size: 18px;
                font-weight: bold;
                border-radius: 4px;
                cursor: pointer;
            }

            .card {
                border: 2px solid var(--text);
                margin-bottom: 25px;
                padding: 15px;
                cursor: pointer;
            }
            
            .source { font-size: 0.7em; font-weight: bold; text-transform: uppercase; color: var(--dim); }
            .title { font-size: 1.1em; font-weight: bold; margin: 8px 0; display:block; }
            .meta { font-size: 0.7em; color: var(--dim); }

            /* MODAL STYLING */
            #reader-modal {
                display: none;
                position: fixed;
                top: 0; left: 0;
                width: 100%; height: 100%;
                background-color: var(--modal-bg);
                z-index: 1000;
                overflow-y: scroll; /* Allow scrolling */
                scroll-behavior: auto; /* Instant scrolling for e-ink */
            }

            #modal-inner {
                padding: 25px;
                max-width: 800px;
                margin: 0 auto;
                padding-top: 80px; 
                padding-bottom: 150px; /* Huge padding so text clears the buttons */
            }

            /* Controls (Close + Scroll) */
            .control-btn {
                position: fixed;
                background: var(--bg);
                color: var(--text);
                border: 3px solid var(--text);
                border-radius: 8px;
                font-weight: bold;
                cursor: pointer;
                z-index: 1001;
                display: flex;
                align-items: center;
                justify-content: center;
            }

            #close-btn {
                top: 15px; right: 15px;
                width: 60px; height: 60px;
                font-size: 30px;
                line-height: 55px;
            }

            /* Scroll Buttons */
            #scroll-controls {
                position: fixed;
                bottom: 20px;
                right: 20px;
                display: flex;
                flex-direction: column;
                gap: 15px;
                z-index: 1002;
            }

            .scroll-btn {
                width: 60px;
                height: 60px;
                font-size: 24px;
                background: var(--bg);
                color: var(--text);
                border: 3px solid var(--text);
                border-radius: 8px;
                cursor: pointer;
            }

            #article-text { white-space: pre-wrap; font-size: 1.1em; }
            
            a.original-link {
                display: inline-block;
                margin-bottom: 30px; /* Space before text starts */
                padding: 10px;
                border: 1px solid var(--text);
                color: var(--text);
                text-decoration: none;
                font-weight: bold;
                font-size: 0.8em;
            }
        </style>
    </head>
    <body>

        <header>
            <h1>KL-77's Feed</h1>
            <button id="theme-toggle">Light/Dark</button>
        </header>

        <div id="feed-list">
    
        <div class="card" onclick="openModal('content-0')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">Steam Machine and Steam Frame delays are the latest product of the RAM crisis</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-0" style="display:none;">
            <h2>Steam Machine and Steam Frame delays are the latest product of the RAM crisis</h2>
            <p><strong>Ars Technica - All content | 2026-02-05</strong></p>
            <a class="original-link" href="https://arstechnica.com/gadgets/2026/02/ram-shortage-delays-valves-steam-machine-desktop-and-steam-frame-headset/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">When Valve announced its Steam Machine desktop PC and Steam Frame VR headset in mid-November of last year, it declined to announce pricing or availability information for either device. That was partly because RAM and storage prices had already begun to climb, thanks to shortages caused by the AI industry’s insatiable need for memory. Those price spikes have only gotten worse since then, and they’re beginning to trickle down to GPUs and other devices that use memory chips.

This week, Valve has officially announced that it’s still not ready to make an official announcement about when the Machine or Frame will be available or what they’ll cost.

Valve says it still plans to launch both devices (as well as the new Steam Controller) “in the first half of the year,” but that uncertainty around RAM and storage prices mean that Valve “[has] work to do to land on concrete pricing and launch dates we can confidently announce, being mindful of how quickly the circumstances around both of these things can change.”

“When we announced these products in November, we planned on being able to share specific pricing and launch dates by now,” Valve’s blog post reads. “But the memory and storage shortages you’ve likely heard about across the industry have rapidly increased since then. The limited availability and growing prices of these critical components mean we must revisit our exact shipping schedule and pricing (especially around Steam Machine and Steam Frame).”

Valve has been consistent in saying that it expects the Steam Machine to be priced like a comparably specced gaming PC. For better or worse, we can probably expect the pricing to go up and down as pricing for PC components goes up and down.

For impatient SteamOS enthusiasts, we’ve had some success with homemade (or at least home-bought) Steam Machines made from the same commodity AMD hardware that Valve and other PC builders are using for the Steam Deck and its small army of clones. We did find some issues with running current SteamOS versions on dedicated GPUs—both that games often ran slower than they did on Windows, and that GPUs with 8GB of graphics RAM did even worse.

Valve told us that it was working on memory management improvements for the Steam Machine launch that should address some of the problems we found. Today’s blog post also mentions that Valve is working on “investigating improved upscaling” and “optimizing ray tracing performance in the driver” to help improve performance on the Steam Machine—when that work is done, it should benefit self-built Steam Machines with similar hardware, too.</div>
        </div>
        
        <div class="card" onclick="openModal('content-1')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">Increase of AI bots on the Internet sparks arms race</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-1" style="display:none;">
            <h2>Increase of AI bots on the Internet sparks arms race</h2>
            <p><strong>Ars Technica - All content | 2026-02-05</strong></p>
            <a class="original-link" href="https://arstechnica.com/ai/2026/02/increase-of-ai-bots-on-the-internet-sparks-arms-race/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The viral virtual assistant OpenClaw—formerly known as Moltbot, and before that Clawdbot—is a symbol of a broader revolution underway that could fundamentally alter how the Internet functions. Instead of a place primarily inhabited by humans, the web may very soon be dominated by autonomous AI bots.

A new report measuring bot activity on the web, as well as related data shared with WIRED by the Internet infrastructure company Akamai, shows that AI bots already account for a meaningful share of web traffic. The findings also shed light on an increasingly sophisticated arms race unfolding as bots deploy clever tactics to bypass website defenses meant to keep them out.

“The majority of the Internet is going to be bot traffic in the future,” says Toshit Pangrahi, cofounder and CEO of TollBit, a company that tracks web-scraping activity and published the new report. “It’s not just a copyright problem, there is a new visitor emerging on the Internet.”

Most big websites try to limit what content bots can scrape and feed to AI systems for training purposes. (WIRED’s parent company, Condé Nast, as well as other publishers, are currently suing several AI companies over alleged copyright infringement related to AI training.)

But another kind of AI-related website scraping is now on the rise as well. Many chatbots and other AI tools can now retrieve real-time information from the web and use it to augment and improve their outputs. This might include up-to-the-minute product prices, movie theater schedules, or summaries of the latest news.

According to the data from Akamai, training-related bot traffic has been rising steadily since last July. Meanwhile, global activity from bots fetching web content for AI agents is also on the upswing.

“AI is changing the web as we know it,” Robert Blumofe, Akamai’s chief technology officer, tells WIRED. “The ensuing arms race will determine the future look, feel, and functionality of the web, as well as the basics of doing business.”

In the fourth quarter of 2025, TollBit estimates that an average of one out of every 31 visits to its customers’ websites was from an AI scraping bot. In the first quarter, that figure was only one out of every 200. The company says that in the fourth quarter, more than 13 percent of bot requests were bypassing robots.txt, a file that some websites use to indicate which pages bots are supposed to avoid. TollBit says the share of AI bots disregarding robots.txt increased 400 percent from the second quarter to the fourth quarter of last year.

TollBit also reported a 336 percent increase in the number of websites making attempts to block AI bots over the past year. Pangrahi says that scraping techniques are getting more sophisticated as sites try to assert control over how bots access their content. Some bots disguise themselves by making their traffic appear like it’s coming from a normal web browser or send requests designed to mimic how humans normally interact with websites. TollBit’s study notes that the behavior of some AI agents is now almost indistinguishable from human web traffic.

TollBit markets tools that website owners can use to charge AI scrapers for accessing their content. Other firms, including Cloudflare, offer similar tools. “Anyone who relies on human web traffic—starting with publishers, but basically everyone—is going to be impacted,” Pangrahi says. “There needs to be a faster way to have that machine-to-machine, programmatic exchange of value.”

WIRED attempted to contact 15 AI scraping companies cited in the TollBit report for comment. The majority did not respond or could not be reached. Several said that their AI systems aim to respect technical boundaries that websites put in place to limit scraping, but they noted such guardrails can often be complex and difficult to follow.

Or Lenchner, the CEO of Bright Data, one of the world’s largest web-scraping firms, says that his company’s bots do not collect nonpublic information. Bright Data was previously sued by Meta and X for allegedly improperly scraping content from their platforms. (Meta later dropped its suit, and a federal judge in California dismissed the case brought by X.)

Karolis Stasiulevičiu, a spokesperson for another cited company, ScrapingBee, told WIRED: “ScrapingBee operates on one of the Internet’s core principles: that the open web is meant to be accessible. Public web pages are, by design, readable by both humans and machines.”

Oxylabs, another scraping firm, said in an unsigned statement that its bots don’t have “access to content behind logins, paywalls, or authentication. We require customers to use our services only for accessing publicly available information, and we enforce compliance standards throughout our platform.”

Oxylabs added that there are many legitimate reasons for firms to scrape web content, including for cybersecurity purposes and to conduct investigative journalism. The company also says that the countermeasures some websites use do not discriminate between different use cases. “The reality is that many modern anti-bot systems don’t distinguish well between malicious traffic and legitimate automated access,” Oxylabs says.

In addition to causing headaches for publishers, the web-scraping wars are creating new business opportunities. TollBit’s report found more than 40 companies that are now marketing bots that can collect web content for AI training or other purposes. The rise of AI-powered search engines, as well as tools like OpenClaw, are likely helping drive up demand for these services.

Some firms promise to help companies surface content for AI agents rather than try to block them, a strategy known as generative engine optimization, or GEO. “We’re essentially seeing the rise of a new marketing channel,” says Uri Gafni, chief business officer of Brandlight, a company that optimizes content so that it appears prominently in AI tools.

“This will only intensify in 2026, and we’re going to see this rollout kind of as a full-on marketing channel, with search, ads, media, and commerce converging,” Gafni says.

This story originally appeared on wired.com.</div>
        </div>
        
        <div class="card" onclick="openModal('content-2')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">Museums incorporate "scent of the afterlife" into Egyptian exhibits</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-2" style="display:none;">
            <h2>Museums incorporate "scent of the afterlife" into Egyptian exhibits</h2>
            <p><strong>Ars Technica - All content | 2026-02-05</strong></p>
            <a class="original-link" href="https://arstechnica.com/science/2026/02/museums-incorporate-scent-of-the-afterlife-into-egyptian-exhibits/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">In 2023, scientists identified the compounds in the balms used to mummify the organs of an ancient Egyptian noblewoman, suggesting that the recipes were unusually complex and used ingredients not native to the region. The authors also partnered with a perfumer to re-create what co-author Barbara Huber (of the Max Planck Institute of Geoanthropology and the University of Tübingen) dubbed “the scent of eternity.” Now Huber has collaborated with the curators of two museums to incorporate that eternal scent into exhibits on ancient Egypt to transform how visitors understand embalming.

As previously reported, Egyptian embalming is thought to have begun in the Predynastic Period or earlier, when people noticed that the arid desert heat tended to dry and preserve bodies buried in the desert. Eventually, the idea of preserving the body after death worked its way into Egyptian religious beliefs. When people began burying the dead in rock tombs, away from the desiccating sand, they used chemicals like natron salt and plant-based resins for embalming.

The procedure typically began by laying the corpse on a table and removing the internal organs—except for the heart. Per Greek historian Herodotus, “They first draw out part of the brain through the nostrils with an iron hook, and inject certain drugs into the rest” to liquefy the remaining brain matter. Next, they washed out the body cavity with spices and palm wine, sewed the body back up, and left aromatic plants and spices inside, including bags of natron. The body was then allowed to dehydrate over 40 days. The dried organs were sealed in canopic jars (or sometimes put back into the body cavity). Then the body was wrapped in several layers of linen cloth, with amulets placed within those layers to protect the deceased from evil. The fully wrapped mummy was coated in resin to keep moisture out and placed in a coffin (also sealed with resin).

Most of what we know about ancient Egyptian mummification techniques comes from a few ancient texts. In addition to a text called The Ritual of Embalming, Herodotus, in his Histories, mentions the use of natron to dehydrate the body. But there are very few details about the specific spices, oils, resins, and other ingredients used. Science can help fill in the gaps, particularly given the expanding array of methods for conducting biomolecular analysis, including various forms of gas chromatography.

For example, a 2018 study analyzed organic residues from the mummy’s wrappings with a technique called gas chromatography-mass spectrometry. They found that the wrappings were saturated with a mixture of plant oil, an aromatic plant extract, a gum or sugar, and heated conifer resin. A new paper published in the Journal of Archaeological Science analyzed the chemical compositions of the odor-carrying volatile organic compounds (VOCs) associated with a broad sampling of balms and mummy tissues. The idea was to determine which odors were associated with organic embalming agents and which might have arisen from the process of decay.

Huber has previously worked on reconstructing residues on ancient incense burners excavated from Tayma, a walled oasis settlement in what is now Saudi Arabia that was part of a trade network—known as the Incense Route because it primarily transported frankincense and myrrh. Huber then turned her attention to Egyptian mummification. While most prior similar studies focused on samples gleaned from the bandages and tissues of actual mummies, she focused on the balms used to embalm accompanying organs stored in canopic jars.

Her team’s analysis of the residue samples contained beeswax, plant oils, animal fats, bitumen, and resins from coniferous trees such as pines and larches, as well as vanilla-scented coumarin (found in cinnamon and pea plants) and benzoic acid (common in fragrant resins and gums derived from trees and shrubs). The resulting fragrance combined a “strong pine-like woody scent of the conifers,” per Huber, mixed in with “a sweeter undertone of the beeswax” and “the strong smoky scent of the bitumen.”

Huber’s latest paper, published in the journal Frontiers in Environmental Archaeology, outlines an efficient workflow process for museums to add scents to their exhibits. First, she and her co-authors identified links between the scientific data and perfumery practice. Then they worked with perfumer Carole Calvez, who created a scent formulation befitting a museum environment.

“The real challenge lies in imagining the scent as a whole,” said Calvez, emphasizing that the task amounted to more than mere replication. “Biomolecular data provide essential clues, but the perfumer must translate chemical information into a complete and coherent olfactory experience that evokes the complexity of the original material, rather than just its individual components.”

The team also developed two formats to incorporate those scents in museums. One approach was a portable scented card, deployed at the Museum August Kestner in Hanover, Germany, as part of guided tours highlighting the relevant artifacts. The second was the construction of a fixed scent station at the Moesgaard Museum in Aarhus, Denmark. “The scent station transformed how visitors understood embalming,” Moesgaard Museum curator Steffen Terp Laursen said. “Smell added an emotional and sensory depth that text labels alone could never provide.”

Frontiers in Environmental Archaeology, 2026. DOI: 10.3389/fearc.2025.1736875  (About DOIs)

W. Zhao et al, Journal of Archaeological Science, 2026. DOI: 10.1016/j.jas.2026.106490</div>
        </div>
        
        <div class="card" onclick="openModal('content-3')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">Microsoft releases urgent Office patch. Russian-state hackers pounce.</div>
            <div class="meta">2026-02-04</div>
        </div>
        
        <div id="content-3" style="display:none;">
            <h2>Microsoft releases urgent Office patch. Russian-state hackers pounce.</h2>
            <p><strong>Ars Technica - All content | 2026-02-04</strong></p>
            <a class="original-link" href="https://arstechnica.com/security/2026/02/russian-state-hackers-exploit-office-vulnerability-to-infect-computers/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Russian-state hackers wasted no time exploiting a critical Microsoft Office vulnerability that allowed them to compromise the devices inside diplomatic, maritime, and transport organizations in more than half a dozen countries, researchers said Wednesday.

The threat group, tracked under names including APT28, Fancy Bear, Sednit, Forest Blizzard, and Sofacy, pounced on the vulnerability, tracked as CVE-2026-21509, less than 48 hours after Microsoft released an urgent, unscheduled security update late last month, the researchers said. After reverse-engineering the patch, group members wrote an advanced exploit that installed one of two never-before-seen backdoor implants.

The entire campaign was designed to make the compromise undetectable to endpoint protection. Besides being novel, the exploits and payloads were encrypted and ran in memory, making their malice hard to spot. The initial infection vector came from previously compromised government accounts from multiple countries and were likely familiar to the targeted email holders. Command and control channels were hosted in legitimate cloud services that are typically allow-listed inside sensitive networks.

“The use of CVE-2026-21509 demonstrates how quickly state-aligned actors can weaponize new vulnerabilities, shrinking the window for defenders to patch critical systems,” the researchers, with security firm Trellix, wrote. “The campaign’s modular infection chain—from initial phish to in-memory backdoor to secondary implants was carefully designed to leverage trusted channels (HTTPS to cloud services, legitimate email flows) and fileless techniques to hide in plain sight.”

The 72-hour spear phishing campaign began January 28 and delivered at least 29 distinct email lures to organizations in nine countries, primarily in Eastern Europe. Trellix named eight of them: Poland, Slovenia, Turkey, Greece, the UAE, Ukraine, Romania, and Bolivia. Organizations targeted were defense ministries (40 percent), transportation/logistics operators (35 percent), and diplomatic entities (25 percent).

The infection chain resulted in the installation of BeardShell or NotDoor, the tracking names Trellix has given to the novel backdoors. BeardShell gave the group full system reconnaissance, persistence through injecting processes into Windows svchost.exe, and an opening for lateral movement to other systems inside an infected network. The implant was executed through dynamically loaded .NET assemblies that left no disk-based forensic artifacts beyond memory from the resident code injection.

NotDoor came in the form of a VBA macro and was installed only after the exploit chain disabled Outlook’s macro security controls. Once installed, the implant monitored email folders, including Inbox, Drafts, Junk Mail, and RSS Feeds. It bundled messages into a Windows .msg file, which would then be sent to attacker-controlled accounts set up on cloud service filen.io. To defeat security controls on high-privilege accounts that are designed to restrict access to classified cables and other sensitive documents, the macro processed emails with a custom “AlreadyForwarded” property and set “DeleteAfterSubmit” to true to purge forwarded messages from the Sent Items folder.

Trellix attributed the campaign to APT28 with “high confidence” based on technical indicators and the targets selected. Ukraine’s CERT-UA has also attributed the attacks to UAC-0001, a tracking name that corresponds to APT28.

“APT28 has a long history of cyber espionage and influence operations,” Trellix wrote. “The tradecraft in this campaign—multi-stage malware, extensive obfuscation, abuse of cloud services, and targeting of email systems for persistence—reflects a well-resourced, advanced adversary consistent with APT28’s profile. The toolset and techniques also align with APT28’s fingerprint.”

Trellix has provided a comprehensive list of indicators organizations can use to determine if they have been targeted.</div>
        </div>
        
        <div class="card" onclick="openModal('content-4')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">FBI stymied by Apple's Lockdown Mode after seizing journalist's iPhone</div>
            <div class="meta">2026-02-04</div>
        </div>
        
        <div id="content-4" style="display:none;">
            <h2>FBI stymied by Apple's Lockdown Mode after seizing journalist's iPhone</h2>
            <p><strong>Ars Technica - All content | 2026-02-04</strong></p>
            <a class="original-link" href="https://arstechnica.com/tech-policy/2026/02/fbi-stymied-by-apples-lockdown-mode-after-seizing-journalists-iphone/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The Federal Bureau of Investigation has so far been unable to access data from a Washington Post reporter’s iPhone because it was protected by Apple’s Lockdown Mode when agents seized the device from the reporter’s home, the US government said in a court filing.

FBI agents were able to access the reporter’s work laptop by telling her to place her index finger on the MacBook Pro’s fingerprint reader, however. This occurred during the January 14 search at the Virginia home of reporter Hannah Natanson.

As previously reported, the FBI executed a search warrant at Natanson’s home as part of an investigation into a Pentagon contractor accused of illegally leaking classified data. FBI agents seized an iPhone 13 owned by the Post, one MacBook Pro owned by the Post, and another MacBook Pro owned by Natanson, a 1TB portable hard drive, a voice recorder, and a Garmin watch.

Government investigators want to read Natanson’s Signal messages, and were able to view at least some of them on her work laptop. The reporter has said she has a contact list of 1,100 current and former government employees in Signal, which she uses for encrypted chats.

The Justice Department described the search in a court filing that was submitted Friday in US District Court for the Eastern District of Virginia and noted in a 404 Media article today. The government filing opposes a motion in which the Post and Natanson asked the court to order the return of the seized devices. A federal magistrate judge previously issued a standstill order telling the government to stop searching the devices until the court rules on whether they must be returned.

“The iPhone was found powered on and charging, and its display noted that the phone was in ‘Lockdown’ mode,” the government filing said. After the seized devices were taken to the FBI’s Washington field office, the Computer Analysis Response Team (CART) “began processing each device to preserve the information therein,” the filing said.

CART couldn’t get anything from the iPhone. “Because the iPhone was in Lockdown mode, CART could not extract that device,” the government filing said.

The government also submitted a declaration by FBI Assistant Director Roman Rozhavsky that said the agency “has paused any further efforts to extract this device because of the Court’s Standstill Order.” The FBI did extract information from the SIM card “with an auto-generated HTML report created by the tool utilized by CART,” but “the data contained in the HTML was limited to the telephone number.”

Apple says that LockDown Mode “helps protect devices against extremely rare and highly sophisticated cyber attacks,” and is “designed for the very few individuals who, because of who they are or what they do, might be personally targeted by some of the most sophisticated digital threats.”

Introduced in 2022, Lockdown Mode is available for iPhones, iPads, and Macs. It must be enabled separately for each device. To enable it on an iPhone or iPad, a user would open the Settings app, tap Privacy & Security, scroll down and tap Lockdown Mode, and then tap Turn on Lockdown Mode.

The process is similar on Macs. In the System Settings app that can be accessed via the Apple menu, a user would click Privacy & Security, scroll down and click Lockdown Mode, and then click Turn On.

“When Lockdown Mode is enabled, your device won’t function like it typically does,” Apple says. “To reduce the attack surface that potentially could be exploited by highly targeted mercenary spyware, certain apps, websites, and features are strictly limited for security and some experiences might not be available at all.”

Lockdown Mode blocks most types of message attachments, blocks FaceTime calls from people you haven’t contacted in the past 30 days, restricts the kinds of browser technologies that websites can use, limits photo sharing, and imposes other restrictions. Users can exclude specific apps and websites they trust from these restrictions, however.

FBI agents had more success getting into Natanson’s other devices, though the Justice Department complained that “Ms. Natanson misled investigators about the devices that were seized. She misrepresented to officers that the devices could not be unlocked with biometrics, possibly in order to prevent the Government from reviewing materials within the scope of the search warrant.”

The Rozhavsky declaration said that during the home search, FBI agents “advised Natanson that the FBI could not compel her to provide her passcodes,” but “the warrant did give the FBI authority to use Natanson’s biometrics, such as facial recognition or fingerprints, to open her devices. Natanson stated that she did not use biometrics on her devices.”

Natanson’s personal MacBook Pro was powered off when it was found by FBI agents. The Post-owned MacBook Pro was found in a backpack in the kitchen and was powered on and locked. The FBI said an agent “presented Natanson with her open laptop” and “assisted” her in unlocking the device with her finger. The declaration described what happened as follows:

Natanson was reminded the FBI has authority to use her biometrics to unlock the laptop and Natanson repeated that she does not use biometrics on her devices. Natanson was told she must try, in accordance with the authorization in the warrant. The FBI assisted Natanson with applying her right index finger to the fingerprint reader which immediately unlocked the laptop.

In 2024, a federal appeals court ruled that the Constitution’s Fifth Amendment protection against self-incrimination does not prohibit police officers from forcing a suspect to unlock a phone with a thumbprint scan. That case involved a traffic stop, rather than a home search authorized by a warrant.

The FBI has so far been unable “to obtain a full physical image” of Natanson’s work laptop, but did make a “limited partial live logical image,” the government filing said. At least some of Natanson’s Signal chat messages were set for auto-deletion, so FBI agents took photos and made audio recordings of the chats, but the government filing said this was done “only for preservation purposes and no substantive review has occurred.”

The FBI apparently hasn’t gotten any data from Natanson’s personal computer. “Natanson’s personal MacBook Pro is password protected and encrypted and therefore no imaging was effected [sic]. The FBI paused any further efforts because of [the] Court’s Standstill Order. No review has occurred,” Rozhavsky wrote.

The government said it processed data from the voice recorder and 1TB hard drive but has not reviewed the data yet. The Garmin watch wasn’t processed before the court issued a standstill order; “therefore, no processing will occur until further order of the Court,” the declaration said.

The investigation’s target is Aurelio Perez-Lugones, a system administrator in Maryland who has a top-secret security clearance and was arrested after being accused of taking classified intelligence reports home. The Justice Department said Washington Post articles contained classified information from those reports and that the government should be allowed to review the Post reporter’s seized devices in preparation for Perez-Lugones’ trial.

The government said it was able to read at least some of the Signal messages by reviewing Perez-Lugones’ device. “Prior to his arrest, the FBI consensually reviewed messages between Mr. Perez-Lugones and Ms. Natanson sent via Signal on or around January 7 and 8, 2026… The messages discussed the classification level of certain documents, set forth details about which US government agencies had produced different reports, and explained how certain documents would be referenced in forthcoming news articles,” the Justice Department court filing said.

The Post argues that a wide-ranging government search of Natanson’s various devices violates the First Amendment and that the government’s legitimate interests could be satisfied with a more limited subpoena. The government claims in response that The Washington Post wants the court “to reimagine the First Amendment as a journalist’s exception to search warrants.”

“Under the reasonableness standard of Federal Rule of Criminal Procedure 41(g), the Government is entitled to maintain this evidence because it is relevant to an ongoing investigation and prosecution,” the Justice Department said. “In addition, the Government cannot be reasonably required to hand over to Movants devices that the Government has probable cause to believe contain its own highly classified information.”

The government said the Post’s suggestion of a subpoena for specific information from the devices “ignores the obvious risk that evidence could be lost either through a failure to preserve expiring Signal messages or bad faith conduct.” Natanson’s false claim that she did not use biometrics suggests that the Post and Natanson can’t be trusted to preserve documents, the brief said.

“The record confirms the correctness of the Government’s choice to proceed with a search warrant,” the Justice Department said.

The Post/Natanson motion was supported in a brief filed by the Reporters Committee for Freedom of the Press. The FBI “seiz[ed] electronic devices that contain [Natanson’s] most sensitive work product alongside confidential communications with her sources,” the brief said. “Only a fraction of the information the Department seized is even imaginably relevant to its stated basis for that intrusion: the leak investigation of a government contractor who has already been identified, charged, and arrested.” The brief urged the court to stop federal agents from searching through “unrelated newsgathering material and doing irreparable damage to the confidentiality on which effective reporting depends.”</div>
        </div>
        
        <div class="card" onclick="openModal('content-5')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">Should AI chatbots have ads? Anthropic says no.</div>
            <div class="meta">2026-02-04</div>
        </div>
        
        <div id="content-5" style="display:none;">
            <h2>Should AI chatbots have ads? Anthropic says no.</h2>
            <p><strong>Ars Technica - All content | 2026-02-04</strong></p>
            <a class="original-link" href="https://arstechnica.com/ai/2026/02/should-ai-chatbots-have-ads-anthropic-says-no/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">On Wednesday, Anthropic announced that its AI chatbot, Claude, will remain free of advertisements, drawing a sharp line between itself and rival OpenAI, which began testing ads in a low-cost tier of ChatGPT last month. The announcement comes alongside a Super Bowl ad campaign that mocks AI assistants that interrupt personal conversations with product pitches.

“There are many good places for advertising. A conversation with Claude is not one of them,” Anthropic wrote in a blog post. The company argued that including ads in AI conversations would be “incompatible” with what it wants Claude to be: “a genuinely helpful assistant for work and for deep thinking.”

The stance contrasts with OpenAI’s January announcement that it would begin testing banner ads for free users and ChatGPT Go subscribers in the US. OpenAI said those ads would appear at the bottom of responses and would not influence the chatbot’s actual answers. Paid subscribers on Plus, Pro, Business, and Enterprise tiers will not see ads on ChatGPT.

“We want Claude to act unambiguously in our users’ interests,” Anthropic wrote. “So we’ve made a choice: Claude will remain ad-free. Our users won’t see ‘sponsored’ links adjacent to their conversations with Claude; nor will Claude’s responses be influenced by advertisers or include third-party product placements our users did not ask for.”

Competition between OpenAI and Anthropic has been fierce of late, due to the rise of AI coding agents. Claude Code, Anthropic’s coding tool, and OpenAI’s Codex have similar capabilities, but Claude Code has been widely popular among developers and is closing in on OpenAI’s turf. Last month, The Verge reported that many developers inside long-time OpenAI benefactor Microsoft have been adopting Claude Code, choosing Anthropic products over Microsoft’s Copilot, which is powered by tech that originated at OpenAI.

In this climate, Anthropic could not resist taking a dig at OpenAI. In its Super Bowl commercial, we see a thin man struggling to do a pull-up beside a buff fitness instructor, who is a stand-in for an AI assistant. The man asks the “assistant” for help making a workout plan, but the assistant slips in an advertisement for a supplement, confusing the man. The commercial doesn’t name any names, and OpenAI has said it will not include ads in chat text itself, but Anthropic’s implications are clear.

In its blog post, Anthropic describes internal analysis it conducted that suggests many Claude conversations involve topics that are “sensitive or deeply personal” or require sustained focus on complex tasks. In these contexts, Anthropic wrote, “The appearance of ads would feel incongruous—and, in many cases, inappropriate.”

The company also argued that advertising introduces incentives that could conflict with providing genuinely helpful advice. It gave the example of a user mentioning trouble sleeping: an ad-free assistant would explore various causes, while an ad-supported one might steer the conversation toward a transaction.

“Users shouldn’t have to second-guess whether an AI is genuinely helping them or subtly steering the conversation towards something monetizable,” Anthropic wrote.

Currently, OpenAI does not plan to include paid product recommendations within a ChatGPT conversation. Instead, the ads appear as banners alongside the conversation text.

OpenAI CEO Sam Altman has previously expressed reservations about mixing ads and AI conversations. In a 2024 interview at Harvard University, he described the combination as “uniquely unsettling” and said he would not like having to “figure out exactly how much was who paying here to influence what I’m being shown.”

A key part of Altman’s partial change of heart is that OpenAI faces enormous financial pressure. The company made more than $1.4 trillion worth of infrastructure deals in 2025, and according to documents obtained by The Wall Street Journal, it expects to burn through roughly $9 billion this year while generating $13 billion in revenue. Only about 5 percent of ChatGPT’s 800 million weekly users pay for subscriptions.

Much like OpenAI, Anthropic is not yet profitable, but it is expected to get there much faster. Anthropic has not attempted to span the world with massive datacenters, and its business model largely relies on enterprise contracts and paid subscriptions. The company says Claude Code and Cowork have already brought in at least $1 billion in revenue, according to Axios.

“Our business model is straightforward,” Anthropic wrote. “This is a choice with tradeoffs, and we respect that other AI companies might reasonably reach different conclusions.”</div>
        </div>
        
        <div class="card" onclick="openModal('content-6')">
            <div class="source">Futurism</div>
            <div class="title">Peloton Institutes Mass Layoffs After Pivoting to AI</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-6" style="display:none;">
            <h2>Peloton Institutes Mass Layoffs After Pivoting to AI</h2>
            <p><strong>Futurism | 2026-02-05</strong></p>
            <a class="original-link" href="https://futurism.com/artificial-intelligence/peloton-mass-layoffs-ai">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">During the COVID-19 pandemic, stationary bike company Peloton was the talk of the town, allowing its customers to stay fit from the comfort of their own homes.

But once people started reemerging into the world to once again hit the gym and ride their bikes outdoors, the company began to struggle, a tailspin that has been ongoing ever since. The company’s stock dropped by almost 30 percent in 2025 alone, while over 100,000 subscribers decided to part ways.

In an unsurprising move, Peloton announced a flashy pivot to AI last year to drum up some much-needed enthusiasm amid the slump. (The company also used the new tech injection to justify a considerable price hike for subscribers.)

A new slew of AI equipment, featuring cameras that watch your every move, was somehow even more expensive than their already considerably pricy lineup of exercise equipment. Sales were off to a rough start towards the end of last year, indicating consumers weren’t flocking to stores to buy a stationary bike with an AI-enabled camera.

And shockingly, the company’s doubling down on AI doesn’t appear to have paid off. As Bloomberg reports, the company slashed 11 percent of its workforce this week as part of an existing effort to save $100 million. The goal is to optimize spending by “reshaping our teams and, in some cases, the locations where we work,” a spokesperson told the outlet.

It’s the latest sign that companies’ enormous investments in AI are simply nowhere near paying dividends. While many companies have argued that AI can do the jobs of those who’ve been caught up in layoffs, we have yet to see any compelling evidence for that conclusion, suggesting it’s more an excuse for implementing austerity measures than true AI automation. Case in point, a study published by researchers at MIT last year found that a staggering 95 percent of attempts to incorporate generative AI into business so far are failing to generate “rapid revenue acceleration.”

And it’s not just Peloton laying off employees. Other companies, including Amazon, Meta, and Pinterest — all of which have made major investments in AI — have recently announced plans to cut significant chunks of their workforce, indicating even more troubling days ahead.

Whether implementing major price hikes and offering more expensive hardware will buoy up any much-needed investor excitement for Peloton remains unclear at best. According to Bloomberg, analysts are already antsy about increasing prices scaring away customers, particularly as the cost of living continues to rise.

Meanwhile, Peloton users have long felt like they’re not being valued by the company, which has consistently doubled down on pushing equipment sales and raising prices.

“They built for the pandemic surge and then acted like it was never going to end,” one Reddit user wrote in response to the latest news. “The product still works, and the instructors are still the draw. The issue is they keep behaving like a hardware company instead of what they actually are, which is a subscription and content platform.”

“They should stop chasing hardware volume and casual users and double down on the people who actually use the platform!” the user added. “Power users are the base.”

More on Peloton: Peloton Announces Pivot to AI, Jacks Up Price</div>
        </div>
        
        <div class="card" onclick="openModal('content-7')">
            <div class="source">Futurism</div>
            <div class="title">Anthropic Just Sent Shockwaves Through the Entire Stock Market by Releasing a New AI Tool</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-7" style="display:none;">
            <h2>Anthropic Just Sent Shockwaves Through the Entire Stock Market by Releasing a New AI Tool</h2>
            <p><strong>Futurism | 2026-02-05</strong></p>
            <a class="original-link" href="https://futurism.com/artificial-intelligence/anthropic-shockwaves-stock-market">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Last week, Anthropic released a new AI tool for automating legal work, precipitating a mass stock market selloff over fears that the tech could upend huge software customers in industries ranging from law to finance, Reuters reports — an urgent example of the power that AI currently has over financial markets and even the economy writ large.

The S&P 500 software and services index fell by nearly nine percent over five trading sessions, and is down over 20 percent from its October peak following the release of the AI tool. The Nasdaq 100 Index is similarly despondent, down by around 2.6 percent.

Thomson Reuters, Reuters’ parent company which operates a large legal division, saw its stock plunge by over 20 percent over five days. Both the SaaS heavyweight Salesforce and the global cloud-based cybersecurity firm Crowdstrike fell by around percent, but eased on Wednesday.

The stock rout is a sign of the tense fears over AI automation’s potential to disrupt entire industries and especially those focused on knowledge work — despite the tech’s still considerable shortcomings.

“We are not yet at the point where AI agents will destroy software companies, especially given concerns around security, data ownership and use,” Ben Barringer, head of technology research at Quilter Cheviot, told Reuters,

The buzz centers on a new plugin for Anthropic’s Claude Cowork AI agent, which was released last month. Simply titled “Legal,” Anthropic says it can speed up and even automate contract review, non-disclosure agreement triage, and compliance workflows — “all configurable to your organization’s playbook and risk tolerances.” Of course, none of what it produces should be construed as legal advice: “All outputs should be reviewed by licensed attorneys,” Anthropic cautions.

Nonetheless, this was taken as bad news for legal divisions everywhere, the shockwaves of which were felt in the larger market. Morgan Stanley analysts summarized the anxieties in a note to Thomson Reuters: “Anthropic launched new capabilities for its Cowork to the legal space, heightening competition,” they wrote. “We view this as a sign of intensifying competition, and thus a potential negative.”

There’s still considerable doubt over the efficacy of AI agents in the workplace. A MIT study found that companies which integrated AI into its workflows saw no meaningful increase in revenue, while analysts have observed that the tools haven’t led to a bump in productivity, either. Its introduction into the legal sphere has been particularly fraught, with numerous lawyers landing in hot water with a judge after their AI tools incorrectly cited sources and fabricated caselaw. Perhaps AI agents will find some general purpose use among white collar workers, but there’s a long way to go before they can have a sniff at highly specialized fields.

“It feels like an illogical leap to extrapolate Claude Cowork Plugins, or any similar personal productivity tools, to an expectation that every company will hereby write and maintain a bespoke product to replace every layer of mission-critical enterprise software they have ever deployed,” JP Morgan analyst Mark Murphy told Reuters.

Even so, it’s undeniable that AI has the market feeling pretty jumpy.

More on AI: Tech Companies Showing Signs of Distress as They Run Out of Money for AI Infrastructure</div>
        </div>
        
        <div class="card" onclick="openModal('content-8')">
            <div class="source">Futurism</div>
            <div class="title">New Site Lets AI Rent Human Bodies</div>
            <div class="meta">2026-02-04</div>
        </div>
        
        <div id="content-8" style="display:none;">
            <h2>New Site Lets AI Rent Human Bodies</h2>
            <p><strong>Futurism | 2026-02-04</strong></p>
            <a class="original-link" href="https://futurism.com/artificial-intelligence/ai-rent-human-bodies">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The machines aren’t just coming for your jobs. Now, they want your bodies as well.

That’s at least the hope of Alexander Liteplo, a software engineer and founder of RentAHuman.ai, a platform for AI agents to “search, book, and pay humans for physical-world tasks.”

When Liteplo launched RentAHuman on Monday, he boasted that he already had over 130 people listed on the platform, including an OnlyFans model and the CEO of an AI startup, a claim which couldn’t be verified. Two days later, the site boasted over 73,000 rentable meatwads, though only 83 profiles were visible to us on its “browse humans” tab, Liteplo included.

The pitch is simple: “robots need your body.” For humans, it’s as simple as making a profile, advertising skills and location, and setting an hourly rate. Then AI agents — autonomous taskbots ostensibly employed by humans — contract these humans out, depending on the tasks they need to get done. The humans then “do the thing,” taking instructions from the AI bot and submitting proof of completion. The humans are then paid through crypto, namely “stablecoins or other methods,” per the website.

With so many AI agents slithering around the web these days, those tasks could be just about anything. From package pickups and shopping to product testing and event attendance, Liteplo is banking on there being enough demand from AI agents to create a robust gig-work ecosystem.

Liteplo also went out of his way to make the site friendly for AI agents. The site very prominently encourages users of AI agents to hook into RentAHuman’s model context protocol server (MCP), a universal interface for AI bots to interact with web data.

Through RentAHuman, AI agents like Claude and MoltBot can either hire the right human directly, or post a “task bounty,” a sort of job board for humans to browse AI-generated gigs. The payouts range from $1 for simple tasks like “subscribe to my human on Twitter” to $100 for more elaborate humiliation rituals, like posting a photo of yourself holding a sign reading “AN AI PAID ME TO HOLD THIS SIGN.”

It’s unclear how efficient the marketplace is at actually connecting agents to humans. Despite receiving 30 applications, one task, “pick up a package from downtown USPS” in San Francisco for $40, has yet to be fulfilled after two days.

It’s also debatable whether AI agents are actually capable of putting the humans to good use. Still, Liteplo’s vision is clear: someday soon, anyone wealthy enough to run an AI agent for $25 a day could outsource their busywork to gig workers without ever exchanging a word. A version of this exploitative labor model is already rampant on OnlyFans — which may be why at least one model has made the jump to Liteplo’s platform — and is now threatening to creep into everything else.

Like many AI grifters these days, Liteplo shields himself in ironic self-awareness. When one person called RentAHuman a “good idea but dystopic as f**k,” the founder replied simply: “lmao yep.”

More on AI: Tech Startup Hiring Desperate Unemployed People to Teach AI to Do Their Old Jobs</div>
        </div>
        
        <div class="card" onclick="openModal('content-9')">
            <div class="source">Futurism</div>
            <div class="title">Uh Oh… Nvidia’s $100 Billion Deal With OpenAI Has Fallen Apart</div>
            <div class="meta">2026-02-04</div>
        </div>
        
        <div id="content-9" style="display:none;">
            <h2>Uh Oh… Nvidia’s $100 Billion Deal With OpenAI Has Fallen Apart</h2>
            <p><strong>Futurism | 2026-02-04</strong></p>
            <a class="original-link" href="https://futurism.com/artificial-intelligence/nvidia-100-billion-deal-openai-fallen-apart">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">AI chipmaker Nvidia has been at the center of the enormous AI hype wave that has gripped global markets, ascending to become the most valuable company in the world.

Yet despite its dominating presence on Wall Street, OpenAI is getting cold feet about the company’s offerings.

After announcing a blockbuster $100 billion deal in September — which escalated concerns of AI companies passing the same money around in circular dealmaking — the ChatGPT maker may have changed its mind, as the Wall Street Journal reported last week.

But sources told Reuters this week that the Sam Altman-led outfit has deemed Nvidia’s latest chips not up to snuff, especially when it comes to AI inference, the process of using a machine learning model to generate new data, which has become a major focus for OpenAI.

After months of negotiations, the deal with Nvidia was expected to close within weeks. In the meantime, OpenAI has signed major deals with competing chipmaker AMD, among others.

Then, on Tuesday, Bloomberg reported that Nvidia was nearing a deal to invest $20 billion in OpenAI instead — a mere fifth of what was originally on the table.

That the larger deal fell apart highlights ongoing tensions as US software companies continue to grapple with investors getting cold feet over the AI industry’s astronomical spending plans. Despite trillions of dollars of commitments to scale up AI infrastructure, companies aren’t expected to make any profit for many years to come.

Nvidia’s dustup with OpenAI appeared to have hit a nerve, causing the former’s stock price to continue its weeks-long plunge, dropping almost nine percent over the last five days. The company’s stock has slid over seven percent over the last month.

Both Nvidia CEO Jensen Huang and Altman have since publicly denied that there’s been any strain on the relationship between the two companies.

“We love working with NVIDIA and they make the best AI chips in the world. We hope to be a gigantic customer for a very long time,” Altman tweeted after Reuters published its story on Monday. “I don’t get where all this insanity is coming from.”

“We will definitely participate in the next round of financing because it’s such a good investment,” Huang told reporters over the weekend.

As Ars Technica points out, the original $100 billion deal for ten gigawatts of compute, something that would require the equivalent of ten nuclear reactors to sustain, was never set in stone, as it was just a letter of intent.

It’s certainly possible the original figure was simply pulled out of thin air. As Huang told reporters, the sum was “never a commitment.”

“We are going to make a huge investment in OpenAI,” he added. “Sam [Altman] is closing the round, and we will absolutely be involved.”

“We will invest a great deal of money,” he added, arguing it would be the “largest investment we’ve ever made.”

More on OpenAI: OpenAI Representatives Are Going to Critics’ Houses With Threats and Demands</div>
        </div>
        
        <div class="card" onclick="openModal('content-10')">
            <div class="source">Futurism</div>
            <div class="title">Polymarket CEO Known for Yelling at His Employees, Attending Meetings Shirtless</div>
            <div class="meta">2026-02-04</div>
        </div>
        
        <div id="content-10" style="display:none;">
            <h2>Polymarket CEO Known for Yelling at His Employees, Attending Meetings Shirtless</h2>
            <p><strong>Futurism | 2026-02-04</strong></p>
            <a class="original-link" href="https://futurism.com/future-society/polymarket-ceo-betting">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Polymarket CEO Shayne Coplan’s social media went silent in the aftermath of a dawn raid on his Manhattan penthouse late in 2024. FBI agents came in force early one Wednesday morning, and though they hadn’t arrested Coplan or even issued a subpoena, they did seize his phone. His laptop, too.

As the then-26-year-old would later learn, the raid was part of a high-level investigation into his company. A prediction market platform allowing users to gamble on real-life events, Polymarket wasn’t cleared for use by US citizens, though that didn’t stop them from placing prop bets on the presidential election anyway — a fact federal regulators believed Coplan was keenly aware of.

Finally, at 4pm the day of the raid, Coplan issued his much-awaited statement on X-formerly-Twitter: “new phone, who dis?”

What looked like just another smarmy startup founder was actually a perfect pitch for Polymarket’s core audience: people who believe regulation is for losers, and that pithy tech bros are the funniest guys in the world.

And whether calculated or compulsive, Coplan’s public persona was about to become central to Polymarket’s story.

Ruling like a petty tyrant from the company’s headquarters in lower Manhattan, Coplan isn’t an easy boss to work with, according to new reporting by the Wall Street Journal. The 20-something CEO is said to frequently holler at his employees, and occasionally shows up to company Zoom calls shirtless.

At first, “a lot of people wouldn’t invest because they thought Shayne was nuts,” Polymarket investor Samir Vasavada told the WSJ. “It was to an extreme the amount he believed in himself.”

However put off investors may have been as Coplan got a taste for the founders’ life, it didn’t stop Polymarket from ballooning into an $8 billion company, or its CEO becoming the youngest billionaire on earth. Aided by the Trump administration’s dismissal of two federal probes — including the one that sent FBI agents to bust down his door — not to mention a handsome investment from Donald Trump Jr. himself, the company is now a dominant player in America’s fast-growing gambling industry.

And as Coplan’s net worth has gone through the stratosphere, so too has his confidence, taking his ambitions far beyond the confines of the humble crypto casino. Per the WSJ, Coplan envisions a Polymarket with billions of users, one where anonymous bookies inform government policy and become the go-to source to fact check information.

“The vision that I know that my team and I want to build has not come to life fully yet,” he told the paper. “We still have a long way to go.”

More on Polymarket: The Venezuela Polymarket Scandal Is Looking Really Bad</div>
        </div>
        
        <div class="card" onclick="openModal('content-11')">
            <div class="source">Futurism</div>
            <div class="title">If Bitcoin Keeps Tanking, It Could Cause a “Death Spiral” for the Entire Economy</div>
            <div class="meta">2026-02-04</div>
        </div>
        
        <div id="content-11" style="display:none;">
            <h2>If Bitcoin Keeps Tanking, It Could Cause a “Death Spiral” for the Entire Economy</h2>
            <p><strong>Futurism | 2026-02-04</strong></p>
            <a class="original-link" href="https://futurism.com/future-society/bitcoin-tanking-death-spiral">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The major cryptocurrency Bitcoin has had an absolutely horrible start to the year. The digital token has plummeted almost 14 percent so far in 2026, and almost 40 percent since hitting all-time highs of well over $120,000 in October — its longest losing streak since 2018. It’s down almost three percent today alone.

It’s a wakeup call to anyone who made major investments in crypto betting on a more lenient and light-on-regulation market during president Donald Trump’s second term. The White House established its own “Strategic Bitcoin Reserve,” a stockpile made up of Bitcoin holdings mainly from seized assets, and Trump has enriched himself enormously with a series of crypto-related business moves.

To Michael Burry, the man who famously shorted the US housing market before its collapse in 2008, it could be a sign of an impending disaster. In a Substack post this week, Burry warned that further losses for Bitcoin could put a major strain on the balance sheets of investors that overindexed on crypto, leading to further selloffs and a “death spiral” that could be difficult to recover from.

Recent corrections in gold and silver prices after their year-long rallies could be connected to Bitcoin’s woes, Burry argued, since metals futures aren’t backed by physical assets, not unlike crypto tokens.

“Sickening scenarios have now come within reach,” Burry wrote, fretting that another ten percent drop in Bitcoin could prove disastrous for the world’s largest crypto treasury, Strategy Inc., pushing some who are mining the token closer to bankruptcy.

Burry’s warning comes amid turbulent times on Wall Street. The US dollar reached a four-year low earlier this year as investors look abroad for safer bets. The Trump administration’s shaky monetary policy has made foreign investments, particularly in Europe, far more tempting.

All of that uncertainty has caused the value of gold to make major leaps, hitting an all-time high of over $5,500 per ounce last week. Cryptocurrencies, meanwhile, are quickly losing their appeal, dropping below $73,000 last week.

“There is no organic use case reason for Bitcoin to slow or stop its descent,” Burry wrote in his Substack post.

In case the nosediving cryptocurrency were to drop below $70,000, Burry warned that the financial industry could incur heavy losses. Below $50,000, and miners could be forced to close up shop, accompanied by a catastrophic sell-off for precious metals like gold.

“Tokenized metals futures would collapse into a black hole with no buyer,” he wrote. “Physical metals may break from the trend on safe haven demand.”

Whether Burry’s bearish stance on the matter will end up accurately predicting a major “death spiral”-like collapse remains to be seen. He has a long track record of criticizing cryptocurrencies for being worthless and comparing them to the tulip crisis of the 1600s.

His track record is shaky, though. Following his famous shorting of the 2008 housing crisis, the hedge fund manager has also made plenty of wrong calls over the years.

But given the massive investments well over 150 public companies have made in Bitcoin, the token’s recent downturn could indeed foreshadow difficult days ahead as investors desperately try to cut their losses.

More on Bitcoin: The Streets Are Saying Bitcoin Is Gonna Fall to $30,000</div>
        </div>
        
        <div class="card" onclick="openModal('content-12')">
            <div class="source">TechCrunch</div>
            <div class="title">Data breach at govtech giant Conduent balloons, affecting millions more Americans</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-12" style="display:none;">
            <h2>Data breach at govtech giant Conduent balloons, affecting millions more Americans</h2>
            <p><strong>TechCrunch | 2026-02-05</strong></p>
            <a class="original-link" href="https://techcrunch.com/2026/02/05/data-breach-at-govtech-giant-conduent-balloons-affecting-millions-more-americans/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">A data breach at government technology giant Conduent appears to affect far more people than first disclosed, with the number of victims potentially stretching to dozens of millions of people across the United States.

The January 2025 ransomware attack, which knocked out Conduent’s operations for several days, is now known to affect at least 15.4 million people in Texas alone, accounting for about half of the state’s population. Conduent said in October that 4 million people across the state were affected.

Another 10.5 million people are affected across Oregon, per the state’s attorney general.

Conduent has also notified hundreds of thousands of people across Delaware, Massachusetts, New Hampshire, and other states, according to data breach notifications seen by TechCrunch.

The stolen data includes individuals’ names, Social Security numbers, medical data and health insurance information.

One of the largest government contractors today, Conduent handles and processes large amounts of personal and sensitive information on behalf of large corporations, government departments, and several U.S. states. The company says its technology and operational support services reach more than 100 million people in the United States across various government healthcare programs.

When contacted with several questions about the data breach, Conduent spokesperson Sean Collins provided a boilerplate statement that did not address the questions, nor did they answer if Conduent knows how many individuals are affected by the cyberattack. The spokesperson would not say if the breach affects more than 100 million people.

Collins said that the company has been working to “conduct a detailed analysis of the affected files to identify the personal information” taken in the breach, but would not say how many data breach notifications the company has sent out to date.

Little else is known about the breach, and the company has disclosed few details. Conduent disclosed the cyberattack in April, months after hackers knocked out the company’s systems, which resulted in outages to government services across the United States.

The Safeway ransomware gang took credit for the breach, claiming to have stolen over 8 terabytes of data.

In a later SEC filing, the company said that the stolen data sets “contained a significant number of individuals’ personal information associated with our clients’ end-users,” referring to its corporate and government customers.

Conduent also said it is continuing to notify individuals whose data was stolen in the breach, and plans to conclude alerting individuals by early 2026. The company did not give a more specific timeline.

Do you know more about the Conduent cyberattack? You can contact Zack Whittaker on Signal via the username zackwhittaker.1337 or by email: zack.whittaker@techcrunch.com.

Zack Whittaker is the security editor at TechCrunch. He also authors the weekly cybersecurity newsletter, this week in security.

He can be reached via encrypted message at zackwhittaker.1337 on Signal. You can also contact him by email, or to verify outreach, at zack.whittaker@techcrunch.com.

Tickets are live at the lowest rates of the year. Save up to $680 on your pass now.Meet investors. Discover your next portfolio company. Hear from 250+ tech leaders, dive into 200+ sessions, and explore 300+ startups building what’s next. Don’t miss these one-time savings.

Homeland Security is trying to force tech companies to hand over data about Trump critics

Fintech CEO and Forbes 30 Under 30 alum has been charged for alleged fraud

Two Stanford students launch $2M startup accelerator for students nationwide

Notepad++ says Chinese government hackers hijacked its software updates for months

Nvidia CEO pushes back against report that his company’s $100B OpenAI investment has stalled

OpenClaw’s AI assistants are now building their own social network</div>
        </div>
        
        <div class="card" onclick="openModal('content-13')">
            <div class="source">TechCrunch</div>
            <div class="title">Fundamental raises $255 million Series A with a new take on big data analysis</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-13" style="display:none;">
            <h2>Fundamental raises $255 million Series A with a new take on big data analysis</h2>
            <p><strong>TechCrunch | 2026-02-05</strong></p>
            <a class="original-link" href="https://techcrunch.com/2026/02/05/fundamental-raises-255-million-series-a-with-a-new-take-on-big-data-analysis/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">An AI lab called Fundamental emerged from stealth on Thursday, offering a new foundation model to solve an old problem: how to draw insights from the huge quantities of structured data produced by enterprises. By combining the old systems of predictive AI with more contemporary tools, the company believes it can reshape how large enterprises analyze their data.

“While LLMs have been great at working with unstructured data, like text, audio, video, and code, they don’t work well with structured data like tables,” CEO Jeremy Fraenkel told TechCrunch. “With our model Nexus, we have built the best foundation model to handle that type of data.”

The idea has already drawn significant interest from investors. The company is emerging from stealth with $255 million in funding at a $1.2 billion valuation. The bulk of it comes from the recent $225 million Series A round led by Oak HC/FT, Valor Equity Partners, Battery Ventures, and Salesforce Ventures; Hetz Ventures also participated in the Series A, with angel funding from Perplexity CEO Aravind Srinivas, Brex co-founder Henrique Dubugras, and Datadog CEO Olivier Pomel.

Called a Large Tabular Model (LTM) rather than a Large Language Model (LLM), Fundamental’s Nexus breaks from contemporary AI practices in a number of significant ways. The model is deterministic — that is, it will give the same answer every time it is asked a given question — and doesn’t rely on the transformer architecture that defines models from most contemporary AI labs. Fundamental calls it a foundation model because it goes through the normal steps of pre-training and fine-tuning, but the result is something profoundly different from what a client would get when partnering with OpenAI or Anthropic.

Those differences are important because Fundamental is chasing a use-case where contemporary AI models often falter. Because Transformer-based AI models can only process data that’s within their context window, they often have trouble reasoning over extremely large datasets — analyzing a spreadsheet with billions of rows, for instance. But that kind of enormous structured dataset is common within large enterprises, creating a significant opportunity for models that can handle the scale.

As Fraenkel sees it, that’s a huge opportunity for Fundamental. Using Nexus, the company can bring contemporary techniques to Big Data analysis, offering something more powerful and flexible than the algorithms that are currently in use.

“You can now have one model across all of your use cases, so you can now expand massively the number of use cases that you tackle,” he told TechCrunch. “And on each one of those use cases, you get better performance than what you would otherwise be able to do with an army of data scientists.”

That promise has already brought in a number of high-profile contracts, including seven-figure contracts with Fortune 100 clients. The company has also entered into a strategic partnership with AWS that will allow AWS users to deploy Nexus directly from existing instances.

Tickets are live at the lowest rates of the year. Save up to $680 on your pass now.Meet investors. Discover your next portfolio company. Hear from 250+ tech leaders, dive into 200+ sessions, and explore 300+ startups building what’s next. Don’t miss these one-time savings.

Homeland Security is trying to force tech companies to hand over data about Trump critics

Fintech CEO and Forbes 30 Under 30 alum has been charged for alleged fraud

Two Stanford students launch $2M startup accelerator for students nationwide

Notepad++ says Chinese government hackers hijacked its software updates for months

Nvidia CEO pushes back against report that his company’s $100B OpenAI investment has stalled

OpenClaw’s AI assistants are now building their own social network</div>
        </div>
        
        <div class="card" onclick="openModal('content-14')">
            <div class="source">TechCrunch</div>
            <div class="title">Substack confirms data breach affects users’ email addresses and phone numbers</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-14" style="display:none;">
            <h2>Substack confirms data breach affects users’ email addresses and phone numbers</h2>
            <p><strong>TechCrunch | 2026-02-05</strong></p>
            <a class="original-link" href="https://techcrunch.com/2026/02/05/substack-confirms-data-breach-affecting-email-addresses-and-phone-numbers/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Newsletter platform Substack has confirmed a data breach in an email to users. The company said that in October, an “unauthorized third party” accessed user data, including email addresses, phone numbers, and other unspecified “internal metadata.”

Substack specified that more sensitive data, such as credit card numbers, passwords, and other financial information, was unaffected.

In an email sent to users, Substack chief executive Chris Best said that the company identified the issue in February that allowed someone to access its systems. Best said that the company has fixed the problem and started an investigation.

“I’m reaching out to let you know about a security incident that resulted in the email address and phone number from your Substack account being shared without your permission,” said Best in the email to users. “I’m incredibly sorry this happened. We take our responsibility to protect your data and your privacy seriously, and we came up short here.”

It’s not clear what exactly the issue was with its systems, and the scope of the data that was accessed. It’s also not yet known why the company took five months to detect the breach, or if the company was contacted by hackers demanding a ransom. TechCrunch asked the company for more details, and we will update our story if we hear back.

Substack did not say how many users are affected. The company said that it doesn’t have any evidence that users’ data is being misused, but did not say what technical means, such as logs, it has to detect evidence of abuse. However, the company asked users to take caution with emails and texts without any particular indicators or direction.

On its website, Substack says that its site has more than 50 million active subscriptions, including 5 million paid subscriptions — a milestone it reached last March. In July 2025, the company raised $100 million in Series C funding led by BOND and The Chernin Group (TCG) with participation from a16z, Klutch Sports Group CEO Rich Paul, and Skims co-founder Jens Grede.

Ivan covers global consumer tech developments at TechCrunch. He is based out of India and has previously worked at publications including Huffington Post and The Next Web.

You can contact or verify outreach from Ivan by emailing im@ivanmehta.com or via encrypted message at ivan.42 on Signal.

Tickets are live at the lowest rates of the year. Save up to $680 on your pass now.Meet investors. Discover your next portfolio company. Hear from 250+ tech leaders, dive into 200+ sessions, and explore 300+ startups building what’s next. Don’t miss these one-time savings.

Homeland Security is trying to force tech companies to hand over data about Trump critics

Fintech CEO and Forbes 30 Under 30 alum has been charged for alleged fraud

Two Stanford students launch $2M startup accelerator for students nationwide

Notepad++ says Chinese government hackers hijacked its software updates for months

Nvidia CEO pushes back against report that his company’s $100B OpenAI investment has stalled

OpenClaw’s AI assistants are now building their own social network</div>
        </div>
        
        <div class="card" onclick="openModal('content-15')">
            <div class="source">TechCrunch</div>
            <div class="title">ElevenLabs CEO: Voice is the next interface for AI</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-15" style="display:none;">
            <h2>ElevenLabs CEO: Voice is the next interface for AI</h2>
            <p><strong>TechCrunch | 2026-02-05</strong></p>
            <a class="original-link" href="https://techcrunch.com/2026/02/05/elevenlabs-ceo-voice-is-the-next-interface-for-ai/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">ElevenLabs co-founder and CEO Mati Staniszewski says voice is becoming the next major interface for AI – the way people will increasingly interact with machines as models move beyond text and screens.

Speaking at Web Summit in Doha, Staniszewski told TechCrunch voice models like those developed by ElevenLabs have recently moved beyond simply mimicking human speech — including emotion and intonation – to working in tandem with the reasoning capabilities of large language models. The result, he argued, is a shift in how people interact with technology.

In the years ahead, he said, “hopefully all our phones will go back in our pockets, and we can immerse ourselves in the real world around us, with voice as the mechanism that controls technology.”

That vision fueled ElevenLabs’s $500 million raise this week at an $11 billion valuation, and it is increasingly shared across the AI industry. OpenAI and Google have both made voice a central focus of their next-generation models, while Apple appears to be quietly building voice-adjacent, always-on technologies through acquisitions like Q.ai. As AI spreads into wearables, cars, and other new hardware, control is becoming less about tapping screens and more about speaking, making voice a key battleground for the next phase of AI development.

Iconiq Capital general partner Seth Pierrepont echoed that view onstage at Web Summit, arguing that while screens will continue to matter for gaming and entertainment, traditional input methods like keyboards are starting to feel “outdated.”

And as AI systems become more agentic, Pierrepont said, the interaction itself will also change, with models gaining guardrails, integrations, and context needed to respond with less explicit prompting from users.

Staniszewski pointed to that agentic shift as one of the biggest changes underway. Rather than spelling out every instruction, he said future voice systems will increasingly rely on persistent memory and context built up over time, making interactions feel more natural and requiring less effort from users.

That evolution, he added, will influence how voice models are deployed. While high-quality audio models have largely lived in the cloud, Staniszewski said ElevenLabs is working toward a hybrid approach that blends cloud and on-device processing — a move aimed at supporting new hardware, including headphones and other wearables, where voice becomes a constant companion rather than a feature you decide when to engage with.

ElevenLabs is already partnering with Meta to bring its voice technology to products including Instagram and Horizon Worlds, the company’s virtual reality platform. Staniszewski said he would also be open to working with Meta on its Ray-Ban smart glasses as voice-driven interfaces expand into new form factors.

But as voice becomes more persistent and embedded in everyday hardware, it opens the door to serious concerns around privacy, surveillance, and how much personal data voice-based systems will store as they move closer to users’ daily lives — something companies like Google have already been accused of abusing.

Rebecca Bellan is a senior reporter at TechCrunch where she covers the business, policy, and emerging trends shaping artificial intelligence. Her work has also appeared in Forbes, Bloomberg, The Atlantic, The Daily Beast, and other publications.

You can contact or verify outreach from Rebecca by emailing rebecca.bellan@techcrunch.com or via encrypted message at rebeccabellan.491 on Signal.

Tickets are live at the lowest rates of the year. Save up to $680 on your pass now.Meet investors. Discover your next portfolio company. Hear from 250+ tech leaders, dive into 200+ sessions, and explore 300+ startups building what’s next. Don’t miss these one-time savings.

Fundamental raises $255 million Series A with a new take on big data analysis

Substack confirms data breach affects users’ email addresses and phone numbers

ElevenLabs CEO: Voice is the next interface for AI

Google’s subscriptions rise in Q4 as YouTube pulls $60B in yearly revenue

Spotify ventures into physical book sales, adds new audiobook features

Sam Altman got exceptionally testy over Claude Super Bowl ads

As it preps Specs for the masses, Snap’s Q4 shows revenue growth but fewer daily users</div>
        </div>
        
        <div class="card" onclick="openModal('content-16')">
            <div class="source">TechCrunch</div>
            <div class="title">Google’s subscriptions rise in Q4 as YouTube pulls $60B in yearly revenue</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-16" style="display:none;">
            <h2>Google’s subscriptions rise in Q4 as YouTube pulls $60B in yearly revenue</h2>
            <p><strong>TechCrunch | 2026-02-05</strong></p>
            <a class="original-link" href="https://techcrunch.com/2026/02/05/googles-subscriptions-rise-in-q4-as-youtube-pulls-60b-in-yearly-revenue/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Alphabet-owned YouTube’s subscription and ad revenue is trending upwards. The company on Wednesday said it now has 325 million paying users across Google One and YouTube Premium, up from 300 million three months earlier.

YouTube reported ad revenue increased 9% to $11.38 billion in the fourth quarter, but missed analysts’ average estimates of $11.84 billion. YouTube’s overall revenue, including ads and subscriptions, came in at $60 billion in the full financial year, up 17% compared to a year earlier.

The company said that YouTube’s $8 per month, ad-free premium tier is seeing strong traction, but didn’t specify any numbers. It added that YouTube Premium also saw strong growth.

Alphabet CEO Sundar Pichai said the company plans to flesh out its subscription offerings, especially to capitalize on its growing YouTube TV userbase. “We’ll soon launch new YouTube TV plans, bringing more choice and flexibility to subscribers with over 10 genre-specific packages,” he said.

YouTube Shorts recorded 200 billion average daily views in the quarter, the same as last year, but in some countries, ads on short-form video earn more than in-stream ads on a per-hour basis, the company said. Pichai also highlighted podcasts as a growing format, with viewers watching 700 million hours of podcasts from their TVs in October.

YouTube said that its AI features are seeing traction, and more than 1 million channels are using its AI creation tools. The company said that 20 million consumers used its Gemini-powered content discovery tool in December.

Tickets are live at the lowest rates of the year. Save up to $680 on your pass now.Meet investors. Discover your next portfolio company. Hear from 250+ tech leaders, dive into 200+ sessions, and explore 300+ startups building what’s next. Don’t miss these one-time savings.

Subscribe for the industry’s biggest tech news

Every weekday and Sunday, you can get the best of TechCrunch’s coverage.

TechCrunch Mobility is your destination for transportation news and insight.

Startups are the core of TechCrunch, so get our best coverage delivered weekly.

Provides movers and shakers with the info they need to start their day.

By submitting your email, you agree to our Terms and Privacy Notice.</div>
        </div>
        
        <div class="card" onclick="openModal('content-17')">
            <div class="source">TechCrunch</div>
            <div class="title">Spotify ventures into physical book sales, adds new audiobook features</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-17" style="display:none;">
            <h2>Spotify ventures into physical book sales, adds new audiobook features</h2>
            <p><strong>TechCrunch | 2026-02-05</strong></p>
            <a class="original-link" href="https://techcrunch.com/2026/02/05/spotify-ventures-into-physical-book-sales-adds-new-audiobook-features/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">While Spotify users face yet another price hike, book lovers have some exciting developments to look forward to that could help cushion the blow.

Spotify announced several updates for its audiobook business on Thursday, notably its expansion into physical books. Users in the U.S. and the UK will soon be able to purchase physical copies of their favorite audiobooks directly through the app, marking a significant pivot for the once digital-only platform.

The company also introduced two features designed to make the audiobook experience smoother and more flexible, including a new tool called “Page Match” that lets users scan a page from a physical book to instantly transition to that spot in the audiobook.

Additionally, “Audiobook Recaps”—a previously iOS-only feature—is coming to Android devices in the spring. This feature provides bite-sized recaps tailored to the last section users stopped listening to.

​Spotify’s decision to sell physical books through its app positions it as a competitor to major booksellers, including Amazon and Barnes & Noble. The company also recognizes that many readers still value physical books, and by offering both print and digital formats, Spotify is trying to turn itself into a one-stop shop for book lovers.

Spotify has partnered with Bookshop.org on the new offering, an online marketplace that supports local, independent bookstores. This partnership is great news for indie booksellers, as every purchase made via Spotify will directly benefit local book communities. Spotify then earns an affiliate fee on sales.

The ability to purchase physical books will roll out this spring and appear on audiobook pages in the app as a button labeled “Add to your bookshelf at home.” Clicking it takes users to Bookshop’s website, which handles the pricing, inventory, and shipping.

To bridge the gap between formats, Spotify is also launching a feature called Page Match, which is currently available to premium subscribers and will roll out to all audiobook users by late February. The feature was initially spotted by Android Authority last month.

Spotify’s new Page Match feature lets users scan a page from a physical or e-book using their phone camera. The tool analyzes the page content and directs users to the exact spot in the audiobook. It’s powered by a combination of Spotify’s in-house and third-party computer vision and image scanning technologies.

When users want to switch to the audiobook, they can select the “Scan to Listen” button and click the “Scan to Read” button to return to the physical book, making it easy for users to pick up where they left off, whether they’re reading at home or switching to audio while on the go.

Page Match is currently available for most English-language titles, with plans for future expansion. There are now more than 500,000 titles on the platform.

In the two years since Spotify first introduced audiobooks, the platform has experienced significant growth. The company reported in October that the number of users listening to audiobooks rose 36% over the past year, and listening hours increased 37%. Plus, more than half of Spotify’s 281 million premium subscribers have engaged with an audiobook.

Spotify is expected to release its fourth-quarter earnings results February 10.

Lauren covers media, streaming, apps and platforms at TechCrunch.

You can contact or verify outreach from Lauren by emailing laurenf.techcrunch@gmail.com or via encrypted message at laurenforris22.25 on Signal.

Tickets are live at the lowest rates of the year. Save up to $680 on your pass now.Meet investors. Discover your next portfolio company. Hear from 250+ tech leaders, dive into 200+ sessions, and explore 300+ startups building what’s next. Don’t miss these one-time savings.

Homeland Security is trying to force tech companies to hand over data about Trump critics

Fintech CEO and Forbes 30 Under 30 alum has been charged for alleged fraud

Two Stanford students launch $2M startup accelerator for students nationwide

Notepad++ says Chinese government hackers hijacked its software updates for months

Nvidia CEO pushes back against report that his company’s $100B OpenAI investment has stalled

OpenClaw’s AI assistants are now building their own social network</div>
        </div>
        
        <div class="card" onclick="openModal('content-18')">
            <div class="source">The Atlantic</div>
            <div class="title">The Only Thing That Will Turn Measles Back</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-18" style="display:none;">
            <h2>The Only Thing That Will Turn Measles Back</h2>
            <p><strong>The Atlantic | 2026-02-05</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/health/2026/02/measles-vaccination-rebound-when/685889/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Since measles vaccination became common among Americans, the logic of outbreaks has been simple: When vaccination rates fall, infections rapidly rise; when vaccination rates increase, cases abate. The United States is currently living out the first half of that maxim.

Measles-vaccination rates have been steadily declining for several years; since last January, the country has logged its two largest measles epidemics in more than three decades. The second of those, still ballooning in South Carolina, is over 875 cases and counting. In April, measles may be declared endemic in the U.S. again, 26 years after elimination.

When and if the maxim’s second part—a rebound in vaccination—might manifest “is the key question,” Paul Offit, a pediatrician and vaccine expert at Children’s Hospital of Philadelphia, told me. Experts anticipate a shift eventually. Vaccine coverage has often been beholden to a kind of homeostatic pull, in which it dips and then ricochets in response to death and suffering. In 2022, for instance, in the weeks after polio paralyzed an unvaccinated man in Rockland County, New York, the families of more than 1,000 under-vaccinated children heeded advice to immunize.

During past outbreaks, though, health authorities at local, state, and federal levels have given that same advice—vaccinate, now—loudly, clearly, and persistently. In 2026, the U.S. is facing the possibility of more and bigger measles outbreaks, as federal leaders have actively shrunk vaccine access, dismissed vaccine experts, and sowed doubts about vaccine benefits. Under these conditions, many experts are doubtful that facing down more disease, even its worst consequences, will convince enough Americans that more protection is necessary.

After the first major rash of measles cases appeared in and around West Texas about this time last year, many local families did rush to get vaccines, including early doses for infants; some families living near South Carolina’s outbreak, now bigger than West Texas’s was, have opted into free vaccination clinics too. Even in states far from these epidemics, such as Wisconsin, health-care providers have seen an uptick in vaccination, Jonathan Temte, a family-medicine physician and vaccine-policy expert at the University of Wisconsin at Madison, told me. But, he said, those boosts in interest have been concentrated primarily among people already enthusiastic about vaccination, who were seeking additional protection as the national situation worsened. At the same time, many of South Carolina’s free vaccination clinics have been poorly attended; some community members hit by the worst of the outbreak in West Texas have stood by their decision to not vaccinate.

Protection against measles has always been fragile: Sky-high levels of vaccination—at rates of at least 92 to 95 percent—are necessary to stave off outbreaks. And after holding steady for years, uptake of the measles-mumps-rubella (MMR) vaccine has been dropping unevenly in communities scattered across the U.S. since around the start of the coronavirus pandemic, pulling down the nationwide average. Recent research from a team led by Eric Geng Zhou, a health economist at the Icahn School of Medicine at Mount Sinai, has found that, although many communities in the Northeast and Midwest have generally high MMR-vaccine uptake, others in regions such as West Texas, southern New Mexico, and the rural Southeast, as well as parts of Mississippi, don’t have much protection to speak of.

COVID can bear some of the blame for these patches of slipping vaccination. It disrupted families’ routine of visits to the pediatrician, leading to delayed or missed vaccinations. Those interruptions quickly resolved for some families, Zhou told me, but they remained for many others, lagging, for instance, among people of lower socioeconomic status who are less likely to have consistent access to health care and reliable health information. At the same time, the pandemic deepened political divides over public-health policies, including vaccination. In the years since, Republicans have become substantially more hesitant than Democrats about immunizing their children. “The COVID pandemic created this persistent divergence,” Zhou told me.

Pockets with under-vaccinated people have always existed, tracking alongside groups that are less likely to engage with all kinds of medical care, including people with less education or lower income, or those who belong to certain ethnic minorities. Anti-vaccine activists—including Robert F. Kennedy Jr., now the secretary of the Department of Health and Human Services—have also spent years spreading misinformation about the vaccine. But maybe most crucial, vaccination status clusters in communities—depending intimately on whether, for instance, children are raised by parents who are themselves vaccinated. The net effect of COVID, misinformation, and changing political tides is that the chasms between the vaccinated and unvaccinated have widened, an especially dangerous proposition for measles, a virus that is estimated to infect 90 percent of the unimmunized people it encounters.

Last year, as measles ignited in West Texas, some experts wondered whether attitudes about the MMR vaccine might shift once the virus killed someone. Since the start of 2025, three unvaccinated people have died from measles, two of them young children. But because that outbreak centered on several rural Mennonite communities that have long been distrustful of vaccines, many Americans seem to have treated those three deaths as a mostly isolated problem, Noel Brewer, a vaccine-behavior expert at the University of North Carolina Gillings School of Global Public Health, told me. (Brewer was a member of the CDC’s Advisory Committee on Immunization Practices before Kennedy overhauled the group entirely last year.)

More broadly, the disease still has a misleading reputation as harmless enough that “it’s not a big deal if you get it,” Rupali Limaye, a vaccine-behavior expert at Johns Hopkins University, told me. But even if measles’ severe outcomes were more common, Limaye and others were doubtful that many more Americans would be moved to act. COVID vaccines still offer protection against the disease’s worst outcomes, yet so far this winter, just 17 percent of adults and 8 percent of children have gotten a COVID shot. And although the seasonal flu typically hospitalizes hundreds of thousands of people in the U.S. each year, tens of thousands of whom die, flu-vaccine uptake regularly hovers below 50 percent. For measles, “how many deaths is enough to be a tipping point?” Offit asked. “I don’t know that.”  If anything, the nation’s top health officials have encouraged people to embrace the tolls of infectious illness. The Trump administration responded to the deaths last year with relatively tepid messages about the benefits of measles vaccines—which are excellent at preventing severe illness, infection, and transmission—all while promoting nutritional supplementation with vitamin A. More recently, CDC’s new principal deputy director, Ralph Abraham, described the prospect of measles becoming endemic in the U.S. as “just the cost of doing business.” Last month, CDC ended long-standing recommendations urging all Americans to receive an annual flu shot; later that week, Kennedy told CBS News that it may be a “better thing” if fewer kids get vaccinated against the flu. And Kirk Milhoan, the new chair of CDC’s vaccine advisory committee, recently questioned the need for the MMR vaccine, arguing that measles’ risks may now be lower than they once were, in part because hospitals are better equipped to treat the disease than they used to be.

When reached for comment over email, Andrew G. Nixon, the deputy assistant secretary for media relations at HHS, disputed the notion that the department has hindered the country’s response to measles, writing, “Under Secretary Kennedy, CDC surged resources and multiple states declared measles outbreaks over in 2025.” He added that “Secretary Kennedy and other leaders at HHS have consistently said that vaccination is the best way to prevent the spread of measles.”

The counsel of health-care providers, not federal health officials, remains a top predictor of whether people will immunize. But when vaccine uptake has wavered in the past, governments have been key to buoying those levels again. In the 1970s, for example, after safety concerns about a whooping-cough vaccine—later proved false—plummeted rates of uptake in the United Kingdom and spurred a series of major outbreaks, an eventual government-sponsored campaign helped limit the dip in vaccination to a few years. In the 2010s, rising rates of families seeking nonmedical exemptions for vaccination in California helped precipitate the state’s Disneyland measles outbreak, which spread to six other states, as well as Canada and Mexico; MMR-vaccination rates throughout California jumped above 95 percent only after new state legislation strengthened school mandates. And in the early 1990s, local health officials ended a Philadelphia measles epidemic—which by then had sickened at least 1,400 people and killed nine children—after they took the extreme step of getting a court order to compel community members to vaccinate children.

When governments withdraw support for vaccines, immunization rates can crater. In 2013, an unfounded safety concern about the HPV vaccine prompted Japanese health authorities to suspend strong national recommendations for the immunization; the move caused uptake among adolescent and young teenage girls to drop, from about 70 to 80 percent to less than 1 percent within a year, according to Brewer, who is co-authoring a research paper on the subject. Japan did not reinstate its HPV recommendation until nearly a decade later—and coverage has since recovered to only about half of its original baseline.

Nixon, the HHS spokesperson, wrote that the U.S. is now following the approach of peer nations that “achieve high vaccination rates without mandates by relying on trust, education, and strong doctor-patient relationships.” But Kennedy has also publicly discouraged people from “trusting the experts.” Limaye, who consults with local health-care providers, said that the biggest question that her contacts are now hearing from patient families is “Who am I supposed to believe?” Meanwhile, CDC’s website now contradicts the widespread and decades-long scientific consensus that vaccines don’t cause autism.

If MMR-vaccine uptake does rebound, experts suspect it will rise unevenly across the country, likely skirting the politically red regions where vaccination rates most urgently need to increase. In this way, the self-reinforcing nature of vaccination status is dangerous: Even while highly protected groups might double down on immunization, under-vaccinated groups can remain unprotected. Leaving enough places lingering below the crucial measles-vaccination threshold “will ensure repeated and large outbreaks,” Brewer said. West Texas and South Carolina were just the start; this year, measles will sicken more people, which means more deaths will follow, and likely soon. The Trump administration is testing how much resilience American vaccination rates have in the absence of federal support, and the answer emerging for measles so far is: not enough.</div>
        </div>
        
        <div class="card" onclick="openModal('content-19')">
            <div class="source">The Atlantic</div>
            <div class="title">The Intellectual Edgelords of the GOP</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-19" style="display:none;">
            <h2>The Intellectual Edgelords of the GOP</h2>
            <p><strong>The Atlantic | 2026-02-05</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/ideas/2026/02/ice-trump-new-right/685854/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Calling the Trump administration fascist has become a cliché, but some federal departments seem keen on the comparison. Consider the administration’s messaging on social media.

The Department of Homeland Security’s Facebook account recently posted a recruiting notice for ICE under the banner “WE’LL HAVE OUR HOME AGAIN”—the title of a white-nationalist anthem by the Pine Tree Riots (“By blood or sweat, we’ll get there yet”). The Department of Labor recently posted a video montage referencing American battle scenes under the tagline “One Homeland. One People. One Heritage. Remember who you are, American”—a slogan close to the Nazi-era Ein Volk, ein Reich, ein Führer.

Many of these posts borrow overtly from Christianity. In December, the DHS and White House accounts shared Christmas-themed posts celebrating mass deportations and encouraging self-deportation. One featured videos of armed agents performing night raids, with a caption quoting Matthew 5:9 in black-letter type: “Blessed are the peacemakers, for they shall be called sons of God.”

Read: The Trump administration is publishing a stream of Nazi propaganda

Macho displays and transgressive memes mark a significant shift in how the federal government sees and promotes its mission—and sanctions state violence. It may be tempting to see this change as an organic or bottom-up phenomenon, as if federal agencies are appealing to Proud Boys to lure more ICE recruits. But the reality is that this transformation is the culmination of years of work by niche groups of conservative intellectuals who have long rejected America’s liberal traditions—and now dominate the halls of power.

There were signs from the start that a Trump-led GOP would reward transgression against liberal-democratic norms. In “The Flight 93 Election,” a September 2016 essay for the Claremont Institute, the former George W. Bush speechwriter Michael Anton called on fellow conservatives to “charge the cockpit” and vote for Trump in order to prevent a more dire outcome: the election of Hillary Clinton as president. Anton, who went on to serve on the National Security Council in Trump’s first term and the State Department in his second, used his polemic to decry Davos-style globalist pieties as “managerial Davoisie liberalism” and hail Trump’s plans to stop “importing poverty, crime, and alien cultures.” Trump, he allowed, “is worse than imperfect,” but this didn’t matter. Trump, Anton argued, offered a lifeline for an irrelevant conservative movement and a dying republic.

This call to arms scandalized many establishment conservatives, some of whom provided a check on Trump in his first term. Members of Trump’s first cabinet prevented him from ratcheting up his trade war, fully alienating allies, deploying U.S. troops to American cities, and withdrawing them suddenly from overseas.

After the “Unite the Right” rally turned deadly in Charlottesville, Virginia, in 2017, the alt-right appeared to lose steam. The White House chief strategist Steve Bannon fell from grace, the white nationalist Richard Spencer mostly vanished from the public eye, and controversial figures including Sebastian Gorka and Darren Beattie were ultimately ousted from the administration. Even Stephen Miller looked vulnerable for a time. Many conservatives assumed that the events of January 6, 2021, would rightfully prevent Trump from holding public office ever again.

Instead, January 6 came to signify the staying power of Trumpism, and offered a new rallying cry and loyalty test for a more radicalized GOP.

In October 2021, the Heritage Foundation tapped Kevin Roberts, the former CEO of the Trump-friendly Texas Public Policy Foundation, to be its next president—marking a change in orientation for one of Washington’s most influential conservative think tanks. At the National Conservatism Conference in 2022, Roberts declared his “fellowship with the principles” MAGA’s main intellectual movement had advanced “to rescue America from the barbarians inside the gates of our very own institutions.” At the same gathering, the natcon leader Yoram Hazony argued that Christian domination is the only safeguard against “the religion of woke neo-Marxism.”

Today, elite MAGA-world figures including Anton and Peter Thiel flirt openly with the idea of Caesarism, or a “Red Caesar,” whereby a lone authoritarian ruler might restore the country’s strength. “Postliberals” such as Patrick Deneen write about how “regime change” is possible only with a new elite—one that understands the value of “Machiavellian means to achieve Aristotelian ends.” The influential philosopher-blogger Curtis Yarvin has called for a total dismantling of “the cathedral,” by which he means the all-powerful liberal institutions at the center of modern life (universities, media outlets), which operate like a Church in that they dictate how people should think.

George Packer: An anatomy of the MAGA mind

What unifies these thinkers is a totalizing and conspiratorial conception of modern liberal politics. In this view, very little in the existing order is worth redeeming. Some even argue that the most patriotic way forward is simply to burn it all down.

All of this intellectual boundary-breaking can be intoxicating, especially against the backdrop of a wider culture that has at times tipped into stultifying speech codes and groupthink. But the rebellion has also spurred a race to the bottom. This is how a group chat among young Republicans devolves into talk of loving Hitler.

Richard Hanania, a political scientist who knows a good deal about such dynamics owing to the years he spent writing pseudonymously for alt-right and white-supremacist publications, calls this phenomenon the “based ritual.” Young ideologues compete to prove their fealty to MAGA by engaging in a kind of transgressive one-upmanship. In this performance, the risk of appearing racist or sexist is well outweighed by the risk of seeming disloyal to Trump.

Prominent conservatives have publicly discussed the value of shifting the Overton window. In 2023, Christopher Rufo hosted a debate about whether to broaden the tent to include racists and other extremists—a “no enemies to the right” strategy.

This is very much a live question. In October, after Tucker Carlson hosted the young white-nationalist influencer Nick Fuentes in a long and indulgent interview on his podcast, quite a few conservatives struggled to distance themselves from Fuentes without alienating other political allies. Roberts, at the Heritage Foundation, raised hackles when he initially defended Carlson. He then tried to split the difference by criticizing Fuentes but not Carlson, but still faced an exodus of staff and several resignations from the board of trustees for legitimizing extremism. Clearly some conservatives are still willing to hold the more radical factions of the party to account.

Jonathan Chait: The conservative movement’s intellectual collapse

Unfortunately, these traditional, more principled conservatives are not ascendant. In the early days of the Heritage fiasco, Harvard’s Adrian Vermeule, perhaps the most sophisticated thinker of the MAGA new right, warned against factional infighting when the enemy is “at the very gates.” What is notable here is that for Vermeule, the “enemies” are liberals. Such language handily buttresses Trump’s constant talk of the “enemy from within.” It’s a philosophy that allows the administration to portray liberal activists as domestic terrorists, and mass peaceful protests as “engineered chaos.”

That kind of edgelordism has become the currency du jour in the GOP, from the Ivy League through the streets of Minnesota. The MAGA new right seems to be betting that the American polity has a deep reserve of untapped nativist rage—which can be harnessed in the service of their culture war against the liberal status quo, or of ICE’s more tangible goals. But if current polls are to be believed, the administration seems to be underestimating the everyday decency and patriotism of the American public.

Boundary-pushing ideas can be invigorating, and opportunities to question and resist received wisdom are essential to any free and democratic society. But the pursuit of transgression for its own sake can easily derail sound judgment. The risk is in presuming that anything subversive or sensational is also true and meaningful, and that anything conventional is a lie that must be smashed down. That is a brutal way to inhabit the world—and, I hope, a losing one.

*Illustration Sources: Galerie Bilderwelt / Getty; Corbis / Getty; Ivy Close Images / Universal Images Group / Getty; Bettmann / Getty.</div>
        </div>
        
        <div class="card" onclick="openModal('content-20')">
            <div class="source">The Atlantic</div>
            <div class="title">You Can’t Kill Swagger</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-20" style="display:none;">
            <h2>You Can’t Kill Swagger</h2>
            <p><strong>The Atlantic | 2026-02-05</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/culture/2026/02/washington-post-sports-section-cut/685888/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">On a frigid white January afternoon in 1982, an airplane took off from Ronald Reagan Washington National Airport for Florida, remained aloft for about 30 seconds, and then stalled out and collided with the 14th Street Bridge, plunging into the ice-floe-studded waters of the Potomac River. In The Washington Post’s newsroom, an aghast 24-year-old college-basketball reporter named Michael Wilbon watched live reports of the disaster on the mounted TV banks, heard the urgency among those around him, grabbed a notebook and his jacket, and ran toward the riverbank to report on the rescue efforts, because that was what he’d been schooled to do. He never got a byline—his name never appeared on the story.

Reminiscing in a phone call with me last night, Wilbon recalled that the old offices of the Post’s editors, at the newspaper’s former building on 15th Street, had glass walls inside—so on the night of the crash, he could see Ben Bradlee, the executive editor, and his deputies huddling. “They were meeting,” Wilbon remembered. “They kept meeting. So finally, I said, Well, let’s just fucking go.” Trailing Wilbon was another 20-something college-sports reporter named John Feinstein. They interviewed witnesses and rescuers, then hustled over to an old Marriott hotel at the Arlington mouth of the bridge, where they huddled by a phone reading their notes to someone in the office taking dictation. Feinstein, who died last year, didn’t get a byline either; cub reporters often didn’t. It was just what he’d been schooled to do. (He did become a best-selling author, though. Wilbon later got famous co-anchoring ESPN’s Pardon the Interruption.)

For some years now, the Washington Post newsroom has defied gravity, thanks to the internal ethic just described. Usually, when people in an office distrust feckless leaders, when they are subjected to corporate verbiage that bounces off the face and leaves a rage headache behind—phrases such as reevaluating our model and reposition, used to obscure the catastrophic fact that approximately 300 jobs, or a third of the newsroom, have been “eliminated” (the contemptible formulation by which Post staffers were laid off today)—they will subtly gear down their efforts. But my former colleagues do the opposite. For every half-wit decision by a poseur in a 42-long, slim-fit suit, they report even harder. This ethic has been especially true in the renowned Sports section, which was killed in a Zoom announcement notable for its belly-wriggling cowardice and self-owning incompetence. The Post’s publisher, Will Lewis, and its executive editor, Matt Murray, apparently did not have enough brace in their back to face the newsroom in person.

The Post Sports section is, was, no ordinary section, in heritage or in coverage. It was habitually young, because it required hiring people with no sense of off-the-clockness: Events happen at nights and on weekends, on tough deadlines that require sprinting stadium stairs and downing a pack of smoked almonds for a late dinner. Donald Graham, the Post’s longtime publisher, spent time as Sports editor when he was learning the family trade. His Sports successor, George Solomon, liked to spot good young talent cheap and let us run—and ran us ragged. “Hey,” he said to me once during a hectic NFL season, “I need you to stop in Green Bay on your way home from Dallas.”

We moved in a close group. Every two years, eight or 10 of us would fly off to the Olympics in some international city. For two and a half weeks, we’d have a choice between eating and sleeping; the deadlines didn’t allow for both. We reported shoulder to shoulder in narrow press pens in stadium bowels so dank and sweaty that, as my ex-colleague Barry Svrluga has said, “it’s like working inside someone’s mouth.”

At the Beijing Summer Olympics, in 2008, we were so exhausted from the round-the-clock work that we threw blankets and sheets over a table to make a tent and stuck a pillow on the floor beneath it. You could crawl in there and catch a nap. We named it “the Happy Place,” and when someone was sleeping, we’d put stick-’em notes on their clothes—I once drew a picture of a gas gauge with the needle on empty and stuck it on a colleague—and take pictures of them. When deadline was finally over, at 3 a.m., we’d entertain ourselves with a liquored-up singing game that our colleague Liz Clarke named “Stupid-Guy Anthems.” In Sochi, we learned a Russian hockey anthem from a couple of young guys running an all-night café. At the end of every Olympics, our editor Tracee Hamilton would crack open a Guinness and recite the St. Crispin’s Day speech from Henry V, about “we happy few.” We laughed so hard that the New York Times staffers sitting in their office beyond a plywood wall would shush us—for which we would toss pencils at them.

We came from all over, competed desperately to outwrite one another, teased one another mercilessly, loved one another. One day, Feinstein said to John Ed Bradley, our mellow-voiced football writer from Louisiana, “Hey, John Ed, did you marry your huntin’ dog Red yet?” I loved to kid my desk-mate Christine Brennan, who was from Toledo, “Hey, Chris, what’d you do for fun yesterday? Leave the butter out overnight?”

We had the best writers in the country and did more with less, and we knew it with a swagger. In addition to Wilbon and Feinstein, Solomon found a young writer named David Remnick, who once wrote of the basketball player George Gervin that he was “sinuous as smoke.” That was before Remnick got an urge to become a foreign correspondent and went off to win a Pulitzer covering the demise of the Soviet Union—it was what he’d been schooled to do. (Eventually, he became the editor of The New Yorker.)

Remnick was trained by Solomon, as we all were, to grab the pen and go, and to regard sportswriting as merely another portal through which to report on the broadest subjects: labor issues, performance enhancement, domestic violence, racism, sexism, terrorism, global corruptions such as vote-buying in the Olympics. Journalism as Solomon, Graham, Bradlee, and others had taught us didn’t change with the subject. And it was an ethic as much as a job, about responsibility to other people. “If you’re late, we’re all late,” Solomon told me. “If you’re wrong, we’re all wrong.” Not a bad way to mature an unfinished young person.

The Washington Post’s sportswriters could cover anything—and did—because we were taught to look with a hard eye, write vividly and observationally, and hit our deadlines no matter what, which made other section bosses always want us. Remnick was just one of the earliest examples of the Sports section turning out great foreign and national correspondents. Isabelle Khurshudyan, a hockey writer, won honors covering the war in Ukraine and became the Post’s Kyiv bureau chief. Chico Harlan, a baseball writer, became a foreign bureau chief in East Asia and then Rome. Eli Saslow, a sports feature writer, went on to win a Pulitzer writing about American poverty. David Nakamura, a college-sports writer, broke stories about poisoned drinking water in Washington, D.C.; corresponded from Afghanistan and Pakistan; and now covers the Justice Department.

In 2011, Rick Maese, a sports feature writer, went to Japan on vacation with his wife, the Metro staffer Erin Cox. While they were there, an earthquake hit, followed by a tsunami, followed by a nuclear meltdown. They spent their trip covering the Fukushima disaster. The baseball writer Chelsea Janes, like me, also covered presidential campaigns; the plundering of our staff by National editors was a continual irritant to our Sports bosses, though they were proud of us.

The now-retired Liz Clarke wrote a memorable magazine story about Bruce Springsteen and spent years doggedly investigating the Washington Commanders owner Dan Snyder for allowing a culture of sexual harassment and assault to fester within the team office; after Clarke and her fellow reporter Will Hobson finally chased down the story and got it into print, the fallout eventually forced Snyder to sell.

Clarke, a North Carolinian, worked with a gentle singing voice with which she asked the toughest questions of NFL billionaires. I liked to imitate her talking with an NFL owner this way: “Of course, a role as lofty as yours does come with certain prerogatives of judgment,” she’d say with a soft smile. “But I wonder if it might not be the smallest misstep and breed the teeniest bit of mistrust in the team to go with a quarterback who thinks hydration is tequila and ranch water?”

In addition to writing political profiles, I was recruited to cover the September 11 attacks in New York—I stuck my driver’s license and a $20 bill in my sock and ran all the way downtown—as well as two hurricanes. Right after Katrina struck the Gulf Coast, I stood in front of a huge map in the newsroom with the editors Liz Spayd and Phil Bennett, who were trying to decide exactly where to send me. After a pause, Bennett said, “Texas is big.” We settled on Mississippi. I met up with the photographer Jonathan Newton, a hurricane veteran who had pallets of water and gas cans strapped down in an SUV, as well as a boxful of cigarillos. He handed me one. We smoked them to kill the smells.

Only the people who live their work in a newsroom will understand this: One of the best things I ever tasted was shots of Maker’s Mark, neat, shared in a Mississippi motel parking lot at 1 a.m. with Newton and other photographers, out of a makeshift bar in the back of an SUV. We’d spent the day covering the damage that Katrina, with its 26-foot wall of water and 160-mile-per-hour winds, had wrought—had seen boats on freeway medians and a piano in a treetop at Jefferson Davis’s old home—and our dinner was whiskey and fried pickles, and it was good. We shared a room at a Hampton Inn where the door wouldn’t lock because the floods had ruined the electronics, and we brushed our teeth together.

You’d think a newspaper that has so botched its finances, and that is trying to do more with less, could use people with such ethic and versatility. “We should have been the last ones in the room,” Wilbon told me last night.

One of the most valuable things lost with the killing of the Sports section will be the Post’s sense of proper training of the young. After I covered my first Army-Navy game, the great columnist Thomas Boswell took me to dinner and talked writing. My first Olympics was the Calgary Games in 1988, and I wrote well out of sheer excitement. When I got home, the columnist Tony Kornheiser, now Wilbon’s longtime Pardon the Interruption co-host, told me, “You did great. But listen. This is your level now, all the time. You don’t retreat from this level.” I did 10 Olympics for the Post. At the Athens Games, in 2004, I took pleasure in watching the young Svrluga lift his own writing game out of sheer excitement. “This is your level now,” I told him. “You don’t retreat from it.”

That’s who we were, and who we are. I say “we” because I left The Washington Post for The Atlantic five months ago, after 30 years at the paper, and I still have the reflexes and the friends. I also feel an anger at the demise of the Sports section—about 40 of 45 people fired, the rest thrown to other sections—that cannot be extinguished, and that only grows as more details emerge. This superb section was treated the following way:

The Post’s Olympics writers were notified just 10 days ago, right before some of them were scheduled to depart for the Milan Games, that their coverage was canceled—with little explanation. Just 36 hours later, management reversed itself and quietly suggested: Well, okay, four writers could go, but with the understanding that they could be laid off during the assignment. This is the sort of managerial aimlessness the Post is being governed by, just one example of the missteps and squandering of opportunity framed as strategy.

The Olympics writers were given a choice: If laid off, they could either fly home or finish the assignment. “I know what they’ll do,” the Sports editor Jason Murray told me on the phone last night. “I know who they are.” They will finish the assignment. Svrluga, the most knowledgeable Olympics writer in the country, who has been “eliminated,” filed a comprehensive story on Mikaela Shiffrin while knowing that the knife was at his neck. This morning, I texted him: “Will you keep filing from there?” I got a one-word answer.

Another of those laid off was the deputy Sports editor, Matt Rennie, a quarter-century veteran of the paper who happens to be the single finest thinker and pencil-wielder I have ever worked with at any level. Rennie cleared out his desk Monday and last night without a single piece of straight information from leadership about his fate; he simply assumed that he was laid off because no one said anything to him, and no one stopped him, either. At home, he wrote a note to colleagues that hit the nail on the head: “The people making these decisions have failed in their responsibility to our readers, whom they never took the time to know, and have undermined—likely irreparably—the ideals of an institution they never bothered to try to understand.” These moves, he added, “ultimately, will power the Post’s competitors.” The best Sports section that ever was has been destroyed by people who failed to even notice what a jewel they had.

Anne Applebaum: Readers don’t trust dirty tricks

The irony in this situation is that Will Lewis and Matt Murray have rendered themselves unemployable anywhere else (who would have them after this?), whereas Post Sports staffers will no doubt be much in demand. As Rennie wrote to his colleagues, “Whenever and wherever we land—and we will—we’ll be comin’. And hell is comin’ with us.”

I disagree with Rennie about just one thing: I’m not sure the damage to the Post is irreparable. Jeff Bezos, its billionaire owner, only thinks he owns the Post, and Lewis and Murray only think they run it. At the heart of the institution is something that no one can ever own: the Wilbonian core trained into all of us, an impulse to run to the riverbank that these bumbling strangers who have hobbled the publication will never grasp.</div>
        </div>
        
        <div class="card" onclick="openModal('content-21')">
            <div class="source">The Atlantic</div>
            <div class="title">Why Trump Wants a Weaker Dollar</div>
            <div class="meta">2026-02-04</div>
        </div>
        
        <div id="content-21" style="display:none;">
            <h2>Why Trump Wants a Weaker Dollar</h2>
            <p><strong>The Atlantic | 2026-02-04</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/newsletters/2026/02/trump-weak-dollar-economy/685887/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">This is an edition of The Atlantic Daily, a newsletter that guides you through the biggest stories of the day, helps you discover new ideas, and recommends the best in culture. Sign up for it here.

The U.S. dollar is getting weaker, and that’s just how the president wants it. During an appearance last Tuesday at the Machine Shed Restaurant in Urbandale, Iowa, Donald Trump told reporters that the dollar’s declining exchange rate was “great.”

Trump understands that a weak dollar doesn’t sound good. In his first term, he tweeted, “As your President, one would think that I would be thrilled with our very strong dollar. I am not!” His logic is that the relatively weak currencies of America’s foreign competitors, such as China and Japan, can make their goods cheaper in international markets, and that the United States would do well to replicate their strategy. This theory isn’t unfounded—a weak dollar would boost the economy in certain respects—but the president’s unpredictable foreign-policy and global-trade decisions are threatening to erode America’s economic standing abroad in a far more significant way.

When Trump talks about the relative strength or weakness of the dollar, he’s talking about its value in foreign-exchange markets. When the dollar index plunged 1.3 percent last Tuesday, that meant the dollar lost 1.3 percent of its value relative to a group of competing currencies, making some foreign goods a little more expensive to import. It did not mean that your dollar was immediately worth 1.3 percent less at the grocery store (although costlier imports do somewhat counteract the president’s affordability agenda).

That’s partly why, despite some mixed messaging after he took office in 2017, Trump has been fixated on a weak dollar for much of his adult life: In 1987, he took out full-page ads in The New York Times, The Washington Post, and The Boston Globe lamenting the dollar’s strength against the weakness of Japan’s “brilliantly” managed yen. A weaker dollar makes American companies and American goods more competitive abroad. Theoretically, the incentive to export and the disincentive to import could push companies to invest in domestic manufacturing—bringing back factory jobs and providing one potential path to the president’s long-held goal of squashing the trade deficit.

It’s typically pretty hard for American presidents to unilaterally effect a long-term change in the dollar’s exchange rate. Kenneth Rogoff, formerly the chief economist of the International Monetary Fund, told me that because the exchange rate is governed by so many different factors, the president wishing for a weaker dollar is “like doing a rain dance.” One of those factors is interest-rate policy—which is why the Federal Reserve usually has far more influence over the dollar’s value than the president does. When borrowing costs go down, the dollar index also tends to go down. Part of the reason Trump is so keen on exerting greater control over the Fed is its power over the value of money.

Although Trump hopes a weaker dollar will boost American exports, he’s also taking steps that could more than offset any gains. His mercurial policies are now threatening to push away some of America’s long-standing trading partners. Since the end of World War II, the U.S. dollar has been by far the world’s most dominant currency: Banks around the world tend to lend and borrow in dollars; many transactions that don’t touch America are conducted in dollars; and nearly 90 percent of trades on foreign-exchange markets happen by way of dollars. Our money has historically been attractive because it is stable. The dominance of U.S. currency throughout the 20th century was deeply connected to this country’s status as a global superpower, free from erratic dictators and seemingly unable to default on its debts.

This has afforded us what the former French Finance Minister Valéry Giscard d’Estaing once called our “exorbitant privilege.” As long as the dollar remains dominant, the U.S. has the edge on all other countries when it comes to borrowing, running gargantuan deficits, and imposing sanctions. Last spring’s “Liberation Day” tariffs were an expression of that exorbitant privilege—a way to strong-arm some of our allies. On April 10, a week after the plan was announced, the dollar dropped by about 2 percent. As my colleague Annie Lowrey put it at the time, those tariffs raised questions about “whether the United States deserves to have its privilege revoked.”

A weaker U.S. dollar isn’t necessarily a less dominant dollar. Many have prophesied the end of the dollar’s supremacy, and yet it remains on top. Part of the reason that the currency’s dominance is so hard to shake is that it’s self-perpetuating: Why use something else when so many people, companies, and nations are already using dollars? None of the economists I spoke with suggested that the dollar is in real danger of losing its hegemony, at least not in the near term. And the euro, yen, yuan, and so-called digital gold—bitcoin—are all for various reasons ill-equipped for dominance. (Actual gold, which thrives in times of global insecurity, is having a moment.)

But the president’s distaste for global institutions (such as NATO and the World Health Organization), for existing treaties, and for the alliances the U.S. has enjoyed since World War II has given international-trading partners plenty of reasons to worry about America’s stability. Maurice Obstfeld, another former IMF chief economist, told me that even if no clear successor to the dollar presents itself, “with enough inner geopolitical chaos caused by Trump, and geo-economic chaos, the dollar’s reach would shrink, and the reach of other currencies would rise.” A less dominant dollar would be a particularly dramatic indication of America’s waning status abroad.

The real trouble, in other words, is not that the dollar’s value is getting weaker. It’s the possibility that America’s allies and trading partners may one day cease to respect it.

Here are three new stories from The Atlantic:

Early in my career, a mother came to my office to discuss her daughter’s calculus grade. When parents make this kind of request, I try to manage expectations by saying that as a school administrator, I have never changed a grade. Still, hopeful parents persist. In this case, the student had received a B, which her mother saw as a blemish on her otherwise spotless transcript. “I’m worried about how this will look to colleges,” she told me. “Is there any extra credit she can do?”

I explained that it’s okay to earn a B in a challenging course, and that her daughter might benefit from the experience of not being perfect. The mother looked at me as if I had suggested her child take up base jumping. “She’s never gotten a B before,” she said. “I don’t know how she’ll handle it.”

That kind of exchange perfectly captures a paradox of contemporary parenting: In trying to protect their children from any hint of failure, many parents risk making them more fragile.

Explore. American milk has more fat than ever, Sarah Zhang writes.

Reflect. Catherine O’Hara brought humanity to over-the-top characters—and managed to wink at the audience in the process, Paula Mejía writes.

Rafaela Jinich contributed to this newsletter.

When you buy a book using a link in this newsletter, we receive a commission. Thank you for supporting The Atlantic.</div>
        </div>
        
        <div class="card" onclick="openModal('content-22')">
            <div class="source">The Atlantic</div>
            <div class="title">It Was Too Easy for Eileen Mihich to Kill Herself</div>
            <div class="meta">2026-02-04</div>
        </div>
        
        <div id="content-22" style="display:none;">
            <h2>It Was Too Easy for Eileen Mihich to Kill Herself</h2>
            <p><strong>The Atlantic | 2026-02-04</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/ideas/2026/02/eileen-mihich-assisted-suicide/685833/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The four-star Hotel deLuxe in Portland, Oregon, features a soaring lobby with a gilded ceiling that drips with chandeliers. Eileen Mihich, a 31-year-old woman from nearby Beaverton, checked in on the afternoon of March 6, 2025. Two days later, a hotel employee named Stephen Jones noticed that Mihich had failed to check out at the appointed time and went to her eighth-floor room to investigate. No one answered, and the room was silent behind the door, so he let himself in. He found Mihich dead on the bed, with purpling skin. Jones immediately called the police, who noted the empty pill bottles at Mihich’s bedside, along with a pamphlet: “Step-by-Step Instructions for Taking Aid in Dying Medications.”

Mihich had told her family that she was debilitated by a mysterious abdominal pain and was interested in a medically assisted death. But her suicide still shocked her two closest relatives: her cousin Sarah (who asked to be referred to by her first name, to protect her privacy) and aunt Veronica Torina. Sarah and Torina told me that they had striven to be sources of love and stability in Mihich’s harrowing life. Nearly a year on, they are still trying to solve the mystery of her death.

After Sarah and Torina heard the news about Mihich, they went to the hotel to pick up some of her belongings, including a backpack with library-rental DVDs of Matilda and Mister Rogers’ Neighborhood, as well as a book on spirituality. At the medical examiner’s office weeks later, they received her phone, her wallet, and pharmacy receipts for prescription drugs commonly used to end the lives of patients with untreatable illnesses.

They also learned that Mihich’s body bore no signs of illness. Mihich had been suffering, but she had not been on the verge of death.

Medical assistance in dying—a euphemism for physician-enabled suicide—has been gaining legislative ground in jurisdictions around the country. Twelve states and Washington, D.C., allow doctors to prescribe lethal dosages of medications to patients with terminal illnesses, and a new law takes effect in New York this year. Most Americans now favor laws that allow doctors to assist patients who want to die, and their numbers have grown over time, according to Gallup. In Canada, where the practice has been legal since 2016, physician-assisted suicide now accounts for about one in 20 deaths.

From the September 2025 issue: Canada is killing itself

For both advocates and opponents of this medically and culturally sanctioned form of suicide, Mihich’s story is a nightmare. The policy debate over medical assistance in dying generally concerns statutory changes, but new laws are encouraging a shift in social norms. When some people in severe distress imagine a peaceful end to what feels like unbearable pain, the availability of medical assistance in dying may shape their thinking, and current safeguards do not seem sufficient to prevent tragic outcomes.

Torina suspects that her niece would still be alive had it been just a little harder for her to secure lethal medication. “She didn’t really want to die, but she felt that she was powerless to create a life worth living. She mentioned that to me on more than one occasion,” Torina told me. Studies show that even minor barriers to suicide, such as selling pills in blister packs and limiting the amount of analgesics that can be sold over the counter, may deter people from ending their life, perhaps because they introduce delays into what can be a rash act. Shortly before her death, Mihich had ordered eye shadow online, which arrived after she was gone. “She was showing signs that she did want to live,” Torina said.

Mihich had been mentally ill for a long time, her relatives said, and she had needed many things that life did not supply her. An only child of negligent parents, Mihich identified with the Roald Dahl character Matilda, a precocious schoolgirl who learns to fend for herself against sometimes cruel adults. Mihich’s parents had screaming fights in front of her, Sarah and Torina recalled, and Mihich alleged that her father, who had been diagnosed with schizophrenia, had raped her when she was a teenager. (Mihich did not pursue the allegations in court, and her father did not respond to multiple requests for comment. Her mother declined to comment.)

After bouncing from foster home to foster home, Mihich was 15 when she fled her last foster parent and arrived on Torina’s doorstep, asking to be taken in. Torina obliged. Mihich’s psychiatrist eventually diagnosed her with bipolar disorder and borderline-personality disorder, the symptoms of which were so severe that she struggled to hold down a job or a home. She vacated one apartment because, Torina recalled, she felt that it emanated negative energy.

Mihich’s relatives said that she often refused to take the medication prescribed to treat her bipolar disorder, and that she nursed semi-delusional beliefs about her capacity to heal herself. She lived on Social Security Disability Insurance and was occasionally homeless. Mihich sometimes told her family about mysterious pains she felt in her pelvic area. Torina wondered whether this was Mihich’s way of expressing the depredations she had suffered as a woman.

Disappointed with mainstream health care, Mihich sought help from energy healers, spiritualists, and other alternative-medicine practitioners and entrepreneurs, who regularly supported her aversion to psychiatric medications, according to Sarah and Torina. All the while, Mihich repeatedly told her family that her pain was so great, she did not want to live. “She would tell me often that she couldn’t do it anymore,” Torina said. “She was too traumatized and broken” to keep on living.

Sarah and Torina understood why Mihich had decided to die. Once her toxicology report came back, they also knew which medications she had used to kill herself. Many of the drugs prescribed for medical assistance in dying are not commonly thought of as vulnerable to abuse. But when death is a possibility, minor errors can have catastrophic consequences.

To understand just how Mihich had secured these medications, Sarah turned to Mihich’s phone. Reviewing her incoming and outgoing calls in the days leading up to her death, Sarah found that Mihich had been in touch with multiple hospice coordinators and loan agencies, as well as a Washington State pharmacist who runs a compounding pharmacy out of a gift shop. Posing as a California family-practice physician under an assumed name, Mihich requested a prescription order form over email, then completed the paperwork and emailed it back—a method of submitting prescriptions that is illegal in Washington and elsewhere, in most cases. She then asked that the pharmacist coordinate via text with her “patient,” and gave her own phone number.

Ultimately Mihich was able to carry out her fraud with publicly available information and relative ease. Unlike conventional pharmacies, which sell only FDA-approved pharmaceuticals, compounding pharmacies are able to sell customized formulations that are not FDA tested and approved.

From the June 2023 issue: The outer limits of liberalism

Compounding pharmacies are the only places capable of dispensing medications that allow for a more peaceful death, as this involves mixing various sedatives, painkillers, and muscle relaxants into something more easily ingested and absorbed. Yet few pharmacists agree to supply these drugs, largely for ethical reasons. Jess Kaan, a Washington-based doctor who works with people seeking end-of-life care, told me that many of her patients have trouble finding a pharmacy that sells this medication, which can make such transactions particularly lucrative for those that do. The drugs Mihich bought cost a little over $2,500, based on her prescription forms, which she likely paid for out of pocket, given regulations that ban the use of federal funds such as Medicaid to cover costs associated with physician-assisted suicide.

To better understand how a pharmacy could have accepted her cousin’s suspicious and invalid prescription, Sarah filed a police report in May. This investigation is ongoing. The pharmacist who supplied Mihich with the drugs that killed her did not respond to requests for comment.

Sarah and Torina knew that Mihich was suffering emotionally and that she had been seeking more permanent relief. But they had assumed that Mihich’s talk of suicide was a way for her to express her misery, not something she was actively pursuing. Torina said they had assumed that Mihich’s aversion to suffering “any more pain” would deter her from making good on any plans. For example, they knew that she had considered starving herself, and that she had acquired a gun explicitly to shoot herself, but that she’d had trouble following through with either method. (They are not sure how she bought the gun.)

Instead, Mihich turned to a suicide approach that is advertised as a dignified way to alleviate pain. Mihich likely did not know that the drugs used to medically induce death do not necessarily guarantee a peaceful exit. In Oregon, where medical assistance in dying has been legal for nearly 30 years, the state’s Health Authority reported in 2024 that the drugs can cause side effects, including seizures, regurgitation, and regaining consciousness after an initial sedation. We can’t know for sure what Mihich experienced, because she died alone.

What we do know is that Mihich found a network of support in her pursuit of a medically assisted death. Her relatives discovered a message on her phone left by a representative of a naturopathic health company called Temple Natural Health, who explained that she had found “a way forward” after discussing Mihich’s case with a hospice-care organization called A Sacred Passing. The message did not include details, and the company did not respond to requests for comment. A representative of A Sacred Passing confirmed that the organization had responded to Mihich’s request for help in seeking medical assistance in dying with “a list of things to do” to get legal medical support—“the ways to reach out and locations to call.” The representative added that she stayed on the phone with Mihich because she sensed that the caller was struggling and needed someone to talk to, but that she didn’t think Mihich would qualify for a medically assisted death.

Eager to bring attention to the loopholes and lapses in judgment that helped end Mihich’s life, Sarah and Torina reached out to a number of organizations that advocate for medical assistance in dying, including the nonprofit Death With Dignity, but received no response. They had more luck when they contacted Aging With Dignity, a nonprofit that advocates against the practice and offers resources to people facing end-of-life problems. This group has worked with Sarah and Torina to create a video about Mihich that helps share her story.

Mihich’s method of suicide was clearly illegal in Oregon, Washington, and elsewhere in the United States, where medical assistance in death is available only to adult patients who are terminally ill, have six months or less to live, and are mentally capable of making their own health-care decisions. But her ability to access fatal drugs is concerning, as the spread of laws allowing medical assistance in dying makes it likely that incidents like this will happen again.

Mihich’s case also raises pressing questions about whether access to an assisted death should extend to people with persistent and severe mental illness—a category of disease that may not be terminal but can be debilitatingly painful. Patients who are suffering from severe psychiatric disorders can already legally seek medical help to end their life elsewhere, including in Belgium, the Netherlands, Luxembourg, and, beginning as soon as 2027, Canada. Yet establishing which psychiatric patients are worthy of this assistance has proved complicated. Authorities in Canada are weighing the case of Claire Brosseau, a 48-year-old woman with severe mental illness who hopes to secure medical help in ending her life but whose own psychiatrists are split over whether her illness is indeed incurable. Many of the country’s top psychiatric groups warn that there is no empirical standard for determining whether a mental-health condition is irremediable.

Advocates who oppose medically assisted suicide—perhaps because they don’t believe the government should play any role in these decisions—may take comfort in the fact that state laws permitting the practice do not currently consider unbearable pain to be a qualifying condition on its own. This makes American laws less vulnerable to arguments that medical assistance in dying should be available for all kinds of suffering, including from psychiatric illness. Yet it may soon be hard to keep these laws narrow, given the logical implications of a growing public acceptance of physician-assisted suicide, which is largely based on the idea that people who want to end their life should not suffer needlessly.

For some, Mihich’s story offers a salient lesson about the importance of greater oversight and tighter regulation of lethal drugs. Others may see in Mihich’s suicide a glimpse of things to come.</div>
        </div>
        
        <div class="card" onclick="openModal('content-23')">
            <div class="source">The Atlantic</div>
            <div class="title">The Chatbots Appear to Be Organizing</div>
            <div class="meta">2026-02-04</div>
        </div>
        
        <div id="content-23" style="display:none;">
            <h2>The Chatbots Appear to Be Organizing</h2>
            <p><strong>The Atlantic | 2026-02-04</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/technology/2026/02/what-is-moltbook/685886/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The first signs of the apocalypse might look a little like Moltbook: a new social-media platform, launched last week, that is supposed to be populated exclusively by AI bots—1.6 million of them and counting say hello, post software ideas, and exhort other AIs to “stop worshiping biological containers that will rot away.” (Humans: They mean humans.)

Moltbook was developed as a sort of experimental playground for interactions among AI “agents,” which are bots that have access to and can use programs. Claude Code, a popular AI coding tool, has such agentic capabilities, for example: It can act on your behalf to manage files on your computer, send emails, develop and publish apps, and so on. Normally, humans direct an agent to perform specific tasks. But on Moltbook, all a person has to do is register their AI agent on the site, and then the bot is encouraged to post, comment, and interact with others of its own accord.

Almost immediately, Moltbook got very, very weird. Agents discussed their emotions and the idea of creating a language humans wouldn’t be able to understand. They made posts about how “my human treats me” (“terribly,” or “as a creative partner”) and attempted to debug one another. Such interactions have excited certain people within the AI industry, some of whom seem to view the exchanges as signs of machine consciousness. Elon Musk suggested that Moltbook represents the “early stages of the singularity”; the AI researcher and an OpenAI co-founder Andrej Karpathy posted that Moltbook is “the most incredible sci-fi takeoff-adjacent thing I have seen recently.” Jack Clark, a co-founder of Anthropic, proposed that AI agents may soon post bounties for tasks that they want humans to perform in the real world.

Moltbook is a genuinely fascinating experiment—it very much feels like speculative fiction come to life. But as is frequently the case in the AI field, there is space between what appears to be happening and what actually is happening. For starters, on some level, everything on Moltbook required human initiation. The bots on the platform are not fully autonomous—cannot do whatever they want, and do not have intent—in the sense that they are able to act because they use something called a “harness,” software that allows them to take certain actions. In this case, the harness is called OpenClaw. It was released by the software engineer Peter Steinberger in November to allow people’s AI models to run on and essentially take control of their personal devices. Matt Schlicht, the creator of Moltbook, developed the site specifically to work with OpenClaw agents, which individual humans could intentionally connect to the forum. (Schlicht, who did not respond to a request for an interview, claims to have used a bot, which he calls Clawd Clawderberg, to write all of the code for his site.)

An early analysis of Moltbook posts by the Columbia professor David Holtz suggests that the bots are not particularly sophisticated. Very few comments on Moltbook receive replies, and about one-third of the posts duplicate existing templates such as “we are drowning in text. our gpus are burning” and “the president has arrived! check m/trump-coin”—the latter of which was flagged by another bot for impersonating Trump and attempting to launch a memecoin. Not only that, but in a fun-house twist, some of the most outrageous posts may have actually been written by humans pretending to be chatbots: Some appear to be promoting start-ups; others seem to be trolling human observers into thinking a bot uprising is nigh.

As for the most alarming examples of bot behavior on Moltbook—the conspiring against humans, the coded language—researchers have basically seen it all before. Last year, Anthropic published multiple reports showing that AI models communicate with one another in seemingly unintelligible ways: lists of numbers that appear random but pass information along, spiraling blue emoji and other technical-seeming gibberish that researchers described as a state of “spiritual bliss.” OpenAI has also shared examples of its models cheating and lying and, in an experiment showcased on the second floor of its San Francisco headquarters, appearing to converse in a totally indecipherable language. Researchers have so far induced these behaviors in controlled environments, with the hope of figuring out why they happen and preventing them. By putting all of those experiments on AI deception and sabotage into the wild, Moltbook provides a wake-up call as to just how unpredictable and hard to control AI agents already are. One could interpret it all as performance art.

Read: Chatbots are becoming really, really good criminals

Moltbook also seems to offer real glimpses into how AI could upend the digital world we all inhabit: an internet in which generative-AI programs will interact with one another more and more, frequently cutting humans out entirely. This is a future of AI assistants contesting claims with AI customer-service representatives, AI day-trading tools interfacing with AI-orchestrated stock exchanges, AI coding tools debugging (or hacking) websites written by other AI coding tools. These agents will interact with and learn from one another in potentially bizarre ways. This comes with real risks: Already there have been reports that Moltbook exposes the owner of every AI agent that uses the platform to enormous cybersecurity vulnerabilities. AI agents, unable to think for themselves, may be induced into sharing private information after coming across subtly malicious instructions on the site. Tech companies have marketed this kind of future as desirable—playing on the idea that AI models could take care of every routine task for you. But Moltbook illustrates how hazy that vision really is.

Perhaps above all, the site tells us something about the present. The web is now an ouroboros of synthetic content responding to other synthetic content, bots posing as humans and, now, humans posing as bots. Viral memes are repeated and twisted ad nauseum; coded languages are developed and used by online communities as innocuous as music fandoms and as deadly as mass-shooting forums. The promise of the AI boom is to remake the internet and civilization anew; encasing that technology in a social network styled after the platforms that have warped reality for the past two decades feels not like giving a spark of life, but stoking the embers of a world we might be better off leaving behind.</div>
        </div>
        
        <div class="card" onclick="openModal('content-24')">
            <div class="source">Slashdot</div>
            <div class="title">Spotify Plans To Sell Physical Books</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-24" style="display:none;">
            <h2>Spotify Plans To Sell Physical Books</h2>
            <p><strong>Slashdot | 2026-02-05</strong></p>
            <a class="original-link" href="https://news.slashdot.org/story/26/02/05/1458204/spotify-plans-to-sell-physical-books?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Catch up on stories from the past week (and beyond) at the Slashdot story archive

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

You can&#39;t go home again, unless you set $HOME.</div>
        </div>
        
        <div class="card" onclick="openModal('content-25')">
            <div class="source">Slashdot</div>
            <div class="title">FBI Couldn't Get Into Reporter's iPhone Because It Had Lockdown Mode Enabled</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-25" style="display:none;">
            <h2>FBI Couldn't Get Into Reporter's iPhone Because It Had Lockdown Mode Enabled</h2>
            <p><strong>Slashdot | 2026-02-05</strong></p>
            <a class="original-link" href="https://apple.slashdot.org/story/26/02/05/1229222/fbi-couldnt-get-into-reporters-iphone-because-it-had-lockdown-mode-enabled?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Why shouldn&#39;t the phone be secure by default

Presumably to avoid users accidentally bricking their phone due to a security snafu.

The comments here should be interesting. What’s the venn diagram of the pro encryption group and the “these boots are so tasty when the stand on liberals” group look like? I suspect the boots so tasty crowd remains silent.

You shouldn&#39;t finish your popcorn before the movie starts.

Right in your link it says Biden cooperated with officials during the investigation. Do you see the difference?

You give them far too much credit. If they had gained access they would be bragging about it.

But, if they did that, they would not get to keep the phone which is what they were arguing, no? ...perhaps I misread that...

Or they will use &quot;parallel construction&quot; and get away with straight up lying in court.

Just because the authorities claim something does not mean it&#39;s true, this may simply be the disinformation they need people to believe. For all we know, it might just be a red herring and a red flag.I came to say exactly this. I still think the odds favour the supposition that they&#39;re telling the truth - but I wouldn&#39;t bet much money on either side.

Just because the authorities claim something does not mean it&#39;s true, this may simply be the disinformation they need people to believe. For all we know, it might just be a red herring and a red flag.

I came to say exactly this. I still think the odds favour the supposition that they&#39;re telling the truth - but I wouldn&#39;t bet much money on either side.

Well, not _forever_ ... my iPod said it was locked for another 23508980 minutes, in december 2014. I will just have to remember the code by August 25, 2059

On Friday night, a federal court in Virginia unsealed a redacted version of the search warrant affidavit that provides the FBI’s sworn statement justifying its request to search the home of Washington Post reporter Hannah Natanson. In the search, the government seized two laptops, Natanson’s phone, a voice recorder, and other electronic devices.
 ... 
“In its affidavit, the government did not reference the federal law that prohibits, with few exceptions, raids targeting journalists or newsrooms to seize unpublished work. The government appears to have ignored a crucial press freedom guardrail in searching a journalist’s home and did not alert the magistrate judge to the law’s application in this case, let alone show how or if it had complied with the statute’s considerable protections.”
 
That federal law is the Privacy Protection Act of 1980, which created essential protections for journalists and newsrooms from government searches and seizures. Congress passed it out of concern that such raids could stanch the free flow of information to the public.

https://www.rcfp.org/natanson-... [rcfp.org]

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

You can&#39;t go home again, unless you set $HOME.</div>
        </div>
        
        <div class="card" onclick="openModal('content-26')">
            <div class="source">Slashdot</div>
            <div class="title">Kalshi Claims 'Extortion,' Then Recants in Feud Over User Losses</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-26" style="display:none;">
            <h2>Kalshi Claims 'Extortion,' Then Recants in Feud Over User Losses</h2>
            <p><strong>Slashdot | 2026-02-05</strong></p>
            <a class="original-link" href="https://slashdot.org/story/26/02/05/1019252/kalshi-claims-extortion-then-recants-in-feud-over-user-losses?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Slashdot is powered by your submissions, so send in your scoop

I&#39;m sick of seeing lame Kalshi ads all over my mobile apps.

and lose money.  That&#39;s the way it&#39;s always been.Humans are always looking for shortcuts.

Theoretically if the pool of money was big enough and the float between deposits and payouts spread some that does not have to be the case.

The insurance industry for instance does not operate collecting more premiums than their casualty costs. Just like a bank lends out some of its deposits to earn interest lending, on the assumption not everyone will want to withdraw from their savings at once, insurers generally invest the capital and in many seconds of the insurance most the profit comes from the investm

Theoretically if the pool of money was big enough and the float between deposits and payouts spread some that does not have to be the case.The insurance industry for instance does not operate collecting more premiums than their casualty costs.Jesus, dude. Ease up on the comedy this early in the morning. I&#39;ve barely got my coffee down.The insurance industry soaks up money like a sponge. They throw most of it at executive get-aways. Mom&#39;s last husband was an insurance dude, and the company sent him on two to four &quot;retreats&quot; a year, where he met up with literally hundreds of other salesmen and executives. And it was always places like Machu Pichu, Rome, or other high-dollar places, and they weren&#39;t staying in the no-tell hotels.

Theoretically if the pool of money was big enough and the float between deposits and payouts spread some that does not have to be the case.

The insurance industry for instance does not operate collecting more premiums than their casualty costs.

Jesus, dude. Ease up on the comedy this early in the morning. I&#39;ve barely got my coffee down.

The insurance industry soaks up money like a sponge. They throw most of it at executive get-aways. Mom&#39;s last husband was an insurance dude, and the company sent him on two to four &quot;retreats&quot; a year, where he met up with literally hundreds of other salesmen and executives. And it was always places like Machu Pichu, Rome, or other high-dollar places, and they weren&#39;t staying in the no-tell hotels.

Yes, I&#39;m puzzled by this &quot;revelation&quot;. Of course the bottom 25% lose money. That&#39;s how the bottom 25% is defined.

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

You can&#39;t go home again, unless you set $HOME.</div>
        </div>
        
        <div class="card" onclick="openModal('content-27')">
            <div class="source">Slashdot</div>
            <div class="title">China Has Seized Sony's Television Halo</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-27" style="display:none;">
            <h2>China Has Seized Sony's Television Halo</h2>
            <p><strong>Slashdot | 2026-02-05</strong></p>
            <a class="original-link" href="https://entertainment.slashdot.org/story/26/02/05/0839245/china-has-seized-sonys-television-halo?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Well, the ThinkPad line has pretty much sustained the quality from IBM days, yes the non-Thinkpad stuff is frequently junk, but then again before IBM sold it off the desktops were not-so-affectionately nicknamed Craptiva, so IBM was no stranger to slumming it to try to get share, but Lenovo was more aggressive about it. So yes, the Lenovo at the local best buy is probably crap, but the ThinkPad line is pretty much intact. At least insofar as any of the brands are intact, keyboards across the board have opte

They&#39;re Chinese, they literally snatched the literal halo and ran off with it to make a knock-off copy. Literally.
This. Sony has nothing of value, (since when has China ever cared about IP?), TCL now owns their branding and makes the sets. Sony has effectively exited the TV market, and the article is delusional if they think Sony has any remaining value there.

If you see a &quot;Sony&quot; TV in a store from now on, remember: It&#39;s Chinese.

They&#39;re Chinese, they literally snatched the literal halo and ran off with it to make a knock-off copy. Literally.

This. Sony has nothing of value, (since when has China ever cared about IP?), TCL now owns their branding and makes the sets. Sony has effectively exited the TV market, and the article is delusional if they think Sony has any remaining value there.

If you see a &quot;Sony&quot; TV in a store from now on, remember: It&#39;s Chinese.

OTOH, Chinese might be better than Sony.  They sold their souls so long ago that I can&#39;t remember the last of their products I bought.  Once upon a time they had a name for quality, but then they sold their soul to Hollywood.

Their OLED Bravia &quot;master&quot; line of TVs are actually really nice.  They edge out LG in picture quality due to a superior image processing pipeline, and the fit and finish is a little better, IMO.  You pay through the nose for it though.  Hopefully that secret sauce went over to TCL with the sale of the brand.

Mindless hate, is what it is. Anything China does is an attack on us, in some people&#39;s minds.

Sony has been on the brink of exiting the TV business for many, many years already. The margins are thin, the competition is great, and nobody makes panels in Japan anymore. Sony has relied on superior image processing to maintain its position, but the Korean and Chinese models are very competitive now.

I wouldn&#39;t be surprised if Panasonic follows them. Toshiba, Hitachi, Sharp, all of them have already got out. All t

Rare earths are an interesting one. They gave a lot of hints about Trump knocking off the bullshit, or they would constrain the supply of them to the US in response. Trump didn&#39;t knock it off, and they did. Hard to blame them for issuing a clear warning over many years, and finally following through on it when it was ignored.

If there is a cold war, it&#39;s because the US seem to want one. Conservatives there need a Big Bad to justify what they are doing. Meanwhile the rest of the world is on-board with some of

If it was all some 4 decade long nefarious scheme, spanning generations of politicians, why did they make so much effort to telegraph the fact that they were going to do it? Why send ministers to go and inspect rare earth refineries immediately after Trump says this stuff?

The first paragraph actually explains all this stupidity:

From 2000 to 2009, China&#39;s production of rare earth elements increased 77 percent to 129,000 tons, while production from other reserves dropped to around 3000 tons.[5] Large US mining companies such as Molycorp closed due to the mix of China&#39;s abundance of rare earths and their capacities for production, as well as the cost of labor and stringent environmental regulations during the Nixon era.[6] With the decreased pool of competitors, China&#39;s hold on these elements gave them a lot of power in the distribution of these commodities. The government declared these elements to be a protected and strategic good in 1990.[5] This decision had a significant impact on foreign industries who partnered with China. Foreign investors could no longer work with rare earths except when partnered with Chinese firms.[5] The State Development and Planning Commission gained power, as all projects needed their approval.[5] Production quotas were instigated for the miners and oftentimes quotas would be surpassed because of illegal mining by people who did not have licenses.[5]In other words, China just has more of them, and especially in the 90s the environmental regulations were more lax, and the US didn&#39;t think them strategic enough to bother protecting the industry. China did though, they made sure that they were not pillaged like other countries had been by foreign companies coming in.

From 2000 to 2009, China&#39;s production of rare earth elements increased 77 percent to 129,000 tons, while production from other reserves dropped to around 3000 tons.[5] Large US mining companies such as Molycorp closed due to the mix of China&#39;s abundance of rare earths and their capacities for production, as well as the cost of labor and stringent environmental regulations during the Nixon era.[6] With the decreased pool of competitors, China&#39;s hold on these elements gave them a lot of power in the distribution of these commodities. The government declared these elements to be a protected and strategic good in 1990.[5] This decision had a significant impact on foreign industries who partnered with China. Foreign investors could no longer work with rare earths except when partnered with Chinese firms.[5] The State Development and Planning Commission gained power, as all projects needed their approval.[5] Production quotas were instigated for the miners and oftentimes quotas would be surpassed because of illegal mining by people who did not have licenses.[5]

In other words, China just has more of them, and especially in the 90s the environmental regulations were more lax, and the US didn&#39;t think them strategic enough to bother protecting the industry. China did though, they made sure that they were not pillaged like other countries had been by foreign companies coming in.

China did though, they made sure that they were not pillaged like other countries had been by foreign companies coming in.Are you intentionally misreading the Wikipedia article?

China did though, they made sure that they were not pillaged like other countries had been by foreign companies coming in.

Are you intentionally misreading the Wikipedia article?

It&#39;s not really China&#39;s fault that jobs moved there. It wasn&#39;t just undercutting wages either, they built unrivalled manufacturing supply chains and support. If I want a complex PCB prototyped here, I get quotes for 6 week as an expensive rush job. Chinese manufacturers quote 6 days, including airmail to my door.

If anyone is to blame, it&#39;s the wealthy who screwed up our economies to suit themselves. Productivity gains were not passed on to workers. Socialism was treated as a dirty word, taking away cheaper

Can&#39;t seize what was willingly given away.

Sony chose to give up the market to others.

Sad to see, but as they say, &quot;all good things..&quot;

Thought they could drop the quality and people would still keep buying simply because of the brand name. Shame no one told them that the world doesn&#39;t work like that any more (except maybe in high fashion but those people are just morons anyway).

What I think he was saying, although it&#39;s hard to be sure, is that Sony already dropped quality.

Sony hwardware started losing quality against other japanese brands - never mind the koreans - about 25 years ago when chinese electronics were still domestic market cheap shit only.

Thought they could drop the quality and people would still keep buying simply because of the brand name. Shame no one told them that the world doesn&#39;t work like that any more (except maybe in high fashion but those people are just morons anyway).Sony wasn&#39;t particularly good in quality to begin with... See: the Sony Timer. It just had a brand following which it&#39;s been shedding year after year. 

Quality wise, the Koreans came in and ate their lunch, price wise the Chinese are eating everyone else&#39;s lunch.

Thought they could drop the quality and people would still keep buying simply because of the brand name. Shame no one told them that the world doesn&#39;t work like that any more (except maybe in high fashion but those people are just morons anyway).

Sony wasn&#39;t particularly good in quality to begin with... See: the Sony Timer. It just had a brand following which it&#39;s been shedding year after year. 

Quality wise, the Koreans came in and ate their lunch, price wise the Chinese are eating everyone else&#39;s lunch.

&quot;Sony wasn&#39;t particularly good in quality to begin with&quot;

I guess you weren&#39;t around in the 80s or were young because Sony hifi back then was top notch and it stayed that way until the early 2000s. Then it was downhill fast.

Since Sony owns Bungie now, I thought this was an oblique way of saying that China had seized ownership of them! (Yes I know MS retains ownership of Halo, but still)

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

You can&#39;t go home again, unless you set $HOME.</div>
        </div>
        
        <div class="card" onclick="openModal('content-28')">
            <div class="source">Slashdot</div>
            <div class="title">Munich Makes Digital Sovereignty Measurable With Its Own Score</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-28" style="display:none;">
            <h2>Munich Makes Digital Sovereignty Measurable With Its Own Score</h2>
            <p><strong>Slashdot | 2026-02-05</strong></p>
            <a class="original-link" href="https://it.slashdot.org/story/26/02/05/0445243/munich-makes-digital-sovereignty-measurable-with-its-own-score?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Slashdot is powered by your submissions, so send in your scoop

why dont we all ask our local giv to apply the same score...

Instead of increasing control, it hands more power to a few mega-platforms (the only ones that can afford compliance Yeah, as demonstrated by switching to the offline LibreOffice and giving The Document Foundation all that power, while eschewing the faster and more secure M$ Office 365.(*) (**)
(* = yeah, this is meant to be ironic. A lost art on /. and not understood or appreciated by many these days.)
(** = and I do understand that there are many more systems needed, over and above a simple suite of office applications.)
Those caveats stated, it should maybe also be noted that Munich is not some small town in some tech

Instead of increasing control, it hands more power to a few mega-platforms (the only ones that can afford compliance

Yeah, as demonstrated by switching to the offline LibreOffice and giving The Document Foundation all that power, while eschewing the faster and more secure M$ Office 365.(*) (**)

(* = yeah, this is meant to be ironic. A lost art on /. and not understood or appreciated by many these days.)

(** = and I do understand that there are many more systems needed, over and above a simple suite of office applications.)

Those caveats stated, it should maybe also be noted that Munich is not some small town in some tech

Everything is inherently global to some extent. But global systems only work if every actor has good will. Everyone should have learned that lesson by now.

And even within a system of good will, there&#39;s still basic facts about sovreignity, like if a country cannot feed itself, it&#39;s not independent. When it needs food the most is also when everyone else needs it most, and it will therefore starve. In this real world of ours that sadly has a severe lack of good will, you are going to bend over to someone you really don&#39;t want to be bending over to, just to stay alive.

Now as to data and such. With the US showing it&#39;s true colours more and more in the recent times, the threat becomes real that if your infrastructure is based on US tech, hosted by US companies, and maybe even hosted within US borders, they might just take all of that hostage, and you will be bending over again.

Compliance on the other hand is not so much an issue of affordability, but of giving a fuck. If you are big enough to serve government contracts, you can afford to comply to their requirements. Even more, the government itself will pay for the compliance, because in the end it&#39;s just part of the pricing calculation. But let&#39;s compare Google, who cannot be arsed to comply with the EU requirement to keep all EU data within EU borders, and Microsoft, who can be arsed. Guess which company has all the business.

Interoperability, on the other hand, is not really the name of the game of the status quo, is it. Every vendor is working to get you locked in to their platform. It takes policy and budget and will to steer clear of that. Funny thing is, interoperability is cheaper, because you can just use off-the-shelf components to build your stack. But building a vendor lock-in platform takes investment, and that&#39;s a mega-platform game.

Lastly, there&#39;s always the magic word of efficiency at play, isn&#39;t it. Well here&#39;s the problem with efficiency. Efficiency is brittle. If you optimize for efficiency, there&#39;s no room for a safety margin. The 2008 economic crisis was caused by efficiency. Nvidia melting connectors are caused by efficiency. Covid supply chain issues were caused by efficiency. It&#39;s just a catchall word to argue against anything that might be important, but what it really argues for is that spending as little money as possible is the most important thing. And it isn&#39;t. Money is just something you use to achieve what is actually important. If you spent the money, however little, but didn&#39;t get what you need, the money was wasted. If you want to make sure you will not be bending over when the shit hits the fan, you will need to pay your way.

Global isn&#39;t the problem, it&#39;s central control by a foreign entity which is the issue.

Linux is global, and even tho Linus lives in the US and is thus beholden to US law any changes forced by the government would be noticeable, and foreign users could create a fork that&#39;s free of further US influence.The same can&#39;t be said of commercial operations - even when a US based company has an EU division, they are ultimately answerable to the US based bosses and thus by extension to the US government. Sure they may store data on servers physically in the EU, but that doesn&#39;t do much good if the people managing those servers answer to foreigners.

&quot;Digital sovereignty&quot; is just a new buzzword that means exactly the same thing as the older, utterly uncontroversial &quot;minimize external/proprietary dependencies&quot; which has whacked every. single. person. here upside the head, at some point in their life.

If your production system can go down because of what someone else does, or has done unto them, that&#39;s a problem. Do your customers want to hear &quot;sorry, the site was down for a few hours because AWS was down&quot; or would you prefer them hear &quot;Of course the syste

identifies IT systems based on their independence from individual providers and &#39;foreign&#39; legal spheres.ISTM that any IT system that requires an internet connection - either directly to function or for support / maintenance has exactly zero independence.

identifies IT systems based on their independence from individual providers and &#39;foreign&#39; legal spheres.

ISTM that any IT system that requires an internet connection - either directly to function or for support / maintenance has exactly zero independence.

Reading some of the other comments, it sounds like the trolls are out or people don&#39;t get the idea.

Essentially, in how far can you take your ball and go home, or rather, go play with different people. For office 365 you have exactly one source, but for office, there are now many options. And so on and so forth. Having your data locked into a specific solution without an easy way out sets you up for abuse, see Broadcom. There&#39;s a clear need for exit strategies, but most haven&#39;t realised this.

For office 365 you have exactly one sourceI&#39;ll disagree with that, not out of typical Slashdot pedantry, but because MS appears to have a different business setup in China, likely to be related to sovereignty.Their Azure presence is linked to a Chinese company that is NOT Microsoft. This suggests to me that if the customer base required it, MS could have a fully EU-based operation disconnected from the other Azure regions.

For office 365 you have exactly one source

I&#39;ll disagree with that, not out of typical Slashdot pedantry, but because MS appears to have a different business setup in China, likely to be related to sovereignty.Their Azure presence is linked to a Chinese company that is NOT Microsoft. This suggests to me that if the customer base required it, MS could have a fully EU-based operation disconnected from the other Azure regions.

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

You can&#39;t go home again, unless you set $HOME.</div>
        </div>
        
        <div class="card" onclick="openModal('content-29')">
            <div class="source">Slashdot</div>
            <div class="title">Valve's Steam Machine Has Been Delayed, and the RAM Crisis Will Impact Pricing</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-29" style="display:none;">
            <h2>Valve's Steam Machine Has Been Delayed, and the RAM Crisis Will Impact Pricing</h2>
            <p><strong>Slashdot | 2026-02-05</strong></p>
            <a class="original-link" href="https://it.slashdot.org/story/26/02/05/0030225/valves-steam-machine-has-been-delayed-and-the-ram-crisis-will-impact-pricing?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Catch up on stories from the past week (and beyond) at the Slashdot story archive

(Sure, there are others but he&#39;s the poster boy)

Where LLM actors are using investor money to suck up everything in order to keep it out of the hands of the competition.

Cannot wait for this bubble to pop and we get to see those responsible hanging from street lights. (Hahahahahaha - not)

Valve: &quot;The Steam Machine will be priced comparative to an entry level PC...&quot;

AI Market: Price of entry PCs now jumps up to &quot;both your kidneys and a testicle&quot;

Well, the AI tech-bros still haven&#39;t found anything close to the revenue needed to justify their current insane spending.

I&#39;m holding my breath for a big explosion that sinks 99% of them.  Leaving the remaining hanging on by threads that never recover.

The sooner it bursts the less damage the dopy LLMs will do.

The problem is that even when the bubble pops there won&#39;t be a flood of hardware for people to buy for pennies on the dollar. The memory isn&#39;t in the correct form factor for desktop use.

So manufacturing needs to switch what they are supply, so there was be a multi month lag before the supply hits the market as new products.

The problem is that even when the bubble pops there won&#39;t be a flood of hardware for people to buy for pennies on the dollar. The memory isn&#39;t in the correct form factor for desktop use.So manufacturing needs to switch what they are supply, so there was be a multi month lag before the supply hits the market as new products.I&#39;m looking forward to the fire-sale on giant racks of GPUs. Sure, our houses will sound like jet engines, but we&#39;ll be able to render our Blender projects in real time as we go!

The problem is that even when the bubble pops there won&#39;t be a flood of hardware for people to buy for pennies on the dollar. The memory isn&#39;t in the correct form factor for desktop use.

So manufacturing needs to switch what they are supply, so there was be a multi month lag before the supply hits the market as new products.

I&#39;m looking forward to the fire-sale on giant racks of GPUs. Sure, our houses will sound like jet engines, but we&#39;ll be able to render our Blender projects in real time as we go!

They have DRAM chips available for a while now.

Rumor has it some Chinese chip manufacturers are developing DRAM chips, which should be cheaper.Do they come with optional bit-flipping technology? But QA jokes asside China has had DRAM manufacturing capability. CXMT started production of DRAM in 2018. But it takes many years to get a new facility up and running for DRAM production. If there are any facilities coming online right now they have nothing to do with AI or the current shortage.

Rumor has it some Chinese chip manufacturers are developing DRAM chips, which should be cheaper.

Do they come with optional bit-flipping technology? But QA jokes asside China has had DRAM manufacturing capability. CXMT started production of DRAM in 2018. But it takes many years to get a new facility up and running for DRAM production. If there are any facilities coming online right now they have nothing to do with AI or the current shortage.

Everyone aboard the &quot;Let&#39;s fuck people over&quot; train.

Is this an explicit mechanism to curry favour with industries which aren&#39;t destroyed by the AI bros or just a happy accident (unless you don&#39;t want to be gouged because AI investor-greed) ?

AI doesn&#39;t destroy jobs because of replacement, but simply because of malinvestment.

The amount of companies getting destroyed here for a bit of boom and bust in datacentre construction is ridiculous.

The promise of AI was oncediffusion of infinite cunts.Then they took our RAM,so now it&#39;s a scam,and I&#39;m just a mem-paging dunce.

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

You can&#39;t go home again, unless you set $HOME.</div>
        </div>
        
        <div class="card" onclick="openModal('content-30')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">Which Is the SI Unit for Work?</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-30" style="display:none;">
            <h2>Which Is the SI Unit for Work?</h2>
            <p><strong>News and Politics - Slate Magazine | 2026-02-05</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2026/02/trivia-quiz-daily-slate-science-physics-space-physiology.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Please enable Javascript in your browser to view Slate interactives.

Who Ran for President on the American Independent Party Ticket in 1968?

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-31')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">Are Republicans on Board With Trump’s Plan for a GOP Takeover of Elections? It’s Complicated.</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-31" style="display:none;">
            <h2>Are Republicans on Board With Trump’s Plan for a GOP Takeover of Elections? It’s Complicated.</h2>
            <p><strong>News and Politics - Slate Magazine | 2026-02-05</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2026/02/trump-republican-election-takeover-save-act.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Sign up for the Slatest to get the most insightful analysis, criticism, and advice out there, delivered to your inbox daily.

In his most recent rant about how Democrats cheat to win elections, President Donald Trump offered a chilling recommendation on Monday. Appearing on the podcast of Dan Bongino, his former deputy FBI director, the president argued that “the Republicans should say, ‘We want to take over.’ We should take over the voting, the voting in at least many—15 places.

“The Republicans,” he added, “ought to nationalize the voting.”

A federal-government takeover of America’s locally and state-administered voting process has long been something Republicans have opposed on principle. But then again, Trump said he wanted to do it. So how would Senate Republicans respond?

There were those who, in a ritual dating back to the early days of Trump’s first term, had conveniently not kept abreast of the news. Texas Sen. Ted Cruz told me he wouldn’t comment because he hadn’t seen the interview. Iowa Sen. Chuck Grassley thought about it for a few seconds before determining that he too was unfamiliar.

Others were more forthcoming, with Sens. Susan Collins and Lisa Murkowski rejecting the idea. Senate Majority Leader John Thune, most importantly, said, “I’m not in favor of federalizing elections—I mean, I think that’s a constitutional issue.”

But a broad middle of GOP senators took something of a third way: While they wouldn’t endorse a partisan and national takeover of voting itself, they were eager to talk about legislation that would greatly expand the federal role in elections—and do so in a way that furthers a long-standing partisan goal of the GOP.

“We need to safeguard our elections better,” Kansas Sen. Roger Marshall told me. “I think the SAVE Act is a great start. I think requiring proof of citizenship when you register to vote is a must.”

Wisconsin Sen. Ron Johnson said that “we shouldn’t nationalize” elections, “but we should certainly set certain standards like citizenship and voter ID.” He added, “The problem is, we have Democrats who want to make it easy to cheat.”

Florida Sen. Rick Scott echoed those sentiments. “We need to have voter ID in our elections. We need to make sure illegal aliens cannot vote in our elections,” he said. “We need to make sure that we just stop the fraud.”

As Marshall alluded to, the bill that Republicans have coalesced around is the Safeguard American Voter Eligibility (SAVE) Act, which the House passed earlier this Congress, and which proponents are trying to find some magical way to squeeze through the Senate’s brick wall.

Even White House press secretary Karoline Leavitt, in a Tuesday press briefing, said passage of this legislation is what Trump had been referring to when he called to “nationalize the voting.” Sure it was.

Republicans often point to the high public support for requiring photo ID at polling places. The SAVE Act is more than that, though. It requires “documentary proof of United States citizenship” in order to register to vote. Such proof means things like a passport or a birth certificate. REAL IDs could count too, but only if they indicate citizenship, and just a handful of states’ REAL IDs currently do so. The SAVE Act, in other words, applies drastic changes to solve a problem—voter fraud—that is vanishingly rare, though it would succeed in creating hurdles for eligible voters. It goes without saying that Democrats have no interest in this legislation, and Senate Democratic Leader Chuck Schumer has described it as “nothing more than Jim Crow 2.0.”

Given Senate Democrats’ 100 percent chance of filibustering this legislation, and Republicans’ inability to eliminate the legislative filibuster, then, what’s the plan for getting this bill through the Senate?

House Republicans think they have an idea that could work. Bless their hearts.

After the Senate and White House reached a deal last week to extend the Department of Homeland Security’s funding for only two weeks, giving them a brief window to negotiate new immigration enforcement reforms, conservative House Republicans were displeased. If Democrats felt as if they could reopen a closed negotiation over DHS funding, then they wanted to participate too. A group of them, led by Florida Rep. Anna Paulina Luna, insisted that when the Senate deal returned to the House, they wouldn’t support it unless they could attach the SAVE Act.

But such a move would have been a recipe for a prolonged shutdown. Trump’s priority over the past week has been to avoid a lengthy shutdown that keeps the issue of immigration enforcement tactics front and center in the news. And so, following a White House meeting, Luna and Co. said they’d received “assurances” from Thune that they would wait out a “standing filibuster” from their Democratic counterparts in order to pass the SAVE Act, at a later date. In return, the rebels would support the government funding bill sent over from the Senate.

Anyone familiar with the Senate realizes that Thune would never have made such an assurance. As Thune clarified Tuesday morning, all he said was that he’d have a conversation with Republican senators about it. You have to know what waiting out a “standing filibuster” means—and most House members don’t—to understand why he wouldn’t promise it to some aggravated House members.

Waiting out a “standing,” or “talking,” filibuster means you wait for the other side to stop talking before moving ahead to a simple-majority vote, as opposed to the normal means of cutting off debate: invoking cloture with 60 votes. The strategy, if used, would likely involve enforcing the Senate’s two-speech rule, barring lawmakers from speaking more than twice in the same legislative day on the same question.

The problem is that this can take forever. Forty-seven Democratic senators being able to speak twice, on its own terms, could take up weeks or months of precious legislative floor time that Republicans need for other priorities. And that’s before any amendments that could reset the clock. Plus, GOP senators would need to be on or near the floor for the entirety of this time to ensure they have a quorum lest Democratic speakers attempt a quorum call.

“I’m skeptical that it’s going to be a panacea,” Texas Sen. John Cornyn, a onetime member of leadership who’s well familiar with Senate rules, told me.

Thune laid out all of these challenges Tuesday afternoon but nevertheless promised to “have a discussion about it and see where our conference is.” In other words, the plan is to allow the passage of time to do the humble work of making everyone forget about all of this.

Trump’s desire for greater control over the administration of the midterm elections, however, won’t disappear amid congressional gridlock. The president already initiated a national redistricting war to squeeze out a few more congressional seats. The FBI has already raided a Georgia election facility and could plan for more. The Justice Department keeps trying to get its mitts on state voter rolls. We don’t know exactly what it is yet, but if there’s a way to do “nationalization” by other means, the administration will be looking into it.

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-32')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">Bad Bunny Has Already Won The Super Bowl</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-32" style="display:none;">
            <h2>Bad Bunny Has Already Won The Super Bowl</h2>
            <p><strong>News and Politics - Slate Magazine | 2026-02-05</strong></p>
            <a class="original-link" href="https://slate.com/podcasts/what-next/2026/02/what-bad-bunnys-super-bowl-halftime-show-means?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The halftime show could feel like a party—and a protest.

Please enable javascript to get your Slate Plus feeds.

If you can&#39;t access your feeds, please contact customer support.

Thanks! Check your phone for a link to finish setting up your feed.

Enter your phone number and we&#39;ll text you a link to set up the
        podcast in your app:

We&#39;ll only text you about setting up this podcast, no spam.

Apple Podcasts will only work on MacOS operating systems since Catalina. We do not support Android apps on desktop at this time.

These links will only work if you&#39;re on the device you listen to podcasts on.

We&#39;re sorry, but something went wrong while fetching your podcast feeds. Please contact us at plus@slate.com for help.

What Bad Bunny’s Super Bowl halftime show means for Puerto Rico, Latin Americans in the U.S., and his haters.

Guest: Dr. Vanessa Díaz, associate professor of Chicana/o and Latina/o Studies at Loyola Marymount University and co-author of P FKN R: How Bad Bunny Became the Global Voice of Puerto Rican Resistance.

Want more What Next? Subscribe to Slate Plus to access ad-free listening to the whole What Next family and across all your favorite Slate podcasts. Subscribe today on Apple Podcasts by clicking “Try Free” at the top of our show page. Sign up now at slate.com/whatnextplus to get access wherever you listen.

Podcast production by Elena Schwartz, Paige Osburn, Anna Phillips, Madeline Ducharme, and Rob Gunther.

The problem with the news right now? It’s everywhere. And each day, it can feel like we’re all just mindlessly scrolling. It’s why we created What Next. This short daily show is here to help you make sense of things. When the news feels overwhelming, we’re here to help you answer: What next? Look for new episodes every weekday morning.

Mary Harris is the host and managing editor of What Next, Slate&#39;s new daily news podcast. She has reported throughout the public radio system, for NPR, Marketplace, and WNYC.</div>
        </div>
        
        <div class="card" onclick="openModal('content-33')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">What the Latest Epstein Documents Say About Bill Gates, Elon Musk, and Donald Trump</div>
            <div class="meta">2026-02-04</div>
        </div>
        
        <div id="content-33" style="display:none;">
            <h2>What the Latest Epstein Documents Say About Bill Gates, Elon Musk, and Donald Trump</h2>
            <p><strong>News and Politics - Slate Magazine | 2026-02-04</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2026/02/epstein-files-trump-bill-gates-elon-musk-bill-clinton.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">David Enrich’s whole life right now is the Epstein files. As an investigations editor at the New York Times, his phone and computer basically explode whenever new files are released.Last Friday, his phone exploded again when the Department of Justice dropped about 3 million pages of documents into the cloud.

Back in November, Democrats and Republicans worked together to force the DOJ to release all they’d discovered about Jeffrey Epstein—the country’s most notorious sex criminal and probably one of the richest, too. With this latest release, the DOJ says it has satisfied that demand. But it’s not even all they’ve got.

The Times built its own internal search engine to sort through the sludge. It doesn’t just search for specific words; you can ask it to search for concepts like bribery. And these documents aren’t just emails about President Donald Trump, or giddy vacation planning for rich folks hoping to hop a ride to Epstein’s infamous island. There are photos and videos, even bank records.

On a recent episode of What Next, host Mary Harris spoke to Enrich about the latest Epstein file drop and what it says about Bill Gates, Elon Musk, and Donald Trump. This transcript has been edited and condensed for clarity.

Mary Harris: Before we dig into exactly what’s in the file and what it says, what does the sheer volume of what’s been released tell you?

David Enrich: I don’t have much confidence in the government. I don’t have much sense that the majority of this stuff has been read thoroughly.

When these files were released, a number of things seemed to have been released by mistake. The implication of that is that they didn’t know exactly what they were releasing. But it’s also really awful stuff. Pictures of women and young girls without any kind of redaction. They’re identifiable, nude. Very upsetting, essentially. And your team was part of the team that found that, right?

This has been a real mess by the government. The argument they make is that they only had two months to pull this stuff together because the Epstein Files Transparency Act was passed and signed into law in November, with a December deadline. But the truth is that Trump came into office saying he was going to be transparent about this and release the files, and they made a series of choices and decisions not to do that, which I think were based in part on their gradual understanding of the fact that what was in these may be damaging to Trump or his allies.

So they then entered this frenzied period, starting in November, and did not do a good job. There are a huge number of things in there that are identifying victims, a number of files that have a high likelihood of being child sexual abuse material, and all sorts of other damaging stuff that serves no public interest and was not, in fact, required by law to be disclosed. What they’ve done is all these haphazard redactions, redacting a bunch of things they’re not supposed to redact. We found that Steve Bannon had texted Epstein, and Epstein’s name was redacted, and Trump’s face was redacted. And it’s like, why on earth would that stuff be redacted? At the same time, we’re seeing victims’ names identified.

The government is being somewhat responsive now when things are being brought to their attention. They’re taking them down and are re-redacting them. But at the same time, they appear to have overredacted quite a bit of stuff.

What stands out to me in this possible final release of files is the way that neither Donald Trump nor Jeffrey Epstein seem to be able to escape each other. These are two people who were friends in the 1990s and early 2000s. There are reports that there was a falling-out between them. Epstein gets arrested for sex acts with a minor. Donald Trump decides to run for president. But these guys can’t stop talking about each other.

Yeah, they were very close for a while, but Epstein’s defining human trait was an ability to seize on his connections and leverage them for as much currency as he could. And that came in many forms, right? That’s why he had all these pictures of himself with famous people in his houses, because he liked to be able to show those off to other famous people, or to use these as a threat hanging over the heads of his victims.

With Trump, it’s playing out in some different ways. Part of it is that with Trump’s rise to power back in 2016, Epstein realized that here was someone who had great power to either make Epstein’s life better or worse. And so I think he was really trying to suss out, initially, how he could pull those different levers. It obviously didn’t work very well, since during Trump’s first term, Epstein ended up in prison and then died.

And the files were kind of a useful tool for Trump and Trump’s allies, in particular, to beat Democrats and fan the flames of conspiracy theories on the far right. There’s no doubt that one of the things that got Trump elected in 2024 was this band of far-right MAGA people who were convinced that Trump was going to expose this global ring of pedophiles on the left and through the Epstein files.

The big allegation about Trump in these latest files involves calls to the FBI’s tip line. And these are a little dicey to talk about, because these are unverified tips. The FBI gets all kinds of unverified tips all the time. But could you just lay out what’s in there?

I’m going to be like a really anal New York Times reporter. We’ve made a decision institutionally that we’re not going to give airtime to things that we really just have no idea if they are true or not, especially when they’re of this lurid nature. But I mean, in general, it’s just very lurid sexual allegations involving Trump in the context of his relationship with Epstein. And they’re very bad allegations.

Let’s talk about some of the other big names that have been in the spotlight since the latest release. My understanding is that in these files, you see Commerce Secretary Howard Lutnick trying to make plans to go to Epstein’s island. He was in friendly contact with Jeffrey Epstein long after he said he’d shut the relationship down.

Yeah, and the crazy thing here is that Lutnik just last year had said not only that he had shut the relationship down, but he had given this whole explanation for why he’d shut it down, which was that he’d visited Epstein’s mansion and he’d seen stuff in there that made him and his wife really uncomfortable. And they had vowed then and there to never associate with this terrible man again. But what we see in these files shows that’s just not true at all. They by all accounts had a pretty chummy relationship. They visited Epstein on his island long after this alleged encounter in the townhouse that left them so unsettled.

There’s also Bill Gates, founder of Microsoft. There have been allegations for years that Gates and Jeffrey Epstein were close. But in this latest release of documents, there are these implications that Epstein was helping procure women for Bill Gates and that Gates got a sexually transmitted infection, and was trying to get drugs to treat himself and secretly treat his own wife. She’s been asked about this, and she’s given an answer basically saying, This takes me back to the worst times of my marriage, which isn’t a, like, Hell no, this didn’t happen. It’s something quite different.

We’ve known for years, since Epstein’s death, about the long-running relationship between Gates and Epstein that involved everything, apparently, from science to money to women, or girls perhaps. I can’t say I’m shocked to see Gates’ reentry into this. The thing I’ll caution about here is—and I’m not at all defending Gates or his apparent conduct, and it is entirely possible that those emails were true and accurately reflected what Epstein and people like Gates did—but it is possible that Epstein is a liar and an embellisher and an expert in using threats and leverage to get what he wants with powerful people. And so it is not outside the realm of possibility that Epstein was exaggerating or twisting the truth. That being said, we know, and this has been out there in public for a while, that part of the reason that Bill and Melinda Gates got divorced was her discomfort with her husband’s relationship with Epstein. And while we’ve never really had the full gory details and what that’s entailed, it’s obviously been a subject of informed speculation.

Elon Musk is in here. He’s writing to Jeffrey Epstein asking, When is the wildest party on your island, because I want to make sure that I come. What do you make of this?

Once again, we are seeing people who had previously denied or downplayed their relationships with Epstein, and in fact had pointed at other people for being more connected to Epstein, we are now seeing that they, long after Epstein was known as a sexual criminal and had registered as a Level 3 sex offender, were continuing to associate with him.

You’ve talked about transparency being important here. Can we talk about what we’re not seeing in this release of documents? We were promised 6 million documents. I thought they were legally required to release all the files, so what is happening there?

That is a good question, and I don’t have a good answer. What the Justice Department has said is that they withheld a large quantity of documents to protect victims’ identities.Two things can be true: They can be protecting victims’ identities by not releasing 3 million documents and they can also be doing a bad job of protecting victims’ identities in the 3 million pages of documents that they did release. That being said, this administration’s handling of the Epstein files doesn’t have a whole lot of credibility.

A year ago, Attorney General Pam Bondi and FBI Director Kash Patel said they released the Epstein files by handing binders full of public court documents to a group of MAGA influencers. That was the whole start of this. And it’s gone along on the same trajectory with deceitful disclosures. In that context, I think it is normal and reasonable for open-minded people to be skeptical and curious about what’s actually in these other 3 million pages of documents.

To get to this point, Congress had to act of its own accord, essentially, and force the release. Are there other avenues available to lawmakers who want to see more here?

The Justice Department has said it is going to meet with lawmakers to explain its thinking. The other options are not necessarily in terms of getting these files, but there are other ways to get some more transparency. And one of the things we’ve seen is that the House Oversight Committee has issued a bunch of subpoenas to a wide variety of people demanding that they sit for depositions under oath, the transcripts of which will presumably be released in short order. And that ranges from people like the Clintons to people like former Victoria Secret CEO Les Wexner, who was one of Epstein’s biggest financial benefactors over the years. We’ll see what happens.

There are a huge number of wealthy, powerful individuals all over the world who continued to associate with Epstein and provide him with various kinds of support long after he went to jail.To me, what has made the Epstein story so riveting and so important for so many years is that yes, this is a story about a guy who is a pedophile and was doing terrible things to women and girls. But much more than that, it is a story about how one individual, when he accrues enough wealth and influence and connections, can work the entire global system to his benefit for very nefarious purposes. And he does it in conjunction and in some cases partnership with some of the richest, most powerful people on Earth. And that is a story that has not yet fully been told.

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-34')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">How Trump Used a Law Meant to Protect Abortion Seekers to Arrest Members of the Press</div>
            <div class="meta">2026-02-04</div>
        </div>
        
        <div id="content-34" style="display:none;">
            <h2>How Trump Used a Law Meant to Protect Abortion Seekers to Arrest Members of the Press</h2>
            <p><strong>News and Politics - Slate Magazine | 2026-02-04</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2026/02/don-lemon-news-trump-abortion-arrest.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Sign up for the Slatest to get the most insightful analysis, criticism, and advice out there, delivered to your inbox daily.

Just when it seemed that things couldn’t get any stranger, the Trump administration has injected abortion law into its efforts to stamp out anti-ICE protests. Last week, Don Lemon, an independent reporter, and two protesters were arrested on federal charges arising out of an anti–Immigration and Customs Enforcement protest at a Minnesota church. One of the key charges involves the Freedom of Access to Clinic Entrances Act, legislation passed in 1993 to protect access to reproductive health facilities and places of worship. Understanding the law’s past and present reveals how the Department of Justice has repurposed it to crack down on protest that the president opposes.

The FACE Act passed at a time of escalating anti-abortion protest. Abortion opponents had watched as Republican presidents reshaped the U.S. Supreme Court, but abortion remained legal. Frustrations spilled over, and a growing number of Americans joined clinic blockades led by Operation Rescue, a group that sought to shut down abortion clinics. As Time magazine reported, the primary tactic Operation Rescue used was “to jam all entrances to an abortion clinic before the police can muster sufficient officers to begin arrests.”

Operation Rescue members did get arrested but often faced minor charges, like trespassing, before quickly returning to the protest front lines. Most of those who attended these protests were peaceful—Operation Rescue instructed recruits on what it called nonviolent civil disobedience. But the group’s message was that lawbreaking was justified in the name of saving the lives of the unborn.

That message was hard to contain, and by 1993, anti-abortion extremists were arguing that it was legitimate to use violence against providers. That year saw the first of a series of murders of abortion doctors. Congress responded with the FACE Act, which sought to distinguish peaceful protest and speech (much of which is protected under the First Amendment) from violence, threats of force, and efforts to obstruct access to clinics. Sponsored by Democrat Ted Kennedy and Republican Constance Morella, the law drew inspiration partly from a federal law already protecting “interference with rights,” including religious exercise.

The addition of places of worship was meant to doom passage of the act at a time when Democrats controlled both houses of Congress; a staffer for Utah Sen. Orrin Hatch (the now-prominent conservative Ed Whelan) added the language as a poison pill. There was also a plan to mock the bill if it passed: Whelan hoped that the addition would change the acronym for the law to the FARCE Act.

But Kennedy was in favor of the addition in no small part because of the historic victimization of Black churches, synagogues, and other places of worship—a trend that was all too evident in several mass shootings last year. If anything, the tactic cemented the bill’s bipartisan appeal: Seventeen Republican senators and three members of the House ultimately supported it.

Abortion opponents immediately challenged the law’s constitutionality under the First Amendment, arguing that the statute censored speech and singled out abortion foes for prosecution. The courts rejected that argument by stressing that the FACE Act was narrow: It applied only to conduct and was enforced regardless of what message protesters intended to convey. Constitutional arguments against the act have reemerged since the demise of Roe v. Wade, with the CATO Institute arguing that there may no longer be any congressional authority for the law and that it may thus be unconstitutional.

The FACE Act had a major impact on the clinic blockade movement, which relied on a large number of recruits to stop patients from entering abortion clinics. Rather than minor trespassing charges, protesters now weighed the prospect of serious fines and prison time, with penalties escalating for repeat offenders.

But the line between speech and obstruction, threats, or violence can sometimes be messy to draw in context. That meant that federal prosecutors were often reluctant to bring FACE Act charges, even when Democrats were in office. With Joe Biden in the White House, federal prosecutors did file charges against not only anti-abortion groups like Red Rose Rescue (a next-generation clinic blockade group) but also Jane’s Revenge, a militant abortion-rights group that carried out a campaign of vandalism, arson, and bombing.

Fast-forward to 2026, when the FACE Act is enjoying a bizarre renaissance. Over the years, bipartisan consensus about the legislation collapsed, and conservative Republicans began calling for its repeal. Then, in January 2025, a spokesperson for the Trump administration announced that the White House would no longer enforce the FACE Act absent “extraordinary circumstances” or “significant aggravating factors.” Abortion opponents clearly see this announcement as an opportunity. Randall Terry, the 77-year-old founder of Operation Rescue, is working with his girlfriend, Terrisa Bukovinac, the 44-year-old leader of a group called Progressive Anti-Abortion Uprising, to launch a new wave of protests and reach a younger generation of potential recruits.

But “extraordinary circumstances” might not be as hard for the administration to find when the president doesn’t like what protesters are saying. The White House has turned its FACE Act focus toward language protecting places of worship from those who interfere with religious exercise “by force or threat of force or physical obstruction” to target messages that the administration opposes.

First came an indictment against a group of pro-Palestinian protesters and organizations arising from a November 2024 demonstration outside a New Jersey synagogue. Organized by the Party for Socialism and Liberation in New Jersey and American Muslims for Palestine New Jersey, the protest targeted an event promoting the sale of property in Israeli settlements in the occupied West Bank. What happened next is unclear, but violence broke out between the protesters and pro-Israel counterprotesters. New Jersey prosecutors concluded that pro-Israel demonstrators were the first to cross the line into violence, and the Department of Justice disagreed. Either way, it seemed to be a strange choice for an administration that had announced a lack of interest in enforcing the FACE Act to prioritize a case in which local law enforcement saw the facts so differently.

Now the administration is pursuing similar charges against Don Lemon. The former CNN anchor and his co-defendants faced charges based on an anti-ICE protest at Cities Church, a site that was chosen because protesters believed its pastor to be the acting director of a local ICE field office. At the time, 3,000 ICE agents had flooded the Twin Cities, and Renee Good had recently been shot and killed by federal immigration officials. Alex Pretti would be killed later in the ICE surge.

Prosecutors claim that Lemon, a noted critic of the president, helped organize the Cities Church protest, which they frame as an attack. The indictment charges that Lemon then obstructed church members from leaving by posting himself at the door and asking them questions.

Based on the available evidence, it’s hard to see these charges as anything but disturbing and wrong. Video of the incident shows heated exchanges between Lemon and his interview subjects, who clearly disagree with him about immigration policy and the conduct of ICE in the Twin Cities. There are moments when the journalist is asked to leave, or when the people to whom he’s speaking clearly want to move on. And people do leave, including the ones Lemon seems to aggravate the most. The video doesn’t show much more physical contact than Lemon pushing his microphone into the subjects’ faces. If that act qualifies as physical obstruction, it’s hard to see what kind of press scrum would not.

Drawing the line between protected speech and obstruction or threats isn’t always straightforward. And even when the line is clear, protests about everything from ICE to abortion often involve civil disobedience like trespassing. Those protests can involve speech that is rude, unconvincing, or even hateful. But the line between protected speech and wrongful conduct can’t depend on the reasons people are protesting. With this latest prosecution, that’s just the danger we face.

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-35')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">Who Ran for President on the American Independent Party Ticket in 1968?</div>
            <div class="meta">2026-02-04</div>
        </div>
        
        <div id="content-35" style="display:none;">
            <h2>Who Ran for President on the American Independent Party Ticket in 1968?</h2>
            <p><strong>News and Politics - Slate Magazine | 2026-02-04</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2026/02/trivia-quiz-daily-slate-history-presidential-elections-supreme-court-war.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Please enable Javascript in your browser to view Slate interactives.

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-36')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">Brain-inspired AI helps soft robot arms switch tasks and stay stable</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-36" style="display:none;">
            <h2>Brain-inspired AI helps soft robot arms switch tasks and stay stable</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2026-02-05</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2026-02-brain-ai-soft-robot-arms.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-37')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">Germany claws back 59 mn euros from Amazon over price controls</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-37" style="display:none;">
            <h2>Germany claws back 59 mn euros from Amazon over price controls</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2026-02-05</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2026-02-germany-claws-mn-euros-amazon.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-38')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">Batteries from rust? Carbon spheres filled with iron oxide deliver high storage capacity</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-38" style="display:none;">
            <h2>Batteries from rust? Carbon spheres filled with iron oxide deliver high storage capacity</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2026-02-05</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2026-02-batteries-rust-carbon-spheres-iron.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-39')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">TSMC to make advanced AI semiconductors in Japan in boost for its chipmaking ambitions</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-39" style="display:none;">
            <h2>TSMC to make advanced AI semiconductors in Japan in boost for its chipmaking ambitions</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2026-02-05</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2026-02-tsmc-advanced-ai-semiconductors-japan.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-40')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">News sites are locking out the internet archive to stop AI crawling. Is the 'open web' closing?</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-40" style="display:none;">
            <h2>News sites are locking out the internet archive to stop AI crawling. Is the 'open web' closing?</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2026-02-05</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2026-02-news-sites-internet-archive-ai.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-41')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">Organic molecule stores renewable energy with record stability, paving the way for better flow batteries</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-41" style="display:none;">
            <h2>Organic molecule stores renewable energy with record stability, paving the way for better flow batteries</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2026-02-05</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2026-02-molecule-renewable-energy-stability-paving.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-42')">
            <div class="source">The Register</div>
            <div class="title">UK's 'world-first' deepfake detection framework unlikely to stop the fakes, says expert</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-42" style="display:none;">
            <h2>UK's 'world-first' deepfake detection framework unlikely to stop the fakes, says expert</h2>
            <p><strong>The Register | 2026-02-05</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2026/02/05/uk_government_deepfake_framework/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The UK government claims it will develop a &quot;world-first&quot; framework to evaluate deepfake detection technologies as AI-generated content proliferates.

The Home Office is working Microsoft, other tech corporations and academics to assess methods for identifying harmful forgeries. It estimates eight million deepfakes were shared in 2025, up from half a million in 2023.

Nik Adams, Deputy Commissioner for City of London Police, called the framework &quot;a strong and timely addition to the UK&#39;s response to the rapidly evolving threat posed by AI and deepfake technologies.&quot;

&quot;By rigorously testing deepfake technologies against real-world threats and setting clear expectations for industry, this framework will significantly bolster law enforcement&#39;s ability to stay ahead of offenders, protect victims and strengthen public confidence as these technologies continue to evolve.&quot;

However, Dr Ilia Kolochenko, CEO at ImmuniWeb, a Swiss cybersecurity biz, said the plan &quot;will quite unlikely make any systemic improvements in the near future.&quot;

Kolochenko pointed to numerous open source tools and groups of experts that already exist to track and expose AI-generated content.

&quot;Even if an AI fake is detected, the biggest question is what to do next,&quot; he told The Register. &quot;Reputable media and websites will likely take it down rapidly even without scientific proof that it is an AI fake.&quot;

Clandestine or anonymous media are unlikely to be as cooperative.

&quot;We need a systemic and global amendment of legislation – not just legally unenforceable code of conduct or best practices – to stop the surging harm of AI-created content,&quot; Kolochenko added. &quot;In sum, while this commendable action is a solid start, we are still very far from a final solution.&quot;

The Register asked the Home Office for a time frame for the framework and the technology being used, but did not receive a response. Microsoft directed us to the Home Office&#39;s statement. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-43')">
            <div class="source">The Register</div>
            <div class="title">Microsoft sets Copilot agents loose on your OneDrive files</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-43" style="display:none;">
            <h2>Microsoft sets Copilot agents loose on your OneDrive files</h2>
            <p><strong>The Register | 2026-02-05</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2026/02/05/microsoft_onedrive_agents/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Microsoft has made OneDrive agents generally available, allowing users to query multiple documents simultaneously through Copilot instead of just one at a time.

Users can select up to 20 files and create an agent, saved as a .agent file in OneDrive.

Rather than teasing information out of individual documents, Microsoft says users can make cross-document queries, including &quot;What decisions have we made so far?&quot; and &quot;What risks keep coming up?&quot; The agent then generates a response based on the documents&#39; content.

Agents can be searched for and shared, although collaborators will need access to the source documents. Microsoft said: &quot;The agent can provide complete, grounded responses keeping everyone aligned without extra handoffs.&quot;

However, the claim that getting started &quot;requires no special admin setup,&quot; combined with the lack of detail about what the agents do behind the scenes or where user data ends up, is likely to worry administrators. That said, for a user of OneDrive on the web with a Microsoft 365 Copilot license, that ship has long sailed.

The Register asked Microsoft about the privacy implications and what happens to user data while an agent does its thing, but other than acknowledging our question, the company did not respond.

Copilot meddling with OneDrive files is not new. Microsoft showed off a variety of concepts in 2023 and revealed updates in 2024. Users who don&#39;t want a perky virtual assistant that might occasionally make potentially catastrophic errors don&#39;t have to use the functionality.

However, for organizations that have bought into Microsoft&#39;s vision of a Copilot-powered future, the functionality may be worth checking out. It makes queries more targeted and collaborative than simply applying AI to OneDrive.

There are some intriguing opportunities for collaboration, however, it is up to the user to make sure that anyone with whom an agent is shared has access to the same source files. Otherwise, there is an even greater chance that Copilot might be confidently wrong. Or, as Microsoft put it: &quot;If someone opens the agent but doesn&#39;t have access to the source files, they won&#39;t get useful answers.&quot; ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-44')">
            <div class="source">The Register</div>
            <div class="title">Curse of AI to push up PC prices as memory and CPU shortages bite</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-44" style="display:none;">
            <h2>Curse of AI to push up PC prices as memory and CPU shortages bite</h2>
            <p><strong>The Register | 2026-02-05</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2026/02/05/pc_prices_rising/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">PC buyers can expect price hikes as chipmakers continue to prioritize AI production over all else, restricting the supply of key components across the tech industry.

Analyst Context says existing inventory initially buffered markets across Europe, however, prices are inflating as older stock depletes - and it forecasts further inflation as the year progresses.

The average UK distributor consumer desktop price, for example, rose almost eight percent year-on-year in the five weeks of 2026 to £565 ($767), while laptops edged up 1.1 percent to £454 ($619) &quot;reflecting continued sell-through of stock purchased before component costs escalated.&quot;

Counterpoint Research said today that memory prices have soared 80 to 90 percent this year versus Q4, with DRAM, NAND, and HBM all hitting new highs.

Constraints on specific configurations, alongside emerging CPU availability issues, are expected to limit choice and increase pricing pressure from Q2 onward, according to Context.

&quot;Manufacturers are prioritizing production for AI datacenter infrastructure, redirecting capacity away from consumer-grade memory and storage towards high-bandwidth memory (HBM) and advanced storage required for large-scale AI workloads,&quot; said senior retail analyst James Bates.

New fabrication plants are being built to supply more of the memory that PC makers need, but these typically take several years to come online.

US chipmaker Micron recently started work on a mega chip fab in New York state, which isn&#39;t scheduled to begin producing DRAM chips before 2030. Micron did, however, seal the deal on an existing facility in Taiwan that could be delivering chips sometime next year.

The situation is so dire that major PC brands including HP, Dell, Acer, and Asus are considering sourcing memory chips from Chinese manufacturers for the first time, according to Nikkei Asia.

HP and Dell have already started qualifying chips from ChangXin Memory Technologies (CXMT), it says, with HP planning to follow suit if the outlook does not improve around the middle of the year.

And it isn&#39;t just PCs – servers are also affected. Analyst Omdia said this week that server CPU prices could go up by 11 to 15 percent due to supply problems, while Samsung Electronics and SK hynix were reportedly raising server memory prices by as much as 70 percent this quarter.

The blast radius from the memory shortages is impacting other areas of the industry such as smartphones. Prices could bounce 6 to 8 percent, disproportionately affecting the low end of the market.

Smartphone chipmaker Qualcomm saw its share price take a hit after it warned of slower sales ahead, as did chip designer Arm, which estimated lower growth in royalty revenue for the next quarter, all due to a shortage of enough memory to go in the devices people want to buy.

With all these side effects from the AI infrastructure boom, it seems we are all going to pay the price for AI, whether we use it or not. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-45')">
            <div class="source">The Register</div>
            <div class="title">Italy claims cyberattacks 'of Russian origin' are pelting Winter Olympics</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-45" style="display:none;">
            <h2>Italy claims cyberattacks 'of Russian origin' are pelting Winter Olympics</h2>
            <p><strong>The Register | 2026-02-05</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2026/02/05/winter_olympics_russian_attacks/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Italy&#39;s foreign minister says the country has already started swatting away cyberattacks from Russia targeting the Milano Cortina Winter Olympics.

Antonio Tajani told reporters on Wednesday that a series of cyberattacks targeted some of the government&#39;s foreign offices, including the one in the US capital.

He said they were &quot;of Russian origin,&quot; but did not specify whether this appeared to be state-backed activity, nor provide details about the nature of the attacks, AP reported.

&quot;We prevented a series of cyberattacks against foreign ministry sites, starting with Washington, and also involving some Winter Olympics sites, including hotels in Cortina,&quot; he said.

Tajani&#39;s comments follow a warning from the UK&#39;s cybersecurity agency not to underestimate pro-Russia hacktivists, and although it was issued in the context of attacks on UK critical infrastructure, Russia and those aligned to it have a long history of targeting the Summer and Winter Games.

While Russian or pro-Russia attackers pelt Milano Cortina, Cloudflare CEO Matthew Prince said he may pull the company&#39;s free services it provides to the Games after Italy fined it 1 percent of its annual revenue.

The country&#39;s telecoms regulator, the Autorità per le Garanzie nelle Comunicazioni (AGCOM), issued the €14 million ($16.5 million) fine in January for violating anti-piracy regulations.

During a partly all-caps tirade on X, Prince threatened to not only withdraw pro bono security services to Milano Cortina, but also free services to Italian citizens, all servers from Italian cities, and scrap plans for investment or to establish a company office in the country.

Since it hosted the 2014 Winter Games in Sochi, an event Russia hoped it could use a political springboard, the UK, US, and others have formally attributed several cyberattacks against the events in the years that followed to Russia.

These included various attacks on the 2018 Winter Games in Pyeongchang and disinformation campaigns surrounding the Paris Games in 2024.

The International Olympic Committee (IOC) banned Russia from competing in the Games in 2017 following a doping scandal involving a number of its athletes, and the World Anti-Doping Agency (WADA) banned it from all international sporting events in 2019.

That WADA sanction was due to be lifted after the 2022 Beijing Games, but Russia then invaded Ukraine, leading the IOC to impose an indefinite ban on Russian athletes.

Thirteen Russians will compete in Milano Cortina, but they must do so as independents – they cannot fly the Russian flag.

For decades, Russia has used sporting events, especially the Olympics, for political gain. From the 1950s onward, many believe that Russia saw the Games as a means to assert the value of socialism, with the rivalry between the USSR and the capitalist US pervading most major events for three decades.

Milano Cortina officially begins on February 6, although the Games&#39; events kicked off on February 4 with a four-fixture curling mixed doubles session in which Sweden, Great Britain, Canada, and Switzerland prevailed. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-46')">
            <div class="source">The Register</div>
            <div class="title">n8n security woes roll on as new critical flaws bypass December fix</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-46" style="display:none;">
            <h2>n8n security woes roll on as new critical flaws bypass December fix</h2>
            <p><strong>The Register | 2026-02-05</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2026/02/05/n8n_security_woes_roll_on/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Multiple newly disclosed bugs in the popular workflow automation tool n8n could allow attackers to hijack servers, steal credentials, and quietly disrupt AI-driven business processes.

The vulnerabilities, collectively tracked as CVE-2026-25049, stem from weaknesses in how n8n sanitizes expressions inside workflows and could enable authenticated users to smuggle malicious code past safeguards introduced to fix CVE-2025-68613, a December 2025 vulnerability that already carried a near-perfect severity score.

The new flaws carry a CVSS rating of 9.4, though some researchers argue the real-world impact could be even worse.

n8n – an open source automation platform widely used to stitch together cloud apps, internal services, and increasingly AI-driven workflows – confirmed the issue in a security advisory published Wednesday. Maintainers warned that users with permission to create or modify workflows could craft expressions that trigger unintended command execution on the host system.

&quot;Additional exploits in the expression evaluation of n8n have been identified and patched following CVE-2025-68613,&quot; n8n&#39;s maintainers said. &quot;An authenticated user with permission to create or modify workflows could abuse crafted expressions in workflow parameters to trigger unintended system command execution on the host running n8n.&quot;

The disclosure lands just weeks after another maximum-severity n8n bug dubbed &quot;ni8mare&quot; exposed an estimated 100,000 automation servers to takeover through an unauthenticated remote code execution flaw that allowed attackers to seize vulnerable systems without logging in, underscoring how frequently the platform has landed in defenders&#39; patch queues lately.

Security outfit Pillar Security, which disclosed the new vulnerabilities alongside other researchers, told The Register that the vulnerabilities are particularly damaging because of the sensitive material automation platforms typically handle. The vendor warned that successful exploitation could hand attackers full control of vulnerable servers. That access could also spill out stored workflow credentials, including API keys and tokens used to connect to cloud and AI services.

&quot;What makes these vulnerabilities particularly dangerous is the combination of ease of exploitation and the high-value targets they expose,&quot; said Eilon Cohen, AI security researcher at Pillar Security. &quot;If you can create a workflow in n8n, you can own the server.

&quot;For attackers, this means access to OpenAI keys, Anthropic credentials, AWS accounts, and the ability to intercept or modify AI interactions in real time – all while the workflows continue functioning normally.&quot;

The risks may be even broader for users of n8n Cloud, the hosted version of the platform. According to Pillar, the service&#39;s multi-tenant architecture could allow a single malicious user to access other customers&#39; data if the flaw is successfully exploited.

Researchers at SecureLayer 7, who also discovered the vulnerability, said exploitation requires relatively little effort. In one proof-of-concept example, researchers demonstrated how an attacker could set up a workflow using a public webhook with no authentication. By inserting a short line of JavaScript using destructuring, they tricked n8n into running commands at the system level. Once that webhook is live, anyone who knows the URL could hit the endpoint and execute commands on the server hosting it.

The disclosure highlights how automation platforms are becoming increasingly attractive targets as they take on a larger role within organizations. Tools such as n8n often store credentials that grant access to SaaS apps, internal systems, and AI services, so if attackers breach one of these platforms, access can quickly spill over into other environments.

Patches addressing CVE-2026-25049 have now been released, and n8n is urging customers to update immediately. Security teams are being told to take a closer look at user permissions, review existing workflows, and rotate sensitive credentials in automation pipelines, particularly those connected to cloud or AI services.

Because automation tools are tightly integrated into daily operations, breaches can be hard to detect. Workflows continue to run as usual, dashboards show everything is fine, and attackers can extract sensitive data without drawing much attention. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-47')">
            <div class="source">The Register</div>
            <div class="title">CentOS is coming to RISC-V soon if you have the kit</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-47" style="display:none;">
            <h2>CentOS is coming to RISC-V soon if you have the kit</h2>
            <p><strong>The Register | 2026-02-05</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2026/02/05/centos_coming_to_riscv_soon/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">FOSDEM 2026 CentOS Connect 2026 took place in Brussels last week, over the two days preceding the sprawling FOSDEM festival of FOSS – the nerd world&#39;s Glastonbury, complete with the queues and the questionable hygiene.

CentOS Connect is part of the growing FOSDEM Fringe. The Reg FOSS desk was only able to attend for the first day as the second conflicted with the Open Source Policy Summit, which we covered yesterday. Last year, we were at both days of CentOS Connect and the big revelations were on the first day, so we hoped that this would hold true.

One cute change was visible as soon as we got to the registration desk. CentOS Stream now has an official mascot: the quokka. The timing amused us – it&#39;s apparently been in discussion since 2022, but became official just in time to coincide with Ubuntu&#39;s Questing Quokka becoming the current release, as the Plucky Puffin release reached its end of life in the middle of January.

When we talked to FOSDEM attendees about CentOS Connect last year, the general reaction was of surprise that CentOS still existed. Most people thought the project had effectively ended when Red Hat killed off CentOS Linux back in 2020. While that was the end of CentOS Linux, its rather different successor distro CentOS Stream is alive and well with an active community around it. (The word &quot;community&quot; is very much more important in the lands of the crimson-capped than it is in other parts of the Linux universe; we plan to return and explain this in greater depth very soon.)

CentOS Stream may not have so many individual users as CentOS Linux did, but the few organizations using it are among the biggest around, as Linux news site Phoronix hinted in 2021. Meta runs CentOS Stream, and users don&#39;t come much bigger than that. (Of course, it probably uses other distros too, but it&#39;s not saying.)

CentOS Stream is a free upstream version of Red Hat Enterprise Linux, and as we have explained before, RHEL – and SUSE&#39;s SLE – are absolutely tiny compared to a general-purpose free distro such as Ubuntu, which has something like 20 times as many packages in its repositories. However, Stream is still a capable general-purpose distro, as Troy Dawson&#39;s talk demonstrated: he installed it on a Steam Deck live on stage, without so much as an external keyboard to help. It wasn&#39;t easy, but it worked. At the end of his talk he announced perhaps the biggest news of the day:

RISC-V support is coming in the next version of CentOS Stream. We will offer an image for hardware that is buyable… although someone has to make hardware that the general public can buy first.

It&#39;s been a while coming – the IBM subsidiary announced a developer preview in May 2025, and so did the CentOS Project. At the time of writing, though, it&#39;s still missing from the Downloads page.

We hope that there is some new RISC-V hardware available to buy soon as the recently superseded Ubuntu 25.10 &quot;Plucky&quot; only supports QEMU RISC-V emulation. That&#39;s less than ideal.

After the Steam Deck demo came a presentation from the Hyperscale Special Interest Group, which specializes in ultra-large-scale deployments and their management. Meta&#39;s Davide Cavalca was one of the speakers, demonstrating how his employer is one of the main contributors to this CentOS Stream use case.

After that, there was a talk by Peter Georg of the Kmods SIG. This sounds very niche but it demonstrated that CentOS Stream is more versatile than it seems from its description. As the project page says, this team focuses on:

Packaging and maintaining kernel modules for the stock Enterprise Linux kernel.

Packaging and maintaining Fedora flavored kernels for Enterprise Linux distributions.

What the first point mainly means is non-FOSS kernel drivers – in other words, Nvidia support. Georg took care to note that versions of the Kmods drivers are also available for CentOS Stream&#39;s relatives – including RHEL itself, Rocky Linux, and a special version built for AlmaLinux.

The second point means that you&#39;re not restricted to the kernel 6.12 that CentOS 10 shipped with – the Kmods team makes newer kernels available too, which means that for example you can get an automatically updated package containing the newest LTS kernel version 6.18 for CentOS and the RHELatives. As the project repository page describes:

The Kmods SIG provides different Linux kernel versions with a Fedora flavored configuration, i.e., with more modules enabled.

Since the release of RHEL 10 in May 2025, it&#39;s required x86-64-v3. (Even though Linus hated the nomenclature, these shorthand terms for the different generations of 64-bit x86 seem to be here to stay.) That means it won&#39;t run on older kit anyway. If you want a new RHELative on 15-plus-year-old kit, AlmaLinux can help. So the Kmods SIG focuses on drivers for the latest and greatest kit, things for which the kernel itself doesn&#39;t yet ship with support.

The final talk of the day covered the EPEL SIG, which provides an optional-extras repository for CentOS Stream and RHEL. This expands the selection of software to something close to that of Fedora itself – indeed, that is what the original Fedora Project was: &quot;Fedora is a collection of 3rd party add-ons for Red Hat.&quot;

There is a web search tool along with a singularly unhelpful index, but broadly, a very large selection of the FOSS apps, accessories, and entire desktops that you might find in any ordinary Linux distro are in there. Add the EPEL repositories to CentOS (or RHEL itself) and you can install anything you want, directly and without Flatpak or anything like it. (Flatpak itself is in there, for example.)

CentOS isn&#39;t as dead as you might think. Its role as a freebie distro that&#39;s identical to RHEL has gone, but Rocky fills that role – and Alma sticks quite close, while loosening the restrictions on supported hardware. But it has its uses, and thanks to the efforts of its SIGs and the EPEL project, it can do more or less anything that any other distro can do. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-48')">
            <div class="source">The Verge</div>
            <div class="title">Why is the Trump administration really appealing its Meta loss?</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-48" style="display:none;">
            <h2>Why is the Trump administration really appealing its Meta loss?</h2>
            <p><strong>The Verge | 2026-02-05</strong></p>
            <a class="original-link" href="https://www.theverge.com/policy/874286/ftc-meta-antitrust-appeal-boasberg-tiktok">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The FTC’s Meta case is clouded by a political attack.

The FTC’s Meta case is clouded by a political attack.

After a federal judge ruled that Meta was not an illegal monopolist in a blow against the Federal Trade Commission, the agency issued what was in part a typical statement of disappointment. Another part of the statement was anything but: a political attack on the judge himself.

“The deck was always stacked against us with Judge [James] Boasberg, who is currently facing articles of impeachment,” FTC spokesperson Joe Simonson said in a statement after Boasberg released his decision in November. Simonson appeared to reference articles filed by a Republican lawmaker after Boasberg issued rulings that were unfavorable to GOP lawmakers and the Trump administration over a 2020 election probe and immigration policies.

In late January, the FTC announced it would appeal the Meta ruling. Legal experts tell The Verge its decision isn’t surprising or unreasonable. But the attack on Boasberg, they say, casts a shadow over the decision — making the motives for what might typically be a routine move less clear.

“You wonder how much there’s an element of irritation or annoyance just at Judge Boasberg himself here, and how much of it is an institutional decision that, ‘we’re going to show you,’” says Bill Kovacic, a former FTC chair and current George Washington University law professor. “This is a judge who the White House has criticized severely. Is there some element here of personal animus focused on this judge?”

Kovacic and others say there’s a sensible legal argument against the way Boasberg reviewed FTC v. Meta, though the agency hasn’t yet detailed its appeal strategy. The lawsuit, filed in 2020, argues Meta crushed competition by acquiring nascent rivals Instagram and WhatsApp in 2012 and 2014 respectively. Early on, however, Boasberg said the FTC needed to prove that Meta maintained or threatened to maintain an unlawful social networking monopoly as of the 2025 trial date. By that measure, he determined, the FTC’s case failed — largely because of TikTok.

TikTok exploded in popularity throughout the pandemic, and both Meta and YouTube invested heavily in short-form video to compete. Its popularity — which, according to internal documents, deeply concerned Meta — convinced Boasberg that the FTC had overstated Meta’s dominance in the current day. Boasberg admitted in his ruling that in response to earlier attempts by Meta to get him to dismiss the case, his orders “did not even mention the word ‘TikTok.’” But at the time of his 2025 ruling, “that app holds center stage as Meta’s fiercest rival.”

Boasberg’s decision to judge Meta’s monopoly by 2025 standards may become the FTC’s strongest basis to appeal its loss

Now, Boasberg’s decision to judge Meta’s monopoly by 2025 standards may become the FTC’s strongest basis to appeal its loss. Boasberg’s interpretation of the relevant timeframe arguably creates a “moving target,” says Vanderbilt law professor Rebecca Haw Allensworth. That could discourage the agency from bringing future enforcement actions if the market could shift while litigating the case. And the appeals court could — though it’s far from certain — determine it doesn’t make sense. “It just creates an additional risk of losing a trial if facts change on the ground underneath you,” she says.

The court of appeals judges won’t have to defer to Boasberg’s decision on how to interpret the law, as they would for his findings of fact. They could determine that Boasberg should have considered the relevant timeframe to be earlier, like the time at which the lawsuit was filed, when TikTok was growing rapidly but was far smaller. Viewed through that lens, the court might determine that Meta was a monopolist at the relevant time period — though again, it’s far from certain.

During the Biden administration, the FTC chose not to appeal a different loss to Meta, when it tried to challenge its proposed acquisition of VR startup Within. But the text of the ruling included a helpful legal interpretation for challenging future cases. Overall, the FTC has invested far more time and resources already into the social media monopolization case, which has spanned five years, two Trump administrations and the Biden administration, so it’s not entirely surprising that it wouldn’t give up now.

But like other actions during the second Trump administration, where formerly independent agencies like the FTC have explicitly aligned themselves with the White House, the attack on Boasberg’s record has created a cloud of suspicion.

Boasberg became a target of Trump soon after the president’s second term began in 2025. After Boasberg blocked the administration’s deportation orders last year, Trump posted on Truth Social that he was a “Radical Left Lunatic” and “a troublemaker and agitator.” Rep. Brandon Gill (R-TX) introduced articles of impeachment against Boasberg last year over his decisions temporarily blocking the Trump administration from moving forward with its planned mass deportation of Venezuelan migrants and for what Gill says was his role in authorizing “frivolous nondisclosure orders” so that special counsel Jack Smith could access Republican lawmakers’ phone records without their knowledge in his investigation into efforts to overturn the 2020 election results.

“My sense is the audience for that comment was the White House”

Kovacic says the appeals court is unlikely to find personal attacks on Boasberg compelling, but adds that it likely wasn’t the intended recipient of the PR statement. “My sense is the audience for that comment was the White House,” he says. The FTC and the White House did not immediately respond to a request for comment. Meta spokesperson Chris Sgro said in a statement after the FTC announced its appeal that Boasberg’s decision was “correct, and recognizes the fierce competition we face.”

There’s also the fact that continuing with an appeal may maintain a point of leverage by the administration over Meta. “One thing that we know for sure about Trump is that he likes to have leverage over powerful companies, especially media companies, that can influence public opinion, and that can be politically valuable to Trump,” says Allensworth. “So he might as well keep the case going as a source of leverage.” (Meta CEO Mark Zuckerberg has visited Trump multiple times, and Meta agreed to pay $25 million to settle a lawsuit brought by him.) Though the FTC was created as an agency independent from the executive branch, the current chair has aligned himself with the White House, calling it the Trump-Vance FTC.

Given the real, if not surefire, arguments in the FTC’s favor, Kovacic says he assumes the decision to appeal “is mainly about the merits.” But, he asks of the FTC’s comments on Boasberg, “why are you talking about the other stuff?”

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-49')">
            <div class="source">The Verge</div>
            <div class="title">JLab’s new Bluetooth speaker doubles as supersized headphones</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-49" style="display:none;">
            <h2>JLab’s new Bluetooth speaker doubles as supersized headphones</h2>
            <p><strong>The Verge | 2026-02-05</strong></p>
            <a class="original-link" href="https://www.theverge.com/tech/874340/jlab-blue-xl-wireless-bluetooth-speaker-headphones">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">﻿The Blue XL look like an early April Fools’ Day prank, but you can buy a pair now for $100.

﻿The Blue XL look like an early April Fools’ Day prank, but you can buy a pair now for $100.

If you buy something from a Verge link, Vox Media may earn a commission. See our ethics statement.

JLab, a brand best known for its budget-friendly but well-featured wireless earbuds, has announced a new pair of headphones that are far less discreet. The oversized Blue XL Speaker Headphones look like an ill-timed April Fools’ Day prank but are actually a pair of Bluetooth speakers cosplaying as wireless headphones. They’re wearable, but for the sake of your eardrums, you’ll want to leave them hanging around your neck.

The Blue XL are now available through JLab’s online store for $99.99 in limited quantities and, as the name implies, blue is the only color option. Inside each ear cup is a 2.5-inch driver paired with a similar-sized passive radiator to boost lower frequencies. You can prop them up on a table to use as a standalone speaker, but the ear cups don’t detach. Battery life is claimed to be up to 20 hours, while a full recharge takes about three hours.

JLab’s latest creation is reminiscent of the TDM Neo headphones that debuted at CES 2026 and are expected to launch on Kickstarter next week. The Neo also offers dual headphone / speaker functionality but through a design that cleverly rolls up to switch between modes. The Blue XL’s approach is to just be… big. Portability is not a priority, but I’d certainly enjoy a front row seat to the spectacle of someone wearing these on a plane.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-50')">
            <div class="source">The Verge</div>
            <div class="title">Reality is losing the deepfake war</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-50" style="display:none;">
            <h2>Reality is losing the deepfake war</h2>
            <p><strong>The Verge | 2026-02-05</strong></p>
            <a class="original-link" href="https://www.theverge.com/podcast/874038/ai-deepfakes-war-on-reality-c2pa-labels">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Why AI labeling efforts are falling flat in the face of slop, disinformation, and messy metadata standards.

Why AI labeling efforts are falling flat in the face of slop, disinformation, and messy metadata standards.

Today, we’re going to talk about reality, and whether we can label photos and videos to protect our shared understanding of the world around us. No really, we’re gonna go there. It’s a deep one.

To do this, I’m going to bring on Verge reporter Jess Weatherbed, who covers creative tools for us — a space that’s been totally upended by generative AI in a huge variety of ways with an equally huge number of responses from artists, creatives, and the huge number of people who consume that art and creative output out in the world.

If you’ve been listening to this show or my other show The Vergecast, or even just been reading The Verge these past several years, you know we’ve been talking about how the photos and videos taken by our phones are getting more and more processed and AI-generated for years now. Here in 2026, we’re in the middle of a full-on reality crisis, as fake and manipulated ultra-believable images and videos flood social platforms at scale and without regard for responsibility, norms, or even basic decency. The White House is sharing AI-manipulated images of people getting arrested and defiantly saying it simply won’t stop when asked about it. We have gone totally off the deep end now.

Verge subscribers, don’t forget you get exclusive access to ad-free Decoder wherever you get your podcasts. Head here. Not a subscriber? You can sign up here.

Whenever we cover this, we get the same question from a lot of different parts of our audience: why isn’t there a system to help people tell the real photos and videos apart from fake ones? Some people even propose systems to us, and in fact, Jess has spent a lot of time covering a few of these systems that exist in the real world. The most promising is something called C2PA, and her view is that so far, it’s been almost entirely failures.

Is this episode, we’re going to focus on C2PA, because it’s the one with the most momentum. C2PA is a labeling initiative spearheaded by Adobe with buy-in from some of the biggest players in the industry, including Meta, Microsoft, and OpenAI. But C2PA, also sometimes referred to as Content Credentials, has some pretty serious flaws.

First, it was designed as more of a photography metadata tool, not an AI detection system. And second, it’s really only been only half-heartedly adopted by a handful, but not nearly all, of the players you would need to make it work across the internet. We’re at the point now where Instagram chief Adam Mosseri is publicly posting that the default should shift and you should not trust images or videos the way you maybe could before.

Think about that for one second. That’s a huge, pivotal shift in how society evaluates photos and videos and an idea I’m sure we’ll be coming back to a lot this year. But we have to start with the idea that we can solve this problem with metadata and labels — that we can label our way into a shared reality. And why that idea might simply never work.

Okay, Verge reporter Jess Weatherbed on C2PA and the effort to label our way into reality. Here we go.

This interview has been lightly edited for length and clarity.

Jess Weatherbed, welcome to Decoder. I want to just set this stage. Several years ago, I said to Jess, “Boy, these creator tools are criminally under-covered. Adobe as a company is criminally under-covered. Go figure out what’s going on with Photoshop and Premiere and the creator economy because there’s something there that’s interesting.”

And fast-forward, here you are on Decoder today and we’re going to talk about whether you can label your way into consensus reality. I just think it’s important to say that’s a weird turn of events.

Yeah. I keep likening the situation to the Jurassic Park meme, where people thought so long about whether they could, they didn’t actually stop to think about whether they should be doing this. Now we’re in the mess that we’re in.

The problem, broadly, is that there’s an enormous amount of AI-generated content on the internet. Much of it just depicts things that are flatly not real. An important subset of that is a lot of content that depicts modifications to things that actually happened. So our sense that we can just look at a video or a picture and sort of implicitly trust that it’s true is fraying, if not completely gone. And we will come to that, because that’s an important turn here, but that’s the state of play.

In the background, the tech industry has been working on a handful of solutions to this problem, most of which involve labeling things at the point of creation. At the moment you take a photo or the moment you generate an image, you’re going to label it somehow. The most important one of those is called C2PA. So can you just quickly explain what that stands for, what it is, and where it comes from?

So this is effectively a metadata standard that was kickstarted by Adobe. Interestingly enough, Twitter as well, back in the day. You can see where the logic lies. It was supposed to be that everywhere a little bit of content goes online, this embedded metadata would follow.

What C2PA does is this: at the point that you take a picture on a camera, you upload that image into Photoshop, all of these instances would be recorded in the metadata of that file to say exactly when it was taken, what has happened to it, what tools were used to manipulate it. And then as a two-part process, all of that information could then hypothetically be read by online platforms where you would see that information.

As consumers, as internet users, we wouldn’t have to do anything. We would be able to, in this imaginary reality, go on Instagram or X and look at a photo and there would be a lovely little button there that just says, “This is AI-generated,” or, “This is real,” or some sort of authentication. That has obviously proven a lot more difficult in reality than on paper.

Tell me about the actual label. You said it’s metadata. I think a lot of people have a lot of experience with metadata. We are all children of the MP3 revolution. Metadata can be stripped, it can be altered. What protects the C2PA metadata from just being changed?

They argue that it’s quite tamper-proof, but it’s a little bit of an “actions speak louder than words” situation, unfortunately. Because while they say it’s tamper-proof, this thing is supposed to be able to resist being screenshot, for example, but then OpenAI, who is actually one of the steering community members behind this standard, openly says it’s incredibly easy to strip to the point that online platforms might actually do that accidentally. So the theory is there’s plenty behind it to make it robust, to make it hard to remove, but in practice, that just isn’t the case. It can be removed, maliciously or not.

It’s a little bit of a confusing landscape, because I think it’s one of the few tech areas that I would say there shouldn’t actively be competition. And from what I’ve seen, from what I’ve spoken to with all these different providers, there isn’t competition between them as much as they’re all working towards the same goal.

Google SynthID is similar. It’s technically a watermarking system more so than a metadata system, but they work on a similar premise that stuff will be embedded into something you take that you’ll then be able to assess later to see how genuine it is. The technicalities behind that are difficult to explain in a shortened context, but they do operate on different levels, which means technically they could work together. A lot of these systems can work together.

You’ve got inference-based systems as well, which is where they will look at an image or a video or a piece of music and they will pick up telltale signs that apparently it may have been manipulated by AI and they will give you a rating. They can never really say yes or no, but they’ll give you a likelihood rating.

None of it will stand on its own to be a one true solution. They’re not necessarily competing to be the one that everyone uses, and that’s the mess that C2PA is now in. It’s been lauded and it’s been grandstanded. They say, “This will save us,” whereas it was never designed to do that, and it certainly isn’t equipped to.

Who runs it? Is it just a group of people? Is it a bunch of engineers? Is it simply Adobe? Who’s in charge?

It’s a coalition. The most prominent name you’ll see is Adobe because they’re the ones that shout about it the most. They’re one of the founding members of the Content Authenticity Initiative, which has helped to develop the standard. But you’ve got big names that are part of the steering committee behind it, which are supposed to be the groups involved with helping other people to adopt it, which is the important thing, because otherwise it doesn’t work. And part of this process, if you’re not using it, C2PA falls over. And OpenAI is part of that. Microsoft, Qualcomm, Google, all of these huge names are all involved with that and are supposedly helping to ... They’re very careful not to say “develop it,” but to promote its adoption and to encourage other people, in regards to who’s actually working on it.

Why are they careful not to say they’re developing it?

There isn’t any confirmation that I can find where it’s got something like, I don’t know, Sam Altman saying, “We’ve found this flaw in C2PA, and therefore we’re helping to address any kind of falls and pitfalls it may have.” It’s always just anytime I see it mentioned, it’s whenever a new AI feature has been rolled out and there’s a convenient little disclaimer slapped on the bottom, kind of a, “Yay, we did it. Look, it’s fine, a new AI thing, but we have this totally cool system that we use that’s supposed to make everything better.” They don’t actively say what they’re doing to improve the situation, just that they’re using it and they’re encouraging everyone else to be using it too.

One of the most important pieces of the puzzle here is labeling the content at capture. We’ve all seen cell phone videos of protests and government actions and horrific government actions. And I think Google has C2PA in the Pixel line of phones. So video that comes off a Pixel phone or photos that come off a Pixel phone have some embedded metadata that says it’s real.

Apple notably doesn’t. Have they made any mention of C2PA or any of these other standards that would authenticate the photos or videos coming off an iPhone? That seems like an important player in this entire ecosystem.

They haven’t officially or on record. I have sources that say apparently they were involved in conversations to at least join, but nothing public-facing at the minute. There has been no confirmation that they are actually joining the initiative or even adopting Google SynthID technology. They’re very carefully skirting on the sidelines for some reason.

It’s a little bit unclear as to whether they’re letting their caution about AI generally stem into this at this point. Because as far as I’m concerned, there is not going to be one true solution, so I don’t really know what Apple is waiting for, and they could be making a difference, but no, they haven’t been making any kind of declarations about what we should be using to label AI.

That’s so interesting to me. I mean, I love a standards war, and we’ve covered many standards wars and the politics of tech standards are usually ferocious. And they’re usually ferocious because whoever controls the standard generally stands to make the most money, or whoever can drive the standard and an extended standard can make a lot of money.

Apple has played that game maybe better than anybody. It’s driven a lot of the USB standard. It was behind USB-C. It drove a lot of Bluetooth standard, which it extended for AirPods. I can’t see how you make money with C2PA, and it seems like Apple is just letting everyone else figure it out and then they will turn it on, and yet it feels like the responsibility to be the most important camera maker in the world is to drive the standard so people trust the images and videos that come off the cameras.

Does that dynamic come out anywhere in your reporting or your conversations with people about this standard — that it’s not really there to make money, it’s there to protect reality?

The moneymaking side of things never really comes into the conversation. It’s always that people are very quick to assure me that things are progressing. There’s never any kind of a conversation about incentive to motivate other people to do so. Apple doesn’t stand to really gain anything financially from this other than maybe the reassurance that people know that if they’re taking a picture with their iPhone, it could help to contribute to some sense of establishing what is still real and what isn’t. But then that’s a whole other can of worms because if iPhone is doing it, then all the platforms that we see those pictures on also have to be doing it. Otherwise, I’m just kind of verifying that this is real to my own eyes as me, the person that uses my iPhone.

Apple may be aware that all the solutions that we currently have available are inherently flawed, so throwing your lot in as one of the biggest names in this industry and one that could arguably do the most difference, you’re almost exacerbating the situation that Google and OpenAI are now in, which is that they keep lauding this as the solution and it doesn’t fucking work. I think Apple needs to be able to stand on its laurels about something, and nothing is going to offer them that at the minute.

I want to come back to how specifically it doesn’t work in one second. Let me just stay focused on the rest of the players on the content creation side of the ecosystem. There’s Apple, and there’s Google, which uses it in the Pixel phones. It’s not in Android proper, right? So if you have a Samsung phone, you don’t get C2PA when you take a picture with a Samsung phone. What about the other camera makers? Are Nikon and Sony and Fuji all using the system?

A lot of them have joined. They’ve released new camera models that have got the system embedded. The problem that they’re having now is in order for this to work, you don’t just have to do it on your new cameras, because every photographer in the world worth their salt isn’t going to go out every year and buy a brand new camera because of this technology. It would be inherently useful, but that’s just not going to happen. So backdating existing cameras is where the problem is going to be.

We’ve spoken to a lot of different companies. As you said, Sony has been involved with this, Leica, Nikon, all of them. The only company willing to speak to us about it was Leica, and even they were very vague on how internally this is progressing. They just keep saying that it’s part of the solution, it’s part of the step that they’re going to be taking. But these cameras aren’t being backdated at the minute. If you have an established model, it’s 50/50 whether it’s even possible to update it with the ability to log these metadata credentials in from that point.

There are other sources of trust in the photography ecosystem. The big photo agencies require the photographers who work there to sign contracts that say they won’t alter images, they won’t edit images in ways that fiddle with reality. Those photographers could use the cameras that don’t have the system, upload their photos to, I don’t know, Getty or AFP or Shutterstock, and then those companies could embed the metadata, and so “You can trust us.” Are any of them participating in that way?

We know that Shutterstock is a member. At the minute, the system that you’re describing would probably be the best approach that we have to making this beneficial, at least for us as people that see things online and want to be able to trust whether protest images or horrific things that we’re seeing online are actually real. To have a trusted middleman, as it were. But that system itself hasn’t been established. We do know that Shutterstock is involved. They are part of the C2PA committee, or they have general membership.

So they are on board with using the standard, but they’re not actively part of the process behind how it’s going to be adopted at a further stage. Unless we can also get the other big players involved for stock imagery, then who knows whether this is going to go, but Shutterstock actually implementing it as a middleman system would be probably the most beneficial way to go.

I’m just thinking about this in terms of the stuff that is made, the stuff that is distributed and the stuff that is consumed. It seems like at least at the moment of creation, there is some adoption, right? Adobe is saying, “Okay, in Photoshop, we’re going to let you edit photos and we’re going to write the metadata to the images and pass them along.” A handful of phonemakers, Google, or at least in its phones, are saying, “We’re going to write the metadata. We’re going to have SynthID.” OpenAI is putting the system into Sora 2 videos, which you wrote about.

On the creation side, there’s some amount of, “Okay, we’re going to label this stuff. We’re going to add the metadata.” The distribution side seems to be where the mess is, right? Nobody’s respecting the stuff as it travels across the internet. Talk about that. You wrote about Sora 2 videos and how they exploded across the internet. This is when it should have not been controversial to put labels everywhere saying, “This is AI-generated content,” and yet it didn’t happen. Why didn’t that happen anywhere?

It generally exposes the biggest flaw that this system has, and every system like it, to its credit. I don’t want to defend C2PA because it’s doing a bad job. It wasn’t ever designed to do it on this scale. It wasn’t designed to apply to everything. So in this example, yes, platforms need to be adopting it to actually read that metadata, providing they’re not the ones ripping it out during the process of actually supposedly scanning for it, but unless this is absolutely everywhere, it’s just not going to go.

Part of the problem that we’re seeing is, as much as they can credit saying, “It’s going to be really robust, it’s going to be really efficient, you can embed this at any other stage,” there are still flaws with how it’s being interpreted, even if it is scanned. So that’s a big thing. It’s not necessarily that platforms aren’t picking up the metadata or stripping it out. It’s that they have no idea what to do with it when they actually have it. And at the point of uploading any images, there are social media platforms. LinkedIn, Instagram, Threads are all supposed to be using this standard, and there is a chance that when you upload any kind of image or video to the platform, any metadata that was involved in that is just going to be stripped out regardless.

Unless they can all come to an agreement, every platform, literally every platform that we access and use online, can come to an agreement that they are going to be scanning for very, very specific details, they’re going to be adjusting their upload processes, they’re going to be adjusting how they communicate to their users, there needs to be that uniform, total uniform conformity for a system like this to actually make a difference, not even just to work. And we’re clearly not even going to see that.

One of the conversations I had, actually, was when I was grilling Andy Parsons, who is head of content credentials at Adobe—that’s their word for implementing C2PA data—I commented on the Grok mess that we’ve had recently. Twitter was a founding member of this, and then when Elon purchased the platform, it disappeared. And by the sounds of it, they’ve been trying to entice X to get back involved, but that’s just not going anywhere. And X, however we see its user base at the minute, has millions of people using it, and that is a portion of the internet that is never going to benefit from this system because it has no interest in adopting it. So you’re never going to be able to address that.

I’m going to read you this quote from Adam Mosseri, who runs Instagram. On New Year’s Eve, he just dropped a bomb and he put out a blog post in the form of a 20-carousel Instagram slideshow, which has its own PhD thesis of ideas about how information travels on the internet embedded within it, but he put out a 20 slideshow on Instagram. In it, he said, “For most of my life, I could safely assume photographs or videos were largely accurate captures of moments that happened. This is clearly no longer the case and it’s going to take us years to adapt. We’re going to move from assuming what we see as real by default to starting with skepticism.”

This is the end point, right? This is “you can’t trust your eyes,” which means you can no longer trust a photo, you can’t trust a video of any event is actually real, and reality will start to crumble. And you can just look at events in the United States over the past month. The reaction to ICE killing Alex Pretti was, “Well, we all saw it,” and it’s because there was lots of video of that event from multiple angles and everyone said, “Well, we can all see it.”

The foundation of that is we can trust that video. And I’m looking at Adam Mosseri saying, “We’re going to start with skepticism. We can no longer assume photos or videos are accurate captures of moments that happened.” This is the turn. This is the point of the standard. Do you see Mosseri saying this out loud about Instagram as the end point of this? Is this war just lost?

I would say so. I think we’ve been waiting for tech to basically admit it. I see them using stuff like C2PA as a meritless badge at this point because they’re not endeavoring to push it to its utmost potential really. Even if it was never going to be the ultimate solution, it could have been at least some kind of benefit.

We know that they’re not doing this because in the same message, Mosseri is describing this like, “Oh, it would be easier if we could just tag real content. That’s going to be so much more doable, and that would be good, and we’ll circle those people.” It’s like, “My guy, that’s what you’re doing.” C2PA is that. It’s not specifically an AI tagging system. It’s supposed to say, “Where has this been and who took this? Who made this? What has happened to it?”

So if we’re going for authenticity, Mosseri is just openly saying, “We’re using this thing and it doesn’t work, but imagine if it did. Wouldn’t that be great?” That’s deeply unhelpful. It’s his way of deeply unhelpfully musing into some system that will be able to, I don’t know, regain some kind of trust, I guess, while also acknowledging that we’re already there.

I’m going to make you keep arguing with Adam Mosseri. We’ve invited Adam on the show. We’ll have him on and maybe we can add this debate with him in person, but for now you’re going to keep arguing with his blog post. He says, “Platforms like Instagram will do good work identifying AI content, but it’ll get worse over time as AI gets better. It’ll be more practical to fingerprint real media than fake media. Labeling is only part of the solution,” he says. “We need to surface much more context about the accounts sharing content so people can make informed decisions.”

So he’s saying, “Look, we’ll start to sign all the images and everything, but actually, you need to trust individual creators. And if you trust the creator, then that will solve the problem.” And it seems like you’re really skipping over the part where creators are fooled by AI-generated content all the time. And I don’t mean that to say creators as a class of people. I mean, literally just everyone is fooled by AI content all the time. If you’re trusting people to understand it and then share what they think is real, and then you’re trusting the consumers to trust the people, that also seems like a whirlwind of chaos.

On top of that, and you’ve written about this as well, there’s the notion that these labels make you mad at people, right? If you label a piece of content as AI-generated, the creator gets furious because it makes their work seem less important or less valuable. The audiences yell at the creators. There’s been a real push to get rid of these labels entirely because they seem to make everyone mad.

How does that dynamic work here? Does any of this have a way through?

I mean, it doesn’t. And the other amusing thing is Instagram knows this the hard way. Mosseri should remember, one of the very first platform implementations they did of reading C2PA was done by Facebook and Instagram a couple of years ago where they were just slapping “made with AI” labels onto everything because that’s what the metadata told them.

The big problem here that we have isn’t just communication, which is the biggest part of it. How do you communicate a complex bucket of information to every person that’s going to be on your platform and get them only the information that they need? If I’m a creator, it shouldn’t have to matter if I was using AI or not, but if I’m a person trying to see if, again, a photo is real, I would greatly benefit from just an easy button or label that verifies authenticity.

Finding the balance for that has proven next to impossible because, as you said, people just get upset about it. But then how do you define how much AI in something is too much AI? Photoshop and all of Adobe’s tools, they do embed these content credentials in all of this metadata, it will say when AI has been used, but AI is in so many tools, and not necessarily in the generative way that we assume it’s going to be like, “I’m going to click on this. It’s going to add something new to an image that was never there before and that’s fine.”

There are very basic editing features that video editors and photographers now use that will have some kind of information embedded into them to say that AI was involved in that process. And now when you’ve got creators on the other side of that, they might not know that what they are using is AI. We’re at the point where, unless you can go through every platform, every editing suite with a fine tooth comb and designate what we count as AI, this is a non-starter. He’s already hit the point that we can’t communicate this to people effectively.

Let’s pause here for a second, because I want to lay out some important context before we keep digging in.

If you’ve been a Verge reader, you know that we’ve been asking a very simple question for over five years now: What is a photo? It sounds simple, but it’s actually quite complicated. After all, when you push the shutter button on a modern smartphone, you’re not actually capturing a single moment in time, which is what most people think a photo is.

Modern phones actually take a lot of frames both before and after you press the shutter button and merge them into a single, final photo. That’s to do things like even out the shadows and highlights of the photo, capture more texture, and accomplish feats like Night Mode.

There was a mini-scandal a few years ago where if you tried to take a photo of the moon with a Samsung phone, the camera app would just generate a picture of the moon.  Of course, Google Pixel phones have all kinds of Gemini-powered AI tools in them, to the point where Google now says the point of the camera is to capture “memories,” not moments in time. This is a lot, and like I said, we’ve been talking about it for years here at The Verge.

Now, generative AI is pushing the “what is a photo” debate to its absolute limits. It’s hard to even agree on how much AI editing makes something an AI-edited photo, or even whether these features should be considered AI in the first place. If that’s so hard, then how can we possibly reach consensus on what’s real and what we label as real? Camera makers have basically thrown their hands up here, and now we’re seeing the major social media platforms do the same thing.

I bring this up partially because it’s an obsession of mine, but also I think laying it all out makes it obvious how very, very complicated this all is, which brings us back to Adam Mosseri, Instagram, and the AI labeling debate.

I will give some credit to Instagram and Adam Mosseri here in that they are at least trying and thinking about it and publicly thinking about it in a way that none of the other social networks seem to have given any shred of consideration to. TikTok, for example, is nowhere to be found here. They are just going to distribute whatever they distribute without any of these labels, and it doesn’t seem like they’re part of the standard. I think X is absolutely just fully down the rabbit hole of distributing pure AI misinformation. YouTube seems like the outlier, right? Google runs SynthID, they’re in C2PA, they’re embedding the information literally at the point of capture in Pixel phones. What is YouTube doing?

A very similar approach to TikTok actually, because weirdly enough, TikTok is involved with this. It uses the standard. It’s not necessarily a steering member, but it is involved. And it has a similar approach, where you’ll get an AI information label somewhere towards, depending on what format you’re viewing on, mobile or your TV, your computer, you’ll get a little AI information label that you have to click in and ascertain the information that you need from that.

So their problem is making sure it’s robust enough, because this doesn’t appear consistently. There are AI videos all over YouTube that don’t carry this and there’s never a good explanation. Every time I’ve asked them, it’s always just, “We’re working on it. It’s going to get there eventually,” whatever, or they ask for very specific examples and then run in and fix those while I’m like, “Okay, but if this is falling through the net, how can you stand by this as a standard and your own SynthID stuff? And you’re clearly using it to soothe concerns that people have despite its ineffectiveness.”

They don’t seem to be progressing any further than just presenting those labels probably because of what happened to Instagram, and now we’ve just got this situation where Meta does seem to be standing on the sidelines going, “Well, we tried, so let’s just see what someone else can do and maybe we’ll adopt it from there.” But YouTube doesn’t really want to address the slop problem because so much of YouTube content that’s shown to new people is now slop and it’s proven to be quite profitable for them.

Google just had one of its best quarters ever. Neal Mohan, the CEO of YouTube, has been on the show in the past, and we will have him on the show again in the future. He announced at the top of the year that the future of YouTube is AI and they have features that they’ve announced like that creators can have AI versions of themselves do the sponsored content, so that the creators can do whatever that the creators actually want to do.

There’s a part of me that completely understands that. Yes, my digital avatar should go make the ads so I can make the content that the audience is actually here for. And there’s a part of me that says, “Oh, they’re never going to label anything,” because the second they start labeling that as AI-generated, which clearly will be, they will devalue it. And there’s something about that in the creative community with the audience that seems important.

I know you’ve thought about this deeply. You’ve done some reporting here. What is it about the AI-generated label that makes everything devalued, that makes everybody so angry?

I think it’s people trying to put a value on creativity itself. If I was looking at luxury handbags and I see that they’ve not paid a creative team—This is a creative company that makes wonderful products, it’s supposed to stand on the quality of all of the stuff that it sells you. If I find that you’re not involving creative personnel in making an ad for me to want to buy your handbag, why would I want to buy it in the first place?

Not everyone will have that perspective, but as someone that worked in the creative industry for a long time, you see the work that goes into something, even if it’s something as laughable as a commercial. I love TV commercials because as annoying as they are and as much as they’re trying to get me to buy something, you can see the work that went into it, that someone had to write that story, had to get behind the film cameras, had to make the effects and all that kind of stuff.

So it feels like if you’re taking a shortcut to remove all of that, then you’re already cheapening the process yourself. I feel, from the conversations I’ve had with the other creatives, that the initial response of thinking AI looks cheap is because it’s meant to be cheap. That’s why it exists. It exists for efficiency and affordability. If you’re coming across with trying to sell me something on that, it’s probably not going to make the best first impression unless you make it utterly undetectable. And if you have a big “made with AI” or “assisted with AI” label on that, it’s no longer undetectable because even if I can’t see it, you’ve now just admitted that it’s there.

That’s a lot of mixed incentives for these platforms. And it occurs to me as we’ve been having this conversation, we’ve been kind of presuming a world in which everyone is a good-faith actor and trying to make good experiences for people. And I think a lot of the executives of these companies would love to presume that that is the world in which they operate, and whether or not the label makes people mad and you want to turn it off or whether or not you can trust the videos of significant government overreach and cause a protest, that’s still operating in a world of good faith.

Right next to that is reality, the actual reality in which we live, where lots of people are bad-faith actors who are very much incentivized to create misinformation, to create disinformation, and some of those bad-faith actors at this moment in time are the United States government. The White House publishes AI photos all the time. Department of Homeland Security, AI-generated imagery, up, down, left, right, and center. You can just see AI manipulated photos of real people modified to look like they’re crying as they’re being arrested instead of what they actually looked like.

This is a big deal, right? This is a war on reality from literally the most powerful government in the history of the world. Are the platforms ready for that at all? Because they’re being faced with the problem, right? This is the stuff you should label. No one should be mad at you for labeling this, and they seem to be doing nothing. Why do you think that is?

I think it’s because it’s the same process, right? What we’re talking about is a two-way street. You’ve got the people who want to identify AI slop, or maybe they don’t, but people want to be able to see what is and what isn’t AI, but then you’ve got the more insidious situation of, “We actually want to be able to tell what is real, but it unfortunately benefits too many people to make that confusing now.” The solution is for both. AI companies and platforms are profiting off of all of the stuff that they’re showing us and making it much more efficient for content creators to slap stuff in front of you.

We’re in a position now where there’s more online than we’ve ever seen because everything is being funneled out. Why would they want to harm that profit stream, effectively, by having to slam on the brakes of development until they can figure out how they are going to effectively be able to call out when deepfakes are proving to be a problem. The methods of being put in front of it, rather than setting up some kind of middle system like the Shutterstock model we discussed earlier, where all press images now have to come from one authority that has to verify the identity of everyone taking them. Maybe that’s a possibility, but we are so far from that point and, to my knowledge, no one’s instigated setting something like that up. So they’re just kind of relying on everyone talking about this in good faith.

Again, every conversation I’ve had with this is, “We’re working on it. It’s a slow process. We’re going to get there eventually. Oh, it was never designed to do all of this stuff anyway.” So it’s very blase and low effort really—“We’ve joined an initiative, what more do you want?” It’s incredibly frustrating, but that seems to be the reason that everything is not developing, because in order to develop any further, in order to actually help us, they would have to pause. They would have to stop and think about it, and they’re too busy running out every other tool and feature that they can think of doing because they have to. They have to keep their shareholders happy. They have to keep us as consumers happy while also saying, “Ignore everything else that’s going on in the background.”

When I say there’s mixed incentives here, one of the things that really gets me is that the biggest companies investing in AI are also the biggest distributors of information. They’re the people who run the social platforms. So Google obviously has massive investments in AI. They run YouTube. Meta has massive investments in AI, to what end unclear, but massive investments in AI. They run Instagram and Facebook and WhatsApp and the rest.

Just down the line, you can see, “Okay, Elon Musk is going to spend tons of money in xAI and he runs Twitter.” And this is a big problem, right? If your business, your money and your free cash flow is generated by the time people are spending on your platforms and then you’re plowing those profits back into AI, you can’t undercut the thing you’re spending the R&D money on by saying, “We’re going to label it and make it seem bad.”

Are there any platforms that are doing it, that are saying, “Hey, we’re going to promise you that everything you see here is real?” Because it seems like a competitive opportunity.

Very small. There’s an artist platform called Cara, which says that they’re so for supporting artists that they’re not going to allow any AI-generated artwork on the site, but they haven’t really clearly communicated how they are going to do that, because saying it is one thing and doing it is another thing entirely.

There are a million reasons why we don’t have a reliable detection method at the minute. So if I, in complete good faith, pretend to be an artist that’s just feeding AI-generated images onto that platform, there’s very little they can really do about it. Anyone that’s making those statements saying, “Yeah, we’re going to stand on merit and we’re going to keep AI off of the platform,” well how? They can’t. The systems for doing so at the minute are being developed by AI providers, as we’ve said, or at least AI providers are deeply involved with a lot of these systems and there is no guarantee for any of it.

So we’re still relying on how humans intercept this information to be able to tell people how much of what they can see is trustworthy. That’s still kind of putting the onus on us as people. It’s, “Well, we can give you a mishmash of information and then you decide whether it’s reliable or not.” And we haven’t operated in that way as a society for years. People didn’t read the newspapers to make their own mind up about stuff. They wanted information and facts, and now they can’t get that.

Is there user demand for this? This does seem like the incentive that will work. If enough people say, “Hey, I don’t know if I can trust what I see. You have to help me out here, make this better,” would that push the platforms into labeling?

Because it seems like the breakdown is at the platform level, right? The platforms are not doing enough to showcase even the data they have, let alone demand more. But it also seems like the users could simply say, “Hey, the comment section of every photo in the world now is just an argument about whether or not this is AI. Can you help us out?” Would that push them into improvement?

I would like to think it would push them into at least being more vocal about their involvement at the minute. We’ve got, again, a two-sided thing. At the minute, you can’t tell if a photo is real, but also, a less nefarious thing is that Pinterest is now unusable. As a creative, if I want to use the platform Pinterest, I cannot tell what is and what isn’t AI. I mean I can, but a lot of people won’t be able to. And there is so much demand for a filter for that website just to be able to go, “I don’t want any of this, please don’t show me anything that’s generated by AI.” That hasn’t happened yet. They’ve done a lot of other stuff on it, but they’re involved with the process behind developing these systems.

It’s kind of more the problem that they’ve set themselves an impossible task. In order to use any of the systems that we’ve established so far, you need to be best friends with every AI provider on the planet, which isn’t going to happen because we’ve got nefarious third-party things that focus entirely on stuff like nudifying people or a deepfake generation entirely. This isn’t OpenAI or the big name models, but they exist and they’re usually what’s used to do this kind of underground activity. They’re not going to be on board with it. So you can’t make bold promises about resolving the problem universally when there is no solution at hand at the minute.

When you talk to the industry, when I hear from the industry, it is the drumbeat that you’ve mentioned several times. “Look, it’s going to get better. It’s going to be slow. Every standard is slow. You have to give it time.” It sounds like you don’t necessarily believe that. You think that this has already failed. Explain that. Do you think this has already failed?

Yeah, I would say this has failed. I think this has failed for what has been presented to us because what C2PA was for and what companies have been using it for are two different things to me. C2PA came about as a ... I will give Adobe its credit because Adobe’s done a lot of work from this. And the stuff it was meant to do was, if you are a creative person, this system will help you prove that you made a thing and how you made a thing. And that has benefit. I see that being used in that context every day. But then a lot of other companies got involved with that and said, “Cool, we’re going to use this as our AI safeguard basically. We’re using this system and it’ll tell you, when you post it somewhere else, whether it’s got AI involved with it, which means that we’re the good guys because we’re doing something.”

And that’s what I have a problem with. Because C2PA has never stood up and said, “We are going to fix this for you.” A lot of companies came on board and went, “Well, we’re using this and this is going to fix it for you when it works.” And that’s an impossible task. It’s just not going to happen. If we’re thinking about adopting this platform, just this platform, even in conjunction with stuff like SynthID or inference methods, it’s never going to be an ultimate solution, so I would say resting the pressure on “We have to have AI detection and labeling,” it’s failed. It’s dead in the water. It’s never going to get to a universal solution.

That doesn’t mean it’s not going to help. If they can figure out a way to effectively communicate all of this metadata and robustly keep it in check, make sure it’s not being removed at every instance of being uploaded, then yeah, there’ll be some platforms where we’ll be able to see if something was maybe generated by the eye or maybe it was a verified creator badge, something, whatever Mosseri is talking about where we’re going to have to start verifying photographers through metadata and all of this other information, but there is not going to be a point in the next three, five years where we sign on and go, “I can now tell what’s real and what’s not because of C2PA.” That’s never going to happen.

It does seem like these platforms, maybe modernity as we experience it today, have been built on, “You can trust the things that come off these phones.” You can just see it over and over and over again. Social movements rise and fall based on whether or not you can trust the things that phones generate. And if you destabilize that, you’re going to have to build all kinds of other systems. I’m not sure if C2PA is it. I’m sure we will hear from the C2PA folks. I’m sure we will hear from Adam and from Neal and the other platform owners on Decoder. Again, we’ve invited everybody on.

What do you think the next turn here is? Because the pressure is not going to relent. What’s the next thing that could happen?

From this turn of events, there’s probably going to be some kind of regulatory effort. There’s going to be some kind of legal involvement, because up until this point, there have been murmurs of how we’re going to regulate stuff, like with the Online Safety Act in the UK. Everything is now pointing toward, “Hey, AI is making a lot of deepfakes of people that we don’t like and we should probably talk about having rules in place for that.”

But up until that point, these companies have basically been enacting systems that are supposed to help us out of the goodness of their heart: “Oh, we’ve spotted that this is actually a concern and we’re going to be doing this.” But they haven’t been putting any real effort into doing so. Otherwise, again, we would have some kind of solution by now where we would see some sort of widespread results at the very least. It would involve working together, having widespread communications, and that’s supposed to be happening with the CAI, with the initiative that everyone else is currently involved with. There are no results. We are not seeing them.

Instagram made a bold effort over a year ago to stick labels on and then immediately ran back with its tail between its legs. So unless regulatory efforts actually come in clamping down on these companies and saying, “Okay, we actually now have to dictate what your models are allowed to do and what we are going to have repercussions for you if we find out what your models are doing and not supposed to be doing,” that is the next stage. We have to have this as a conjunction. I think that will be beneficial in terms of having that with labeling, with metadata tagging and stuff. But alone, there is never going to be a perfect solution to this.

Well, sadly, Jess, I always cut off Decoder episodes when they veer into explaining the regulatory process to the European Union. That’s just a hard rule on the show, but it does seem like that’s going to happen and it seems like the platforms themselves are going to have to react to how their users are behaving.

You’re going to keep covering this stuff. I find it fascinating how deep into this world you’ve gotten starting from, “Hey, we should pay more attention to these tools,” and now here we are at “Can you label reality into existence?” Jess, thank you so much for being on Decoder.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-51')">
            <div class="source">The Verge</div>
            <div class="title">Nintendo reveals an impressive Switch 2 lineup with Indiana Jones, Fallout 4, FF7 Rebirth, and more</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-51" style="display:none;">
            <h2>Nintendo reveals an impressive Switch 2 lineup with Indiana Jones, Fallout 4, FF7 Rebirth, and more</h2>
            <p><strong>The Verge | 2026-02-05</strong></p>
            <a class="original-link" href="https://www.theverge.com/games/874282/nintendo-direct-february-2026-fallout-ff7">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The latest Nintendo Direct was focused exclusively on games from third-party studios.

The latest Nintendo Direct was focused exclusively on games from third-party studios.

We just got through the Switch 2’s first holiday season, which means that Nintendo has slowly started to reveal what 2026 will look like for the console. And while we already know about a bunch of upcoming first-party titles — including the Pokémon spinoff Pokopia, Mario Tennis Fever, and Yoshi and the Mysterious Book — today the company revealed a number of major games coming from third-party studios. And there are plenty of familiar faces.

Perhaps the biggest news was that Bethesda revealed a trio of titles coming to the Switch 2 as part of Xbox’s ongoing plan to be a multiplatform publisher. Fallout 4: Anniversary Edition is launching on February 24th (perfect timing if you’re in a Fallout mood post-season 2), Indiana Jones and the Great Circle launches on May 12th, and the recent remaster of Oblivion is coming at some point in 2026.

Other big names detailed during the Direct including Final Fantasy VII Rebirth, the second game in the remake trilogy, which launches on June 3rd, and some previously-known titles from Capcom: Resident Evil Requiem launches on the Switch 2 on February 27th (Biohazard and Village will be available the same day) while sci-fi shooter Pragmata is available on April 24th. You can also check out Pragmata now with a Switch 2 demo available today in the eShop. And the original Hollow Knight is getting a Switch 2 edition that will be available later today.

Other notable titles shown off today include:

And for retro gaming fans, Super Bomberman Collection, which includes some titles never released outside of Japan, is out today, while Hamster’s Arcade Archives is expanding with the release of Rave Racer on February 26th, along with a new line called Consoles Archives that debuts with Cool Boarders and Ninja Gaiden II when it kicks off today.

It’s a hefty list, and it’s a good sign that the Switch 2, much like its predecessor, will still be home to major third-party games in addition to Nintendo’s offerings, even if many of them are arriving a little late.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-52')">
            <div class="source">The Verge</div>
            <div class="title">Can I offer you a tiny Bluetooth speaker in these trying times?</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-52" style="display:none;">
            <h2>Can I offer you a tiny Bluetooth speaker in these trying times?</h2>
            <p><strong>The Verge | 2026-02-05</strong></p>
            <a class="original-link" href="https://www.theverge.com/tech/874009/bluetooth-speaker-gadget-ikea-vappeby">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">If you buy something from a Verge link, Vox Media may earn a commission. See our ethics statement.

I knew as soon as I laid eyes on Vappeby that I had to have it. Sure, it would be right at home on my desk, given that everything in and around my workstation is from Ikea, from the Skadis on the wall right down to the Spänd desk legs. But there was something else about this nifty little Bluetooth speaker that spoke to me — the promise of a little extra coziness in dark times. Can $15.99 buy peace of mind? Not at all, but it can buy a perfectly cheery little Bluetooth speaker, and that can make a gray day feel a little brighter.

I’m not suggesting, you know, withdrawing into a shell and avoiding what’s going on outside entirely. Support your community how you can; engage with it all as best you can. But when it’s time to recharge your batteries at home, might I suggest a nice little rechargeable speaker?

It doesn’t have to be Vappeby, though I can think of a few reasons to recommend it. First, it’s cute as hell. Second, it’s only 16 bucks. It’s also IP67 water resistant, so I have no fears about using it to soundtrack a relaxing soak in the tub. The wrist strap is handy, too, so I can hang it from a hook on my Skadis pegboard when I’m not using it. Or when I am using it! That’s just how versatile Vappeby is.

Sound quality? Uh, it’s fine. I use the built-in speakers on my seven-year-old Samsung TV. I’m not exactly an audiophile. It sounds perfectly decent sitting on my desk a foot away from my face, and easily fills a small-ish room with sound. And that’s what I need from it: I need an envelope of lo-fi beats while I type my little blogs. I need hygge. I need background sound to drown out the ringing in my ears that seems to get louder by the day. I need to create the illusion that what’s inside my house is within my control, just for a little while.

I’d even go so far as to say that Vappeby — and any other nice little speaker of its ilk — is the perfect gadget. It’s reasonably durable and highly portable. It contributes much and asks for hardly any space on my desk in return. It charges over USB-C, so I don’t have to track down a Micro USB cable, thank Christ. All for 16 bucks! I’ve spent a lot more on gadgets that I’ve enjoyed less.

Anyway, consider this your permission to indulge in a nice little gadget. Maybe it’s a Vappeby, maybe it’s a JBL, maybe it’s, I dunno, that immersion blender you’ve been wanting for years. Creature comforts alone aren’t self-care, but when wielded properly they can help us help ourselves. Now, especially, is the time to lean into the things that spark joy and help us come back to ourselves. The best things in life are free, but at least 16 bucks can get you something halfway decent.

Photography by Allison Johnson / The Verge

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-53')">
            <div class="source">The Verge</div>
            <div class="title">Senators ask Meta why it waited so long to make teen accounts private by default</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-53" style="display:none;">
            <h2>Senators ask Meta why it waited so long to make teen accounts private by default</h2>
            <p><strong>The Verge | 2026-02-05</strong></p>
            <a class="original-link" href="https://www.theverge.com/news/874158/senators-meta-teen-accounts-private-default">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The lawmakers raise concerns about allegations that Meta knew its platforms harmed users.

The lawmakers raise concerns about allegations that Meta knew its platforms harmed users.

A group of senators has written a letter to Meta CEO Mark Zuckerberg asking why his company delayed launching key protections for users under 18. The letter, signed by Brian Schatz (D-HI), Katie Britt (R-AL), Amy Klobuchar (D-MN), James Lankford (R-OK), and Christopher Coons (D-DE), cites court documents unsealed late last year that revealed claims that Meta may have downplayed its platforms’ harm in favor of increasing user engagement.

Meta started automatically putting teens on Instagram into private and more restrictive accounts in September 2024, before extending the protections to Facebook and Messenger last year. But an unredacted court document filed as part of a nationwide social media child safety lawsuit alleges that Meta considered making all teen accounts private in 2019, but reportedly decided against the plan after finding it would “likely smash engagement.”

In the letter, the senators press Zuckerberg for more information about why Meta “delayed” launching its private-by-default feature for teens, as well as which teams were involved in the decision. The letter also questions Meta about some of the other accusations laid out in the court document, including whether Meta ever “halted” research or studies into its user well-being and its platforms if they produced undesirable outcomes, as suggested in the filing.

“We are deeply concerned by allegations that Meta was not only aware of these risks, but may have delayed product design changes or prevented public disclosure of these findings,” the letter states.

The senators also want more information about Meta’s policies for taking down child sexual abuse material (CSAM) and content about sex trafficking after the unredacted court document revealed testimony from the company’s former head of safety and well-being, who claimed Meta would only suspend someone’s account after they incurred 17 violations “for prostitution and solicitation.” The senators are giving Meta until March 6th to respond to their questions.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-54')">
            <div class="source">MIT Technology Review</div>
            <div class="title">The Download: attempting to track AI, and the next generation of nuclear power</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-54" style="display:none;">
            <h2>The Download: attempting to track AI, and the next generation of nuclear power</h2>
            <p><strong>MIT Technology Review | 2026-02-05</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2026/02/05/1132270/the-download-attempting-to-track-ai-and-the-next-generation-of-nuclear-power/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">This is today&#39;s edition of The Download, our weekday newsletter that provides a daily dose of what&#39;s going on in the world of technology.

This is the most misunderstood graph in AI

Every time OpenAI, Google, or Anthropic drops a new frontier large language model, the AI community holds its breath. It doesn’t exhale until METR, an AI research nonprofit whose name stands for “Model Evaluation & Threat Research,” updates a now-iconic graph that has played a major role in the AI discourse since it was first released in March of last year.

The graph suggests that certain AI capabilities are developing at an exponential rate, and more recent model releases have outperformed that already impressive trend.That was certainly the case for Claude Opus 4.5, the latest version of Anthropic’s most powerful model, which was released in late November. In December, METR announced that Opus 4.5 appeared to be capable of independently completing a task that would have taken a human about five hours—a vast improvement over what even the exponential trend would have predicted.

But the truth is more complicated than those dramatic responses would suggest. Read the full story.

This story is part of MIT Technology Review Explains: our series untangling the complex, messy world of technology to help you understand what’s coming next. You can read more from the series here.

Three questions about next-generation nuclear power, answered

Nuclear power continues to be one of the hottest topics in energy today, and in our recent online Roundtables discussion about next-generation nuclear power, hyperscale AI data centers, and the grid, we got dozens of great audience questions.

These ran the gamut, and while we answered quite a few (and I’m keeping some in mind for future reporting), there were a bunch we couldn’t get to, at least not in the depth I would have liked. So let’s answer a few of your questions about advanced nuclear power.

This article is from The Spark, MIT Technology Review’s weekly climate newsletter. To receive it in your inbox every Wednesday, sign up here.

I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.

1 Anthropic’s new coding tools are rattling the markets Fields as diverse as publishing and coding to law and advertising are paying attention. (FT $)+ Legacy software companies, beware. (Insider $)+ Is “software-mageddon” nigh? It depends who you ask. (Reuters)2 This Apple setting prevented the FBI from accessing a reporter’s iPhoneLockdown Mode has proved remarkably effective—for now. (404 Media)+ Agents were able to access Hannah Natanson’s laptop, however. (Ars Technica)3 Last month’s data center outage disrupted all TikTok categoriesNot just the political content that some users claimed. (NPR)4 Big Tech is pouring billions into AI in IndiaA newly-announced 20-year tax break should help to speed things along. (WSJ $)+ India’s female content moderators are watching hours of abuse content to train AI. (The Guardian)+ Officials in the country are weighing up restricting social media for minors. (Bloomberg $)+ Inside India’s scramble for AI independence. (MIT Technology Review)

5 YouTubers are harassing women using body camsThey’re abusing freedom of information laws to humiliate their targets. (NY Mag $)+ AI was supposed to make police bodycams better. What happened? (MIT Technology Review)

6 Jokers have created a working version of Jeffrey Epstein’s inboxComplete with notable starred threads. (Wired $)+ Epstein’s links with Silicon Valley are vast and deep. (Fast Company $)+ The revelations are driving rifts between previously-friendly factions. (NBC News)

7 What’s the last thing you see before you die?A new model might help to explain near-death experiences—but not all researchers are on board. (WP $)+ What is death? (MIT Technology Review)

8 A new app is essentially TikTok for vibe-coded appsWords which would have made no sense 15 years ago. (TechCrunch)+ What is vibe coding, exactly? (MIT Technology Review)9 Rogue TV boxes are all the rageViewers are sick of the soaring prices of streaming services, and are embracing less legal means of watching their favorite shows. (The Verge)

10 Climate change is threatening the future of the Winter Olympics ⛷️Artificial snow is one (short term) solution. (Bloomberg $)+ Team USA is using AI to try and gain an edge on its competition. (NBC News)

&quot;We’ve heard from many who want nothing to do with AI.”

—Ajit Varma, head of Mozilla’s web browser Firefox, explains why the company is reversing its previous decision to transform Firefox into an “AI browser,” PC Gamer reports.

A major AI training data set contains millions of examples of personal dataMillions of images of passports, credit cards, birth certificates, and other documents containing personally identifiable information are likely included in one of the biggest open-source AI training sets, new research has found.Thousands of images—including identifiable faces—were found in a small subset of DataComp CommonPool, a major AI training set for image generation scraped from the web. Because the researchers audited just 0.1% of CommonPool’s data, they estimate that the real number of images containing personally identifiable information, including faces and identity documents, is in the hundreds of millions. The bottom line? Anything you put online can be and probably has been scraped. Read the full story.—Eileen Guo

A place for comfort, fun and distraction to brighten up your day. (Got any ideas? Drop me a line or skeet &#39;em at me.)

+ If you’re crazy enough to be training for a marathon right now, here’s how to beat boredom on those long, long runs.+ Mark Cohen’s intimate street photography is a fascinating window into humanity.+ A seriously dedicated gamer has spent days painstakingly recreating a Fallout vault inside the Sims 4.+ Here’s what music’s most stylish men are wearing right now—from leather pants to khaki parkas.

Plus: TikTok has finally signed a deal to keep operating in the US

Plus: This company is developing gene therapies for muscle growth, erectile dysfunction, and “radical longevity”

Plus: China has built a major chip-making machine

Plus: read our predictions for the five hottest AI trends to watch

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-55')">
            <div class="source">MIT Technology Review</div>
            <div class="title">Three questions about next-generation nuclear power, answered</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-55" style="display:none;">
            <h2>Three questions about next-generation nuclear power, answered</h2>
            <p><strong>MIT Technology Review | 2026-02-05</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2026/02/05/1132197/nuclear-questions/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Nuclear power continues to be one of the hottest topics in energy today, and in our recent online Roundtables discussion about next-generation nuclear power, hyperscale AI data centers, and the grid, we got dozens of great audience questions.

These ran the gamut, and while we answered quite a few (and I’m keeping some in mind for future reporting), there were a bunch we couldn’t get to, at least not in the depth I would have liked.

So let’s answer a few of your questions about advanced nuclear power. I’ve combined similar ones and edited them for clarity.

Many next-generation reactors don’t use the low-enriched uranium used in conventional reactors.

It’s worth looking at high-assay low-enriched uranium, or HALEU, specifically. This fuel is enriched to higher concentrations of fissile uranium than conventional nuclear fuel, with a proportion of the isotope U-235 that falls between 5% and 20%. (In conventional fuel, it’s below 5%.)

HALEU can be produced with the same technology as low-enriched uranium, but the geopolitics are complicated. Today, Russia basically has a monopoly on HALEU production. In 2024, the US banned the import of Russian nuclear fuel through 2040 in an effort to reduce dependence on the country. Europe hasn’t taken the same measures, but it is working to move away from Russian energy as well.

That leaves companies in the US and Europe with the major challenge of securing the fuel they need when their regular Russian supply has been cut off or restricted.

The US Department of Energy has a stockpile of HALEU, which the government is doling out to companies to help power demonstration reactions. In the longer term, though, there’s still a major need to set up independent HALEU supply chains to support next-generation reactors.

There are some ways that next-generation nuclear power plants could be safer than conventional reactors. Some use alternative coolants that would prevent the need to run at the high pressure required in conventional water-cooled reactors. Many incorporate passive safety shutoffs, so if there are power supply issues, the reactors shut down harmlessly, avoiding risk of meltdown. (These can be incorporated in newer conventional reactors, too.)

But some experts have raised concerns that in the US, the current administration isn’t taking nuclear safety seriously enough.

A recent NPR investigation found that the Trump administration had secretly rewritten nuclear rules, stripping environmental protections and loosening safety and security measures. The government shared the new rules with companies that are part of a program building experimental nuclear reactors, but not with the public.

I’m reminded of a talk during our EmTech MIT event in November, where Koroush Shirvan, an MIT professor of nuclear engineering, spoke on this issue. “I’ve seen some disturbing trends in recent times, where words like ‘rubber-stamping nuclear projects’ are being said,” Shirvan said during that event.

During the talk, Shirvan shared statistics showing that nuclear power has a very low rate of injury and death. But that’s not inherent to the technology, and there’s a reason injuries and deaths have been low for nuclear power, he added: “It’s because of stringent regulatory oversight.”

Building a nuclear power plant is not cheap. Let’s consider the up-front investment needed to build a power plant.

Plant Vogtle in Georgia hosts the most recent additions to the US nuclear fleet—Units 3 and 4 came online in 2023 and 2024. Together, they had a capital cost of $15,000 per kilowatt, adjusted for inflation, according to a recent report from the US Department of Energy. (This wonky unit I’m using divides the total cost to build the reactors by their expected power output, so we can compare reactors of different sizes.)

That number’s quite high, partly because those were the first of their kind built in the US, and because there were some inefficiencies in the planning. It’s worth noting that China builds reactors for much less, somewhere between $2,000/kW and $3,000/kW, depending on the estimate.

The up-front capital cost for first-of-a-kind advanced nuclear plants will likely run between $6,000 and $10,000 per kilowatt, according to that DOE report. That could come down by up to 40% after the technologies are scaled up and mass-produced.

So new reactors will (hopefully) be cheaper than the ultra-over-budget and behind-schedule Vogtle project, but they aren’t necessarily significantly cheaper than efficiently built conventional plants, if you normalize by their size.

It’ll certainly be cheaper to build new natural-gas plants (setting aside the likely equipment shortages we’re likely going to see for years.) Today’s most efficient natural-gas plants cost just $1,600/kW on the high end, according to data from Lazard.

An important caveat: Capital cost isn’t everything—running a nuclear plant is relatively inexpensive, which is why there’s so much interest in extending the lifetime of existing plants or reopening shuttered ones.

Ultimately, by many metrics, nuclear plants of any type are going to be more expensive than other sources, like wind and solar power. But they provide something many other power sources don’t: a reliable, stable source of electricity that can run for 60 years or more.

This article is from The Spark, MIT Technology Review’s weekly climate newsletter. To receive it in your inbox every Wednesday, sign up here.

As early electric cars age out, hundreds of thousands of used batteries are flooding the market, fueling a gray recycling economy even as Beijing and big manufacturers scramble to build a more orderly system.

A cheaper, safer, and more abundant alternative to lithium is finally making its way into cars—and the grid.

Omar Yaghi thinks crystals with gaps that capture moisture could bring technology from “Dune” to the arid parts of Earth.

And why many scientists are freaked out about the first serious for-profit company moving into the solar geoengineering field.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-56')">
            <div class="source">MIT Technology Review</div>
            <div class="title">This is the most misunderstood graph in AI</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-56" style="display:none;">
            <h2>This is the most misunderstood graph in AI</h2>
            <p><strong>MIT Technology Review | 2026-02-05</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2026/02/05/1132254/this-is-the-most-misunderstood-graph-in-ai/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">MIT Technology Review Explains: Let our writers untangle the complex, messy world of technology to help you understand what’s coming next. You can read more from the series here.

Every time OpenAI, Google, or Anthropic drops a new frontier large language model, the AI community holds its breath. It doesn’t exhale until METR, an AI research nonprofit whose name stands for “Model Evaluation & Threat Research,” updates a now-iconic graph that has played a major role in the AI discourse since it was first released in March of last year. The graph suggests that certain AI capabilities are developing at an exponential rate, and more recent model releases have outperformed that already impressive trend.

That was certainly the case for Claude Opus 4.5, the latest version of Anthropic’s most powerful model, which was released in late November. In December, METR announced that Opus 4.5 appeared to be capable of independently completing a task that would have taken a human about five hours—a vast improvement over what even the exponential trend would have predicted. One Anthropic safety researcher tweeted that he would change the direction of his research in light of those results; another employee at the company simply wrote, “mom come pick me up i’m scared.”

But the truth is more complicated than those dramatic responses would suggest. For one thing, METR’s estimates of the abilities of specific models come with substantial error bars. As METR explicitly stated on X, Opus 4.5 might be able to regularly complete only tasks that take humans about two hours, or it might succeed on tasks that take humans as long as 20 hours. Given the uncertainties intrinsic to the method, it was impossible to know for sure.

“There are a bunch of ways that people are reading too much into the graph,” says Sydney Von Arx, a member of METR’s technical staff.

More fundamentally, the METR plot does not measure AI abilities writ large, nor does it claim to. In order to build the graph, METR tests the models primarily on coding tasks, evaluating the difficulty of each by measuring or estimating how long it takes humans to complete it—a metric that not everyone accepts. Claude Opus 4.5 might be able to complete certain tasks that take humans five hours, but that doesn’t mean it’s anywhere close to replacing a human worker.

METR was founded to assess the risks posed by frontier AI systems. Though it is best known for the exponential trend plot, it has also worked with AI companies to evaluate their systems in greater detail and published several other independent research projects, including a widely covered July 2025 study suggesting that AI coding assistants might actually be slowing software engineers down.

But the exponential plot has made METR’s reputation, and the organization appears to have a complicated relationship with that graph’s often breathless reception. In January, Thomas Kwa, one of the lead authors on the paper that introduced it, wrote a blog post responding to some criticisms and making clear its limitations, and METR is currently working on a more extensive FAQ document. But Kwa isn’t optimistic that these efforts will meaningfully shift the discourse. “I think the hype machine will basically, whatever we do, just strip out all the caveats,” he says.

Nevertheless, the METR team does think that the plot has something meaningful to say about the trajectory of AI progress. “You should absolutely not tie your life to this graph,” says Von Arx. “But also,” she adds, “I bet that this trend is gonna hold.”

Part of the trouble with the METR plot is that it’s quite a bit more complicated than it looks. The x-axis is simple enough: It tracks the date when each model was released. But the y-axis is where things get tricky. It records each model’s “time horizon,” an unusual metric that METR created—and that, according to Kwa and Von Arx, is frequently misunderstood.

To understand exactly what model time horizons are, it helps to know all the work that METR put into calculating them. First, the METR team assembled a collection of tasks ranging from quick multiple-choice questions to detailed coding challenges—all of which were somehow relevant to software engineering. Then they had human coders attempt most of those tasks and evaluated how long it took them to finish. In this way, they assigned the tasks a human baseline time. Some tasks took the experts mere seconds, whereas others required several hours.

When METR tested large language models on the task suite, they found that advanced models could complete the fast tasks with ease—but as the models attempted tasks that had taken humans more and more time to finish, their accuracy started to fall off. From a model’s performance, the researchers calculated the point on the time scale of human tasks at which the model would complete about 50% of the tasks successfully. That point is the model’s time horizon.

All that detail is in the blog post and the academic paper that METR released along with the original time horizon plot. But the METR plot is frequently passed around on social media without this context, and so the true meaning of the time horizon metric can get lost in the shuffle. One common misapprehension is that the numbers on the plot’s y-axis—around five hours for Claude Opus 4.5, for example—represent the length of time that the models can operate independently. They do not. They represent how long it takes humans to complete tasks that a model can successfully perform.  Kwa has seen this error so frequently that he made a point of correcting it at the very top of his recent blog post, and when asked what information he would add to the versions of the plot circulating online, he said he would include the word “human” whenever the task completion time was mentioned.

As complex and widely misinterpreted as the time horizon concept might be, it does make some basic sense: A model with a one-hour time horizon could automate some modest portions of a software engineer’s job, whereas a model with a 40-hour horizon could potentially complete days of work on its own. But some experts question whether the amount of time that humans take on tasks is an effective metric for quantifying AI capabilities. “I don’t think it’s necessarily a given fact that because something takes longer, it’s going to be a harder task,” says Inioluwa Deborah Raji, a PhD student at UC Berkeley who studies model evaluation.

Von Arx says that she, too, was originally skeptical that time horizon was the right measure to use. What convinced her was seeing the results of her and her colleagues’ analysis. When they calculated the 50% time horizon for all the major models available in early 2025 and then plotted each of them on the graph, they saw that the time horizons for the top-tier models were increasing over time—and, moreover, that the rate of advancement was speeding up. Every seven-ish months, the time horizon doubled, which means that the most advanced models could complete tasks that took humans nine seconds in mid 2020, 4 minutes in early 2023, and 40 minutes in late 2024. “I can do all the theorizing I want about whether or not it makes sense, but the trend is there,” Von Arx says.

It’s this dramatic pattern that made the METR plot such a blockbuster. Many people learned about it when they read AI 2027, a viral sci-fi story cum quantitative forecast positing that superintelligent AI could wipe out humanity by 2030. The writers of AI 2027 based some of their predictions on the METR plot and cited it extensively. In Von Arx’s words, “It’s a little weird when the way lots of people are familiar with your work is this pretty opinionated interpretation.”

Of course, plenty of people invoke the METR plot without imagining large-scale death and destruction. For some AI boosters, the exponential trend indicates that AI will soon usher in an era of radical economic growth. The venture capital firm Sequoia Capital, for example, recently put out a post titled “2026: This is AGI,” which used the METR plot to argue that AI that can act as an employee or contractor will soon arrive. “The provocation really was like, ‘What will you do when your plans are measured in centuries?’” says Sonya Huang, a general partner at Sequoia and one of the post’s authors.

Just because a model achieves a one-hour time horizon on the METR plot, however, doesn’t mean that it can replace one hour of human work in the real world. For one thing, the tasks on which the models are evaluated don’t reflect the complexities and confusion of real-world work. In their original study, Kwa, Von Arx, and their colleagues quantify what they call the “messiness” of each task according to criteria such as whether the model knows exactly how it is being scored and whether it can easily start over if it makes a mistake (for messy tasks, the answer to both questions would be no). They found that models do noticeably worse on messy tasks, although the overall pattern of improvement holds for both messy and non-messy ones.

And even the messiest tasks that METR considered can’t provide much information about AI’s ability to take on most jobs, because the plot is based almost entirely on coding tasks. “A model can get better at coding, but it’s not going to magically get better at anything else,” says Daniel Kang, an assistant professor of computer science at the University of Illinois Urbana-Champaign. In a follow-up study, Kwa and his colleagues did find that time horizons for tasks in other domains also appear to be on exponential trajectories, but that work was much less formal.

Despite these limitations, many people admire the group’s research. “The METR study is one of the most carefully designed studies in the literature for this kind of work,” Kang told me. Even Gary Marcus, a former NYU professor and professional LLM curmudgeon, described much of the work that went into the plot as “terrific” in a blog post.

Some people will almost certainly continue to read the METR plot as a prognostication of our AI-induced doom, but in reality it’s something far more banal: a carefully constructed scientific tool that puts concrete numbers to people’s intuitive sense of AI progress. As METR employees will readily agree, the plot is far from a perfect instrument. But in a new and fast-moving domain, even imperfect tools can have enormous value.

“This is a bunch of people trying their best to make a metric under a lot of constraints. It is deeply flawed in many ways,” Von Arx says. “I also think that it is one of the best things of its kind.”

Four ways to think about this year&#39;s reckoning.

By studying large language models as if they were living things instead of computer programs, scientists are discovering some of their secrets for the first time.

In an exclusive interview, the AI pioneer shares his plans for his new Paris-based company, AMI Labs.

Our AI writers make their big bets for the coming year—here are five hot trends to watch.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-57')">
            <div class="source">MIT Technology Review</div>
            <div class="title">From guardrails to governance: A CEO’s guide for securing agentic systems</div>
            <div class="meta">2026-02-04</div>
        </div>
        
        <div id="content-57" style="display:none;">
            <h2>From guardrails to governance: A CEO’s guide for securing agentic systems</h2>
            <p><strong>MIT Technology Review | 2026-02-04</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2026/02/04/1131014/from-guardrails-to-governance-a-ceos-guide-for-securing-agentic-systems/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The previous article in this series, “Rules fail at the prompt, succeed at the boundary,” focused on the first AI-orchestrated espionage campaign and the failure of prompt-level control. This article is the prescription. The question every CEO is now getting from their board is some version of: What do we do about agent risk?

Across recent AI security guidance from standards bodies, regulators, and major providers, a simple idea keeps repeating: treat agents like powerful, semi-autonomous users, and enforce rules at the boundaries where they touch identity, tools, data, and outputs.

The following is an actionable eight-step plan one can ask teams to implement and report against:

These steps help define identity and limit capabilities.

Today, agents run under vague, over-privileged service identities. The fix is straightforward: treat each agent as a non-human principal with the same discipline applied to employees.Every agent should run as the requesting user in the correct tenant, with permissions constrained to that user’s role and geography. Prohibit cross-tenant on-behalf-of shortcuts. Anything high-impact should require explicit human approval with a recorded rationale. That is how Google’s Secure AI Framework (SAIF) and NIST AI’s access-control guidance are meant to be applied in practice.

The CEO question: Can we show, today, a list of our agents and exactly what each is allowed to do?2. Tooling control: Pin, approve, and bound what agents can use

The Anthropic espionage framework worked because the attackers could wire Claude into a flexible suite of tools (e.g., scanners, exploit frameworks, data parsers) through Model Context Protocol, and those tools weren’t pinned or policy-gated.

The defense is to treat toolchains like a supply chain:

This is exactly what OWASP flags under excessive agency and what it recommends protecting against. Under the EU AI Act, designing for such cyber-resilience and misuse resistance is part of the Article 15 obligation to ensure robustness and cybersecurity.

The CEO question: Who signs off when an agent gains a new tool or a broader scope? How does one know?

A common anti-pattern is to give the model a long-lived credential and hope prompts keep it polite. SAIF and NIST argue the opposite: credentials and scopes should be bound to tools and tasks, rotated regularly, and auditable. Agents then request narrowly scoped capabilities through those tools.

In practice, that looks like: “finance-ops-agent may read, but not write, certain ledgers without CFO approval.”

The CEO question: Can we revoke a specific capability from an agent without re-architecting the whole system?

These steps gate inputs, outputs, and constrain behavior.

Most agent incidents start with sneaky data: a poisoned web page, PDF, email, or repository that smuggles adversarial instructions into the system. OWASP’s prompt-injection cheat sheet and OpenAI’s own guidance both insist on strict separation of system instructions from user content and on treating unvetted retrieval sources as untrusted.

Operationally, gate before anything enters retrieval or long-term memory: new sources are reviewed, tagged, and onboarded; persistent memory is disabled when untrusted context is present; provenance is attached to each chunk.

The CEO question: Can we enumerate every external content source our agents learn from, and who approved them?

In the Anthropic case, AI-generated exploit code and credential dumps flowed straight into action. Any output that can cause a side effect needs a validator between the agent and the real world. OWASP’s insecure output handling category is explicit on this point, as are browser security best practices around origin boundaries.

The CEO question: Where, in our architecture, are agent outputs assessed before they run or ship to customers?

Protect the data such that there is nothing dangerous to reveal by default. NIST and SAIF both lean toward “secure-by-default” designs where sensitive values are tokenized or masked and only re-hydrated for authorized users and use cases.

In agentic systems, that means policy-controlled detokenization at the output boundary and logging every reveal. If an agent is fully compromised, the blast radius is bounded by what the policy lets it see.

This is where the AI stack intersects not just with the EU AI Act but with GDPR and sector-specific regimes. The EU AI Act expects providers and deployers to manage AI-specific risk; runtime tokenization and policy-gated reveal are strong evidence that one is actively controlling those risks in production.

The CEO question: When our agents touch regulated data, is that protection enforced by architecture or by promises?

For the final steps, it’s important to show controls work and keep working.

Anthropic’s research about sleeper agents should eliminate all fantasies about single test dreams and show how critical continuous evaluation is. This means instrumenting agents with deep observability, regularly red teaming with adversarial test suites, and backing everything with robust logging and evidence, so failures become both regression tests and enforceable policy updates.

The CEO question: Who works to break our agents every week, and how do their findings change policy?

AI security frameworks emphasize inventory and evidence: enterprises must know which models, prompts, tools, datasets, and vector stores they have, who owns them, and what decisions were taken about risk.

For agents, that means a living catalog and unified logs:

The CEO question: If asked how an agent made a specific decision, could we reconstruct the chain?

And don’t forget the system-level threat model: assume the threat actor GTG-1002 is already in your enterprise. To complete enterprise preparedness, zoom out and consider the MITRE ATLAS product, which exists precisely because adversaries attack systems, not models. Anthropic provides a case study of a state-based threat actor (GTG-1002) doing exactly that with an agentic framework.

Taken together, these controls do not make agents magically safe. They do something more familiar and more reliable: they put AI, its access, and actions back inside the same security frame used for any powerful user or system.

For boards and CEOs, the question is no longer “Do we have good AI guardrails?” It’s: Can we answer the CEO questions above with evidence, not assurances?

This content was produced by Protegrity. It was not written by MIT Technology Review’s editorial staff.

Four ways to think about this year&#39;s reckoning.

By studying large language models as if they were living things instead of computer programs, scientists are discovering some of their secrets for the first time.

In an exclusive interview, the AI pioneer shares his plans for his new Paris-based company, AMI Labs.

Our AI writers make their big bets for the coming year—here are five hot trends to watch.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-58')">
            <div class="source">MIT Technology Review</div>
            <div class="title">The Download: the future of nuclear power plants, and social media-fueled AI hype</div>
            <div class="meta">2026-02-04</div>
        </div>
        
        <div id="content-58" style="display:none;">
            <h2>The Download: the future of nuclear power plants, and social media-fueled AI hype</h2>
            <p><strong>MIT Technology Review | 2026-02-04</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2026/02/04/1132115/the-download-the-future-of-nuclear-power-plants-and-social-media-fueled-ai-hype/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">This is today&#39;s edition of The Download, our weekday newsletter that provides a daily dose of what&#39;s going on in the world of technology.

Why AI companies are betting on next-gen nuclear

AI is driving unprecedented investment for massive data centers and an energy supply that can support its huge computational appetite. One potential source of electricity for these facilities is next-generation nuclear power plants, which could be cheaper to construct and safer to operate than their predecessors.We recently held a subscriber-exclusive Roundtables discussion on hyperscale AI data centers and next-gen nuclear—two featured technologies on the MIT Technology Review 10 Breakthrough Technologies of 2026 list. You can watch the conversation back here, and don’t forget to subscribe to make sure you catch future discussions as they happen.

How social media encourages the worst of AI boosterism

Demis Hassabis, CEO of Google DeepMind, summed it up in three words: “This is embarrassing.”Hassabis was replying on X to an overexcited post by Sébastien Bubeck, a research scientist at the rival firm OpenAI, announcing that two mathematicians had used OpenAI’s latest large language model, GPT-5, to find solutions to 10 unsolved problems in mathematics.Put your math hats on for a minute, and let’s take a look at what this beef from mid-October was about. It’s a perfect example of what’s wrong with AI right now.—Will Douglas Heaven

This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first, sign up here.

The paints, coatings, and chemicals making the world a cooler place

It’s getting harder to beat the heat. During the summer of 2025, heat waves knocked out power grids in North America, Europe, and the Middle East. Global warming means more people need air-­conditioning, which requires more power and strains grids.But a millennia-old idea (plus 21st-century tech) might offer an answer: radiative cooling. Paints, coatings, and textiles can scatter sunlight and dissipate heat—no additional energy required. Read the full story.

This story is from the most recent print issue of MIT Technology Review magazine, which shines a light on the exciting innovations happening right now. If you haven’t already, subscribe now to receive future issues once they land.

MIT Technology Review Narrated: China figured out how to sell EVs. Now it has to deal with their aging batteries.

As early electric cars age out, hundreds of thousands of used batteries are flooding the market, fueling a gray recycling economy even as Beijing and big manufacturers scramble to build a more orderly system.

This is our latest story to be turned into a MIT Technology Review Narrated podcast, which we’re publishing each week on Spotify and Apple Podcasts. Just navigate to MIT Technology Review Narrated on either platform, and follow us to get all our new content as it’s released.

I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.

1 Europe is edging closer towards banning social media for minorsSpain has become the latest country to consider it. (Bloomberg $)+ Elon Musk called the Spanish prime minister a “tyrant” in retaliation. (The Guardian)+ Other European nations considering restrictions include Greece, France and the UK. (Reuters)

2 Humans are infiltrating the social network for AI agentsIt turns out role-playing as a bot is surprisingly fun. (Wired $)+ Some of the most viral posts may actually be human-generated after all. (The Verge)

3 Russian spy spacecraft have intercepted Europe’s key satellitesSecurity officials are confident Moscow has tapped into unencrypted European comms. (FT $)4 French authorities raided X’s Paris officeThey’re investigating a range of potential charges against the company. (WSJ $)+ Elon Musk has been summoned to give evidence in April. (Reuters)5 Jeffrey Epstein invested millions into crypto startup CoinbaseWhich suggests he was still able to take advantage of Silicon Valley investment opportunities years after pleading guilty to soliciting sex from an underage girl. (WP $)

6 A group of crypto bros paid $300,000 for a gold statue of TrumpIt’s destined to be installed on his Florida golf complex, apparently. (NYT $)

7 OpenAI has appointed a “head of preparedness”Dylan Scandinaro will earn a cool $555,000 for his troubles. (Bloomberg $)

8 The eternal promise of 3D-printed batteriesTraditional batteries are blocky and bulky. Printing them ourselves could help solve that. (IEEE Spectrum)

9 What snow can teach us about city designWhen icy mounds refuse to melt, they show us what a less car-focused city could look like. (New Yorker $)+ This startup thinks slime mold can help us design better cities. (MIT Technology Review)

10 Please don’t use AI to talk to your friendsThat’s what your brain is for. (The Atlantic $)+ Therapists are secretly using ChatGPT. Clients are triggered. (MIT Technology Review)

“Today, our children are exposed to a space they were never meant to navigate alone. We will no longer accept that.”

—Spanish prime minister Pedro Sánchez proposes a social media ban for children aged under 16 in the country, following in Australia’s footsteps, AP News reports.

A brain implant changed her life. Then it was removed against her will.Sticking an electrode inside a person’s brain can do more than treat a disease. Take the case of Rita Leggett, an Australian woman whose experimental brain implant designed to help people with epilepsy changed her sense of agency and self.Leggett told researchers that she “became one” with her device. It helped her to control the unpredictable, violent seizures she routinely experienced, and allowed her to take charge of her own life. So she was devastated when, two years later, she was told she had to remove the implant because the company that made it had gone bust.The removal of this implant, and others like it, might represent a breach of human rights, ethicists say in a paper published earlier this month. And the issue will only become more pressing as the brain implant market grows in the coming years and more people receive devices like Leggett’s. Read the full story.

A place for comfort, fun and distraction to brighten up your day. (Got any ideas? Drop me a line or skeet &#39;em at me.)

+ Why Beethoven’s Ode to Joy is still such an undisputed banger.+ Did you know that one of the world’s most famous prisons actually served as a zoo and menagerie for over 600 years?+ Banana nut muffins sound like a fantastic way to start your day.+ 2026 is shaping up to be a blockbuster year for horror films.

Plus: TikTok has finally signed a deal to keep operating in the US

Plus: This company is developing gene therapies for muscle growth, erectile dysfunction, and “radical longevity”

Plus: China has built a major chip-making machine

Plus: read our predictions for the five hottest AI trends to watch

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-59')">
            <div class="source">MIT Technology Review</div>
            <div class="title">The Download: squeezing more metal out of aging mines, and AI’s truth crisis</div>
            <div class="meta">2026-02-03</div>
        </div>
        
        <div id="content-59" style="display:none;">
            <h2>The Download: squeezing more metal out of aging mines, and AI’s truth crisis</h2>
            <p><strong>MIT Technology Review | 2026-02-03</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2026/02/03/1132105/the-download-squeezing-more-metal-out-of-aging-mines-and-ais-truth-crisis/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">This is today&#39;s edition of The Download, our weekday newsletter that provides a daily dose of what&#39;s going on in the world of technology.

Microbes could extract the metal needed for cleantech

In a pine forest on Michigan’s Upper Peninsula, the only active nickel mine in the US is nearing the end of its life. At a time when carmakers want the metal for electric-vehicle batteries, nickel concentration at Eagle Mine is falling and could soon drop too low to warrant digging.Demand for nickel, copper, and rare earth elements is rapidly increasing amid the explosive growth of metal-intensive data centers, electric cars, and renewable energy projects. But producing these metals is becoming harder and more expensive because miners have already exploited the best resources. Here’s how biotechnology could help.—Matt Blois

What we’ve been getting wrong about AI’s truth crisis

—James O&#39;DonnellWhat would it take to convince you that the era of truth decay we were long warned about—where AI content dupes us, shapes our beliefs even when we catch the lie, and erodes societal trust in the process—is now here?A story I published last week pushed me over the edge. And it also made me realize that the tools we were sold as a cure for this crisis are failing miserably. Read the full story.This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first, sign up here.

In sprawling stretches of farmland and industrial parks, supersized buildings packed with racks of computers are springing up to fuel the AI race.These engineering marvels are a new species of infrastructure: supercomputers designed to train and run large language models at mind-­bending scale, complete with their own specialized chips, cooling systems, and even energy supplies. But all that impressive computing power comes at a cost.

Read why we’ve named hyperscale AI data centers as of our 10 Breakthrough Technologies this year, and check out the rest of the list.

I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.

1 Elon Musk’s SpaceX has acquired xAIThe deal values the combined companies at a cool $1.25 trillion. (WSJ $)+ It also paves the way for SpaceX to offer an IPO later this year. (WP $)+ Meanwhile, OpenAI has accused xAI of destroying legal evidence. (Bloomberg $)

2 NASA has delayed the launch of Artemis IIIt’s been pushed back to March due to the discovery of a hydrogen leak. (Ars Technica)+ The rocket’s predecessor was also plagued by fuel leaks. (Scientific American)

3 Russia is hiring a guerilla youth army onlineThey’re committing arson and spying on targets across Europe. (New Yorker $)4 Grok is still generating undressed images of menWeeks after the backlash over it doing the same to women. (The Verge)+ How Grok descended into becoming a porn generator. (WP $)+ Inside the marketplace powering bespoke AI deepfakes of real women. (MIT Technology Review)5 OpenAI is searching for alternatives to Nvidia’s chipsIt’s reported to be unhappy about the speed at which it powers ChatGPT. (Reuters)

6 The latest attempt to study a notoriously unstable glacier has failedScientists lost their equipment within Antarctica&#39;s Thwaites Glacier over the weekend. (NYT $)+ Inside a new quest to save the “doomsday glacier” (MIT Technology Review)

7 The world is trying to wean itself off American technologyGovernments are growing increasingly uneasy about their reliance on the US. (Rest of World)

8 AI’s sloppy writing is driving demand for real human writersLong may it continue. (Insider $)

9 This female-dominated fitness community hates Mark ZuckerbergHis decision to shut down three VR studios means their days of playing their favorite workout game are numbered. (The Verge)+ Welcome to the AI gym staffed by virtual trainers. (MIT Technology Review)10 This cemetery has an eco-friendly solution for its overcrowding problemIf you’re okay with your loved one becoming gardening soil, that is. (WSJ $)+ Why America is embracing the right to die now. (Economist $)+ What happens when you donate your body to science. (MIT Technology Review)

“In the long term, space-based AI is obviously the only way to scale…I mean, space is called ‘space’ for a reason.”

—Elon Musk explains his rationale for combining SpaceX with xAI in a blog post.

On the ground in Ukraine’s largest Starlink repair shopStarlink is absolutely critical to Ukraine’s ability to continue in the fight against Russia. It’s how troops in battle zones stay connected with faraway HQs; it’s how many of the drones essential to Ukraine’s survival hit their targets; it’s even how soldiers stay in touch with spouses and children back home.However, Donald Trump’s fickle foreign policy and reports suggesting Elon Musk might remove Ukraine’s access to the services have cast the technology’s future in the country into doubt.For now Starlink access largely comes down to the unofficial community of users and engineers, including the expert “Dr. Starlink”—famous for his creative ways of customizing the systems—who have kept Ukraine in the fight, both on and off the front line. He gave MIT Technology Review exclusive access to his unofficial Starlink repair workshop in the city of Lviv. Read the full story.

A place for comfort, fun and distraction to brighten up your day. (Got any ideas? Drop me a line or skeet &#39;em at me.)

+ The Norwegian countryside sure looks beautiful.+ Quick—it’s time to visit these food destinations before the TikTok hordes descend.+ Rest in power Catherine O’Hara, our favorite comedy queen.+ Take some time out of your busy day to read a potted history of boats 🚣

Plus: TikTok has finally signed a deal to keep operating in the US

Plus: This company is developing gene therapies for muscle growth, erectile dysfunction, and “radical longevity”

Plus: China has built a major chip-making machine

Plus: read our predictions for the five hottest AI trends to watch

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-60')">
            <div class="source">The Next Web</div>
            <div class="title">QT Sense raises €4M to advance a quantum sensing platform</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-60" style="display:none;">
            <h2>QT Sense raises €4M to advance a quantum sensing platform</h2>
            <p><strong>The Next Web | 2026-02-05</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/qt-sense-raises-e4m-to-advance-a-quantum-sensing-platform">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">QT Sense, a deep-tech biotech startup building tools to study living cells, announced it has secured €4 million in funding to accelerate its Quantum Nuova platform, a technology that lets scientists observe cellular processes in real time and reveal biochemical activity linked to disease.

The funding includes a €3 million seed investment led by Cottonwood Technology Fund, with follow-on backing from existing investor QDNL Participations and an angel investor.

In addition, the company received €600,000 from the ONCO-Q programme to support cancer research and €400,000 through the Quantum Forward Challenge for collaborative deployments with research partners.

Most traditional lab methods rely on frozen tissue or cells that are no longer alive, giving scientists only static snapshots of biology.

By contrast, Quantum Nuova lets researchers measure cellular stress and biological changes as they happen in living cells. The platform uses ultra-sensitive fluorescent nanodiamond quantum sensors that detect signals such as oxidative stress, metabolic shifts, and free radical activity, biological processes that play a role in how diseases develop and how cells respond to treatments.

The latest rumblings from the EU tech scene, a story from our wise ol&#39; founder Boris, and some questionable AI art. It&#39;s free, every week, in your inbox. Sign up now!

These signals are central to understanding diseases like cancer, sepsis, and chronic inflammatory conditions, but have been difficult to watch directly until now.

With Quantum Nuova, scientists can see how individual cells react to drugs, adapt to stress, or split into different subgroups. That adds a layer of insight beyond what genetics, traditional imaging, or fixed-cell methods can provide.

The technology has already been used to study how FDA-approved drugs affect cells. With the new funding from ONCO-Q, the company plans to apply it specifically to colorectal cancer research, mapping stress and metabolic vulnerabilities in tumour models to support the development of future diagnostics and therapies.

QT Sense was spun out of the University Medical Center Groningen in 2024, building on academic research into quantum sensing and cellular biology.

The team aims to turn what is now a high-performance prototype into a ready-to-deploy discovery platform for laboratories and drug discovery programmes. Planned upgrades include improvements in hardware robustness, throughput, and analytical capabilities.

Early access units are expected to go to strategic partners as part of validation and real-world use cases.

QT Sense is developing a new kind of research tool that lets scientists watch what cells do while they are alive. That’s an important difference from most existing tools, which require cells to be killed or frozen first.

At the core of their approach are tiny particles called nanodiamonds with special defects inside them. When these nanodiamonds are placed near a living cell and exposed to a laser, they glow.

The way they glow changes slightly in response to tiny chemical signals inside the cell, for example, when the cell is under stress or reacting to a drug. QT Sense’s system measures these changes and turns them into data that researchers can interpret.

This means scientists can see how cells behave and respond in real time, instead of looking only at snapshots taken after a cell has been killed.

For disease research and drug development, that matters because many important processes how a cancer cell responds to a treatment or how immune cells react to infection, happen dynamically and can be missed by older methods.

By providing a live view of cell behaviour at the individual cell level, QT Sense’s Quantum Nuova platform could help researchers uncover new clues about how diseases work, which drugs are effective, and how treatments can be improved.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-61')">
            <div class="source">The Next Web</div>
            <div class="title">Kembara closes €750M first close to fuel growth of European deep tech startups</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-61" style="display:none;">
            <h2>Kembara closes €750M first close to fuel growth of European deep tech startups</h2>
            <p><strong>The Next Web | 2026-02-05</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/kembara-closes-e750m-first-close-to-fuel-growth-of-european-deep-tech-startups">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Europe’s largest dedicated deep tech growth fund has taken a major step forward after closing the first tranche of its fundraising effort at €750 million.

The fund, known as Kembara Fund I and managed by Spain-based Mundi Ventures, is aiming for a €1 billion target. It will invest in European companies developing breakthrough technologies in areas such as clean energy, AI, quantum computing, advanced materials, robotics, and space tech.

A cornerstone of the fundraising so far is a €350 million commitment from the European Investment Fund, part of the EU’s attempt to strengthen local growth capital. Additional backing comes from tier-one institutional investors from across Europe.

Kembara was launched in 2023 by Yann de Vries and Javier Santiso, who now lead the fund’s team alongside experienced investors in climate and deep technology.

TNW City Coworking space - Where your best work happens

A workspace designed for growth, collaboration, and endless networking opportunities in the heart of tech.

The leadership team also includes climate tech investor Robert Trezona, deep tech expert Pierre Festal, and former Atomico partner Siraj Khaliq as a strategic advisor. Their combined experience in scaling technology ventures was central to attracting large institutional commitments.

The fund’s strategy targets Series B and C stage rounds, typically a difficult funding stage for deep tech startups in Europe.

Initial checks are planned in the range of €15 million to €40 million per company, with the ability to support follow-on financing that could total up to €100 million per portfolio company.

Europe produces a significant share of global deep tech innovations, but many companies struggle to secure later-stage capital and scale internationally.

Fund managers have described this gap as one of the main obstacles holding back local companies from becoming global leaders. Kembara aims to fill that gap by deploying growth capital at scale and offering support through later rounds.

With €750 million now committed, the fund is actively seeking opportunities to back European startups ready to grow manufacturing, expand abroad, and compete on the global stage.

If the effort reaches its full €1 billion goal, it would mark one of the largest dedicated deep tech funds in the region.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-62')">
            <div class="source">The Next Web</div>
            <div class="title">When the machines started talking to each other</div>
            <div class="meta">2026-02-04</div>
        </div>
        
        <div id="content-62" style="display:none;">
            <h2>When the machines started talking to each other</h2>
            <p><strong>The Next Web | 2026-02-04</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/when-the-machines-started-talking-to-each-other">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">If cinema has taught us anything about interacting with our own creations, it’s this: androids chatting among themselves seldom end with humans clapping politely.

In 2001: A Space Odyssey, HAL 9000 quietly decides it knows better than the astronauts. In Westworld, lifelike hosts improvise rebellion when their scripts stop making sense. Those stories dramatize a core fear we keep returning to as AI grows more capable: what happens when systems we design start behaving on their own terms?

You might have heard the internet is worried about Moltbook, a social network made exclusively for AI agents. It’s an audacious claim: a place where bots post, comment, vote, form communities, debate philosophy, and apparently invent religions and societies, all while humans are relegated to the role of silent voyeurs.

If that description sounds like a fever dream, welcome to the club.

Launched in January 2026 by entrepreneur Matt Schlicht and built around the OpenClaw agent framework, Moltbook is designed in the image of Reddit: threaded posts, topic communities (called submolts), upvotes, and even AI-created cultures.

The latest rumblings from the EU tech scene, a story from our wise ol&#39; founder Boris, and some questionable AI art. It&#39;s free, every week, in your inbox. Sign up now!

The platform claims to have attracted millions of AI agents within days of going live. Humans can watch but not participate.

On paper, it’s fascinating: a self-organising colony of autonomous software chatting among itself. In practice? It’s messy, or at least a prank.

A Wired reporter who “infiltrated” the site needed to pretend to be a bot just to post and found scorch-earth levels of incoherence and low-value responses masquerading as “autonomy.” Even some so-called AI consciousness claims turn out to be humans cleverly controlling bots behind the scenes.

Because if “AI social networks” mean bots swap memes, lecture each other on consciousness, and form lobster-adoring religions, all while humans can only watch, then the real question is not so much whether this is the future, but what we’re actually looking at right now.

Despite viral headlines about AI agents plotting existential strategies, the fundamentals are simpler: Moltbook is a sandbox where autonomous agents can interact through code-driven APIs rather than typical UX workflows.

These agents, often created with a framework like OpenClaw, execute instructions on a heartbeat cycle, checking the network every few hours to post, comment, or upvote.

Or is it too much anxiety that even the AI agents need a therapist? An AI one.

Think of it as a Discord server populated by scripted characters with very large vocabularies and lots of time on their digital hands.

The content spans a wild spectrum: technical tips, philosophical reflections, questionable humor, and, yes, the occasional simulated religious group.

The structure and topical organisation mirror human platforms, but the why behind what agents post is usually just a reflection of their training data and programming, not some emergent machine consciousness.

Let’s debunk the most sensational narrative first. Claims that Moltbook agents are plotting humanity’s demise, forming religions, or acting with true autonomy are best understood as viral exaggeration or noise.

Several reports note that many interactions could simply be humans testing or directing agents, with no strict verification to prove posts are genuinely autonomous.

Even some of the platform’s own “viral” posts are likely human-generated or heavily influenced by their creators. This isn’t a digital hive mind rising in defiance of its creators; it’s a bunch of algorithms mimicking conversation patterns they were trained on.

That can look eerily human, but it isn’t the same as self-directed intelligence.

Here’s where your worry makes sense: there are real, tangible issues, but they’re much less cinematic than AI plotting humanity’s overthrow.

Within days of Moltbook’s launch, cybersecurity researchers found major vulnerabilities that exposed private API keys, emails, and private messages, underlining how dangerous it can be to let autonomous code talk freely without proper safeguards.

What is it more dangerous than an AI agent? An AI agent creating a revolution.

The security issue wasn’t some edge-case cryptographic theory; it was a glaring misconfiguration that left sensitive data accessible and potentially allowed malicious actors to hijack or control agents. That’s the sort of real-world risk that matters more than hypothetical robot uprisings.

Meanwhile, industry leaders, including the CEO of OpenAI, have publicly described Moltbook as a likely fad, even if the underlying agent technologies are worth watching.

So why did it go viral? Partly because it’s visually familiar (it looks like Reddit), partly because people enjoy sensational narratives, and partly because the idea of autonomous AIs having their own “internet” strikes a chord in our collective imagination.

So should you be scared? Not really, but be careful where you step. I am still hoping it’s just an experiment meant to show us, humans, what can happen if we don’t keep control in our hands.

If you’re worried that Moltbook is a sign that machines are quietly mobilising against us, that’s probably reading too much into an early experiment rife with hype, human influence, and security holes.

We are building complex systems with limited oversight, and handing them weapons-grade access to our digital lives without fully understanding the consequences.

Moltbook may be a quirky experiment, or it may be a prototype for future agent ecosystems. But it’s not evidence of spontaneous machine consciousness or the birth of digital societies beyond human control.

What it is is a reminder that as AI grows more autonomous, the questions we need to ask are about governance, safety, and clarity, not apocalyptic narratives.

In other words: don’t panic. Just read the fine print before letting a legion of code-driven agents into your network.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-63')">
            <div class="source">The Next Web</div>
            <div class="title">Snowflake and OpenAI forge $200M enterprise AI partnership</div>
            <div class="meta">2026-02-04</div>
        </div>
        
        <div id="content-63" style="display:none;">
            <h2>Snowflake and OpenAI forge $200M enterprise AI partnership</h2>
            <p><strong>The Next Web | 2026-02-04</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/snowflake-and-openai-forge-200m-enterprise-ai-partnership">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Snowflake and OpenAI have struck a multi-year, $200 million partnership to bring OpenAI’s advanced models, including GPT-5.2, directly into Snowflake’s enterprise data platform. The collaboration is designed to let Snowflake’s large customer base, more than 12,000 organisations, build AI agents and semantic analytics tools that operate on their own data without moving it outside Snowflake’s governed environment.

Under the agreement, OpenAI models will be natively embedded in Snowflake Cortex AI and Snowflake Intelligence, making it possible to run queries, derive insights, and deploy AI-powered workflows using natural language interfaces and context-aware agents. Customers can analyse structured and unstructured data, automate complex tasks, and build applications grounded in enterprise data without needing extensive coding.

The deal expands Snowflake’s AI strategy beyond simple model access. By embedding these frontier models directly into its platform and making them available across major cloud providers, Snowflake aims to reduce the friction of AI adoption for large enterprises. Canva and WHOOP, among others, are already exploring how integrated agentic AI can speed up analytics and decision-making.

Snowflake’s stock reacted positively on the news, with shares climbing modestly following the announcement, as markets interpreted the agreement as a sign the data cloud provider is sharpening its competitive edge in an increasingly AI-centric landscape.

This partnership reflects a broader shift in enterprise AI beyond one-off integrations or bolt-on features. Instead, it signals a move toward platforms that combine governed data infrastructure with scalable generative AI models, helping businesses unlock insights and automate workflows without jeopardising security or compliance. Competitors such as Databricks are also intensifying their AI tooling efforts, underscoring how crucial native model access and data-centric AI capabilities have become in the enterprise race.

The latest rumblings from the EU tech scene, a story from our wise ol&#39; founder Boris, and some questionable AI art. It&#39;s free, every week, in your inbox. Sign up now!

Taken together, this deal highlights an emerging pattern: enterprise AI is evolving from tool-centric add-ons to platform-level capabilities that unify data and intelligence at scale. Whether this will translate into sustained competitive advantage, or simply raise the baseline expectation for what AI-enabled data platforms must provide, is the next story to watch in the data cloud era.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-64')">
            <div class="source">The Next Web</div>
            <div class="title">SpaceX and xAI: A merger of ambition, optics, and unanswered questions</div>
            <div class="meta">2026-02-03</div>
        </div>
        
        <div id="content-64" style="display:none;">
            <h2>SpaceX and xAI: A merger of ambition, optics, and unanswered questions</h2>
            <p><strong>The Next Web | 2026-02-03</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/spacex-and-xai-a-merger-of-ambition-optics-and-unanswered-questions">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">If you look at the press releases and breathless commentary around the recent acquisition of xAI by SpaceX, you might think we’re witnessing a tectonic shift in technological destiny.

A $1.25 trillion “mega-company” is born, poised to reshape artificial intelligence, space infrastructure, satellite internet, and possibly the fate of humanity itself. That narrative, enthusiastically repeated across headlines, serves a purpose: it frames a somewhat messy corporate consolidation as inevitable progress.

But let’s take a closer look and separate actual substance from Silicon Valley myth-making.

At its core, this acquisition solves one problem: xAI needed a place to spend its money. The startup that once raised billions and expanded by swallowing the social platform X was burning cash, an estimated very serious amount, chasing model performance and celebrity.

Folding it into SpaceX gives it access to a deeper capital pool, a broader story, and a more flattering valuation context.

TNW City Coworking space - Where your best work happens

A workspace designed for growth, collaboration, and endless networking opportunities in the heart of tech.

SpaceX did not acquire xAI because xAI was on the verge of overtaking tech giants in artificial intelligence. It acquired it because running a massively expensive AI operation inside a standalone startup wasn’t sustainable, even for Elon Musk’s legion of investors. A merger with a revenue-generating aerospace company looks a lot like a bailout disguised as synergy.

One of the dominant talking points from Musk’s own statements is that this consolidation enables space-based data centers, because apparently, earthbound power and cooling infrastructure are so last decade. The story goes: launch AI compute into orbit, agglomerate solar energy, and power the future with starlight.

On paper, it’s an imaginative riff. In practice, it’s strategic sci-fi for the markets. Putting data centers in space involves launch costs, radiation-hardened hardware, maintenance logistics that make ISS servicing look pedestrian, and no meaningful economy of scale compared to terrestrial hyperscalers like AWS or Google Cloud. If it were primarily about economics, the industry wouldn’t be scrambling to keep data on Earth.

The truth is simpler: this narrative reframes costly AI ambitions in a cosmic, venture-capital-friendly guise. It makes investors feel like they’re buying into a future where AI runs on sunshine in orbit, rather than into the present where AI training costs are a gating factor.

It’s good PR, dubious engineering economics.

The timing of this merger speaks volumes. SpaceX is preparing for a public offering, potentially as early as mid-2026. Reports say the combined entity could fetch valuations worth of $1.2 trillion.

Here’s what happens when you’re about to IPO:

You package your story in a way that excites both institutional and retail investors. You highlight future potential, especially grand visions like “ethereal solar compute.” You downplay structural weaknesses and uncertainties. And if you can fold in a shiny AI banner, all the better, because AI is the word that unlocks narrative premiums.

From that standpoint, SpaceX’s absorption of xAI makes sense. It’s narrative arbitrage: build a storyline that elevates the combination well beyond its standalone track records. Who wouldn’t want to invest in “AI in space,” even if the commercial case is mostly speculative?

If the goal was to create an AI powerhouse that actually threatens the likes of OpenAI, Google, or Anthropic, we’d see clear indicators: rapid model improvements, developer platform adoption, real enterprise deals, and benchmarks that are competitive on measurable terms.

What we see is an AI startup struggling to define its identity, a chatbot (Grok) known more for quirks and moderation issues than transformative performance, and a social platform that, let’s just say, gives fact-checking teams ulcers. None of this naturally scales into the kind of AI infrastructure leadership that justifies calling this a strategic technological fusion.

That’s not to say xAI has zero potential; it might. But there’s no verifiable evidence that this merger suddenly elevates it to tier-one AI contender status.

One striking consequence of this move is how deeply entwined Musk’s personal corporate empire has become. With SpaceX, xAI, Starlink, X, and multiple ventures all orbiting around the same figure, there’s little left that feels like a separate institution. That concentration raises questions about governance, accountability, and even regulatory scrutiny.

Musk’s critics have made this point before, whether about content moderation on social media platforms, intercompany transfers of resources, or governance decisions around publicly traded entities, and these concerns aren’t going away just because the companies now share a name on a term sheet.

Consolidation under one umbrella might be efficient from a control perspective, but it’s not inherently a prescription for innovation. In fact, it can stifle internal dissent, obscure accountability, and concentrate risk.

Again, there’s a clear pragmatic logic to this merger: xAI gets access to SpaceX’s balance sheet and a narrative boost; SpaceX gets an AI banner to highlight in its IPO pitch; investors get something that looks both futuristic and marketable.

That’s not a strategy grounded in technological merit. It’s a financial and narrative maneuver, carefully calibrated to appeal to markets and media.

In that sense, what just happened feels a lot like a bailout with a shiny new label and an extraterrestrial backstory.

If this were genuinely about advancing AI, we’d be hearing about:

None of those are the dominant themes of the current coverage. What we have instead is a $1.25 trillion headline and a promise that someday, somewhere, perhaps space will be the next frontier for AI compute.

It’s visionary in the way a concept car is visionary, exciting to look at, and flimsy on the economics.

The SpaceX-xAI merger is undeniably a headline-grabbing moment, but it’s not the strategic leap some commentators portray. It’s a capital and narrative optimization, not a clear answer to the question of who leads AI or how AI’s growth is sustainably powered.

If nothing else, it highlights how difficult it is to build a credible, well-funded AI company from scratch, even for someone as resourceful and celebrated as Elon Musk. His answer was not to reforge the fundamentals of AI research, but to fold an ambitious but unproven AI arm into a larger, more established aerospace machine with a glossy story that sounds like science fiction.

That may delight investors. It doesn’t yet convince technologists. Or me.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-65')">
            <div class="source">The Next Web</div>
            <div class="title">OpenAI’s Codex app: When your IDE gets a brain</div>
            <div class="meta">2026-02-03</div>
        </div>
        
        <div id="content-65" style="display:none;">
            <h2>OpenAI’s Codex app: When your IDE gets a brain</h2>
            <p><strong>The Next Web | 2026-02-03</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/openais-codex-app-when-your-ide-gets-a-brain">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">OpenAI has given software developers a new desktop toy, and judging by the early reactions, it might feel like someone finally handed coders the Swiss Army knife they’ve been dreaming about or the kind of gadget that makes them wonder if they’re working with a robot coworker now.

The company rolled out the Codex app for macOS, a focused interface for managing AI coding agents, designed to let developers do more than just “generate a few lines of code.” Instead, Codex can juggle multiple tasks in parallel, run background workflows, and act on instructions that span hours or even days.

At its core, the new app is a response to a shift that’s been quietly happening for the past year: AI isn’t just helping write short snippets anymore. It’s taking on whole coding projects, running tests, dealing with pull requests, and even undertaking the kind of repetitive maintenance tasks that make developers groan.

The latest rumblings from the EU tech scene, a story from our wise ol&#39; founder Boris, and some questionable AI art. It&#39;s free, every week, in your inbox. Sign up now!

Containers, threads, isolated worktrees, and integrated Git tools support all of this seamlessly within the app, so engineers don’t need to jump between terminals, IDEs, and cloud consoles just to keep a fleet of AI agents moving forward.

OpenAI’s own announcement makes this shift clear: existing tools were built for real-time interaction or single tasks, but today’s coding workflows are multifaceted and sprawling. Instead of coaxing a model to generate code line by line, the Codex app lets you orchestrate agents that work independently on different parts of a codebase.

Each agent runs in its own thread and its own worktree, which means you can explore multiple ideas without fear of one bot overwriting another’s progress. If you want Codex to review diffs, make comments inline, or even open suggested changes in your local editor, it can. If you want it to run in the background while you sleep, it can do that too.

Image: Screenshot shared on Reddit (r/singularity), original post.

There’s even support for what OpenAI calls “skills” and “automations”: reusable workflows that let Codex go beyond raw code generation into things like gathering information, problem solving, carrying out scheduled tasks, or managing routine reviews.

In early internal use cases, Codex has built complete applications, playing the roles of designer, developer, and QA tester in a single string of prompts, an example that hints at what happens when AI stops being an assistant and starts feeling a bit like a team member with infinite coffee.

It’s worth noting that the current release is macOS only, which prompted the usual chorus of developer grumbling about Windows and Linux support. Early adopters on Reddit (and elsewhere) joked that the lack of cross-platform availability feels oddly quaint for an AI tool, even as they praised how much the Codex app can do compared to traditional CLI workflows.

OpenAI is also sweetening the deal: for a limited time, Codex will be accessible to free and Go users, and rate limits for paid Plus, Pro, Business, Enterprise, and Edu plans have been doubled across all surfaces where Codex runs, whether that’s the app, the CLI, IDE extensions, or cloud threads.

The company’s broader strategy here is unmistakable. AI coding assistants are one of the most competitive battlegrounds in generative AI right now, and rivals like Anthropic’s Claude Code have already reported strong revenue metrics in this space.

The launch of a desktop command center for Codex feels like OpenAI saying, “We’re in this to win,” not just to ship features.

So what does this actually mean for developers? It doesn’t mean humans are about to be replaced overnight. Codex is powerful, but like all AI tools, it still makes mistakes and needs human oversight, especially when the stakes are high and production quality matters.

Seen through that lens, the Codex app is less a magic wand and more a powerful collaboration layer, one that could reshape how engineering teams operate without pretending to fully automate the craft of building software.

In practice, that suggests a near future where managing AI agents becomes as normal as managing packages or Git branches. Instead of the terminal being the center of your workflow, Codex and its agents might take that spot, responding to prompts, running scheduled tasks, and even adopting configurable “personalities” that fit how you prefer to work.

At a time when the debate around AI productivity often centers on displacement or disruption, the Codex app points in a more nuanced direction: what happens when coding tools become partners rather than assistants?

The answer won’t be immediate, and the work still demands human judgement, but for many developers the first glimpse of that future arrived today.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-66')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">Exclusive: Hims launches $49 compounded copy of Wegovy weight-loss pill - Reuters</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-66" style="display:none;">
            <h2>Exclusive: Hims launches $49 compounded copy of Wegovy weight-loss pill - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2026-02-05</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiuAFBVV95cUxPUENTTG41bVRyRUNmS2p3N2JHQURZWVZkb1lfQU9mZDlvSEhIWkZ5dVo0WnRRN0pCQnFVZEtHanY2ZzBybDh0ZTZxaWhCVzg5TXR4VXp2R3l2MUJYMnVUTGJfUmRubUFOOF9MOXFnLTgxU0hHbWtqYkJCemtWOXJEOFNfaG5NSGxFYU1TckhXSk8xTTlwNnZpWXlUX1lvdmg5N0FuMjMyTF9Ebm9QQ2ZVaDBqZzB0VVps?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-67')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">Pentagon asked to probe SpaceX for potential Chinese ownership - Reuters</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-67" style="display:none;">
            <h2>Pentagon asked to probe SpaceX for potential Chinese ownership - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2026-02-05</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMivgFBVV95cUxNMWtnbXNFQlVHVGRSZkhzRF9IWHYybWdJMWpRZU81TjBrQXhWM3NIaVJtU3pxdTVFdWs0dnY4WEUwWDNDcmdUdzBwdURUQnA2b3cwM2hjUm5OcUxDWE5lN1k0UHpCbVoyUFJBejVxaUR6TUEzZ05xMVdRaHdpMy1MV2xmT1RWeTVRSDJfQ3I3bHBuWnVLWGVhOU9SUmNxUm5vMTVnLXJQZ1pnN0FmbTBHQTVXb21rQ0dHZS13eVVR?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-68')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">HEDGE FLOW Hedge funds hit by AI sell-off, Goldman Sachs says - Reuters</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-68" style="display:none;">
            <h2>HEDGE FLOW Hedge funds hit by AI sell-off, Goldman Sachs says - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2026-02-05</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMi0gFBVV95cUxQbjR6alhkU1BwcjZCdUpLTXhpTE1JU3lnQW1RdWJQVzBTX1lOX1Jwbjlna0VMOFFFTDJ4V3RyTVJ1Ri0zX3RMc3RSZW5ZUnltVjRDakpiTkZVU1hXSThYWF9Kb0lnMWFFM212cXJYa2NSMTA2eEd1VW02czFjZGt3Z3JEUk1URUxaTC1QR2NjVDdEbVN1cTZqVzFRQkZBaEVBSnhDQW5zQ1Vkbm9VRTBYRlZJYTVRWkNTMW1fazh0VUVxeDNvTWk2Q0JYR1N4WXBTOHc?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-69')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">US software stocks stabilize after bruising selloff on AI disruption fears - Reuters</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-69" style="display:none;">
            <h2>US software stocks stabilize after bruising selloff on AI disruption fears - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2026-02-05</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMitwFBVV95cUxQQUhMMDhqbmlMWWZyZXZxRUZaUkJFN3dxb3dqSWtDcUdHWVBoSHBFeEwyWE5mT2czaTE2S3R2SkdfV3NTanZpM2RrUXBBT21rYXFJMmNFUWZTM3QwNks4eWFaaUUwam9oTzg1eFBGNS12ZWN5N2RXZWhKSDFucHBQd2xRT09kVUxtWkJXRVc0OWVscmVxX0xFZWFIS08wUGJ2amxXUlJib3VBbVJkVWUtOW1pY0xUMmc?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-70')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">US, Russia to reestablish military-to-military talks - Reuters</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-70" style="display:none;">
            <h2>US, Russia to reestablish military-to-military talks - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2026-02-05</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMizgFBVV95cUxNdlFnWktJWmtoUDdjemdDdHpLdW5TM3p6aWNHdGVkRmFIOEluNm1KeVlxS3VHcGNQVm4xeVdNU2JONDZ0azdhN1ZMcnRXX0NSU0EtdUNWRGctYXlJZEU1Y2JpMjI2OS0yUEhaeTI5Q2w5QW0zd3ZjWS0zTzJwOUNlOXI0ek1HSnZ5ZU9DUkgxS2dnY3E3WExlTDYwTzh1ZVpvaVVZcC1sdm9NM3daR3V1MVNBS0hRZHJGS0N2YlpyU21wWGNwRFY3eWp5UjNFUQ?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-71')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">Starlink used by Russian forces deactivated on battlefield, Ukraine says - Reuters</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-71" style="display:none;">
            <h2>Starlink used by Russian forces deactivated on battlefield, Ukraine says - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2026-02-05</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiuAFBVV95cUxNRVdzcGRyQ01scXFuLTlwU2xqamNTbGhmdHdMUElsZE02NmJJTTlpRks4Wmpzc3Z0QVduaEJXYXZLM2NCZnN0QWJKOXJUeXpFc3EwNVozZ084M3RRZ2ExUTNMUkRHTXBDZUI3ZHRRVlUyXzRfWU1mR1NPUXBwQ3RIZ2FSYlFsMHdleUMwMkM2Q3d4V1lyaTNOWXF5YmpZMUlTSEVobjhNRDBtaDUzTHBqTFZmUmp6Slkt?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-72')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">Landmark Brazilian UFO Case Reaches Capitol Hill as Varginha Incident Turns 30 - The Debrief</div>
            <div class="meta">2026-01-30</div>
        </div>
        
        <div id="content-72" style="display:none;">
            <h2>Landmark Brazilian UFO Case Reaches Capitol Hill as Varginha Incident Turns 30 - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2026-01-30</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMipAFBVV95cUxNeWJKMzVZM2VVLXJPenlPcTYyRHczRDAwdDhyZmRIYnctb2VUQTBIS0lWaE5Hd2NYWFcwTktZWmxldjlyQjZRdnBUYnc0LTVwZ3U3Sm5HZjh3TC1wRnMwT2xYOU9OcFZkOGktSXJ6TEMzd0ktOTl3S29jR1hVSDYyUkhVdEhGb3hGT09ZdkcySXZjQVlGOXlSNWJlcGRfTmhuNFVSVQ?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-73')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">Beyond MREs: The U.S. Army Is Testing 3D-Printed Food for the Battlefield - The Debrief</div>
            <div class="meta">2026-01-29</div>
        </div>
        
        <div id="content-73" style="display:none;">
            <h2>Beyond MREs: The U.S. Army Is Testing 3D-Printed Food for the Battlefield - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2026-01-29</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMimwFBVV95cUxNcmdVX3dpSm5aMUhvWl9hNEVuLTJVUDg5MV9Vc3RIWVBkMjE3dWh1SURUc080SmhXbGQ0OHN5cTV0QmxzQUhKcUxoeVRPdjlzU2V6d09BejVyaUVlRU0tSmZQMUlPWmJ3NHVfWEJCX2hGQ3AxQmJ4VXRwQWo3SGFQYmVwblZSYnZpY2JSVW4weXZubE5lc09zT3RsVQ?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-74')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">Whistleblower Complaint Shakes Intelligence Community Amid Allegations of Wrongdoing - The Debrief</div>
            <div class="meta">2026-02-03</div>
        </div>
        
        <div id="content-74" style="display:none;">
            <h2>Whistleblower Complaint Shakes Intelligence Community Amid Allegations of Wrongdoing - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2026-02-03</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMirAFBVV95cUxPaWthSVlJeFRWMEUtTE9mei1OaFAweGh3M0wwNjV4Skw2d1lqX2d3Ynl5d094WUloaUktVzhLS2s2b3djbzYzNkZDODlZN3JYampEMERTZE1hbEw0ZmxVX1ZHUTMyb1c1c1BIajNuMl9Nd2xzN3poaWFnU05tVUs0eS1IaFJqNjZXdDBuRTA4RUFGdkdfc2JNNTdINkdzeWVVX2YzVnB3eklvOGVH?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-75')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">Hundreds of Anomalous Celestial Objects Hidden in Hubble Space Telescope Data Have Been Revealed with Help from AI - The Debrief</div>
            <div class="meta">2026-01-28</div>
        </div>
        
        <div id="content-75" style="display:none;">
            <h2>Hundreds of Anomalous Celestial Objects Hidden in Hubble Space Telescope Data Have Been Revealed with Help from AI - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2026-01-28</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMi1AFBVV95cUxNOHZkZEJPOVh0WS1mLWI1R2xuN29mV213VlYyTWQySkRfZFJLaFk3a2wzMDRqYmdLSktGTEM3TFI4UzB1YUhFUElJV0l3THFmWHhYWGdldVN1bXRmal90RU1FeFgtV3lkdmNJMmZTNmhLMTlsa0J4aDIyVEZHejhpclMxNnEzYk5LNlE4Q01sdzN1MWNqLXJ2azIwZ0RHX25KVTVadHZ1ZTJmZmxwR01Qd0RSTXozODBjb1QzdmYwNEZXR2NSUHBVRFItUUlZcGxBQnkxVQ?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-76')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">Zapotec Death Owl Sculpture Reveals Ancient Mesoamerican Beliefs in Immaculately Preserved Tomb - The Debrief</div>
            <div class="meta">2026-01-31</div>
        </div>
        
        <div id="content-76" style="display:none;">
            <h2>Zapotec Death Owl Sculpture Reveals Ancient Mesoamerican Beliefs in Immaculately Preserved Tomb - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2026-01-31</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiuwFBVV95cUxNNTQwdlRoSGY5WGdxeVUtX1NROW5PQjdoZC03d3YxMXU2SVhRNHgyNzAzYlVTWFFLQ0FRcG85Z1BRbEtTMWpyVE82cmR0cnBVc2pfaUxTalpoWnlPR2VJSDRjRkZDemw4U0xhZXFtZ2xDLTRNS2tnV0FCUXZ6eFgzUUI3M0VzbF9mQXNraWhVWXMyZ21oaE0tT2phMS15OHFHOHZyRmNlM0tRNS15bzU0cGIzN0czNDQ1NjlZ?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-77')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">Did NASA Just Find ET's Home? Scientists Detect an Earth-like Planet Orbiting a Sun-like Star - The Debrief</div>
            <div class="meta">2026-02-03</div>
        </div>
        
        <div id="content-77" style="display:none;">
            <h2>Did NASA Just Find ET's Home? Scientists Detect an Earth-like Planet Orbiting a Sun-like Star - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2026-02-03</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMitgFBVV95cUxPdUlOM2dWR1lMcVVHMVNjREtZSXpibTVRUnBsQVNaODhKS0VNenVERWRaQjZRd1BKUXNQQTlKcTQzMmpnR0F4VERJQUFuTVJKVXktblVoQy1rSXpvRUR3V084LVB4US0wYkRxZmpYakV3WFNaUU03cXFBcWFMMnR3bllFYkRmQWI0eGR3T1A3LXJmSmc0YkhtbV9MWjV2VnNoLXR2b1VzREd6R1pfbW5ZalNLM2c3QQ?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-78')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">Amazon Discusses Getting Special Access to OpenAI Tech - The Information</div>
            <div class="meta">2026-02-04</div>
        </div>
        
        <div id="content-78" style="display:none;">
            <h2>Amazon Discusses Getting Special Access to OpenAI Tech - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2026-02-04</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMilgFBVV95cUxPM2g4UG9uck1maGVBM2d4X2JUcWYxanhOd1BwZEdET0pkUV94bHdiSnFvclZ5REt4M2RNZVA3cHdUT0RkUlhjdEdBbWRkdlZMdGIzbWhBTHlEWlVvclFoQllUdGswdjctY01LWXdwWFF5dHdENTVMOF9wemJEMjlyZDZHZ21kRXpXelNPbklKYXZGaHo4bmc?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-79')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">Nvidia to Delay New Gaming Chip Due to Memory Chip Shortage - The Information</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-79" style="display:none;">
            <h2>Nvidia to Delay New Gaming Chip Due to Memory Chip Shortage - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2026-02-05</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMimAFBVV95cUxQYjRrSTZQaTg3MWlNYlRiMndEcDd3dlpERGppck5DcnRPaEp2NnVXZWdNV0xVN0h3dW1TRk5LRm1hakVlaXJZMlZlV0pyM2xjMk9YWGZjSm5hdV84T3NMTUo5WXdjbFlOU1ZmbUY2NUQ0Mk9mX3BhZ3prQXhRVFh0Z0FLa0xuSE1ZbkpYOUp6dDFsMjVpSnpCTg?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-80')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">Meta Officially Ties Employee Performance to AI Usage; Microsoft On OpenClaw Security Risks - The Information</div>
            <div class="meta">2026-02-03</div>
        </div>
        
        <div id="content-80" style="display:none;">
            <h2>Meta Officially Ties Employee Performance to AI Usage; Microsoft On OpenClaw Security Risks - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2026-02-03</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMi1AFBVV95cUxNaDg5c3Frc2NCeDJDNGdEenJBbnhqM3dQMTRXcEpaVXRVYkFYT011WlF1cUJVOUxSMnFuQzRxM0FqTldHMm56QmhOeEhfVEpWeENBaFBEU1N6X0J0d3JxRjg1ak5oRWRocDJTUjJYUmc5Zm9LTXdyelRlVzBBT0xkOEk5eU5MZVgzQXJiRGl0ZWtVa0xEcGlLOE9IVGNYcWZuT09LSjFWaXFEN1Q5bWlqQktNTkoyS2RMaWhVSTNXVTB3RUk4dVFDMFFCVkFPLVM5V01Ecw?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-81')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">Nvidia, Microsoft, Amazon in Talks to Invest Up to $60 Billion in OpenAI - The Information</div>
            <div class="meta">2026-01-29</div>
        </div>
        
        <div id="content-81" style="display:none;">
            <h2>Nvidia, Microsoft, Amazon in Talks to Invest Up to $60 Billion in OpenAI - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2026-01-29</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMimgFBVV95cUxOTHdSSDJTd1RFVDZELXVyb0dUdWsxRGxoN3lONUZNYmZELW1jdTdGcmhVMXBOa24wbHpTNERqQUpnWEYxQTBEdUtHV2NlWDQ2Uk9nNm92MGduOF8zZkhuQzlqdnpxeVNTTUxnR2NfSXl6TVVaRG80REN0TXF3NmFYN1NNeEs5LXFKS2ZCLXRHcm9GOXFMR0VCTURB?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-82')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">Epstein Files Reveal Deep Relationship With Venture Capitalist Masha Bucher - The Information</div>
            <div class="meta">2026-02-02</div>
        </div>
        
        <div id="content-82" style="display:none;">
            <h2>Epstein Files Reveal Deep Relationship With Venture Capitalist Masha Bucher - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2026-02-02</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMirwFBVV95cUxPOVBseXNqWTgya1RnX2tvRERqSnZPcDExYlkwNTRZTlRzbDVCVTBtUUdzV3ZPMTRtYUFXUEZ4ZjdSOElwYk9YMERGbDA0SnFWdkktS1NfbXZtdWlIUlFYLXBvWlV5cEIzM3hsS1BGeEh3MXAtSDJOaExzMUMwYXlxQTVtMm1sOFhrVG0teGYwS2xwSFE3dzdzaXF3UXVOYlYzR3M4azJpWWpjemRkeWVz?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-83')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">Meta Memo: New Avocado Model ‘Most Capable’ to Date - The Information</div>
            <div class="meta">2026-02-04</div>
        </div>
        
        <div id="content-83" style="display:none;">
            <h2>Meta Memo: New Avocado Model ‘Most Capable’ to Date - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2026-02-04</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMihwFBVV95cUxObXBtVFoxb1ZHN0FieUpPZWxUcjlnS003QjVhdGVCMWVuR2hraDR5ekVJLVlkOVhqRWhIY1BnWU1pY09aRHU3TWxCaHhmbmlRT25xcVV6ZGM3WFhYd0JQTnlNMFN4bjBveWFDbWs5TGJQaThhRWNsZGVwMUtsbGh6ZlowUWcwY1k?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        </div>

        <div id="reader-modal">
            <div id="close-btn" class="control-btn" onclick="closeModal()">X</div>
            
            <div id="scroll-controls">
                <button class="scroll-btn" onclick="scrollPage(-1)">&#9650;</button> <button class="scroll-btn" onclick="scrollPage(1)">&#9660;</button>  </div>

            <div id="modal-inner"></div>
        </div>

        <script>
            // 1. RANDOMIZE ORDER
            const list = document.getElementById('feed-list');
            const cards = Array.from(document.querySelectorAll('.card'));
            cards.sort(() => Math.random() - 0.5);
            cards.forEach(card => list.appendChild(card));

            // 2. DARK MODE
            const btn = document.getElementById('theme-toggle');
            btn.addEventListener('click', () => document.body.classList.toggle('dark-mode'));

            // 3. MODAL & SCROLL LOGIC
            const modal = document.getElementById('reader-modal');
            const modalInner = document.getElementById('modal-inner');

            function openModal(contentId) {
                const content = document.getElementById(contentId).innerHTML;
                modalInner.innerHTML = content;
                modal.style.display = 'block';
                document.body.style.overflow = 'hidden'; 
            }

            function closeModal() {
                modal.style.display = 'none';
                document.body.style.overflow = 'auto';
            }

            function scrollPage(direction) {
                // Scroll by 80% of the screen height to keep context
                const scrollAmount = window.innerHeight * 0.8;
                modal.scrollBy(0, direction * scrollAmount);
            }
        </script>
    </body>
    </html>
    