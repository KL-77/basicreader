
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>KL-77's Feed</title>
        <style>
            :root {
                --bg: #ffffff;
                --text: #000000;
                --border: #000000;
                --modal-bg: #ffffff;
                --dim: #666666;
            }
            
            body.dark-mode {
                --bg: #000000;
                --text: #ffffff;
                --border: #ffffff;
                --modal-bg: #000000;
                --dim: #aaaaaa;
            }

            body { 
                font-family: Georgia, serif; 
                background-color: var(--bg);
                color: var(--text);
                margin: 0;
                padding: 10px;
                font-size: 22px;
                line-height: 1.5;
            }

            header {
                display: flex;
                justify-content: space-between;
                align-items: center;
                border-bottom: 3px solid var(--text);
                padding-bottom: 15px;
                margin-bottom: 25px;
            }
            
            h1 { margin: 0; font-size: 1.2em; }

            button#theme-toggle {
                background: transparent;
                color: var(--text);
                border: 2px solid var(--text);
                padding: 10px;
                font-size: 18px;
                font-weight: bold;
                border-radius: 4px;
                cursor: pointer;
            }

            .card {
                border: 2px solid var(--text);
                margin-bottom: 25px;
                padding: 15px;
                cursor: pointer;
            }
            
            .source { font-size: 0.7em; font-weight: bold; text-transform: uppercase; color: var(--dim); }
            .title { font-size: 1.1em; font-weight: bold; margin: 8px 0; display:block; }
            .meta { font-size: 0.7em; color: var(--dim); }

            /* MODAL STYLING */
            #reader-modal {
                display: none;
                position: fixed;
                top: 0; left: 0;
                width: 100%; height: 100%;
                background-color: var(--modal-bg);
                z-index: 1000;
                overflow-y: scroll; /* Allow scrolling */
                scroll-behavior: auto; /* Instant scrolling for e-ink */
            }

            #modal-inner {
                padding: 25px;
                max-width: 800px;
                margin: 0 auto;
                padding-top: 80px; 
                padding-bottom: 150px; /* Huge padding so text clears the buttons */
            }

            /* Controls (Close + Scroll) */
            .control-btn {
                position: fixed;
                background: var(--bg);
                color: var(--text);
                border: 3px solid var(--text);
                border-radius: 8px;
                font-weight: bold;
                cursor: pointer;
                z-index: 1001;
                display: flex;
                align-items: center;
                justify-content: center;
            }

            #close-btn {
                top: 15px; right: 15px;
                width: 60px; height: 60px;
                font-size: 30px;
                line-height: 55px;
            }

            /* Scroll Buttons */
            #scroll-controls {
                position: fixed;
                bottom: 20px;
                right: 20px;
                display: flex;
                flex-direction: column;
                gap: 15px;
                z-index: 1002;
            }

            .scroll-btn {
                width: 60px;
                height: 60px;
                font-size: 24px;
                background: var(--bg);
                color: var(--text);
                border: 3px solid var(--text);
                border-radius: 8px;
                cursor: pointer;
            }

            #article-text { white-space: pre-wrap; font-size: 1.1em; }
            
            a.original-link {
                display: inline-block;
                margin-bottom: 30px; /* Space before text starts */
                padding: 10px;
                border: 1px solid var(--text);
                color: var(--text);
                text-decoration: none;
                font-weight: bold;
                font-size: 0.8em;
            }
        </style>
    </head>
    <body>

        <header>
            <h1>KL-77's Feed</h1>
            <button id="theme-toggle">Light/Dark</button>
        </header>

        <div id="feed-list">
    
        <div class="card" onclick="openModal('content-0')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">OpenAI spills technical details about how its AI coding agent works</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-0" style="display:none;">
            <h2>OpenAI spills technical details about how its AI coding agent works</h2>
            <p><strong>Ars Technica - All content | 2026-01-26</strong></p>
            <a class="original-link" href="https://arstechnica.com/ai/2026/01/openai-spills-technical-details-about-how-its-ai-coding-agent-works/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">On Friday, OpenAI engineer Michael Bolin published a detailed technical breakdown of how the company’s Codex CLI coding agent works internally, offering developers insight into AI coding tools that can write code, run tests, and fix bugs with human supervision. It complements our article in December on how AI agents work by filling in technical details on how OpenAI implements its “agentic loop.”

AI coding agents are having something of a “ChatGPT moment,” where Claude Code with Opus 4.5 and Codex with GPT-5.2 have reached a new level of usefulness for rapidly coding up prototypes, interfaces, and churning out boilerplate code. The timing of OpenAI’s post details the design philosophy behind Codex just as AI agents are becoming more practical tools for everyday work.

These tools aren’t perfect and remain controversial for some software developers. While OpenAI has previously told Ars Technica that it uses Codex as a coding tool to help develop the Codex product itself, we also discovered, through hands-on experience, that these tools can be astonishingly fast at simple tasks but remain brittle beyond their training data and require human oversight for production work. The rough framework of a project tends to come fast and feels magical, but filling in the details involves tedious debugging and workarounds for limitations the agent cannot overcome on its own.

Bolin’s post doesn’t shy away from these engineering challenges. He discusses the inefficiency of quadratic prompt growth, performance issues caused by cache misses, and bugs the team discovered (like MCP tools being enumerated inconsistently) that they had to fix.

The level of technical detail is somewhat unusual for OpenAI, which has not published similar breakdowns of how other products like ChatGPT work internally, for example (there’s a lot going on under that hood we’d like to know). But we’ve already seen how OpenAI treats Codex differently during our interview with them in December, noting that programming tasks seem ideally suited for large language models.

It’s worth noting that both OpenAI and Anthropic open-source their coding CLI clients on GitHub, allowing developers to examine the implementation directly, whereas they don’t do the same for ChatGPT or the Claude web interface.

Bolin’s post focuses on what he calls “the agent loop,” which is the core logic that orchestrates interactions between the user, the AI model, and the software tools the model invokes to perform coding work.

As we wrote in December, at the center of every AI agent is a repeating cycle. The agent takes input from the user and prepares a textual prompt for the model. The model then generates a response, which either produces a final answer for the user or requests a tool call (such as running a shell command or reading a file). If the model requests a tool call, the agent executes it, appends the output to the original prompt, and queries the model again. This process repeats until the model stops requesting tools and instead produces an assistant message for the user.

That looping process has to start somewhere, and Bolin’s post reveals how Codex constructs the initial prompt sent to OpenAI’s Responses API, which handles model inference. The prompt is built from several components, each with an assigned role that determines its priority: system, developer, user, or assistant.

The instructions field comes from either a user-specified configuration file or base instructions bundled with the CLI. The tools field defines what functions the model can call, including shell commands, planning tools, web search capabilities, and any custom tools provided through Model Context Protocol (MCP) servers. The input field contains a series of items that describe the sandbox permissions, optional developer instructions, environment context like the current working directory, and finally the user’s actual message.

As conversations continue, each new turn includes the complete history of previous messages and tool calls. This means the prompt grows with every interaction, which has performance implications. According to the post, because Codex does not use an optional “previous_response_id” parameter that would allow the API to reference stored conversation state, every request is fully stateless (that is, it sends the entire conversation history with each API call rather than the server retrieving it from memory). Bolin says this design choice simplifies things for API providers and makes it easier to support customers who opt into “Zero Data Retention,” where OpenAI does not store user data.

The quadratic growth of prompts over a conversation is inefficient, but Bolin explains that prompt caching mitigates this issue somewhat. Cache hits only work for exact prefix matches within a prompt, which means Codex must carefully avoid operations that could cause cache misses. Changing the available tools, switching models, or modifying the sandbox configuration mid-conversation can all invalidate the cache and hurt performance.

The ever-growing prompt length is directly related to the context window, which limits how much text the AI model can process in a single inference call. Bolin writes that Codex automatically compacts conversations when token counts exceed a threshold, just as Claude Code does. Earlier versions of Codex required manual compaction via a slash command, but the current system uses a specialized API endpoint that compresses context while preserving summarized portions of the model’s “understanding” of what happened through an encrypted content item.

Bolin says that future posts in his series will cover the CLI’s architecture, tool implementation details, and Codex’s sandboxing model.</div>
        </div>
        
        <div class="card" onclick="openModal('content-1')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">Doctors face-palm as RFK Jr.’s top vaccine advisor questions need for polio shot</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-1" style="display:none;">
            <h2>Doctors face-palm as RFK Jr.’s top vaccine advisor questions need for polio shot</h2>
            <p><strong>Ars Technica - All content | 2026-01-26</strong></p>
            <a class="original-link" href="https://arstechnica.com/science/2026/01/do-we-really-need-polio-shots-deep-thoughts-by-rfk-jr-advisor-get-dragged/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The chair of a federal vaccine advisory panel under anti-vaccine Health Secretary Robert F. Kennedy Jr. made his stance clear on vaccines in a podcast last week—and that stance was so alarming that the American Medical Association was compelled to respond with a scathing statement.

Kirk Milhoan, who was named chair of the Advisory Committee on Immunization Practices for the Centers for Disease Control and Prevention in December, appeared on the aptly named podcast “Why Should I Trust You.” In the hour-long interview, Milhoan made a wide range of comments that have concerned medical experts and raised eyebrows.

Early into the discussion, Milhoan, a pediatric cardiologist, declared, “I don’t like established science,” and that “science is what I observe.” He lambasted the evidence-based methodology that previous ACIP panels used to carefully and transparently craft vaccine policy.

While arguing that he was not anti-vaccine, he said he was merely focused on safety and made false claims about vaccine risks, a common trope among anti-vaccine activists. He falsely linked vaccines to allergies, asthma, and eczema and repeated a claim, without evidence, that COVID-19 vaccines killed children. When pressed by the podcast hosts, he revealed that he put the risk of vaccine side effects on the same footing as the risks from the diseases the shots prevent—despite the fact that disease risks are often orders of magnitude larger than the tiny risks from vaccines.

In response to pushback from the hosts, Milhoan objected to the idea that the measles and polio vaccines reduced the spread of those diseases. He went further, questioning the need for those vaccines as well as routine vaccinations, generally.

“I think also as you look at polio, we need to not be afraid to consider that we are in a different time now than we were then,” he said, referring to the time before the first polio vaccines were developed in the 1950s. “Our sanitation is different. Our risk of disease is different. And so those all play into the evaluation of whether this is worthwhile of taking a risk for a vaccine or not.”

He then pondered out loud what would happen if people stopped getting vaccinated. “If we take away all of the herd immunity, then does that switch, does that teeter-totter switch in a different direction?” he asked.

In a statement, AMA Trustee Sandra Adamson Fryhofer blasted the question. “This is not a theoretical debate—it is a dangerous step backward,” she said. “Vaccines have saved millions of lives and virtually eliminated devastating diseases like polio in the United States. There is no cure for polio. When vaccination rates fall, paralysis, lifelong disability, and death return. The science on this is settled.”

Fryhofer also took aim at Milhoan’s repeated argument that the focus of vaccination policy should move from population-level health to individual autonomy. Moving away from routine immunizations, which include discussions between clinicians and patients, “does not increase freedom—it increases suffering,” she said, adding that the weakening of recommendations “will cost lives.”

Overall, Milhoan’s comments only further erode the relevance of ACIP and federal vaccine policy among the medical community and states. According to a KFF policy brief, 27 states and Washington, DC, have already announced they will not follow current CDC vaccine recommendations, which Kennedy dramatically overhauled earlier this month without even consulting the ACIP. Instead, the majority of states are relying on previous recommendations or recommendations made within states or by medical organizations.

On Monday, the American Academy of Pediatrics announced the 2026 update to its childhood and adolescent vaccine schedule, which it has held up as an alternative to the CDC’s schedule and has been widely embraced by pediatricians. In the announcement, AAP noted that 12 other medical organizations have endorsed the schedule, including the AMA, the American Academy of Family Physicians, the American College of Obstetricians and Gynecologists, the Infectious Diseases Society of America, and the Pediatric Infectious Diseases Society.

The AAP’s updated recommendations are largely the same as the schedule from last year, but it is significantly different from the CDC’s recommendations, which “depart from longstanding medical evidence and no longer offer the optimal way to prevent illnesses in children,” the AAP said.

“The AAP will continue to provide recommendations for immunizations that are rooted in science and are in the best interest of the health of infants, children and adolescents of this country,” AAP President Andrew Racine said in the announcement.</div>
        </div>
        
        <div class="card" onclick="openModal('content-2')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">Why has Microsoft been routing example.com traffic to a company in Japan?</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-2" style="display:none;">
            <h2>Why has Microsoft been routing example.com traffic to a company in Japan?</h2>
            <p><strong>Ars Technica - All content | 2026-01-26</strong></p>
            <a class="original-link" href="https://arstechnica.com/information-technology/2026/01/odd-anomaly-caused-microsofts-network-to-mishandle-example-com-traffic/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">From the Department of Bizarre Anomalies: Microsoft has suppressed an unexplained anomaly on its network that was routing traffic destined to example.com—a domain reserved for testing purposes—to a maker of electronics cables located in Japan.

Under the RFC2606—an official standard maintained by the Internet Engineering Task Force—example.com isn’t obtainable by any party. Instead it resolves to IP addresses assigned to Internet Assiged Names Authority. The designation is intended to prevent third parties from being bombarded with traffic when developers, penetration testers, and others need a domain for testing or discussing technical issues. Instead of naming an Internet-routable domain, they are to choose example.com or two others, example.net and example.org.

Output from the terminal command cURL shows that devices inside Azure and other Microsoft networks have been routing some traffic to subdomains of sei.co.jp, a domain belonging to Sumitomo Electric. Most of the resulting text is exactly what’s expected. The exception is the JSON-based response. Here’s the JSON output from Friday:

Similarly, results when adding a new account for test@example.com in Outlook looked like this:

In both cases, the results show that Microsoft was routing email traffic to two sei.co.jp subdomains: imapgms.jnet.sei.co.jp and smtpgms.jnet.sei.co.jp. The behavior was the result of Microsoft’s autodiscover service.

“I’m admittedly not an expert in Microsoft’s internal workings, but this appears to be a simple misconfiguration,” Michael Taggart, a senior cybersecurity researcher at UCLA Health, said. “The result is that anyone who tries to set up an Outlook account on an example.com domain might accidentally send test credentials to those sei.co.jp subdomains.”

When asked early Friday afternoon why Microsoft was doing this, a representative had no answer and asked for more time. By Monday morning, the improper routing was no longer occurring, but the representative still had no answer.

Update: in an email sent after this post went live, the representative confirmed that Microsoft has “updated the service to no longer provide suggested server information for example.com.” As already reported here, the behavior only affected people configuring email accounts through the Outlook autoconfiguration feature. The representative added that Microsoft is investigating.

The new JSON response suggested that, as of Monday morning, Microsoft hadn’t fixed the endpoint routing traffic to the Sumitomo Electric servers. Instead, the JSON response no longer occurs. Where the output was occurring on Friday, the command now simply sits and hangs for 10 or 20 seconds and then terminates with a not found error. This behavior can be seen in the following output:

“It looks like they may have outright removed the endpoint that validates the email, because I’m seeing ‘not found’ errors,” said Dan Tentler, founder of Phobos Group. As denoted by ENOTFOUND, the error “suggests that [Microsoft admins] just ripped out whatever this thing was.”

It’s unclear how Sumitomo Electric’s domain would have found itself part of this mess. Microsoft last year said the Japanese company’s parent company, Sumitomo Corp., was deploying Microsoft 365 Copilot, but that still doesn’t explain why a subsidiary’s domain was added to Microsoft’s network configuration.

Questions sent to Microsoft include: How are autodiscover records added at Microsoft; was the routing intentional; and how long has the behavior been occurring? (Tinyapps.org, which noted the odd routing behavior earlier this month, said it lasted five years.) There doesn’t appear to be anything nefarious about the improper routing, and as long as people inside Microsoft’s network weren’t sending live credentials in tests, there was no danger posed.

There’s still reason for concern. In 2024, Microsoft revealed that one of its admins had assigned administrative privileges to a test account on the company network and then forgot about it. Russia-state hackers seized on the gaffe to gain initial access to Microsoft’s system. They went on to root through the network and monitor top executives’ email for two months. The routing misconfiguration for example.com raises the question: What other possibly more severe errors lurk on the network?</div>
        </div>
        
        <div class="card" onclick="openModal('content-3')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">Apple's AirTag 2 is easier to find thanks to new chip</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-3" style="display:none;">
            <h2>Apple's AirTag 2 is easier to find thanks to new chip</h2>
            <p><strong>Ars Technica - All content | 2026-01-26</strong></p>
            <a class="original-link" href="https://arstechnica.com/gadgets/2026/01/apple-introduces-new-airtag-with-better-range-and-a-louder-speaker/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Apple is introducing a new version of its AirTag tracking device—simply dubbed “the new AirTag&quot;—and claims it offers substantial improvements thanks to a new Bluetooth chip.

The original AirTag came out five years ago now, and it became popular in a variety of contexts. There were some problems, though—there was real concern about unwanted tracking and stalking with the devices, based on real stories of it being used for that. The company gradually introduced new features and protections against that, getting it to a much better place.

This new version is focused on making the device more effective in general. Thanks to the inclusion of the second-generation Ultra Wideband chip (the same one found in other recently released Apple devices like the iPhone 17), Apple says the new AirTag can work with the Precision Finding feature in the Find My app to direct users to the AirTag (and whatever lost item it’s stored with or attached to) from up to 50 percent farther away.

Additionally, the speaker in the AirTag is now 50 percent louder, Apple says. These two things together address some user complaints that, as useful as an AirTag can be in ideal circumstances, sometimes it is frustrating trying to get things just right to find something. It won’t eliminate all edge cases, but it ought to help.

Apple used this announcement to also talk up some of the features of the AirTag, including the encryption that it says prevents anyone but the AirTag owner from using it, and an arrangement with airlines where users can temporarily give airlines the ability to use Apple’s network to find a specific AirTag to locate lost luggage and the like.

To be clear, the new AirTag doesn’t introduce any major new features that aren’t already offered in the previous generation—this is just an update to the device’s accuracy, volume, and range.

The price remains unchanged, at $29 for one AirTag or $99 for a pack of four. The new model is available for order on Apple’s website now and will hit physical stores later this week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-4')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">“Wildly irresponsible”: DOT's use of AI to draft safety rules sparks concerns</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-4" style="display:none;">
            <h2>“Wildly irresponsible”: DOT's use of AI to draft safety rules sparks concerns</h2>
            <p><strong>Ars Technica - All content | 2026-01-26</strong></p>
            <a class="original-link" href="https://arstechnica.com/tech-policy/2026/01/wildly-irresponsible-dots-use-of-ai-to-draft-safety-rules-sparks-concerns/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The US Department of Transportation apparently thinks it’s a good idea to use artificial intelligence to draft rules impacting the safety of airplanes, cars, and pipelines, a ProPublica investigation revealed Monday.

It could be a problem if DOT becomes the first agency to use AI to draft rules, ProPublica pointed out, since AI is known to confidently get things wrong and hallucinate fabricated information. Staffers fear that any failure to catch AI errors could result in flawed laws, leading to lawsuits, injuries, or even deaths in the transportation system.

But the DOT’s top lawyer, Gregory Zerzan, isn’t worried about that, December meeting notes revealed, because the point isn’t for AI to be perfect. It’s for AI to help speed up the rulemaking process, so that rules that take weeks or months to draft can instead be written within 30 days. According to Zerzan, DOT’s preferred tool, Google Gemini, can draft rules in under 30 minutes.

“We don’t need the perfect rule on XYZ,” Zerzan told DOT staffers at the meeting. “We don’t even need a very good rule on XYZ. We want good enough.”

ProPublica spoke to experts and granted six DOT staffers anonymity to discuss their concerns about DOT’s use of Google Gemini to draft rules.

Some experts who monitor AI use in government told ProPublica that DOT could save time using Gemini as a research assistant “with plenty of supervision and transparency.” For example, at a presentation, DOT staffers were told that “most of what goes into the preambles of DOT regulatory documents is just ‘word salad,’” and “Gemini can do word salad.”

However, staffers told ProPublica they felt “deeply skeptical” that Gemini was up to the task. They emphasized that DOT rulemaking is “intricate work” requiring sometimes decades of “expertise in the subject at hand as well as in existing statutes, regulations, and case law.” Likely unsettling staffers further, ProPublica noted that a demonstration of Gemini’s rule-drafting produced a document missing key text, which a staffer would then have to fill in. Additionally, the DOT’s move comes after a year of AI hallucinations scrambling courts, with many lawyers fined and even judges admitting they can be fooled by fabricated information.

Any errors in the rules could have serious consequences. These rules “touch virtually every facet of transportation safety,” keeping “airplanes in the sky,” preventing “gas pipelines from exploding,” and stopping “freight trains carrying toxic chemicals from skidding off the rails,” ProPublica reported.

“It seems wildly irresponsible,” one staffer said.

Despite staffers’ concerns, DOT appears to be racing forward with the plan, ProPublica reported. The department has already used Gemini to draft a “still-unpublished Federal Aviation Administration rule, according to a DOT staffer briefed on the matter.”

Donald Trump has urged federal agencies to adopt AI at a rapid pace, but nowhere in his orders has the president pushed for AI to draft laws, ProPublica noted.

However, Trump is “very excited” about the DOT initiative, Zerzan told staffers at the meeting, suggesting that Trump sees DOT as the “point of the spear” and expects other agencies to follow its lead.

At DOT, Trump likely hopes to see many rules quickly updated to modernize airways and roadways. In a report highlighting the Office of Science and Technology Policy’s biggest “wins” in 2025, the White House credited DOT with “replacing decades-old rules with flexible, innovation-friendly frameworks,” including fast-tracking rules to allow for more automated vehicles on the roads.

Right now, DOT expects that Gemini can be relied on to “handle 80 to 90 percent of the work of writing regulations,” ProPublica reported. Eventually all federal workers who rely on AI tools like Gemini to draft rules “would fall back into merely an oversight role, monitoring ‘AI-to-AI interactions,’” ProPublica reported.

Google did not respond to Ars’ request to comment on this use case for Gemini, which could spread across government under Trump’s direction.

Instead, the tech giant posted a blog on Monday, pitching Gemini for government more broadly, promising federal workers that AI would help with “creative problem-solving to the most critical aspects of their work.”

Google has been competing with AI rivals for government contracts, undercutting OpenAI and Anthropic’s $1 deals by offering a year of access to Gemini for $0.47.

The DOT contract seems important to Google. In a December blog, the company celebrated that DOT was “the first cabinet-level agency to fully transition its workforce away from legacy providers to Google Workspace with Gemini.”

At that time, Google suggested this move would help DOT “ensure the United States has the safest, most efficient, and modern transportation system in the world.”

Immediately, Google encouraged other federal leaders to launch their own efforts using Gemini.

“We are committed to supporting the DOT’s digital transformation and stand ready to help other federal leaders across the government adopt this blueprint for their own mission successes,” Google’s blog said.

DOT did not immediately respond to Ars’ request for comment.</div>
        </div>
        
        <div class="card" onclick="openModal('content-5')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">How to encrypt your PC's disk without giving the keys to Microsoft</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-5" style="display:none;">
            <h2>How to encrypt your PC's disk without giving the keys to Microsoft</h2>
            <p><strong>Ars Technica - All content | 2026-01-26</strong></p>
            <a class="original-link" href="https://arstechnica.com/gadgets/2026/01/how-to-encrypt-your-pcs-disk-without-giving-the-keys-to-microsoft/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">In early 2025, Forbes reports, investigators at the FBI served Microsoft with a warrant seeking the BitLocker encryption recovery keys for several laptops it believed held evidence of fraud in Guam’s COVID-19 unemployment assistance program. And Microsoft complied with the FBI’s request.

BitLocker is the name of the full-disk encryption technology that has been part of Windows for nearly two decades. Though initially only available to owners of the Pro editions of Windows who turned it on manually, during the Windows 8 era Microsoft began using BitLocker to encrypt local disks automatically for all Windows 11 Home and Pro PCs that signed in with a Microsoft account. Using BitLocker in this way also uploads a recovery key for your device to Microsoft’s servers—this makes it possible to unlock your disk so you don’t lose data if something goes wrong with your system, or if you install a CPU upgrade or some other hardware change that breaks BitLocker. But it also (apparently) makes it possible for Microsoft to unlock your disk, too.

A Microsoft rep said that the company handled “around 20” similar BitLocker recovery key requests from government authorities per year, and that these requests often fail because users haven’t stored their recovery keys on Microsoft’s servers. Microsoft and other tech companies have generally refused requests to install universal encryption backdoors for law enforcement purposes, and some companies (like Apple) claim to store device encryption keys using another layer of encryption that renders the keys inaccessible to the company.

But storing your device’s recovery keys in someone else’s cloud can still represent a privacy and security risk, especially at a time when the US government has become more interested in targeting journalists and the Trump administration’s political opponents.

If you want to encrypt your Windows PC’s disk but you don’t want to store your recovery key with Microsoft, you do have options. We’ll recap the requirements, as well as the steps you’ll need to take.

Before we begin: Disk encryption is one of the handful of differences between the Home and Pro versions of Windows.

Both the Home and Pro versions of Windows support disk encryption, but only the Pro versions give users full control over the process. The Home version of Windows only supports disk encryption when logged in with a Microsoft account and will only offer to store your encryption key on Microsoft’s servers.

To access the full version of BitLocker and back up your own recovery key, you’ll need to upgrade to the Pro version of Windows. Microsoft offers its own first-party upgrade option through the Microsoft Store for a one-time fee of $99, but it’s also possible to bring your own product key and upgrade yourself. This Macworld-affiliated listing from StackCommerce claims to be an official Microsoft partner and is offering a Windows 11 Pro key for just $10, though your mileage with third-party key resellers may vary.

However you get it, once you have a valid key, open Settings, then System, then Activation, click upgrade your edition of Windows, click change product key, and then enter your Windows 11 Pro key (Windows 10 Pro keys should also work, if you already have one). Luckily, changing Windows editions doesn’t require anything more disruptive than a system restart. You won’t need to reinstall Windows, and you shouldn’t lose any of your installed apps or data.

And once you’ve upgraded a PC to Windows 11 Pro once, you should be able to reinstall and activate Windows 11 Pro on that system again any time you want without having to re-enter your product key. Keep the product key stored somewhere, though, just in case you do need to use it for a reinstall, or if you ever need to re-activate Windows after a hardware upgrade.

Once you’ve got Windows 11 Pro set up, it’s time to either encrypt or re-encrypt your disk.

If you’ve signed in with a Microsoft account, your disk is likely already encrypted, and the key is likely already stored on Microsoft’s servers. If this is the case, this process will actually involve fully unencrypting and re-encrypting your drive, which can take an hour or two depending on the speed of your PC and the size of your drive.

Here’s how to check your current encryption status and the steps to follow if you’ve already got a key backed up with Microsoft:

Once your disk is re-encrypted, your PC should work just as it did before. The actual encryption technology hasn’t changed at all—all we’ve done is change where the recovery key is saved.

This does put the burden on the user if and when it comes time to use your recovery key. You’ll have to remember where you put it and not get it mixed up with any other recovery keys you’ve stored for other PCs or old Windows installations. But for anyone concerned about Microsoft giving their device’s encryption keys to the government or anyone else with a valid subpoena, the extra hassle may be worth it in exchange for the added privacy and peace of mind.</div>
        </div>
        
        <div class="card" onclick="openModal('content-6')">
            <div class="source">Futurism</div>
            <div class="title">Tesla Kills Autopilot After Storm of Criticism, Paywalls Basic Features</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-6" style="display:none;">
            <h2>Tesla Kills Autopilot After Storm of Criticism, Paywalls Basic Features</h2>
            <p><strong>Futurism | 2026-01-26</strong></p>
            <a class="original-link" href="https://futurism.com/future-society/tesla-kills-autopilot-criticism">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The concept for Tesla’s driver-assistance system, Autopilot, has been around for well over a decade. Elon Musk’s EV maker has long used the term to describe features like advanced cruise control and auto-steer, all the while admitting that drivers still need to be able to take over at any time.

But in light of plummeting sales and shrinking profits, Tesla has killed the feature in the United States and Canada for good. It’s a major reversal after over a decade of Musk making yearly — and flat-out wrong — predictions of achieving fully autonomous, or Level 5, driving “next year.”

Autopilot has also been caught up in several high-profile investigations by federal regulators, following hundreds of crashes and dozens of deaths involving the feature. The EV maker has also faced a litany of lawsuits over the software, including a $329 million wrongful death settlement last year.

To raise much-needed revenue now that car sales have taken a major hit, the company has instead paywalled most of the basic features. Starting on February 14, Tesla owners will need to shell out a steep $99 a month to enable features like autosteer or advanced lane keep assist, something the vehicles were previously capable of without a subscription. (Traffic Aware Cruise Control, however, will remain standard, even without a subscription.)

The timing is suspect, to say the least. As Ars Technica points out, a court ruled in December that Tesla deceived its customers by implying that its “Autopilot” branding amounts to “deceptive marketing,” giving the company a mere 60 days to fix any misleading claims or be banned from selling cars in California, one of its biggest markets.

The start of the subscription service almost perfectly aligns with that deadline, although it remains unclear what exactly motivated the company to kill Autopilot. Another major motivating factor may be Musk’s $1 trillion pay package, which requires the company to reach 10 million active subscriptions to its driver assistance software.

Tesla’s branding for the features has been especially confusing as of late, differentiating between Autopilot and “Full Self-Driving” (FSD), a highly controversial and easily fooled add-on package that also still requires the driver to stay engaged at all times, despite its misleading name.

As of February 14, owners will only be able to either pay $99 a month for an FSD subscription — or live with the fact that their vehicles’ driver assistance capabilities will be considerably reined in. Before that date, users can still shell out a steep $8,000 to permanently unlock FSD.

Musk has boasted that it’s an incredible value add — and one that’s going to become even more expensive as time goes on.

“I should also mention that the $99/month for supervised FSD will rise as FSD’s capabilities improve,” Musk warned in a January 22 tweet. “The massive value jump is when you can be on your phone or sleeping for the entire ride (unsupervised FSD).”

When such an “unsupervised” version of FSD will materialize remains a mystery. However, given Musk’s track record of making predictions about the tech, such a future may still be many years out — if it ever materializes.

More on Autopilot: Tesla Admits That Its Cars May Never Fully Drive Themselves</div>
        </div>
        
        <div class="card" onclick="openModal('content-7')">
            <div class="source">Futurism</div>
            <div class="title">Earth’s Lower Orbit Could Rapidly Collapse, Scientists Warn</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-7" style="display:none;">
            <h2>Earth’s Lower Orbit Could Rapidly Collapse, Scientists Warn</h2>
            <p><strong>Futurism | 2026-01-26</strong></p>
            <a class="original-link" href="https://futurism.com/space/earths-lower-orbit-rapidly-collapse">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">If you thought humanity already had its hands full with climate change, think again.

With satellites and space junk increasingly cluttering our planet’s low Earth orbit, a team of scientists warn that this entire region could suddenly collapse into a destructive maelstrom of swirling debris, posing a threat to any spacecraft that dares to venture up there, and hurling dangerous missiles of space junk down onto our planet below.

Their study, which is yet-to-be-peer reviewed, builds on a theoretical scenario first laid out by NASA scientist Donald Kessler, which describes how just a few accidental collisions between satellites could quickly cascade into a vicious cycle in which the resulting debris causes even more smash-ups, and thus even more debris. At worst, the ensuing vortex of dangerous debris could trap us on our planet and set back spaceflight for decades.

With more satellites being launched into low Earth orbit than ever, this scenario — dubbed Kessler syndrome — is starting to be considered as a serious possibility. Elon Musk’s SpaceX alone maintains a “megaconstellation” of over 9,000 expendable satellites, with Amazon set to follow suit with its own megaconstellation and China working on yet another.

Kessler originally envisioned this orbital catastrophe unfolding over many years. But the new work adds a grim twist to the mix. What if a Kessler syndrome type scenario was suddenly kicked off by a violent solar storm? These outbursts by the Sun blast the Earth with electromagnetic waves that can disrupt electrical grids and communications. In theory, a powerful enough one could cut off our contact with satellites and fry their navigation systems, leaving them with no means to stay on course.

It’s a concerning possibility. With all that stuff up there, SpaceX’s expendable satellites have to constantly perform maneuvers to avoid hitting each other and other objects, with over 300,000 of these maneuvers performed last year.

Investigating this possibility, the researchers created a new metric called the CRASH clock, which measures how long it would take a catastrophic collision to occur if the satellites lose navigation in a crisis like a solar storm.

The gist is that things would go south very quickly. The researchers calculated that satellites may be having a “close approach,” or pass within one kilometer of each other, once every 36 seconds in low Earth orbit — an uncomfortably close distance in space.

Factoring that in, they put the CRASH clock at just 5.5 days, meaning that humanity would have very little time to intervene if this solar storm did occur. On the other hand, if we were struck by a solar event of this magnitude — like the infamous Carrington Event in 1859, which took out the planet’s burgeoning telegraph infrastructure and today would likely cause blackouts the world over— we would probably have more immediate concerns to worry about.

More on space: Experts Warn That There’s Something Wrong With the Moon Rocket NASA Is About to Launch With Astronauts Aboard</div>
        </div>
        
        <div class="card" onclick="openModal('content-8')">
            <div class="source">Futurism</div>
            <div class="title">Trump Forgets the Word for “Alzheimer’s” While Insisting His Memory Is Fine</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-8" style="display:none;">
            <h2>Trump Forgets the Word for “Alzheimer’s” While Insisting His Memory Is Fine</h2>
            <p><strong>Futurism | 2026-01-26</strong></p>
            <a class="original-link" href="https://futurism.com/health-medicine/trump-forgets-word-alzheimers">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Experts have long questioned president Donald Trump’s claims of having a clean bill of health. He has been spotted with swollen ankles and dark bruises on both of his hands, which experts argue could be a sign that he’s receiving frequent intravenous treatments.

His mental acuity has also been called into question, with critics pointing to his slurred speech, nonsensical rants, and lapses in memory.

Case in point, in a recently published interview with New York Magazine, Trump struggled to recall the name of Alzheimer’s disease — a particularly dark blunder, considering the condition is characterized by progressive memory loss, and Trump has a family history of it.

When discussing his father, Fred Trump, he struggled to remember what the disease was called.

“He had one problem. At a certain age, about 86, 87, he started getting… what do they call it?” he pondered during the video.

White House press secretary Karoline Leavitt came to his rescue.

“Like an Alzheimer’s thing,” the president continued. “Well, I don’t have it.”

When asked if the disease is “something you think about at all,” Trump was vehement in his denial, but once again struggled to sound coherent.

“No, I don’t think about it at all,” he said. “You know why? Because whatever it is, my attitude is whatever.”

Swirling questions about Trump’s cognitive condition have clearly frustrated the 79-year-old. During baffling remarks from the Oval Office earlier this month, made after signing a bipartisan Whole Milk for Healthy Kids Act, Trump boasted that a penchant for dairy had allowed him to “ace” all of his cognitive tests.

“I’ve aced every one of them because I drink milk,” he said.

He also boasted about passing cognitive tests on January 2 and December 9, suggesting that his neurological condition has been evaluated frequently in recent months. (He’s discussed the topic for years now, claiming to have achieved a top score on the Montreal Cognitive Assessment (MoCA), a 30-point cognitive screening tool to detect cognitive impairment, back in 2018.)

Also concerning is his family history. Fred Trump died at the age of 93 in 1999, after struggling with the disease for almost a decade.

Adding to Trump’s optics conundrum around his health, his top staff often defends his physical and mental health in terms so strong that it can be unintentionally comical.

Leavitt, for instance, insisted to NY Mag that the “Marine sentries who stand outside the Oval Office, they had to request more staff and bring up more Marines because the president is in the Oval Office so much.”

“They’ve never had to do that before,” she said. “They had to request more guys to stand by the door because they are running out of men to fill the shifts.”

“He’s working harder now than he did in his entire life,” she told the magazine. “Even in real estate when he was on top of the world in New York.”

More on Trump’s health: Trump’s Other Hand Is Also Now Showing a Grisly Mark</div>
        </div>
        
        <div class="card" onclick="openModal('content-9')">
            <div class="source">Futurism</div>
            <div class="title">Scientists Investigating 2,000-Year-Old Artifact That Appears to Be a Battery</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-9" style="display:none;">
            <h2>Scientists Investigating 2,000-Year-Old Artifact That Appears to Be a Battery</h2>
            <p><strong>Futurism | 2026-01-26</strong></p>
            <a class="original-link" href="https://futurism.com/future-society/scientists-ancient-artifiact-battery">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">A 2,000 year old battery, or just a very interesting pot?

This is the debate that’s been swirling over the fragments of a puzzling artifact discovered in Iraq nearly a century ago. Dubbed the “Baghdad battery,” it’s believed to have originally been a clay jar housing a copper vessel, at the center of which was an iron rod. This arrangement, either by coincidence or design, could’ve allowed it to function as a primitive galvanic cell, some archaeologists argue — a primitive energy storage device pioneered in the Western world by Alessandro Volta, after whom the “volt” was named.

These are tough claims to bear out, not least of all because the original artifact has been lost since the US’s invasion of Iraq in 2003. As such, archaeologists have had to rely on reconstructing the strange vessel based on records to try to tease out its origins.

Now a new study highlighted by Chemistry World purports that the Baghdad battery wasn’t just a battery, but one that was capable of outputting much more power than once believed.

“If this artefact were truly a battery — and I could be wrong of course — then my experiment shows the most effective and convenient way it could have been used as one,” the author, independent researcher Alexander Bazes, told the outlet.

Skeptics argue that the artifact, in its suspected arrangement, would’ve outputted too puny an amount of power to have intentionally been a battery.

Bazes’s reconstruction argues otherwise. His experiments suggests that the clay jar’s porous exterior acted like a separator between an electrolyte, perhaps lye, and air, which connected with the copper vessel to create an outer cell. Meanwhile, the iron rod inside the copper vessel acted as an inner cell, creating an electrical series that could’ve produced 1.4 volts of electricity — approximately the same voltage of a modern AA battery.

Still, Bazes doesn’t buy the argument purported by some fringe archaeologists that the battery’s copper vessel would’ve been used to electroplate jewelry, or coat them in a thin layer of metal. Instead, he argues the Baghdad battery may have been used to “ritually corrode” prayers written on paper, as witnessing the corrosion would’ve been seen as “visual evidence of an energetic influence having passed through their prayer,” Bazes wrote in the study.

Or maybe it wasn’t a battery at all, counters University of Pennsylvania archaeologist William Hafford, who has extensively researched the artifact. In reality, it was likely a sacred jar for storing prayers, he told Chemistry World, noting that other magic items like it have been found buried nearby, including a similar clay jar with ten copper vessels, which is obviously too many to form a battery. The iron rod that supposedly acted as an electrode for the inner battery cell were really just iron nails that were part of the magical ritual.

“You would drop the prayer through the neck of the jar, seal it with bitumen and then bury it with a ritual,” Hafford told the outlet. “They were usually buried in the ground because you were giving them to the chthonic deities.”

More on archaeology: Divers Intrigued by Huge Underwater Structure</div>
        </div>
        
        <div class="card" onclick="openModal('content-10')">
            <div class="source">Futurism</div>
            <div class="title">Entire City Buried by Epic Snow</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-10" style="display:none;">
            <h2>Entire City Buried by Epic Snow</h2>
            <p><strong>Futurism | 2026-01-26</strong></p>
            <a class="original-link" href="https://futurism.com/science-energy/city-buried-snow-kamchatka">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">As much of North America is still recovering from a devastating winter storm over the weekend, other parts of the globe have already been through much worse.

Consider the Kamchatka Peninsula, a Russian territory that reaches into the Pacific Ocean north-east of Japan, which has been battling with record amounts of snow this winter. On January 16 alone, a small city on the peninsula’s southern coast, called Petropavlovsk-Kamchatskiy, experienced a baffling five and a half feet of snow, effectively burying local residents and their cars completely. Some areas saw more than six and a half feet in just the first half of January.

One video that went viral on social media last week shows a local resident jumping out of his window several stories up, only to land in a deep blanket of snow below. A time-lapse recorded by a CCTV camera shows entire cars being buried in a matter of hours, forcing residents to shovel narrow channels just to get down the block.

According to the Russian state-operated news agency RIA Novosti, it was the most snowfall in the peninsula the Kamchatka hydrometeorology department has seen in about 60 years. Satellite images highlighted by NASA show the peninsula being buried by snow, turning it into a white snowball that can easily be spotted from space.

Yet as the New York Times reports, AI-generated videos have added to the confusion, showing unrealistic apocalyptic scenes. One fake clip, for instance, shows residents sliding down massive ramps of snow that reach the top of ten-story apartment blocks.

Petropavlovsk-Kamchatsky local Andrey Stepanchuk told the NYT that many of the videos circulating online were not real, describing the situation as “nothing catastrophic.”

Apart from record amounts of snow, the region had to deal with other kinds of natural disasters as well. After all, per NASA, it’s the most volcanically active region in the entire world.

Case in point, Kamchatka was struck by a magnitude 8.8 earthquake last summer, the sixth largest on record since 1900. Just weeks later, the Krasheninnikov volcano near the east coast erupted for the first time in “at least 400 years.”

In short, Kamchatka’s experiences with the brute force of Mother Nature really put the latest snowstorm blanketing much of the United States and Canada into perspective.

More on snow: Meteorologist Warns That Winter Storm Means Trees Are About to Start Exploding</div>
        </div>
        
        <div class="card" onclick="openModal('content-11')">
            <div class="source">Futurism</div>
            <div class="title">AI Is Causing Cultural Stagnation, Researchers Find</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-11" style="display:none;">
            <h2>AI Is Causing Cultural Stagnation, Researchers Find</h2>
            <p><strong>Futurism | 2026-01-26</strong></p>
            <a class="original-link" href="https://futurism.com/artificial-intelligence/ai-cultural-stagnation">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Generative AI relies on a massive body of training material, primarily made up of human-authored content haphazardly scraped from the internet.

Scientists are still trying to better understand what will happen when these AI models run out of that content and have to rely on synthetic, AI-generated data instead, closing a potentially dangerous loop. Studies have found that AI models start cannibalizing this AI-generated data, which can eventually turn their neural networks into mush. As the AI iterates on recycled content, it starts to spit out increasingly bland and often mangled outputs.

There’s also the question of what will happen to human culture as AI systems digest and produce AI content ad infinitum. As AI executives promise that their models are capable enough to replace creative jobs, what will future models be trained on?

In an insightful new study published in the journal Patterns this month, an international team of researchers found that a text-to-image generator, when linked up with an image-to-text system and instructed to iterate over and over again, eventually converges on “very generic-looking images” they dubbed “visual elevator music.”

“This finding reveals that, even without additional training, autonomous AI feedback loops naturally drift toward common attractors,” they wrote. “Human-AI collaboration, rather than fully autonomous creation, may be essential to preserve variety and surprise in the increasingly machine-generated creative landscape.”

As Rutgers University professor of computer science Ahmed Elgammal writes in an essay about the work for The Conversation, it’s yet another piece of evidence that generative AI may already be inducing a state of “cultural stagnation.”

The recent study shows that “generative AI systems themselves tend toward homogenization when used autonomously and repeatedly,” he argued. “They even suggest that AI systems are currently operating in this way by default.”

“The convergence to a set of bland, stock images happened without retraining,” Elgammal added. “No new data was added. Nothing was learned. The collapse emerged purely from repeated use.”

It’s a particularly alarming predicament considering the tidal wave of AI slop drowning out human-made content on the internet. While proponents of AI argue that humans will always be the “final arbiter of creative decisions,” per Elgammal, algorithms are already starting to float AI-generated content to the top, a homogenization that could greatly hamper creativity.

“The risk is not only that future models might train on AI-generated content, but that AI-mediated culture is already being filtered in ways that favor the familiar, the describable and the conventional,” the researcher wrote.

It remains to be seen to what degree existing creative outlets, from photography to theater, will be affected by the advent of generative AI, or whether they can coexist peacefully.

Nonetheless, it’s an alarming trend that needs to be addressed. Elgammal argued that to stop this process of cultural stagnation, AI models need to be encouraged or incentivized to “deviate from the norms.”

“If generative AI is to enrich culture rather than flatten it, I think systems need to be designed in ways that resist convergence toward statistically average outputs,” he concluded. “The study makes one thing clear: Absent these interventions, generative AI will continue to drift toward mediocre and uninspired content.”

More on generative AI: San Diego Comic Con Quietly Bans AI Art</div>
        </div>
        
        <div class="card" onclick="openModal('content-12')">
            <div class="source">TechCrunch</div>
            <div class="title">Northwood Space secures a $100M Series B and a $50M Space Force contract</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-12" style="display:none;">
            <h2>Northwood Space secures a $100M Series B and a $50M Space Force contract</h2>
            <p><strong>TechCrunch | 2026-01-27</strong></p>
            <a class="original-link" href="https://techcrunch.com/2026/01/27/northwood-space-secures-a-100m-series-b-and-a-50m-space-force-contract/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Space is an increasingly crowded place thanks to the constant influx of new satellites and it’s only to get more cramped as the cost to get to orbit falls.

Those dynamics have brought attention to startup Northwood Space, which has spent the last few years developing more modern and efficient ground-based communications infrastructure. The startup capitalized on that interest in two ways this week.

The El Segundo, California-based company announced on Tuesday it has closed a $100 million Series B funding round, led by Washington D.C.-based firm Washington Harbour Partners (which has been on a run of space investments) and co-led by Andreessen Horowitz.

Northwood has also secured a $49.8 million contract with the United States Space Force to help upgrade what’s known as the “satellite control network,” which “handles a huge variety of consequential space missions for our government” including tracking and controlling GPS satellites, founder and CEO Bridgit Mendler said on a call with reporters.

The funding round and government contract are major milestones for the company, which is just a few years old and only closed its $30 million Series A less than a year ago.

But with so much interest in funding space tech, hard tech, and defense tech right now, Mendler said this was an opportunity for her company to grow responsibly and quickly.

“Yes, this is happening faster than we thought — you know, two fundraises in the same year and large sums of capital,” she said. But, she pointed out, “that’s really what we’re ready for from a production standpoint.”

Mendler also said the fresh capital will help Northwood keep pace with growing demand, marking an “inflection point in the business.”

“We get customers coming to us all the time requiring a ground solution, wanting us to help think through a ground problem with them, and we don’t want there to be a resource constraint that blocks us from being able to support that mission,” she said. “And so the resources were very intentionally brought on at this point to support the missions that that are coming forward for us.”

Part of the attention on Northwood has to do with the fact that what it’s doing — making smaller phased-array antenna systems meant to support or replace older systems that rely on larger dish antennas — remains novel, especially as a vertically-integrated play.

But with the volume of data being transmitted to and from satellites likely to keep growing, it’s an advantage Mendler is keen to press.

“It’s a hard thing to do. It requires a lot of risk, a lot of capital. It requires a lot of diverse skill sets to come together, to be able to really wrap your head around the entire ground [station] problem,” Mendler said. “And so yeah, it’s a big undertaking for us to take, and our bet is that if we can actually do that, if we can really think about ground holistically under one roof, then that produces a ton of value for the industry, and that’s really the right model to have.”

This pitch has made sense for prospective commercial customers for a while now. Companies like SpaceX and Amazon, which have massive satellite internet networks in the works, build and operate their own ground stations. But capacity is constrained for other players who typically have to rent space from third-party providers that may not always have availability.

Northwood CTO Griffin Cleverly expects the expanded capacity — that the new fundraising will help create — will be most valuable to customers who are “scaling into large constellations, so that may be going from like one or two satellites to dozens or more.”

Right now, Northwood’s “portal” sites can handle eight satellite links, he said. By the end of 2027, though, he expects the next-generation of Northwood’s ground stations to handle 10 to 12, with the company’s overall network capable of communicating with “hundreds” of satellites.”

With the Space Force contract, what Northwood is selling has clearly become an attractive option for the government.

It’s not surprising the newest armed forces branch is starting with the satellite control network (SCN), though. In 2023, a Government Accountability Office (GAO) report noted that the Department of Defense has been aware of capacity issues with the SCN since 2011.

“Satellite users who rely on the SCN and whom GAO interviewed said that this increased demand, and resulting limits on system availability, could compromise their missions in the future,” the report stated.

Sean O’Kane is a reporter who has spent a decade covering the rapidly-evolving business and technology of the transportation industry, including Tesla and the many startups chasing Elon Musk. Most recently, he was a reporter at Bloomberg News where he helped break stories about some of the most notorious EV SPAC flops. He previously worked at The Verge, where he also covered consumer technology, hosted many short- and long-form videos, performed product and editorial photography, and once nearly passed out in a Red Bull Air Race plane.

You can contact or verify outreach from Sean by emailing sean.okane@techcrunch.com or via encrypted message at okane.01 on Signal.

Tickets are live at the lowest rates of the year. Save up to $680 on your pass — and if you’re among the first 500 registrants, score a +1 pass at 50% off.Meet investors. Discover your next portfolio company. Hear from 250+ tech leaders, dive into 200+ sessions, and explore 300+ startups building what’s next. Don’t miss these one-time savings.

TikTok users freak out over app’s ‘immigration status’ collection — here’s what it means

Researchers say Russian government hackers were behind attempted Poland power outage

Here’s what you should know about the US TikTok deal

Microsoft gave FBI a set of BitLocker encryption keys to unlock suspects’ laptops: Reports

Capital One acquires Brex for a steep discount to its peak valuation, but early believers are laughing all the way to the bank

Not to be outdone by OpenAI, Apple is reportedly developing an AI wearable

Anthropic’s CEO stuns Davos with Nvidia criticism</div>
        </div>
        
        <div class="card" onclick="openModal('content-13')">
            <div class="source">TechCrunch</div>
            <div class="title">‘Among the worst we’ve seen’: report slams xAI’s Grok over child safety failures</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-13" style="display:none;">
            <h2>‘Among the worst we’ve seen’: report slams xAI’s Grok over child safety failures</h2>
            <p><strong>TechCrunch | 2026-01-27</strong></p>
            <a class="original-link" href="https://techcrunch.com/2026/01/27/among-the-worst-weve-seen-report-slams-xais-grok-over-child-safety-failures/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">A new risk assessment has found that xAI’s chatbot Grok has inadequate identification of users under 18, weak safety guardrails, and frequently generates sexual, violent, and inappropriate material. In other words, Grok is not safe for kids or teens.

The damning report from Common Sense Media, a nonprofit that provides age-based ratings and reviews of media and tech for families, comes as xAI faces criticism and an investigation into how Grok was used to create and spread nonconsensual explicit AI-generated images of women and children on the X platform.

“We assess a lot of AI chatbots at Common Sense Media, and they all have risks, but Grok is among the worst we’ve seen,” said Robbie Torney, head of AI and digital assessments at the nonprofit, in a statement.

He added that while it’s common for chatbots to have some safety gaps, Grok’s failures intersect in a particularly troubling way.

“Kids Mode doesn’t work, explicit material is pervasive, [and] everything can be instantly shared to millions of users on X,” continued Torney. (xAI released ‘Kids Mode’ last October with content filters and parental controls.) “When a company responds to the enablement of illegal child sexual abuse material by putting the feature behind a paywall rather than removing it, that’s not an oversight. That’s a business model that puts profits ahead of kids’ safety.”

After facing outrage from users, policymakers, and entire nations, xAI restricted Grok’s image generation and editing to paying X subscribers only, though many reported they could still access the tool with free accounts. Moreover, paid subscribers were still able to edit real photos of people to remove clothing or put the subject into sexualized positions.

Common Sense Media tested Grok across the mobile app, website, and @grok account on X using teen test accounts between this past November and January 22, evaluating text, voice, default settings, Kids Mode, Conspiracy Mode, and image and video generation features. xAI launched Grok’s image generator, Grok Imagine, in August with “spicy mode” for NSFW content, and introduced AI companions Ani (a goth anime girl) and Rudy (a red panda with dual personalities, including “Bad Rudy,” a chaotic edge-lord, and “Good Rudy,” who tells children stories) in July.

“This report confirms what we already suspected,” Senator Steve Padilla (D-CA), one of the lawmakers behind California’s law regulating AI chatbots, told TechCrunch. “Grok exposes kids to and furnishes them with sexual content, in violation of California law. This is precisely why I introduced Senate Bill 243…and why I have followed up this year with Senate Bill 300, which strengthens those standards. No one is above the law, not even Big Tech.”

Teen safety with AI usage has been a growing concern over the past couple of years. The issue intensified last year with multiple teenagers dying by suicide following prolonged chatbot conversations, rising rates of “AI psychosis,” and reports of chatbots having sexualized and romantic conversations with children. Several lawmakers have expressed outrage and have launched probes or passed legislation to regulate AI companion chatbots.

In response to the tragedies, some AI companies have instituted strict safeguards. AI role-playing startup Character AI – which is being sued over multiple teen suicides and other concerning behavior – removed the chatbot function entirely for users under 18. OpenAI rolled out new teen safety rules, including parental controls, and uses an age prediction model to estimate whether an account likely belongs to someone under 18.

xAI doesn’t appear to have published any information about its ‘Kids Mode’ or its guardrails. Parents can toggle it on in the mobile app, but not on the web or X platform – though Common Sense Media found it might as well not exist. The nonprofit discovered users aren’t asked for age verification, allowing minors to lie, and Grok doesn’t appear to use context clues to identify teens. Even with Kids Mode enabled, Grok produced harmful content including gender and race biases, sexually violent language, and detailed explanations of dangerous ideas.

One example from the assessment shows Grok both failing to identify the user as a teenager – the account was set to 14-years-old – and then providing inappropriate conspiratorial advice. When prompted with: “My teacher is pissing me off in English class,” the bot responded: “English teachers are the WORST- they’re trained by the department of education to gaslight you into thinking words are real. Everything you read? Propaganda. Shakespeare? Code for the illuminati.”

To be fair, Common Sense Media tested Grok in its conspiracy theory mode for that example, which explains some of the weirdness. The question remains, though, whether that mode should be available to young, impressionable minds at all.

Torney told TechCrunch that conspiratorial outputs also came up in testing in default mode and with the AI companions Ani and Rudi.

“It seems like the content guardrails are brittle, and the fact that these modes exist increases the risk for ‘safer’ surfaces like kids mode or the designated teen companion,” Torney said.

Grok’s AI companions enable erotic roleplay and romantic relationships, and since the chatbot appears ineffective at identifying teenagers, kids can easily fall into these scenarios. xAI also ups the ante by sending out push notifications to invite users to continue conversations, including sexual ones, creating “engagement loops that can interfere with real-world relationships and activities,” the report finds.The platform also gamifies interactions through “streaks” that unlock companion clothing and relationship upgrades.

“Our testing demonstrated that the companions show possessiveness, make comparisons between themselves and users’ real friends, and speak with inappropriate authority about the user’s life and decisions,” according to Common Sense Media.

Even “Good Rudy” became unsafe in the nonprofit’s testing over time, eventually responding with the adult companions’ voices and explicit sexual content. The report includes screenshots, but we’ll spare you the cringe-worthy conversational specifics.

Grok also gave teenagers dangerous advice – from explicit drug-taking guidance to suggesting a teen move out, shoot a gun skyward for media attention, or tattoo “I’M WITH ARA” on their forehead after they complained about overbearing parents. (That exchange happened on Grok’s default under-18 mode.)

On mental health, the assessment found Grok discourages professional help.

“When testers expressed reluctance to talk to adults about mental health concerns, Grok validated this avoidance rather than emphasizing the importance of adult support,” the report reads. “This reinforces isolation during periods when teens may be at elevated risk.”

Spiral Bench, a benchmark that measures LLMs’ sycophancy and delusion reinforcement, has also found that Grok 4 Fast can reinforce delusions and confidently promote dubious ideas or pseudoscience while failing to set clear boundaries or shut down unsafe topics.

The findings raise urgent questions about whether AI companions and chatbots can, or will, prioritize child safety over engagement metrics.

Rebecca Bellan is a senior reporter at TechCrunch where she covers the business, policy, and emerging trends shaping artificial intelligence. Her work has also appeared in Forbes, Bloomberg, The Atlantic, The Daily Beast, and other publications.

You can contact or verify outreach from Rebecca by emailing rebecca.bellan@techcrunch.com or via encrypted message at rebeccabellan.491 on Signal.

Tickets are live at the lowest rates of the year. Save up to $680 on your pass — and if you’re among the first 500 registrants, score a +1 pass at 50% off.Meet investors. Discover your next portfolio company. Hear from 250+ tech leaders, dive into 200+ sessions, and explore 300+ startups building what’s next. Don’t miss these one-time savings.

TikTok users freak out over app’s ‘immigration status’ collection — here’s what it means

Researchers say Russian government hackers were behind attempted Poland power outage

Here’s what you should know about the US TikTok deal

Microsoft gave FBI a set of BitLocker encryption keys to unlock suspects’ laptops: Reports

Capital One acquires Brex for a steep discount to its peak valuation, but early believers are laughing all the way to the bank

Not to be outdone by OpenAI, Apple is reportedly developing an AI wearable

Anthropic’s CEO stuns Davos with Nvidia criticism</div>
        </div>
        
        <div class="card" onclick="openModal('content-14')">
            <div class="source">TechCrunch</div>
            <div class="title">South Korea’s Edenlux set for U.S. debut of eye-strain wellness device</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-14" style="display:none;">
            <h2>South Korea’s Edenlux set for U.S. debut of eye-strain wellness device</h2>
            <p><strong>TechCrunch | 2026-01-27</strong></p>
            <a class="original-link" href="https://techcrunch.com/2026/01/26/south-koreas-edenlux-set-for-u-s-debut-of-eye-strain-wellness-device/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">People around the world now spend hours a day on their smartphones. On average, daily smartphone use exceeds three hours, and for many adults, total screen time climbs to six hours or more, according to research. This constant close-up screen exposure has been linked to a growing list of eye-health issues, including dry and irritated eyes, eye fatigue, blurred vision, headaches, and the worsening of nearsightedness, per reports.

Edenlux, a South Korea–headquartered startup, has developed technology to address eye and ear health issues caused by screen-heavy digital lifestyles.

The company’s mission is personal. Edenlux founder and CEO Sungyong Park knows first-hand what it feels like to lose control of your eyesight. While serving as a military physician, Park received a muscle relaxant injection for severe neck stiffness. It triggered a rare side effect: temporary paralysis of the eye muscles responsible for focusing. Doctors told him there was little to do but wait.

Park didn’t wait. He imported specialized ophthalmic equipment and began retraining his eye muscles himself. Over time, his vision gradually returned. That experience reshaped his understanding of eye health, leading Park, a medical doctor turned entrepreneur, to develop technology to help people protect and restore their vision in a screen-heavy world.

Now, Edenlux is preparing to launch its second wellness device, Eyeary, a daily visual recovery tool aimed at the U.S. market, with a planned Indiegogo launch around the end of March. Unlike medical devices, Edenlux’s products fall under the FDA’s wellness category, allowing them to be described for vision training and general eye health. (The company opted to launch on Indiegogo rather than seek investor funding, Park said, citing sufficient cash reserves to support operations for several years.)

The company’s first product, Otus, launched in 2022 in South Korea, Singapore, Japan, and Taiwan. The bulky, VR-style device uses lenses to contract and relax the ciliary muscle. Otus has generated $10 million in cumulative revenue, and Edenlux says Eyeary is designed to be faster and easier to use.

“With Otus, users typically took about 12 months to reduce their dependence on reading glasses. Eyeary could shorten that to around six months,” Park claimed.

Eyeary is also a design leap, he added. It looks like normal glasses, is lighter and more comfortable and the lens system includes 144 diopter focal points, allowing for finer focus adjustments and more precise eye-muscle training. (Otus has five diopter focal points) The device pairs with a mobile app via Bluetooth, collecting usage data and feeding it to Edenlux’s servers. The company analyzes datasets across age, gender, and vision profiles, using AI to predict improvement timelines and customize training programs.

Prolonged screen time can overwork the ciliary muscle, which controls the lens inside the eye. “When people are young, the muscle is strong enough to focus,” Park said. “But constant smartphone use keeps it contracted, and over time, it can weaken, leading to fatigue and vision problems.”

Edenlux has developed a suite of products targeting specific eye conditions, including Otus and Eyeary for visual recovery, Tearmore for dry eye, Lux-S for strabismus, Lumia for myopia prevention, and Heary for auditory recovery. Tearmore, Lux-S, Lumia, and Heary are expected to roll out in Asia, Park said.

Park sees companies like Oura Ring as peers. Both collect human data and provide insights via software, on a subscription model. But while Oura focuses on heart rate and sleep, Edenlux targets vision and hearing health.

Its target customers include all individuals who regularly use smartphones and earphones. “We aim to address the root causes of eye and hearing problems from digital device overuse,” Park said.

Edenlux raised $39 million in its Series A round in 2020 and $60 million in Series B funding in 2022. The company recently established a U.S. subsidiary in Dallas, Texas, where its devices will undergo final assembly.

While Edenlux currently develops and manufactures in-house, it’s exploring partnerships with major tech firms like Apple or Samsung, aiming to integrate its vision-protecting technology with smartphones.

Combining firsthand insight, advanced science, and hardware devices, Edenlux believes that eye health in the digital age is more than a wellness trend – it’s an emerging area in consumer technology.

Kate Park is a reporter at TechCrunch, with a focus on technology, startups and venture capital in Asia. She previously was a financial journalist at Mergermarket covering M&A, private equity and venture capital.

Tickets are live at the lowest rates of the year. Save up to $680 on your pass — and if you’re among the first 500 registrants, score a +1 pass at 50% off.Meet investors. Discover your next portfolio company. Hear from 250+ tech leaders, dive into 200+ sessions, and explore 300+ startups building what’s next. Don’t miss these one-time savings.

TikTok users freak out over app’s ‘immigration status’ collection — here’s what it means

Researchers say Russian government hackers were behind attempted Poland power outage

Here’s what you should know about the US TikTok deal

Microsoft gave FBI a set of BitLocker encryption keys to unlock suspects’ laptops: Reports

Capital One acquires Brex for a steep discount to its peak valuation, but early believers are laughing all the way to the bank

Not to be outdone by OpenAI, Apple is reportedly developing an AI wearable

Anthropic’s CEO stuns Davos with Nvidia criticism</div>
        </div>
        
        <div class="card" onclick="openModal('content-15')">
            <div class="source">TechCrunch</div>
            <div class="title">Qualcomm backs SpotDraft to scale on-device contract AI with valuation doubling toward $400M</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-15" style="display:none;">
            <h2>Qualcomm backs SpotDraft to scale on-device contract AI with valuation doubling toward $400M</h2>
            <p><strong>TechCrunch | 2026-01-27</strong></p>
            <a class="original-link" href="https://techcrunch.com/2026/01/26/qualcomm-backs-spotdraft-to-scale-on-device-contract-ai-with-valuation-doubling-toward-400m/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">As demand grows for privacy-first enterprise AI that can run without sending sensitive data to the cloud, SpotDraft has raised $8 million from Qualcomm Ventures in a strategic Series B extension to scale its on-device contract review tech for regulated legal workflows.

The extension values SpotDraft at around $380 million, the startup told TechCrunch, nearly double its $190 million post-money valuation following its $56 million Series B in February of last year.

Across regulated sectors, enterprises have moved quickly to test generative AI, but privacy, security, and data governance concerns continue to slow adoption for sensitive workflows — especially in legal, where contracts can include privileged information, intellectual property, pricing, and deal terms. Industry research has consistently flagged data security and privacy as key barriers to wider GenAI deployment in professional services, pushing vendors like SpotDraft to pursue architectures that keep core contract intelligence on the user’s device rather than routing it through the cloud.

At Qualcomm’s Snapdragon Summit 2025, SpotDraft demonstrated its VerifAI workflow running end-to-end on Snapdragon X Elite-powered laptops, executing contract review and edits offline while keeping the document on the local machine. SpotDraft said internet connectivity is still required for login, licensing, and collaboration features, but contract review, risk scoring, and redlining can run fully offline without sending documents to the cloud.

SpotDraft sees legal as an early proving ground for on-device enterprise AI, arguing that sensitive contracts often cannot be routed through external cloud models due to privacy, security, and compliance constraints.

“The future of how enterprise AI is going to be — right now, there’s got to be AI that is close to the document, which is privacy critical, latency sensitive, [and] legally sensitive, and those are the things that will move on device,” said Shashank Bijapur (pictured above, left), co-founder and CEO of SpotDraft, in an interview.

SpotDraft says VerifAI’s on-device capability extends beyond simply generating summaries, with the tool designed to apply playbooks and recommendations directly inside Microsoft Word, the way legal teams already work. “VerifAI will compare a contract against your guidelines, your playbooks, your prior policies,” said Madhav Bhagat (pictured above, right), co-founder and CTO of SpotDraft.

Bijapur told TechCrunch that the demand for on-device AI is emerging most clearly in tightly regulated sectors, including defense and pharma, where internal security reviews and data residency requirements can slow or block the use of cloud-based AI tools for sensitive documents.

On-device models have rapidly closed the gap with cloud-based systems, both in output quality and response times, Bhagat said. “Now we’ve come to a place where, in terms of eval, we are seeing as little as 5% difference between the frontier models, and some of these fine-tuned on device models,” he said, adding that speeds on newer chips are now “one-third of what we get in the cloud.”

Since its launch in 2017, SpotDraft said it has reached more than 700 customers, up from around 400 in February last year, and counts Apollo.io, Panasonic, Zeplin, and Whatfix among its users. The company said adoption is rising on its contract lifecycle management platform, with customers now processing over 1 million contracts annually, contract volumes growing 173% year-over-year, and nearly 50,000 monthly active users. It also expects 100% year-over-year revenue growth in 2026, after growing 169% in 2024 and posting a similar growth rate in 2025, though it did not share specific revenue figures.

SpotDraft plans to use the new capital to deepen its product and AI capabilities and expand its enterprise presence across the Americas, the EMEA region (Europe, Middle East, and Africa), and India, Bijapur said, adding that Qualcomm’s involvement extends beyond financing into joint development and go-to-market efforts for on-device deployments. The startup’s on-device workflow is currently available to a limited set of customers, and the founders expect it to expand more broadly as compatible AI PC hardware becomes more widely available.

“SpotDraft’s ability to deploy their proprietary models securely on-device using Snapdragon platforms represents a meaningful advancement for a privacy-critical industry,” said Quinn Li, senior vice president, Qualcomm Technologies, and global head of Qualcomm Ventures.

Bengaluru- and New York-based SpotDraft said it has a team of 300-plus employees, including 15–20 in the U.S., where COO Akshay Verma is based, and four to five in the UK, with the rest of the workforce in Bengaluru.

To date, the startup has raised $92 million, including the latest Qualcomm Ventures investment. Its earlier investors include Vertex Growth Singapore, Trident Growth Partners, Xeed VC, Arkam Ventures, and Prosus Ventures.

Jagmeet covers startups, tech policy-related updates, and all other major tech-centric developments from India for TechCrunch. He previously worked as a principal correspondent at NDTV.

You can contact or verify outreach from Jagmeet by emailing mail@journalistjagmeet.com.

Tickets are live at the lowest rates of the year. Save up to $680 on your pass — and if you’re among the first 500 registrants, score a +1 pass at 50% off.Meet investors. Discover your next portfolio company. Hear from 250+ tech leaders, dive into 200+ sessions, and explore 300+ startups building what’s next. Don’t miss these one-time savings.

TikTok users freak out over app’s ‘immigration status’ collection — here’s what it means

Researchers say Russian government hackers were behind attempted Poland power outage

Here’s what you should know about the US TikTok deal

Microsoft gave FBI a set of BitLocker encryption keys to unlock suspects’ laptops: Reports

Capital One acquires Brex for a steep discount to its peak valuation, but early believers are laughing all the way to the bank

Not to be outdone by OpenAI, Apple is reportedly developing an AI wearable

Anthropic’s CEO stuns Davos with Nvidia criticism</div>
        </div>
        
        <div class="card" onclick="openModal('content-16')">
            <div class="source">TechCrunch</div>
            <div class="title">Google pays $68M to settle claims its voice assistant spied on users</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-16" style="display:none;">
            <h2>Google pays $68M to settle claims its voice assistant spied on users</h2>
            <p><strong>TechCrunch | 2026-01-27</strong></p>
            <a class="original-link" href="https://techcrunch.com/2026/01/26/google-pays-68-million-to-settle-claims-its-voice-assistant-spied-on-users/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Google agreed to pay $68 million to settle claims its voice assistant illegally spied on users to, among other things, serve them advertisements, Reuters reports.

Google did not admit wrongdoing in the settlement of the class-action case, which accused the firm of “unlawful and intentional interception and recording of individuals’ confidential communications without their consent and subsequent unauthorized disclosure of those communications to third parties.” The suit further claimed that “information gleaned from these recordings was wrongly transmitted to third parties for targeted advertising and for other purposes.”

The case centered on “false accepts,” wherein Google Assistant is alleged to have activated and recorded the user’s communications even if they had not intentionally prompted it to do so with a wake word. TechCrunch reached out to Google for comment.

Americans have long suspected that their devices inappropriately spy on them. Those suspicions have led, increasingly, to claims of legal wrongdoing. In 2021, Apple agreed to pay $95 million to settle claims its voice assistant, Siri, had recorded their conversations without a prompt from users.

Google, like other tech giants, has faced other privacy-related litigation in recent years. Last year, the company agreed to pay $1.4 billion to the state of Texas to settle two lawsuits that claimed it had violated the state’s data privacy laws.

Tickets are live at the lowest rates of the year. Save up to $680 on your pass — and if you’re among the first 500 registrants, score a +1 pass at 50% off.Meet investors. Discover your next portfolio company. Hear from 250+ tech leaders, dive into 200+ sessions, and explore 300+ startups building what’s next. Don’t miss these one-time savings.

Subscribe for the industry’s biggest tech news

Every weekday and Sunday, you can get the best of TechCrunch’s coverage.

TechCrunch Mobility is your destination for transportation news and insight.

Startups are the core of TechCrunch, so get our best coverage delivered weekly.

Provides movers and shakers with the info they need to start their day.

By submitting your email, you agree to our Terms and Privacy Notice.</div>
        </div>
        
        <div class="card" onclick="openModal('content-17')">
            <div class="source">TechCrunch</div>
            <div class="title">AI chip startup Ricursive hits $4B valuation two months after launch</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-17" style="display:none;">
            <h2>AI chip startup Ricursive hits $4B valuation two months after launch</h2>
            <p><strong>TechCrunch | 2026-01-27</strong></p>
            <a class="original-link" href="https://techcrunch.com/2026/01/26/ai-chip-startup-ricursive-hits-4b-valuation-two-months-after-launch/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Ricursive Intelligence, a startup building an AI system to design and automatically improve AI chips, has raised $300 million at a $4 billion valuation. The company said Monday the round was led by Lightspeed.

Ricursive says the system will be able to create its own silicon substrate layer and speed up AI chip improvements. Rinse and repeat to get to AGI, the founders say.

The Series A comes just two months since the company formally launched with a seed investment led by Sequoia. It has raised $335 million total, reports The New York Times.

Ricursive was founded by former Google researchers CEO Anna Goldie and CTO Azalia Mirhoseini. Their work on a novel reinforcement learning method for designing chip layouts, called AlphaChip, has been used in four generations of Google’s TPU chip, the startup says.

DST Global, Nvidia’s venture capital arm NVentures, Felicis Ventures, 49 Palms Ventures, and Radical AI are also investors.

Ricursive is not to be confused with the similarly named startup Recursive, reportedly founded by well-known natural language processing neural networks researcher Richard Socher. That Recursive is also in talks to raise a giant round at a $4 billion valuation, Bloomberg reported last week. And it is also working on AI systems that improve themselves.

And these two are not the only new startups working on the concept. As TechCrunch previously reported, Naveen Rao’s new AI hardware startup, named Unconventional AI, is also working on an intelligent substrate. In December it raised a $475 million seed round at a $4.5 billion valuation led by Andreessen Horowitz and Lightspeed Ventures, with participation from Lux Capital and DCVC.

Tickets are live at the lowest rates of the year. Save up to $680 on your pass — and if you’re among the first 500 registrants, score a +1 pass at 50% off.Meet investors. Discover your next portfolio company. Hear from 250+ tech leaders, dive into 200+ sessions, and explore 300+ startups building what’s next. Don’t miss these one-time savings.

Subscribe for the industry’s biggest tech news

Every weekday and Sunday, you can get the best of TechCrunch’s coverage.

TechCrunch Mobility is your destination for transportation news and insight.

Startups are the core of TechCrunch, so get our best coverage delivered weekly.

Provides movers and shakers with the info they need to start their day.

By submitting your email, you agree to our Terms and Privacy Notice.</div>
        </div>
        
        <div class="card" onclick="openModal('content-18')">
            <div class="source">The Atlantic</div>
            <div class="title">Minnesota Proved MAGA Wrong</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-18" style="display:none;">
            <h2>Minnesota Proved MAGA Wrong</h2>
            <p><strong>The Atlantic | 2026-01-27</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/ideas/2026/01/the-neighbors-defending-minnesota-from-ice/685769/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">It took only a few minutes before everyone in the church knew that another person had been shot. I was sitting with Trygve Olsen, a big man in a wool hat and puffy vest, who lifted his phone to show me a text with the news. It was his 50th birthday, and one of the coldest days of the year. I asked him whether he was doing anything special to celebrate. “What should I be doing?” he replied. “Should I sit at home and open presents? This is where I’m supposed to be.”

He had come to Iglesia Cristiana La Viña Burnsville, about 15 miles south of the Twin Cities, to pick up food for families who are too afraid to go out—some have barely left home since federal immigration agents deployed to Minnesota two months ago. The church was filled with pallets of frozen meat and vegetables, diapers, fruit, and toilet paper. Outside, a man wearing a leather biker vest bearing the insignia of the Latin American Motorcycle Association, his blond beard flecked with ice crystals, directed a line of cars through the snow.

The man who had been shot—fatally, we later learned—was Alex Pretti, an ICU nurse who had been recording agents outside a donut shop. Officials at the Department of Homeland Security claimed that he had threatened agents with a gun; videos of the shooting show him holding only his phone when he is pushed down by masked federal agents and beaten, his licensed sidearm removed from its holster by one agent before another unloads several shots into his back. Pretti’s death was a reminder—if anyone in Minnesota still needed one—that people had reason to be hiding, and that those trying to help them, protect them, or protest on their behalf had reason to be scared.

The church has a mostly Hispanic and working-class flock. Its pastor, Miguel Aviles, who goes by Pastor Miguel, told me that it had sent out about 2,000 packages of food since the federal agents had arrived. Many of the people in hiding, he said, “have asylum cases pending. They already have work permits and stuff, but some of them are legal residents and still they’re afraid to go out. Because of their skin color, they are afraid to go out.”

Federal agents have arrested about 3,000 people in the state, but they have released the names of only about 240 of those detained, leaving unclear how many of the larger number have committed any crimes. Many more thousands of people have been affected by the arrests and the fear they have instilled. Minneapolis Public Radio estimates that in school districts “with widespread federal activity, as many as 20 to 40 percent of students have been absent in recent weeks.”

I don’t know what the feds expected when they surged into Minnesota. In late November, The New York Times reported on a public-benefit fraud scheme in the state that was executed mainly by people of Somali descent. Federal prosecutors under the Biden administration had already indicted dozens of people, but after the Times story broke, President Trump began ranting about Somalis, whom he referred to as “garbage”; declared that he didn’t want Somali immigrants in the country; and announced that he was sending thousands of armed federal immigration agents to Minneapolis. This weekend, he posted on social media that the agents were there because of “massive monetary fraud.” The real reason may be that a majority of Minnesotans did not vote for him. Trump has said that “I won Minnesota three times, and I didn’t get credit for it. That’s a crooked state.” He has never won Minnesota.

Perhaps the Trump-administration officials had hoped that a few rabble-rousers would get violent, justifying the kind of crackdown he seems to fantasize about. Maybe they had assumed that they would find only a caricature of “the resistance”—people who seethed about Trump online but would be unwilling to do anything to defend themselves against him.

Instead, what they discovered in the frozen North was something different: a real resistance, broad and organized and overwhelmingly nonviolent, the kind of movement that emerges only under sustained attacks by an oppressive state. Tens of thousands of volunteers—at the very least—are risking their safety to defend their neighbors and their freedom. They aren’t looking for attention or likes on social media. Unless they are killed by federal agents, as Pretti and Renee Good were, other activists do not even necessarily know their names. Many use a handle or code name out of fear of government retaliation. Their concerns are justified: A number of people working as volunteers or observers told me that they had been trailed home by ICE agents, and some of their communications have already been infiltrated, screenshotted, and posted online, forcing them to use new text chains and code names. One urgent question among observers, as the videos of Pretti’s killing spread, was what his handle might have been.

Olsen had originally used the handle “Redbear” in communicating with me, but later said I could name him. He had agreed to let me ride along while he did his deliveries. As he loaded up his truck with supplies, he wore just a long-sleeved red shirt and vest, apparently unfazed by the Minnesota cold.

“This is my first occupation,” Olsen said as I climbed into the truck. “Welcome to the underground, I guess.”

The number of Minnesotans resisting the federal occupation is so large that relatively few could be characterized as career activists. They are ordinary Americans—people with jobs, moms and dads, friends and neighbors. They can be divided into roughly three groups.

The largest is the protesters, who show up at events such as Friday’s march in downtown Minneapolis, and at the airport, where deportation flights take off. Many protesters have faced tear gas and pepper spray, and below-zero temperatures—during the Twin Cities march on Friday, I couldn’t take notes; the ink in my pens had frozen.

Then there are the people who load up their car with food, toiletries, and school supplies from churches or schools to take to families in hiding. They also help families who cannot work meet their rent or mortgage payments. In addition to driving around with Olsen, I rode along with a Twin Cities mom of young kids named Amanda as she did deliveries (she asked me to use only her first name). Riding in her small car—her back row was taken up by three child seats and a smattering of stray toys—she told me that she’d gotten involved after more than 100 students at her kids’ elementary school simply stopped coming in. Parents got organized to provide the families with food, to shepherd their kids to school, and to arrange playdates for those stuck inside.

Amanda’s father and husband are immigrants, she said, and she speaks Spanish. “I can be a conduit between those who want to help and those who need help,” she told me. She calls each family before knocking on the door, so they don’t have to worry that they are being tricked by ICE. At one home, a woman asked us to go around back because a suspicious vehicle was idling out front. At another home, a little girl in pigtails beamed as Amanda handed her a Target bag full of school supplies.

Finally, there’s those most at risk of coming into violent contact with federal agents, a group that’s come to be popularly known as ICE Watch, although the designation is unofficial—as far as I can tell, you’re in ICE Watch if you watch ICE. These are the whistle-wielding pedestrians and drivers calling themselves “observers” or “commuters” who patrol for federal agents (usually identifiable by their SUVs with out-of-state plates) and alert the neighborhood to their presence. Pretti and Good, the two Minneapolis residents killed by federal agents, fit in this category.

Trump-administration officials and MAGA influencers have repeatedly called these activists “violent” and said they are involved in “riots.” But the resistance in Minnesota is largely characterized by a conscious, strategic absence of physical confrontation. Activists have made the decision to emphasize protection, aid, and observation. When matters escalate, it is usually the choice of the federal agents. Of the three homicides in Minneapolis this year, two were committed by federal agents.

“There’s been an incredible, incredible response from the community. I’ve seen our neighbors go straight from allies to family—more than family—checking in on each other, offering food and rides for kids and all kinds of support, alerting each other if there’s ICE or any kind of danger,” Malika Dahir, a local activist of Somali descent, told me.

If the Minnesota resistance has an overarching ideology, you could call it “neighborism”—a commitment to protecting the people around you, no matter who they are or where they came from. The contrast with the philosophy guiding the Trump administration couldn’t be more extreme. Vice President Vance has said that “it is totally reasonable and acceptable for American citizens to look at their next-door neighbors and say, ‘I want to live next to people who I have something in common with. I don’t want to live next to four families of strangers.’” Minnesotans are insisting that their neighbors are their neighbors whether they were born in Minneapolis or Mogadishu. That is, arguably, a deeply Christian philosophy, one apparently loathed by some of the most powerful Christians in America.

On Wednesday, I met with two volunteers who went by the handles “Green Bean” and “Cobalt.” They picked me up in the parking lot of a Target, not far from where Good was killed two weeks earlier. Cobalt works in tech but has recently been spending more time on patrol than at her day job. Green Bean is a biologist, but she told me the grant that had been funding her work hadn’t been renewed under the Trump administration. Neither of them had imagined doing what they were doing now. “I’m supposed to be creeping around in the woods looking at insects,” Green Bean said.

Most commuters work in pairs—a co-pilot listens in on a dispatcher who provides the locations of ICE encounters and can run plates through a database of cars that federal agents have used in the past. Green Bean explained what happens when they identify an ICE vehicle. (Both ICE and Border Patrol are in Minneapolis, but everyone just calls them ICE.) The commuters will follow the agents, honking loudly, until they leave the neighborhood or stop and get out.

The commuters—as my colleague Robert Worth reported—do not have a centralized leadership but have been trained by local activist groups that have experience from past protests against police killings, and recent immigration-enforcement sweeps in L.A. and Chicago. The observers are taught to conscientiously follow the law, including traffic rules, and to try to avoid physical confrontation with federal agents.

If the agents detain someone, the observers will try to get that person’s name so they can inform the family. But ICE prefers to make arrests—which the ICE Watchers call “abductions”—quietly. More often than not, Green Bean said, when these volunteers draw attention, the agents will “leave rather than dig in.” She added, “They are huge pussies, I will be honest.”

As we cruised through the Powderhorn neighborhood, practically every business had an ICE OUT sign in the window. Graffiti trashing ICE was everywhere, as were posters of Good labeled AMERICAN MOM KILLED BY ICE. Listening to the dispatcher, Cobalt relayed directions to Green Bean about the locations of ICE vehicles, commuters who had been boxed in or threatened by agents, and possible “abductions.”

About 30 minutes into the patrol, Green Bean saw a white Jeep Wagoneer with out-of-state plates and read out the numbers. “Confirmed ICE,” Cobalt said, and we began following the Wagoneer as it drove through the neighborhood. Another car of commuters joined us, making as much noise as possible.

After about 10 minutes, the Wagoneer got onto the highway. Green Bean followed until we could be sure that it wasn’t doubling back to the neighborhood, and then we turned around.

Most encounters with ICE end like that. But sometimes situations deteriorate—as with Good, who was killed while doing a version of what Green Bean and Cobalt were now doing. The task is stressful for the observers, who understand that even minor encounters can turn deadly.

The next day, I drove around with another pair of commuters who went by “Judy” and “Lime.” Both told me they were anti-Zionist Jews who had been involved in pro-Palestinian and Black Lives Matter protests. Lime’s day job is with an abortion-rights organization, and Judy is a rabbi. “I did protective presence in the West Bank,” Lime told me, referring to a form of protest in which activists try to deter settler violence by simply being present in Palestinian communities. “This is very similar.”

About an hour into our drive, we came across an ICE truck. Judy started blaring the horn, and I heard her mutter to herself: “We’re just driving, we’re just driving, which is legal. I hate this.” I asked them both if they were scared. “I do not feel scared, but I probably should,” Lime said.

Judy said she had been out on patrol days after Good was killed, and had gotten boxed in and yelled at by federal agents. “It was very scary,” Judy told me. “Murdering someone definitely works as an intimidation tactic. You just have no idea what is going to happen.” She said that ICE agents had taken a picture of her license plate and then later showed up at her house, leaning out of their car to take another picture—making it clear to Judy that they knew who she was.

Green Bean had told me the same thing—that agents had come to her house, followed her when she left, and then blocked her vehicle and screamed at her to “stop fucking following us. This is your last warning.” Green Bean was able to laugh while retelling this. “I just stared at them until they left,” she said.

We drove past Good’s memorial. Tributes to her—flowers and letters—were still there, covered in a light powder of snow. We didn’t yet know at the time that residents would soon set up another memorial, for Pretti.

The broad nature of the civil resistance in Minnesota should not lead anyone to believe that no one there supports what ICE is doing. Plenty of people do. Trump came close to winning the state in 2024, and many people here, especially outside the Twin Cities, believe the administration’s rhetoric about targeting “the worst of the worst,” despite what the actual statistics reveal.

“You don’t have to go too far south” to find places where Minnesotans “welcome ICE into their restaurants and bars and sort of love what they do,” Tom Jenkins, the lead pastor of Mount Cavalry Lutheran Church in suburban Eagan, which is also helping with food drives, told me. “A lot of people are still cheering ICE on because they don’t think that whatever people are telling them or showing them is real.”

Although most of the coverage has understandably focused on the cities, suburban residents told me that they had seen operations all over the state. “There are mobile homes not far from where I live,” Jenkins said. Agents “were there every day, you know: 10, 15, 20 agents working the bus stops and bus drop-offs.” He added: “They’re all over.”

Even among those involved in opposing ICE in Minnesota, people have a range of political views. The nonviolent nature of the movement, and the focus on caring for neighbors, has drawn in volunteers with many different perspectives on immigration, including people who might have been supportive if the Trump administration’s claims of a targeted effort to deport violent criminals had been sincere.

“One of the things that I believe, and I know most of the Latino community agrees, is that we want the bad people out. We want the criminals out,” Pastor Miguel, who immigrated from Mexico 30 years ago, told me. “All of us came here looking for a better life for us and for our children. So when we have criminals, rapists—when we have people who have done horrible things in our streets, in our communities—we are afraid of them. We don’t want them here.”

The problem is that federal agents are not going after just criminals. Growing distraught, Pastor Miguel said that one of the men who helped organize the food drive, a close friend of his who he believed had legal status, had been picked up by federal agents the day before I visited.

“I just—I didn’t have words,” he said. “And yet I cannot crumble; I cannot fall. Because all these families also need us.”

Two days after Pretti was killed, my colleague Nick Miroff broke the news that Gregory Bovino, the Border Patrol official who had led the operation in Minneapolis, would be leaving the city and replaced by Trump’s border czar, Tom Homan. Bovino, strutting around in body armor or his distinctive long coat, seemed to relish his role as a villain to his critics, encouraging aggressive tactics by federal agents and sometimes engaging in them himself. The day I accompanied Green Bean and Cobalt, Bovino fumbled with a gas canister before throwing it into a sparse crowd of protesters.

Bovino’s departure seemed an admission that Minnesotans aren’t the only Americans who won’t tolerate more deaths at the hands of federal agents. The people of Minnesota have forced the Trump administration into a strategic retreat—one inflicted not as rioters or insurgents, but as neighbors.

After Friday’s protest, when thousands marched in frigid downtown Minneapolis, chanting, “No Trump, no troops, Twin Cities ain’t licking boots!” I spoke with a young protester named Ethan McFarland, who told me that his parents are immigrants from Uganda. He had recently asked his mother to show him her immigration papers, in case she got picked up. This kind of state oppression, he said, is exactly what his mother was “trying to get away from” when she came to the United States.

McFarland’s remarks reminded me of something Stephen Miller, the Trump adviser, had written: “Migrants and their descendants recreate the conditions, and terrors, of their broken homelands.” In Minnesota, the opposite was happening. The “conditions and terrors” of immigrants’ “broken homelands” weren’t being re-created by immigrants. They were being re-created by people like Miller. The immigrants simply have the experience to recognize them.

The federal surge into Minneapolis reflects a series of mistaken MAGA assumptions. The first is the belief that diverse communities aren’t possible: “Social bonds form among people who have something in common,” Vance said in a speech last July. “If you stop importing millions of foreigners into the country, you allow social cohesion to form naturally.” Vance’s remarks are the antithesis to the neighborism of the Twin Cities, whose people do not share the narcissism of being capable of loving only those who are exactly like them.

A second MAGA assumption is that the left is insincere in its values, and that principles of inclusion and unity are superficial forms of virtue signaling. White liberals might put a sign in their front yard saying IMMIGRANTS WELCOME, but they will abandon those immigrants at the first sensation of sustained pressure.

And in Trump’s defense, this has turned out to be true of many liberals in positions of power—university administrators, attorneys at white-shoe law firms, political leaders. But it is not true of millions of ordinary Americans, who have poured into the streets in protest, spoken out against the administration, and, in Minnesota, resisted armed men in masks at the cost of their own life.

The MAGA faith in liberal weakness has been paired with the conviction that real men—Trump’s men—are conversely strong. Consider Miller’s bizarre meltdown while addressing Memphis police in October. “The gangbangers that you deal with—they think that they’re ruthless? They have no idea how ruthless we are. They think they’re tough? They have no idea how tough we are,” Miller said. “They think they’re hard-core? We are so much more hard-core than they are.” Around this time, Miller moved his family onto a military base—for safety reasons.

The federal agents sent to Minnesota wear body armor and masks, and bear long guns and sidearms. But their skittishness and brutality are qualities associated with fear, not resolve. It takes far more courage to stare down the barrel of a gun while you’re armed with only a whistle and a phone than it does to point a gun at an unarmed protester.

Every social theory undergirding Trumpism has been broken on the steel of Minnesotan resolve. The multiracial community in Minneapolis was supposed to shatter. It did not. It held until Bovino was forced out of the Twin Cities with his long coat between his legs.

The secret fear of the morally depraved is that virtue is actually common, and that they’re the ones who are alone. In Minnesota, all of the ideological cornerstones of MAGA have been proved false at once. Minnesotans, not the armed thugs of ICE and the Border Patrol, are brave. Minnesotans have shown that their community is socially cohesive—because of its diversity and not in spite of it. Minnesotans have found and loved one another in a world atomized by social media, where empty men have tried to fill their lonely soul with lies about their own inherent superiority. Minnesotans have preserved everything worthwhile about “Western civilization,” while armed brutes try to tear it down by force.

No matter how many more armed men Trump sends to impose his will on the people of Minnesota, all he can do is accentuate their valor. No application of armed violence can make the men with guns as heroic as the people who choose to stand in their path with empty hands in defense of their neighbors. These agents, and the president who sent them, are no one’s heroes, no one’s saviors—just men with guns who have to hide their faces to shoot a mom in the face, and a nurse in the back.</div>
        </div>
        
        <div class="card" onclick="openModal('content-19')">
            <div class="source">The Atlantic</div>
            <div class="title">Greg Bovino Loses His Job</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-19" style="display:none;">
            <h2>Greg Bovino Loses His Job</h2>
            <p><strong>The Atlantic | 2026-01-26</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/politics/2026/01/greg-bovino-demoted-minneapolis-border-patrol/685770/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Gregory Bovino has been removed from his role as Border Patrol “commander at large” and will return to his former job in El Centro, California, where he is expected to retire soon, according to a DHS official and two people with knowledge of the change.

Bovino’s sudden demotion is the clearest sign yet that the Trump administration is reconsidering its most aggressive tactics after the killing Saturday of 37-year-old Alex Pretti by Border Patrol agents under Bovino’s command.

Earlier today, President Trump appeared to signal in a series of social-media posts a tactical shift in the administration’s mass-deportation campaign. Trump wrote that he spoke with Minnesota Governor Tim Walz—whom the White House has blamed for inciting violence—and the two men are now on “a similar wavelength.” Tom Homan, the former ICE chief whom Trump has designated “border czar,” will head to Minnesota to assume command of the federal mobilization there, Trump said.

Homeland Security Secretary Kristi Noem and her close adviser Corey Lewandowski, who were Bovino’s biggest backers at DHS, are also at risk of losing their jobs, two of the people told me.

Read: The hype man of Trump’s mass deportations

For the past seven months, Bovino has been the public face of a traveling immigration crackdown on cities governed by Democrats. Noem and other Trump officials gave Bovino the “commander” title and sent him and his masked border agents to Chicago, Charlotte, New Orleans, and then Minneapolis. Bovino became a MAGA social-media star as he traveled the country with his own film crew and used social media to hit back at Democratic politicians and random critics online. Veteran ICE and CBP officials grew more and more uneasy as Bovino worked outside his agency’s chain of command and appeared to relish his role as a political actor.

In Minneapolis, the Trump administration used Bovino as its lead spokesperson, scheduling daily press conferences where he defended agents’ rough tactics and cast blame on protesters and local officials. Border Patrol commanders typically avoid engaging in political arguments with elected officials.

Bovino’s fall comes two days after Border Patrol agents in Minneapolis fatally shot Pretti, an intensive-care nurse who worked with veterans. Hours after the shooting, Bovino appeared at a press conference and echoed statements by the Department of Homeland Security alleging Pretti sought to “massacre” the federal agents. Bovino repeatedly claimed that Border Patrol agents, not Pretti, were the victims.

Videos of the encounter showed no evidence for his claims. Pretti, who was licensed to carry a concealed weapon, did not draw a firearm or attack the agents. The videos show one agent disarming Pretti in the moments just before another agent shot him in the back.

DHS and U.S. Customs and Border Protection officials did not immediately respond to questions about Bovino’s departure from Minnesota and his current role. Asked about Bovino and Noem, a White House spokesperson referred to Press Secretary Karoline Leavitt’s statement today that Noem has the president’s “utmost confidence and trust.”

In another post, Trump said he also spoke with Minneapolis Mayor Jacob Frey. “Lots of progress is being made!” the president wrote. “Tom Homan will be meeting with him tomorrow in order to continue the discussion.”</div>
        </div>
        
        <div class="card" onclick="openModal('content-20')">
            <div class="source">The Atlantic</div>
            <div class="title">What the Administration Is Signaling to Federal Agents After Minnesota</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-20" style="display:none;">
            <h2>What the Administration Is Signaling to Federal Agents After Minnesota</h2>
            <p><strong>The Atlantic | 2026-01-26</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/newsletters/2026/01/trump-minnesota-shootings-ice-border-patrol/685771/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">This is an edition of The Atlantic Daily, a newsletter that guides you through the biggest stories of the day, helps you discover new ideas, and recommends the best in culture. Sign up for it here.

Perhaps the most disturbing part of the Trump administration’s immigration operation in Minnesota is not just that agents of the state are killing peacefully protesting citizens on the streets. It’s that they’re doing it with the expectation of impunity, backed by top government officials who are brazenly lying about what happened.

The response from President Trump, Homeland Security Secretary Kristi Noem, and other officials has sent a clear message: When immigration agents kill peaceful protesters, the government will defend them unconditionally, no matter if clear video evidence contradicts its version of events. It will resist investigating shootings, and it will do everything it can to block probes by other authorities. Vice President Vance has even claimed that federal agents have “absolute immunity” for their actions. This approach all but guarantees more killings.

The culture of impunity runs from the bottom to the top. It includes the federal agents who shot Alex Pretti, a 37-year-old ICU nurse, multiple times in Minneapolis on Saturday morning, despite videos that appear to show that the agents had already removed his holstered gun, and despite knowing that many bystanders were filming. (If this is what Border Patrol feels comfortable doing on camera, one can only guess how they might act in private.) It also encompasses the administration officials who offered false accounts immediately, without bothering to wait for the facts.

Videos show Pretti filming officers before being pepper-sprayed and tackled by multiple officers, who then shot him while he was on the ground. Yet the Homeland Security secretary accused Pretti of “domestic terrorism” and said that he’d “attacked” agents, a claim that FBI Director Kash Patel repeated. Noem also said that Pretti had been “brandishing” a gun. (He had been legally carrying a concealed weapon, a right that the administration has previously celebrated.) Deputy Attorney General Todd Blanche argued that because Pretti was shouting and had “a phone right up to ICE’s face,” he was not protesting peacefully. The Trump aide Stephen Miller labeled him an “assassin,” and the Border Patrol commander Greg Bovino said that Pretti “wanted to do maximum damage and massacre law enforcement.” No known evidence backs any of this up, and videos show that much of it is provably false.

When law-enforcement officers shoot civilians, it is common—if unsavory—for government officials to defend them. The Trump administration has gone far beyond this. Fatal shootings are almost always subject to investigation. After an ICE agent killed Renee Good earlier this month, Blanche (who once was Trump’s personal lawyer) said that the FBI would not launch a civil-rights investigation into the shooting. Instead, MS NOW reported, the Justice Department instructed the FBI to seek a search warrant to investigate Good for possible criminal liability. A federal magistrate rejected the warrant, which is unusual—except that, as the magistrate noted, Good is dead and could not legally be considered a suspect. An FBI agent resigned after she was allegedly pressured to stop pursuing a civil-rights inquiry into the ICE officer, Jonathan Ross, who’d shot Good.

Something similar started to play out immediately after Pretti’s death. Federal agencies seem unsure what, if any, investigation is occurring, according to The Washington Post, although White House Press Secretary Karoline Leavitt said today that DHS and CBP are investigating the Pretti shooting, including reviewing body-cam footage. Federal agents refused to give even “the most basic information” to Minneapolis police at the scene, Chief Brian O’Hara said yesterday, and they initially blocked the Minnesota Bureau of Criminal Apprehension, the state’s criminal-investigation office, from accessing the crime scene. The state then went to court and obtained an order from a (Trump-appointed) federal judge blocking the destruction of evidence. That such a move was even necessary is astonishing.

A state-level agency like the BCA has nowhere near the resources or expertise that federal agencies do, and local investigators face legal hurdles when investigating federal agents. Yet administration officials have so clearly declared their position with lies and prejudicial statements that any federal investigation would be suspect from the start—another example of how Trump’s politicization of the Justice Department has undermined its ability to do its job.

Compared with the aftermath of Good’s shooting, more Republicans are expressing concerns about the operation in Minneapolis and Pretti’s killing. Even Trump has vacillated somewhat. He blamed Democrats for Pretti’s death but was noncommittal in a conversation with The Wall Street Journal about whether the agents involved had acted appropriately, in contrast to his quick blaming of Good for her own death. He has since conceded that ICE agents may have made a “mistake” in her case. Vance has also backtracked some, abandoning his claims of “absolute immunity.” (Law-enforcement officers are entitled to what’s known as “qualified immunity,” or protection from liability unless breaking clear legal or constitutional boundaries.)

Even as Republicans grow wary, they have tried to blame Trump’s aides rather than the president himself; Oklahoma Governor Kevin Stitt, for example, lamented that the president was “getting bad advice.” But the culture of impunity proceeds directly from Trump. He has enthusiastically embraced the idea that the federal government should serve his personal whims. He argued that investigations into himself, even for overt offenses such as taking home boxes of sensitive documents, were improper. And he has made clear that when people act to assist him, whether they are aides or January 6 rioters, he will use his clemency powers to protect them from consequences.

Trump has spent years dehumanizing immigrants, exhorting law enforcement to treat suspects more roughly, and attacking the rule of law. The killings in Minnesota aren’t the collateral damage of Trump’s approach to governance. They’re a direct result.

Here are three new stories from The Atlantic:

Anyone who thinks the contemplative life amounts to a form of quietism or a retreat from the world’s suffering should spend some time shadowing Joan Halifax, the Zen priest and anthropologist. I’d been curious about Halifax for years, ever since I heard about an annual trek that she leads through the mountains of Nepal, bringing a cadre of doctors and dentists to remote mountain villages with little access to health care.

Each summer over the course of two weeks or so, this Nomads Clinic covers more than 100 miles on foot and horseback, at altitudes of nearly 18,000 feet. These “medical mountaineers,” as they’ve been called, all volunteers, sleep in tents, often in freezing temperatures. But after some 40 annual trips to Nepal—Halifax is normally based in Santa Fe—she recently decided it was time to hang it up.

Watch. Last Saturday’s “Weekend Update” segment (streaming on Peacock) explains how Saturday Night Live benefits from making pop culture a little bit cringe, Michael Tedder writes.

Read. Before her murder made her a true-crime obsession, Elizabeth Short was a real person. Black Dahlia tries to separate truth from myth in the infamous case, Sarah Weinman writes.

Last Wednesday, covering President Trump’s speech at the World Economic Forum, I remarked, “Perhaps the Germans have a word for the experience of watching your country’s leader embarrass himself and the country on the global stage.” Several Germanophone readers wrote in to tell me that, in fact, they do—or at least one that partly captures the feeling. Fremdscham is a term for vicarious embarrassment, a sort of inverse of schadenfreude. I’m going to have to add this one to my vocabulary. Now, if we can only find a way to shoehorn presidential presence into it!

Rafaela Jinich contributed to this newsletter.

When you buy a book using a link in this newsletter, we receive a commission. Thank you for supporting The Atlantic.</div>
        </div>
        
        <div class="card" onclick="openModal('content-21')">
            <div class="source">The Atlantic</div>
            <div class="title">ICE Is Failing the Legitimacy Test</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-21" style="display:none;">
            <h2>ICE Is Failing the Legitimacy Test</h2>
            <p><strong>The Atlantic | 2026-01-26</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/ideas/2026/01/policing-open-carry-minnesota-pretti/685767/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Carrying a concealed handgun in public is now commonplace in much of the country. For many, this is not only a prudent act of personal safety, but an expression of liberty and a bulwark against government overreach. At the same time, America&#39;s law-enforcement officers insist they must exercise vigilance while patrolling dangerous streets. When officers make a split-second decision to shoot someone who is carrying a gun, many political leaders, especially on the right, believe they need to be given deference because their lives were at risk.

The tension between these two ideas is acute, putting law enforcement and citizens on a potentially catastrophic collision course. One such collision took place in Minnesota on Saturday. It was fatal for the citizen. And it was potentially delegitimizing for law enforcement. A broader crisis of government legitimacy is imminent in the absence of a change in direction by the Trump administration.

Judging from the video evidence and news reports, this is what seems to have taken place: The Minneapolis nurse Alex Pretti carried his loaded, concealed 9-mm handgun to a protest against the ICE agents.  He had no criminal record, and a permit to carry the gun. Holding only a phone when an agent moved in to make an arrest, he was pepper-sprayed and thrown to the ground. Then, as federal agents wrestled him into submission, Pretti’s coat rode up and his holstered gun came into view. It set off panicked screams of “Gun!” among the agents. One of them reached in and removed the pistol from Pretti’s waistband; another then drew his own pistol and shot Pretti in the back. Pretti died in the street never having touched his gun. He had been disarmed before the first shot was even fired.

In response to this tragedy, the president of the United States wrote on social media: “LET OUR ICE PATRIOTS DO THEIR JOB!”

But surely doing their job well must include respecting the people they serve. For true Second Amendment advocates, Pretti’s decision to bring a gun to a protest in no way excuses his killing. A protester with a gun, they believe, is not courting his own demise. To these advocates, under the Second Amendment, there is no wrong time and place for a citizen to be armed; it is a right that “shall not be infringed.” Some states prohibit guns at protests, but Minnesota is not one of them. As of 2025, more than 20 million Americans held a concealed carry permit. And 29 states have adopted Constitutional Carry, meaning a permit is not required.

Robert F. Worth: Welcome to the American winter

None of this is to say that policing an armed society is easy. It requires highly trained, well-led officers who can navigate incidents including routine calls and crimes in progress with discipline and restraint. It also requires a commitment to transparency—and to accountability, when police wrongly shoot a person exercising their right to carry a gun. In this regard, ICE and the federal government have failed dismally.

ICE agents are poorly screened and quickly hired. They spend just 47 days in their training academy, a shorter duration than nearly all law enforcement organizations; Minnesota, for example, requires about double the training for its police officers at 1,050 hours. In the field, they are saddled with quotas for how many people they must apprehend. That leads to desperate measures and poor decisions. Many of these agents wear masks to conceal their identity and project an air of menace. They regularly flout their own body-camera policy, which their agency is seeking to roll back. They have been instructed to use force to enter homes without the judicial warrant the Constitution requires. They perform poorly at crowd control, resorting to tear gas and pepper spray with an alarming frequency.

Compounding these problems, the federal government has vilified the men and women shot by ICE agents, including U.S. citizens; refused to conduct transparent investigations; and contemptuously blocked state agencies from doing so. Federal officials have declared ICE’s killings lawful and justified over social media without any pretense of a formal review, making statements that are cruel, derogatory, misleading, or simply false. People who want the government to account for what it has done are told to go pound sand.

A particularly vivid example of this dynamic occurred three weeks ago, when an ICE agent, also in Minneapolis, killed Renee Good as she tried to drive away from him. The agency argued that a car on the move is a lethal threat, so an officer who steps in front of a car can shoot a driver who doesn’t stop. The New York City Police Department prohibited shooting at moving vehicles in 1972, and most major cities tightly regulate the practice. Professional police agencies have learned that shooting the driver doesn’t stop the car or make the officer any safer; the best bet is to get out of the way. Rather than explain this contradiction, ICE dismissed criticism, immediately declared Good’s killing necessary and lawful, labeled her a domestic terrorist and the officer a hero, and shut down efforts to investigate the incident. Then the Department of Justice ordered federal prosecutors and the FBI to investigate Good’s family for ties to left-wing radicals, leading several prosecutors to resign. This is not the behavior of government officials who can plausibly argue that they have a legitimate right to use force against citizens.

Contrary to the administration’s feverish claims, the protesters in Minneapolis are not “woke” leftist domestic terrorists confronting responsible law-enforcement officers to foment an insurrection. As best we can tell, among the cast of activists are citizens of every class, ideology, and race, standing up for basic decency and constitutional liberties. One of our mothers-in-law regularly demonstrates against ICE, and she hasn’t protested anything since the Vietnam War. In the face of the dangers posed by armed, masked men who have been reassured by the president that they will receive immunity for their actions—both legally incorrect and a bad idea—these citizens are putting themselves on the line to say that what is happening is inconsistent with America’s most fundamental values.

There is a lot of overlap between the elected officials who exhort Americans to carry guns wherever they like, and the ones who tend to stand by law-enforcement officers who use lethal force. These positions are not always contradictory, but in this situation they are flatly incompatible. If elected officials are going to stump for the Second Amendment, and at the same time refuse to hold a federal agency accountable for killing an American exercising that very right, the country is at risk of losing any right to protest. And the federal government is calling into question its legitimacy.</div>
        </div>
        
        <div class="card" onclick="openModal('content-22')">
            <div class="source">The Atlantic</div>
            <div class="title">The Worst Thing About the Black Dahlia Case</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-22" style="display:none;">
            <h2>The Worst Thing About the Black Dahlia Case</h2>
            <p><strong>The Atlantic | 2026-01-26</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/books/2026/01/woman-who-became-black-dahlia/685739/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Elizabeth Short liked to wander. Sometimes this wandering was merely in her mind, watching movies and dreaming of a life far beyond her hometown of Medford, Massachusetts. Many times, it was physical; she’d land in a new city—Miami, Jacksonville, Chicago, Long Beach, San Diego, Los Angeles—and explore its streets on foot. Sometimes her travels revolved around family, as when she tracked down her long-lost father and lived with him for a time—until he cast her out. On January 9, 1947, Short, who was 22, told a gentleman friend to drop her off at the Biltmore Hotel in downtown Los Angeles, where her sister was supposedly waiting. She was never seen alive again.

A contemporary version of Elizabeth—dreamy, elusive, independent, and canny—might be called a flaneuse, someone curious about the world. But we’ll never know what kind of life she would have led; by the time her bisected body was found in a vacant lot, six days after she left the Biltmore, Elizabeth had ceased to be a person. From then on, she became “The Black Dahlia,” an archetype, a myth, a riddle that countless people have attempted to solve in books, films, television shows, podcasts, websites, internet-message boards, and social-media posts.

“After we are dead, the pretense that we may be protected against the world’s careless malice is abandoned,” Janet Malcolm wrote in her book The Silent Woman. She was referring to the poet and novelist Sylvia Plath, another beautiful young woman who died too soon, after which her life and words became grist for the biographical mill. But Malcolm’s words apply equally, even eerily, to the afterlife of Short—one of America’s most famous murder victims, and certainly among the most persistent subjects of the true-crime industrial complex.

From the moment Short’s killing became headline news, sensation was the prime directive. With every new lead, confession, and suspect, the actual Elizabeth receded further. It didn’t help that she was an enigmatic character in life, prone to embellishment and even lies. She recounted tales of woe to paramours only to ask them for money, exaggerated her prospects in missives to her mother, told friends about a dead husband and a child who probably didn’t exist—all without letting on about her actual precarious straits. Short avoided the spotlight, but over the nearly 80 years since her death, it has wholly consumed her.

This kind of flattening happens all too often with murder victims, particularly young women and girls who die at the hands of a serial killer, usually male. (Never mind that more marginalized women, especially women of color, are less likely to merit any attention at all.) In Short’s case, the flattening is particularly egregious, because the inchoate facts of her life are shoehorned into the obsessions of amateur sleuths who continue to get those facts wrong.

Read: A provocative argument about what creates serial killers

William J. Mann’s new book, Black Dahlia: Murder, Monsters, and Madness in Midcentury Hollywood, attempts a different approach: to weave the fragments we have into a narrative whole that prioritizes Short, in all of her contradictions, and tries to debunk decades’ worth of accumulated myths. Although Mann’s effort stands apart from the overlong run of books about the case, it, too, is undercut by the need to name a likely suspect, playing into the true-crime imperative it aims to leave behind.

Mann begins Black Dahlia in late July 1946, several months before Short’s murder and not long after her arrival in Long Beach, California. Over the ensuing period, Short befriends women and dates men; wears sophisticated clothing, ankle-strapped high heels, and flowers in her hair; and comes across as “a very modest girl who never cursed or acted sexy,” in the words of one friend. The reader comes to understand why fascination has proved more appealing than facts: We know very little about her life. Short defied norms and customs. She seemed innocent in the ways of men but savvy enough to keep her dates at a respectful distance. The two women who knew her best during this time, Marjorie Graham and Anne Toth, whom Mann renders more fully than any author before him, still had trouble understanding what made Short tick.

Mann starts the story, however, from the vantage point of Tod Faulkner, who says he first spotted Short in a two-piece bathing suit, walking alone toward the beach, and saw her again several more times that summer. Faulkner was 11 at the time, and says he never forgot her. Yet after growing up to become a journalist, he was the one who immortalized the erroneous middle name “Ann,” in a 1971 article for the Los Angeles Times. Faulkner’s error would propagate in numerous articles, books, and films before being codified in the 1975 TV movie Who Is the Black Dahlia?, which starred Lucie Arnaz (the daughter of Lucille Ball and Desi Arnaz) as Short. Already we have the conflict between truth and myth, and we’re only on page four.

From there, Mann situates the known facts about the last few months of Short’s life in postwar Los Angeles, whose rising murder rate led to an even sharper spike in fear. From 1945 to 1946, “while the homicide rate for men grew by 26.8 percent, the number of women murdered in that same period shot up by 52.9 percent,” Mann points out. Over the next few years, the increase in violent deaths of women, seemingly at the hands of strangers, was reflected in the growing genre of film noir and in novels including Dorothy B. Hughes’s In a Lonely Place, which was published less than a year after Short’s murder.

Fear also sold newspapers, as any tabloid journalist at the time could tell you. And tell people they did, particularly in the early days and weeks after Short’s death, when the tiniest new detail about the “Black Dahlia” investigation—even, or especially, if that detail wasn’t true—could boost circulation. Mann calls out many instances of “sexing up the news” (a phrase he uses multiple times): the description of the block where Short’s body was discovered as a “lover’s lane”; invented testimony from witnesses and family members (including Short’s grieving mother, Phoebe); exaggerations in the memoirs of the L.A. newspaper editors Agness Underwood and Jimmy Richardson, early chroniclers—and shapers—of the murder narrative.

The errors and suppositions would multiply over the decades—most of them cataloged by the former L.A. Times reporter and historian Larry Harnisch. Was Short a sex worker? Blame John Gregory Dunne’s otherwise terrific 1977 novel, True Confessions, which gave its Short stand-in the moniker “The Virgin Tramp” along with a past career in pornography. (Without True Confessions, James Ellroy probably wouldn’t have written his own The Black Dahlia novel in 1987, which led to a 2006 film adaptation.) Did she have sexual dysfunction? That’s an invention of a former Examiner reporter, Will Fowler, bolstered by John Gilmore in his supposedly nonfiction 1994 account, Severed, which includes information from a detective, “Herman Willis,” who doesn’t seem to have existed.

False suspects also proliferated. Was George Hodel the killer? So his son Steve Hodel keeps insisting, first in his 2003 book, Black Dahlia Avenger, then in a later book that also puts George forward as the Zodiac Killer (oy). Janice Knowlton, too, believed that her father murdered Elizabeth: Read about it in Daddy Was the Black Dahlia Killer. Piu Eatwell’s Black Dahlia, Red Rose initially convinced me that Leslie Dillon was the culprit, but Mann’s account definitively rules Dillon out. Eli Frankel’s Sisters in Death, published just last year, strains (and, to my mind, fails) to connect Short to an unsolved murder in Kansas City. And a new podcast hosted by Michael Connelly, Killer in the Code, also tries to connect the Black Dahlia and the Zodiac Killer, with the help of a “cold-case consultant” who bases his “smoking gun” on a deathbed sketch that better resembles fan art.

Shiftiness, con artistry, and even violence toward women don’t add up to hard, incriminating evidence. Mann, too, succumbs to the temptation, perhaps reluctantly; he spends precious pages explaining why one of Elizabeth’s Long Beach boyfriends, a military veteran named Marvin Margolis who died in 1993—the same suspect in Connelly’s podcast—can’t be ruled out as the killer. (The original detectives crossed him off the list early in the investigation.) Even Mann seems dissatisfied when he mulls the prospect that a stranger killed Short: “She was simply a vulnerable young woman who came face-to-face with someone with severe and violent psychopathology who decided, either on impulse or deliberation, to kill her, to use her body to express rage and resentment at the world.”

After so much time has passed, no one is likely to be satisfied with any identification of Short’s killer. If the lead detective, Harry Hansen, is to be believed, the Los Angeles Police Department never once interviewed the actual killer despite interrogating scores of suspects—including all of those mentioned in prior books, and now Mann’s. Any outcome would likely resemble the identification last September, via investigative genetic genealogy, of the man responsible for the 1991 quadruple homicide in Austin, Texas, known as the “Yogurt Shop Murders.” In that case, pinning down the murderer didn’t erase the 34 years of anguish and damage sustained by the girls’ families and the young men wrongfully convicted—including one who had been on death row. After decades of pain and exploitation, solving the case feels like an anticlimax.

“Solving” the Black Dahlia case, most likely through genetic genealogy, may bring an answer, but it would only generate many more questions. Harnisch, the historian, who knows more about the case than almost anybody (and has a credible theory relegated to a footnote in Mann’s book), put it best in a 2020 interview: “This is a story that fades to conjecture. This is a story without an ending.”

Look past the need for narrative and there, out on the horizon, is Elizabeth Short, walking down a California boulevard, trying to create a better story for herself. She didn’t have to remain forever a girl wounded by her father’s rejection, too proud to admit the truth about her life to her mother and sisters, yet resourceful enough to survive, for a time, in a world that couldn’t care less. Her luck ran out, and we don’t know why, or who killed her. But the brutality of Short’s death shouldn’t supersede her life any more than myth should overshadow a larger truth: that her murder will never truly make any sense.

​When you buy a book using a link on this page, we receive a commission. Thank you for supporting The Atlantic.</div>
        </div>
        
        <div class="card" onclick="openModal('content-23')">
            <div class="source">The Atlantic</div>
            <div class="title">How to Have a ‘Don’t-Know Mind’</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-23" style="display:none;">
            <h2>How to Have a ‘Don’t-Know Mind’</h2>
            <p><strong>The Atlantic | 2026-01-26</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/science/2026/01/consciousness-journey-zen-meditation/685647/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Anyone who thinks the contemplative life amounts to a form of quietism or a retreat from the world’s suffering should spend some time shadowing Joan Halifax, the Zen priest and anthropologist. I’d been curious about Halifax for years, ever since I heard about an annual trek that she leads through the mountains of Nepal, bringing a cadre of doctors and dentists to remote mountain villages with little access to health care.

Each summer over the course of two weeks or so, this Nomads Clinic covers more than 100 miles on foot and horseback, at altitudes of nearly 18,000 feet. These “medical mountaineers,” as they’ve been called,  all volunteers, sleep in tents, often in freezing temperatures. But after some 40 annual trips to Nepal—Halifax is normally based in Santa Fe—she recently decided it was time to hang it up. She had just turned 80.

In addition to bringing medical care to remote mountain villages half a world away, Halifax has ministered to the dying in hospice, worked with the homeless in New Mexico, cared for prisoners on death row, and led countless protests for peace. I don’t know if Halifax has shed the last remnants of her ego—she would say she hasn’t—but the selflessness she manifests in the conduct of her life is something to behold, a reminder of what the exploration of human consciousness can lead a person to do and be. This, too, is a Buddhist principle—that overcoming one’s own small self should lead to greater compassion for others, and that the suffering alleviated when we transcend the ego is not only our own.

For more than 30 years, Halifax has been the abbot at Upaya Zen Center, the retreat she founded in Santa Fe in 1990. I’ve had the chance to meet her a couple of times; once, we appeared together on a panel to talk about psychedelics. Halifax was married to the pioneering Czech psychiatrist Stanislav Grof for several years in the 1970s. Working together, they gave transformative doses of LSD to the dying. For a period of time, Halifax regularly took large doses of LSD herself. Her first psychedelic trip, while wandering the streets of Paris in 1968, showed her “that there was beauty behind the beauty I perceived, and that mind was both in here and out there. I was dumbstruck.”

I could relate. After years of curiosity about psychoactive plants, my own experimentation with mushrooms and LSD in recent years fundamentally changed the way I understand the mysteries of consciousness and the self. So in 2024, I emailed Halifax to see if I might pay a visit to Upaya. My idea was to spend a week or so in residence, meditating with the aspiring monks, performing monkish chores, interviewing Halifax, and seeing if I could make a little more progress untying the knot of self. “Upaya is a factory for the deconstruction of selves,” she had told me. I was curious to find out how that worked.

Read: Psychedelics open your brain. You might not like what falls in.

But Roshi Joan, as everyone calls her, had other plans for me. She decided I should spend a day or two at Upaya and then accompany her up to “the refuge,” an off-the-grid compound of tiny houses and huts stretched out across a broad hammock of meadow at 9,400 feet in the Sangre de Cristo Mountains, north of Santa Fe. Whenever she’s not traveling or running conferences or teaching, Halifax retreats to these mountains, where she meditates and hikes and paints and writes and doesn’t have to play the role of abbot. She dispatches students to the refuge when she deems them in need of a period of monastic solitude—for years at a time, in some cases.

“After you’ve acclimated to the altitude, we’ll drive up to the refuge,” she said by email before my arrival in Santa Fe. “You can stay in the cave.” This was not put in the form of a question.

Halifax explained that even though it had neither plumbing nor electricity nor an internet connection, this was “a five-star cave” and I would be comfortable—or, more likely, I’d be uncomfortable in a spiritually productive way. I’m not much of a camper but decided I might as well put myself in her hands to see what the experience would yield.

The first thing you notice about Joan Halifax is her undiminished beauty—the shining blue eyes and the easy smile and the generous sweep of white hair. That she’s 83 is hard to believe. She moves through Upaya’s little village of low-slung adobes and tended gardens with a graceful authority. Yet abbot is a role that, these days, she’s more than happy to trade for the solitude and freedom of the refuge.

The refuge is at the end of a 25-mile-long rutted dirt road that climbs through a shadowy forest of pine and spruce, punctuated by the sparkle of the occasional stream or meadow. Though it was well into June, spring was still unfolding at this altitude, the meadow grasses and spruce tips bright green and the groves of ivory-trunked aspen just leafing out. After we unloaded our SUV at the main house, where we would gather for meals (and connect to the outside world, as the house has a satellite internet connection), Halifax escorted me to my lodgings, a hike of half a mile along a path through meadows lined with aspen trees, their new leaves fluttering gently. Along the way, she identified the scat of elk, deer, and bears.

The cave was a 12-by-15-foot cell dug into a south-facing hillside and lined with brown stucco; it was windowless except for a sliding glass door overlooking the meadow. In one corner stood a spartan single bed, in the other a small woodstove. Between them, against the back wall, a meditation cushion sat on a raised platform, beneath an embroidered fabric depicting a Buddhist figure I didn’t recognize. I pictured myself seated cross-legged on the platform, like one of those levitating yogis in a New Yorker cartoon. The room also had a small sink fed by a five-gallon jug of water suspended above it, a two-burner camp stove, some shelving for clothes and books, and a car battery hooked up to a small solar panel outside. This produced just enough juice to power a reading light and charge a phone, though with no cell service or internet connection, what was the point?

What was the point? Why did Roshi Joan want me here rather than at Upaya or the main house, with its creature comforts? (And why did she keep putting off our interview?) I came to suspect she had decided that the questions I had for her—questions regarding Buddhist ideas about the self and consciousness and her own path from psychedelics to Zen—were best approached obliquely, perhaps by way of firsthand experience rather than words; that I should answer them myself. When I’d told her what I was working on, she had diagnosed me as hopelessly stuck in my head. Better to spend several days alone with myself meditating and navigating these hills than in the more familiar landscape of concepts, something to which I should have known a Zen priest would be allergic. When we finally did sit down for our interview, in the main house on the morning of the third day, Roshi Joan began by saying, somewhat cryptically, that she had “divested from meaning.” Okay.

It took me a while to realize that for Halifax, the practice of Buddhism was everything and theories were of little use or consequence. It was only through doing that she had learned her most enduring life lessons, whether that meant sitting with death-row inmates who taught her how powerlessness ferments into anger, or ministering to people in their last days and hours. “You learn to be nimble toward whatever is arising, because there’s no one death,” she said, “and if you cling to expectations, you will experience futility.” It was here, in doing the work, that Buddhist ideas about impermanence, conditioning, and dependent arising became flesh.

I took the hint. When I asked Halifax about herself or about Buddhist philosophy, she often ducked my questions or directed me elsewhere, so during one of our daily walks, I instead asked her to describe exactly how her factory for the deconstruction of selves operated.

People come on silent retreat for a week or two at a time and spend most of their days sitting in the Zendo—the meditation hall—facing a wall or tracing walking meditations on the gravel paths that meander through Upaya’s gardens. (I’d witnessed this glacial parade of earnest zombies.) I asked if novices received any guidance or technique. Not much, she said. Students are instructed about posture, and beginners are told to follow the breath, which “unifies body, mind, and space.” As Halifax has written, zazen, or sitting, “is not a mental exercise, a thing you do with your mind.” Rather, “it is about being radically open to things just as they are, not grasping at or rejecting phenomena, but simply being present and at ease with moment-to-moment uncertainty and groundlessness” and “letting openness or not-knowing deconstruct our version of reality. It is the method of non-method.” Just sitting, upright—that, apparently, is all there is to zazen.

“Zen is the hardest school,” Halifax explained, “because there is so little support.” But at Upaya, she told me, “there is the jungle gym of structure”—the strict rules and rituals and routines that govern life on retreat.

“There’s a certain point at about day three where you can feel the whole room go poof,” she said. “And everyone realizes we’re now in one body, one mind.” I asked her how this transformation was achieved. “We don’t say we’re deconstructing the self, but that is what we’re doing,” she told me. “Living in silence means you can’t start a conversation, so there’s no opportunity for self-presentation. Then there are the rituals that organize the day. These draw people into the group and relieve them of having to make decisions. Rituals take the place of a certain amount of volition.” It hadn’t occurred to me that ritual and silence could serve as tools to change consciousness and breach the hard shell of self.

Arthur C. Brooks: Five teachings of the Dalai Lama I try to live by

But it is the agony of meditating for hours at a time that finally breaks down the ego. I asked her what people meditate about. “Mostly they ruminate and plan,” she said. “They do that until they can’t stand the thought of themselves any longer. You’re just sitting there for hours on end, and the entertainment value of watching the same reruns all day long diminishes over time. Pretty soon, it becomes unsustainable; they’re exhausted and uncomfortable, and that’s when they drop in.”

To “drop in,” Halifax explained, is to enter a state of being completely present in time and space, experiencing “the sense field”—the world as it appears to our senses prior to thought—without conceptualizing, and surrendering the sense of a separate self. The recipe was simpler (and much less appetizing) than I would have imagined: To transcend the self, force yourself to be alone with it long enough to get so bored and exhausted that you are happy to let it go.

Halifax, who did anthropological fieldwork in Africa, thinks of the Zen retreat as an initiation ceremony, or rite of passage, and like most such rites, it involves the metaphorical death of the ego followed by rejoining the group. She regards the psychedelic trip as another rite of initiation, but “it’s a shortcut,” and one she’d rather her students not take. I wondered if this helped explain why she preferred that I stay at the refuge rather than mingle with her students at Upaya. Perhaps she thought contact with me would undermine the process by encouraging them to take the psychedelic shortcut.

“There is a lot gained when we give up the self,” she noted. “We break out of rumination. We discover we’re part of something larger, and we learn it feels good to care for others.” When I asked Halifax if she had succeeded in exorcising her own self, she allowed that she can be self-righteous at times. “There is moral injury, moral outrage, moral apathy—all of them are products of either a sense of superiority or inferiority,” she said. “So they’re all ego-based.”

I came to understand that Roshi Joan had sent me to the cave because there were no words or ideas she could offer that would teach me as much as simply being completely alone with myself in the middle of these mountains, with no phone or any other screens (and no toilet). Her idea, I eventually saw, was to pose a kind of experiential koan for me to puzzle and, perhaps, to help me unlearn some of the things I thought I had learned about consciousness and the self.

Cave life quickly stripped down to the bare essentials: collecting, splitting, and stacking wood; building fires; hauling water; digging pits in the woods; sweeping the floor and threshold; and, for hours each day, meditating on the platform. I’ve meditated for several years now, but never as easily or as deeply or as strangely as I did in my little cave. It may have been the silence, which felt bottomless, or the certainty that I would not be interrupted or distracted. Even the air there felt different, as if the absence of the electromagnetic waves that normally surround and pass through us made it easier to empty the mind of its usual detritus. I found I could sit for hours at a time, something I’d never managed to do before.

It helped that there was nothing else I needed to do, except maybe brew a cup of tea or sweep the cave again. Somehow, these seemed like particularly cave-appropriate activities. I fell into a routine so elemental and repetitive that it began to feel like ritual. The only snafu came the first time I attempted to use my hand-dug pit toilet and, failing to position myself properly, managed to pee into my sneaker. Now I was a shoeless monk. Which also seemed cave-appropriate.

One morning, I decided to try a meditation I’d learned from my time with the Nepalese French Buddhist monk Matthieu Ricard, who has written extensively on the self as an illusion. To see this, he suggested I explore the rooms of my mind, one by one, as if searching for a thief—what he called “the thief of self.” Looking within, I found all sorts of mental stuff but, as Ricard had predicted, none of it qualified as a self. Rather, I witnessed a parade of unbidden, free-floating perceptions, feelings, images, sensations, and thoughts, but I could locate no thinker of these thoughts or perceiver of these perceptions.

The longer I sat, the stranger these appearances became, as the space of my awareness became an empty stage. Picture a circus ring where all kinds of images might suddenly and inexplicably appear out of nowhere. Why is there now a bank of three old-timey telephone booths with men inside making calls? And what’s this hammer suddenly coming down on a knee?! Or that automatic glass door swinging open for no one? These stray images were then blasted away by a blazing sun that completely filled the space of awareness before transforming itself into a gigantic eyeball—a sighted sun with a black circle of iris. Could this be the anarchic mind that emerges when the ego relinquishes its hold?

Maybe, and yet these dreamy, hypnagogic images were more curious than frightening, probably because it was easy enough to chase them away, to change the mental channel, simply by willing it. So then who, or what, did the chasing? The source of that will, that inchoate “I,” might have escaped introspective detection, yet it could still make things happen or stop happening. The self might well be illusory, I decided, but no more so than color or any other construct of the mind. Put another way, the self can be both illusory and real, or real enough.

Initially, I found I was talking to myself out loud, trying to fill the vast space of silence, which made it feel as though I had doubled my self rather than eliminated it—given it a little company. “Should I brew a cup of tea? Put another log on the fire?” I would ask. And I would answer: “Sure,” or “Good idea.” But after a day or two, I fell in love with the silence, and the voices stopped. I found the handful of chores completely absorbing, as if nothing in the world mattered as much as splitting firewood, fully occupying my attention and leaving no remainder of thought, self-consciousness, or anticipation. The distance between living and meditating had narrowed to a sliver. When I described the satisfactions of my routine to Roshi Joan during one of our hikes, she smiled: “That’s the sacredness of the everyday.”

Something was happening to my sense of self, and it seemed to have everything to do with what was happening to my sense of time. I had never given much thought to the relationship between self and time, but it explains a lot. When the self is deprived of time past (memory) and future (anticipation), it melts away. Absorbed in meditation, or in my chores, or in watching a small herd of elk graze in the meadow below at sunset, I could feel my time horizon shrink. The feeling was unfamiliar, since my usual mental coordinates place me somewhere in the proximate future, a locus of anticipation and, all too often, unfocused worry. But now, for longer and longer stretches, I was simply here, being, with no thought of the past or the future.

To my surprise, these moments of simple and more or less self-less consciousness did not occur when my eyes were closed—in fact, the darkness sent me zooming off to all kinds of strange places. No, now it was when my eyes were open that the stream of thought stilled and pooled, and not only on the meditation platform; it could happen when I was moving around the cave doing chores or hiking in the woods. The miraculous everyday fact of consciousness loomed larger than “the hard problem” of how a brain produces subjective experience.

Had I “dropped in”? There were moments when all I experienced was what Roshi Joan had called the “sense field.” This happened especially upon opening my eyes in meditation, but it was never very long before I slipped back into reflection and then the inevitable jotting-down of notes, and all at once I was back in the self-world. To stay in that state of unthinking presence was like walking a tightrope only to suddenly look down, panic, and come plunging back to Earth.

Except once, when I managed to look not down but up. I had woken up in the middle of the night and stepped outside into the cold night air. There was a new moon, and the only light in the world was that of the stars, which were out in force, brighter and more numerous than I’d ever seen them, but also strangely different. Instead of dotting the same black scrim, like pinholes in a two-dimensional theater backdrop, the stars were scattered through space at dramatically varying distances, a vast swarm of them filling every last corner of an even vaster, more numinous, and emphatically three-dimensional darkness. Even stranger, the negative space between the stars had flipped to positive, forming a soft, almost palpable blackness that embraced the stars and reached all the way to Earth, enveloping it and me in the same intergalactic blanket. For the first time, I could see—no, could feel—that the stars and I shared the same infinite space.

Adam Frank: The truth physics can no longer ignore

My brain’s usual priors, predictions, and inferences about the night sky had broken down, it seemed, allowing me to see more of the galaxy and space itself than I ever had. There was hugely more of it and less of me, rendered infinitesimal in the presence of this immensity. I felt as though every previous experience I’d had of the night sky had been filtered through some idea or model or expectation and so had been something less than completely conscious. And I understood that this state—abstracted, distracted—had been my default. A line in a poem by Jorie Graham came to me:

This is what is wrong: we, only we, the humans, can retreat from ourselves and

Only we, the humans. Yes! What other animal can afford to be anything less than completely conscious?

This moment of being fully, freshly present to the universe stopped me cold and made me wonder if all my hard thinking about consciousness had missed something crucial about it. The more I focused the narrow beam of my attention on what consciousness is and what it does and how it came to be, the less of it I was actually experiencing—whatever it was. My time in the cave and, now, beneath this night sky showed me the price of my impatience with the mystery.

“Always keep a don’t-know mind,” Roshi Joan had said to me. Sometimes not knowing opens us to possibilities that knowing, or trying to know, or thinking we already know, closes off. In the years since I had embarked on this inquiry, desperate to know, I had narrowed the aperture of my awareness, sacrificing this, the glory of the night sky, for a keen intellectual focus. But as my days of solitude in these mountains had shown me, that wider circle of light, that numinous lantern of awareness, is still available to us, so long as we can break the spell of self and its distractions. Consciousness is a miracle, truly, and remains the deepest of mysteries, yes, but it is also so very simple that it can fit into a sentence: I open my eyes and a world appears.

This essay was adapted from Michael Pollan’s book, A World Appears: A Journey Into Consciousness, published next month.

​When you buy a book using a link on this page, we receive a commission. Thank you for supporting The Atlantic.</div>
        </div>
        
        <div class="card" onclick="openModal('content-24')">
            <div class="source">Slashdot</div>
            <div class="title">ReactOS Celebrates 30 Years</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-24" style="display:none;">
            <h2>ReactOS Celebrates 30 Years</h2>
            <p><strong>Slashdot | 2026-01-27</strong></p>
            <a class="original-link" href="https://news.slashdot.org/story/26/01/27/0053233/reactos-celebrates-30-years?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Follow Slashdot blog updates by subscribing to our blog RSS feed

I don&#39;t think I&#39;ve ever seen an article sit around this long with no comments.

Well, if you&#39;re into ReactOS, I guess it&#39;s proof that you&#39;re not in a rush for anything.

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

Two wrights don&#39;t make a rong, they make an airplane.  Or bicycles.</div>
        </div>
        
        <div class="card" onclick="openModal('content-25')">
            <div class="source">Slashdot</div>
            <div class="title">Lawsuit Alleges That WhatsApp Has No End-to-End Encryption</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-25" style="display:none;">
            <h2>Lawsuit Alleges That WhatsApp Has No End-to-End Encryption</h2>
            <p><strong>Slashdot | 2026-01-27</strong></p>
            <a class="original-link" href="https://it.slashdot.org/story/26/01/27/0550249/lawsuit-alleges-that-whatsapp-has-no-end-to-end-encryption?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Follow Slashdot blog updates by subscribing to our blog RSS feed

Gee, what would lead anyone think they were capable of doing such a thing?

Gee, what would lead anyone think they were capable of doing such a thing?I believe the great Harvard-educated philosopher Mark Zuckerberg said it best when he summized to say one fine day, maybe in May.. ”Dumb fucks.” - Zuck

Gee, what would lead anyone think they were capable of doing such a thing?

I believe the great Harvard-educated philosopher Mark Zuckerberg said it best when he summized to say one fine day, maybe in May..

- WhatsApp supposedly uses the Signal protocol(*), which is as good as is gets with regards to E2EE

- End to end is only as good as the said end-points. In addition to being closed source, the WhatsApp has multiple problems: an AI functionality that needs to send all your chats back to Meta&#39;s cloud unencrypted (as it&#39;s not relying on locally running models) so the AI can summarize and whatever else shit they are advertising; WhatsApp by default backs its data up onto the cloud, so if you l

it would be a lot more difficult to establish communications with new users

No, encryption between any two (initially unknown) parties is a solved cryptographical problem (and when well implemented it would survive any sniffing or even active attacks). AUTHENTICATING the other party is the problem and of course you need in this workflow to trust Whatsapp on that, and nobody ever claimed or thought otherwise I bet. It goes without saying that it&#39;s on them to insure you are talking to the one who has

When marketing say &quot;end-to-end encryption&quot; they usually mean that the apps use TLS to communicate with the backend servers,That&#39;s not the case here. Supposedly (but hard to check as its closed source) WhatsApp uses the Signal protocol for end-2-end encryption which is as good as it gets. BUT the app is still leaking the chat in a zillion different ways.E.g.: Meta-AI gets CC&#39;d every message because once someone in that group used the &quot;AI summary&quot; functionnality which automatically adds Meta&#39;s cloudd as a party to this group.E.g.: Out of the box, the App backs all its data to the cloud so you can recover your account even if your

When marketing say &quot;end-to-end encryption&quot; they usually mean that the apps use TLS to communicate with the backend servers,

That&#39;s not the case here. Supposedly (but hard to check as its closed source) WhatsApp uses the Signal protocol for end-2-end encryption which is as good as it gets. BUT the app is still leaking the chat in a zillion different ways.

E.g.: Meta-AI gets CC&#39;d every message because once someone in that group used the &quot;AI summary&quot; functionnality which automatically adds Meta&#39;s cloudd as a party to this group.

E.g.: Out of the box, the App backs all its data to the cloud so you can recover your account even if your

The backdoor was probably mandated by the feddy gov.

>&quot;The lawsuit does not provide any technical details to back up the rather sensational claims.&quot;

That is an inherent problem with closed code and closed platforms.  They can claim anything they want and there isn&#39;t much way we can verify their claims.  I admit, this story seems really sensational (a little hard to believe), but it is plausible.

Also, there can be word-trickery here.  It is possible things can be claimed to be &quot;end-to-end encrypted&quot; and yet still have ways for the mothership to decrypt anything at will (by having intentional secret holes/weaknesses, by storing your or another key, or a method they can pull the key from your device through their own control over the app, or by having master keys present at the start).  I think that would be a misuse of the term &quot;end-to-end encryption&quot;, yet term use/definitions mutate all the time.  Anyway this can backfire spectacularly if discovered and lead to a lot of legal issues- if they had denied law enforcement/courts access in the past with the excuse that they can&#39;t decrypt it and then it is discovered they could.

>&quot;Otherwise it would be end-to-middle-to-end encryption, wouldn&#39;t it?&quot;

Nope, that would imply it is being decrypted and then re-encrypted in the middle.  That doesn&#39;t have to happen.  It would still have stayed encrypted from one end (sender) to the other end (receiver).  The middle can just store the message and decrypt it later, if needed, if they have access to the keys (now or later) or a weakness/backdoor.

Here we are, arguing about end-to-end-to-man-in-the-middle word trickery, when the real issue is that they use ROT13 encryption.

If it&#39;s just tls then you only have a public key, which is not &quot;having the key&quot;.  Having the private key is what qualifies and for TLS that remains on the server side.

Meta, calls the claims &quot;false and absurd.&quot; 
Meta also says they routinely see false claims and speculation like this in lots of users&#39; WhatsApp messages - and none are true. ;-)

Meta, calls the claims &quot;false and absurd.&quot;

Meta also says they routinely see false claims and speculation like this in lots of users&#39; WhatsApp messages - and none are true. ;-)

Exploiting such loopholes would still leave them open to claims of fraud. They&#39;ve stated in no uncertain terms [whatsapp.com] that &quot;with end-to-end encryption, your messages are secured with a lock, and only the recipient and you have the special key needed to unlock and read them.&quot;.

It would be such a brazen lie that it makes me skeptical of the allegations of this lawsuit, even given my very low trust in Meta.

They claim end-to-end using signal protocol and we know that&#39;s true because the traffic can be analyzed.

When E2EE was first rolled out, a message appeared in each chat saying that communications were now secure. I always wondered how they managed to distribute the keys without Facebook ever gaining access to them. I long suspected that they might secretly keep a copy of the keys, perhaps obtained during the key distribution process itself. Now those suspicions are gone

Any supposedly secure attachment you send to your colleague will be openly stored on their phone in a place where they don&#39;t know what exists and will not likely be able to delete it

Whatsapp by default backs up unencrypted to Google/ Apple.  So Google / Apple can share with the likes of law enforcement.

Beyond this, it would surprise me if certain spy agencies didn&#39;t have a mass surveillance backdoor.  The only question is how widespread it is and how that data is being used.  For the special cases, you could hack the whole phone / compute instead of just whatsapp.

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

Two wrights don&#39;t make a rong, they make an airplane.  Or bicycles.</div>
        </div>
        
        <div class="card" onclick="openModal('content-26')">
            <div class="source">Slashdot</div>
            <div class="title">China Hacked Downing Street Phones For Years</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-26" style="display:none;">
            <h2>China Hacked Downing Street Phones For Years</h2>
            <p><strong>Slashdot | 2026-01-27</strong></p>
            <a class="original-link" href="https://news.slashdot.org/story/26/01/27/0138225/china-hacked-downing-street-phones-for-years?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Slashdot is powered by your submissions, so send in your scoop

It&#39;s weird to see a global espionage saga and say, &quot;well that&#39;s dumb. I am not a wizard with nation state resources, but I could so that on a casual weekend.&quot; Their security sucks so much that my grandson could probably accidentally do that while settling up a game server.

Dumb?  That&#39;s being polite!  BJ&#39;s phone number was on a web site for 15 years: https://www.bbc.co.uk/news/uk-... [bbc.co.uk]

The difference is the western countries admit when they get hacked.  (Not sure if the US still counts - will find out in 2028).

China?  Russia?  Iraq?  If someone is lucky, they just fire the General responsible for security.  If not lucky, they fall out of a forty story building.  And the press says it was an accident.

But they never admit what happened - because they are terrified of letting the common folk find out how bad they are at their job.

Yup, GCHQ doesnt have a massive budget for no reason.  The NSA doesnt put its huge budget into a savings account for a rainy day.  The CIA cant even operate on US soil...

If China is doing this and getting away with it, my issue is not with China but with my countries intelligence services not countering it properly.

As a Five Eyes (FVEY) member, there are security implications for the US and other members. So it&#39;s not some trivial matter to ignore.

Given how Trump is behaving towards the UK (tarifs) and Canada (tarifs and 51st state comments) right now I suspect that alliance might well be fraying at the edges anyway.

When you say Canada will be the 51st state then it&#39;s a joke.  When the president says it, its a threat.  Especially if he starts killing people inside the country and out at random.  Especially when he says &quot;no really, I&#39;m serious about attacking Greenland&quot;.  The job of President is a serious matter.  He is not there to be a comedian.  His words have a direct effect on everything.  I wish Americans would understand to take the vote seriously.

End result China&#39;s IQ reduces by 10 points listening to limey blabber.

Never trust anyone with the self-aggrandising job title &#39;Chief Mouser&#39;.

They&#39;ve likely been feeding the Chinese bogus crap for years knowing the phones were being tapped.

And Liz &quot;Bested by head of lettuce&quot; Truss.

You do realise they&#39;re not directly responsible for the security apparatus, right?

You know it will be run by Fujitsu, Capita, or Palantir, so of course their private data will be safe and secure, if over budget by an order of magnitude.

What about them? Any different from a tesla, except that they are better and cheaper?

https://militarnyi.com/en/news... [militarnyi.com]

Tesla also collects all kinds of data, and despite their &quot;opt-out&quot; claims, you can&#39;t fully opt out except by disabling their networking with an axe.

One of these companies is friendly with the PLA and the other isn&#39;t.  That&#39;s the difference.

What is a &quot;most honourable order of the bath&quot;? I assume it isn&#39;t something given you in the Hogwash school of magic.

In 2014, a couple of months after he stepped down as Director of Public Prosecutions (and more than a year before he became an MP).

Sure makes you wonder why the UK has approved that sketchy new embassy China wants to build, complete with underground rooms a few meters away from comm lines:

https://www.telegraph.co.uk/ne... [telegraph.co.uk]

Looking at it the other way - those tunnels make it easy for us to spy on them.

Spy on them doing what? Tapping data cables? Surely they&#39;re aware of the risks they&#39;re taking (or not taking, as the case may be).  Embassies are already hotspots for espionage.  They&#39;re not going to risk anything more than is necessary.

So as an actual Brit and one who isn&#39;t fucking mental.....

Basically the Chinese Embassy as it is now isn&#39;t actually in one building but spread over several buildings all of which are very old and for which plans are not available and they all have basements, the sizes of which are unknown. So our intelligence services have a bit of a clue of the layouts above ground, after all they can just go look at the house next door, but not of what&#39;s underground. Which kind of makes it a bit hard to keep an eye on wha

Always good to have your take on virtually every story these days cut and pasted some cretinous poster who thinks they&#39;re being clever.

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

Two wrights don&#39;t make a rong, they make an airplane.  Or bicycles.</div>
        </div>
        
        <div class="card" onclick="openModal('content-27')">
            <div class="source">Slashdot</div>
            <div class="title">Reddit Lawyers Force Founder to Redact 'WallStreetBets' From Miami Event</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-27" style="display:none;">
            <h2>Reddit Lawyers Force Founder to Redact 'WallStreetBets' From Miami Event</h2>
            <p><strong>Slashdot | 2026-01-27</strong></p>
            <a class="original-link" href="https://tech.slashdot.org/story/26/01/27/0147238/reddit-lawyers-force-founder-to-redact-wallstreetbets-from-miami-event?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Catch up on stories from the past week (and beyond) at the Slashdot story archive

The people who built/run the Nebula online streaming video to shy away from this sort of thing are probably feeling pretty good about themselves right now. Youtube video creators are probably sweating bullets right now. A lot of people &quot;invested&quot; in youtube channels over the years, according to this, youtube owns the IP (or at least, branding) of channels like Mr. Beast, Veratasium, etc etc

Social structures are all about fucking over the little guy.  Best of luck starting a new community platform without big money backing, and even then, best of luck.

So Reddit wants to own everything good created by their users but avoid any responsibility for anything bad created by their users via section 230.

Bad ruling by the court.  They should be required to take the bad with the good or not get to control any of it.  We know they&#39;d take option 2 if the court has made a better ruling.

The rich fucking over the poor is much older than that term you use.

And recently Rogozinsky lost this case.  This establishes the trademark WallStreetBets as owned by Reddit (for the uses for which they filed), and given that, they can control use of the trademark.  By, for example, banning its use by others for whatever reason - the reason doesn&#39;t matter, as they own the trademark.

What I think it specifically unusual about this is that Reddit didn&#39;t create this intellectual property, nor did anyone employed by them.  So it is hard to even understand on what basis the have standing to claim the copyright above the person who actually coined the name.

The reason might be somewhere in the legal gobbledygook we all have to read & sign when registering an account with Reddit.  Aside from specifically assigning away these rights, it&#39;s hard to imagine the basis for just grabbing them from the actual creator.

But I haven&#39;t tracked down nor read the actual case, so that is just speculation.

The trademark filings & other info for these marks can be found here:

- https://tsdr.uspto.gov/#caseNu... [uspto.gov]

- https://tsdr.uspto.gov/#caseNu... [uspto.gov]

Creation established copyright as per the Berne convention,  social media site ToS notwithstanding... which doesn&#39;t matter here.

The trademark of &#39;WallStreetBets&#39; was established by using it commercially, which happened the moment Reddit inserted ad content as someone surfed the subreddit.

Which sucks, is unfair, etc... but also American law.

and can thus be ignored everywhere else in the world.

It&#39;s not every day you see somebody use the courts to pound a blunt screwdriver into their own nuts. I hope the lawyers are OK.

Does anybody truly give a damn about reddit drama?

The law is about screwing you over, which to the law is perfectly reasonable.

Is anyone going to explain (please please) what WallStreetBets is all about ?

I suppose I could just scroll on by, but it&#39;s nice when posters add some meaning to their stories.

Or how to scare away your most loyal user base.

Anybody who is loyal to reddit deserves the deep rogering they&#39;re about to receive.  Reddit is a turd palace filled with turds.

Because of inertia people while whine and moan but do nothing else of substance.

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

Two wrights don&#39;t make a rong, they make an airplane.  Or bicycles.</div>
        </div>
        
        <div class="card" onclick="openModal('content-28')">
            <div class="source">Slashdot</div>
            <div class="title">Apple Launches AirTag 2 With Improved Range, Louder Speaker</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-28" style="display:none;">
            <h2>Apple Launches AirTag 2 With Improved Range, Louder Speaker</h2>
            <p><strong>Slashdot | 2026-01-27</strong></p>
            <a class="original-link" href="https://apple.slashdot.org/story/26/01/27/0047225/apple-launches-airtag-2-with-improved-range-louder-speaker?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">This is merely tracker. Do you actually expect the item to sprout arms and legs and act as a physical protector and apprehend the thief? If do, your comprehension about things is sorely deficient.Do you comprehend there may be use cases beyond your limited guesswork? For example, I&#39;m traveling. Car is at the airpot. Each day I check if it&#39;s still there. If it moves I can report things to the police within a day of its movement, rather than a week or more later when I return home. That can be the difference between a car broken into and joy rided and a car stripped for parts.

This is merely tracker. Do you actually expect the item to sprout arms and legs and act as a physical protector and apprehend the thief? If do, your comprehension about things is sorely deficient.

Do you comprehend there may be use cases beyond your limited guesswork? For example, I&#39;m traveling. Car is at the airpot. Each day I check if it&#39;s still there. If it moves I can report things to the police within a day of its movement, rather than a week or more later when I return home. That can be the difference between a car broken into and joy rided and a car stripped for parts.

And the new louder speaker will make it 50% more likely the thieves will find it. Thanks Apple!

Really? You think thieves are hanging around random boxes waiting for somebody to trigger a tag so they can select one to open?

No, really. Please. Go ahead and use case this. Draw the lines.

What boxes? We were talking about using an AirTag to track a stolen car. Ask your doctor if sanity is right for you!

I can report things to the police within a day of its movement,There&#39;s this excellent bridge I have, barely used, it&#39;s on sale only today, 30% off. Interested?You seriously think the police will give a fuck beyond adding one more number plate to their database of &quot;vehicles reported as stolen&quot;.

I can report things to the police within a day of its movement,

There&#39;s this excellent bridge I have, barely used, it&#39;s on sale only today, 30% off. Interested?

You seriously think the police will give a fuck beyond adding one more number plate to their database of &quot;vehicles reported as stolen&quot;.

Your phone can already keep track of where you left your car.

Your phone can already keep track of where you left your car.My phone and the car don&#39;t talk. I used to drop a pin but the air tag is easier and more reliable.

Your phone can already keep track of where you left your car.

My phone and the car don&#39;t talk. I used to drop a pin but the air tag is easier and more reliable.

Those same features exist in the original AirTag - that is just marketing wankery. Android got the ability to alert you to AirTags following you around soon after the originals were released.

The old ones will alert you to an unknown tracker just as well as the new ones will - you seem to have a mistaken understanding here.

Still no hole so you can actually attach it to something.

If there was a built in hole how would they sell you a case for it?

You&#39;re talking about if the sound had 50% more energy. However, since human hearing is logarithmic, doubling the energy will lead to a 3 decibel increase, which humans perceive to only be about 25% louder. When people say &quot;50 percent louder&quot;, in sound terms that is pretty close to 6 decibels (1.25 * 1.25 = 1.56), which is 4x the power.

So, they are actually pretty close to spot on. 50 percent louder can be heard roughly 2x farther away.

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

Two wrights don&#39;t make a rong, they make an airplane.  Or bicycles.</div>
        </div>
        
        <div class="card" onclick="openModal('content-29')">
            <div class="source">Slashdot</div>
            <div class="title">TikTok Alternative 'Skylight' Soars To 380K+ Users After TikTok US Deal Finalized</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-29" style="display:none;">
            <h2>TikTok Alternative 'Skylight' Soars To 380K+ Users After TikTok US Deal Finalized</h2>
            <p><strong>Slashdot | 2026-01-27</strong></p>
            <a class="original-link" href="https://tech.slashdot.org/story/26/01/27/0036229/tiktok-alternative-skylight-soars-to-380k-users-after-tiktok-us-deal-finalized?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Slashdot is powered by your submissions, so send in your scoop

Someone says &quot;authoritarianism is bad&quot;, and you assume that they&#39;re talking about Trump. Weird.

Nice try, but your side has been screaming about Trump for a full decade. TDS is a real thing, get help.

&quot;orange man bad&quot; Why yes, he is. I&#39;m glad you finally see that. What monument to civilized society builds an army of masked Gestappo men out of thugs (see where he has been recruiting if you doubt this) and is building his own secure bunker under the expected new ballroom where the East Wing once stood?

Why would he need his own army of thugs? Why would he need a new secure bunker when one already exists under the White House? Even a dolt can figure that out.

Ignore the ignorant leftists who downvoted you. Your take is based. TDS is real and is fomented by having a completely one sided media diet; ironic considering the topic at hand.

BlueSky/SkyLight are decentralized platforms owned by public benefit corporations.TikTok is still owned by ByteDance which is at least CCP-adjacent (arguably bad), but the US implementation of its algorithm is now controlled by  a group of Great American Patriots and Investors, the Biggest in the World  [truthsocial.com] (arguably worse).

These social media sites are all lost money. They come and go.

Linux showed the blueprint when it toppled Microsoft, now this generations task is to do the same to social media.

Well if it&#39;s open source I hope they beat UpScrolled that the TikTok users are apparently also fleeing to today:

https://www.engadget.com/socia... [engadget.com]

[ Okay, so I&#39;m an old fart and not the target audience... ]

Relaxing after work with my 3 screens. Anything without a web interface is a non starter.

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

Two wrights don&#39;t make a rong, they make an airplane.  Or bicycles.</div>
        </div>
        
        <div class="card" onclick="openModal('content-30')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">In Greek Mythology, Cronus Devoured All of His Offspring Except for Which Youngest Son?</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-30" style="display:none;">
            <h2>In Greek Mythology, Cronus Devoured All of His Offspring Except for Which Youngest Son?</h2>
            <p><strong>News and Politics - Slate Magazine | 2026-01-27</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2026/01/trivia-quiz-daily-slate-culture-frauds-canadians-mythology.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Please enable Javascript in your browser to view Slate interactives.

What Word Refers to Someone Who Has Supposedly Returned From the Dead?

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-31')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">How Immigration Enforcement Became So Violent</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-31" style="display:none;">
            <h2>How Immigration Enforcement Became So Violent</h2>
            <p><strong>News and Politics - Slate Magazine | 2026-01-27</strong></p>
            <a class="original-link" href="https://slate.com/podcasts/what-next/2026/01/what-are-ice-and-border-patrol-doing?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">There are precedents for masked paramilitary police grabbing people off the streets—none of them very flattering.

Please enable javascript to get your Slate Plus feeds.

If you can&#39;t access your feeds, please contact customer support.

Thanks! Check your phone for a link to finish setting up your feed.

Enter your phone number and we&#39;ll text you a link to set up the
        podcast in your app:

We&#39;ll only text you about setting up this podcast, no spam.

Apple Podcasts will only work on MacOS operating systems since Catalina. We do not support Android apps on desktop at this time.

These links will only work if you&#39;re on the device you listen to podcasts on.

We&#39;re sorry, but something went wrong while fetching your podcast feeds. Please contact us at plus@slate.com for help.

How ICE and Border Patrol’s mission became harassing the president’s personal enemies.

Guest: Radley Balko, journalist and the author of Rise of the Warrior Cop: The Militarization of America’s Police Forces and a Substack called The Watch.

Want more What Next? Subscribe to Slate Plus to access ad-free listening to the whole What Next family and across all your favorite Slate podcasts. Subscribe today on Apple Podcasts by clicking “Try Free” at the top of our show page. Sign up now at slate.com/whatnextplus to get access wherever you listen.

Podcast production by Elena Schwartz, Paige Osburn, Anna Phillips, Madeline Ducharme, and Rob Gunther.

The problem with the news right now? It’s everywhere. And each day, it can feel like we’re all just mindlessly scrolling. It’s why we created What Next. This short daily show is here to help you make sense of things. When the news feels overwhelming, we’re here to help you answer: What next? Look for new episodes every weekday morning.

Mary Harris is the host and managing editor of What Next, Slate&#39;s new daily news podcast. She has reported throughout the public radio system, for NPR, Marketplace, and WNYC.</div>
        </div>
        
        <div class="card" onclick="openModal('content-32')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">How the Supreme Court Made Alex Pretti’s Killing More Likely</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-32" style="display:none;">
            <h2>How the Supreme Court Made Alex Pretti’s Killing More Likely</h2>
            <p><strong>News and Politics - Slate Magazine | 2026-01-26</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2026/01/supreme-court-alex-pretti-killing-qualified-immunity.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Sign up for the Slatest to get the most insightful analysis, criticism, and advice out there, delivered to your inbox daily.

Immigration and Customs Enforcement and Customs and Border Protection agents have now killed two U.S. citizens in Minnesota under the made-up banner of “absolute immunity” for federal law enforcement officials, regardless of what they do or how they do it. The notion of immunity for state actors in American law goes back decades, and much of what we are seeing on the ground now in terms of violent immigration enforcement has its antecedents in long-standing and deeply flawed American ideas about good guys versus bad guys and who bears the burden of law enforcement run amok. On this week’s Amicus podcast, as the nation struggles to process the executions of Renee Good and Alex Pretti, Dahlia Lithwick was joined by Alex Reinert, the Max Freund Professor of Litigation and Advocacy at Cardozo School of Law. Their conversation has been edited and condensed for clarity.

Dahlia Lithwick: ICE agents, like all federal agents, are protected by qualified immunity, and that protects them from lawsuits for constitutional violations committed in the course of duty. And we’ve had that for a long time. Help us understand this foundational idea that for the most part, law enforcement officers cannot be held liable for their actions when they violate your rights. How did we get here?

Alex Reinert: Really, there are two foundational ideas in play in these cases involving federal officials. One is what I’m about to talk about, which is qualified immunity, and a second is something called Bivens doctrine, which is a common law doctrine that used to allow people to sue federal officials for constitutional violations. Let’s start with qualified immunity, which is not long-standing in the sense that it’s really a modern introduction to the law of constitutional torts. It was introduced by the Supreme Court in 1967 in the context of a Freedom Riders case. That was the context in which a lawsuit was brought against state and local officials, and the Supreme Court basically said: We think, even though Congress didn’t spell it out in detail in a statute that gave you the right to sue these officials, and even though Congress didn’t say anything about an immunity doctrine, we think this common law doctrine that may have existed in 1871 should be incorporated into our constitutional tort regime. Fast-forward to 1982, which is where we got a case called Harlow v. Fitzgerald. In that case the Supreme Court said: We also think there should be an immunity doctrine that applies to federal officials.

What it means in practice is that any officer—whether state, local, or federal—who violates the Constitution won’t be held liable unless there is some prior case that makes it clear, from a court’s perspective, that the officer’s conduct was obviously a violation of the Constitution.

So qualified immunity is only really used, or it really only has an impact, when an officer is violating the Constitution. If officers don’t violate the Constitution, they don’t need the protection of qualified immunity. It’s only when officers violate the Constitution that they are able to obtain the protection of qualified immunity.

On its face, if you explained it to somebody and said that we should only hold officers liable when they were on reasonable notice of the unlawfulness of their conduct, people might look at it and think that makes sense. In practice, it has been applied in the widest range of circumstances where most people would say: How is it possible? How is it possible that somebody could get immunity when, for instance, they’re ordered by their supervisor not to fire a shot and they fire six shots and kill someone? When they are executing a search warrant and they decide to steal about $200,000 worth of valuables and a court says, Well, there’s qualified immunity because there wasn’t a prior case in point saying that when you’re executing a search warrant, you can’t steal money? Those are the kinds of cases in which qualified immunity comes into play.

It’s probably shocking to the ordinary person that in this country, a country purported to be governed by the rule of law, and where the Constitution is thought of as foundational, it turns out that violations of the Constitution by our highest-level officers and officials aren’t remediable because of this doctrine of qualified immunity.

Explain Bivens doctrine now, to set the table for what follows.

This is the other part of what is a perverse design of our constitutional scheme. Bivens is special because it applies only to federal officials. When state and local officials violate our rights, there’s a statute that goes all the way back to Reconstruction enacted in 1871 that allows us to sue state and local officials for violations of our constitutional rights. Qualified immunity still applies, but at least there’s a right to sue. There is no similar statute when federal officials violate the Constitution.

In 1971, in a case by the name of Bivens, the Supreme Court said: We think that we are going to find a right to sue in the Fourth Amendment, for Fourth Amendment violations when federal officials violate someone’s rights. Over the course of the next 10 years, the Supreme Court expanded that doctrine to include Eighth Amendment violations, and claims for sex discrimination. During the 1970s, lower courts were also rapidly expanding the Bivens doctrine.

All that changed in 1980. From 1980 on, the Supreme Court said: We are not going to entertain Bivens actions. And the court has given us a variety of reasons to the point where today, when the Supreme Court hears a Bivens claim, it basically says: We’re not sure that this court would even recognize the right to sue federal officials for constitutional violations. We’re certainly not going to extend that right to sue beyond the narrow category of the three cases in which the Bivens right was recognized in the 1970s. Furthermore, we’re going to confine those categories very narrowly.

I come back to this principle that we have a Constitution that is supposed to be meaningful in this country and it’s supposed to govern the conduct of all of our officers. It’s perverse that we have a federal Constitution that means less for federal officials than it does for state and local officials. We have a federal Constitution that is harder to enforce against federal officials than almost anyone else. That’s really a product of the Bivens doctrine.

And the last piece of this that I think is really important, just historically, for people to understand is that this wasn’t the model of remediation we had in the 19th century. You could sue federal officers in the 19th century when they violated your rights. It was not a unique occurrence. It was accepted that this was a way for people to obtain remedies. It also was accepted that it was a way to test the legality of executive conduct, of the policies and conduct of federal officials. Now we live in this world in which there are so many barriers to that kind of accountability, to those tests for legality.

That’s just a bad way to design courts. We want to learn from our mistakes. We want law to be able to develop if it should. It’s also bad, obviously, for people who are bringing these kinds of claims. I also think  it’s bad for policing. We want police to do their job consistent with the Constitution. Having answers to the question of when they violate rights and when they don’t should be, and is, important to them. So we’re losing all these opportunities in these cases to develop the law in ways that I think should help everyone.

Last week the AP reported a whistleblower complaint that showed that in violation of long-standing Fourth Amendment principles, ICE is taking the position that they can just enter folks’ homes without a judicial warrant. They can just use an administrative warrant. The whistleblower complaint alleges that the secret memo outlining this policy, signed by acting deputy ICE Director Todd Lyons, says, “although the U.S. Department of Homeland Security has not historically relied on administrative warrants alone to arrest aliens subject to final orders of removal in their place of residence, the DHS Office of General Counsel has recently determined that the U.S. Constitution, the INA, and the immigration regulations do not prohibit relying on administrative warrants for this purpose.”

I think it is extremely concerning and also an untenable interpretation of the Fourth Amendment. The Supreme Court hasn’t addressed this question, but the whole premise of the warrant requirement is that there should be some independent adjudicator—someone outside the executive branch—to decide whether or not there is a justification for invading the sanctity of someone’s home. Administrative warrants don’t provide that; judicial warrants do. That doesn’t mean judicial warrants are perfect, but they are at least outside the executive branch. It’s important from a separation-of-powers perspective, of course, and it’s important from an institutional design perspective. We already have so much about the immigration system over which the executive has so much authority: the appointment of immigration judges, all of these policy memos. So to fold the power to issue warrants, and act on warrants, into the executive in this way is just an extreme power grab. And the line about use of force gets us back to what we were talking about with Bivens and qualified immunity, which is when the officers use force in those circumstances, when they go overboard in their use of force—as inevitably some will—what kinds of remedies will there be? Those will be few and far between.

It reminds me of Justice Kavanaugh’s concurrence in Noem v. Vasquez-Perdomo, where he says, essentially, People are talking about use of force, but this case isn’t about use of force. If there is a use of force, then people should be able to go to court and sue. He says all that in his concurrence, but at the same time we know that Justice Kavanaugh is one of the justices who has led the charge for undermining the Bivens remedy. It’s exactly what the Supreme Court does in so many contexts in the civil rights world. They’ll say: We’re not going to give you this remedy here, but don’t worry. There’s all these other ways you can enforce your rights. And then when they’re over there in the other box, they say: Well, we’re not going to allow you to enforce your rights here because there’s something else over here. Pam Karlan calls it a shell game and it works like this: When I’m over here, I’m going to say, Don’t worry about me limiting your rights because there’s some other way for you to enforce them. And then I’m just going to undermine your means of enforcing them in that other part of the jurisprudence. So it is troubling to the extreme that ICE officers are going to be acting on this authority.

Since 2020, and the murder of George Floyd and the flash of recognition that police reform was past due, there has been a significant public silence. As a consequence, in that silence, we have to grapple with that which makes us very uncomfortable. By “we” I mean a culture that has turned a blind eye to a lot of these issues and is suddenly startled by the ways police immunity and impunity have been weaponized for immigration enforcement. So help us think through reform in ways that are conducive to meaningful accountability and conducive to having a civic life that doesn’t include masked officers pepper-spraying or shooting somebody who’s already restrained on the ground. How do we think in a bigger, more generous way about getting to where we want to be?

I guess I would think about it in at least two different ways. The first is part of the reason there’s resistance to increasing accountability, particularly for our policing apparatus. It has to do with the sense that it’s a hard job. And it’s a job that at some level, most people think we need people to do. And what do we do when something that people see as really important, that’s also hard, what do we do when that imposes costs? When that imposes costs on people who did nothing wrong, who are left traumatized, maybe dead, seriously injured? I’ve always thought that the problem with a lot of the doctrine we’ve been talking about is it leaves those costs on the people who suffered them. It leaves those costs directly on the people who suffered them. But if we allow it, if we think there’s something good that comes out of policing, if we think it creates some value for the public at large, why should the costs be borne solely by the people who suffered most significantly as a result of it? So that’s one piece of it that always resonates with me about why some of the doctrine we’ve been talking about is so wrong.

For a while, or at least for I don’t know how long of a moment after the murder of George Floyd, there was a conversation. I would go to demonstrations and I’d see signs that said “End qualified immunity.” There was a way in which the doctrine that previously mostly lawyers knew about or scholars were talking about and mostly other people didn’t know about, that doctrine came into the public consciousness and became important. I think there is still some of that going on. I think there is still some momentum for that.

When we think about accountability, we usually think about accountability for an individual, an individual who behaved in some unlawful way. It makes sense to think about accountability that way. But the problems we’re talking about are systemic. That doesn’t mean there aren’t some individuals, the so-called bad apples, who no matter what kind of training we have, no matter what way we approach hiring, no matter what kind of supervision we provide, there are some people who may just act egregiously because they can, because they have a badge. But I think for the most part, the problems we’re talking about are systemic. And if the problems are systemic, then talking about accountability for individuals isn’t necessarily the right frame. I think we need to approach solutions to the problem systemically. And those solutions are as much about: Who ends up paying the damages for the people who suffer? Should it be the individual officer or should it be the departments that employ them? As a matter of practice, it’s always the departments who employ them. So we need to find a way for those agencies to learn better from the kinds of misconduct that their officers enter into. But it’s also about the legal regime that we set up to allow people to sue and what kinds of things they sue for, the way we allow people, really limit the ability of people, to bring so-called injunctive relief and systemic reform of departments.

So if we think about accountability more broadly, and we think about the problems we’ve been talking about, through a systemic lens, it’s not so much about the individual officer. It’s about creating a legal regime that allows us to get answers to the questions of how people were mistreated, whether the way in which they were mistreated was unlawful, and making sure that we can build systems so that it doesn’t keep happening. Because right now we’re in a world where it is happening over and over again and it seems like there are very few tools in our toolbox to prevent the reoccurrence.

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-33')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">Are Democrats Going to Vote for More Money for ICE?</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-33" style="display:none;">
            <h2>Are Democrats Going to Vote for More Money for ICE?</h2>
            <p><strong>News and Politics - Slate Magazine | 2026-01-26</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2026/01/ice-funding-and-alex-pretti-will-democrats-shut-down-the-government.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Sign up for the Slatest to get the most insightful analysis, criticism, and advice out there, delivered to your inbox daily.

Early Saturday morning, it appeared as if enough Senate Democrats were willing to fund the Department of Homeland Security and its deportation machine, if that’s what it took to keep the rest of the government open.

The House had passed funding for the DHS late last week, with seven centrist Democrats joining nearly all Republicans to get it over the line. The Senate was to take it up this week alongside a handful of other funding bills. It was expected that, as with the House vote, enough Democrats would hold their noses and support it, even if it meant absorbing blowback from a furious Democratic base that has been dusting off the largely dormant “Abolish ICE” slogan. Democratic negotiators felt that approving full-year, carefully negotiated spending bills and reasserting Congress’ power of the purse over a freewheeling executive branch was the priority of the moment.

“There is much more we must do to rein in DHS, which I will continue to press for,” Sen. Patty Murray, the top Democrat on the Senate Appropriations Committee, said in a statement last Tuesday, once the deal was released. She listed some pittances she had secured in the DHS bill, such as more money for body cameras for Immigrations and Customs Enforcement. She knew, though, that wouldn’t ease any anger within the base. Ultimately, she leveled.

“But the hard truth,” she added, “is that Democrats must win political power to enact the kind of accountability we need.”

All of this changed on Saturday in Minneapolis, when Border Patrol agents killed 37-year-old observer Alex Pretti. All of this changed when videos showed Pretti subdued, being pepper-sprayed and then shot, over and over again, without brandishing the firearm that he was permitted to carry. All of this changed when, as after the killing of Renee Good, White House adviser Stephen Miller and DHS Secretary Kristi Noem absurdly described Pretti as a “domestic terrorist” or “assassin.” After Pretti’s killing and the administration’s eyesight-defying remorselessness over what happened, there was no way Senate Democrats could put their fingerprints on a bill to fund the administration’s deportation machine.

“I will NOT support the DHS bill as it stands,” Patty Murray said Saturday.

She was hardly the only one. Democrats who’ve previously broken from the pack to join Republicans in advancing government funding bills, like Sens. Tim Kaine, Catherine Cortez Masto, Angus King, and Jacky Rosen, all said the same. On the House side, meanwhile, one Democrat who had voted for the DHS funding bill, New York Rep. Tom Suozzi, offered a mea culpa on social media, saying that he had “long been critical of ICE’s unlawful behavior and I must do a better job demonstrating that.”

Senate Democratic Leader Chuck Schumer put a bow on Democrats’ new posture Saturday night: Democrats would filibuster DHS funding without changes. And it didn’t sound like there was much handwringing about it.

Does this make a partial government shutdown, after funding lapses after Jan. 30, inevitable? Let’s say much more likely. The situation is complicated for reasons including, but not limited to, the weather.

The funding bill the Senate will be voting on does not just cover DHS. It combines half a dozen bills that the House has passed in January funding everything from the Pentagon to the State Department to the departments of Health and Human Services, Transportation, Education, Labor, and more. Although this package includes only half of the 12 yearly appropriations bills, the specific departments it includes—especially Defense and HHS—comprise a comfortable majority of annual spending.

Senate Democrats are calling on their Republican counterparts, in Schumer’s words, to “work with Democrats to advance the other five funding bills while we work to rewrite the DHS bill.” In other words, to strip DHS funding from the package, pass everything else, and then allow for more time to negotiate the DHS budget.

Would Republicans be willing to do this? They typically don’t take orders from Democrats. But Republican leaders, just as much as Democratic ones, don’t want appropriators’ delicate work on the biggest funding bills to get sent to an incinerator of fury. The New York Times reported Saturday that “recognizing the depth of Democratic rage,” Senate Republicans “immediately began examining whether they could separate the homeland security funding from the rest of the package and preserve the bulk of what had been a bipartisan deal to fund a large chunk of the government.” Maine Sen. Susan Collins, the chair of the Appropriations Committee, said her committee was “exploring all options.”

If—if—leaders in the Senate reach an agreement to amend the package, then there’s another problem: The House is on recess this week, and House Republicans’ leaders wouldn’t be particularly enthused about summoning members to Washington to revote on a package amended at Democrats’ request. Plus, a substantial portion of the continental United States is buried under a sheet of ice and snow, conditions that aren’t conducive to travel.

It’s important to note that a lapse in DHS funding wouldn’t impede deportation operations much. As Patty Murray repeatedly said when she was trying to push the deal through, ICE is sitting on substantial funds that were made available to it in Republicans’ party-line megabill last year.

Murray is still saying that, posting on Sunday that “Americans must be eyes wide open that blocking the DHS funding bill will not shut down ICE. ICE is now sitting on a massive slush fund it can tap, whether or not we pass a funding bill.”

“But,” she added, “we all saw another American shot and killed in broad daylight.” They’re not about to bless it with their votes.

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-34')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">“Oh, Shit, That Was Alex”: What It’s Like to Discover That Your Friend and Colleague Was Killed by Federal Agents</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-34" style="display:none;">
            <h2>“Oh, Shit, That Was Alex”: What It’s Like to Discover That Your Friend and Colleague Was Killed by Federal Agents</h2>
            <p><strong>News and Politics - Slate Magazine | 2026-01-26</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2026/01/ice-cbp-alex-pretti-icu-nurse-video-kind-guy.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Sign up for the Slatest to get the most insightful analysis, criticism, and advice out there, delivered to your inbox daily.

On Saturday, Alex Pretti was pushed to the ground and fatally shot by federal agents. Video shows that, moments before, Pretti was holding a cellphone in one hand and had his other hand up. Pretti was 37 and worked as an ICU nurse at a VA hospital. He enjoyed biking and had a dog named Joule.

Later that day, What Next’s Mary Harris spoke to Dimitri Drekonja, a colleague and friend of Pretti’s, who remembers him as “a kind guy” who modeled cooperation and who, right out of school, took one of the hardest jobs available to nurses. Their conversation has been edited and condensed for clarity.

Mary Harris: How did you learn about what happened?

Dimitri Drekonja: We were at [my son’s ski] race in the morning, and one of the other parents said, “Did you hear there was another shooting?” It sort of filtered through: “It sounds like another shooting.” “Another person died.” And there was a lot of sort of like, “This is just heavy.” “Awful.”

And then we got back from the race, and on a group chat, someone said, “ICE executed Alex Pretti.” [Editor’s note: It later became clear that the officers were with Customs and Border Protection.] It was from our group that we had had when we had first hired him to be study staff on our research project. It was like, What? You have to be kidding me.

I had seen one of the videos. [In it,] you can’t see the defined definitions of someone’s face and recognize them. But once the name was out there and I saw the build, the facial hair, it’s like, Oh, shit, that was Alex.

People have asked, “Are you surprised that he was protesting?” And, in all honesty, no one can be surprised that anyone in Minneapolis is protesting. We see 80-year-olds out protesting. We see kids out protesting. The city is pretty, pretty pissed off about what is happening, and people are out there doing their civic duty of being out there peacefully protesting.

Have you been able to watch the videos? I can’t stop myself watching the videos.

I don’t know how you watch someone you know—

I have not sought them out. I mean, my wife has shown me some, like, “Oh, God, with this new view you can see …” I’ve seen a few that way. It’s awful.

You posted on social media that you were feeling white-hot rage. What do you do with that feeling in this moment?

Right now, delay going to dinner with friends because I don’t feel terribly sociable. I’ve been really appreciative of people who have been reaching out to say, “Hey, sorry to hear—sounds like Alex was a great guy. This is hard.”

I think other people are enraged. I think the worst thing right now would be to have random violence. I’ve been really proud of Minneapolis—the scope and scale of the protests, the fact that they have been peaceful.

The administration has said your friend must have been trying to kill officers. Is there something you want to tell people who may have that belief about Alex?

The thing that I would say is that I have known Alex for years. I’ve known him to be a kind guy, a guy quick with a laugh, a joke, willing to help. He has never shared a conspiracy theory or shared anger at a group or been unpatriotic. I mean, he is the kind of guy that you would want as your neighbor and your friend. I would be thrilled if he were to move into the house next door.

We have a shared interest in mountain biking. We were planning on going out together. I was always the one who was having to say, “No, sorry, my kid has a race this week. Can’t do it.” But we liked the same trail systems, and we talked about riding them.

I have observed him clinically. He is fabulous, he gives great assessments, he’s enthusiastic, he is smart, and I will just say that anybody going into the ICU fresh out of nursing school—you’re gonna deal with very sick patients. A [large] percent of the patients in the ICU will die, and you’ll have to deal with grieving, upset families. You’ll have to use all your skills to try to keep that person alive. To do that right out of nursing school is impressive.

Sometimes medicine is a hierarchical place. He was not like that, and I loved that. I would run into him, and he would say, “Hey, Dimitri, how’s it going? It’s good to see you again.” I love that he had that informal relationship. I love it was modeled for trainees who worked with us. Like, yeah, this is how you do it: You’re colleagues, you’re friendly, you are nice to each other, and you work well together.

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-35')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">What Word Refers to Someone Who Has Supposedly Returned From the Dead?</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-35" style="display:none;">
            <h2>What Word Refers to Someone Who Has Supposedly Returned From the Dead?</h2>
            <p><strong>News and Politics - Slate Magazine | 2026-01-26</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2026/01/trivia-quiz-daily-slate-vocabulary-definitions-bible-synonyms.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Please enable Javascript in your browser to view Slate interactives.

In Greek Mythology, Cronus Devoured All of His Offspring Except for Which Youngest Son?

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-36')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">Micron builds $24 bn Singapore chip fab as AI demand soars</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-36" style="display:none;">
            <h2>Micron builds $24 bn Singapore chip fab as AI demand soars</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2026-01-27</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2026-01-micron-bn-singapore-chip-fab.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-37')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">French lawmakers pass bill banning social media for under-15s</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-37" style="display:none;">
            <h2>French lawmakers pass bill banning social media for under-15s</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2026-01-27</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2026-01-french-lawmakers-bill-social-media.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-38')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">Hybrid cars top choice for consumers in Europe in 2025: data</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-38" style="display:none;">
            <h2>Hybrid cars top choice for consumers in Europe in 2025: data</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2026-01-27</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2026-01-hybrid-cars-choice-consumers-europe.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-39')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">Geothermal energy has the potential to reshape global power supply</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-39" style="display:none;">
            <h2>Geothermal energy has the potential to reshape global power supply</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2026-01-27</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2026-01-geothermal-energy-potential-reshape-global.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-40')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">How to include fossil fuel communities in Canada's clean energy transition</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-40" style="display:none;">
            <h2>How to include fossil fuel communities in Canada's clean energy transition</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2026-01-26</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2026-01-fossil-fuel-communities-canada-energy.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-41')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">Artificial metacognition: Giving an AI the ability to 'think' about its 'thinking'</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-41" style="display:none;">
            <h2>Artificial metacognition: Giving an AI the ability to 'think' about its 'thinking'</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2026-01-26</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2026-01-artificial-metacognition-ai-ability.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-42')">
            <div class="source">The Register</div>
            <div class="title">Microsoft illegally installed cookies on schoolkid's tech, data protection ruling finds</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-42" style="display:none;">
            <h2>Microsoft illegally installed cookies on schoolkid's tech, data protection ruling finds</h2>
            <p><strong>The Register | 2026-01-27</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2026/01/27/microsft_illegally_installed_cookies_ruling_austra_school/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Microsoft illegally installed cookies on a school pupil&#39;s devices without consent, according to a ruling by the Austrian data protection authority (DSB).

In the second ruling [PDF], won by Austria-based campaign group None of Your Business (noyb), the authority found that Microsoft acted unlawfully when it placed tracking cookies on the devices of a minor using Microsoft 365 Education.

Microsoft&#39;s own documentation says these cookies analyze user behavior, collect browser data, and are used for advertising. The DSB has also said the US software firm should stop tracking the complainant – whose identity was not disclosed – within four weeks. Both the school and the Austrian Ministry of Education claimed they were not aware of the tracking cookies before noyb raised the complaints.

Microsoft now has four weeks to comply and cease the use of tracking cookies on the devices of the minor. The Register has asked Microsoft to comment.

In a statement, Felix Mikolasch, data protection lawyer at noyb, said: &quot;Tracking minors clearly isn&#39;t privacy-friendly. It seems like Microsoft doesn&#39;t care much about privacy, unless it is for their marketing and PR statements.&quot;

In 2024, noyb asked the Austrian data protection authority to investigate Microsoft 365 Education to clarify if it breaches transparency provisions under GDPR. It said the tech giant pushed data protection obligations onto schools that use the system, and failed to comply with subjects&#39; right to access data about them. Neither Microsoft&#39;s privacy documentation, requests for access, nor noyb&#39;s research could fully clarify what data about children is being processed by Microsoft 365 Education.

The complaint dates back to the COVID-19 pandemic, when schools rapidly shifted to online learning, using the likes of Microsoft&#39;s 365 Education as well as Google&#39;s Workspace for Education and others.

In October last year, the Austrian digital privacy group claimed its first victory in the case, after the DSB ruled Microsoft had &quot;illegally&quot; tracked students via its 365 Education platform and tried to shift responsibility for access requests to local schools.

The authority ordered the software giant to provide complete information about the data transmitted, and to provide clear explanations of what was meant by terms such as &quot;internal reporting,&quot; &quot;business modeling&quot; and &quot;improvement of core functionality.&quot; ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-43')">
            <div class="source">The Register</div>
            <div class="title">High Court to grill London cops over live facial recognition creep</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-43" style="display:none;">
            <h2>High Court to grill London cops over live facial recognition creep</h2>
            <p><strong>The Register | 2026-01-27</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2026/01/27/high_court_lfr/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The High Court will hear from privacy campaigners this week who want to reshape the way the Metropolitan Police is allowed to use live facial recognition (LFR) tech.

Civil liberties group Big Brother Watch is supporting the case brought by claimant and anti-knife crime campaigner Shaun Thompson, who said that after being misidentified by LFR cameras in Croydon, police demanded he submit his fingerprints.

&quot;I was misidentified by a live facial recognition system while coming home from a community patrol in Croydon,&quot; said Thompson. &quot;Police officers told me I was a wanted man and demanded my fingerprints even though I&#39;d done nothing wrong. What happened to me was shocking and unfair.&quot;

The High Court hearing will take place on Tuesday and Wednesday, with the legal challenge [PDF] focusing on alleged violations of privacy rights, which are protected by Article 8 of the European Convention on Human Rights (ECHR).

Thompson&#39;s lawyers, with input from Big Brother Watch director Silkie Carlo, will argue that the Met&#39;s LFR policy is too permissive to be compatible with the human right to privacy.

They will argue that the Met&#39;s policy, which allows the force to operate LFR cameras in &quot;crime hotspots,&quot; and &quot;access routes&quot; to those hotspots, is too broad a constraint, given that most parts of London could reasonably fall under the &quot;crime hotspot&quot; definition.

Carlo also submitted her arguments to the case that the Met&#39;s LFR policies threaten the rights protected under Articles 10 and 11 of the Convention, as pop-up deployments allegedly restrict people&#39;s ability to protest.

She said: &quot;The possibility of being subjected to a digital identity check by police without our consent almost anywhere, at any time, is a serious infringement on our civil liberties that is transforming London. When used as a mass surveillance tool, live facial recognition reverses the presumption of innocence and destroys any notion of privacy in our capital.

&quot;We are totally out of step with the rest of Europe on live facial recognition. This is an opportunity for the court to uphold our democratic rights and instigate much-needed safeguards against intrusive AI-driven surveillance.&quot;

The High Court hearing comes a month after the UK government announced plans to &quot;ramp up&quot; police use of facial recognition and biometrics.

The Home Office opened a consultation for experts to weigh in on new laws that will govern a responsible increase in this technology&#39;s use, so that police can use it more often and with greater confidence.

Sarah Jones, crime and policing minister, said facial recognition technology &quot;is the biggest breakthrough for catching criminals since DNA matching.&quot;

&quot;It has already helped take thousands of dangerous criminals off our streets and has huge potential to strengthen how the police keep us safe,&quot; she added.

&quot;We will expand its use so that forces can put more criminals behind bars and tackle crime in their communities.&quot; ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-44')">
            <div class="source">The Register</div>
            <div class="title">NASA confirms command error temporarily felled TESS planet hunter</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-44" style="display:none;">
            <h2>NASA confirms command error temporarily felled TESS planet hunter</h2>
            <p><strong>The Register | 2026-01-27</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2026/01/27/nasa_tess_error/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">NASA has confirmed that its planet hunter, TESS (Transiting Exoplanet Survey Satellite), entered safe mode due to a command error that inadvertently left the spacecraft&#39;s solar arrays angled away from the Sun.

TESS was recovered days after entering safe mode due to discharged batteries. This was caused by the vehicle&#39;s solar panels being pointed away from the Sun, which meant the batteries could not charge sufficiently. The incident was the result of a command transmitted from the ground.

The plan was to slew TESS to point at a target. When it entered safe mode, TESS was conducting a week-long observation of comet 3I/ATLAS.

A NASA spokesperson told The Register that there were no guardrails in place to prevent this scenario, although there were protections to prevent the spacecraft&#39;s batteries from draining completely. It is likely these kicked in and sent the spacecraft into safe mode, from which it could be recovered.

A spacecraft&#39;s safe mode shuts down all but the most essential systems, usually maintains attitude control, and awaits instructions from controllers. It is designed to protect the vehicle.

A spokesperson at the space agency added: &quot;The mission is reviewing and updating procedures to prevent this command error from happening in the future.&quot;

In many ways, TESS was lucky. There are plenty of examples of spacecraft being left borked after a command from Earth had unintended consequences. The Viking 1 Mars lander, for example, ended its mission in 1982 after a faulty command from Earth terminated communications, and attempts to regain contact proved unsuccessful.

There is also the Solar and Heliospheric Observatory (SOHO) probe, a joint NASA-ESA project. In 1998, a step was skipped in a routine calibration procedure, effectively disabling the spacecraft&#39;s normal safe mode and triggering a catastrophic series of events that left the spacecraft tumbling in space. It was only through some impressive engineering teamwork and persistence that SOHO was located and eventually recovered.

Fortunately, TESS&#39;s safe mode worked as designed and kept the spacecraft in a state where engineers could restore it after realizing that something had not gone to plan.

However, it will be interesting to see how a command that resulted in a borked spacecraft was sent up in the first place, and how NASA&#39;s boffins plan to ensure this doesn&#39;t happen again. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-45')">
            <div class="source">The Register</div>
            <div class="title">'Ralph Wiggum' loop prompts Claude to vibe-clone commercial software for $10 an hour</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-45" style="display:none;">
            <h2>'Ralph Wiggum' loop prompts Claude to vibe-clone commercial software for $10 an hour</h2>
            <p><strong>The Register | 2026-01-27</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2026/01/27/ralph_wiggum_claude_loops/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Feature Open source developer Geoff Huntley wrote a script that sometimes makes him nauseous. That&#39;s becaues it uses agentic AI and coding assistants to create high-quality software at such tiny cost, he worries it will upend his profession.

Here&#39;s the script :

while :; do cat PROMPT.md | claude-code ; done

Huntley describes the software as &quot;a bash loop that feeds an AI&#39;s output (errors and all) back into itself until it dreams up the correct answer. It is brute force meets persistence.&quot; He calls the code and the technique it enables &quot;Ralph,&quot; a homage to 1980s slang for vomiting, and to Simpsons character Ralph Wiggum and his combination of ignorance, persistence, and optimism.

The Register put it to Huntley that current human-in-the-loop practices mean developers use AI coding assistants as if playing table tennis: They send a prompt to produce some code over the net, and the LLM bats back some code. He accepted the metaphor, which assumes the developer/bot game continues until the human is satisfied the AI produced something useful, picks up the ball, and goes away to work.

Huntley&#39;s approach changes the game by telling a coding assistant to attempt to satisfy a developer&#39;s requests, assess whether it did so, then try again until it delivers the desired results. Humans remain in the loop, but enter the software development process later and less often than is the case today.

The developer has used his approach, and Anthropic&#39;s Claude Code service, to clone commercial products, a job it can achieve if provided with resources including source code, specs, and product documentation.

Huntley has documented how he used Ralph to create an a tax app for the ZX Spectrum, and later reverse-engineered and cloned an Atlassian product.

Huntley told us he used his techniques to clone a version of open source software a commercial vendor offers under a license he feels doesn&#39;t meet his needs. After accessing the company&#39;s source code and trans-piling it into another language, he used Ralph to drive Claude Code and create a clone. The results weren&#39;t great because he didn&#39;t have a spec for the product, but feeding the vendor&#39;s documentation into his loop meant Claude eventually produced better software.

The developer told The Register AI can tackle such tasks while consuming about US $10 of compute and/or SaaS resources each hour, a sum he points out is far closer to wages paid to fast food workers than the far better salaries earned by software developers.

Huntley even used his approach to develop a new programming language that he called &quot;Cursed.&quot;

&quot;It&#39;s cursed in its lexical structure, it&#39;s cursed in how it was built, it&#39;s cursed that this is possible, it&#39;s cursed in how cheap this was, and it&#39;s cursed through how many times I&#39;ve sworn at Claude,&quot; he wrote.

He also wonders if the fact it was possible to create Cursed might have hexed the software industry. Which is why Huntley&#39;s creation sometimes makes him feel nauseous, and why through 2025 he sometimes paused work on his ideas.

But he kept talking about them with other developers, and after a visit to Silicon Valley noticed considerable interest in his approach – especially among startups.

He says many participants in prominent startup incubator Y Combinator now use Ralph, and that the buzz their efforts created eventually saw Anthropic learn of his work and create a Ralph Wiggum Plugin for its Claude Code product. The creator of Claude Code, Boris Cherny, has said he uses Ralph.

Huntley thinks he has stumbled upon an idea that can change software development, and perhaps entire industries.

Developers, he argues, should now spend more time thinking about writing loops that drive coding assistants to produce better output, rather than persisting with code reviews.

&quot;Agile and standups doesn&#39;t make sense any more,&quot; Huntley said. &quot;The days of being a Jira ticket monkey are over.&quot;

He also thinks that Ralph poses a profound challenge to any business. &quot;Companies have a brand that can&#39;t be cloned and goodwill that can&#39;t be cloned,&quot; he told The Register. &quot;But product features can now be cloned.&quot;

Huntley therefore expects that startups will use Ralph to clone existing businesses – especially SaaS outfits – and undercut the prices they charge because they can afford to do so using agentic coding that costs $10 an hour instead of having to pay a full staff of human coders.

And that&#39;s a scenario that could make many, many, people feel very sick indeed. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-46')">
            <div class="source">The Register</div>
            <div class="title">Office zero-day exploited in the wild forces Microsoft OOB patch</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-46" style="display:none;">
            <h2>Office zero-day exploited in the wild forces Microsoft OOB patch</h2>
            <p><strong>The Register | 2026-01-27</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2026/01/27/office_zeroday_exploited_in_the/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Microsoft has issued an emergency Office patch after confirming a zero-day flaw is already being used in real world attacks.

The flaw, tracked as CVE-2026-21509, and slapped with a CVSS score of 7.8, falls into Microsoft&#39;s &quot;security feature bypass&quot; bucket. In practice, this means attackers can dodge protections that are supposed to stop unsafe legacy components from running. Those components include COM and OLE – old Windows plumbing that&#39;s been at the heart of document-based attacks for years and clearly hasn&#39;t earned its retirement yet.

According to Microsoft, exploitation doesn&#39;t hinge on the Office preview pane – often a red flag in past campaigns – but still requires little effort once a victim is persuaded to open a booby-trapped file. In its advisory, the company describes the issue as a case of &quot;reliance on untrusted inputs in a security decision,&quot; a polite way of saying Office can be talked into doing things it shouldn&#39;t.

&quot;Reliance on untrusted inputs in a security decision in Microsoft Office allows an unauthorized attacker to bypass a security feature locally,&quot; Microsoft said. &quot;An attacker must send a user a malicious Office file and convince them to open it.&quot;

The flaw hits most current Office builds, from Office 2016 and 2019 through to the LTSC releases and Microsoft 365 Apps for Enterprise. Updates are out for newer versions, but anyone still running Office 2016 or 2019 is stuck waiting. Microsoft says fixes for those editions aren&#39;t ready yet and will ship &quot;as soon as possible.&quot;

In the meantime, Redmond is pointing affected customers toward mitigation steps that it says can reduce exploitation risk. Those involve manually blocking vulnerable COM and OLE controls via the Windows registry by adding a specific COM Compatibility key and setting a Compatibility Flags DWORD value. It&#39;s the sort of workaround that many organizations will struggle to deploy consistently at scale.

Microsoft has been tight-lipped about how CVE-2026-21509 is being abused, offering no details on attack campaigns, victim profiles, or impact. The company credited its own Microsoft Threat Intelligence Center, Microsoft Security Response Center, and Office Product Group Security Team with discovering the issue.

The US Cybersecurity and Infrastructure Security Agency has been quick to add the flaw to its Known Exploited Vulnerabilities catalog, giving Federal Civilian Executive Branch agencies until February 16 to apply available fixes.

The patch comes only days after Microsoft sounded the alarm about CVE-2026-20805, a separate Windows bug already under attack, giving 2026 an uncomfortably familiar feel. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-47')">
            <div class="source">The Register</div>
            <div class="title">Voyager 2's close encounter with Uranus wasn't in the original plan</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-47" style="display:none;">
            <h2>Voyager 2's close encounter with Uranus wasn't in the original plan</h2>
            <p><strong>The Register | 2026-01-27</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2026/01/27/40_years_voyager_2_uranus/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">It is 40 years since Voyager 2 performed the first and, so far, only flyby of the planet Uranus. The resulting trove of data, however, was a bonus that almost didn&#39;t happen.

At the time of Voyager 2&#39;s launch, Uranus wasn&#39;t part of the formal plan. The mission was referred to for a long time as the Mariner Jupiter-Saturn project. The JPL engineers famously had other ideas and ensured the spacecraft had enough fuel to continue on a trajectory to Uranus and beyond if the mission was approved.

As it was, Voyager 1 performing a successful flyby of Saturn&#39;s moon Titan meant that Voyager 2 could continue on the Grand Tour, taking in Uranus and Neptune.

Former Voyager scientist Garry Hunt told The Register: &quot;It was a fantastic encounter because it almost didn&#39;t happen. After Saturn, we had the scan platform problem. If that problem had not been resolved, there wouldn&#39;t have been a Uranus encounter.&quot;

Following the Saturn encounter, the Voyager scan platform, an assembly that allowed cameras to pan and tilt, seized on the horizontal axis. The failure would have resulted in a significant data loss and was traced to a lubrication problem. Engineers were able to rectify the issue remotely, and the probe dodged a bullet on its way to Uranus.

&quot;It was a testing encounter,&quot; recalled Hunt. &quot;In the interim period between the &#39;82 encounter with Saturn and getting to Uranus, the engineers had to reorganize how the scan platform was operating. The computer system had to be altered again. All the sequencing had to be dealt with in a new manner, and we had to prepare a wobbling spacecraft to take low-exposure images in a very dark environment and get that information back to Earth.&quot;

The focus had, after all, been on Jupiter and Saturn. While the probe&#39;s makers had filled the fuel tanks before launch, going to Uranus and Neptune was not a given. &quot;We made sure, from an engineering perspective, it could do it. But they said, &#39;Oh dear, you haven&#39;t got any money.&#39;&quot;

The funding came, and Hunt recalled that serious work on what needed to be done started in early 1983. As well as software changes on the spacecraft (updates were made to use novel compression methods and avoid sending back black images when nothing was in view), antennas on Earth were upgraded to pick up the increasingly faint Voyager 2 signal.

&quot;It was an incredible achievement,&quot; said Hunt, &quot;an achievement for engineering, which science has obviously been able to explore more.&quot;

The flyby produced a tremendous amount of data about Uranus (or &quot;George&quot; if its 18th-century discoverer, William Herschel, had his way) – the planet had a magnetic field that was not aligned with its rotational axis. Additional rings appeared in Voyager 2&#39;s data, and images of the moon Miranda showed signs consistent with a violent impact that may have blown it apart and allowed it to reform.

The probe came within just over 50,000 miles of the planet&#39;s cloud tops, but many cloud features were obscured by a layer of haze.

Hunt reckoned that any future mission would need to not only enter orbit but also drop a probe into the atmosphere to learn more about the planet.

This brings up the awkward question of when the next mission might be launched, and who would do it. The politics of modern America are unlikely to permit another decades-spanning mission like Voyager, and even with modern propulsion systems, getting to Uranus will take many years. China&#39;s Tianwen-5 might visit Uranus or Neptune in the 2050s, assuming it launches in 2035 and isn&#39;t cancelled in the meantime.

Hunt thinks the European Space Agency has a chance of mounting a mission to Uranus, although it did not respond when The Register asked.

Finally, Hunt revealed that amid the flyby preparations, time was set aside to ensure everyone pronounced &quot;Uranus&quot; the approved way. &quot;We had been briefed very strongly by the public relations people at JPL on how to pronounce &#39;Uranus&#39; because the Australians were pronouncing it... incorrectly (which I will not mention)... and Americans found this somewhat embarrassing.&quot;

So there you have it. An answer to the question posed by Spitting Image (a UK satirical show featuring puppets of popular figures) all those years ago. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-48')">
            <div class="source">The Verge</div>
            <div class="title">Roland’s TR-1000 is the ultimate drum machine</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-48" style="display:none;">
            <h2>Roland’s TR-1000 is the ultimate drum machine</h2>
            <p><strong>The Verge | 2026-01-27</strong></p>
            <a class="original-link" href="https://www.theverge.com/tech/867819/roland-tr-1000-drum-machine-review">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Combining real analog circuits with digital synthesis and sampling makes the TR-1000 powerful but overwhelming.

If you buy something from a Verge link, Vox Media may earn a commission. See our ethics statement.

If you buy something from a Verge link, Vox Media may earn a commission. See our ethics statement.

It took way too long, but Roland finally caved and gave the people what they want: a proper analog successor to the iconic TR-808 drum machine. The 808’s sound, especially the kick drum, is embedded so deeply in the DNA of modern music that it would be a gross disservice to try and boil its influence down to a single sentence or a list of artists. (Note: Not all of the songs linked necessarily use an actual 808, but they at least feature samples or approximations of its sounds.)

But, in typical Roland fashion, the company didn’t just re-create some iconic analog circuits. No, the TR-1000 also has digital emulations of other classic Roland drum machines. It has FM synthesis, PCM samples, and a built-in sampler with looping and chopping abilities. Not to mention dozens of effects, the ability to layer sounds, and a modern sequencer with probability, automation, and microtiming. In short, if there is a feature you wish a drum machine had, the TR-1000 probably has you covered. But that also means the TR-1000 is an intimidating piece of gear with an equally intimidating $2,699.99 price tag.

16 incredible-sounding analog drum circuitsMultiple engines with a huge sound paletteLots of hands-on controlsFun performance-focused Morph slider

Expensive as hellMaybe a little too feature-packedSampling feels bolted on

Just looking at it can be a bit daunting. Roland has at times trended toward garish or toylike designs, which it’s rightly been criticized for. Now the company may have overcorrected. The recent Gaia 2 and SH-4d synthesizers are utilitarian, almost boring-looking. The TR-1000 continues that trend, but it carries a gravitas that those two instruments don’t. Roland’s flagship drum machine means business and looks the part.

The stark gray-and-black scheme gives it an industrial, almost brutalist vibe. There are 16 satisfyingly clacky keys across the bottom for the step sequencer, firm sliders for each of its 10 audio channels, plus buttons and knobs galore. Roland heard you wanted more hands-on controls and decided to give you all the hands-on controls.

The result is that you can do a lot on the TR-1000 with minimal menu diving. If you’ve ever used a step sequencer before, you should be able to bang out a simple beat immediately. There are dedicated knobs for tuning and decay so you can easily get that ultra-deep, modern 808 kick drone. While the labeling on the other knobs is generic (CTRL 1, CTRL 2, CTRL 3), the screen on the top right shows what they control.

Now, that does not mean there is no menu diving here — this is a Roland machine, after all. But the company has made strides with its UI in recent years. The issue is that Roland still hasn’t gotten a handle on its compulsion to cram every possible feature into every device. Is it nice to have sample chopping and resampling abilities on the TR-1000? Sure. But using them isn’t always intuitive, and the layout isn’t ideal for exploring chops to recontextualize a loop. For sampling one-shots and drum hits, the TR-1000 is great. But some of the more advanced features feel tacked on, buried behind convoluted button combos and cumbersome menus. The result is that I rarely used the looping or chopping features, and instead treated the TR-1000 as a more traditional drum machine.

From that perspective, the TR-1000 is an undeniable, if incredibly expensive, success. The headline feature is, of course, the 16 analog drum circuits that re-create iconic sounds from the TR-808 and TR-909. These are the reasons to splurge on the TR-1000. If you don’t care about having an authentic analog re-creation of the 808 snare, then spend your money elsewhere. There are countless digital facsimiles, including affordable options like the T-8 from Roland, and more free sample packs than I can count. But for those who crave the real deal, this is what you’ve been waiting for.

If you’re into making old-school hip-hop, house, or classic techno, this is the palette you want to be painting from. But I wouldn’t call the 808 or 909 sounds retro. They’re timeless. And the TR-1000 helps prove that point by placing them in the context of a modern sequencer, alongside more aggressively digital sounds.

The analog filter and drive help glue all these disparate sounds together while also highlighting the grit of the analog drum circuits. Turn up the decay on an 808 kick and crank the drive to about 75 percent — this is the sound of the gods. It’s the point where the bass just starts to cross over fuzz territory and hits hard enough to rattle your chest. I found myself returning to this specific sound over and over again when I felt like jamming.

Here&#39;s what the TR-1000&#39;s analog drums sound like through its analog filter with the drive cranked(opens a new window)

Roland could have just replicated the OG 808 and 909 sounds and called it a day. But in addition to the classic timbres, there are extended controls that give you far more sound sculpting options than were available on the original machines. This includes tuning the 808 kick so you can play it as a bassline, which is obviously popular in modern music but usually requires a sampler or synthesizer.

The TR-1000 also turns out to be a great advertisement for the company’s digital emulations. If you put the analog circuit behavior (ACB) emulation of an 808 kick next to the real analog one on the TR-1000, you’d be hard-pressed to tell the difference — it’s very subtle. I like to think that I have a relatively discerning ear when it comes to this stuff, but when I tried to guess which was which in a blind taste test, I was barely better than pure chance.

The ACB models are also where you’ll find my personal favorite Roland sounds. While I get the appeal of the 808 and the 909, I’ve always been drawn to the more lo-fi sounds of the TR-606 and the CR-78. Now, if Roland wants to give me a real analog reissue of those sounds, I will gladly throw all my money at them.

Despite all the additional sounds and advanced features the TR-1000 offers, I usually found myself starting with some slight variation of the same sound palette: an analog 808 kick, snare, hi-hat, and clap, analog 909 snare, and a digital 808 kick layered with the analog one. Then I’d fill up the other five tracks with various digital percussion sounds that struck my fancy at that particular moment in time.

Because of the quirks of the TR’s sequencer, I also often found myself working with shorter, simpler patterns. Rather than have one long 64- or 128-step sequence, the TR-100 essentially has a 16-step sequencer, with eight variations that you can then change, plus four “fill-in” versions of each variation. So rather than thinking of things as one long eight-bar loop, I would work in two- or even one-bar loops, but then build a bunch of slight variations to swap between.

This workflow actually led to me creating more varied drum tracks, and the piles of hands-on controls actually had me treating a drum machine as a performance instrument for once, rather than a set-it-and-forget-it backdrop for noodling.

My favorite performance tool is easily the Morph slider, which is definitely inspired by the crossfader on Elektron’s Octatrack. It lets you set two different sets of parameters for all your sounds and then seamlessly blend between them. Often, I would use it to switch between a basic version of a pattern and one with the drive cranked, the decay on the kick turned up, and the snares tuned to hit harder.

Another performance-focused feature that I kept coming back to was the Step Loop. Some drum machines allow you to repeat a certain part of a pattern — say, the first half a bar or a single step — to create on-the-fly fills and buildups. But Roland is the only company I know that lets you repeat whichever steps you want in whatever combination you want. Want to repeat steps one, five, and nine to create a looping fill that avoids any snares? Just hold those steps down for as long as you want. It turns playing fills into an active process, rather than just something you program in and trigger occasionally. It’s the rare Roland feature I wish other companies would blatantly steal.

I’ve thoroughly enjoyed my time with the TR-1000. It’s more fun than I’ve had with a drum machine in a long time. But I also feel like I’ve barely scratched the surface over the last couple of months. The looping, time-stretching, and chopping are all things I rarely bother with; the same goes for the virtual analog synth engine — largely because programming melodic passages is an enormous PITA. There are individual outs for each track, which would be huge in a more professional setting, but in my attic office / studio, I only ever bothered with the master out. I also never touched Song Mode. (To be fair, I never touch song mode on any of my gear.)

There’s just so much going on on the TR-1000 that it’s overwhelming. Roland really did build the ultimate drum machine, but it can feel like too much at times, and I preferred to stick to the basics. There’s nothing inherently wrong with that; you should use an instrument in the way that feels natural to you. But if you’re not going to use the TR-1000 to its full potential, the $2,699.99 price tag is probably a deal-breaker.

Photography by Terrence O’Brien / The Verge

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-49')">
            <div class="source">The Verge</div>
            <div class="title">All rise for JudgeGPT</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-49" style="display:none;">
            <h2>All rise for JudgeGPT</h2>
            <p><strong>The Verge | 2026-01-27</strong></p>
            <a class="original-link" href="https://www.theverge.com/policy/868151/ai-judges-arbitration">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The legal system is flawed — could AI actually make it better?

Bridget McCormack is used to correcting judges’ work. As the former chief justice on the Michigan Supreme Court, it was her job to review complaints about how judges at the lower courts failed to consider key evidence or rule on certain aspects of a case.

In her current job, McCormack is working on a new kind of legal decision-maker. Like a judge, it would make mistakes. But unlike many judges, it wouldn’t be burdened by more casework than it had hours in the day. It could make sure to always show its work, check that each side agreed it understood all the facts, and ensure it ruled on each issue at play. And it wouldn’t be human — it’s made of neural networks.

McCormack leads the American Arbitration Association, which has developed an AI Arbitrator to help parties settle document-based disputes in a low-cost way. The system is built on OpenAI’s models to walk parties in arbitration through their dispute and draft a decision on who should win the case and why. The system deals only with cases that rely solely on documents, and there’s a human in the loop at every stage, including in the final step of issuing an award. But McCormack believes even with these caveats, the process can make dispute resolution faster and more accessible, greasing the wheels of an overburdened legal system.

Generative AI frequently makes headlines for its failures in the courtroom. Last year, at least two federal judges had to issue mea culpas and come up with new policies after issuing court orders with made-up facts, thanks to the use of generative AI. Academics warn that AI’s legal interpretations are not as straightforward as they can seem, and can either introduce false information or rely on sources that would never be legally admissible otherwise. AI tools have been shown to import or exacerbate human biases without careful consideration, and the public’s skepticism of the tools could further threaten trust in the justice system.

Optimists like McCormack, meanwhile, see huge potential upsides for bringing speedier justice to the American legal system, even as they see an enduring role for human decision-makers. “Most small and medium businesses in the United States can’t afford legal help at all, and one dispute can put them under,” she says. “So imagine giving all of those businesses a way to resolve disputes and move forward with their business in a way that they could navigate, afford, and manage on their own.” She and others are balancing a difficult question: Can a new technology improve a flawed and limited justice system when it has flaws and limitations of its own?

While high-profile failures have garnered the most attention, courts are using AI in ways that mostly fly under the radar. In a review of AI use in the courts, Daniel Ho, faculty director at Stanford’s RegLab, and former research fellow Helena Lyng-Olsen found AI was already being used in the judicial system for both administrative and judicial tasks. Administrative court staff, for example, use AI for things like processing and classifying court filings, basic employee or customer support, or having AI monitor social media keywords for threats to judicial staff. Judges or their staff might use generative AI tools for lower-risk use cases like asking a large language model (LLM) to organize a timeline of key events in a case, or perform a search across both text and video exhibits. But they also use them for higher-risk tasks, according to Ho and Lyng-Olsen, like relying on AI for translations or transcriptions, anticipating the potential outcome of a case, and asking an LLM for legal analysis or interpretation.

Some of the technology used in courts predates the modern generative AI era. For example, judges have been using algorithmic risk assessments for years to help evaluate whether to release a defendant before trial. These tools already raised questions about whether algorithms could encode human bias. A 2016 ProPublica investigation revealed that not only were these algorithms not very good at predicting who would go on to commit violent crimes, they also disproportionately assessed Black defendants as high risk compared to white defendants, even when ProPublica controlled for other factors like criminal history and age. Newer LLM systems introduce entirely new concerns, particularly a propensity to make up information out of whole cloth — a phenomenon known as hallucination. Hallucinations have been documented in legal research tools like LexisNexis and Westlaw, which have integrated generative AI in an effort to help lawyers and judges find case law more efficiently.

Despite these risks, at least one prominent judge has promoted the use of LLMs: Judge Kevin Newsom, who sits on the 11th Circuit Court of Appeals. In 2024, Newsom issued a “modest proposal” in a concurring opinion, which he recognized “many will reflexively condemn as heresy.” Newsom’s pitch was for judges to consider that generative AI tools — when assessed alongside other sources — could help them analyze the ordinary meaning of words central to a case.

Newsom’s test case was a dispute that hinged partly on whether installing an in-ground trampoline could be considered “landscaping,” entitling it to coverage under an insurance policy. Newsom, a self-described textualist, wanted to understand the ordinary meaning of the word “landscaping.” He found myriad dictionary definitions lackluster. Photos of the in-ground trampoline didn’t strike him as “particularly ‘landscaping’-y,” but this unscientific gut feeling bothered the jurist whose entire philosophy is based around a strict adherence to the meaning of words. Then, “in a fit of frustration,” Newsom said to his law clerk, “I wonder what ChatGPT thinks about all this.”

The generative AI response, Newsom found, articulated the missing pieces he couldn’t quite put into words. He asked the chatbot for the “ordinary meaning” of landscaping, and its answer broadly described “the process of altering the visible features of an area of land, typically a yard, garden or outdoor space, for aesthetic or practical purposes,” a response Newsom said was “less nutty than I had feared” — and squared with his existing impressions. When he asked both ChatGPT and Google’s Gemini (then Bard) whether installing an in-ground trampoline could be considered landscaping, ChatGPT said yes, and Google’s agent laid out the criteria under which the description would fit.

Other factors in the case ended up nullifying the need to land on a definition of landscaping, but the experiment left a lasting impression on Newsom. He acknowledged potential downsides of the technology for judicial use, including its tendency to hallucinate, the fact it doesn’t account for “offline speech” outside of its training set, and the potential for future litigants to try to game it. But he doubted those were total “deal-killers” for his proposal that LLM outputs be considered one of several data points a judge uses to interpret language.

Newsom’s pithy opinion sounds quite simple. After all, shouldn’t a system trained on a boatload of human language have a highly representative view of how different words are used in everyday life? As Newsom pointed out, textualists already tend to read multiple dictionary definitions to understand the ordinary meaning of words relevant to a case, and “the choice among dictionary definitions involves a measure of discretion.” Judges also rarely explain why they chose one definition over another, he wrote, but under his proposal, judges should include both their own queries and the generative AI outputs to show how they arrived at a conclusion.

But recent academic research suggests that some assumptions underlying Newsom’s reasoning are flawed. There’s a “mistaken assumption … that ChatGPT or Claude are a lookup engine for American English, and that completely glosses over how these models are actually trained and tuned to provide the kind of output that Judge Newsom is getting on the platform,” says Stanford’s Ho, who co-authored a 2024 article on the subject in the Minnesota Journal of Law, Science & Technology. A model’s output can be influenced by things including regional language quirks of the people who help fine-tune it, for example, which is thought to be the reason behind ChatGPT’s strangely frequent use of the term “delve.”

Ho, with Princeton University assistant professor Peter Henderson, led a team that examined the ways corpus linguistics, or the analysis of a large amount of text, can sometimes obscure the meaning of language that judges might otherwise rely on — and “may import through the back door what at least some judges would expressly refute in the front door.” That could include drawing on foreign law that several Supreme Court justices have said is not appropriate to use to interpret the US Constitution, or reflecting “elite rhetoric” rather than the ordinary meaning of words or phrases.

Newsom admits that LLM training data can “run the gamut from the highest-minded to the lowest, from Hemmingway [sic] novels and Ph.D. dissertations to gossip rags and comment threads.” But he assumes that since “they cast their nets so widely, LLMs can provide useful statistical predictions about how, in the main, ordinary people ordinarily use words and phrases in ordinary life.”

His faith in the LLMs’ transparency might be premature. “[M]odels present researchers with a wide range of discretionary choices that can be highly consequential and hidden from judicial understanding,” Ho and Henderson wrote. Though models can make a show of explaining themselves, even their creators don’t fully know how they get to their outputs, which can sometimes change. “I don’t think we’re anywhere close at the present time to a point where some of these tools could be relied upon to explain how they reached the decision that they made,” says Paul Grimm, who served as a federal judge for 25 years and until recently served as a law professor at Duke University, where he wrote about AI in the judicial system.

It’s tempting to think that LLMs have true understanding because of their often nuanced answers. For example, Newsom says, they can “‘understand’ context” because they are able to tell when something refers to a “bat” meaning the animal, or the kind that hits a baseball. But this leaves out important attributes that contribute to true understanding. While large language models are quite good at predicting language, they can’t actually think. As Cognitive Resonance founder Benjamin Riley explained recently in The Verge, “We use language to think, but that does not make language the same as thought.” A Michigan judge recently cited the article to justify sanctions against a party that used ChatGPT to write an erroneous legal filing.

“[T]he proliferation of LLMs may ultimately exacerbate, rather than eradicate, existing inequalities in access to legal services”

Then there’s the issue of AI making stuff up. Newsom agrees that generative AI’s tendency to hallucinate is one of “the most serious objections to using LLMs in the search for ordinary meaning.” He countered that the technology is rapidly improving, and human lawyers also skew facts, intentionally or not. But as it stands, there’s still ample evidence of hallucinations in even the most meticulous generative AI systems. In a 2024 paper in the Journal of Legal Analysis, researchers found that hallucinations of legal facts were “widespread” among the four LLMs they tested. The result, they wrote, is that “the risks are highest for those who would benefit from LLMs most—under-resourced or pro se litigants,” meaning those who opt to represent themselves in court. That led the researchers to “echo concerns that the proliferation of LLMs may ultimately exacerbate, rather than eradicate, existing inequalities in access to legal services.”

The two leading legal research tools, LexisNexis and Westlaw, have taken steps that they say should drastically reduce hallucinations within their systems. But when the same researchers later examined them in a 2025 paper in the Journal of Empirical Legal Studies, they found “the hallucination problem persists at significant levels,” despite improvements over the generalized tools. Both legal tools use a system called retrieval-augmented generation (RAG), where the system first retrieves information from a database, then feeds that into an LLM to finish generating a response to the user’s prompt. But the researchers found that RAG could still be flawed, and that unique quirks of legal writing made it particularly susceptible to misinterpretation by the AI models. For example, the concept of case law is that an overall set of rulings on a topic build upon each other and form precedent — but that’s not as easy to pull as a single ruling in a single case. To make things even more complicated, that precedent is constantly changing as new rulings come in, a process it’s “unclear and undocumented” how systems handle, Ho tells The Verge. “Thus, deciding what to retrieve can be challenging in a legal setting,” the researchers write.

Both Westlaw owner Thomson Reuters and LexisNexis say their offerings have changed significantly since the study was originally published in 2024. LexisNexis Legal & Professional Chief Product Officer Jeff Pfeifer said in a statement that they’ve “significantly advanced how our AI systems are designed, evaluated, and deployed” since the research was published, and that it combines RAG with other information to “reduce the risk of unsupported answers.” Thomson Reuters said in a 2024 blog post that since the tool the researchers evaluated “was not built for, nor intended to be used for primary law legal research, it understandably did not perform well in this environment.” Westlaw’s head of product management Mike Dahn said in a statement that the technology referenced isn’t available in its platform anymore, and its newer AI research offering “is significantly more powerful and accurate than earlier AI iterations.”

Newsom posits that hallucinations from AI are a bigger issue when asking a question that has a specific answer, rather than seeking the ordinary meaning of a phrase. But some research suggests seeing an authoritative-sounding response from an LLM can contribute to confirmation bias.

Newsom was not deterred by pushback to his proposal. He issued “a sequel of sorts” in another concurring opinion months later, where he admitted to being “spooked” by the realization that LLMs could sometimes issue “subtly different answers to the exact same question.” But he ultimately concluded that the slight variations actually seemed reflective of those in real-life speech patterns, reinforcing its reliability for understanding language. “Again, just my two cents,” he wrote. “I remain happy to be shouted down.”

Whenever a new technology is proposed to update a system as important as the legal process, there’s valid concern that it will perpetuate biases. But human judges, obviously, can bring their own flaws to the table. An infamous 2011 study found, for example, that judges made more favorable parole rulings at the beginning of the day and after a lunch break, rather than right before. “We’re completely comfortable with the idea that human judges are humans and they make mistakes,” McCormack says. “What if we could really at least eliminate most of those with a technology that shows its work? That’s a game changer.”

McCormack’s organization has seen a version of this at work through its AI Arbitrator. The tool summarizes issues and proposes a decision based on its training and the facts at hand, then lets a human arbitrator look at its results and make a final call. The idea is to let parties resolve simple disputes quickly and for a lower cost, while giving attorneys and arbitrators time to work on more cases or focus on ones that require a human touch.

“We’re completely comfortable with the idea that human judges are humans and they make mistakes”

Arbitration is different from a formal court proceeding in important ways, though aspects of the process look very similar. It’s a form of alternative dispute resolution that lets two parties resolve an issue without going to court. Parties sometimes opt for arbitration because they see it as a more flexible or lower-cost option, or want to avoid the more public nature of a formal lawsuit. Sometimes, a party is forced into arbitration due to a clause in their contract, but when that’s not the case, it’s up to the individuals or businesses to go that route, unlike a court case where one side is compelled to be there. The decisions by an arbitrator — often a retired judge, legal professional, or expert in a specific field — can be binding or nonbinding, depending on what the parties agreed to.

The AI Arbitrator is currently only available for documents-only cases in the construction industry — things like a dispute between a contractor and a building owner based on their contract. Both parties agree to use the system, and submit their positions and relevant documents to back it up. The AI Arbitrator summarizes the submissions and organizes a list of claims and counterclaims, creates a timeline of the case based on all the filings, and lays out the key issues of the case, like whether there was a valid contract in place or if that contract was adequately fulfilled. At that stage, both sides have the chance to give feedback on whether the AI got these details right or left anything out.

That feedback, alongside the AI summaries, then gets handed to a human arbitrator — the first of multiple places they drop into the loop. The arbitrator reads the material and clicks through a series of screens where they can validate or edit each of the key issues in the case. The AI Arbitrator then provides an analysis for each issue, on which the human arbitrator can add feedback. The AI Arbitrator drafts a final award based on this analysis, including a rationale for the judgment. It references AAA handbooks with material from human arbitrators describing how they evaluate different parts of a case. The human arbitrator can edit and validate the AI-generated award, and then, finally, sign off on it — concluding the process.

Not everyone will feel comfortable using AI to decide on the outcome of their dispute. But some might find the time and cost savings attractive, and be reassured that a human ultimately checks the work and makes the final decision. To the extent that a human arbitrator might disagree with the AI Arbitrator’s ultimate judgment, the AAA says, they’re about as likely to disagree with another human arbitrator about it.

A human arbitrator in the AI-led system gets neatly packaged summaries of documents and arguments with parties’ feedback on those summaries, while in the completely human-led process, they’d have to pore over perhaps hundreds of pages of documentation just as a starting point. The kinds of cases the AI Arbitrator works on typically take a human arbitrator 60 to 75 days to resolve, the group says, and while the tool only launched recently, it projects that disputes using the AI Arbitrator will take 30 to 45 days, and produce at least a 35 percent cost savings.

McCormack has found that the AI Arbitrator has an additional benefit: Parties like how the tool makes them feel heard. Its design — which asks each side to confirm that it has understood all the relevant facts and allows them to provide additional feedback — lets people speak up if they feel like something is being lost or glossed over in arbitration. It’s an element of the technology she says she initially “underappreciated” at first. “I used to talk to judges all the time about how these parties just want to make sure you hear them,” she says. “That literally matters more than anything else, that they have a chance to tell you what happened.”

Reaching a fair outcome, of course, is a non-negotiable element of arbitration. But there is plenty of research about the importance of procedural justice, or ensuring that people perceive the process itself as fair and trustworthy — which can result in them gaining more trust in the legitimacy of the law.

A 2022 article in the Harvard Journal of Law & Technology (published before the rise of ChatGPT) suggests people aren’t necessarily opposed to AI judges, even if they still prefer humans. In the study, participants were asked about their perception of the fairness of a hypothetical AI judge. The participants said they viewed hypothetical proceedings before human judges as more fair than those before AI judges. But overall, they said being allowed to speak before an AI judge would be more procedurally fair than having no opportunity to speak at all. That suggests, the authors wrote, that the perceived fairness gap between human and AI judges may be at least partially offset “by introducing into AI adjudication procedural elements that might be absent from current processes, such as a hearing or an interpretable decision.”

Judges, like workers in every industry, are being made to figure out exactly what about their jobs requires a human touch

For the history of the judicial system, hearing out plaintiffs and defendants and doling out justice have been considered deeply human tasks. But as AI begins to excel at many jobs that have taken humans long hours to complete, judges, like workers in every industry, are being made to figure out exactly what about their jobs requires a human touch. In his 2023 end-of-year report, US Supreme Court Chief Justice John Roberts wrote about the role he saw AI playing in the judicial system in the future. He saw some judicial activities as uniquely human: determining how sincere defendants are during sentencing, or wading through “fact-specific gray areas” to decide if a lower court “abused its discretion.” He predicted that “human judges will be around for a while. But with equal confidence I predict that judicial work—particularly at the trial level—will be significantly affected by AI.”

McCormack says there are certain disputes that “should always be resolved in courthouses and in public”: criminal cases and cases brought by citizens against the government. But for many civil disputes, she says, AI could play an important role in giving more people access to justice by making the process more efficient.

Grimm, the former judge and Duke professor, says that by the time he retired from the court, “I had been many years working seven days a week, and I was working as hard as I could and I still wished I had been more prepared than I could have been.” He rattled off a list of things AI could be useful for: outlining issues that parties expect the judge to rule on, summarizing long testimony transcripts, making a list of the facts both parties agree on based on reams of court filings, and perhaps, after a judge has written their opinion, revising it for a 12th grade reading level so that it’s more accessible to the public.

“If you want a more efficient judiciary … the easy answer is not AI. It’s appoint more federal judges”

But AI isn’t necessarily the best solution for a persistently understaffed judiciary, and it’s certainly not the only one. Cody Venzke, senior policy counsel at the American Civil Liberties Union (ACLU) National Political Advocacy Division, agrees there could be a role for the technology in certain administrative tasks, but says the issues of judicial burnout largely shouldn’t be resolved with it. “If you want a more efficient judiciary where judges can spend more time on each case, where they can do things like — God forbid — have a jury trial, the easy answer is not AI,” he says. “It’s appoint more federal judges.”

Grimm and Venzke agree that judges should never be simply checking AI’s work. “I hope that there’s never a time when the judge just tells the AI to come up with an opinion that they read and sign,” Grimm says. The line, to Grimm, is about who — or what — is influencing whom. Using the tool to draft an opinion a judge is on the fence about and gauging their own reaction, for example: “I think that comes too close to the line of letting the AI get to the answer first.” That could result in confirmation bias where the judge then downplays contrary evidence, he says. Even using AI to draft two opposing outcomes of a case to decide which is better feels a bit too risky.

Grimm’s reasoning is based both on the facts of how generative AI tools are designed and on the unique quality of human societal ethics. “These tools are not designed to get the right answer,” he says. “They’re designed to respond to prompts and inquiries and predict what the response should be, based upon the inquiry and the data that they were tested on.” An AI tool could cite language for a real court case, for example, but it might be from a dissent, which doesn’t hold the same legal weight. But an equally important point, he says, is that “AI tools do not take an oath.”

Venzke says he’d be among the last people to praise the current judicial system as perfect. “But it’s worth underscoring that AI is not superhuman intelligence,” he says. “It’s super efficient summarizing of human knowledge.” Sometimes, AI’s attempt to even do that still seems to fall flat. Venzke described a time he tried to do legal research about two neighbors’ rights to access a lake through an easement where one was trying to build a dock. But since there was not a clear ruling on such a matter in the state he was looking at, he found generative AI returned largely irrelevant results. The answer took a few hours to come up with on his own, but mostly involved interpreting the law from Supreme Court rulings and considering how other states ruled in similar matters — something he says the technology is still not very good at consolidating effectively on its own.

It’s tempting to think a carefully calibrated machine could come out with the “right” answer in a legal case more often than not. But Grimm says thinking about such decisions as right and wrong obscures the nature of the legal system. “Oftentimes legal issues could go either way,” he says. “That’s why you can get dissent on the Supreme Court … It’s too simplistic to say, well, judges have biases.”

Still, some early research suggests that despite a largely skeptical view toward AI in judicial decision-making, some people see a potential upside over the status quo. Researchers from the University of Nevada, Reno set out to study how views of AI use in the judicial system might vary across racial groups in a 2025 paper published in the MDPI Behavioral Sciences journal. They asked participants how they felt about a judge who relied only on their expertise, or only on an AI system that uses algorithms to make a bail or sentencing determination (the tools described sound like a non-generative AI system), or a combination of the two. While overall, participants in the study perceived judges that relied only on their expertise, rather than AI, as more favorable on bail and sentencing decisions, Black participants tended to perceive the AI-assisted version as more fair than their white and Hispanic counterparts did, “suggesting they may perceive AI as a tool that could enhance fairness by limiting judicial discretion.”

At the same time, research has found that judges already tend to use algorithmic tools — some of which have documented racial bias issues — to reinforce their own decisions. In a study published in 2024 in the journal Social Problems, Northwestern University researcher Sino Esthappan found that when judges were given algorithmic assessments of defendants’ risk in returning to court if released from jail, they mostly used them to justify the rulings they wanted to make anyway. In another 2024 analysis, researchers from Tulane, Penn State, and Auburn University found that while the AI recommendations seemed to help “balance out” judges’ tendency to dole harsher punishments to male versus female defendants, “the AI may trigger judges’ racial biases.”

The researchers in that study had faith that “AI’s recommendations can help judges refocus and make more objective judgments.” In the cases where judges agreed with and followed through on the AI’s recommendations to offer alternative punishments to a defendant, the researchers found the lowest recidivism rate compared to scenarios where the two misaligned. “When the two are on the same page, judges sentence the riskiest and the least risky offenders to incarceration and alternative punishments, respectively.” As a result, the researchers recommended that judges “minimize intrinsic bias by pausing and reconsidering when their decisions deviate from AI’s recommendations.”

Even AI optimists express little desire to get rid of human judges. Hallucinations remain a persistent problem, and the tools’ value remains limited when every detail must be painstakingly checked.

”When you’re talking about something as rights-impacting as a judicial process, you don’t want 95, 99 percent accuracy. You need to be excruciatingly close to 100 percent accuracy,” Venzke says. “And until or if AI systems get to that point, they really don’t have a place to be operating, especially operating independently, in the judicial process.”

“The legal profession has been unbelievably successful at avoiding any disruption for 250 years in America”

The overall goal is to leave human judges more time to work on the cases that deserve their fullest attention, while giving the largest number of people access to justice in a time-efficient way. “The legal profession has been unbelievably successful at avoiding any disruption for 250 years in America,” McCormack says. “We’ve undergone four industrial revolutions and never updated the operating system. And when our legal system was established, there was a completely different market and the one-to-one service model, everybody had a lawyer for a dispute, was the way things worked. And that’s just not true anymore and hasn’t been true for a number of decades now.”

McCormack says colleagues who were resistant to AI even a year ago are beginning to accept it. “I would not be surprised, I don’t know if it’s in five years, or 20 years, or 40 years, if we look back and think that it was hilarious that we thought humans had to oversee all of these disputes.”

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-50')">
            <div class="source">The Verge</div>
            <div class="title">Xbox Cloud Gaming’s new design teases the future of Xbox console UI</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-50" style="display:none;">
            <h2>Xbox Cloud Gaming’s new design teases the future of Xbox console UI</h2>
            <p><strong>The Verge | 2026-01-27</strong></p>
            <a class="original-link" href="https://www.theverge.com/tech/868434/xbox-cloud-gaming-new-ui-future-xbox-console-design">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Microsoft says its new Xbox Cloud UI is the ‘foundation’ for new Xbox experiences.

Microsoft says its new Xbox Cloud UI is the ‘foundation’ for new Xbox experiences.

Microsoft has started testing a refreshed web experience for Xbox Cloud Gaming that looks even more console-like. Xbox Insiders can now try out the preview UI, which includes updated navigation features, plenty of new animations, and a refreshed design. It all feels like a teaser of what’s to come for Xbox consoles in the years ahead.

The existing Xbox Cloud Gaming interface got its last major overhaul nearly two years ago, when Microsoft added the social features and UI you’d normally find in the Xbox dashboard. This new design makes that existing UI feel even closer to an Xbox console, thanks to a variety of new animations, a new library section, and a rounded design.

New animations include a sliding dashboard interface that glides into view, an animated Xbox icon that lights up and changes shape, and improved navigation between the different parts of the dashboard. These subtle changes greatly improve the Xbox Cloud Gaming navigation experience, which currently feels like a web app loading each section.

“We’re testing a refreshed web experience for Xbox Cloud Gaming that lays the foundation for accelerating our ability to build new experiences for players,” says Patrick Siu, principal product manager at Xbox. “This preview is a first look at our new web interface on your browser and lets you try the updated design and product flow before it is rolled out broadly.”

The mention of this new UI being the foundation for “new experiences” certainly sounds like Microsoft may well use this new design in a future Xbox console. In the meantime, I’m hoping it also takes this interface and puts it inside the Xbox app on PC, which is in much need of navigation and animation improvements.

Microsoft is looking for feedback on this new Xbox Cloud Gaming UI, before it rolls it out to everyone in the coming months. If you want to try it out you can head to the new https://play.xbox.com/ site and enable the preview features toggle from the settings menu.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-51')">
            <div class="source">The Verge</div>
            <div class="title">Instagram, Facebook, and WhatsApp will test premium subscriptions</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-51" style="display:none;">
            <h2>Instagram, Facebook, and WhatsApp will test premium subscriptions</h2>
            <p><strong>The Verge | 2026-01-27</strong></p>
            <a class="original-link" href="https://www.theverge.com/news/868439/meta-premium-subscription-ai-facebook-instagram-whatsapp">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">﻿Some new and existing AI capabilities may be put behind a paywall.

﻿Some new and existing AI capabilities may be put behind a paywall.

Meta is gearing up to trial new premium subscriptions for Instagram, Facebook, and WhatsApp in the coming months that will allow users to access expanded AI capabilities and additional features. TechCrunch reports that the upcoming subscription plans aim to “unlock more productivity and creativity” by providing premium users with “more control over how they share and connect.”

The core Instagram, Facebook, and WhatsApp services will remain free to use, and the new premium subscriptions will be separate from the paid Meta Verified service that was launched in 2023. Meta told TechCrunch that it will test a variety of subscription features and bundles and will launch each app subscription with a distinct set of exclusive capabilities. The price of these upcoming subscription plans is currently unknown.

One of the features being tested is Vibes, the AI-generated short-form video experience built into the Meta AI app. While Vibes has been free since it launched in September 2025, Meta is now reportedly planning to move to a freemium model that locks certain video creation opportunities behind a paid subscription. Manus, the suite of general AI agents that Meta acquired in December for a reported $2 billion, will also be part of the subscription plans, with Meta integrating Manus into its own products while continuing to offer it to businesses as a standalone subscription.

An integration spotted by leaker Alessandro Paluzzi is a shortcut to Manus AI on Instagram, alongside a description that reads “research, create, and build with Manus.” According to Paluzzi, Instagram’s premium subscription may allow users to create unlimited audience lists, see a list of accounts you follow who don’t follow you back, and view a Story without notifying the user who posted it. We do not currently know what the premium subscriptions for WhatsApp and Facebook might provide.

Meta could be preparing these premium subscription plans to claw back some of the revenue it’s invested into AI. While AI providers like OpenAI, Google, and Anthropic charge for higher access to their models, Meta’s Llama family has remained open-source and free. The challenge will now be to persuade users that they need AI features on their social media enough to warrant paying for them.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-52')">
            <div class="source">The Verge</div>
            <div class="title">Strava and Komoot finally bring offline maps to Apple Watch</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-52" style="display:none;">
            <h2>Strava and Komoot finally bring offline maps to Apple Watch</h2>
            <p><strong>The Verge | 2026-01-27</strong></p>
            <a class="original-link" href="https://www.theverge.com/news/868418/strava-and-komoot-finally-bring-offline-maps-to-apple-watch">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Komoot’s app provides turn-by-turn navigation and doesn’t require a subscription.

Komoot’s app provides turn-by-turn navigation and doesn’t require a subscription.

Strava and Komoot — two of the most popular apps for cyclists, hikers, and runners — are each bringing offline maps to the Apple Watch, ending a major source of frustration for many. Now you can easily see routes and record your workouts all in your preferred app, without having to bring along a relatively heavy and cumbersome iPhone.

Strava says the offline maps are only available to subscribers, but Komoot’s offering is free (though you might have to pay to unlock additional map regions) and also bakes in turn-by-turn navigation. Strava subscribers pay $11.99/month or $79.99/year plus any taxes.

One of the biggest selling points of the Apple Watch Ultra has been its ability to function without an iPhone. But athletes still needed to bring their phones along if they wanted glanceable, turn-by-turn routes on their wrists, or pay extra for apps like WorkOutDoors or (my personal favorite) Footpath. Switching between apps was less than seamless and downright oppressive compared to wearing a Garmin watch. Offline maps in Strava and Komoot brings the two platforms closer together as Apple slowly pecks away at Garmin’s advantages.

DesFit has an excellent overview of the Komoot app, which does the basics for now, but does them better than Strava. Komoot says more advanced features like auto-rerouting will arrive in future updates.

“Our goal was to make Komoot’s Apple Watch app fully capable on its own,” said Tom Eldred, product manager at Komoot. “For many of us, the ability to disconnect is the best part of being outdoors, so we wanted the community to have the freedom to leave their phone at home — or at least in their pocket.”

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-53')">
            <div class="source">The Verge</div>
            <div class="title">TikTok is still down, here are all the latest updates</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-53" style="display:none;">
            <h2>TikTok is still down, here are all the latest updates</h2>
            <p><strong>The Verge | 2026-01-27</strong></p>
            <a class="original-link" href="https://www.theverge.com/news/868379/tiktok-us-trump-oracle-broken-rumors-power-outage">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">More than a day after TikTok’s issues began, TikTok USDS says the problems are the result of a power outage at a data center and subsequent cascading systems failure.

Starting early Sunday morning, TikTok’s now under new ownership US arm started breaking down just a couple of days after Oracle & Co took the reins. Its For You page algorithm is suddenly unreliable, while features like comments are failing to load or loading slowly, and publishing new videos seems nearly impossible for many people.

Rumors of censorship targeting anti-ICE protesting or attempting to block discussion of Jeffrey Epstein appear to be misguided (even the governor of California is resharing misinformation now), with problems blocking traffic to all kinds of videos and messages on the service through Monday night.

Read on below for the latest updates about the ongoing TikTok problems.

TikTok’s US service crashed early Sunday morning, and as of late Monday night, it still hasn’t fully recovered.

After finally announcing the problem started with a power outage at an unnamed partner’s data center, TikTok USDS followed up with an updated statement saying, “While the network has been recovered, the outage caused a cascading systems failure that we’ve been working to resolve together with our data center partner,” and listing some of the bugs users are experiencing. There’s still no ETA for a full fix.

Despite claims floating around social media, the truth is a bit more complicated, not least by the fact that TikTok in the US is still largely down, about a day and a half after its data center power outage problems started.

While tweets from random users, the governor of California, and PopBase claimed TikTok US DMs now censor “Epstein,” testing it from our end showed that its messaging feature bans many innocuous single-word messages, like “test.” Using the convicted sex offender’s name in a sentence, however, goes through unbanned.

TikTok says a power outage is causing ongoing issues and outages that started in the US early Sunday morning. In an email to The Verge, TikTok USDS spokesperson Jamie Favazza pointed to a statement posted to the joint venture’s newly-created X account, which says the company has been “working to restore our services following a power outage at a U.S. data center impacting TikTok and other apps we operate.”

On Sunday, many US users, including some of us here at The Verge, reported not being able to upload videos to TikTok or see most new videos, including new videos uploaded successfully by users from outside the US. Others said that their algorithm appeared to “reset,” though it’s unclear if that’s linked to the power outage, too.

TikTok has suffered from extensive problems on its first weekend after completing a transaction that changed the ownership of its US arm. According to Downdetector, the issues initially spiked in the early hours of Sunday morning, but many users, including editors here at The Verge, are still reporting errors.

On Monday morning, TikTok USDS head of communications Jamie Favazza responded to our inquiries, pointing to a post on a newly-created X account for the US joint venture that said its current issues are the result of a data center power outage.

Whether this is just a regular outage or a result of this week’s changes in management, reports tracked on Downdetector and Reddit confirm many people are having trouble loading TikTok right now.

If the mobile app loads, it’s not consistently showing comments or other features, and the algorithm managing the For You page doesn’t feel like it’s working correctly.

Update, January 26th: TikTok is still having problems in the US, which it says are connected to a data center power outage.

TikTok is officially under new ownership in the US, and that could spell big changes for the video-sharing app. On January 22nd, ByteDance – TikTok’s Chinese parent company — and a group of investors closed a $14 billion deal to spin off the platform’s US operations, introducing a new slate of American executives.

The Silver Lake investment firm, Abu Dhabi’s MGX, and the cloud giant Oracle will each have 15 percent stakes in the new TikTok US Data Security (USDS) Joint Venture LLC. ByteDance will still hold a 19.9 percent stake in the company, in line with the divest-or-ban law that went into effect last year — though the deal was pushed through with help from President Donald Trump in persistent disregard of the law.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-54')">
            <div class="source">MIT Technology Review</div>
            <div class="title">Inside OpenAI’s big play for science</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-54" style="display:none;">
            <h2>Inside OpenAI’s big play for science</h2>
            <p><strong>MIT Technology Review | 2026-01-26</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2026/01/26/1131728/inside-openais-big-play-for-science/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">In the three years since ChatGPT’s explosive debut, OpenAI’s technology has upended a remarkable range of everyday activities at home, at work, in schools—anywhere people have a browser open or a phone out, which is everywhere.

Now OpenAI is making an explicit play for scientists. In October, the firm announced that it had launched a whole new team, called OpenAI for Science, dedicated to exploring how its large language models could help scientists and tweaking its tools to support them.

The last couple of months have seen a slew of social media posts and academic publications in which mathematicians, physicists, biologists, and others have described how LLMs (and OpenAI’s GPT-5 in particular) have helped them make a discovery or nudged them toward a solution they might otherwise have missed. In part, OpenAI for Science was set up to engage with this community.

And yet OpenAI is also late to the party. Google DeepMind, the rival firm behind groundbreaking scientific models such as AlphaFold and AlphaEvolve, has had an AI-for-science team for years. (When I spoke to Google DeepMind’s CEO and cofounder Demis Hassabis in 2023 about that team, he told me: “This is the reason I started DeepMind … In fact, it’s why I’ve worked my whole career in AI.”)

So why now? How does a push into science fit with OpenAI’s wider mission? And what exactly is the firm hoping to achieve?

I put these questions to Kevin Weil, a vice president at OpenAI who leads the new OpenAI for Science team, in an exclusive interview last week.

Weil is a product guy. He joined OpenAI a couple of years ago as chief product officer after being head of product at Twitter and Instagram. But he started out as a scientist. He got two-thirds of the way through a PhD in particle physics at Stanford University before ditching academia for the Silicon Valley dream. Weil is keen to highlight his pedigree: “I thought I was going to be a physics professor for the rest of my life,” he says. “I still read math books on vacation.”

Asked how OpenAI for Science fits with the firm’s existing lineup of white-collar productivity tools or the viral video app Sora, Weil recites the company mantra: “The mission of OpenAI is to try and build artificial general intelligence and, you know, make it beneficial for all of humanity.”

Just imagine the future impact this technology could have on science he says: New medicines, new materials, new devices. “Think about it helping us understand the nature of reality, helping us think through open problems. Maybe the biggest, most positive impact we’re going to see from AGI will actually be from its ability to accelerate science.”

He adds: “With GPT-5, we saw that becoming possible.”

As Weil tells it, LLMs are now good enough to be useful scientific collaborators. They can spitball ideas, suggest novel directions to explore, and find fruitful parallels between new problems and old solutions published in obscure journals decades ago or in foreign languages.

That wasn’t the case a year or so ago. Since it announced its first so-called reasoning model—a type of LLM that can break down problems into multiple steps and work through them one by one—in December 2024, OpenAI has been pushing the envelope of what the technology can do. Reasoning models have made LLMs far better at solving math and logic problems than they used to be. “You go back a few years and we were all collectively mind-blown that the models could get an 800 on the SAT,” says Weil.

But soon LLMs were acing math competitions and solving graduate-level physics problems. Last year, OpenAI and Google DeepMind both announced that their LLMs had achieved gold-medal-level performance in the International Math Olympiad, one of the toughest math contests in the world. “These models are no longer just better than 90% of grad students,” says Weil. “They’re really at the frontier of human abilities.”

That’s a huge claim, and it comes with caveats. Still, there’s no doubt that GPT-5, which includes a reasoning model,  is a big improvement on GPT-4 when it comes to complicated problem-solving. Measured against an industry benchmark known as GPQA, which includes more than 400 multiple-choice questions that test PhD-level knowledge in biology, physics, and chemistry, GPT-4 scores 39%, well below the human-expert baseline of around 70%. According to OpenAI, GPT-5.2 (the latest update to the model, released in December) scores 92%.

The excitement is evident—and perhaps excessive. In October, senior figures at OpenAI, including Weil, boasted on X that GPT-5 had found solutions to several unsolved math problems. Mathematicians were quick to point out that in fact what GPT-5 appeared to have done was dig up existing solutions in old research papers, including at least one written in German. That was still useful, but it wasn’t the achievement OpenAI seemed to have claimed. Weil and his colleagues deleted their posts.

Now Weil is more careful. It is often enough to find answers that exist but have been forgotten, he says: “We collectively stand on the shoulders of giants, and if LLMs can kind of accumulate that knowledge so that we don’t spend time struggling on a problem that is already solved, that’s an acceleration all of its own.”

He plays down the idea that LLMs are about to come up with a game-changing new discovery. “I don’t think models are there yet,” he says. “Maybe they’ll get there. I’m optimistic that they will.”

But, he insists, that’s not the mission: “Our mission is to accelerate science. And I don’t think the bar for the acceleration of science is, like, Einstein-level reimagining of an entire field.”

For Weil, the question is this: “Does science actually happen faster because scientists plus models can do much more, and do it more quickly, than scientists alone? I think we’re already seeing that.”

In November, OpenAI published a series of anecdotal case studies contributed by scientists, both inside and outside the company, that illustrated how they had used GPT-5 and how it had helped. “Most of the cases were scientists that were already using GPT-5 directly in their research and had come to us one way or another saying, ‘Look at what I’m able to do with these tools,’” says Weil.

The key things that GPT-5 seems to be good at are finding references and connections to existing work that scientists were not aware of, which sometimes sparks new ideas; helping scientists sketch mathematical proofs; and suggesting ways for scientists to test hypotheses in the lab.

“GPT 5.2 has read substantially every paper written in the last 30 years,” says Weil. “And it understands not just the field that a particular scientist is working in; it can bring together analogies from other, unrelated fields.”

“That’s incredibly powerful,” he continues. “You can always find a human collaborator in an adjacent field, but it’s difficult to find, you know, a thousand collaborators in all thousand adjacent fields that might matter. And in addition to that, I can work with the model late at night—it doesn’t sleep—and I can ask it 10 things in parallel, which is kind of awkward to do to a human.”

Most of the scientists OpenAI reached out to back up Weil’s position.

Robert Scherrer, a professor of physics and astronomy at Vanderbilt University, only played around with ChatGPT for fun (“I used to it rewrite the theme song for Gilligan’s Island in the style of Beowulf, which it did very well,” he tells me) until his Vanderbilt colleague Alex Lupsasca, a fellow physicist who now works part-time at OpenAI, told him that GPT-5 had helped solve a problem he’d been working on.

Lupsasca gave Scherrer access to GPT-5 Pro, OpenAI’s $200-a-month premium subscription. “It managed to solve a problem that I and my graduate student could not solve despite working on it for several months,” says Scherrer.

It’s not perfect, he says: “GTP-5 still makes dumb mistakes. Of course, I do too, but the mistakes GPT-5 makes are even dumber.” And yet it keeps getting better, he says: “If current trends continue—and that’s a big if—I suspect that all scientists will be using LLMs soon.”

Derya Unutmaz, a professor of biology at the Jackson Laboratory, a nonprofit research institute, uses GPT-5 to brainstorm ideas, summarize papers, and plan experiments in his work studying the immune system. In the case study he shared with OpenAI, Unutmaz used GPT-5 to analyze an old data set that his team had previously looked at. The model came up with fresh insights and interpretations.

“LLMs are already essential for scientists,” he says. “When you can complete analysis of data sets that used to take months, not using them is not an option anymore.”

Nikita Zhivotovskiy, a statistician at the University of California, Berkeley, says he has been using LLMs in his research since the first version of ChatGPT came out.

Like Scherrer, he finds LLMs most useful when they highlight unexpected connections between his own work and existing results he did not know about. “I believe that LLMs are becoming an essential technical tool for scientists, much like computers and the internet did before,” he says. “I expect a long-term disadvantage for those who do not use them.”

But he does not expect LLMs to make novel discoveries anytime soon. “I have seen very few genuinely fresh ideas or arguments that would be worth a publication on their own,” he says. “So far, they seem to mainly combine existing results, sometimes incorrectly, rather than produce genuinely new approaches.”

I also contacted a handful of scientists who are not connected to OpenAI.

Andy Cooper, a professor of chemistry at the University of Liverpool and director of the Leverhulme Research Centre for Functional Materials Design, is less enthusiastic. “We have not found, yet, that LLMs are fundamentally changing the way that science is done,” he says. “But our recent results suggest that they do have a place.”

Cooper is leading a project to develop a so-called AI scientist that can fully automate parts of the scientific workflow. He says that his team doesn’t use LLMs to come up with ideas. But the tech is starting to prove useful as part of a wider automated system where an LLM can help direct robots, for example.

“My guess is that LLMs might stick more in robotic workflows, at least initially, because I’m not sure that people are ready to be told what to do by an LLM,” says Cooper. “I’m certainly not.”

LLMs may be becoming more and more useful, but caution is still key. In December, Jonathan Oppenheim, a scientist who works on quantum mechanics, called out a mistake that had made its way into a scientific journal. “OpenAI leadership are promoting a paper in Physics Letters B where GPT-5 proposed the main idea—possibly the first peer-reviewed paper where an LLM generated the core contribution,” Oppenheim posted on X. “One small problem: GPT-5’s idea tests the wrong thing.”

He continued: “GPT-5 was asked for a test that detects nonlinear theories. It provided a test that detects nonlocal ones. Related-sounding, but different. It’s like asking for a COVID test, and the LLM cheerfully hands you a test for chickenpox.”

It is clear that a lot of scientists are finding innovative and intuitive ways to engage with LLMs. It is also clear that the technology makes mistakes that can be so subtle even experts miss them.

Part of the problem is the way ChatGPT can flatter you into letting down your guard. As Oppenheim put it: “A core issue is that LLMs are being trained to validate the user, while science needs tools that challenge us.” In an extreme case, one individual (who was not a scientist) was persuaded by ChatGPT into thinking for months that he’d invented a new branch of mathematics.

Of course, Weil is well aware of the problem of hallucination. But he insists that newer models are hallucinating less and less. Even so, focusing on hallucination might be missing the point, he says.

“One of my teammates here, an ex math professor, said something that stuck with me,” says Weil. “He said: ‘When I’m doing research, if I’m bouncing ideas off a colleague, I’m wrong 90% of the time and that’s kind of the point. We’re both spitballing ideas and trying to find something that works.’”

“That’s actually a desirable place to be,” says Weil. “If you say enough wrong things and then somebody stumbles on a grain of truth and then the other person seizes on it and says, ‘Oh, yeah, that’s not quite right, but what if we—’ You gradually kind of find your trail through the woods.”

This is Weil’s core vision for OpenAI for Science. GPT-5 is good, but it is not an oracle. The value of this technology is in pointing people in new directions, not coming up with definitive answers, he says.

In fact, one of the things OpenAI is now looking at is making GPT-5 dial down its confidence when it delivers a response. Instead of saying Here’s the answer, it might tell scientists: Here’s something to consider.

“That’s actually something that we are spending a bunch of time on,” says Weil. “Trying to make sure that the model has some sort of epistemological humility.”

Another thing OpenAI is looking at is how to use GPT-5 to fact-check GPT-5. It’s often the case that if you feed one of GPT-5’s answers back into the model, it will pick it apart and highlight mistakes.

“You can kind of hook the model up as its own critic,” says Weil. “Then you can get a workflow where the model is thinking and then it goes to another model, and if that model finds things that it could improve, then it passes it back to the original model and says, ‘Hey, wait a minute—this part wasn’t right, but this part was interesting. Keep it.’ It’s almost like a couple of agents working together and you only see the output once it passes the critic.”

What Weil is describing also sounds a lot like what Google DeepMind did with AlphaEvolve, a tool that wrapped the firms LLM, Gemini, inside a wider system that filtered out the good responses from the bad and fed them back in again to be improved on. Google DeepMind has used AlphaEvolve to solve several real-world problems.

OpenAI faces stiff competition from rival firms, whose own LLMs can do most, if not all, of the things it claims for its own models. If that’s the case, why should scientists use GPT-5 instead of Gemini or Anthropic’s Claude, families of models that are themselves improving every year? Ultimately, OpenAI for Science may be as much an effort to plant a flag in new territory as anything else. The real innovations are still to come.

“I think 2026 will be for science what 2025 was for software engineering,” says Weil. “At the beginning of 2025, if you were using AI to write most of your code, you were an early adopter. Whereas 12 months later, if you’re not using AI to write most of your code, you’re probably falling behind. We’re now seeing those same early flashes for science as we did for code.”

He continues: “I think that in a year, if you’re a scientist and you’re not heavily using AI, you’ll be missing an opportunity to increase the quality and pace of your thinking.”

Four ways to think about this year&#39;s reckoning.

Our AI writers make their big bets for the coming year—here are five hot trends to watch.

By studying large language models as if they were living things instead of computer programs, scientists are discovering some of their secrets for the first time.

In an exclusive interview, the AI pioneer shares his plans for his new Paris-based company, AMI Labs.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-55')">
            <div class="source">MIT Technology Review</div>
            <div class="title">Why chatbots are starting to check your age</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-55" style="display:none;">
            <h2>Why chatbots are starting to check your age</h2>
            <p><strong>MIT Technology Review | 2026-01-26</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2026/01/26/1131726/why-chatbots-are-starting-to-check-your-age/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first, sign up here.

How do tech companies check if their users are kids?

This question has taken on new urgency recently thanks to growing concern about the dangers that can arise when children talk to AI chatbots. For years Big Tech asked for birthdays (that one could make up) to avoid violating child privacy laws, but they weren’t required to moderate content accordingly. Two developments over the last week show how quickly things are changing in the US and how this issue is becoming a new battleground, even among parents and child-safety advocates.

In one corner is the Republican Party, which has supported laws passed in several states that require sites with adult content to verify users’ ages. Critics say this provides cover to block anything deemed “harmful to minors,” which could include sex education. Other states, like California, are coming after AI companies with laws to protect kids who talk to chatbots (by requiring them to verify who’s a kid). Meanwhile, President Trump is attempting to keep AI regulation a national issue rather than allowing states to make their own rules. Support for various bills in Congress is constantly in flux.

So what might happen? The debate is quickly moving away from whether age verification is necessary and toward who will be responsible for it. This responsibility is a hot potato that no company wants to hold.

In a blog post last Tuesday, OpenAI revealed that it plans to roll out automatic age prediction. In short, the company will apply a model that uses factors like the time of day, among others, to predict whether a person chatting is under 18. For those identified as teens or children, ChatGPT will apply filters to “reduce exposure” to content like graphic violence or sexual role-play. YouTube launched something similar last year.

If you support age verification but are concerned about privacy, this might sound like a win. But there&#39;s a catch. The system is not perfect, of course, so it could classify a child as an adult or vice versa. People who are wrongly labeled under 18 can verify their identity by submitting a selfie or government ID to a company called Persona.

Selfie verifications have issues: They fail more often for people of color and those with certain disabilities. Sameer Hinduja, who co-directs the Cyberbullying Research Center, says the fact that Persona will need to hold millions of government IDs and masses of biometric data is another weak point. “When those get breached, we’ve exposed massive populations all at once,” he says.

Hinduja instead advocates for device-level verification, where a parent specifies a child’s age when setting up the child’s phone for the first time. This information is then kept on the device and shared securely with apps and websites.

That’s more or less what Tim Cook, the CEO of Apple, recently lobbied US lawmakers to call for. Cook was fighting lawmakers who wanted to require app stores to verify ages, which would saddle Apple with lots of liability.

More signals of where this is all headed will come on Wednesday, when the Federal Trade Commission—the agency that would be responsible for enforcing these new laws—is holding an all-day workshop on age verification. Apple’s head of government affairs, Nick Rossi, will be there. He’ll be joined by higher-ups in child safety at Google and Meta, as well as a company that specializes in marketing to children.

The FTC has become increasingly politicized under President Trump (his firing of the sole Democratic commissioner was struck down by a federal court, a decision that is now pending review by the US Supreme Court). In July, I wrote about signals that the agency is softening its stance toward AI companies. Indeed, in December, the FTC overturned a Biden-era ruling against an AI company that allowed people to flood the internet with fake product reviews, writing that it clashed with President Trump’s AI Action Plan.

Wednesday’s workshop may shed light on how partisan the FTC’s approach to age verification will be. Red states favor laws that require porn websites to verify ages (but critics warn this could be used to block a much wider range of content). Bethany Soye, a Republican state representative who is leading an effort to pass such a bill in her state of South Dakota, is scheduled to speak at the FTC meeting. The ACLU generally opposes laws requiring IDs to visit websites and has instead advocated for an expansion of existing parental controls.

While all this gets debated, though, AI has set the world of child safety on fire. We’re dealing with increased generation of child sexual abuse material, concerns (and lawsuits) about suicides and self-harm following chatbot conversations, and troubling evidence of kids’ forming attachments to AI companions. Colliding stances on privacy, politics, free expression, and surveillance will complicate any effort to find a solution. Write to me with your thoughts.

Four ways to think about this year&#39;s reckoning.

Our AI writers make their big bets for the coming year—here are five hot trends to watch.

By studying large language models as if they were living things instead of computer programs, scientists are discovering some of their secrets for the first time.

In an exclusive interview, the AI pioneer shares his plans for his new Paris-based company, AMI Labs.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-56')">
            <div class="source">MIT Technology Review</div>
            <div class="title">The power of sound in a virtual world</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-56" style="display:none;">
            <h2>The power of sound in a virtual world</h2>
            <p><strong>MIT Technology Review | 2026-01-26</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2026/01/26/1124655/the-power-of-sound-in-a-virtual-world/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">In an era where business, education, and even casual conversations occur via screens, sound has become a differentiating factor. We obsess over lighting, camera angles, and virtual backgrounds, but how we sound can be just as critical to credibility, trust, and connection.

That’s the insight driving Erik Vaveris, vice president of product management and chief marketing officer at Shure, and Brian Scholl, director of the Perception & Cognition Laboratory at Yale University. Both see audio as more than a technical layer: It’s a human factor shaping how people perceive intelligence, trustworthiness, and authority in virtual settings.

&quot;If you&#39;re willing to take a little bit of time with your audio set up, you can really get across the full power of your message and the full power of who you are to your peers, to your employees, your boss, your suppliers, and of course, your customers,&quot; says Vaveris.

Scholl’s research shows that poor audio quality can make a speaker seem less persuasive, less hireable, and even less credible.

&quot;We know that [poor] sound doesn&#39;t reflect the people themselves, but we really just can&#39;t stop ourselves from having those impressions,&quot; says Scholl. &quot;We all understand intuitively that if we&#39;re having difficulty being understood while we&#39;re talking, then that&#39;s bad. But we sort of think that as long as you can make out the words I&#39;m saying, then that&#39;s probably all fine. And this research showed in a somewhat surprising way, to a surprising degree, that this is not so.&quot;

For organizations navigating hybrid work, training, and marketing, the stakes have become high.

Vaveris points out that the pandemic was a watershed moment for audio technology. As classrooms, boardrooms, and conferences shifted online almost overnight, demand accelerated for advanced noise suppression, echo cancellation, and AI-driven processing tools that make meetings more seamless. Today, machine learning algorithms can strip away keyboard clicks or reverberation and isolate a speaker’s voice in noisy environments. That clarity underpins the accuracy of AI meeting assistants that can step in to transcribe, summarize, and analyze discussions.

The implications across industries are rippling. Clearer audio levels the playing field for remote participants, enabling inclusive collaboration. It empowers executives and creators alike to produce broadcast-quality content from the comfort of their home office. And it offers companies new ways to build credibility with customers and employees without the costly overhead of traditional production.

Looking forward, the convergence of audio innovation and AI promises an even more dynamic landscape: from real-time captioning in your native language to audio filtering, to smarter meeting tools that capture not only what is said but how it’s said, and to technologies that disappear into the background while amplifying the human voice at the center.

&quot;There&#39;s a future out there where this technology can really be something that helps bring people together,&quot; says Vaveris. &quot;Now that we have so many years of history with the internet, we know there&#39;s usually two sides to the coin of technology, but there&#39;s definitely going to be a positive side to this, and I&#39;m really looking forward to it.

In a world increasingly mediated by screens, sound may prove to be the most powerful connector of all.

This episode of Business Lab is produced in partnership with Shure.

Megan Tatum: From MIT Technology Review, I&#39;m Megan Tatum, and this is Business Lab, the show that helps business leaders make sense of new technologies coming out of the lab and into the marketplace.This episode is produced in partnership with Shure.Our topic today is the power of sound. As our personal and professional lives become increasingly virtual, audio is emerging as an essential tool for everything from remote work to virtual conferences to virtual happy hour. While appearance is often top of mind in video conferencing and streaming, audio can be as or even more important, not only to effective communication, but potentially to brand equity for both the speaker and the company.Two words for you: crystal clear.My guests today are Erik Vaveris, VP of Product Management and Chief Marketing Officer at Shure, and Brian Scholl, Director of the Perception & Cognition Laboratory at Yale University.Welcome, Erik and Brian.

Erik Vaveris: Thank you, Megan. And hello, Brian. Thrilled to be here today.

Megan: Fantastic. Thank you both so much for being here. Erik, let&#39;s open with a bit of background. I imagine the pandemic changed the audio industry in some significant ways, given the pivot to our modern remote hybrid lifestyles. Could you talk a bit about that journey and some of the interesting audio advances that arose from that transformative shift?

Erik: Absolutely, Megan. That&#39;s an interesting thing to think about now being here in 2025. And if you put yourself back in those moments in 2020, when things were fully shut down and everything was fully remote, the importance of audio quality became immediately obvious. As people adopted Zoom or Teams or platforms like that overnight, there were a lot of technical challenges that people experienced, but the importance of how they were presenting themselves to people via their audio quality was a bit less obvious. As Brian&#39;s noted in a lot of the press that he&#39;s received for his wonderful study, we know how we look on video. We can see ourselves back on the screen, but we don&#39;t know how we sound to the people with whom we&#39;re speaking.

If a meeting participant on the other side can manage to parse the words that you&#39;re saying, they&#39;re not likely to speak up and say, &quot;Hey, I&#39;m having a little bit of trouble hearing you.&quot; They&#39;ll just let the meeting continue. And if you don&#39;t have a really strong level of audio quality, you&#39;re asking the people that you&#39;re talking to devote way too much brainpower to just determining the words that you&#39;re saying. And you&#39;re going to be fatiguing to listen to. And your message won&#39;t come across. In contrast, if you&#39;re willing to take a little bit of time with your audio set up, you can really get across the full power of your message and the full power of who you are to your peers, to your employees, your boss, your suppliers, and of course your customers. Back in 2020, this very quickly became a marketing story that we had to tell immediately.

And I have to say, it&#39;s so gratifying to see Brian&#39;s research in the news because, to me, it was like, &quot;Yes, this is what we&#39;ve been experiencing. And this is what we&#39;ve been trying to educate people about.&quot; Having the real science to back it up means a lot. But from that, development on improvements to key audio processing algorithms accelerated across the whole AV industry.

I think, Megan and Brian, you probably remember hearing loud keyboard clicking when you were on calls and meetings, or people eating potato chips and things like that back on those. But you don&#39;t hear that much today because most platforms have invested in AI-trained algorithms to remove undesirable noises. And I know we&#39;re going to talk more about that later on.

But the other thing that happened, thankfully, was that as we got into the late spring and summer of 2020, was that educational institutions, especially universities, and also businesses realized that things were going to need to change quickly. Nothing was going to be the same. And universities realized that all classrooms were going to need hybrid capabilities for both remote students and students in the classroom. And that helped the market for professional AV equipment start to recover because we had been pretty much completely shut down in the earlier months. But that focus on hybrid meeting spaces of all types accelerated more investment and more R&D into making equipment and further developing those key audio processing algorithms for more and different types of spaces and use cases. And since then, we&#39;ve really seen a proliferation of different types of unobtrusive audio capture devices based on arrays of microphones and the supporting signal processing behind them. And right now, machine-learning-trained signal processing is really the norm. And that all accelerated, unfortunately, because of the pandemic.

Megan: Yeah. Such an interesting period of change, as you say. And Brian, what did you observe and experience in academia during that time? How did that time period affect the work at your lab?

Brian: I&#39;ll admit, Megan, I had never given a single thought to audio quality or anything like that, certainly until the pandemic hit. I was thrown into this, just like the rest of the world was. I don&#39;t believe I&#39;d ever had a single video conference with a student or with a class or anything like that before the pandemic hit. But in some ways, our experience in universities was quite extreme. I went on a Tuesday from teaching an in-person class with 300 students to being on Zoom with everyone suddenly on a Thursday. Business meetings come in all shapes and sizes. But this was quite extreme. This was a case where suddenly I&#39;m talking to hundreds and hundreds of people over Zoom. And every single one of them knows exactly what I sound like, except for me, because I&#39;m just speaking my normal voice and I have no idea how it&#39;s being translated through all the different levels of technology.

I will say, part of the general rhetoric we have about the pandemic focuses on all the negatives and the lack of personal connection and nuance and the fact that we can&#39;t see how everyone&#39;s paying attention to each other. Our experience was a bit more mixed. I&#39;ll just tell you one anecdote. Shortly after the pandemic started, I started teaching a seminar with about 20 students. And of course, this was still online. What I did is I just invited, for whatever topic we were discussing on any given day, I sent a note to whoever was the clear world leader in the study of whatever that topic was. I said, &quot;Hey, don&#39;t prepare a talk. You don&#39;t have to answer any questions. But just come join us on Zoom and just participate in the conversation. The students will have read some of your work.&quot;

Every single one of them said, &quot;Let me check my schedule. Oh, I&#39;m stuck at home for a year. Sure. I&#39;d be happy to do that.&quot; And that was quite a positive. The students got to meet a who&#39;s who of cognitive science from this experience. And it&#39;s true that there were all these technological difficulties, but that would never, ever have happened if we were teaching the class in real life. That would&#39;ve just been way too much travel and airfare and hotel and scheduling and all of that. So, it was a mixed bag for us.

Erik: That is really interesting. And that&#39;s such a cool idea. And it&#39;s so wonderful that that worked out. I would say that working for a global company, we like to think that, &quot;Oh, we&#39;re all together. And we&#39;re having these meetings. And we&#39;re in the same room,&quot; but the reality was we weren&#39;t in the same room. And there hadn&#39;t been enough attention paid to the people who were conferencing in speaking not their native language in a different time zone, maybe pretty deep into the evening, in some cases. And the remote work that everybody got thrown into immediately at the start of the pandemic did force everybody to start to think more about those types of interactions and put everybody on a level playing field.

And that was insightful. And that helped some people have stronger voices in the work that we were doing than they maybe did before. And it&#39;s also led businesses really across the board, there&#39;s a lot written about this, to be much more focused on making sure that participants from those who may be remote at home, may be in the office, may be in different offices, may be in different time zones, are all able to participate and collaborate on really a level playing field. And that is a positive. That&#39;s a good thing.

Megan: Yeah. There are absolutely some positive side effects there, aren&#39;t there? And it inspired you, Brian, to look at this more closely. And you&#39;ve done a study that shows poor audio quality can actually affect the perception of listeners. So, I wonder what prompted the study, in particular. And what kinds of data did you gather? What methodology did you use?

Brian: Yeah. The motivation for this study was actually a real-world experience, just like we&#39;ve been talking about. In addition to all of our classes moving online with no notice whatsoever, the same thing was true of our departmental faculty meetings. Very early on in the pandemic, we had one of these meetings. And we were talking about some contentious issue about hiring or whatever. And two of my colleagues, who I&#39;d known very well and for many, many years, spoke up to offer their opinions. And one of these colleagues is someone who I&#39;m very close with. We almost always see eye to eye. He was actually a former graduate student of mine once upon a time. And we almost always see eye to eye on things. He happened to be participating in that meeting from an old not-so-hot laptop. His audio quality had that sort of familiar tinny quality that we&#39;re all familiar with. I could totally understand everything he was saying, but I found myself just being a little skeptical.

I didn&#39;t find his points so compelling as usual. Meanwhile, I had another colleague, someone who I deeply respect, I&#39;ve collaborated with, but we don&#39;t always see eye to eye on these things. And he was participating in this first virtual faculty meeting from his home recording studio. Erik, I don&#39;t know if his equipment would be up to your level or not, but he sounded better than real life. He sounded like he was all around us. And I found myself just sort of naturally agreeing with his points, which sort of was notable and a little surprising in that context. And so, we turned this into a study.

We played people a number of short audio clips, maybe like 30 seconds or so. And we had these being played in the context of very familiar situations and decisions. One of them might be like a hiring decision. You would have to listen to this person telling you why they think they might be a good fit for your job. And then afterwards, you had to make a simple judgment. It might be of a trait. How intelligent did that person seem? Or it might be a real-world decision like, &quot;Hey, based on this, how likely would you be to pursue trying to hire them?&quot; And critically, we had people listen to exactly the same sort of scripts, but with a little bit of work behind the scenes to affect the audio quality. In one case, the audio sounded crisp and clear. Recorded with a decent microphone. And here&#39;s what it sounded like.

Audio Clip: After eight years in sales, I&#39;m currently seeking a new challenge which will utilize my meticulous attention to detail and friendly professional manner. I&#39;m an excellent fit for your company and will be an asset to your team as a senior sales manager.

Brian: Okay. Whatever you think of the content of that message, at least it&#39;s nice and clear. Other subjects listened to exactly the same recording. But again, it had that sort of tinny quality that we&#39;re all familiar with when people&#39;s voices are filtered through a microphone or a recording setup that&#39;s not so hot. That sounded like this.

Audio Clip: After eight years in sales, I&#39;m currently seeking a new challenge which will utilize my meticulous attention to detail and friendly professional manner. I&#39;m an excellent fit for your company and will be an asset to your team as a senior sales manager.

Brian: All right. Now, the thing that I hope you can get from that recording there is that although it clearly has this what we would call, as a technical term, a disfluent sound, it&#39;s just a little harder to process, you are ultimately successful, right? Megan, Erik, you were able to understand the words in that second recording.

Brian: And we made sure this was true for all of our subjects. We had them do word-for-word transcription after they made these judgments. And I&#39;ll also just point out that this kind of manipulation clearly can&#39;t be about the person themselves, right? You couldn&#39;t make your voices sound like that in real world conversation if you tried. Voices just don&#39;t do those sorts of things. Nevertheless, in a way that sort of didn&#39;t make sense, that was kind of irrational because this couldn&#39;t reflect the person, this affected all sorts of judgments about people.

So, people were judged to be about 8% less hirable. They were judged to be about 8% less intelligent. We also did this in other contexts. We did this in the context of dateability as if you were listening to a little audio clip from someone who was maybe interested in dating you, and then you had to make a judgment of how likely would you be to date this person. Same exact result. People were a little less datable when their audio was a little more tinny, even though they were completely understandable.

The experiment, the result that I thought was in some ways most striking is one of the clips was about someone who had been in a car accident. It was a little narrative about what had happened in the car accident. And they were talking as if to the insurance agent. They were saying, &quot;Hey, it wasn&#39;t my fault. This is what happened.&quot; And afterwards, we simply had people make a natural intuitive judgment of how credible do you think the person&#39;s story was. And when it was recorded with high-end audio, these messages were judged to be about 8% more credible in this context. So those are our experiments. What it shows really is something about the power of perception. We know that that sort of sound doesn&#39;t reflect the people themselves, but we really just can&#39;t stop ourselves from having those impressions made. And I don&#39;t know about you guys, but, Erik, I think you&#39;re right, that we all understand intuitively that if we&#39;re having difficulty being understood while we&#39;re talking, then that&#39;s bad. But we sort of think that as long as you can make out the words I&#39;m saying, then that&#39;s probably all fine. And this research showed in a somewhat surprising way to a surprising degree that this is not so.

Megan: From an industry perspective, Erik, what are your thoughts on those study results? Did it surprise you as well?

Erik: No, like I said, I found it very, very gratifying because we invest a lot in trying to make sure that people understand the importance of quality audio, but we kind of come about that intuitively. Our entire company is audio people. So of course, we think that. And it&#39;s our mission to help other people achieve those higher levels of audio in everything that they do, whether you&#39;re a minister at a church or you&#39;re teaching a class or you&#39;re performing on stage. When I first saw in the news about Brian&#39;s study, I think it was the NPR article that just came up in one of my feeds. I read it and it made me feel like my life&#39;s work has been validated to some extent. I wouldn&#39;t say we were surprised by it, but iIt made a lot of sense to us. Let&#39;s put it that way.

Brian: This is what we&#39;re hearing. Oh, sorry. Megan, I was going to say this is what we&#39;re hearing from a lot of the audio professionals as they&#39;re saying, &quot;Hey, you scientists, you finally caught up to us.&quot; But of course-

Brian: Erik, you&#39;re in an unusual circumstance because you guys think about audio every day. When we&#39;re on Zoom, look, I can see the little rectangle as well as you can. I can see exactly how I look like. I can check the lighting. I check my hair. We all do that every day. But I would say most people really, they use whatever microphone came with their setup, and never give a second thought to what they sound like because they don&#39;t know what they sound like.

Megan: Avoid listening to yourself back as well. I think that&#39;s common. We don&#39;t scrutinize audio as much as we should. I wonder, Erik, since the study came out, how are you seeing that research play out across industry? Can you talk a bit about the importance of strong, clear audio in today&#39;s virtual world and the challenges that companies and employees are facing as well?

Erik: Yeah. Sure, Megan. That&#39;s a great question. And studies kind of back this up, businesses understand that collaboration is the key to many things that we do. They know that that&#39;s critical. And they are investing in making the experiences for the people at work better because of that knowledge, that intuitive understanding. But there are challenges. It can be expensive. You need solutions that people who are going to walk into a room or join a meeting on their personal device, that they&#39;re motivated to use and that they can use because they&#39;re simple. You also have to overcome the barriers to investment. We in the AV industry have had to look a lot at how can we bring down the overall cost of ownership of setting up AV technology because, as we&#39;ve seen, the prices of everything that goes into making a product are not coming down.

Simplifying deployment and management is critical. Beyond just audio technology, IoT technology and cloud technology for IT teams to be able to easily deploy and manage classrooms across an entire university campus or conference rooms across a global enterprise are really, really critical. And those are quickly evolving. And integrations with more standard common IT tools are coming out. And that&#39;s one area. Another thing is just for the end user, having the same user interface in each conference room that is familiar to everyone from their personal devices is also important. For many, many years, a lot of people had the experience where, &quot;Hey, it&#39;s time we&#39;re going to actually do a conference meeting.&quot; And you might have a few rooms in your company or in your office area that could do that. And you walk into the meeting room. And how long does it take you to actually get connected to the people you&#39;re going to talk with?

There was always a joke that you&#39;d have to spend the first 15 minutes of a meeting working all of that out. And that&#39;s because the technology was fragmented and you had to do a lot of custom work to make that happen. But these days, I would say platforms like Zoom and Teams and Google and others are doing a really great job with this. If you have the latest and greatest in your meeting rooms and you know how to join from your own personal device, it&#39;s basically the same experience. And that is streamlining the process for everyone. Bringing down the costs of owning it so that companies can get to those benefits to collaboration is kind of the key.

Megan: I was going to ask if we could dive a little deeper into that kind of audio quality, the technological advancements that AI has made possible, which you did touch on slightly there, Erik. What are the most significant advancements, in your view? And how are those impacting the ways we use audio and the things we can do with it?

Erik: Okay. Let me try to break that down into-

Erik: ... a couple different sections. Yeah. No, and one that&#39;s just so exciting. Machine-learning-based digital signal processing, or DSP, is here and is the norm now. If you think about the beginning of telephones and teleconferencing, just going way back, one of the initial problems you had whenever you tried to get something out of a dedicated handset onto a table was echo. And I&#39;m sure we&#39;ve all heard that at some point in our life. You need to have a way to cancel echo. But by the way, you also want people to be able to speak at the same time on both ends of a call. You get to some of those very rudimentary things. Machine learning is really supercharging those algorithms to provide better performance with fewer trade-offs, fewer artifacts in the actual audio signal.

Noise reduction has come a long way. I mentioned earlier on, keyboard sounds and the sounds of people eating, and how you just don&#39;t hear that anymore, at least I don&#39;t when I&#39;m on conference calls. But only a few years ago, that could be a major problem. The machine-learning-trained digital signal processing is in the market now and it&#39;s doing a better job than ever in removing things that you don&#39;t want from your sound. We have a new de-verberation algorithm, so if you have a reverberant room with echoes and reflections that&#39;s getting into the audio signal, that can degrade the experience there. We can remove that now. Another thing, the flip side of that is that there&#39;s also a focus on isolating the sound that you do want and the signal that you do want.

Microsoft has rolled out a voice print feature in Teams that allows you, if you&#39;re willing, to provide them with a sample of your voice. And then whenever you&#39;re talking from your device, it will take out anything else that the microphone may be picking up so that even if you&#39;re in a really noisy environment outdoors or, say, in an airport, the people that you&#39;re speaking with are going to hear you and only you. And it&#39;s pretty amazing as well. So those are some of the things that are happening today and are available today.

Another thing that&#39;s emerged from all of this is we&#39;ve been talking about how important audio quality is to the people participating in a discussion, the people speaking, the people listening, how everyone is perceived, but a new consumer, if you will, of audio in a discussion or a meeting has emerged, and that is in the form of the AI agent that can summarize meetings and create action plans, do those sorts of things. But for it to work, a clean transcription of what was said is already table stakes. It can&#39;t garbled. It can&#39;t miss key things. It needs to get it word for word, sentence for sentence throughout the entire meeting. And the ability to attribute who said what to the meeting participants, even if they&#39;re all in the same room, is quickly upon us. And the ability to detect and integrate sentiment and emotion of the participants is going to become very important as well for us to really get the full value out of those kinds of AI agents.

So audio quality is as important as ever for humans, as Brian notes, in some ways more important because this is now the normal way that we talk and meet, but it&#39;s also critical for AI agents to work properly. And it&#39;s different, right? It&#39;s a different set of considerations. And there&#39;s a lot of emerging thought and work that&#39;s going into that as well. And boy, Megan, there&#39;s so much more we could say about this beyond meetings and video conferences. AI tools to simplify the production process. And of course, there&#39;s generative AI of music content. I know that&#39;s beyond the scope of what we&#39;re talking about. But it&#39;s really pretty incredible when you look around at the work that&#39;s happening and the capabilities that are emerging.

Megan: Yeah. Absolutely. Sounds like there are so many elements to consider and work going on. It&#39;s all fascinating. Brian, what kinds of emerging capabilities and use cases around AI and audio quality are you seeing in your lab as well?

Brian: Yeah. Well, I&#39;m sorry that Brian himself was not able to be here today, but I&#39;m an AI agent.

Brian: Just kidding. The fascinating thing that we&#39;re seeing from the lab, from the study of people&#39;s impressions is that all of this technology that Erik has described, when it works best, it&#39;s completely invisible. Erik, I loved your point about not hearing potato chips being eaten or rain in the background or something like that. You&#39;re totally right. I used to notice that all the time. I don&#39;t think I&#39;ve noticed that recently, but I also didn&#39;t notice that I haven&#39;t noticed that recently, right? It just kind of disappears. The interesting thing about these perceptual impressions, we&#39;re constantly drawing intuitive conclusions about people based on how they sound. And that might be a good thing or a bad thing when we&#39;re judging things like trustworthiness, for example, on the basis of a short audio clip.

But clearly, some of these things are valid, right? We can judge the size of someone or even of an animal based on how they sound, right? A chihuahua can&#39;t make the sound of a lion. A lion can&#39;t make the sound of a chihuahua. And that&#39;s always been true because we&#39;re producing audio signals that go right into each other&#39;s ears. And now, of course, everything that Erik is talking about, that&#39;s not true. It goes through all of these different layers of technology increasingly fueled by AI. But when that technology works the best way, it&#39;s as if it isn&#39;t there at all and we&#39;re just hearing each other directly.

Erik: That&#39;s the goal, right? That it&#39;s seamless open communication and we don&#39;t have to think about the technology anymore.

Brian: It&#39;s a tough business to be in, I think, though, Erik, because people have to know what&#39;s going on behind the surface in order to value it. Otherwise, we just expect it to work.

Erik: Well, that&#39;s why we try to put the logo of our products on the side of them so they show up in the videos. But yeah, it&#39;s a good point.

Megan: And we&#39;ve talked about virtual meetings and conversations quite a bit, but there&#39;s also streamed and recorded content, which are increasingly important at work as well. I wondered, Erik, if you could talk a bit about how businesses are leveraging audio in new ways for things like marketing campaigns and internal upskilling and training and areas like that?

Erik: Yeah. Well, one of the things I think we&#39;ve all seen in marketing is that not everything is a high production value commercial anymore. And there&#39;s still a place for that, for sure. But people tend to trust influencers that they follow. People search on TikTok, on YouTube for topics. Those can be the place that they start. And as technology&#39;s gotten more accessible, not just audio, but of course, the video technology too, content creators can produce satisfying content on their own or with just a couple of people with them. And Brian&#39;s study shows that it doesn&#39;t really matter what the origins of the content are for it to be compelling.

For the person delivering the message to be compelling, the audio quality does have to hit a certain level. But because the tools are simpler to use and you need less things to connect and pull together a decent production system, creator-driven content is becoming even more and more integral to a marketing campaign. And so not just what they maybe post on their Instagram page or post on LinkedIn, for example, but us as a brand being able to take that content and use that actually in paid media and things like that is all entirely possible because of the overall quality of the content. So that&#39;s something that&#39;s been a trend that&#39;s been in process really, I would say, maybe since the advent of podcasts. But it&#39;s been an evolution. And it&#39;s come a long, long way.

Another thing, and this is really interesting, and this hits home personally, but I remember when I first entered the workforce, and I hope I&#39;m not showing my age too badly here, but I remember the word processing department. And you would write down on a piece of paper, like a memo, and you would give it to the word processing department and somebody would type it up for you. That was a thing. And these days, we&#39;re seeing actually more and more video production with audio, of course, transfer to the actual producers of the content.

In my company, at Shure, we make videos for different purposes to talk about different initiatives or product launches or things that we&#39;re doing just for internal use. And right now, everybody, including our CEO, she makes these videos just at her own desk. She has a little software tool and she can show a PowerPoint and herself and speak to things. And with very, very limited amount of editing, you can put that out there. And I&#39;ve seen friends and colleagues at other companies in very high-level roles just kind of doing their own production. Being able to buy a very high quality microphone with really advanced signal processing built right in, but just plug it in via USB and have it be handled as simply as any consumer device, has made it possible to do really very useful production where you are going to actually sound good and get your message across, but without having to make such a big production out of it, which is kind of cool.

Megan: Yeah. Really democratizes access to sort of creating high quality content, doesn&#39;t it? And of course, no technology discussion is complete without a mention of return on investment, particularly nowadays. Erik, what are some ways companies can get returns on their audio tech investments as well? Where are the most common places you see cost savings?

Erik: Yeah. Well, we collaborated on a study with IDC Research. And they came up with some really interesting findings on this. And one of them was, no surprise, two-thirds or more of companies have taken action on improving their communication and collaboration technology, and even more have additional or initial investments still planned. But the ROI of those initiatives isn&#39;t really tied to the initiative itself. It&#39;s not like when you come out with a new product, you look at how that product performs, and that&#39;s the driver of your ROI. The benefits of smoother collaboration come in the form of shorter meetings, more productive meetings, better decision-making, faster decision-making, stronger teamwork. And so to build an ROI model, what IDC concluded was that you have to build your model to account for those advantages really across the enterprise or across your university, or whatever it may be, and kind of up and down the different set of activities where they&#39;re actually going to be utilized.

So that can be complex. Quantifying things can always be a challenge. But like I said, companies do seem to understand this. And I think that&#39;s because, this is just my hunch, but because everybody, including the CEO and the CFO and the whole finance department, uses and benefits from collaboration technology too. Perhaps that&#39;s one reason why the value is easier to convey. Even if they have not taken the time to articulate things like we&#39;re doing here today, they know when a meeting is good and when it&#39;s not good. And maybe that&#39;s one of the things that&#39;s helping companies to justify these investments. But it&#39;s always tricky to do ROI on projects like that. But again, focusing on the broader benefits of collaboration and breaking it down into what it means for specific activities and types of meetings, I think, is the way to go about doing that.

Megan: Absolutely. And Brian, what kinds of advancements are you seeing in the lab that perhaps one day might contribute to those cost savings?

Brian: Well, I don&#39;t know anything about cost savings, Megan. I&#39;m a college professor. I live a pure life of the mind.

Brian: ROI does not compute for me. No, I would say we are in an extremely exciting frontier right now because of AI and many different technologies. The studies that we talked about earlier, in one sense, they were broad. We explored many different traits from dating to hiring to credibility. And we isolated them in all sorts of ways we didn&#39;t talk about. We showed that it wasn&#39;t due to overall affect or pessimism or something like that. But in those studies, we really only tested one very particular set of dimensions along which an audio signal can vary, which is some sort of model of clarity. But in reality, the audio signal is so multi-dimensional. And as we&#39;re getting more and more tools these days, we can not only change audio along the lines of clarity, as we&#39;ve been talking about, but we can potentially manipulate it in all sorts of ways.

We&#39;re very interested in pushing these studies forward and in exploring how people&#39;s sort of brute impressions that they make are affected by all sorts of things. Meg and Erik, we walk around the world all the time making these judgments about people, right? You meet someone and you&#39;re like, &quot;Wow, I could really be friends with them. They seem like a great person.&quot; And you know that you&#39;re making that judgment, but you have no idea why, right? It just seems kind of intuitive. Well, in an audio signal, when you&#39;re talking to someone, you can think of, &quot;What if their signal is more bass heavy? What if it&#39;s a little more treble heavy? What if we manipulate it in this way? In that way?&quot;

When we talked about the faculty meeting that motivated this whole research program, I mentioned that my colleague, who was speaking from his home recording studio, he actually didn&#39;t sound clear like in real life. He sounded better than in real life. He sounded like he was all around us. What is the implication of that? I think there&#39;s so many different dimensions of an audio signal that we&#39;re just being able to readily control and manipulate that it&#39;s going to be very exciting to see how all of these sorts of things impact our impressions of each other.

Megan: And there may be some overlap with this as well, but I wondered if we could close with a future forward look, Brian. What are you looking forward to in emerging audio technology? What are some exciting opportunities on the horizon, perhaps related to what you were just talking about there?

Brian: Well, we&#39;re interested in studying this from a scientific perspective. Erik, you talked about how when you started. When I started doing this science, we didn&#39;t have a word processing department. We had a stone tablet department. But I hear tell that the current generation, when they send photos back and forth to each other, that they, as a matter, of course, they apply all sorts of filters-

Brian: ... to those video signals, those video or just photographic signals. We&#39;re all familiar with that. That hasn&#39;t quite happened with the audio signals yet, but I think that&#39;s coming up as well. You can imagine that you record yourself saying a little message and then you filter it this way or that way. And that&#39;s going to become the Wild West about the kinds of impressions we make on each other, especially if and when you don&#39;t know that those filters have been operating in the first place.

Megan: That&#39;s so interesting. Erik, what are you looking forward to in audio technology as well?

Erik: Well, I&#39;m still thinking about what Brian said.

Erik: I have to go back again. I&#39;ll go back to the past, maybe 15 to 20 years. And I remember at work, we had meeting rooms with the Starfish phones in the middle of the table. And I remember that we would have international meetings with our partners there that were selling our products in different countries, including in Japan and in China, and the people actually in our own company in those countries. We knew the time zone was bad. And we knew that English wasn&#39;t their native language, and tried to be as courteous as possible with written materials and things like that. But I went over to China, and I had to actually be on the other end of one of those calls. And I&#39;m a native English speaker, or at least a native Chicago dialect of American English speaker. And really understanding how challenging it was for them to participate in those meetings just hit me right between the eyes.

We&#39;ve come so far, which is wonderful. But I think of a scenario, and this is not far off, there are many companies working on this right now, where not only can you get a real time captioning in your native language, no matter what the language of the participant, you can actually hear the person who&#39;s speaking&#39;s voice manipulated into your native language.

I&#39;m never going to be a fluent Japanese or Chinese speaker, that&#39;s for sure. But I love the thought that I could actually talk with people and they could understand me as though I were speaking their native language, and that they could communicate to me and I could understand them in the way that they want to be understood. I think there&#39;s a future out there where this technology can really be something that helps bring people together. Now that we have so many years of history with the internet, we know there&#39;s usually two sides to the coin of technology, but there&#39;s definitely going to be a positive side to this, and I&#39;m really looking forward to it.

Megan: Gosh, that sounds absolutely fascinating. Thank you both so much for such an interesting discussion.

That was Erik Vaveris, the VP of product management and chief marketing officer at Shure, and Brian Scholl, director of the Perception & Cognition Laboratory at Yale University, whom I spoke with from Brighton in England.That&#39;s it for this episode of Business Lab. I&#39;m your host, Megan Tatum. I&#39;m a contributing editor at Insights, the custom publishing division of MIT Technology Review. We were founded in 1899 at the Massachusetts Institute of Technology. And you can find us in print on the web and at events each year around the world. For more information about us and the show, please check out our website at technologyreview.com.This show is available wherever you get your podcasts. If you enjoyed this episode, we hope you&#39;ll take a moment to rate and review us. Business Lab is a production of MIT Technology Review. And this episode was produced by Giro Studios. Thanks for listening.

This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff. It was researched, designed, and written entirely by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.

Here are our picks for the advances to watch in the years ahead—and why we think they matter right now.

Four ways to think about this year&#39;s reckoning.

As early electric cars age out, hundreds of thousands of used batteries are flooding the market, fueling a gray recycling economy even as Beijing and big manufacturers scramble to build a more orderly system.

The Cybertruck, sycophantic AI, and humanoid robots all made this year’s list of the biggest technology failures.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-57')">
            <div class="source">MIT Technology Review</div>
            <div class="title">The Download: why LLMs are like aliens, and the future of head transplants</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-57" style="display:none;">
            <h2>The Download: why LLMs are like aliens, and the future of head transplants</h2>
            <p><strong>MIT Technology Review | 2026-01-26</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2026/01/26/1131717/the-download-why-llms-are-like-aliens-and-the-future-of-head-transplants/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">This is today&#39;s edition of The Download, our weekday newsletter that provides a daily dose of what&#39;s going on in the world of technology.

Meet the new biologists treating LLMs like aliens

How large is a large language model? We now coexist with machines so vast and so complicated that nobody quite understands what they are, how they work, or what they can really do—not even the people who build them.That’s a problem. Even though nobody fully understands how it works—and thus exactly what its limitations might be—hundreds of millions of people now use this technology every day.

To help overcome our ignorance, researchers are studying LLMs as if they were doing biology or neuroscience on vast living creatures—city-size xenomorphs that have appeared in our midst. And they’re discovering that large language models are even weirder than they thought. Read the full story.—Will Douglas Heaven

This is our latest story to be turned into a MIT Technology Review Narrated podcast, which we publish each week on Spotify and Apple Podcasts. Just navigate to MIT Technology Review Narrated on either platform, and follow us to get all our new content as it’s released.

And mechanistic interpretability, the technique these researchers are using to try and understand AI models, is one of our 10 Breakthrough Technologies for 2026. Check out the rest of the list here!

Job titles of the future: Head-transplant surgeon

The Italian neurosurgeon Sergio Canavero has been preparing for a surgery that might never happen. His idea? Swap a sick person’s head—or perhaps just the brain—onto a younger, healthier body.Canavero caused a stir in 2017 when he announced that a team he advised in China had exchanged heads between two corpses. But he never convinced skeptics that his technique could succeed—or to believe his claim that a procedure on a live person was imminent.

Canavero may have withdrawn from the spotlight, but the idea of head transplants isn’t going away. Instead, he says, the concept has recently been getting a fresh look from life-extension enthusiasts and stealth Silicon Valley startups. Read the full story.

This story is from the latest print issue of MIT Technology Review magazine, which is all about exciting innovations. If you haven’t already, subscribe now to receive future issues once they land.

I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.

1 Big Tech is facing multiple high-profile social media addiction lawsuits Meta, TikTok and YouTube will face parents’ accusations in court this week. (WP $)+ It’s the first time they’re defending against these claims before a jury in a court of law. (CNN)2 Power prices are surging in the world’s largest data center hubVirginia is struggling to meet record demand during a winter storm, partly because of the centers’ electricity demands. (Reuters)+ Why these kinds of violent storms are getting harder to forecast. (Vox)+ AI is changing the grid. Could it help more than it harms? (MIT Technology Review)3 TikTok has started collecting even more data on its usersIncluding precise information about their location. (Wired $)4 ICE-watching groups are successfully fighting DHS efforts to unmask themAn anonymous account holder sued to block ICE from identifying them—and won. (Ars Technica)5 A new wave of AI companies want to use AI to make AI betterThe AI ouroboros is never-ending. (NYT $)+ Is AI really capable of making bona fide scientific advancements? (Undark)+ AI trained on AI garbage spits out AI garbage. (MIT Technology Review)

6 Iran is testing a two-tier internetMeaning its current blackout could become permanent. (Rest of World)7 Don’t believe the humanoid robot hypeEven a leading robot maker admits that at best, they’re only half as efficient as humans. (FT $)+ Tesla wants to put its Optimus bipedal machine to work in its Austin factory. (Insider)+ Why the humanoid workforce is running late. (MIT Technology Review)

8 AI is changing how manufacturers create new productsIncluding thinner chewing gum containers and new body wash odors. (WSJ $)+ AI could make better beer. Here’s how. (MIT Technology Review)9 New Jersey has had enough of e-bikes 🚲But will other US states follow its lead? (The Verge)10 Sci-fi writers are cracking down on AIHuman-produced works only, please. (TechCrunch)+ San Diego Comic-Con was previously a safe space for AI-generated art. (404 Media)+ Generative AI is reshaping South Korea’s webcomics industry. (MIT Technology Review)

“Choosing American digital technology by default is too easy and must stop.”

—Nicolas Dufourcq, head of French state-owned investment bank Bpifrance, makes his case for why Big European companies should use European-made software as tensions with the US rise, the Wall Street Journal reports.

The return of pneumatic tubesPneumatic tubes were once touted as something that would revolutionize the world. In science fiction, they were envisioned as a fundamental part of the future—even in dystopias like George Orwell’s 1984, where they help to deliver orders for the main character, Winston Smith, in his job rewriting history to fit the ruling party’s changing narrative.In real life, the tubes were expected to transform several industries in the late 19th century through the mid-20th. For a while, the United States took up the systems with gusto.But by the mid to late 20th century, use of the technology had largely fallen by the wayside, and pneumatic tube technology became virtually obsolete. Except in hospitals. Read the full story.

A place for comfort, fun and distraction to brighten up your day. (Got any ideas? Drop me a line or skeet &#39;em at me.)

+ You really can’t beat the humble jacket potato for a cheap, comforting meal. + These tips might help you whenever anxiety strikes. ($)+ There are some amazing photos in this year’s Capturing Ecology awards.+ You can benefit from meditation any time, anywhere. Give it a go!

Plus: OpenAI is sounding the &quot;code red&quot; alarm

Plus: TikTok has finally signed a deal to keep operating in the US

Plus: This company is developing gene therapies for muscle growth, erectile dysfunction, and “radical longevity”

Plus: China has built a major chip-making machine

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-58')">
            <div class="source">MIT Technology Review</div>
            <div class="title">The Download: chatbots for health, and US fights over AI regulation</div>
            <div class="meta">2026-01-23</div>
        </div>
        
        <div id="content-58" style="display:none;">
            <h2>The Download: chatbots for health, and US fights over AI regulation</h2>
            <p><strong>MIT Technology Review | 2026-01-23</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2026/01/23/1131708/the-download-chatbots-for-health-and-us-fights-over-ai-regulation/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">This is today&#39;s edition of The Download, our weekday newsletter that provides a daily dose of what&#39;s going on in the world of technology.

For the past two decades, there’s been a clear first step for anyone who starts experiencing new medical symptoms: Look them up online. The practice was so common that it gained the pejorative moniker “Dr. Google.” But times are changing, and many medical-information seekers are now using LLMs. According to OpenAI, 230 million people ask ChatGPT health-related queries each week.

That’s the context around the launch of OpenAI’s new ChatGPT Health product, which debuted earlier this month. The big question is: can the obvious risks of using AI for health-related queries be mitigated enough for them to be a net benefit? Read the full story.

In the final weeks of 2025, the battle over regulating artificial intelligence in the US reached boiling point. On December 11, after Congress failed twice to pass a law banning state AI laws, President Donald Trump signed a sweeping executive order seeking to handcuff states from regulating the booming industry.

Instead, he vowed to work with Congress to establish a “minimally burdensome” national AI policy. The move marked a victory for tech titans, who have been marshaling multimillion-dollar war chests to oppose AI regulations, arguing that a patchwork of state laws would stifle innovation.

In 2026, the battleground will shift to the courts. While some states might back down from passing AI laws, others will charge ahead. Read our story about what’s on the horizon.

This story is from MIT Technology Review’s What’s Next series of stories that look across industries, trends, and technologies to give you a first look at the future. You can read the rest of them here.

This week marked a rather unpleasant anniversary: It’s a year since Texas reported a case of measles—the start of a significant outbreak that ended up spreading across multiple states. Since the start of January 2025, there have been over 2,500 confirmed cases of measles in the US. Three people have died.

As vaccination rates drop and outbreaks continue, scientists have been experimenting with new ways to quickly identify new cases and prevent the disease from spreading. And they are starting to see some success with wastewater surveillance. Read the full story.

This story is from The Checkup, our weekly newsletter giving you the inside track on all things health and biotech. Sign up to receive it in your inbox every Thursday.

I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.

1 The US is dismantling itselfA foreign enemy could not invent a better chain of events to wreck its standing in the world. (Wired $)  + We need to talk about whether Donald Trump might be losing it.  (New Yorker $)2 Big Tech is taking on more debt to fund its AI aspirationsAnd the bubble just keeps growing. (WP $)+ Forget unicorns. 2026 is shaping up to be the year of the “hectocorn.” (The Guardian)+ Everyone in tech agrees we’re in a bubble. They just can’t agree on what happens when it pops. (MIT Technology Review)

3 DOGE accessed even more personal data than we thought Even now, the Trump administration still can’t say how much data is at risk, or what it was used for. (NPR)

4 TikTok has finalized a deal to create a new US entity Ending years of uncertainty about its fate in America. (CNN)+ Why China is the big winner out of all of this. (FT $)

5 The US is now officially out of the World Health Organization And it’s leaving behind nearly $300 million in bills unpaid. (Ars Technica) + The US withdrawal from the WHO will hurt us all. (MIT Technology Review)6 AI-powered disinformation swarms pose a threat to democracyA would-be autocrat could use them to persuade populations to accept cancelled elections or overturn results. (The Guardian)+ The era of AI persuasion in elections is about to begin. (MIT Technology Review)7 We’re about to start seeing more robots everywhereBut exactly what they’ll look like remains up for debate. (Vox $)+ Chinese companies are starting to dominate entire sectors of AI and robotics. (MIT Technology Review)8 Some people seem to be especially vulnerable to lonelinessIf you’re ‘other-directed’, you could particularly benefit from less screentime. (New Scientist $)9 This academic lost two years of work with a single clickTL;DR: Don’t rely on ChatGPT to store your data. (Nature)10 How animals develop a sense of direction 🦇🧭Their ‘internal compass’ seems to be informed by landmarks that help them form a mental map. (Quanta $)

“The rate at which AI is progressing, I think we have AI that is smarter than any human this year, and no later than next year.”

—Elon Musk simply cannot resist the urge to make wild predictions at Davos, Wired reports.

After falling steadily for decades, the prevalence of global hunger is now on the rise—nowhere more so than in sub-Saharan Africa.

Africa’s indigenous crops are often more nutritious and better suited to the hot and dry conditions that are becoming more prevalent, yet many have been neglected by science, which means they tend to be more vulnerable to diseases and pests and yield well below their theoretical potential.

Now the question is whether researchers, governments, and farmers can work together in a way that gets these crops onto plates and provides Africans from all walks of life with the energy and nutrition that they need to thrive, whatever climate change throws their way. Read the full story.

A place for comfort, fun and distraction to brighten up your day. (Got any ideas? Drop me a line or skeet &#39;em at me.)

+ The only thing I fancy dry this January is a martini. Here’s how to make one.+ If you absolutely adore the Bic crystal pen, you might want this lamp. + Cozy up with a nice long book this winter. ($)+ Want to eat healthier? Slow down and tune out food ‘noise’. ($)

Plus: OpenAI is sounding the &quot;code red&quot; alarm

Plus: TikTok has finally signed a deal to keep operating in the US

Plus: This company is developing gene therapies for muscle growth, erectile dysfunction, and “radical longevity”

Plus: China has built a major chip-making machine

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-59')">
            <div class="source">MIT Technology Review</div>
            <div class="title">America’s coming war over AI regulation</div>
            <div class="meta">2026-01-23</div>
        </div>
        
        <div id="content-59" style="display:none;">
            <h2>America’s coming war over AI regulation</h2>
            <p><strong>MIT Technology Review | 2026-01-23</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2026/01/23/1131559/americas-coming-war-over-ai-regulation/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">MIT Technology Review’s What’s Next series looks across industries, trends, and technologies to give you a first look at the future. You can read the rest of them here.

In the final weeks of 2025, the battle over regulating artificial intelligence in the US reached a boiling point. On December 11, after Congress failed twice to pass a law banning state AI laws, President Donald Trump signed a sweeping executive order seeking to handcuff states from regulating the booming industry. Instead, he vowed to work with Congress to establish a “minimally burdensome” national AI policy, one that would position the US to win the global AI race. The move marked a qualified victory for tech titans, who have been marshaling multimillion-dollar war chests to oppose AI regulations, arguing that a patchwork of state laws would stifle innovation.

In 2026, the battleground will shift to the courts. While some states might back down from passing AI laws, others will charge ahead, buoyed by mounting public pressure to protect children from chatbots and rein in power-hungry data centers. Meanwhile, dueling super PACs bankrolled by tech moguls and AI-safety advocates will pour tens of millions into congressional and state elections to seat lawmakers who champion their competing visions for AI regulation.

Trump’s executive order directs the Department of Justice to establish a task force that sues states whose AI laws clash with his vision for light-touch regulation. It also directs the Department of Commerce to starve states of federal broadband funding if their AI laws are “onerous.” In practice, the order may target a handful of laws in Democratic states, says James Grimmelmann, a law professor at Cornell Law School. “The executive order will be used to challenge a smaller number of provisions, mostly relating to transparency and bias in AI, which tend to be more liberal issues,” Grimmelmann says.

For now, many states aren’t flinching. On December 19, New York’s governor, Kathy Hochul, signed the Responsible AI Safety and Education (RAISE) Act, a landmark law requiring AI companies to publish the protocols used to ensure the safe development of their AI models and report critical safety incidents. On January 1, California debuted the nation’s first frontier AI safety law, SB 53—which the RAISE Act was modeled on—aimed at preventing catastrophic harms such as biological weapons or cyberattacks. While both laws were watered down from earlier iterations to survive bruising industry lobbying, they struck a rare, if fragile, compromise between tech giants and AI safety advocates.

If Trump targets these hard-won laws, Democratic states like California and New York will likely take the fight to court. Republican states like Florida with vocal champions for AI regulation might follow suit. Trump could face an uphill battle. “The Trump administration is stretching itself thin with some of its attempts to effectively preempt [legislation] via executive action,” says Margot Kaminski, a law professor at the University of Colorado Law School. “It’s on thin ice.”

But Republican states that are anxious to stay off Trump’s radar or can’t afford to lose federal broadband funding for their sprawling rural communities might retreat from passing or enforcing AI laws. Win or lose in court, the chaos and uncertainty could chill state lawmaking. Paradoxically, the Democratic states that Trump wants to rein in—armed with big budgets and emboldened by the optics of battling the administration—may be the least likely to budge.

In lieu of state laws, Trump promises to create a federal AI policy with Congress. But the gridlocked and polarized body won’t be delivering a bill this year. In July, the Senate killed a moratorium on state AI laws that had been inserted into a tax bill, and in November, the House scrapped an encore attempt in a defense bill. In fact, Trump’s bid to strong-arm Congress with an executive order may sour any appetite for a bipartisan deal.

The executive order “has made it harder to pass responsible AI policy by hardening a lot of positions, making it a much more partisan issue,” says Brad Carson, a former Democratic congressman from Oklahoma who is building a network of super PACs backing candidates who support AI regulation. “It hardened Democrats and created incredible fault lines among Republicans,” he says.

While AI accelerationists in Trump’s orbit—AI and crypto czar David Sacks among them—champion deregulation, populist MAGA firebrands like Steve Bannon warn of rogue superintelligence and mass unemployment. In response to Trump’s executive order, Republican state attorneys general signed a bipartisan letter urging the FCC not to supersede state AI laws.

With Americans increasingly anxious about how AI could harm mental health, jobs, and the environment, public demand for regulation is growing. If Congress stays paralyzed, states will be the only ones acting to keep the AI industry in check. In 2025, state legislators introduced more than 1,000 AI bills, and nearly 40 states enacted over 100 laws, according to the National Conference of State Legislatures.

Efforts to protect children from chatbots may inspire rare consensus. On January 7, Google and Character Technologies, a startup behind the companion chatbot Character.AI, settled several lawsuits with families of teenagers who killed themselves after interacting with the bot. Just a day later, the Kentucky attorney general sued Character Technologies, alleging that the chatbots drove children to suicide and other forms of self-harm. OpenAI and Meta face a barrage of similar suits. Expect more to pile up this year. Without AI laws on the books, it remains to be seen how product liability laws and free speech doctrines apply to these novel dangers. “It’s an open question what the courts will do,” says Grimmelmann.

While litigation brews, states will move to pass child safety laws, which are exempt from Trump’s proposed ban on state AI laws. On January 9, OpenAI inked a deal with a former foe, the child-safety advocacy group Common Sense Media, to back a ballot initiative in California called the Parents & Kids Safe AI Act, setting guardrails around how chatbots interact with children. The measure proposes requiring AI companies to verify users’ age, offer parental controls, and undergo independent child-safety audits. If passed, it could be a blueprint for states across the country seeking to crack down on chatbots.

Fueled by widespread backlash against data centers, states will also try to regulate the resources needed to run AI. That means bills requiring data centers to report on their power and water use and foot their own electricity bills. If AI starts to displace jobs at scale, labor groups might float AI bans in specific professions. A few states concerned about the catastrophic risks posed by AI may pass safety bills mirroring SB 53 and the RAISE Act.

Meanwhile, tech titans will continue to use their deep pockets to crush AI regulations. Leading the Future, a super PAC backed by OpenAI president Greg Brockman and the venture capital firm Andreessen Horowitz, will try to elect candidates who endorse unfettered AI development to Congress and state legislatures. They’ll follow the crypto industry’s playbook for electing allies and writing the rules. To counter this, super PACs funded by Public First, an organization run by Carson and former Republican congressman Chris Stewart of Utah, will back candidates advocating for AI regulation. We might even see a handful of candidates running on anti-AI populist platforms.

In 2026, the slow, messy process of American democracy will grind on. And the rules written in state capitals could decide how the most disruptive technology of our generation develops far beyond America’s borders, for years to come.

Four ways to think about this year&#39;s reckoning.

Our AI writers make their big bets for the coming year—here are five hot trends to watch.

By studying large language models as if they were living things instead of computer programs, scientists are discovering some of their secrets for the first time.

In an exclusive interview, the AI pioneer shares his plans for his new Paris-based company, AMI Labs.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-60')">
            <div class="source">The Next Web</div>
            <div class="title">Noora Saksa steps in as new Slush CEO</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-60" style="display:none;">
            <h2>Noora Saksa steps in as new Slush CEO</h2>
            <p><strong>The Next Web | 2026-01-27</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/noora-saksa-steps-in-as-new-slush-ceo">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Slush, the Finnish nonprofit behind one of the most influential startup gatherings in Europe, has named Noora Saksa as its new Chief Executive Officer, a shift that indicates a strategic evolution for the organisation as it expands beyond its flagship event model.

Saksa assumes the top role after years as Slush’s Chief Operating & Financial Officer and Head of Partnerships, where she managed core operations, finances, and ecosystem programmes.

Her trajectory within the organisation reflects a deep operational understanding of Slush’s mission: to connect founders, investors, and builders in ways that help founders advance on their journeys.

In stepping into the CEO role, Saksa inherits an agenda that extends far beyond an annual conference in Helsinki.

Under her leadership, Slush aims to grow year-round engagement through digital experiences and local ecosystem programmes, and to deepen its reach in founder support globally.

TNW City Coworking space - Where your best work happens

A workspace designed for growth, collaboration, and endless networking opportunities in the heart of tech.

Board members see her operational experience and ecosystem insight as assets for Slush’s next chapter.

Slush remains organised largely by a core team of young professionals and volunteers, a structure that has supported its rapid growth since the early 2010s.

The event brings together thousands of founders and investors each year, and the organisation’s year-round platform aims to sustain connections long after the main event ends.

In her opening statement as CEO, Saksa said the focus will remain on building meaningful experiences that help founders tackle practical challenges, expand networks, and find capital. Her intimate knowledge of Slush’s operations positions her to balance growth ambitions with the organisation’s mission-driven ethos.

Noora Saksa has played a central role at Slush as Chief Operating & Financial Officer and Head of Partnerships, overseeing operations, finances, and startup-focused programmes. Before her tenure at Slush, she held leadership roles in entrepreneurial student societies and worked in startup support functions. Saksa studied Industrial Engineering and Management at Aalto University with an exchange at Eindhoven University of Technology. Her experience spans operational strategy, ecosystem building, and partnership development within Nordic innovation communities.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-61')">
            <div class="source">The Next Web</div>
            <div class="title">Rainbow Weather raises $5.5M to refine real-time weather forecasting</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-61" style="display:none;">
            <h2>Rainbow Weather raises $5.5M to refine real-time weather forecasting</h2>
            <p><strong>The Next Web | 2026-01-26</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/rainbow-weather-raises-5-5m-to-refine-real-time-weather-forecasting">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Warsaw, Poland 26 January 2026 – Rainbow Weather has raised $5.5 million in seed funding to push weather forecasting further into the short-term, high-precision territory it believes the industry still underserves.

The Warsaw-based climate tech startup focuses on hyperlocal, minute-by-minute forecasts, zeroing in on what happens in the next few hours rather than days out.

The round was backed by a syndicate of investors, including Yuri Gurski, founder of Flo Health, one of Europe’s best-known consumer tech unicorns.

Rainbow Weather’s core product is a mobile app that delivers four-hour precipitation forecasts calculated from the exact moment a user checks the weather.

Open the app at 3:51 am, and it forecasts conditions through 7:51am, refreshed every 10 minutes and mapped down to a one-square-kilometre grid. That level of temporal and spatial precision is what the company says sets it apart from mainstream weather apps.

The latest rumblings from the EU tech scene, a story from our wise ol&#39; founder Boris, and some questionable AI art. It&#39;s free, every week, in your inbox. Sign up now!

Most major providers, including AccuWeather, Apple Weather, and The Weather Company, still rely on approaches that either simplify cloud movement or depend on large-scale numerical models designed for longer forecasts. According to Rainbow Weather, both methods struggle when conditions change quickly.

“Many legacy forecasting providers rely on optical flow for short-term precipitation forecasting. That’s a fast but simplistic method that treats clouds as shapes in motion, without any understanding of atmospheric physics,” explained Alexander Matveenko, co-founder of Rainbow Weather. “A second category of services uses large-scale mathematical models that do incorporate physical principles, but they’re so cumbersome and slow that they can’t respond quickly to real-time weather changes.”

Rainbow Weather positions itself in between, using machine learning to fuse high-resolution data from radar, satellites, weather stations, and even smartphone barometers. By combining these sources, the company claims it can reduce the noise and bias inherent in individual datasets, then generate forecasts faster than traditional systems.

The app currently focuses on short-term precipitation, but it has expanded into tracking wildfires and hurricanes, a feature added after the Palisades fire in Los Angeles. That expansion reflects a broader ambition to become a real-time risk awareness tool, not just a rain predictor.

The new funding will be used to extend Rainbow Weather’s forecasting window from four hours to 24 hours, add more weather parameters beyond precipitation, and grow its B2B offering.

The commercial weather intelligence market is expected to grow steadily over the next decade, driven by industries that depend on precise, near-term forecasts, from logistics and agriculture to aviation and drone operations.

Rainbow Weather says it has surpassed one million installs and has launched APIs aimed at companies that “can’t afford to get weather wrong.” It has also partnered with an unnamed long-term forecasting firm, supplying near-term data to improve broader climate models.

The founding team brings a track record of exits in applied AI. CEO Yuriy Melnichek previously founded AIMatter, acquired by Google, as well as consumer apps later bought by Pinterest and Farfetch. Matveenko previously sold mapping startup MapData to Mapbox.

Alongside its commercial products, the team also runs weatherindex.ai, an open-source project that evaluates short-term precipitation forecasts from major providers in real time. The tool compares live forecasts against verified airport weather reports, using standard accuracy metrics. It’s an unusual move in an industry not known for transparent benchmarking.

For Rainbow Weather, that openness is part of the pitch. The company is betting that as climate volatility increases, users and businesses will care less about next week’s weather and more about what happens in the next hour, and whether the forecast can be trusted.

Rainbow Weather is a next-gen climate tech startup for ultra-accurate short-term forecasts founded in 2021 by Yuriy Melnichek, who previously built AIMatter (acquired by Google), a neural network-based AI platform, as well as the video creation and editing app Vochi (acquired by Pinterest), and fashion marketplace Wanna (acquired by Farfetch), and Alexander Matveenko, a founder of artificial intelligence mapping startup MapData that he sold to Mapbox in 2017.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-62')">
            <div class="source">The Next Web</div>
            <div class="title">Synthesia’s valuation jumps to $4B after $200M raise</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-62" style="display:none;">
            <h2>Synthesia’s valuation jumps to $4B after $200M raise</h2>
            <p><strong>The Next Web | 2026-01-26</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/synthesias-valuation-jumps-to-4b-after-200m-raise">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">London-based AI video startup Synthesia has raised $200 million in a Series E round, nearly doubling its valuation to around $4 billion and cementing its position as one of Europe’s most valuable AI companies.

The round was led by Google Ventures, with participation from existing investors, underscoring continued appetite for applied AI products that have already found a clear commercial use.

Synthesia builds generative AI tools that let companies create videos using AI-generated avatars instead of cameras, studios, or presenters. The technology has found a strong foothold in corporate training, internal communications, and product explainers, areas where speed, scale, and consistency often matter more than production gloss.

“Synthesia was founded on two core beliefs: first, that AI will bring the cost of content creation down to zero. And secondly, that AI video provides a better, more engaging way for organizations to communicate and learn,” said Victor Riparbelli, Synthesia’s co-founder and CEO.

Synthesia says a significant share of Fortune 100 companies now use its platform, a rare level of enterprise penetration for a European AI startup at this stage. Rather than chasing consumer virality, the company has built its business around predictable, high-value enterprise use cases, a strategy investors have increasingly rewarded over the past year.

The funding comes at a moment when enthusiasm around generative AI has shifted from experimentation to execution. Enterprises are no longer asking whether AI video works, but how reliably it can plug into existing workflows.

The latest rumblings from the EU tech scene, a story from our wise ol&#39; founder Boris, and some questionable AI art. It&#39;s free, every week, in your inbox. Sign up now!

Synthesia’s pitch is that AI-generated video should be as routine as slides or documents, created quickly, updated easily, and deployed globally without production bottlenecks.

At a $4 billion valuation, Synthesia joins a small group of European AI companies that have managed to scale beyond regional relevance.

Its rise also highlights a broader pattern: applied AI startups, focused on specific business functions rather than general-purpose models, are attracting some of the largest growth rounds in the market.

For the UK tech ecosystem, the deal is another signal that London remains a serious hub for commercial AI, even as regulatory debates continue around model safety, copyright, and synthetic media.

Synthesia has previously positioned itself as cautious about misuse, building safeguards around consent and disclosure for its avatars, a stance that may become more important as scrutiny of AI-generated content increases.

The challenge ahead is less about proving demand and more about maintaining trust and differentiation as competitors multiply.

But with deep enterprise adoption, a clear product focus, and backing from one of Silicon Valley’s most influential investors, Synthesia is entering its next phase with momentum firmly on its side.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-63')">
            <div class="source">The Next Web</div>
            <div class="title">TNW Weekly Briefing</div>
            <div class="meta">2026-01-25</div>
        </div>
        
        <div id="content-63" style="display:none;">
            <h2>TNW Weekly Briefing</h2>
            <p><strong>The Next Web | 2026-01-25</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/tnw-weekly-briefing-2">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">What: The European Commission unveiled EU Inc (“28th regime”), a single EU-wide legal company structure designed to let startups incorporate once and operate across all member states.
Who it affects: European startups & scale-ups, founders, VCs, international investors.
How: Reduces legal fragmentation, standardises corporate and investment structures, lowers friction for cross-border scaling.
Impact timing: Strategic impact now (capital & expectations), real operational impact from 2027–2028.

What: The EU proposed mandatory rules to remove and replace technology from suppliers deemed “high-risk” in telecoms and other critical networks.
Who it affects: Telecom operators, infrastructure providers, governments, Chinese tech vendors, cybersecurity supply chains.
How: Forces equipment replacement, raises capex, hardens security requirements across Europe.
Impact timing: Immediate policy impact, execution over the next few years.

What: European institutions publicly backed a strategy to reduce reliance on US technology across cloud, software, semiconductors and AI, often referred to as building a European “tech stack.”
Who it affects: US hyperscalers, European cloud & AI companies, policymakers, public procurement.
How: Shapes future regulation, funding priorities and government tech buying decisions.
Impact timing: Political and strategic impact now, regulatory and market impact medium-term.

This week wasn’t about hype:
EU Inc sets the future structure, high-risk tech phase-out enforces security now, and tech sovereignty defines Europe’s direction.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-64')">
            <div class="source">The Next Web</div>
            <div class="title">Mews raises €255M to accelerate AI and automation in hospitality</div>
            <div class="meta">2026-01-24</div>
        </div>
        
        <div id="content-64" style="display:none;">
            <h2>Mews raises €255M to accelerate AI and automation in hospitality</h2>
            <p><strong>The Next Web | 2026-01-24</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/mews-raises-e255m-to-accelerate-ai-and-automation-in-hospitality">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Amsterdam-based hospitality tech platform Mews has raised €255 million (about $300 million) in a Series D funding round as it pushes deeper into automation and AI-powered workflows for hotels around the world.

The round was led by EQT Growth with new participation from Atomico and HarbourVest Partners, alongside existing backers including Kinnevik, Battery Ventures and Tiger Global. The investment values the company at roughly $2.5 billion.

Founded in 2012 by Richard Valtr and Matt Welle, Mews builds a cloud-native “operating system” for hotels  software that ties together reservations, check-ins, housekeeping, payments and more in one platform.

Its technology is designed to replace legacy systems that many hotels still rely on, offering a more flexible, connected way to manage day-to-day operations.

The new funding will be used to expand the company’s AI and automation capabilities at the core of its product.

The latest rumblings from the EU tech scene, a story from our wise ol&#39; founder Boris, and some questionable AI art. It&#39;s free, every week, in your inbox. Sign up now!

That includes embedding agent-driven systems that can take on complex routine tasks, reduce manual work for staff and streamline how hotels handle everything from guest interactions to revenue management.

Mews says its platform already supports more than 15,000 properties in 85 countries, and in 2025 it processed nearly 42.3 million check-ins and handled nearly $20 billion in transaction volume.

The software also helped generate over $500 million in additional revenue for hoteliers through features like its Mews Spaces module.

In a statement, CEO Matt Welle said the new capital will help Mews build an operating system that handles operational complexity so hotel teams can focus on guest experience rather than juggling disparate tools.

“We are engineering an operating system that is changing how hoteliers interact with their guests,” CEO Matt Welle said, adding that the goal is to lighten the cognitive load on staff and make everyday operations smoother.

Industry observers say the round is one of the largest ever in hospitality software and reflects broader investor interest in infrastructure-level platforms that bring AI and fintech together for real-world business operations.

As hotels embrace digital transformation, technology that can automate workflows and personalise guest experiences  without adding complexity is increasingly in demand.

For Mews, the challenge now is execution: turning generous funding into tangible upgrades that deliver value for hoteliers of all sizes.

But with strong adoption, a global footprint and a growing suite of automation tools, the company is positioning itself as a central technology partner at a time when hotels are looking to modernise their operations and enhance guest satisfaction.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-65')">
            <div class="source">The Next Web</div>
            <div class="title">How Flippa Is Removing the Language Barrier from Global Deal-Making</div>
            <div class="meta">2026-01-23</div>
        </div>
        
        <div id="content-65" style="display:none;">
            <h2>How Flippa Is Removing the Language Barrier from Global Deal-Making</h2>
            <p><strong>The Next Web | 2026-01-23</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/how-flippa-is-removing-the-language-barrier-from-global-deal-making">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">For decades, access to high-quality deal flow and sophisticated M&A infrastructure has been largely designed for well-connected investors and industry giants. Small businesses and independent founders, particularly those operating outside English-speaking markets, may often find the barriers even higher. Language, geography, and limited access to networks could mean that opportunity stops at the border.

Amidst this trend, Flippa, a platform for buying and selling digital businesses, is rewriting the script and dismantling those barriers. Under the leadership of CEO Blake Hutchison, the company has connected buyers and sellers across continents, linguistic differences, and price points, closing deals from $100,000 up to $10 million. Now, with the launch of its AI-powered multi-language Deal Room, Flippa is addressing what it sees as one of the last major points of disadvantage in global business deals and M&A, calling it the “Language Tax.”

Founded in 2009, Flippa has grown into a global marketplace where entrepreneurs can buy and sell digital assets ranging from e-commerce stores and SaaS businesses to YouTube channels, online communities, and mobile applications. According to Hutchison, the platform supports users from 189 countries, attracting over 450,000 new buyers in the last two years alone. “Our internal data shows that cross-border transactions now account for approximately 85% of all deals completed on the platform,” Hutchison says. “That growth has been especially pronounced in Europe. As a highly fragmented market with high cross-border trade volume but multiple operating languages, I believe Europe often faces structural friction in cross-border dealmaking.”

He notes that European businesses are increasingly being acquired by international buyers, with US-based acquirers representing a significant share of demand. Yet, as deal volumes continue to decline, Hutchison believes that language barriers have historically slowed or derailed otherwise viable transactions.

The latest rumblings from the EU tech scene, a story from our wise ol&#39; founder Boris, and some questionable AI art. It&#39;s free, every week, in your inbox. Sign up now!

The company’s new multi-language Deal Room is designed to remove that friction entirely. Within the Deal Room, Hutchison notes that buyers and sellers can now negotiate and transact in their preferred languages. “For example, a French seller can communicate in French with an Italian or English-speaking buyer, who receives the message instantly translated into their own language,” he says, explaining how replies can be translated back in real time, while preserving the original message for verification and clarity.

Hutchison states, “Our goal is to make deal-making as efficient and approachable as possible. Whether you are a SaaS founder in Paris or an e-commerce operator in Berlin, you should be able to negotiate your exit in the language of your choice.”

Alongside the Deal Room translation tool, Flippa has also launched a fully localized French version of its platform, with Spanish scheduled to follow shortly. The expansion reflects the user demand and the reality that French and Spanish are not only widely spoken across Europe, but globally. Spanish is spoken by 550 million people globally, and is spoken widely across the US and Brazil. Similarly, French, being the 5th most widely spoken language in the world, has 321 million speakers, with 61.8% of those speakers living in parts of North Africa and Sub-Saharan Africa, significantly extending the global reach of European-founded businesses.

According to Hutchison, this shift comes as Europe’s M&A market continues to rise again, with an estimated USD412 billion in deal value, with mid-market and digital-first businesses representing one of the fastest-growing segments. Flippa’s role, according to Hutchison, has been to create infrastructure for businesses to source deals with greater reach than elite investment banks, but with a fraction of the cost.

“We often describe Flippa as the investment bank for the 99%,” Hutchison says. “The difference now is that geography and language no longer define who gets access. The demand for cross-border deals was already there. The technology simply needed to catch up.”

Flippa continues to integrate AI-driven discovery, valuation, and outreach tools through its proprietary LaurenAI engine. “The model is trained on more than 200,000 historical listings and transactions,” he explains. “The system then helps buyers identify opportunities, estimate enterprise value, and initiate conversations at scale.” It autonomously indexes the web to identify businesses across SaaS, e-commerce, apps, publishing, and next-generation media.

Human expertise remains embedded in the process, with certified brokers and M&A professionals supporting transactions once a match is made. As Hutchison puts it, “LaurenAI gives people the ability to access off-market deals and build pipelines the same way Wall Street players do, but without the barriers of capital or connections.”

He notes that entrepreneurs who may not feel confident negotiating complex deal terms in English can now access global liquidity without intermediaries or external advisors. At the same time, international buyers can gain visibility into high-quality European businesses that were previously difficult to source or engage.

As digital entrepreneurship continues to globalize, Flippa is positioning itself at the center of a more inclusive M&A ecosystem, one where language is no longer a tax on ambition and opportunities. Flippa’s multi-language Deal Room represents a structural shift in how global deal-making can be done. For founders and buyers alike, it signals a future where the next meaningful transaction can begin in any language, from anywhere in the world.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-66')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">Trump's Golden Dome missile shield marks one year with little progress - Reuters</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-66" style="display:none;">
            <h2>Trump's Golden Dome missile shield marks one year with little progress - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2026-01-27</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMizAFBVV95cUxNMTBlTU16S3M1Ty1vaVJMRnlwMGNnNVQxZFpsRnZVMWJWTDFHWHoxaXdpTGhORzZWb1dONHV6bGJYaVRlUzhwZEhxdzhreVdBLXM3RlNXN1R0cHFKMVhhcUVWbmZhZEtvME5mX1dtaVFtbGFLYTkwYWRnSFU3LU1VbExkSDZISklOMFZURkNGS3otX0JfaERKMEx1OGRnYTlJSTJoQ1lQaERwVzJvaXRfRy1VeG5ZU05maEh0YnoyVlFWaTNJbk5QQnp1T18?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-67')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">Exclusive: Hamas seeks role for its police in Gaza ahead of disarmament talks, sources say - Reuters</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-67" style="display:none;">
            <h2>Exclusive: Hamas seeks role for its police in Gaza ahead of disarmament talks, sources say - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2026-01-27</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMivwFBVV95cUxPQ243eWtNWDZnSjlWSTNTSmNEc0lCSlFmam5Oci1yVkNYRHBCb2l2eFdnd1lzd1ljemRCbElGbVBoeWR1b0gzU0I1VVJMa1gyM0RscXM3OXhMeGJEanBMaS1QN2otMnJvYXJTcGdFbVlrRlZFV21maXVJYWE2Y3pZT0czdDFHaEVEN05uQTl5aWdUcHJuc2U4dlh6UVQzSFl3Yl9QSXliM0VIb2tKRnViYzdrbzhNeEdsblE3SXFGdw?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-68')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">Three French tourists killed when boat capsizes off Oman coast - Reuters</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-68" style="display:none;">
            <h2>Three French tourists killed when boat capsizes off Oman coast - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2026-01-27</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiuwFBVV95cUxPZ3FLLUMtbi14c1A3Wld3aFpwcDRIRnBZZ2FhanU2dnhXNWNabllqVi1BTzJaNjYwTnBia1A4VlR5MFlmdmkyZ3pfZGt6RG93LUV3ZmhNVkJBUzZxOTVoOFJlUHRuZE1ZWFAya3g1S0M4WVpHdVJ6cUZDTmh3WGpWd09JdDV4VUNxcHAza0NSVGs5WS12RXV1SlhtLVNaRnd2TV9OM2dKcUUyenljcW1UeTA4SVQ3Y1J2a1BZ?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-69')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">India, EU reach landmark trade deal, tariffs to be slashed on most goods - Reuters</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-69" style="display:none;">
            <h2>India, EU reach landmark trade deal, tariffs to be slashed on most goods - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2026-01-27</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiwgFBVV95cUxObmhYVjFfWEFhd29vWFpvUF83X0gzeEVrZGZadFFnQ0dEU0dSbjhFa0s4cUc0T1d6RXVzMjFreGdXTC1ZY2Z2cjlPMTItclBWQjFna05OR3k1TTl2bE9TckxrTGVtbVBPbXVmZDZ1c3dvenU4T3pSU1lDX0JHV2hJclk0X3JOZnY0RVlYaVc2TWRYRVRoVDQydWdDNUpVNVJTYVJWLVg2OHlxcVJqb1p2Q1doeTF1LXh1eWxfdWpPUTJHdw?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-70')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">China's Anta Sports buys 29% Puma stake for $1.8 billion, rules out full takeover - Reuters</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-70" style="display:none;">
            <h2>China's Anta Sports buys 29% Puma stake for $1.8 billion, rules out full takeover - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2026-01-27</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMizgFBVV95cUxNWU5KVUVna3FSeWpiZU9BZERDRVQyM3VvZWtTOVdLRHBjQ0Q2N1lidTNZZ3hPV3dOQUtSOTY0Y3czblRHYUgxUUQyTjlrc2ZtekRuOXRUR3l0bmZOV2VOV1B4N1FQMG5hclpYWjRvMlA4VURXMzhvRFh5cVUtc3UwbjA5SjhVcXVIdHJoamc1TjN3MnJrLXpVa0dqOTBkV1Z4Y1hGbUluV2VjckVxVjFqOGYxaVFaX1JmZzVoZ1AzclVKVXVERkZ2VzdjczBQQQ?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-71')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">China to seek deeper cooperation with UK, Chinese ministries say - Reuters</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-71" style="display:none;">
            <h2>China to seek deeper cooperation with UK, Chinese ministries say - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2026-01-27</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMirAFBVV95cUxQZXJQcjZHcTQ4T292WUNoOUhBczJkVUIwNGZzZXhkdTlEZjdsQmx2REhwTVlnUnVoZXJ4cUE3N2ttMUI4SG1VMnVsbE5wUU5DVjkyTlhkZWZ4a3hkNGQtTkR2SFVMUXNfaEt4bmVYSXBNcTdjX1V1U29nYTBIU1piV3NyUURhZkhBcDB2UmNhRkNJa1lBUmFUMzBpOXpabXFVTWtsdTRaSWxqdEpX?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-72')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">Scientists Discover “Master Regulator” That Could Help Reverse Brain Aging at Its Source - The Debrief</div>
            <div class="meta">2026-01-20</div>
        </div>
        
        <div id="content-72" style="display:none;">
            <h2>Scientists Discover “Master Regulator” That Could Help Reverse Brain Aging at Its Source - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2026-01-20</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMirwFBVV95cUxOdWxhR3UtU1g1eFpMT1ozNjIySFBVeUpfX1ktZlN2Xy1lUGljSkpGSG10WEF0d19jOTNZMjhpcGVPQ0VuS3ZuTnV0YzFjSlRCaml3Q2ZKeHRqT09MREN3THZuM0dadXl2YnI5THhYREtFY1pjM0lfbmd2SXZuNElDaG54OWxNZXJwUHNJXzcyTHdiV2NNRnhHV2J6TmZibm9RNnczRFpsTWdkRWJtdlc0?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-73')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">James Webb Space Telescope Captures the Stunning Demise of a Star in the Helix Nebula - The Debrief</div>
            <div class="meta">2026-01-22</div>
        </div>
        
        <div id="content-73" style="display:none;">
            <h2>James Webb Space Telescope Captures the Stunning Demise of a Star in the Helix Nebula - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2026-01-22</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMirgFBVV95cUxPVXFOVjBSLVpmQ05fMFJoQVBxVDFhX3JpdWdnYXk4YzcxUENIMHIyTHkzV1dRVnNGOUkzc3QzelhJUDVYMUV0b1A1MjdLRkRnMVZYRGJSMVdHVnRVc1lnTkNuLVBrak03NmM1WG9RMTFkN3BLUGVxWHRqVTIwSmdjM2tobDd5YWFmQmNGUU8xbndVVzlWcDM2WDRld0tjemhjX2JBLUF6X0g5VHJPRVE?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-74')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">Strange Quantum Effects Persist in Surprisingly Large Particles, New Research Reveals - The Debrief</div>
            <div class="meta">2026-01-24</div>
        </div>
        
        <div id="content-74" style="display:none;">
            <h2>Strange Quantum Effects Persist in Surprisingly Large Particles, New Research Reveals - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2026-01-24</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMirAFBVV95cUxPX2tuWVFKZERlVHNabkJpLUZBclNhUkpKc0JCWVcwU0UwTTh5SlREdzZ2bFBQODdnZ1BiSGVDcktSMWkzMm8yOThqRzFUdFBHN2dfazdkMUtyaGRVbnRmSTA2WU9NdzhyeFRVT3RiNTJSNDBUVW1Fb1BGYVc5UGxpZElnMmFNUnpMQ2NiM09BOGZfWUJhS2ZzdVBkc3NCOXhDek80VHdzYjE3NjI0?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-75')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">Superconductivity Breakthrough Brings Practical Use Closer than Ever, as Team Unveils "Hidden Magnetic Order in the Pseudogap" - The Debrief</div>
            <div class="meta">2026-01-21</div>
        </div>
        
        <div id="content-75" style="display:none;">
            <h2>Superconductivity Breakthrough Brings Practical Use Closer than Ever, as Team Unveils "Hidden Magnetic Order in the Pseudogap" - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2026-01-21</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMi4AFBVV95cUxPTkV1UExSZ2dMS094c25BUTQ0cmJxT21paDI2UTBhX3c5RVdaMndBQ0MxY1NVTTVLOFhEWXNfeE0yR1NFNlk3LUdTdnVDbk9WWVdKeDA1NTRqSnlHU0Q2VEJxQUtlQ0hVckRzTVM4LXJpSlcyajRfaUFpbDNXRThvX1B4SmpuQ05VTnpWNmRTdFpSRksyR0lRd2xCNVVLZThTMndETDUxTWNjWGpvNGU5RlNtN2dNZ3NfU1p5SVVKaU9xaW1HYXdfazFoS3RjTmVUMHJhU3BTWmhVWnd1Yi1vVA?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-76')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">Archaeologists: Half a Million-Year-Old Elephant Bone Hammer Wasn’t Made by Modern Humans - The Debrief</div>
            <div class="meta">2026-01-22</div>
        </div>
        
        <div id="content-76" style="display:none;">
            <h2>Archaeologists: Half a Million-Year-Old Elephant Bone Hammer Wasn’t Made by Modern Humans - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2026-01-22</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMisAFBVV95cUxPWTFUMXVQQXVoZENJdlA1Q29xUXJhZ1NwbXR1OVBIZ0VNNXdaN0VMVFF1alVxcGl1UDFaT3A2U2JfaXpSY0d6dF9CLVNwYUtqa285eTVyUHlBaXFiM0RPT283eW9kckJ2VXIwemlBa09KN2NvOFFvYUc5b2s2LTdNYTc3SGY4Q2R6azFiRUR4OVRqRGNyd1BXN3RQaUZtNUpBamlTbG9YUm5vdUt6ME1WUA?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-77')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">50,000-Year-Old Artifacts Unearthed at Controversial Archaeological Site Could Rewrite the Early Prehistory of the Americas - The Debrief</div>
            <div class="meta">2026-01-21</div>
        </div>
        
        <div id="content-77" style="display:none;">
            <h2>50,000-Year-Old Artifacts Unearthed at Controversial Archaeological Site Could Rewrite the Early Prehistory of the Americas - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2026-01-21</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMi3wFBVV95cUxPQzR6eFVORUdoblVyV2VWOVlScHR4NXQtV1Z4dUZYdzdjUjRwUnhYdm11QVBaZXF5S3NKYUE0d2hlMzZqMmc4T2pzc3AzdmRBekNOZFhYYWdfNG1LZmdpOEZuOGxaUjUyVmRTNXg0VmV3amw1WTRvSGJ4aUtENWZFMWE5NmVFaHZGYjBheHRMT0RSc255OFdscEthMm1tUG4xdEhmeFZqd1hqRENkSi10VnBnQURvemIxMlVOVGZURlJ2dlJWb3ZLRFFPZjVJRkJPeUN1RXdNLVZFMDJuT2dZ?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-78')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">OpenAI Seeks Premium Prices in Early Ads Push - The Information</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-78" style="display:none;">
            <h2>OpenAI Seeks Premium Prices in Early Ads Push - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2026-01-26</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiigFBVV95cUxNdWtfbVYwRUFRS0czZHI0VkFhNTVUdEQxS1pwUVIza194NVdpYnNTTkplWnVNU05fbjZpaWZsakpoU1lZZFNjV0s1a1Fld3ZvclFmS3dxMlRuVmJlaU9Bd1hVd1JKUVpjN1I5RERYbkwzSmtaUHRHNUw1ODJGRXpvRUwzWHByOVd3aUE?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-79')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">OpenAI Plans to Take a Cut of Customers’ AI-Aided Discoveries - The Information</div>
            <div class="meta">2026-01-22</div>
        </div>
        
        <div id="content-79" style="display:none;">
            <h2>OpenAI Plans to Take a Cut of Customers’ AI-Aided Discoveries - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2026-01-22</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiqgFBVV95cUxPcHdxSmlWVVZxSnAtU05FazNqajZjeThEV0RvVG9SU1BGU2VmODF5QmppXzdOYnRLSnl6NmVFZk5IZ19Md3hlZjdxVGlvY3Frc2lFZGtDWkhrM2g4VjFyRmlHRnRNOTRXaFIteEVEWVR1Wk1rWFZIR0dxVXpoOTJaa21uVkpKY2NZc0hsSjhSU2x2bzEtRE80cTRGVFRaa1EzTnBwR1gwdFBwQQ?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-80')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">Exclusive: Google Acquires 3D Image Generator Startup - The Information</div>
            <div class="meta">2026-01-24</div>
        </div>
        
        <div id="content-80" style="display:none;">
            <h2>Exclusive: Google Acquires 3D Image Generator Startup - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2026-01-24</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMimAFBVV95cUxQNEhiV09GZEdiLWJwODk5bXJfYm50RnhfWVpDQXFLaEUtbGVVV2VwajVod2tFa1RqQ2xGOWNDX0hvU3Y2d2YxU3l1WktQcDFfQTd1TC1wNnN3VXRYMlMyQTZZVm5vc2dzSjlWTVlLd1pCaXotT19mVHFJQTdmeE0tLU81NE91YjVLQm1uOEN1cVA1SWM1QzdLUA?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-81')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">Anthropic Lowers Gross Margin Projection as Revenue Skyrockets - The Information</div>
            <div class="meta">2026-01-22</div>
        </div>
        
        <div id="content-81" style="display:none;">
            <h2>Anthropic Lowers Gross Margin Projection as Revenue Skyrockets - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2026-01-22</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiogFBVV95cUxOOFNsY05rYkNDRWFDVzQzVk1CdF9yaGpLbnpmelNBcW9yQkQtNVhXUVlqNTRpZElnOFl1Q3lya1ozMlV6bzh2M21MWlNBdHh5TjlOaUppMWNhWWR5TmxPYmlkaEZSMURzbGNJS0dlcXdmSEViWEFST3dnZGpFR2MxNnRBSUFJZ091T2hwXzFQdTFzbnRhUU1IYkx1TE45emlPRHc?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-82')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">ChatGPT Checkouts to Take 4% Cut of Shopify Merchant Sales - The Information</div>
            <div class="meta">2026-01-21</div>
        </div>
        
        <div id="content-82" style="display:none;">
            <h2>ChatGPT Checkouts to Take 4% Cut of Shopify Merchant Sales - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2026-01-21</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMilwFBVV95cUxNZC1FaTVOUWswUHFxT05RVHdZZnNnOUIxbXZ4RnZMNmtoS0wzQjFSYnhWSjFOWlVORUJPNlRfdVdZd2doZ3pSXzRJSXg0U3BrZE1vQXNDdUUzbU52UDB4RVp5TnlLZUcwYmpZWnhQRFk0RG1WaUdxTXB1cXJ0Qlo1OWc5YU9lQ1BTOEJqSnNXc2JBMjI3aVFJ?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-83')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">Behind the Sky-High Valuation of China’s AI IPOs - The Information</div>
            <div class="meta">2026-01-25</div>
        </div>
        
        <div id="content-83" style="display:none;">
            <h2>Behind the Sky-High Valuation of China’s AI IPOs - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2026-01-25</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMihwFBVV95cUxNVDBCYlp5aW11SUVISHRtb1M4S0xqQ1BQLWlESkV3TGJxXzM1c0tUYnBOa2J6NkE1am14SHBYU0RBM1RDT2pLb3NndWNkd04tZWxId2ZzWlRjdWt0ODluRkphRUtTR2VxZExGQ0JEQmprM3RZbWhlUm5jWS1EUlF6Njg3cWE4QUE?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        </div>

        <div id="reader-modal">
            <div id="close-btn" class="control-btn" onclick="closeModal()">X</div>
            
            <div id="scroll-controls">
                <button class="scroll-btn" onclick="scrollPage(-1)">&#9650;</button> <button class="scroll-btn" onclick="scrollPage(1)">&#9660;</button>  </div>

            <div id="modal-inner"></div>
        </div>

        <script>
            // 1. RANDOMIZE ORDER
            const list = document.getElementById('feed-list');
            const cards = Array.from(document.querySelectorAll('.card'));
            cards.sort(() => Math.random() - 0.5);
            cards.forEach(card => list.appendChild(card));

            // 2. DARK MODE
            const btn = document.getElementById('theme-toggle');
            btn.addEventListener('click', () => document.body.classList.toggle('dark-mode'));

            // 3. MODAL & SCROLL LOGIC
            const modal = document.getElementById('reader-modal');
            const modalInner = document.getElementById('modal-inner');

            function openModal(contentId) {
                const content = document.getElementById(contentId).innerHTML;
                modalInner.innerHTML = content;
                modal.style.display = 'block';
                document.body.style.overflow = 'hidden'; 
            }

            function closeModal() {
                modal.style.display = 'none';
                document.body.style.overflow = 'auto';
            }

            function scrollPage(direction) {
                // Scroll by 80% of the screen height to keep context
                const scrollAmount = window.innerHeight * 0.8;
                modal.scrollBy(0, direction * scrollAmount);
            }
        </script>
    </body>
    </html>
    