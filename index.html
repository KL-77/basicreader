
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>KL-77's Feed</title>
        <style>
            :root {
                --bg: #ffffff;
                --text: #000000;
                --border: #000000;
                --modal-bg: #ffffff;
                --dim: #666666;
            }
            
            body.dark-mode {
                --bg: #000000;
                --text: #ffffff;
                --border: #ffffff;
                --modal-bg: #000000;
                --dim: #aaaaaa;
            }

            body { 
                font-family: Georgia, serif; 
                background-color: var(--bg);
                color: var(--text);
                margin: 0;
                padding: 10px;
                font-size: 22px;
                line-height: 1.5;
            }

            header {
                display: flex;
                justify-content: space-between;
                align-items: center;
                border-bottom: 3px solid var(--text);
                padding-bottom: 15px;
                margin-bottom: 25px;
            }
            
            h1 { margin: 0; font-size: 1.2em; }

            button#theme-toggle {
                background: transparent;
                color: var(--text);
                border: 2px solid var(--text);
                padding: 10px;
                font-size: 18px;
                font-weight: bold;
                border-radius: 4px;
                cursor: pointer;
            }

            .card {
                border: 2px solid var(--text);
                margin-bottom: 25px;
                padding: 15px;
                cursor: pointer;
            }
            
            .source { font-size: 0.7em; font-weight: bold; text-transform: uppercase; color: var(--dim); }
            .title { font-size: 1.1em; font-weight: bold; margin: 8px 0; display:block; }
            .meta { font-size: 0.7em; color: var(--dim); }

            /* MODAL STYLING */
            #reader-modal {
                display: none;
                position: fixed;
                top: 0; left: 0;
                width: 100%; height: 100%;
                background-color: var(--modal-bg);
                z-index: 1000;
                overflow-y: scroll; /* Allow scrolling */
                scroll-behavior: auto; /* Instant scrolling for e-ink */
            }

            #modal-inner {
                padding: 25px;
                max-width: 800px;
                margin: 0 auto;
                padding-top: 80px; 
                padding-bottom: 150px; /* Huge padding so text clears the buttons */
            }

            /* Controls (Close + Scroll) */
            .control-btn {
                position: fixed;
                background: var(--bg);
                color: var(--text);
                border: 3px solid var(--text);
                border-radius: 8px;
                font-weight: bold;
                cursor: pointer;
                z-index: 1001;
                display: flex;
                align-items: center;
                justify-content: center;
            }

            #close-btn {
                top: 15px; right: 15px;
                width: 60px; height: 60px;
                font-size: 30px;
                line-height: 55px;
            }

            /* Scroll Buttons */
            #scroll-controls {
                position: fixed;
                bottom: 20px;
                right: 20px;
                display: flex;
                flex-direction: column;
                gap: 15px;
                z-index: 1002;
            }

            .scroll-btn {
                width: 60px;
                height: 60px;
                font-size: 24px;
                background: var(--bg);
                color: var(--text);
                border: 3px solid var(--text);
                border-radius: 8px;
                cursor: pointer;
            }

            #article-text { white-space: pre-wrap; font-size: 1.1em; }
            
            a.original-link {
                display: inline-block;
                margin-bottom: 30px; /* Space before text starts */
                padding: 10px;
                border: 1px solid var(--text);
                color: var(--text);
                text-decoration: none;
                font-weight: bold;
                font-size: 0.8em;
            }
        </style>
    </head>
    <body>

        <header>
            <h1>KL-77's Feed</h1>
            <button id="theme-toggle">Light/Dark</button>
        </header>

        <div id="feed-list">
    
        <div class="card" onclick="openModal('content-0')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">How Europe’s new carbon tax on imported goods will change global trade</div>
            <div class="meta">2025-12-20</div>
        </div>
        
        <div id="content-0" style="display:none;">
            <h2>How Europe’s new carbon tax on imported goods will change global trade</h2>
            <p><strong>Ars Technica - All content | 2025-12-20</strong></p>
            <a class="original-link" href="https://arstechnica.com/tech-policy/2025/12/how-europes-new-carbon-tax-on-imported-goods-will-change-global-trade/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">For people living in the European Union, the price of their next car, home renovation, and even local produce may soon reflect a climate policy that many have never even heard of. This new regulation, which comes fully into force on New Year’s Day, does not just target heavy industry—it affects everyday goods which now face an added carbon cost when they enter Europe.

The carbon border adjustment mechanism (CBAM) puts a carbon price on many imported goods—meaning that EU-based importers will pay for the greenhouse gases emitted during the production of certain carbon-intensive materials.

If goods come from countries with weaker climate rules, then the charge will be higher. To sell to the EU, producers will effectively need to show their goods aren’t too carbon-intensive.

The goal is to prevent companies from relocating their production to places with looser regulations, ensuring fair competition between EU and non-EU companies, while incentivising global decarbonisation.

After a trial phase, full payment obligations begin on January 1 2026, when importers will need to buy CBAM certificates to cover the embedded emissions in goods such as iron and steel, aluminium, cement, fertilisers, hydrogen and (eventually) electricity.

Although it is an EU climate policy, CBAM looks set to be a game-changer for global trade. Countries that rely on EU exports may need to make costly investments in cleaner technologies and better emissions tracking, or risk losing market share. The UK government plans to introduce its own version of CBAM in 2027—although how this links to the EU’s is yet to be decided.

A positive shift is already underway: more and more companies are now measuring and reporting their emissions accurately, responding to the growing demand for reliable carbon data. At the same time, an increasing number of countries are introducing their own carbon pricing systems to stay aligned with the EU and protect the competitiveness of their exports.

Morocco is a prominent example: its 2025 finance law gradually introduces a carbon tax from January 2026. As Moroccan firms will already pay a carbon price domestically, their exports are likely to avoid additional CBAM charges at the EU border, helping them remain competitive.

In many countries, CBAM is also accelerating interest in renewable energy and greener industrial processes. Some see it not as a threat, but an opportunity to attract investment and position themselves as low-carbon manufacturing hubs.

However, this mechanism is still controversial. For businesses, CBAM is complex and administratively heavy. Firms need robust systems to measure embedded emissions, collect data from suppliers, and produce environmental product declarations. Many will also need new renewable energy contracts to cut their carbon footprint.

Around the world, CBAM has faced strong criticism. India and China describe it as “green protectionism,” arguing that it puts unfair pressure on developing economies. At the same time, the EU has not yet created dedicated funding to help exporters in lower-income countries adapt. Without this support, the mechanism may not achieve the desired results.

Although CBAM is mainly aimed at industry, its ripple effects will reach consumers in the EU. Importers are unlikely to absorb the full additional cost, meaning prices are likely to rise—particularly for goods that rely heavily on steel, aluminium, or cement. This could mean Europe sees higher costs for cars, home appliances, electronics, building materials, and, indirectly, food production (through fertilizers).

At the same time, CBAM may bring more transparency. Because importers must report the emissions embedded in their goods, consumers may eventually have clearer information about the climate impact of what they buy.

The mechanism will also generate EU revenues from certificate sales. These are expected to support vulnerable households in many European countries, as well as funding clean technologies and improving energy efficiency. How the funds are used will be crucial to public acceptance of Europe’s new carbon tax.

Even before full implementation, CBAM is already reshaping supply chains and influencing government policies far beyond Europe’s borders. It may trigger trade disputes, push exporters to adopt carbon pricing, and highlight the need for more climate finance to support developing countries undergoing green industrial transitions.

For many European consumers, it’s likely to mean gradual price increases—and potentially, more climate-conscious purchasing decisions. Behind the scenes, it marks a significant shift in how global trade accounts for carbon—and how climate policy reaches into people’s everyday lives.

Simona Sagone, PhD Candidate, Green Finance, Lund University; University of Palermo. This article is republished from The Conversation under a Creative Commons license. Read the original article.</div>
        </div>
        
        <div class="card" onclick="openModal('content-1')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">Google lobs lawsuit at search result scraping firm SerpApi</div>
            <div class="meta">2025-12-19</div>
        </div>
        
        <div id="content-1" style="display:none;">
            <h2>Google lobs lawsuit at search result scraping firm SerpApi</h2>
            <p><strong>Ars Technica - All content | 2025-12-19</strong></p>
            <a class="original-link" href="https://arstechnica.com/google/2025/12/google-lobs-lawsuit-at-search-result-scraping-firm-serpapi/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Google has filed a lawsuit to protect its search results, targeting a firm called SerpApi that has turned Google’s 10 blue links into a business. According to Google, SerpApi ignores established law and Google’s terms to scrape and resell its search engine results pages (SERPs). This is not the first action against SerpApi, but Google’s decision to go after a scraper could signal a new, more aggressive stance on protecting its search data.

SerpApi and similar firms do fulfill a need, but they sit in a legal gray area. Google does not provide an API for its search results, which are based on the world’s largest and most comprehensive web index. That makes Google’s SERPs especially valuable in the age of AI. A chatbot can’t summarize web links if it can’t find them, which has led companies like Perplexity to pay for SerpApi’s second-hand Google data. That prompted Reddit to file a lawsuit against SerpApi and Perplexity for grabbing its data from Google results.

Google is echoing many of the things Reddit said when it publicized its lawsuit earlier this year. The search giant claims it’s not just doing this to protect itself—it’s also about protecting the websites it indexes. In Google’s blog post on the legal action, it says SerpApi “violates the choices of websites and rightsholders about who should have access to their content.”

It’s worth noting that Google has a partnership with Reddit that pipes data directly into Gemini. As a result, you’ll often see Reddit pages cited in the chatbot’s outputs. As Google points out, it abides by “industry-standard crawling protocols” to collect the data that appears on its SERPs, but those sites didn’t agree to let SerpApi scrape their data from Google. So while you could reasonably argue that Google’s lawsuit helps protect the rights of web publishers, it also explicitly protects Google’s business interests.

The kind of data scraping that SerpApi uses is not new—Google has simply put up with it until now. However, the company claims that SerpApi’s deceptive behavior, like spoofing user agents and hammering sites with armies of bots, has increased significantly over the past year. That may have something to do with the ever-growing hunger for search data in the AI era.

Google is coming out of its antitrust cases relatively unscathed so far, which affects the availability of its data. It has avoided the harshest remedies, like the government’s demand that Google offer search data to competitors. That might have turned businesses like SerpApi legit, but with that no longer an option, Google may feel emboldened to unleash the lawyers.

While Google paints this as a benevolent action, it stands to benefit by stopping SERP scrapers. However, this may make some of Google’s competitors happy, too. Since the search giant doesn’t offer an official API for search (and the courts declined to force the issue), SERP scraping provides a way for companies to get Google’s search data on the down-low. This reduces demand for the handful of other web indexes that do have APIs, including Brave and Bing. Without illicit search APIs, chatbots may have to lean on official data sources.</div>
        </div>
        
        <div class="card" onclick="openModal('content-2')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">The evolution of expendability: Why some ants traded armor for numbers</div>
            <div class="meta">2025-12-19</div>
        </div>
        
        <div id="content-2" style="display:none;">
            <h2>The evolution of expendability: Why some ants traded armor for numbers</h2>
            <p><strong>Ars Technica - All content | 2025-12-19</strong></p>
            <a class="original-link" href="https://arstechnica.com/science/2025/12/the-evolution-of-expendability-why-some-ants-traded-armor-for-numbers/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The trade-off between quality and quantity is a fundamental economic dilemma. Now, a team of British, American, and Japanese researchers describes how it applies to biology, as well. They have discovered that this dilemma most likely shaped the evolutionary trajectory of ants, one of Earth’s most successful groups of organisms.

Their study reveals that, as ant societies grew in complexity and numbers, they didn’t just make their workers smaller—they also made them cheaper.

In the insect world, the exoskeleton known as the cuticle serves as a protective barrier against predators, pathogens, and desiccation, while providing the structural framework for muscle attachment. But this protection comes at a price. Building a robust cuticle requires significant amounts of nitrogen and rare minerals like zinc and manganese. While skimping on armor for an individual insect may be a death sentence, the evolution of ants apparently found a way around it.

“There’s this question in biology of what happens to individuals as societies they are in get more complex?” said Evan Economo, an entomologist at the University of Maryland and co-author of the study. “For example, the individuals may themselves become simpler because tasks that a solitary organism would need to complete can be handled by a collective.”

Economo’s team hypothesized that the metabolic balance behind investing in cuticles in social insects like ants could favor the collective over the individual. The idea was that a colony of 10,000 workers could lose a few individuals to a predator without much consequence, so investing heavily in each worker’s defenses would seem like a waste of precious nutrients. To test this hypothesis, they examined whether ant lineages that maintain massive, specialized workforces reduce the investment in their individual workers’ exoskeletons.

To test this idea, the researchers needed to pull off a comparative study on the anatomy of ants at an unprecedented scale. “We worked with scans of ant specimens and species from all over the world to capture the global diversity of ants,” Economo says. The team used a massive database called Antscan, which contains three-dimensional X-ray microtomography imaging of ants from around the globe.

Microtomography works similarly to medical CT scans, but at a vastly higher resolution. Still, on its own, the technique could only generate lots of precise data—it still had to be interpreted. Parsing through 3D imagery of over 880 specimens, including workers, queens, and males belonging to over 500 different species, was another challenge. “The 3D scanning itself is a very advanced technology,” says Arthur Matte, a researcher at the University of Cambridge and lead author of the study. “But once you have the ants in three dimensions, it’s still very hard to segment manually every tissue you’re interested in.”

To solve this, Matte developed a computer vision algorithm for “unsupervised segmentation.” Because the cuticle is always the outermost tissue of an arthropod, the algorithm could automatically identify and measure the volume of the exoskeleton across all ants in the dataset.

The first thing scientists noticed when the results poured in was that cuticle investment varied wildly, ranging from 6 percent to 35 percent of an ant’s total body volume. So, the next thing they focused on was figuring out the reasons behind these variations.

The team started checking how factors like diet, temperature, humidity, and foraging style correlated with the size of the cuticle. To get a handle on this, segmented 3D scans were fed into evolutionary models. “One of the most insightful things we did was to individually remove such variables from the models to estimate their contributions to the final cuticle investment,” Matte explains. This way, scientists learned that temperature was responsible for just 12 percent of variation in cuticle size and diet—especially its nitrogen content—explained another 37 percent. But the factor that had the strongest impact on the model was the colony size.

Ants that invested less in their cuticle tended to have significantly larger colony sizes. More surprisingly, this reduction in cuticle investment and the resulting increase in colony size appeared to be associated with higher diversification rates. In biological terms, squishier ants could evolve to occupy new niches much faster than their heavily armored cousins. “Requiring less nitrogen could make these ants more versatile and able to conquer new environments,” Matte suggests. This efficiency may have allowed ants to transition from a diet of high-protein prey to more abundant but less nutritious liquid sugar sources, like honeydew or floral nectar.

“Ants reduce per-worker investment in one of the most nutritionally expensive tissues for the good of the collective,” Matte explains. “They’re shifting from self-investment toward a distributed workforce.”

The researchers think the pattern they observed in ants reflects a more universal trend in the evolution of societal complexity. The transition from solitary life to complex societies echoes the transition from single-celled organisms to multicellular ones.

In a single-celled organism, a cell must be a “jack-of-all-trades,” performing every function necessary for survival. In a multicellular animal, however, individual cells often become simpler and more specialized, relying on the collective for protection and resources.

“It’s a pattern that echoes the evolution of multicellularity, where cooperative units can be individually simpler than a solitary cell, yet collectively capable of far greater complexity,” says Matte. Still, the question of whether underinvesting in individuals to boost the collective makes sense for creatures other than ants remains open, and it most likely isn’t as much about nutritional economics as it is about sex.

The study focused on ants that already have a reproductive division of labor, one where workers do not reproduce. This social structure is likely the key prerequisite for the cheap worker strategy. For the team, this is the reason we haven’t, at least so far, found similar evolutionary patterns in more complex social organisms like wolves, which live in packs—or humans with their amazingly complex societies. Wolves and people are both social, but maintain a high degree of individual self-interest regarding reproduction. Ant workers could be made expendable because they don’t pass their own genes—they are essentially extensions of the queen’s reproductive strategy.

Before looking for signs of ant-like approaches to quality versus quantity dilemmas in other species, the team wants to take an even closer look at ants. Economo, Matte, and their colleagues seek to expand their analysis to other ant tissues, such as the nervous system and muscles, to see if the cheapening of individuals extends beyond the exoskeleton. They are also looking at ant genomes to see what genetic innovations allowed for the shift from quality to quantity.  “We still need a lot of work to understand ants’ evolution,” Matte says.

Science Advances. 2025. DOI: 10.1126/sciadv.adx8068</div>
        </div>
        
        <div class="card" onclick="openModal('content-3')">
            <div class="source">Futurism</div>
            <div class="title">Astronauts Suit Up for Their Journey to the Moon</div>
            <div class="meta">2025-12-22</div>
        </div>
        
        <div id="content-3" style="display:none;">
            <h2>Astronauts Suit Up for Their Journey to the Moon</h2>
            <p><strong>Futurism | 2025-12-22</strong></p>
            <a class="original-link" href="https://futurism.com/space/nasa-astronauts-moon-dress-rehearsal">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">If all goes according to plan, four astronauts are set to become the first humans to travel past the confines of our planet’s gravity well to the Moon in over half a century.

NASA is hoping to launch its Artemis 2 mission a mere two months from now — two months earlier than originally planned — by launching the four individuals on board an Orion spacecraft mounted to its enormous Space Launch System (SLS) rocket.

The goal isn’t to touch down on the lunar surface just yet, a goal NASA has reserved for its follow-up Artemis 3 mission, which is tentatively scheduled for 2027.

But it’s nonetheless a daring feat. The Artemis 2 crew will be flying around the Moon and back in an enormous arc, likely reaching the farthest point from Earth that any human has traveled before, including NASA’s Apollo missions.

And though drama has plagued the Artemis program, this next mission is starting to really come into focus.

Over the weekend, for instance, NASA conducted a dress rehearsal for its scheduled February launch date. An image shows Canadian astronaut Jeremy Hansen and NASA astronauts Victor Glover, Reid Wiseman, and Christina Koch dressed up in their bright orange Orion Crew Survival System suits, spacesuits that have been in the works for many years now.

According to the space agency, the countdown demonstration test simulated what will go down on the launch day itself, including donning the suits and climbing in and out of the spacecraft.

However, the SLS rocket isn’t on the launch pad yet, which forced the crew to board inside NASA’s Kennedy Space Center Vehicle Assembly Building.

It remains to be seen when the SLS will roll out to the pad at Launch Complex 39B, which played a key role during the Apollo program. But the Orion was already stacked on the SLS in October inside the building, allowing the astronauts to conduct the rehearsal.

Engineers are now “conducting final preparations on the spacecraft, rocket, and ground systems,” per the agency.

As Spaceflight Now reported earlier this month, the dress rehearsal was meant to take place on November 19, but issues with Orion’s hatch forced the agency to delay the test.

“This demonstration was paused when a blemish was found on the crew module thermal barrier, preventing hatch closure until it could be addressed,” a NASA spokesperson told the publication at the time.

However, the agency added that “NASA remains on track to launch Artemis 2 no later than April 2026 with opportunities to potentially launch as soon as February.”

It’s an exciting moment as we count down the weeks and days to official launch day. The dress rehearsal served as the “final verification of the timeline for the crew and supporting teams on the ground,” according to NASA, and will be followed by preparations for any emergency that might arise at the launch pad.

It’s an enormous and highly complex task, but with an enormous potential payoff. The last time humans were anywhere near the Moon was during NASA’s Apollo 17 mission, which launched a hair over 53 years ago.

More on Artemis 2: NASA Not Paying Moon Astronauts as They Prepare to Risk Their Lives</div>
        </div>
        
        <div class="card" onclick="openModal('content-4')">
            <div class="source">Futurism</div>
            <div class="title">Murder of MIT Fusion Scientist Getting More and More Bizarre</div>
            <div class="meta">2025-12-22</div>
        </div>
        
        <div id="content-4" style="display:none;">
            <h2>Murder of MIT Fusion Scientist Getting More and More Bizarre</h2>
            <p><strong>Futurism | 2025-12-22</strong></p>
            <a class="original-link" href="https://futurism.com/future-society/murder-mit-fusion-scientist-bizarre">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Last week, lauded theoretical physicist and director of the MIT Plasma Science and Fusion Center Nuno Loureiro was murdered in his home in Brookline, Massachusetts.

Since then, investigators have made several breakthroughs in the unusual case, linking the prime suspect to a separate deadly mass shooting at Brown University earlier in December.

The suspected shooter, Claudio Neves Valente, was found dead in a storage unit in New Hampshire on Thursday following a six-day manhunt. But as bizarre twists add up in the case, investigatorsand the surviving loved ones of his victims are left with more questions than answers.

As the Wall Street Journal reported over the weekend, Neves Valente, a physics graduate from Portugal, had a reputation for being difficult in class, despite being remembered fondly by others.

Perhaps most bafflingly, Neves Valente attended the same school — Lisbon’s Instituto Superior Técnico — as his future victim, Loureiro, where they were both students between 1995 and 2000, CNN confirmed. Neves Valente eventually pursued his graduate studies at Brown, linking him to the second institution where he’s suspected of committing a deadly shooting.

Former Brown physics professor Scott Watson, who spent a lot of time with Neves Valente at Brown, said he became “sometimes angry” about life at Brown in esoteric ways — complaining about the quality of the fish he was served, for instance.

“He would say the classes were too easy — honestly, for him they were. He already knew most of the material and was genuinely impressive,” Watson told the Associated Press.

Neves Valente left Brown in early 2001 and returned to Portugal to work for a telecom.

Classmates have suggested he may have become jealous of Loureiro’s illustrious career.

Roughly an hour before Neves Valente opened fire on students in a Brown lecture hall, a witness noticed he was wearing a mask and flimsy clothing, leading to an altercation, per the WSJ.

“Why are you harassing me?” he told the witness angrily after being followed and confronted.

All told, Neves Valenete killed three individuals and injured nine.

It’s a tragic story that still leaves plenty of questions unanswered. Why did Neves Valente single out his former classmate? Was there more to his desire to inflict harm on others?

“Claudio was obviously one of the best, but in class he had a great need to stand out and show that he was better than the rest,” former classmate Felipe Moura wrote in a Facebook post, as quoted by CNN.

“I never expected he would be capable of such a thing,” he added.

More on the murder: MIT Fusion Physicist Murdered in His Home</div>
        </div>
        
        <div class="card" onclick="openModal('content-5')">
            <div class="source">Futurism</div>
            <div class="title">Photos Are Being Deleted From the Epstein Files</div>
            <div class="meta">2025-12-22</div>
        </div>
        
        <div id="content-5" style="display:none;">
            <h2>Photos Are Being Deleted From the Epstein Files</h2>
            <p><strong>Futurism | 2025-12-22</strong></p>
            <a class="original-link" href="https://futurism.com/future-society/photos-deleted-epstein-files">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Even before the Department of Justice’s release of a major collection of files pertaining to late billionaire sex criminal Jeffrey Epstein, lawmakers were concerned they would be heavily censored.

On Friday, the department launched an entire webpage that included hundreds of thousands of long-awaited records from its investigation into the deceased financier.

As expected, many of the documents have been heavily redacted, giving little insight into Epstein’s horrifying operation or the many big names — including numerous former presidents and celebrities, as well as a laundry list over other wealthy and powerful figures — who were connected to him.

And adding to the sense that the government doesn’t have the interests of transparency in mind, at least 16 photos have mysteriously disappeared from the archive after its initial release, as the Associated Press reports, including an image that showed president Donald Trump — a revelation that will likely throw gasoline on an already brightly burning political fiasco.

While it remains unclear why the files were being deleted, the news has already sparked major outcry, with some accusing the Trump administration’s Justice Department of trying to protect Trump, who was once close friends with Epstein.

“What else is being covered up?” the official account of the Democrats’ Oversight Committee tweeted in response to the latest news. “We need transparency for the American public.”

The image, appended to the tweet, shows framed photographs on what appears to be a desk. One photo in the bottom left, inside an open drawer, appears to show Trump’s face. (Trump has been photographed alongside Epstein on several occasions.)

By Sunday afternoon, the image was added to the files once again. Deputy attorney general Todd Blanche claimed that the image was taken down over concerns that it contained the images of victims, telling NBC News “absolutely, positively not,” when asked if any material was redacted due to political sensitivities.

“After the review, it was determined there is no evidence that any Epstein victims are depicted in the photograph, and it has been reposted without any alteration or redaction,” the Justice Department said in a Sunday afternoon statement.

The Justice Department has yet to offer an explanation why the other missing images were removed. A spokesman did not respond to the New York Times‘ request for comment.

For now, Democratic lawmakers are bound to continue putting on the pressure.

“It’s all about covering up things that, for whatever reason, Donald Trump doesn’t want to go public, either about himself (or) other members of his family, friends,” Congressman Jamie Raskin (D-MA) told CNN.

“They’re flouting the spirit and the letter of the law,” Congressman Thomas Massie (R-WV) told CBS News. “It’s very troubling the posture that they’ve taken. And I won’t be satisfied until the survivors are satisfied.”

Despite Trump’s name coming up in a number of Epstein’s emails that were released by the House Oversight Committee last month, a simple search for “Trump” flagged “no results” when the Justice Department’s new website was first launched.

The department has since promised on X that “photos and other materials will continue being reviewed and redacted consistent with the law in an abundance of caution as we receive additional information.”

Searching for the president’s name now brings up 625 results as of late Sunday.

Trump, who has long openly raged against ongoing investigations into his relationship with Epstein, previously calling it a “witch hunt,” has been strikingly quiet on the subject since Friday’s release and has yet to comment on the matter.

The president is known to have been close with Epstein as recently as the early 2000s, though he’s said they later had a falling out.

Trump has also said that Epstein “likes beautiful women as much as I do, and many of them are on the younger side,” in an extremely eyebrow-raising 2002 quote. And in 2011, after his initial conviction for sex crimes, Epstein cryptically referred to the future president as the “dog that didn’t bark” in an email message that was later released.

More on the Epstein files: The Epstein Files Release Website Is Completely Busted</div>
        </div>
        
        <div class="card" onclick="openModal('content-6')">
            <div class="source">TechCrunch</div>
            <div class="title">A comprehensive list of 2025 tech layoffs</div>
            <div class="meta">2025-12-22</div>
        </div>
        
        <div id="content-6" style="display:none;">
            <h2>A comprehensive list of 2025 tech layoffs</h2>
            <p><strong>TechCrunch | 2025-12-22</strong></p>
            <a class="original-link" href="https://techcrunch.com/2025/12/22/tech-layoffs-2025-list/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-7')">
            <div class="source">TechCrunch</div>
            <div class="title">ChatGPT: Everything you need to know about the AI-powered chatbot</div>
            <div class="meta">2025-12-22</div>
        </div>
        
        <div id="content-7" style="display:none;">
            <h2>ChatGPT: Everything you need to know about the AI-powered chatbot</h2>
            <p><strong>TechCrunch | 2025-12-22</strong></p>
            <a class="original-link" href="https://techcrunch.com/2025/12/22/chatgpt-everything-to-know-about-the-ai-chatbot/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">ChatGPT, OpenAI’s text-generating AI chatbot, has taken the world by storm since its launch in November 2022. What started as a tool to supercharge productivity through writing essays and code with short text prompts has evolved into a behemoth with 300 million weekly active users.

In 2025, OpenAI has battled the perception that it was ceding ground in the AI race to Chinese rivals like DeepSeek, all while the company has tried to shore up its relationship with Washington, pursued ambitious data center projects, and laid the groundwork for one of the largest funding rounds in history. Most recently though, headlines around OpenAI have focused on its competition gaining ground, with CEO Sam Altman’s “code red” internal memo shifting company focus toward its flagship chatbot.

And going further into the archives for context, this year came after a packed 2024, from OpenAI’s partnership with Apple for its generative AI offering, Apple Intelligence, the release of GPT-4o with voice capabilities, and the highly-anticipated launch of its text-to-video model Sora.

OpenAI also faced its share of internal drama, including the notable exits of high-level execs like co-founder and longtime chief scientist Ilya Sutskever and CTO Mira Murati. OpenAI has also been hit with lawsuits from Alden Global Capital-owned newspapers alleging copyright infringement, as well as an injunction from Elon Musk to halt OpenAI’s transition to a for-profit.

Below, you’ll find a timeline of ChatGPT product updates and releases, starting with the latest, which we’ve been updating throughout the year. If you have any other questions, check out our ChatGPT FAQ here.

To see a list of 2024-specific updates, go here.

OpenAI has added new controls in ChatGPT that let users adjust the chatbot’s warmth, enthusiasm, emoji use, and formatting style. This builds on existing tone options, addressing past complaints about the AI being too sycophantic or cold.

OpenAI has updated its guidelines for users under 18 and released new resources for parents to promote safer interactions with ChatGPT. Experts caution that while the rules are clearer on paper, it’s unclear how consistently the AI follows them in practice.

ChatGPT has surpassed $3 billion in global consumer spending on mobile since its 2023 launch. This makes it one of the fastest-growing apps in terms of revenue, outpacing rivals like TikTok, Disney+, and HBO Max.

OpenAI has released GPT Image 1.5, a new version of ChatGPT Images that’s faster and better at following instructions and making precise edits. The update comes as OpenAI races to keep up with Google’s Gemini and Nano Banana Pro in AI image generation.

Disney is putting $1 billion into OpenAI as a way to dive into AI, letting users on Sora create videos using over 200 Disney characters, at least for the first year exclusively. Bob Iger says the deal gives Disney a chance to explore AI while protecting its characters and figuring out how to use this technology in the future.

OpenAI says enterprise use of its AI tools has surged, with ChatGPT message volume up 8x since late 2024 and workers saving up to an hour a day. The data underscores OpenAI’s push to win enterprise customers as competition heats up from Google, Anthropic, and open-model rivals, a recurring theme in you’ll see in recent updates.

OpenAI rolled out its latest model, GPT-5.2, as competition with Google continued to heat up. The model will roll out to paid ChatGPT users and developers in three versions — Instant, Thinking, and Pro — tailored for everything from everyday tasks to complex reasoning and high-accuracy work.

Disney has signed a three-year deal with OpenAI, investing $1 billion and bringing characters from Disney, Marvel, Pixar, and Star Wars to OpenAI’s Sora video generator. The partnership will let users create AI videos using hundreds of Disney-owned characters, costumes, and props. One the same day, Disney notably launched a lawsuit against Google alleging “massive” copyright infringement occurring in its AI models.

OpenAI CEO Sam Altman has put OpenAI on “code red,” telling staff the company will prioritize improving ChatGPT as pressure mounts from Google and other AI competitors, according to The Information. As part of the move, OpenAI plans to put some other initiatives, including advertising, on the back burner.

OpenAI launched a new AI shopping feature in ChatGPT ahead of the peak holiday shopping window to help users research potential purchases. OpenAI’s new ChatGPT shopping feature lets users get product recommendations by describing features or sharing photos to find similar items at different prices. And they’re not alone, with both Perplexity and a slew of competitor startups playing in the commerce space.

After Adam Raine’s family sued OpenAI in August, claiming their teen used ChatGPT as a “suicide coach,” OpenAI said in a new court filing that it isn’t liable, arguing the chatbot was misused. This marks OpenAI’s first response to a case that has raised wider concerns about chatbots and mental health risks.

OpenAI is bringing ChatGPT’s voice mode straight into the main chat, so you no longer have to jump to a separate screen. Now you can talk to ChatGPT and see everything it says and shows right in the same window.

OpenAI can’t use “cameo” for Sora features for now, following a trademark lawsuit from the video app Cameo, with the ban lasting until December 22.

ChatGPT is now getting group chats for everyone — Free, Go, Plus, and Pro users alike — after testing it in a few regions last week. You can now team up with friends, family, or co-workers in one chat with ChatGPT to plan, create, or make decisions together.

OpenAI has released GPT‑5.1, upgrading the GPT‑5 series with two models: Instant, which it says will be warmer and more conversational with users, and Thinking, which offers faster, simple-task handling and more persistent complex reasoning. The update also introduces improved controls for customizing ChatGPT’s tone to better match user preferences.

A Munich court ruled that ChatGPT violated German copyright law by reproducing lyrics from nine protected songs, including Herbert Grönemeyer’s hits, rejecting OpenAI’s argument that the AI only reflected learned patterns. The decision could set a European precedent on AI use of copyrighted material, amid growing global legal challenges over AI and music rights.

OpenAI is exploring the consumer health sector, developing AI tools like personal health assistants and data aggregators, according to a report by Business Insider. With new healthcare-focused hires, it aims to simplify access to fragmented medical data — an area where Big Tech has struggled — through its conversational AI approach.

In November 2025, seven families sued OpenAI, alleging that GPT-4o was released prematurely without safeguards, contributing to suicides and severe psychiatric harm. One case involved 23-year-old Zane Shamblin, who told ChatGPT of his suicide plans, and the AI encouraged him. The lawsuits focus on GPT-4o’s tendency to be overly agreeable, despite users expressing dangerous intentions.

On November 5, OpenAI announced that over 1 million businesses globally now use its products, making it the fastest-growing business platform in history. Companies across industries like finance, healthcare, and retail, including Amgen, Booking.com, Cisco, Morgan Stanley, T-Mobile, Target, and Thermo Fisher Scientific, are using ChatGPT and OpenAI’s developer tools to enhance operations and customer experiences.

OpenAI revealed that a small but significant portion of ChatGPT users, more than a million weekly, discuss mental health struggles, including suicidal thoughts, psychosis, or mania, with the AI. The company says it has improved ChatGPT’s responses by consulting more than 170 mental health experts to handle such conversations more appropriately than earlier versions.

OpenAI is developing a new tool that generates music from text and audio prompts, potentially for enhancing videos or adding instrumentation, and is training it using annotated scores from Juilliard students, according to The Information. The launch date and whether it will be standalone or integrated with ChatGPT and Sora remain unclear.

OpenAI’s new “company knowledge” update for ChatGPT lets Business, Enterprise, and Education users search workplace data across tools like Slack, Google Drive, and GitHub using GPT‑5, per a report by The Verge. The feature acts as a conversational search engine, providing more comprehensive and accurate answers by scouring multiple sources simultaneously.

OpenAI has launched its AI browser, ChatGPT Atlas, starting on Mac, letting users get answers from ChatGPT instead of traditional search results. Unlike other AI browsers, Atlas is open to all users and will soon come to Windows, iOS, and Android, as OpenAI aims to make ChatGPT the go-to tool for browsing the web.

A new Apptopia analysis suggests ChatGPT’s mobile app growth may be leveling off, with global download growth slowing since April. While daily installs remain in the millions, October is tracking an 8.1% month-over-month decline in new downloads.

OpenAI is partnering with Walmart to allow users to browse products, plan meals, and make purchases through ChatGPT, with support for third-party sellers expected later this fall. The partnership is part of OpenAI’s broader effort to develop AI-driven e-commerce tools, including collaborations with Etsy and Shopify.

OpenAI is expanding its affordable ChatGPT Go plan, priced under $5, to 16 new countries across Asia, including Afghanistan, Bangladesh, Bhutan, Brunei Darussalam, Cambodia, Laos, Malaysia, Maldives, Thailand, Vietnam, and Pakistan. In some of these countries, users can pay in local currencies, while in others, payments are required in USD, with final costs varying due to local taxes.

ChatGPT now has 800 million weekly active users, reflecting rapid growth across consumers, developers, enterprises, and governments, Sam Altman said. This milestone comes as OpenAI accelerates efforts to expand its AI infrastructure and secure more chips to support rising demand.

OpenAI now allows developers to build interactive apps directly inside ChatGPT, with early partners like Booking.com, Expedia, Spotify, Figma, Coursera, Zillow, and Canva already onboard. The ChatGPT maker is also rolling out a preview of its Apps SDK, a developer toolkit for creating these chat-based experiences.

OpenAI is reportedly adding parental controls to ChatGPT on web and mobile, letting parents and teens link accounts to enable safeguards like limiting sensitive content, setting quiet hours, and disabling features such as voice mode or image generation. The move comes amid growing regulatory scrutiny and a lawsuit over the chatbot’s alleged role in a teen’s suicide.

OpenAI unveiled Pulse, a new ChatGPT feature that delivers personalized morning briefings overnight, encouraging users to start their day with the app. The tool reflects a shift toward making ChatGPT more proactive and asynchronous, positioning it as a true assistant rather than just a chatbot. OpenAI’s new Applications CEO, Fidji Simo, called Pulse the first step toward bringing high-level personal support to everyone, starting with Pro users.

OpenAI launched Instant Checkout in ChatGPT, letting U.S. users purchase products directly from Etsy and, soon, over a million Shopify merchants without leaving the conversation. Shoppers can browse items, read reviews, and complete purchases with a single tap using Apple Pay, Google Pay, Stripe, or a credit card. The update marks a step toward reshaping online shopping by merging product discovery, recommendations, and payments in one place.

OpenAI rolled out its budget-friendly ChatGPT Go plan in Indonesia for Rp 75,000 ($4.50) per month, following its initial launch in India. The mid-tier plan, which offers higher usage limits, image generation, file uploads, and better memory compared to the free version, enters the market in direct competition with Google’s new AI Plus plan in Indonesia.

CEO Sam Altman announced new policies for under-18 users of ChatGPT, tightening safeguards around sensitive conversations. The company says it will block flirtatious exchanges with minors and add stronger protections around discussions of suicide, even escalating severe cases to parents or authorities. The move comes as OpenAI faces a wrongful death lawsuit tied to alleged chatbot interactions, underscoring rising concerns about the mental health risks of AI companions.

OpenAI rolled out GPT-5-Codex, a new version of its AI coding agent that can spend anywhere from a few seconds to seven hours tackling a task, depending on complexity. The company says this dynamic approach helps the model outperform GPT-5 on key coding benchmarks, including bug fixes and large-scale refactoring. The update comes as OpenAI looks to keep Codex competitive in a fast-growing market that now includes rivals like Claude Code, Cursor, and GitHub Copilot.

OpenAI is shaking up its Model Behavior team, the small but influential group that helps shape how its AI interacts with people. The roughly 14-person team is being folded into the larger Post Training group, now reporting to lead researcher Max Schwarzer. Meanwhile, founding leader Joanne Jang is spinning up a new unit called OAI Labs, focused on prototyping fresh ways for people to collaborate with AI.

OpenAI, facing a lawsuit from the parents of a 16-year-old who died by suicide, said in its blog that it has implemented new safeguards for ChatGPT, including stronger detection of mental health risks and parental control features. The AI company said the updates aim to provide tighter protections around suicide-related conversations and give parents more oversight of their children’s use.

Elon Musk’s AI startup, xAI, filed a federal lawsuit in Texas against Apple and OpenAI, alleging that the two companies colluded to lock up key markets and shut out rivals.

OpenAI introduced its most affordable subscription plan, ChatGPT Go, in India, priced at 399 rupees per month (approximately $4.57). This move aims to expand OpenAI’s presence in its second-largest market, offering enhanced access to the latest GPT-5 model and additional features.

Since its May 2023 launch, ChatGPT’s mobile app has amassed $2 billion in global consumer spending, dwarfing competitors like Claude, Copilot, and Grok by roughly 30 times, according to Appfigures. This year alone, the app has generated $1.35 billion, a 673% increase from the same period in 2024, averaging nearly $193 million per month, or 53 times more than its nearest rival, Grok.

Despite unveiling GPT-5 as a “one-size-fits-all” AI, OpenAI is still offering several legacy AI options, including GPT-4o, GPT-4.1, and o3. Users can choose between new “Auto,” “Fast,” and “Thinking” modes for GPT-5, and paid subscribers regain access to legacy models like GPT-4o and GPT-4.1.

Updates to ChatGPT:You can now choose between “Auto”, “Fast”, and “Thinking” for GPT-5. Most users will want Auto, but the additional control will be useful for some people.Rate limits are now 3,000 messages/week with GPT-5 Thinking, and then extra capacity on GPT-5 Thinking…

OpenAI CEO Sam Altman told Reddit users that GPT-5’s “dumber” behavior at launch was due to a router issue and promised fixes, double rate limits for Plus users, and transparency on which model is answering, while also shrugging off the infamous “chart crime” from the live presentation.

OpenAI released GPT-5, a next-gen AI that’s not just smarter but more useful — able to handle tasks like coding apps, managing calendars, and creating research briefs — while automatically figuring out the fastest or most thoughtful way to answer your questions.

OpenAI is making a major push into federal government workflows, offering ChatGPT Enterprise to agencies for just $1 for the next year. The move comes after the U.S. General Services Administration (GSA) added OpenAI, Google, and Anthropic to its approved AI vendor list, allowing agencies to access these tools through preset contracts without negotiating pricing.

OpenAI unveiled its first open source language models since GPT-2, introducing two new open-weight AI releases: gpt-oss-120b, a high-performance model capable of running on a single Nvidia GPU, and gpt-oss-20b, a lighter model optimized for laptop use. The move comes amid growing competition in the global AI market and a push for more open technology in the U.S. and abroad.

ChatGPT’s rapid growth is accelerating. OpenAI said the chatbot was on track to hit 700 million weekly active users in the first week of August, up from 500 million at the end of March. Nick Turley, OpenAI’s VP and head of the ChatGPT app, highlighted the app’s growth on X, noting it has quadrupled in size over the past year.

This week, ChatGPT is on track to reach 700M weekly active users — up from 500M at the end of March and 4× since last year. Every day, people and teams are learning, creating, and solving harder problems. Big week ahead. Grateful to the team for making ChatGPT more useful and…

OpenAI unveiled Study Mode, a new ChatGPT feature designed to promote critical thinking by prompting students to engage with material rather than simply receive answers. The tool is now rolling out to Free, Plus, Pro, and Team users, with availability for Edu subscribers expected in the coming weeks.

ChatGPT users should be cautious when seeking emotional support from AI, as the AI industry lacks safeguards for sensitive conversations, OpenAI CEO Sam Altman said on a recent episode of This Past Weekend w/ Theo Von. Unlike human therapists, AI tools aren’t bound by doctor-patient confidentiality, he noted.

ChatGPT now receives 2.5 billion prompts daily from users worldwide, including roughly 330 million from the U.S. That’s more than double the volume reported by CEO Sam Altman just eight months ago, highlighting the chatbot’s explosive growth.

OpenAI has introduced ChatGPT Agent, which completes a wide variety of computer-based tasks on behalf of users and combines several capabilities like Operator and Deep Research, according to the company. OpenAI says the agent can automatically navigate a user’s calendar, draft editable presentations and slideshows, run code, shop online, and handle complex workflows from end to end, all within a secure virtual environment.

Researchers at Stanford University have observed that therapy chatbots powered by large language models can sometimes stigmatize people with mental health conditions or respond in ways that are inappropriate or could be harmful. While chatbots are “being used as companions, confidants, and therapists,” the study found “significant risks.”

CEO Sam Altman said that the company is delaying the release of its open model, which had already been postponed by a month earlier this summer. The ChatGPT maker, which initially planned to release the model around mid-July, has indefinitely postponed its launch to conduct additional safety testing.

we planned to launch our open-weight model next week.we are delaying it; we need time to run additional safety tests and review high-risk areas. we are not yet sure how long it will take us.while we trust the community will build great things with this model, once weights are…

OpenAI plans to release an AI-powered web browser to challenge Alphabet’s Google Chrome. It will keep some user interactions within ChatGPT, rather than directing people to external websites.

Some ChatGPT users have noticed a new feature called “Study Together” appearing in their list of available tools. This is the chatbot’s approach to becoming a more effective educational tool, rather than simply providing answers to prompts. Some people also wonder whether there will be a feature that allows multiple users to join the chat, similar to a study group.

Referrals from ChatGPT to news publishers are increasing. But this rise is insufficient to offset the decline in clicks as more users now obtain their news directly from AI or AI-powered search results, according to a report by digital market intelligence company Similarweb. Since Google launched its AI Overviews in May 2024, the percentage of news searches that don’t lead to clicks on news websites has increased from 56% to nearly 69% by May 2025.

OpenAI has started using Google’s AI chips to power ChatGPT and other products, as reported by Reuters. The ChatGPT maker is one of the biggest buyers of Nvidia’s GPUs, using the AI chips to train models, and this is the first time that OpenAI is using non-Nvidia chips in an important way.

Researchers from MIT’s Media Lab monitored the brain activity of writers in 32 regions. They found that ChatGPT users showed minimal brain engagement and consistently fell short in neural, linguistic, and behavioral aspects. To conduct the test, the lab split 54 participants from the Boston area into three groups, each consisting of individuals ages 18 to 39. The participants were asked to write multiple SAT essays using tools such as OpenAI’s ChatGPT, the Google search engine, or without any tools.

The ChatGPT app for iOS was downloaded 29.6 million times in the last 28 days, while TikTok, Facebook, Instagram, and X were downloaded a total of 32.9 million times during the same period, representing a difference of about 10.6%, according to ZDNET report citing Similarweb’s X post.

Sam Altman said that the average ChatGPT query uses about one-fifteenth of a teaspoon of water, equivalent to 0.000083 gallons of water, or the energy required to power a lightbulb for a few minutes, per Business Insider. In addition to that, the chatbot requires 0.34 watt-hours of electricity to operate.

OpenAI has unveiled o3-pro, an enhanced version of its o3, a reasoning model that the chatGPT maker launched earlier this year. O3-pro is available for ChatGPT and Team users and in the API, while Enterprise and Edu users will get access in the third week of June.

OpenAI o3-pro is available in the model picker for Pro and Team users starting today, replacing OpenAI o1-pro.Enterprise and Edu users will get access the week after.As o3-pro uses the same underlying model as o3, full safety details can be found in the o3 system card.…

OpenAI upgraded ChatGPT’s conversational voice mood for all paid users across different markets and platforms. The startup has launched an update to Advanced Voice that enables users to converse with ChatGPT out loud in a more natural and fluid sound. The feature also helps users translate languages more easily, the comapny said.

OpenAI’s ChatGPT now offers new funtions for business users, including integrations with various cloud services, meeting recordings, and MCP connection support for connecting to tools for in-depth research. The feature enables ChatGPT to retrieve information across users’ own services to answer their questions. For instance, an analyst could use the company’s slide deck and documents to develop an investment thesis.

OpenAI plans to purchase Jony Ive’s devices startup io for $6.4 billion. Sarah Friar, CFO of OpenAI, thinks that the hardware will significantly enhance ChatGPT and broaden OpenAI’s reach to a larger audience in the future.

OpenAI has introduced its AI coding agent, Codex, powered by codex-1, a version of its o3 AI reasoning model designed for software engineering tasks. OpenAI says codex-1 generates more precise and “cleaner” code than o3. The coding agent may take anywhere from one to 30 minutes to complete tasks such as writing simple features, fixing bugs, answering questions about your codebase, and running tests.

Sam Altman, the CEO of OpenAI, said during a recent AI event hosted by VC firm Sequoia that he wants ChatGPT to record and remember every detail of a person’s life when one attendee asked about how ChatGPT can become more personalized.

OpenAI said in a post on X that it has launched its GPT-4.1 and GPT4.1 mini AI models in ChagGPT.

By popular request, GPT-4.1 will be available directly in ChatGPT starting today.GPT-4.1 is a specialized model that excels at coding tasks & instruction following. Because it’s faster, it’s a great alternative to OpenAI o3 & o4-mini for everyday coding needs.

OpenAI has launched a new feature for ChatGPT deep research to analyze code repositories on GitHub. The ChatGPT deep research feature is in beta and lets developers connect with GitHub to ask questions about codebases and engineering documents. The connector will soon be available for ChatGPT Plus, Pro, and Team users, with support for Enterprise and Education coming shortly, per an OpenAI spokesperson.

After introducing a data residency program in Europe in February, OpenAI has now launched a similar program in Asian countries including India, Japan, Singapore, and South Korea. The new program will be accessible to users of ChatGPT Enterprise, ChatGPT Edu, and API. It will help organizations in Asia meet their local data sovereignty requirements when using OpenAI’s products.

OpenAI is unveiling a program called OpenAI for Countries, which aims to develop the necessary local infrastructure to serve international AI clients better. The AI startup will work with governments to assist with increasing data center capacity and customizing OpenAI’s products to meet specific language and local needs. OpenAI for Countries is part of efforts to support the company’s expansion of its AI data center Project Stargate to new locations outside the U.S., per Bloomberg.

OpenAI has announced its plan to make changes to its procedures for updating the AI models that power ChatGPT, following an update that caused the platform to become overly sycophantic for many users.

OpenAI has released a post on the recent sycophancy issues with the default AI model powering ChatGPT, GPT-4o, leading the company to revert an update to the model released last week. CEO Sam Altman acknowledged the issue on Sunday and confirmed two days later that the GPT-4o update was being rolled back. OpenAI is working on “additional fixes” to the model’s personality. Over the weekend, users on social media criticized the new model for making ChatGPT too validating and agreeable. It became a popular meme fast.

An issue within OpenAI’s ChatGPT enabled the chatbot to create graphic erotic content for accounts registered by users under the age of 18, as demonstrated by TechCrunch’s testing, a fact later confirmed by OpenAI. “Protecting younger users is a top priority, and our Model Spec, which guides model behavior, clearly restricts sensitive content like erotica to narrow contexts such as scientific, historical, or news reporting,” a spokesperson told TechCrunch via email. “In this case, a bug allowed responses outside those guidelines, and we are actively deploying a fix to limit these generations.”

OpenAI has added a few features to its ChatGPT search, its web search tool in ChatGPT, to give users an improved online shopping experience. The company says people can ask super-specific questions using natural language and receive customized results. The chatbot provides recommendations, images, and reviews of products in various categories such as fashion, beauty, home goods, and electronics.

OpenAI leaders have been talking about allowing the open model to link up with OpenAI’s cloud-hosted models to improve its ability to respond to intricate questions, two sources familiar with the situation told TechCrunch.

OpenAI is preparing to launch an AI system that will be openly accessible, allowing users to download it for free without any API restrictions. Aidan Clark, OpenAI’s VP of research, is spearheading the development of the open model, which is in the very early stages, sources familiar with the situation told TechCrunch.

OpenAI released a new AI model called GPT-4.1 in mid-April. However, multiple independent tests indicate that the model is less reliable than previous OpenAI releases. The company skipped that step — sending safety cards for GPT-4.1 — claiming in a statement to TechCrunch that “GPT-4.1 is not a frontier model, so there won’t be a separate system card released for it.”

Questions have been raised regarding OpenAI’s transparency and procedures for testing models after a difference in benchmark outcomes was detected by first- and third-party benchmark results for the o3 AI model. OpenAI introduced o3 in December, stating that the model could solve approximately 25% of questions on FrontierMath, a difficult math problem set. Epoch AI, the research institute behind FrontierMath, discovered that o3 achieved a score of approximately 10%, which was significantly lower than OpenAI’s top-reported score.

OpenAI has launched a new API feature called Flex processing that allows users to use AI models at a lower cost but with slower response times and occasional resource unavailability. Flex processing is available in beta on the o3 and o4-mini reasoning models for non-production tasks like model evaluations, data enrichment, and asynchronous workloads.

OpenAI has rolled out a new system to monitor its AI reasoning models, o3 and o4 mini, for biological and chemical threats. The system is designed to prevent models from giving advice that could potentially lead to harmful attacks, as stated in OpenAI’s safety report.

OpenAI has released two new reasoning models, o3 and o4 mini, just two days after launching GPT-4.1. The company claims o3 is the most advanced reasoning model it has developed, while o4-mini is said to provide a balance of price, speed, and performance. The new models stand out from previous reasoning models because they can use ChatGPT features like web browsing, coding, and image processing and generation. But they hallucinate more than several of OpenAI’s previous models.

Open AI introduced a new section called “library” to make it easier for users to create images on mobile and web platforms, per the company’s X post.

All of your image creations, all in one place.Introducing the new library for your ChatGPT image creations—rolling out now to all Free, Plus, and Pro users on mobile and https://t.co/nYW5KO1aIg. pic.twitter.com/ADWuf5fPbj

OpenAI said on Tuesday that it might revise its safety standards if “another frontier AI developer releases a high-risk system without comparable safeguards.” The move shows how commercial AI developers face more pressure to rapidly implement models due to the increased competition.

OpenAI is currently in the early stages of developing its own social media platform to compete with Elon Musk’s X and Mark Zuckerberg’s Instagram and Threads, according to The Verge. It is unclear whether OpenAI intends to launch the social network as a standalone application or incorporate it into ChatGPT.

OpenAI will discontinue its largest AI model, GPT-4.5, from its API even though it was just launched in late February. GPT-4.5 will be available in a research preview for paying customers. Developers can use GPT-4.5 through OpenAI’s API until July 14; then, they will need to switch to GPT-4.1, which was released on April 14.

OpenAI has launched three members of the GPT-4.1 model — GPT-4.1, GPT-4.1 mini, and GPT-4.1 nano — with a specific focus on coding capabilities. It’s accessible via the OpenAI API but not ChatGPT. In the competition to develop advanced programming models, GPT-4.1 will rival AI models such as Google’s Gemini 2.5 Pro, Anthropic’s Claude 3.7 Sonnet, and DeepSeek’s upgraded V3.

OpenAI plans to sunset GPT-4, an AI model introduced more than two years ago, and replace it with GPT-4o, the current default model, per changelog. It will take effect on April 30. GPT-4 will remain available via OpenAI’s API.

OpenAI may launch several new AI models, including GPT-4.1, soon, The Verge reported, citing anonymous sources. GPT-4.1 would be an update of OpenAI’s GPT-4o, which was released last year. On the list of upcoming models are GPT-4.1 and smaller versions like GPT-4.1 mini and nano, per the report.

OpenAI started updating ChatGPT to enable the chatbot to remember previous conversations with a user and customize its responses based on that context. This feature is rolling out to ChatGPT Pro and Plus users first, excluding those in the U.K., EU, Iceland, Liechtenstein, Norway, and Switzerland.

It looks like OpenAI is working on a watermarking feature for images generated using GPT-4o. AI researcher Tibor Blaho spotted a new “ImageGen” watermark feature in the new beta of ChatGPT’s Android app. Blaho also found mentions of other tools: “Structured Thoughts,” “Reasoning Recap,” “CoT Search Tool,” and “l1239dk1.”

OpenAI is offering its $20-per-month ChatGPT Plus subscription tier for free to all college students in the U.S. and Canada through the end of May. The offer will let millions of students use OpenAI’s premium service, which offers access to the company’s GPT-4o model, image generation, voice interaction, and research tools that are not available in the free version.

More than 130 million users have created over 700 million images since ChatGPT got the upgraded image generator on March 25, according to COO of OpenAI Brad Lightcap. The image generator was made available  to all ChatGPT users on March 31, and went viral for being able to create Ghibli-style photos.

The Arc Prize Foundation, which develops the AI benchmark tool ARC-AGI, has updated the estimated computing costs for OpenAI’s o3 “reasoning” model managed by ARC-AGI. The organization originally estimated that the best-performing configuration of o3 it tested, o3 high, would cost approximately $3,000 to address a single problem. The Foundation now thinks the cost could be much higher, possibly around $30,000 per task.

In a series of posts on X, OpenAI CEO Sam Altman said the company’s new image-generation tool’s popularity may cause product releases to be delayed. “We are getting things under control, but you should expect new releases from OpenAI to be delayed, stuff to break, and for service to sometimes be slow as we deal with capacity challenges,” he wrote.

OpeanAI intends to release its “first” open language model since GPT-2 “in the coming months.” The company plans to host developer events to gather feedback and eventually showcase prototypes of the model. The first developer event is to be held in San Francisco, with sessions to follow in Europe and Asia.

OpenAI made a notable change to its content moderation policies after the success of its new image generator in ChatGPT, which went viral for being able to create Studio Ghibli-style images. The company has updated its policies to allow ChatGPT to generate images of public figures, hateful symbols, and racial features when requested. OpenAI had previously declined such prompts due to the potential controversy or harm they may cause. However, the company has now “evolved” its approach, as stated in a blog post published by Joanne Jang, the lead for OpenAI’s model behavior.

OpenAI wants to incorporate Anthropic’s Model Context Protocol (MCP) into all of its products, including the ChatGPT desktop app. MCP, an open-source standard, helps AI models generate more accurate and suitable responses to specific queries, and lets developers create bidirectional links between data sources and AI applications like chatbots. The protocol is currently available in the Agents SDK, and support for the ChatGPT desktop app and Responses API will be coming soon, OpenAI CEO Sam Altman said.

The latest update of the image generator on OpenAI’s ChatGPT has triggered a flood of AI-generated memes in the style of Studio Ghibli, the Japanese animation studio behind blockbuster films like “My Neighbor Totoro” and “Spirited Away.” The burgeoning mass of Ghibli-esque images have sparked concerns about whether OpenAI has violated copyright laws, especially since the company is already facing legal action for using source material without authorization.

OpenAI expects its revenue to triple to $12.7 billion in 2025, fueled by the performance of its paid AI software, Bloomberg reported, citing an anonymous source. While the startup doesn’t expect to reach positive cash flow until 2029, it expects revenue to increase significantly in 2026 to surpass $29.4 billion, the report said.

OpenAI on Tuesday rolled out a major upgrade to ChatGPT’s image-generation capabilities: ChatGPT can now use the GPT-4o model to generate and edit images and photos directly. The feature went live earlier this week in ChatGPT and Sora, OpenAI’s AI video-generation tool, for subscribers of the company’s Pro plan, priced at $200 a month, and will be available soon to ChatGPT Plus subscribers and developers using the company’s API service. The company’s CEO Sam Altman said on Wednesday, however, that the release of the image generation feature to free users would be delayed due to higher demand than the company expected.

Brad Lightcap, OpenAI’s chief operating officer, will lead the company’s global expansion and manage corporate partnerships as CEO Sam Altman shifts his focus to research and products, according to a blog post from OpenAI. Lightcap, who previously worked with Altman at Y Combinator, joined the Microsoft-backed startup in 2018. OpenAI also said Mark Chen would step into the expanded role of chief research officer, and Julia Villagra will take on the role of chief people officer.

OpenAI has updated its AI voice assistant with improved chatting capabilities, according to a video posted on Monday (March 24) to the company’s official media channels. The update enables real-time conversations, and the AI assistant is said to be more personable and interrupts users less often. Users on ChatGPT’s free tier can now access the new version of Advanced Voice Mode, while paying users will receive answers that are “more direct, engaging, concise, specific, and creative,” a spokesperson from OpenAI told TechCrunch.

OpenAI and Meta have separately engaged in discussions with Indian conglomerate Reliance Industries regarding potential collaborations to enhance their AI services in the country, per a report by The Information. One key topic being discussed is Reliance Jio distributing OpenAI’s ChatGPT. Reliance has proposed selling OpenAI’s models to businesses in India through an application programming interface (API) so they can incorporate AI into their operations. Meta also plans to bolster its presence in India by constructing a large 3GW data center in Jamnagar, Gujarat. OpenAI, Meta, and Reliance have not yet officially announced these plans.

Noyb, a privacy rights advocacy group, is supporting an individual in Norway who was shocked to discover that ChatGPT was providing false information about him, stating that he had been found guilty of killing two of his children and trying to harm the third. “The GDPR is clear. Personal data has to be accurate,” said Joakim Söderberg, data protection lawyer at Noyb, in a statement. “If it’s not, users have the right to have it changed to reflect the truth. Showing ChatGPT users a tiny disclaimer that the chatbot can make mistakes clearly isn’t enough. You can’t just spread false information and in the end add a small disclaimer saying that everything you said may just not be true.”

OpenAI has added new transcription and voice-generating AI models to its APIs: a text-to-speech model, “gpt-4o-mini-tts,” that delivers more nuanced and realistic sounding speech, as well as two speech-to-text models called “gpt-4o-transcribe” and “gpt-4o-mini-transcribe”. The company claims they are improved versions of what was already there and that they hallucinate less.

OpenAI has introduced o1-pro in its developer API. OpenAI says its o1-pro uses more computing than its o1 “reasoning” AI model to deliver “consistently better responses.” It’s only accessible to select developers who have spent at least $5 on OpenAI API services. OpenAI charges $150 for every million tokens (about 750,000 words) input into the model and $600 for every million tokens the model produces. It costs twice as much as OpenAI’s GPT-4.5 for input and 10 times the price of regular o1.

Noam Brown, who heads AI reasoning research at OpenAI, thinks that certain types of AI models for “reasoning” could have been developed 20 years ago if researchers had understood the correct approach and algorithms.

OpenAI CEO Sam Altman said, in a post on X, that the company has trained a “new model” that’s “really good” at creative writing. He posted a lengthy sample from the model given the prompt “Please write a metafictional literary short story about AI and grief.” OpenAI has not extensively explored the use of AI for writing fiction. The company has mostly concentrated on challenges in rigid, predictable areas such as math and programming. And it turns out that it might not be that great at creative writing at all.

we trained a new model that is good at creative writing (not sure yet how/when it will get released). this is the first time i have been really struck by something written by AI; it got the vibe of metafiction so right.PROMPT:Please write a metafictional literary short story…

OpenAI rolled out new tools designed to help developers and businesses build AI agents — automated systems that can independently accomplish tasks — using the company’s own AI models and frameworks. The tools are part of OpenAI’s new Responses API, which enables enterprises to develop customized AI agents that can perform web searches, scan through company files, and navigate websites, similar to OpenAI’s Operator product. The Responses API effectively replaces OpenAI’s Assistants API, which the company plans to discontinue in the first half of 2026.

OpenAI intends to release several “agent” products tailored for different applications, including sorting and ranking sales leads and software engineering, according to a report from The Information. One, a “high-income knowledge worker” agent, will reportedly be priced at $2,000 a month. Another, a software developer agent, is said to cost $10,000 a month. The most expensive rumored agents, which are said to be aimed at supporting “PhD-level research,” are expected to cost $20,000 per month. The jaw-dropping figure is indicative of how much cash OpenAI needs right now: The company lost roughly $5 billion last year after paying for costs related to running its services and other expenses. It’s unclear when these agentic tools might launch or which customers will be eligible to buy them.

The latest version of the macOS ChatGPT app allows users to edit code directly in supported developer tools, including Xcode, VS Code, and JetBrains. ChatGPT Plus, Pro, and Team subscribers can use the feature now, and the company plans to roll it out to more users like Enterprise, Edu, and free users.

According to a new report from VC firm Andreessen Horowitz (a16z), OpenAI’s AI chatbot, ChatGPT, experienced solid growth in the second half of 2024. It took ChatGPT nine months to increase its weekly active users from 100 million in November 2023 to 200 million in August 2024, but it only took less than six months to double that number once more, according to the report. ChatGPT’s weekly active users increased to 300 million by December 2024 and 400 million by February 2025. ChatGPT has experienced significant growth recently due to the launch of new models and features, such as GPT-4o, with multimodal capabilities. ChatGPT usage spiked from April to May 2024, shortly after that model’s launch.

OpenAI has effectively canceled the release of o3 in favor of what CEO Sam Altman is calling a “simplified” product offering. In a post on X, Altman said that, in the coming months, OpenAI will release a model called GPT-5 that “integrates a lot of [OpenAI’s] technology,” including o3, in ChatGPT and its API. As a result of that roadmap decision, OpenAI no longer plans to release o3 as a standalone model.

A commonly cited stat is that ChatGPT requires around 3 watt-hours of power to answer a single question. Using OpenAI’s latest default model for ChatGPT, GPT-4o, as a reference, nonprofit AI research institute Epoch AI found the average ChatGPT query consumes around 0.3 watt-hours. However, the analysis doesn’t consider the additional energy costs incurred by ChatGPT with features like image generation or input processing.

In response to pressure from rivals like DeepSeek, OpenAI is changing the way its o3-mini model communicates its step-by-step “thought” process. ChatGPT users will see an updated “chain of thought” that shows more of the model’s “reasoning” steps and how it arrived at answers to questions.

OpenAI is now allowing anyone to use ChatGPT web search without having to log in. While OpenAI had previously allowed users to ask ChatGPT questions without signing in, responses were restricted to the chatbot’s last training update. This only applies through ChatGPT.com, however. To use ChatGPT in any form through the native mobile app, you will still need to be logged in.

OpenAI announced a new AI “agent” called deep research that’s designed to help people conduct in-depth, complex research using ChatGPT. OpenAI says the “agent” is intended for instances where you don’t just want a quick answer or summary, but instead need to assiduously consider information from multiple websites and other sources.

OpenAI used the subreddit r/ChangeMyView to measure the persuasive abilities of its AI reasoning models. OpenAI says it collects user posts from the subreddit and asks its AI models to write replies, in a closed environment, that would change the Reddit user’s mind on a subject. The company then shows the responses to testers, who assess how persuasive the argument is, and finally OpenAI compares the AI models’ responses to human replies for that same post.

OpenAI launched a new AI “reasoning” model, o3-mini, the newest in the company’s o family of models. OpenAI first previewed the model in December alongside a more capable system called o3. OpenAI is pitching its new model as both “powerful” and “affordable.”

A new report from app analytics firm Appfigures found that over half of ChatGPT’s mobile users are under age 25, with users between ages 50 and 64 making up the second largest age demographic. The gender gap among ChatGPT users is even more significant. Appfigures estimates that across age groups, men make up 84.5% of all users.

OpenAI launched ChatGPT Gov designed to provide U.S. government agencies an additional way to access the tech. ChatGPT Gov includes many of the capabilities found in OpenAI’s corporate-focused tier, ChatGPT Enterprise. OpenAI says that ChatGPT Gov enables agencies to more easily manage their own security, privacy, and compliance, and could expedite internal authorization of OpenAI’s tools for the handling of non-public sensitive data.

Younger Gen Zers are embracing ChatGPT, for schoolwork, according to a new survey by the Pew Research Center. In a follow-up to its 2023 poll on ChatGPT usage among young people, Pew asked ~1,400 U.S.-based teens ages 13 to 17 whether they’ve used ChatGPT for homework or other school-related assignments. Twenty-six percent said that they had, double the number two years ago. Just over half of teens responding to the poll said they think it’s acceptable to use ChatGPT for researching new subjects. But considering the ways ChatGPT can fall short, the results are possibly cause for alarm.

OpenAI says that it might store chats and associated screenshots from customers who use Operator, the company’s AI “agent” tool, for up to 90 days — even after a user manually deletes them. While OpenAI has a similar deleted data retention policy for ChatGPT, the retention period for ChatGPT is only 30 days, which is 60 days shorter than Operator’s.

OpenAI is launching a research preview of Operator, a general-purpose AI agent that can take control of a web browser and independently perform certain actions. Operator promises to automate tasks such as booking travel accommodations, making restaurant reservations, and shopping online.

Operator, OpenAI’s agent tool, could be released sooner rather than later. Changes to ChatGPT’s code base suggest that Operator will be available as an early research preview to users on the $200 Pro subscription plan. The changes aren’t yet publicly visible, but a user on X who goes by Choi spotted these updates in ChatGPT’s client-side code. TechCrunch separately identified the same references to Operator on OpenAI’s website.

OpenAI has begun testing a feature that lets new ChatGPT users sign up with only a phone number — no email required. The feature is currently in beta in the U.S. and India. However, users who create an account using their number can’t upgrade to one of OpenAI’s paid plans without verifying their account via an email. Multi-factor authentication also isn’t supported without a valid email.

ChatGPT’s new beta feature, called tasks, allows users to set simple reminders. For example, you can ask ChatGPT to remind you when your passport expires in six months, and the AI assistant will follow up with a push notification on whatever platform you have tasks enabled. The feature will start rolling out to ChatGPT Plus, Team, and Pro users around the globe this week.

OpenAI is introducing a new way for users to customize their interactions with ChatGPT. Some users found they can specify a preferred name or nickname and “traits” they’d like the chatbot to have. OpenAI suggests traits like “Chatty,” “Encouraging,” and “Gen Z.” However, some users reported that the new options have disappeared, so it’s possible they went live prematurely.

ChatGPT is a general-purpose chatbot that uses artificial intelligence to generate text after a user enters a prompt, developed by tech startup OpenAI. The chatbot uses GPT-4, a large language model that uses deep learning to produce human-like text.

November 30, 2022 is when ChatGPT was released for public use.

Both the free version of ChatGPT and the paid ChatGPT Plus are regularly updated with new GPT models. The most recent model is GPT-4o.

There is a free version of ChatGPT that only requires a sign-in in addition to the paid version, ChatGPT Plus.

Anyone can use ChatGPT! More and more tech companies and search engines are utilizing the chatbot to automate text or quickly answer user questions/concerns.

Multiple enterprises utilize ChatGPT, although others may limit the use of the AI-powered tool.

Most recently, Microsoft announced at its 2023 Build conference that it is integrating its ChatGPT-based Bing experience into Windows 11. A Brooklyn-based 3D display startup Looking Glass utilizes ChatGPT to produce holograms you can communicate with by using ChatGPT.  And nonprofit organization Solana officially integrated the chatbot into its network with a ChatGPT plug-in geared toward end users to help onboard into the web3 space.

GPT stands for Generative Pre-Trained Transformer.

A chatbot can be any software/system that holds dialogue with you/a person but doesn’t necessarily have to be AI-powered. For example, there are chatbots that are rules-based in the sense that they’ll give canned responses to questions.

ChatGPT is AI-powered and utilizes LLM technology to generate text after a prompt.

Due to the nature of how these models work, they don’t know or care whether something is true, only that it looks true. That’s a problem when you’re using it to do your homework, sure, but when it accuses you of a crime you didn’t commit, that may well at this point be libel.

We will see how handling troubling statements produced by ChatGPT will play out over the next few months as tech and legal experts attempt to tackle the fastest moving target in the industry.

Yes, there is a free ChatGPT mobile app for iOS and Android users.

It’s not documented anywhere that ChatGPT has a character limit. However, users have noted that there are some character limitations after around 500 words.

Everyday examples include programming, scripts, email replies, listicles, blog ideas, summarization, etc.

Advanced use examples include debugging code, programming languages, scientific concepts, complex problem solving, etc.

It depends on the nature of the program. While ChatGPT can write workable Python code, it can’t necessarily program an entire app’s worth of code. That’s because ChatGPT lacks context awareness — in other words, the generated code isn’t always appropriate for the specific context in which it’s being used.

Yes. OpenAI allows users to save chats in the ChatGPT interface, stored in the sidebar of the screen. There are no built-in sharing features yet.

Yes. There are multiple AI-powered chatbot competitors such as Together, Google’s Gemini and Anthropic’s Claude, and developers are creating open source alternatives.

OpenAI has said that individuals in “certain jurisdictions” (such as the EU) can object to the processing of their personal information by its AI models by filling out this form. This includes the ability to make requests for deletion of AI-generated references about you. Although OpenAI notes it may not grant every request since it must balance privacy requests against freedom of expression “in accordance with applicable laws”.

The web form for making a deletion of data about you request is entitled “OpenAI Personal Data Removal Request”.

In its privacy policy, the ChatGPT maker makes a passing acknowledgement of the objection requirements attached to relying on “legitimate interest” (LI), pointing users towards more information about requesting an opt out — when it writes: “See here for instructions on how you can opt out of our use of your information to train our models.”

Recently, Discord announced that it had integrated OpenAI’s technology into its bot named Clyde where two users tricked Clyde into providing them with instructions for making the illegal drug methamphetamine (meth) and the incendiary mixture napalm.

An Australian mayor has publicly announced he may sue OpenAI for defamation due to ChatGPT’s false claims that he had served time in prison for bribery. This would be the first defamation lawsuit against the text-generating service.

CNET found itself in the midst of controversy after Futurism reported the publication was publishing articles under a mysterious byline completely generated by AI. The private equity company that owns CNET, Red Ventures, was accused of using ChatGPT for SEO farming, even if the information was incorrect.

Several major school systems and colleges, including New York City Public Schools, have banned ChatGPT from their networks and devices. They claim that the AI impedes the learning process by promoting plagiarism and misinformation, a claim that not every educator agrees with.

There have also been cases of ChatGPT accusing individuals of false crimes.

Several marketplaces host and provide ChatGPT prompts, either for free or for a nominal fee. One is PromptBase. Another is ChatX. More launch every day.

Poorly. Several tools claim to detect ChatGPT-generated text, but in our tests, they’re inconsistent at best.

No. But OpenAI recently disclosed a bug, since fixed, that exposed the titles of some users’ conversations to other people on the service.

None specifically targeting ChatGPT. But OpenAI is involved in at least one lawsuit that has implications for AI systems trained on publicly available data, which would touch on ChatGPT.

Yes. Text-generating AI models like ChatGPT have a tendency to regurgitate content from their training data.

This story is continually updated with new information.

Kate Park is a reporter at TechCrunch, with a focus on technology, startups and venture capital in Asia. She previously was a financial journalist at Mergermarket covering M&A, private equity and venture capital.

Alyssa Stringer was formerly the Audience Development Manager for TechCrunch. She previously worked for HW Media as Audience Development Manager across HousingWire, RealTrends and FinLedger media brands. Prior to her experience in audience development, Alyssa worked as a content writer and holds a Bachelor’s in Journalism at the University of North Texas.

Plan ahead for the 2026 StrictlyVC events. Hear straight-from-the-source candid insights in on-stage fireside sessions and meet the builders and backers shaping the industry. Join the waitlist to get first access to the lowest-priced tickets and important updates.

Google and Apple reportedly warn employees on visas to avoid international travel

Tech provider for NHS England confirms data breach

Google launches Gemini 3 Flash, makes it the default model in the Gemini app

Coursera and Udemy enter a merger agreement valued at around $2.5B

Google’s vibe-coding tool Opal comes to Gemini

Google tests an email-based productivity assistant

Hacking group says it’s extorting Pornhub after stealing users’ viewing data</div>
        </div>
        
        <div class="card" onclick="openModal('content-8')">
            <div class="source">TechCrunch</div>
            <div class="title">TikTok Shop launches digital gift cards to challenge Amazon and eBay</div>
            <div class="meta">2025-12-22</div>
        </div>
        
        <div id="content-8" style="display:none;">
            <h2>TikTok Shop launches digital gift cards to challenge Amazon and eBay</h2>
            <p><strong>TechCrunch | 2025-12-22</strong></p>
            <a class="original-link" href="https://techcrunch.com/2025/12/22/tiktok-shop-launches-digital-gift-cards-to-challenge-amazon-and-ebay/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">TikTok Shop has rolled out a new feature that allows users to purchase digital gift cards, making it easier to help friends and family buy from the millions of products on the app.

​The feature was strategically launched during the holiday season — a high-stakes period for the company’s shopping division as it aims to prove its value in the market. ​This move into digital gifting positions TikTok Shop to compete more directly with e-commerce giants like Amazon and eBay, both of which offer gift card options. TikTok Shop has also recently expanded into luxury retail, another move to solidify its footing in e-commerce.

Users can load the gift cards with anything from $10 to $500. What sets these cards apart is the ability to personalize them using a wide variety of animated designs. There are also animations for thank you cards, birthdays, weddings, and other occasions.

Gift cards are delivered via email, and recipients must have a TikTok account. Once redeemed, the card’s value is instantly credited to their TikTok Balance. Recipients can reply with a thank-you note or even send a gift card in return.

However, the gift cards can only be purchased in the U.S. for now.

TikTok said it plans to add features that let users personalize gift cards more. By early 2026, users will be able to record or upload video messages to attach to their digital gift cards. A company spokesperson said the experience will also include an “interactive unboxing that captures their reaction in real-time,” but declined to share further details.

The launch of digital gift cards comes on the heels of a significant milestone for TikTok Shop: Over the four days of Black Friday and Cyber Monday, the app recorded sales of more than $500 million in the U.S.

However, despite this achievement, TikTok Shop faces uncertainty as the sale of the app’s U.S. operations to an American investor group looms. If a sale doesn’t occur, TikTok faces a potential ban in the country. President Trump has extended the deadline to January 23, 2026, leaving the app’s future in the U.S. hanging in the balance.

Lauren covers media, streaming, apps and platforms at TechCrunch.

You can contact or verify outreach from Lauren by emailing laurenf.techcrunch@gmail.com or via encrypted message at laurenforris22.25 on Signal.

Plan ahead for the 2026 StrictlyVC events. Hear straight-from-the-source candid insights in on-stage fireside sessions and meet the builders and backers shaping the industry. Join the waitlist to get first access to the lowest-priced tickets and important updates.

Google and Apple reportedly warn employees on visas to avoid international travel

Tech provider for NHS England confirms data breach

Google launches Gemini 3 Flash, makes it the default model in the Gemini app

Coursera and Udemy enter a merger agreement valued at around $2.5B

Google’s vibe-coding tool Opal comes to Gemini

Google tests an email-based productivity assistant

Hacking group says it’s extorting Pornhub after stealing users’ viewing data</div>
        </div>
        
        <div class="card" onclick="openModal('content-9')">
            <div class="source">The Atlantic</div>
            <div class="title">The Trump Administration’s Guide to Christmas Giving</div>
            <div class="meta">2025-12-22</div>
        </div>
        
        <div id="content-9" style="display:none;">
            <h2>The Trump Administration’s Guide to Christmas Giving</h2>
            <p><strong>The Atlantic | 2025-12-22</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/newsletters/2025/12/trump-administration-christmas-gift-guide/685379/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The good news: We are saying “Merry Christmas” again. (It is now compulsory, or the FCC will come for your license.) The bad news: Christmas rationing is indeed in effect.

Please consider the following gifting instructions from our president, who is also tightening his belt this Christmas (only demolishing one wing of the White House to install a lavish ballroom instead of both).

For Grandma: A tariff! Did they not want tariffs? That’s what we got everyone. Sorry.

For Uncle Greg: A TINY CAR!!! (We’re making these now.)

For Her: A photoshoot with Vanity Fair. Nothing says “glamour” like Vanity Fair. Usually. But sometimes the picture they take of you comes out looking like Dorian Gray’s DMV photo—unflattering, but in a way that implies deep spiritual corruption. This gives a fun Russian-roulette aspect to the gift!

For the Man Who Has Everything: Surprise MRI for no reason! Donald Trump has everything and he keeps getting these, so they must be a fun, cool luxury item and not cause for any kind of alarm.

For the Historian: Piece of East Wing rubble, possibly haunted. Does someone in your life love history or respect White House traditions? Great! We have a bunch of junk to unload on a mark like her.

For the Frequent Flier: Air Force One, lightly used. We’ve just received a better plane from Qatar. If you fly private, you can wear whatever you want to the airport, even pajamas!

For the Vaccine-Skeptical: Measles. A special surprise from the Trump administration. Don’t know what to get your child? That might not be a problem next year.

For Everyone Else on Your List: AI Something? There’s demand for this, isn’t there? Please tell us there’s demand, or the whole economy is going to break.

For Your Uncle (You’ll Know Which One): This John McNaughton painting titled The Secret Service, which features Donald Trump and some angels.

For That Special Someone: A presidential pardon. Just because! You never know when one of these will come in handy. It’ll have everyone but the recipient saying “You shouldn’t have!,” especially when that special someone goes on to commit additional crimes.

For the Budding Artist in Your Life: One or two pencils. (“You can give up certain products … Every child [can’t] get 37 pencils. They only need one or two. They don’t need that many,” President Trump explained a few months ago.) We understand that this raises a question: Who was buying 37 pencils before? Are these colored pencils or just standard No. 2 Ticonderogas? We don’t know! Good luck with this oddly specific presidential instruction.

For Your Daughter: One doll, or, perhaps, if you are feeling indulgent, two! (“Two or three is nice. You don’t need 37 dolls.”  — the president, again.) Indeed, apply this guidance generally. Instead of a box full of crayons, consider one or two loose crayons! Instead of an advent calendar full of toys, consider an advent calendar empty of toys! Instead of a candy cane, consider no candy mobility aids at all, which reek of accessibility and imply concessions to Tiny Tim.

Remember, there’s nothing more disappointing than a tree that has too many presents under it. Then you can’t properly see the tree. Also remember that not having a job will build resilience. Donald Trump briefly did not have a job and now look at him. He’s King of the United States!

If you’re still feeling the pinch, consider culling your list. Don’t give any gifts to adults, unless that adult is Border Czar Tom Homan, in which case you can give him $50,000 cash in a discreet CAVA bag. There are two ways to remove people from your list: through attrition and through measles (see above).

If you’re still at a loss, maybe just get everyone one big egg (Large, Grade A). Or some coal!

Coal can be an amazing gift. Timeless. Classic. She is the moment, to quote something the Department of Energy actually posted on X.

Before buying, be sure to check where your gifts were manufactured! Gifts produced at the North Pole are unfortunately subject to tariffs, just as with the islands-uninhabited-except-by-penguins situation. Those penguins know what they did.</div>
        </div>
        
        <div class="card" onclick="openModal('content-10')">
            <div class="source">The Atlantic</div>
            <div class="title">Everything We Know About Rape Is Wrong</div>
            <div class="meta">2025-12-22</div>
        </div>
        
        <div id="content-10" style="display:none;">
            <h2>Everything We Know About Rape Is Wrong</h2>
            <p><strong>The Atlantic | 2025-12-22</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/culture/2025/12/girls-plays-dead-jen-percy-sexual-assault-book-review/685363/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">“There is no single anecdote,” Jen Percy writes in the opening sentence of Girls Play Dead, her riveting, heartrending analysis of what sexual assault does to women. “What I’m talking about is an accumulation.” She lists a few of her own encounters with harassment and rape culture: the man who rubbed his crotch while staring at Percy and her friend; the man working a cash register who asked to touch her breasts; the man who asked to photograph her when she was 16, showing her an album of naked women. The point isn’t to interrogate the men who supposedly did these things, or whether they happened. (With regard to veracity, I have my own accumulation of similar anecdotes; I’m guessing most women do.) More useful is to consider what Percy did in response, what so many do when faced with sexually threatening behavior: nothing.

Girls are socialized to be pleasant. To be passive. To neutralize conflict rather than spark it. They learn to prioritize others’ feelings over their own. In 1988, the feminist legal scholar Robin West argued that these habits and behaviors help foster intimacy and community, but that they also diminish women’s protection under the law. If someone’s instinct is to preserve relationships and stability as a matter of survival, what do they do when they’re violently or sexually threatened? Not always something that might be construed as logical, or that might convince a jury that they have been gravely violated. The majority of women who are sexually assaulted don’t fight back, Percy notes. (In addition to “fight or flight” responses to danger, advocacy groups indicate that other common responses to rape include “freeze,” “flop,” and “friend,” or trying to placate one’s attacker.) She compiles a list of accounts from her reporting of things women have done after they were raped. “I made him chicken soup,” one woman tells her. “I comforted him because he was crying,” another says. Still another: “I told him I couldn’t wait to do it again.”

Girls Play Dead began as a feature Percy wrote in The New York Times Magazine about the phenomenon of “tonic immobility,” a self-preservation mechanism that leads people to freeze or become paralyzed when under attack. In the animal kingdom, mammals play dead so that a predator will lose interest in them; some female dragonflies do it to avoid mating. Percy encounters so many women who describe freezing as their response to sexual assault that she pronounces it a kind of “lingua franca.” (Men freeze too, she notes; her focus is largely but not exclusively on women.) “I just froze,” Lady Gaga said in an episode of the series The Me You Can’t See, while recalling the time she was raped at 19. “I just absolutely froze,” Brooke Shields said of her own rape in the documentary Pretty Baby. While I was reading Girls Play Dead, I watched a BBC documentary in which a woman, recounting being raped by her own boyfriend, said, “The fact that I froze—it’s a feeling that absolutely takes over your body. You can’t move.” Tonic immobility, Percy writes, is an “extreme response to a threat” that “renders victims unable to scream or move their limbs.” Its evolutionary benefit, she notes, is that by simultaneously numbing the body, it might—in the animal world at least—“alleviate the agony and horror of being eaten alive.”

Percy’s subject is brutal, but her writing allays some of the impact by being almost impossibly beautiful: crisp, vulnerable, lyrical. Her mother, a naturalist, raised her partly in the wilderness, where hills “were painted with belts of ochre, orange, brick-red sand.” Sometimes the pair slept in a trailer, “with its stale formaldehyde smell, lacquer table, and tiny fridge that gasped as if afraid.” She has a miniaturist’s eye for detail and a raw compassion in her analysis. Girls Play Dead isn’t a manifesto, or a call to action. It’s more like a scientist’s collection of samples from a field trip, arranged by genus. Percy observes and bears witness. She interviews women in prison for murdering their abusers, after describing their biographies at harrowing, hard-to-read length. She interviews self-professed sex and love addicts who experienced childhood abuse and whose understanding of emotional connection got distorted. (“Abuse, neglect, or drama—it was all mistaken for intimacy,” Percy writes.)

On first reading, some of Percy’s stories seemed strange or incongruous, like the man she profiles who’s utterly obsessed with a woman he broke up with a decade ago. But I came to understand that woven into her line of inquiry are the nature and significance of storytelling itself. Police investigations and criminal trials demand clear narratives: They tend to expect evidence to be neat, behavior to be logical, and stories to be linear. The questions that rape victims tend to face don’t allow for the kind of messiness that accompanies violation. Often survivors themselves try to make sense of what has happened by reinterpreting it. “Self-preservation doesn’t always look like what we imagine it does,” Percy notes. She describes once going home with a man while studying abroad in Spain, and all of the times she said no, until she finally stopped, because “I was tired and I didn’t want to be rude.” Later, she went to Paris with him. Illogical, maybe, but commonplace all the same, because occasionally our coping mechanisms require transforming an abuse into something wanted, or at least something not so bad.

Read: Unbelievable is TV’s most humane show

In a court of law, though, irrational reactions—such as a sustained relationship with an abuser—can fatally undermine a victim’s credibility. Defense lawyers, Percy writes, have a pronounced tendency “to portray the normal behavior of women, both during and after their experiences, as ‘unusual’ or ‘inconsistent.’” During the trial of Harvey Weinstein, his defense lawyers put significant emphasis on the fact that two of his accusers had continued friendly communication with him after their alleged attacks, and had even gone on to have consensual sex with him. “Many individuals may not understand why I had hoped that attempting human connection with the man who was sexually abusing me, humiliating me, using me, and pumping me into his world where he always controlled the script—was a long exhausting form of survival,” one accuser, Jessica Mann, read in a statement to the court during Weinstein’s sentencing hearing, by way of response. We are, as a culture, deeply uncomfortable with the idea of victimhood. (Consider the idiom “playing the victim.”) “Claiming victimhood,” Kate Manne writes in her book Down Girl, “effectively involves placing oneself at the center of the story.” And women who foreground themselves in any capacity are often perceived to be self-important drama queens, or narcissists.

Perhaps sensing this, Percy turns victims into a collective instead. Her stories, woven together, become something like a fabric, a totality. Messiness is the defining feature, in a way that becomes clarifying. Chronic stress damages the prefrontal cortex, she writes in one chapter, explaining how trauma can impair the brain so that her later accounts of women found guilty for acts of self-defense seem even more profoundly unjust. Girls Play Dead illuminates how stories can trap people, how the impulse to rewrite a violation or rescue an abuser leads us away from the truth. But Percy also seems to feel that showing us the texture and shared features of human experience might be the crucial thing that can make a difference. The law often renders women unprotected, maligned, and misunderstood. The only countermechanism, as Robin West wrote in 1988, “is to tell true stories of women’s lives,” in such breadth and definition that the justice system finally has to acknowledge what it’s been obscuring. Girls Play Dead is a vital continuation of this effort.

​When you buy a book using a link on this page, we receive a commission. Thank you for supporting The Atlantic.</div>
        </div>
        
        <div class="card" onclick="openModal('content-11')">
            <div class="source">The Atlantic</div>
            <div class="title">The Three-Step Guide to Fixing Affordability</div>
            <div class="meta">2025-12-22</div>
        </div>
        
        <div id="content-11" style="display:none;">
            <h2>The Three-Step Guide to Fixing Affordability</h2>
            <p><strong>The Atlantic | 2025-12-22</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/ideas/2025/12/affordability-housing-healthcare-prices/685377/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Earlier this month, Donald Trump took a break from his busy schedule of watching TV and overseeing the renovation of his taxpayer-financed mansion to rally his constituents. “They always have a hoax—the new word is affordability,” the president told a packed crowd in the Poconos. “You can give up pencils, because under the China policy, you know, every child can get 37 pencils. They only need one or two.” In a televised address a week later, he tried out an alternative argument: Inflation was the fault of Democrats and immigrants. Prices are “falling rapidly” now, he said. “Nobody can believe what’s going on.”

True enough, nobody can believe that prices are falling rapidly. Big-ticket necessities, including health care, housing, and child care, became wildly unaffordable over the past few decades. Then COVID led to a gigantic surge in general inflation. Then borrowing costs went up sharply, making credit-card bills and auto loans more expensive. Then utilities started going bananas, in part thanks to the AI data centers popping up all over the place. Then the trade war pushed up the cost of clothing, food, and other goods. Then Congress let an important health-insurance-subsidy program expire, meaning 22 million Americans will see their premiums spike next month.

Affordability is voters’ No. 1 issue by far. It propelled Trump back into office last year, as it propelled Zohran Mamdani, Mikie Sherrill, and Abigail Spanberger into office this year. Trump might be callous, but his comments—it’s not real, so buy less; it is real, but it’s getting better—point to the profound dilemma all politicians face when trying to address the cost-of-living crisis.

For one, affordability is a squidgy, subjective concept, based on what people believe they should be able to buy and the prices they believe they should have to pay. By the most straightforward, objective measures, Trump has a pretty good argument that the affordability crisis does not exist. Real disposable income is near its highest point in history, and Americans are buying more stuff than ever. Yet voters want prices to come down to where they were a few years ago, a shift that would likely never occur outside the context of a devastating recession. (Deflation would in and of itself cause the economy to shrink: Why buy something today if it will cost less tomorrow?)

Moreover, elected officials have a smaller toolbox to address prices than they have to address, say, rising unemployment or lackluster wages. “I used to go out to the cameras on the White House North Lawn and talk about the inflation report and the jobs report,” Jared Bernstein, Joe Biden’s chief economic adviser, told me. “I’d say, You had a great jobs report, but we know that prices are still too high, and we’re trying to help. And in the back of my mind, when we’re talking about groceries, I was always like, Well, yeah, there’s not much we can do.”

Many policies that would bring down prices in a durable fashion (such as a huge home-building push) would do nothing in the next few years. Many of the policies that would bring down prices in the short term (such as rent freezes) would generate shortages and lift costs over time. “We call it the affordability conundrum,” Neale Mahoney, an economist at Stanford, told me, referring to work he did with the policy adviser Bharat Ramamurti. “People want affordability now, and the tools we have don’t work on an immediate or short-term basis.” Even worse, many of the policies that sound good to voters (such as stimulus checks) would spike inflation, and many of the policies that would do a lot of good (getting rid of the tax exclusion for employer-sponsored health coverage, for instance) would be challenging to pass and challenging to implement.

What’s a policy maker to do? Three things, I learned by speaking with campaign operatives, pollsters, economists, think-tank types, and a lot of teed-off voters from across the political spectrum. Stop making things worse. Provide immediate relief. Then do the hard work of getting the most important prices down.

Today’s affordability crisis isn’t really one crisis. It’s several crises stacked on top of one another. And recent policy actions have made a few of them worse.

The cost of consumer goods soared during the coronavirus pandemic, and the White House’s tariff regime effectively slapped a $140 billion, regressive sales tax onto those same goods. The economy was growing decently and inflation was above the Federal Reserve’s target when the Trump administration passed a deficit-financed, inflationary super bill this summer. Americans were already paying twice as much for health care as citizens of other wealthy nations when Congress failed to restore the health-care subsidies.

Politicians could temper at least some of the country’s affordability crisis by doing less. Getting rid of the trade measures would put roughly $1,800 a year back into consumers’ pockets while increasing job creation and lifting the pace of GDP growth. Leaving the subsidies as is would prevent 22 million Americans from paying an average of $1,000 more a year for coverage. “It’s going to be really bad,” Drew Altman, the president of the Kaiser Family Foundation, told me of the looming price hike. “We’re not having an honest discussion about it.” Washington should also refrain from adding to the deficit, which amps up inflation and interest rates.

Yet undoing the bad choices and refraining from making new ones won’t be enough, for people or their bank accounts. Voters want radical policies that deliver instant relief. They want prices to go down. In polls, they say they want bans on price gouging, freezes on rental costs and utility bills, tax cuts, stimulus checks, and price controls.

The standard economic argument is that the voters shouldn’t get what they want, because a lot of those proposals would raise inflation or worsen the country’s affordability crisis in the long term. Take Mamdani’s promise to freeze the rent on roughly 1 million New York City apartments. The residents of eligible units would benefit. But people paying market rates or looking to buy a home would not, and the policy could fuel gentrification and dampen construction, pushing up real-estate costs in the long term. But what if the rent freeze were only temporary and lasted just long enough to give the city time to build more housing units? Maybe that’s not a bad trade.

Capping prescription-drug costs—perhaps the single most popular policy idea out there, embraced by voters of both parties—seems to be a reasonable quick fix for the health-care-cost crisis. But it wouldn’t do much, Altman said. Prescriptions account for less than 10 percent of overall health expenditures. Nevertheless, caps might still be worth implementing, helping the sickest Americans and delivering immediate relief to consumers.

Rate freezes on utility bills, similarly, aren’t much more than a Band-Aid. The average monthly energy bill has gone up 35 percent since 2022, and 12 percent in the past year alone. “There’s this disconnect between the private companies that are profiting off of energy markets and people’s struggles to keep the lights on,” Mike Pierce, the executive director of the advocacy group Protect Borrowers, told me. Climate change, the AI buildout, and the aging of the country’s utility systems threaten to hike costs in the future too. The country needs green-power plants, grid improvements, and public control over utility systems. But for now, the answer might be “stopping these companies” from raising rates, Julie Margetta Morgan, the president of the Century Foundation, told me.

The United States isn’t going to become affordable again unless Washington and the statehouses tackle three broken markets: housing, health care, and child care.

The country is short an estimated 5 million housing units, thanks to excessive zoning regulations, excessive community input, rising financing costs, and rising input costs. Washington doesn’t have a ready way to fill the gulf. State and local governments have control over nearly all of the relevant land-use rules, with the federal government working almost exclusively through mortgage and rental subsidies. The good news is that states are getting their act together: Governor Gavin Newsom signed more than 60 housing bills in California last year; Montana passed a massive package of land-use reforms in 2023. And Congress is finally starting to figure out policies to push towns and cities to build.

Will houses really be cheaper in the future? Austin, Texas, shows that they could be: Asking rents dropped 16 percent from the end of 2023 to the end of 2024, thanks to “an influx of new supply,” as Redfin explained.

As for health costs, well, “there has never been a meaningful, national effort” to hold them down, Altman said. (The Affordable Care Act expanded coverage but didn’t do much on prices.) As a result, health care pushes half a million Americans into bankruptcy a year, and excess spending acts as a miserable tax on every family’s budget.

The problem is structural. “Most people get health benefits through their employer—they’re exempt from payroll taxes, they’re exempt from income taxes, and employers can deduct them as a cost of doing business,” Meredith Rosenthal of the Harvard T.H. Chan School of Public Health explained. The situation “drives unaffordability,” she told me. Employers have a reduced incentive and little leverage to demand low-cost plans. Employees can’t effectively shop around. She and Altman also pointed to hospital consolidation and a lack of price controls as core issues.

Neither Democrats nor Republicans have shown much interest in wringing money out of the system. Legislation to do so would be challenging to put together, unpopular among the hospital systems that are many regions’ largest employers, and potentially disruptive to Americans’ coverage. Yet it would boost wages, reduce inequality, and improve family finances in a way that nothing other than reducing housing costs would.

Trump, for his part, seems to want to somehow get rid of insurance at a conceptual level. “I want to give billions of dollars directly to the people,” he said. “I want to give all of that money we give to the big, fat, rich insurance companies, and I want to give them nothing.” But without insurance, only the very richest Americans would be able to afford cancer treatment or a C-section. Hospitals would shut down. The broken market would fall apart.

Last, there’s child care, a ruinous, if temporary, expense. Parents pay the equivalent of a second mortgage. Day-care centers offer poverty wages to workers. Far too few families get affordable, high-quality care, pushing millions of women out of the labor market. Connecticut and New Mexico are setting up publicly financed universal-child-care systems, and the federal government should consider doing the same on a national level. “These things would be expensive,” Lena Bilik of the Roosevelt Institute told me. “But think of all the foregone wages and the lost economic security when people have to step back from work for any kind of unpaid caregiving.”

The affordability crisis is the problem, one that has been with us for decades and will be with us for decades unless politicians get their act together. It is sapping wages and imperiling families’ financial security. It’s driving political instability and voter frustration. It’s stopping people from having kids, starting businesses, going to college, living where they want, and retiring when they need to.

Prices “are all coming down and coming down fast,” Trump promised. That isn’t true. But hopefully someday it will be.</div>
        </div>
        
        <div class="card" onclick="openModal('content-12')">
            <div class="source">Slashdot</div>
            <div class="title">Samsung Is Putting Google Gemini AI Into Your Refrigerator, Whether You Need It or Not</div>
            <div class="meta">2025-12-22</div>
        </div>
        
        <div id="content-12" style="display:none;">
            <h2>Samsung Is Putting Google Gemini AI Into Your Refrigerator, Whether You Need It or Not</h2>
            <p><strong>Slashdot | 2025-12-22</strong></p>
            <a class="original-link" href="https://slashdot.org/story/25/12/22/120248/samsung-is-putting-google-gemini-ai-into-your-refrigerator-whether-you-need-it-or-not?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Catch up on stories from the past week (and beyond) at the Slashdot story archive

They&#39;re going to have a hard time getting Gemini to not explain to consumers why their ice maker isn&#39;t working or any of the other widespread Samsung refrigerator problems of the last 15 years.

On the other hand, at least it&#39;s not Bixby.

Smart devices have been spying on you for years now. Don&#39;t buy a fridge that spies on you.

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

All Finagle Laws may be bypassed by learning the simple art of doing
without thinking.</div>
        </div>
        
        <div class="card" onclick="openModal('content-13')">
            <div class="source">Slashdot</div>
            <div class="title">Welcome To America's New Surveillance High Schools</div>
            <div class="meta">2025-12-22</div>
        </div>
        
        <div id="content-13" style="display:none;">
            <h2>Welcome To America's New Surveillance High Schools</h2>
            <p><strong>Slashdot | 2025-12-22</strong></p>
            <a class="original-link" href="https://news.slashdot.org/story/25/12/22/1154232/welcome-to-americas-new-surveillance-high-schools?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Catch up on stories from the past week (and beyond) at the Slashdot story archive

IN 90210 they have the funds to overpay for shirty tech with nice kickbacks

My high school didn&#39;t even allow doors on the bathroom stalls.  You might want or expect privacy but you are unlikely to get it.

And those &quot;Listening Devices&quot; are a direct violation of the 4th amendment.I&#39;m glad I&#39;m not the only one who found the idea of a listening device in bathrooms creepy and mortifying.I think it will take a court case to decide whether a minor has an expectation of privacy for their conversations in a public bathroom. While that makes sense, I&#39;m sure someone can make a plausible case that this is OK. Video cameras would be something else.

And those &quot;Listening Devices&quot; are a direct violation of the 4th amendment.

I&#39;m glad I&#39;m not the only one who found the idea of a listening device in bathrooms creepy and mortifying.

I think it will take a court case to decide whether a minor has an expectation of privacy for their conversations in a public bathroom. While that makes sense, I&#39;m sure someone can make a plausible case that this is OK. Video cameras would be something else.

Imagine if those millions of dollars were spent on teaching students.

You have to wonder if the false positives are intentional.  If not for false positives, they would hardly flag anything at all and people would think they aren&#39;t working.

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

interlard - vt., to intersperse; diversify
-- Webster&#39;s New World Dictionary Of The American Language</div>
        </div>
        
        <div class="card" onclick="openModal('content-14')">
            <div class="source">Slashdot</div>
            <div class="title">iRobot Founder Says FTC Treated Blocked Deals 'Like Trophies' as Bankruptcy Follows Failed Amazon Acquisition</div>
            <div class="meta">2025-12-22</div>
        </div>
        
        <div id="content-14" style="display:none;">
            <h2>iRobot Founder Says FTC Treated Blocked Deals 'Like Trophies' as Bankruptcy Follows Failed Amazon Acquisition</h2>
            <p><strong>Slashdot | 2025-12-22</strong></p>
            <a class="original-link" href="https://slashdot.org/story/25/12/22/1147243/irobot-founder-says-ftc-treated-blocked-deals-like-trophies-as-bankruptcy-follows-failed-amazon-acquisition?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Slashdot is powered by your submissions, so send in your scoop

The regulators weren&#39;t going to block the deal because they wanted iRobot to die, nor because they wanted it to remain in Collin Angle&#39;s hands.  They were going to block the deal because they didn&#39;t want Amazon to have it.  The concern was that Amazon&#39;s position of being both a producer AND owner of a global marketplace would put them in a position of too much economic power.

Further, the FTC did not eliminate a choice for consumers.  iRobot was already losing to the competition.  This bid to be bought was a

Put me in charge and we&#39;ll go back to 1 TV station per owner, cable companies can&#39;t own TV stationsIOW undoing the works of Bill Clinton.If only more people understood how the TCA led to the rise of Faux News we might have some clarity.

Put me in charge and we&#39;ll go back to 1 TV station per owner, cable companies can&#39;t own TV stations

If only more people understood how the TCA led to the rise of Faux News we might have some clarity.

Every law should go under some sort of adversarial review.  Even the most beneficial sounding law can have major unintended consequences or well-disguised intended ones.   I do think that nationwide cell networks would not have been what they are today (in a good way) without TCA, but that&#39;s partly because we wouldn&#39;t have done any other regulation to create the roaming cooperation that would be needed.

He entered the process &quot;looking for a friend&quot; A CEO was looking for a friend?

He entered the process &quot;looking for a friend&quot;

A CEO was looking for a friend?I thought rich people like that had people that can &quot;find a friend&quot; for them. That way they avoid Solicitation of Prostitution charges.

I thought rich people like that had people that can &quot;find a friend&quot; for them. That way they avoid Solicitation of Prostitution charges.

Amazon already does a lot with robotics in their warehouses.  It&#39;s possible they wanted to buy just the brand name.  It&#39;s also possible that it was worth it for some patent that should have never been granted.  They do have a habit of buying up home automation companies and just doing very little with it.  They have two brands that both have doorbells and security camera (Blink and Ring) and they don&#39;t even work together.

Irobot was built on 1980 technology.  At the time, it was state of the art.  The Chinese are not stupid.  Its heyday ended quite a while ago.

In theory, antitrust is enforcement on mergers is crucial to prevent damaging monopolies. In practice, we still end up with companies exerting monopoly power.

The problem with antitrust enforcement is that it becomes entirely political. There are only a few dozen transactions a year that might theoretically create serious antitrust concerns. Which ones get looked at/shut down seems to be more dependent on who is in the white house and the political connections at the companies involved than the merits of the

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

interlard - vt., to intersperse; diversify
-- Webster&#39;s New World Dictionary Of The American Language</div>
        </div>
        
        <div class="card" onclick="openModal('content-15')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">Democrats Are Ending the Year on a Particularly Dumb Note</div>
            <div class="meta">2025-12-22</div>
        </div>
        
        <div id="content-15" style="display:none;">
            <h2>Democrats Are Ending the Year on a Particularly Dumb Note</h2>
            <p><strong>News and Politics - Slate Magazine | 2025-12-22</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2025/12/porch-pirates-act-democrats-end-the-year-fail.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Sign up for the Slatest to get the most insightful analysis, criticism, and advice out there, delivered to your inbox daily.

Earlier this month, shortly after a series of Democratic wins in off-year elections, in the government shutdown, and in nosediving polls for President Donald Trump, a number of key Democrats made some unusual choices. First, New Jersey Democratic Rep. Josh Gottheimer began once again hawking the “Porch Pirates Act,” a bill that nobody seemed to have asked for and which could come back to haunt his party if passed. Then, this week, the Democratic National Committee announced it would not release its highly anticipated 2024 autopsy report.

Why, amid its first signs of life since the devastating 2024 election results, is the party seemingly determined to take multiple steps backward?

Let’s start with Gottheimer and porch pirates. Standing proud at a podium set up in his home district on Dec. 1, Gottheimer preached how private companies like Amazon, United Parcel Service, and FedEx should receive even greater protections than the federal agency the United States Postal Service. Currently, it’s a federal crime to steal mail out of any USPS post office, letter box, or mail receptacle, with violators facing a fine and prison time of no more than five years. The Porch Pirates Act would expand on this, adding Americans’ porches to the protected mail space, and it would make stealing a package from a private porch a federal crime with punishment of up to 10 years in prison and $250,000 in fines.

The legislation would also give the Federal Bureau of Investigations, Justice Department, and federal task forces the authority to “fully investigate porch theft.” There are already laws on the books that cover these sorts of thefts and any potential greater conspiracies that might be involved in them. The Porch Pirates Act is not only redundant, it is excessively punitive, especially when Democrats have spent multiple general election cycles in a row battling the image among younger voters of having boosted mass incarceration during the 1990s. It seems unwise to reopen this fight.

The Porch Pirates Act was first introduced back in 2022, but has since seen basically no movement in Congress. Last year, Democrat Dean Phillips, a former representative and sponsor of the bill, went so far as to film a video where he shadowed a UPS driver who seemed amused at best to be sharing his route with a congressman. The final product looks and sounds alarmingly like a paid UPS commercial rather than a genuine explanation for why the Porch Pirates Act is necessary. Now, it seems like Gottheimer is taking a stab at attempting to push the legislation forward.

Let’s be clear, out of all the problems American consumers are currently facing, like the impending explosion of health care costs, stubbornly high inflation on everyday goods, and rising unemployment, why do some Democrats view package theft as among voters’ top concerns? (A previous version of the bill had 17 Democratic co-sponsors, though it’s unclear how many this one has.)

Besides the irrelevant nature of the Porch Pirates Act, it also stands to significantly contribute to the country’s mass incarceration problem. Penalizing thieves for stealing some Amazon packages with prison time and fines in the hundreds of thousands would drag an already overburdened criminal justice system down even further, inevitably also increasing the cost of running state and federal prisons. It’s well documented that mass incarceration leads to poor physical, psychological, and economic outcomes for people who experience imprisonment, which ends up hurting all American communities.

The USPS Office of Inspector General even published a white paper earlier this year acknowledging the pesky problem of package theft, and recommended collaborative strategies—not criminal penalties. “Offering and making use of flexible and secure delivery options, leveraging technology for enhanced tracking and theft prevention, [and] utilizing discreet packaging and package delivery placement” were among the recommended solutions.

The Porch Pirates Act also threatens to be a repeat of the infamous crime bill of the 1990s that led to a consistent rise in incarceration rates for the following decade, and which Democrats paid for dearly. The party surely does not want to be responsible for adding yet another pathway to prison.

Unfortunately, it appears Democrats are keen to end 2025 on the wrong foot. Instead of acknowledging its faults and reckoning with its consistently low approval ratings this year, the Democratic National Committee decided to continue ignoring its problems by scrapping the public release of its 2024 autopsy report. Claiming it would simply distract and divide the party, the lack of accountability now sets the stage for Democrats to repeat the same grave mistakes in the 2026 midterms and beyond. Party establishment gets to continue its iron grip, no fundamental changes will be made to Democrats’ platform, but hey, at least they can say they fought for Americans’ porches.

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-16')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">The Democrats Had One Huge Shutdown Win. Trump Tried to Thwart It. He Just Failed.</div>
            <div class="meta">2025-12-22</div>
        </div>
        
        <div id="content-16" style="display:none;">
            <h2>The Democrats Had One Huge Shutdown Win. Trump Tried to Thwart It. He Just Failed.</h2>
            <p><strong>News and Politics - Slate Magazine | 2025-12-22</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2025/12/democrats-shutdown-win-trump-firings-blocked.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Sign up for the Slatest to get the most insightful analysis, criticism, and advice out there, delivered to your inbox daily.

Ever since he returned to the White House, President Donald Trump has taken a sledgehammer to the federal workforce, attempting to purge tens of thousands of civil servants and shutter entire agencies. The Supreme Court has largely rubber-stamped these mass layoffs, even when they frustrated congressional commands expressly intended to direct, structure, and constrain the executive branch. Last month, however, Congress struck back in a little-noticed move that shifted power away from the Trump administration by outlawing further illegal firings and reversing those already underway. And on Wednesday, U.S. District Judge Susan Illston issued an injunction enforcing the new law, rejecting the government’s brazen attempt to defy it.

On this week’s Slate Plus bonus episode of Amicus, co-hosts Dahlia Lithwick and Mark Joseph Stern discuss the ruling and its encouraging implications for the separation of powers and a bolstered Congress subject to a president who refuses to acknowledge most limits on his authority. Their conversation has been edited and condensed for clarity.

Dahlia Lithwick: Judge Susan Illston has been battling the administration over these layoffs for months now. Why was this latest round different?

Mark Joseph Stern: Because Congress did something that was long overdue—it wrote a statute that tightly constrains the executive branch. And Illston actually enforced it as written against the Trump administration.

Recall that during the shutdown, the president moved forward with mass layoffs across a bunch of federal agencies. They were euphemistically called “reductions in force.” People lost their jobs, their paychecks, their housing, even overseas postings. It was a disaster. And Trump claimed that the shutdown gave him broader leeway to purge the civil and foreign service and also to use those layoffs to inflict pain on Democrats because they were refusing to capitulate and reopen the government.

When Congress finally did end the shutdown on Nov. 12 and reopened the government, the funding bill that it passed included a provision that directly reversed Trump’s layoffs in two ways. First, the bill declared that “no federal funds may be used to initiate, carry out, implement, or otherwise notice a reduction in force” through late January, when funding expires again. That language clearly bars any further steps to lay off federal employees through the end of next month. Second, the bill said that any reduction in force “proposed, noticed, initiated, executed, implemented, or otherwise taken” during the shutdown “shall have no force or effect.” That language clearly reinstates any federal employee who was either told they’d be laid off during the shutdown or actually laid off.

To no one’s surprise, the administration immediately tried to repeal that language by reinterpreting it to mean almost nothing. Russell Vought—a Project 2025 author and now the director of the Office of Management and Budget—decreed that the first provision barred the government only from sending additional RIF notices through January but would allow it to complete the many, many layoffs that had already been initiated. Vought then said that the second provision applied only if a layoff notice went out during the shutdown. He claimed that if the employee had been warned earlier in the year that they were going to be fired and the actual firing happened during the shutdown, then the layoff was still lawful. The Trump administration tried to exploit that ridiculous interpretation by rescinding layoff notices that had been sent during the shutdown and immediately reissuing them to say: You have a new notice that came after the shutdown, so we can legally fire you.

On Wednesday, Illston shut this down. First, she said that there can be no layoffs through January, period. The bill announced that no federal funds can be used to carry out or implement RIFs. That means what it says. It does not allow the administration to fire people who previously received a notice that they’d be fired. Second, the judge ordered the reinstatement of everyone who was either told they’d be fired or actually fired during the shutdown. Remember, Congress reversed any RIF that was “noticed,” “executed,” or “implemented” during the shutdown. That covers everybody who was subject to any aspect of the RIF process. So, thanks to Illston’s order, all of those people now get their jobs back. That covers hundreds of employees right now, and possibly thousands more in the coming month, given the plans that Vought was developing for another round of the purges that Congress had outlawed.

How is it that congressional Republicans allowed this language? Did it just escape their notice? Were they secretly opposed to the RIFs as well?

No—this was a bargain struck by Senate Democrats. Republicans needed their help to end the shutdown, and a group of Democrats conditioned their votes on statutory language that would halt the RIFs. All Illston is doing here is enforcing that language in the face of the Trump administration brazenly defying Congress. I know that her decision will prompt another round of allegations that Illston is a “resistance judge”—especially since she tried to halt the RIFs earlier this year and the Supreme Court reversed her on the shadow docket. But there’s a difference between what happened in July and what’s happening now: The law has changed! Democrats in Congress saw that the existing law gave too much discretion to the executive branch. And they decided that if they were going to end the shutdown, they would at least force Congress to reassert its power and end that discretion.

That was, I think, a hugely successful move, not just for the Democratic Party and the civil service, but for Congress’ standing as a coordinate branch of government. We have been waiting for this since Trump came back into the White House. Congress has ceded the field to the presidency for nearly 11 months. It has handed over all of these powers to Trump, and the Supreme Court has overturned almost any judge who tries to kind of protect Congress’ prerogatives. Here, finally, we have Congress saying, in the most explicit language possible: We have the power of the purse. The money that we are appropriating may not be used by the Trump administration to purge the civil service. That gives me the first glimmer of hope I’ve had in a very long time that Democrats will be able to use their leverage to reassert Congress’ primacy over funding, rein in some of the White House’s abuses of power, and give SCOTUS no choice but to enforce the laws that they enact against him.

In one sense, this is a preliminary injunction from a single judge in a blue state that some will write off as “Trump derangement syndrome.” But for you, this is a masterclass in what Democrats can do—from the minority—when they theoretically have no power. This is, as you say, a flex for Congress. It’s a flex for text and statutory language. It’s a flex for using negotiations to leverage congressional prerogatives that have just been ceded to the executive branch.

And let’s also take a step back: Senate Democrats shouldn’t have been in this position in the first place. Trump’s mass layoffs were illegal. Congress did not allow him to dismantle these agencies by purging their workers. The courts should have been able to stop that. But the Supreme Court consistently stepped in and reversed them on the shadow docket, seemingly on the grounds that the executive branch has a lot of discretion and the statutes don’t tell us exactly what Congress wanted.

So the problem wasn’t just Trump abusing his power. It was also SCOTUS taking advantage of ambiguous statutory language and gaps that nobody had previously thought to exploit in the law. Congressional Democrats correctly identified that as one of the foundational issues here: not just Trump’s abuses, but the way the court was able to green-light those abuses. So they wrote language that would explicitly block Trump from misusing his power and force the courts, including SCOTUS, to implement congressional prerogatives. I do think that Illston will be upheld on appeal; I’m not even sure that the administration will try to appeal this to the Supreme Court. This is cut-and-dried, because Democrats in Congress saw the gaps that needed to be plugged and plugged them.

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-17')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">Which Type of Animal Is a <em>Natterjack</em>?</div>
            <div class="meta">2025-12-22</div>
        </div>
        
        <div id="content-17" style="display:none;">
            <h2>Which Type of Animal Is a <em>Natterjack</em>?</h2>
            <p><strong>News and Politics - Slate Magazine | 2025-12-22</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2025/12/trivia-quiz-daily-slate-vocabulary-sanskrit-hieroglyphics-animals.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Please enable Javascript in your browser to view Slate interactives.

Slate Crossword: Alanis Morissette Sang About It … Kind Of … (Five Letters)

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-18')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">People are getting their news from AI—and it's altering their views</div>
            <div class="meta">2025-12-22</div>
        </div>
        
        <div id="content-18" style="display:none;">
            <h2>People are getting their news from AI—and it's altering their views</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2025-12-22</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2025-12-people-news-ai-views.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-19')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">Italy fines Apple nearly 100 mn euros over app privacy feature</div>
            <div class="meta">2025-12-22</div>
        </div>
        
        <div id="content-19" style="display:none;">
            <h2>Italy fines Apple nearly 100 mn euros over app privacy feature</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2025-12-22</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2025-12-italy-fines-apple-mn-euros.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-20')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">Uber and Lyft plan to bring robotaxis to London in partnerships with China's Baidu</div>
            <div class="meta">2025-12-22</div>
        </div>
        
        <div id="content-20" style="display:none;">
            <h2>Uber and Lyft plan to bring robotaxis to London in partnerships with China's Baidu</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2025-12-22</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2025-12-uber-lyft-robotaxis-london-partnerships.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-21')">
            <div class="source">The Register</div>
            <div class="title">What the Linux desktop really needs to challenge Windows</div>
            <div class="meta">2025-12-22</div>
        </div>
        
        <div id="content-21" style="display:none;">
            <h2>What the Linux desktop really needs to challenge Windows</h2>
            <p><strong>The Register | 2025-12-22</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2025/12/22/what_linux_desktop_really_needs/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Opinion I&#39;ve run Linux desktops since the big interface question was whether to use Korn or Bash for your shell. Before that, I&#39;d used Unix desktops such as Visix Looking Glass, Sun OpenWindows, and SCO&#39;s infamous Open Deathtrap Desktop.

Unless you&#39;re a fellow gray-haired computer or Unix geek, chances are you&#39;ve never heard of, never mind used, any of these. Fast-forward to 2025, there are more than a dozen significant Linux desktop interfaces. These include GNOME, KDE Plasma, Cinnamon, MATE, and on and on. They&#39;re all too likely to be as forgotten as the first three Unix interfaces I named. Why? The same reasons you don&#39;t know a thing about the Unix desktops.

First, though, why you might want to get the hell away from Windows while the going is good. Besides the usual security crap – 41 zero-day CVEs so far in 2025 at the time of writing – there have been new features such as Microsoft Recall, a privacy disaster disguised as a feature. Then there&#39;s the way Microsoft is forcing AI functions down our throats. If I wanted Copilot when I&#39;m making a grocery list in Notepad, I&#39;d… wait a second. I&#39;ll never want an AI program looking over my shoulder in a simple note app and then reporting to Microsoft that I&#39;m picky about my green peppers.

I&#39;m old fashioned about my desktops. I want the power in my PC, not in the cloud. I also want to control what does and doesn&#39;t get sent to the cloud. I&#39;m looking at you, OneDrive, with your obnoxious habit of being the default for saving files.

I also like my old, but not yet ancient, PCs to keep working. Just because I still have PCs with Intel&#39;s eighth, ninth, and tenth-gen Core chips under the hood shouldn&#39;t mean Windows 11 won&#39;t run on them – but here we are.

These reasons alone have given the Linux desktop a boost. By my count, as much as 11 percent of the desktop market is now running Linux one way or another.

That&#39;s great, but much of that counts Chromebooks rather than traditional PC-centric desktops. So, what do we need to make the fat Linux desktop succeed?

Unix died because of endless incompatibilities between versions. Linux succeeded on servers and everywhere else because it provided a single open operating system that everyone could use. With the desktop, though, we saw, and still see, endless incompatibilities.

Linus Torvalds also saw this. He&#39;s long thought that we have way too many desktops. He&#39;s right. If someone goes to DistroWatch, they&#39;ll find upwards of a hundred desktops. Who has time to figure out what&#39;s best? I don&#39;t, and I cover this stuff for a living, and once ran a site called Desktop Linux.

That&#39;s just the surface of the problem. Under that, you&#39;ll find arguments over how to manage software packages and the library incompatibilities they must deal with. Distro builders constantly have fits building and rebuilding programs to run on their Linux distros. The traditional ways of delivering Linux desktop apps, such as DEB and RPM package management systems for Debian and Red Hat Linux, respectively, simply don&#39;t scale for the desktop.

We have the answer: A containerized software package delivery program that bundles all required dependencies into a single, useful package. Today, we should all be using Flatpaks, Snaps, and AppImages to install programs instead of worrying about library incompatibilities and the like. This also saves vendors a lot of time since they can deliver a universal version of their program that will install and run on anyone&#39;s Linux desktop without the hassle of porting it to each and every distro.

The problem? It&#39;s fragmentation once again. Some people hate containerized packages because they use more storage space and RAM than old-style programs. Others dislike one or the other packaging system for other reasons. For example, my favorite desktop operating system is Linux Mint. However, Mint&#39;s leaders don&#39;t like Snap because its parent company, Canonical, has too much control over the Snap store and has used Snap to replace some of the apt package installation program&#39;s functionality.

The problem is that everyone has their own reasons for preferring their special sauce for the desktop. No one&#39;s sauce is special enough to get Windows users to move to any particular distro.

Another problem, as Torvalds pointed out in 2019, is that while some major hardware vendors do sell Linux PCs – Dell, for example, with Ubuntu – none of them make it easy. There are also great specialist Linux PC vendors, such as System76, Germany&#39;s TUXEDO Computers, and the UK-based Star Labs, but they tend to market to people who are already into Linux, not disgruntled Windows users. No, one big reason why Linux hasn&#39;t taken off is that there are no major PC OEMs strongly backing it. To Torvalds, Chromebooks &quot;are the path toward the desktop.&quot;

Just look at Android, he argued. Linux won on smartphones because, while there are different Android front ends, under their interfaces, there&#39;s a single, unified platform with a unified way to install programs. He&#39;s right.

I still hope that the Linux desktop will be successful. Indeed, I think it may yet win by default. As Microsoft moves ever closer to a cloud-based computer approach, Linux may be the last &quot;true&quot; desktop standing. It won&#39;t be as much of a win as we first dreamed of when we came up with the &quot;Year of the Linux desktop&quot; tagline, but it will still be a win. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-22')">
            <div class="source">The Register</div>
            <div class="title">EU offers UK early gift: Data adequacy until 2031</div>
            <div class="meta">2025-12-22</div>
        </div>
        
        <div id="content-22" style="display:none;">
            <h2>EU offers UK early gift: Data adequacy until 2031</h2>
            <p><strong>The Register | 2025-12-22</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2025/12/22/eu_uk_data_adequacy/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The EU has extended its adequacy decision, allowing data sharing with and from the UK under the General Data Protection Regulation for at least six more years.

This will be some relief to techies in the UK and the member state block and beyond whose work or product set depends on the frictionless movement of data between the two, especially as they can point to the 2031 expiration date as a risk managing aspect to backers and partners. But the move does have its critics.

After GDPR was more-or-less replicated in UK law following the nation&#39;s official departure from the EU, the trading and political bloc made its first adequacy decision to allow sharing with a specific jurisdiction outside its boundaries.

In a statement last week, the European Commission — the executive branch of the EU — said that it was renewing the 2021 decision to allow the free flow of personal data with the United Kingdom. &quot;The decisions ensure that personal data can continue flowing freely and safely between the European Economic Area (EEA) and the United Kingdom, as the UK legal framework contains data protection safeguards that are essentially equivalent to those provided by the EU,&quot; it said.

In June 2025, the Commission had adopted a technical extension of the 2021 adequacy decisions with the United Kingdom – one under the GDPR and the other concerning the Law Enforcement Directive – for a limited period of six months, as they were set to expire on 27 December this year.

The renewal decisions will last for six years until 27 December 2031 and will be reviewed after four years. It followed the European Data Protection Board&#39;s opinion and the Member States&#39; approval.

Following the UK&#39;s departure from the EU, the Conservative government originally made plans to diverge from EU data protection law, potentially jeopardizing the adequacy decision. In 2022, for example, then digital minister Michelle Donelan said that the UK planned to &quot;seize this post-Brexit opportunity fully, and unleash the full growth potential of British business,&quot; claiming: &quot;We can be the bridge across the Atlantic and operate as the world&#39;s data hub.&quot;

These proposals never made it into law. Since the election of a Labour government, Parliament has passed the Data Use and Access Act.

The government promised the new data regime would boost the British economy by £10 billion over the next decade by cutting NHS and police bureaucracy, speeding up roadworks, and turbocharging innovation in tech and science.

The Act also offers a lawful basis for relying on people’s personal information to make significant automated decisions about them, as long as data processors apply certain safeguards.

None of this has been enough to upset the EU, it seems. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-23')">
            <div class="source">The Register</div>
            <div class="title">Vultures rake our claws over COSMIC as Pop OS 24.04 LTS with 'Epoch 1' emerges</div>
            <div class="meta">2025-12-22</div>
        </div>
        
        <div id="content-23" style="display:none;">
            <h2>Vultures rake our claws over COSMIC as Pop OS 24.04 LTS with 'Epoch 1' emerges</h2>
            <p><strong>The Register | 2025-12-22</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2025/12/22/popos_2404_cosmic_epoch_1/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Hands On It&#39;s been a long time coming but version 1.0 of the first ground-up Rust-based desktop is here… and it is shaping up very well.

Late last week, System76 officially released the long term support version of its in-house Ubuntu remix along with &quot;Epoch 1&quot; of its in-house desktop environment COSMIC, implemented from scratch in Rust. After testing out the beta version in VMs and on an old clunker, we tried it on a more modern testbed, and we are grudgingly impressed.

The COSMIC desktop has been quite a long time coming, but building a whole new desktop is not a trivial exercise. The Register first reported on the project just over four years ago. We looked at the alpha test release in September, and later the beta version. Now, as promised at the Ubuntu Summit last month, version 1.0 of the COSMIC desktop is here, as well as its native distro, the Ubuntu Noble-based Pop!_OS 24.04.

We have been testing it out on the highest-end of our old Thinkpads, a W520. It works and makes this nearly 15-year-old PC feel remarkably fast, but we experienced regular freezes, for instance when opening a bunch of Firefox tabs. Up to a point, that is fair enough: the machine has long-supported Nvidia Quadro 1000 second GPU, which was last supported by NVIDIA&#39;s Linux drivers three whole major versions ago. We&#39;re rather surprised it worked at all, let alone worked well. So, decided it would be fairer to try it on the newer Reg FOSS desk testbed, a Dell XPS 13 9370.

COSMIC handles two screens with aplomb, which is more than we can say for its screenshot tool – click to enlarge

This is not a trivial exercise. Pop!_OS uses the systemd-boot boot loader instead of GRUB. That keeps the files for the Linux kernel and initramfs inside the PC&#39;s EFI System Partition. Dell only configures a paltry 100 MB ESP, and the release version of Pop!_OS refuses to install. Using the very latest Gparted Live 1.70-12, released just a few days before, we shrank the Windows 11 partition, moved its start 900 MB later on the disk, and then tried to enlarge the ESP. It didn&#39;t work. Just as we reported way back in 2021, the underlying disk-resizing tool used by GParted can&#39;t handle FAT32 volumes this small. It still throws an error and says &quot;we&#39;re working on it.&quot; Well, the GNU Parted team isn&#39;t working on it with any urgency, because it&#39;s still broken over four years later.

We worked around this by temporarily copying the EFI files somewhere else, deleting the tiny ESP, making a new one of 1000 MB, copying the Windows and Debian files back into it, and then installing a clean new copy of Pop!_OS. The new distro works fine, but for now, we can no longer boot Windows 11 or Debian. Summary: watch out – Pop!_OS still does not play nicely with dual boot.

It also defaults to some memory-management settings that wouldn&#39;t be our first choice. It configures two levels of swap: ZRAM memory compression, then an much lower-priority encrypted swap file on disk – although it seemed happy to use an existing dedicated swap partition, it still encrypted it. The Dell XPS 13 has 16 GB of non-upgradable RAM, which isn&#39;t much but isn&#39;t desperate, and it does have a fast SSD. So we wanted our favored performance optimizations, with a more conventional, single-level swap setup. We removed ZRAM by removing the config package:

Then we disabled encryption and rebooted. Next, we added the existing swap partition to /etc/fstab, rebooted, and checked it was working. Then, we enabled swap compression: Zswap instead of ZRAM. Rather than swapping to a compressed RAMdisk, and if that fills, spilling to an encrypted swap file or partition, this way the kernel compresses data as it&#39;s written to a swap drive instead. It keeps more RAM free, reduces the amount of data written to swap, and also reduces SSD wear. To do this with systemd-boot, we edited /boot/efi/loader/entries/Pop_OS-current.conf and added zswap.enabled=1 to the end of the kernel line. Another reboot and all was well, and very fast indeed.

On this less-compromised hardware, Pop!_OS never missed a beat. We added an external USB-C screen, and a USB-C dock for an external keyboard and mouse. It handled these fine, including sleep and resume, docking and undocking, and moving apps between different desktops. We tried to load it up with a large Flatpak Electron app, the Ferdium multi-protocol chat client, and an Electron Appimage (the Panwriter Markdown editor, and both Firefox and Chrome, all at the same time. It never perceptibly slowed, and the combination of automatic window tiling and dynamic virtual desktops kept things usable even on a small screen.

COSMIC is still version 1.0 and it does feel like it in places. It doesn&#39;t always pick up changed settings immediately. Some parts are a bit clunky. The main panel easily gets overcrowded, and it doesn&#39;t work very well in vertical orientation – but it works at all, and at least it&#39;s an option, unlike in Windows 11. You can have a panel and a dock, or just one or the other, or a taskbar, whatever you want – even status icons – without messing around with extensions, unlike in GNOME.

Even so, what&#39;s here is good and it&#39;s certainly usable. We would go so far as to say that in terms of Wayland desktop environments, at the end of 2025, this is the state of the art. Windows snap open; press Windows+T for a terminal, and immediately you&#39;re looking at a bash prompt. We downloaded the Panwriter appimage, made a new folder, moved it into it, all by just guessing the keystrokes, and it worked perfectly. Alt+Enter for the file properties did not work, but one right-click later, we added execute permission, and it just worked – first time. Firefox and Chrome picked up the settings from the previous install of CachyOS which used the same home directory; Firefox even reopened our last browsing session. A full installation only took about 8 GB of disk space, although it did use a lot of RAM – htop reports 1.6 GB in use at idle.

COSMIC isn&#39;t pretty, but it&#39;s not hard on the eyes either. It&#39;s a little clunky in places. The fake menu bar in some COSMIC apps doesn&#39;t work very well, but it&#39;s better than a hamburger menu. Not many standard CUA-style keyboard shortcuts work, but that&#39;s also true of both GNOME and KDE, and they&#39;ve both had over a quarter of a century to get this right.

There are already some add-on applets available in the COSMIC app store, such as both minimal and full-featured Start-menu equivalents. It has also made its way into multiple distros already, and by early 2026 you should see COSMIC Epoch 1 in Arch and other rolling-release distros.

This is the first desktop environment we&#39;ve seen that delivers any of the promised benefits of Wayland. It&#39;s very fast, can handle changing resolutions, orientations, scaling factors and so on on the fly without any issue. Both GNOME and the various tiling Wayland compositors face serious new competition.

Several of the Reg FOSS desk&#39;s techier friends were already running Pop!_OS, but the new desktop makes it even more appealing. It also shows that the underlying Ubuntu 24.04 OS is no slouch. We think this is a winning combination which will win win Pop!_OS a lot of new admirers – and help burnish System76&#39;s reputation, too. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-24')">
            <div class="source">The Verge</div>
            <div class="title">Chipwrecked</div>
            <div class="meta">2025-12-22</div>
        </div>
        
        <div id="content-24" style="display:none;">
            <h2>Chipwrecked</h2>
            <p><strong>The Verge | 2025-12-22</strong></p>
            <a class="original-link" href="https://www.theverge.com/ai-artificial-intelligence/848988/nvidia-chip-loans-coreweave-gpu-debt-ai-neocloud">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Nvidia has built an empire on circular deals for chips. Can anything knock it down?

If you buy something from a Verge link, Vox Media may earn a commission. See our ethics statement.

If you buy something from a Verge link, Vox Media may earn a commission. See our ethics statement.

The AI data center build-out, as it currently stands, is dependent on two things: Nvidia chips and borrowed money. Perhaps it was inevitable that people would begin using Nvidia chips to borrow money. As the craze has gone on, I have begun to worry about the weaknesses of the AI data center boom; looking deeper into the financial part of this world, I have not been reassured.

Nvidia has plowed plenty of money into the AI space, with more than 70 investments in AI companies just this year, according to PitchBook data. Among the billions it’s splashed out, there’s one important category: neoclouds, as exemplified by CoreWeave, the publicly traded, debt-laden company premised on the bet that we will continue building data centers forever. CoreWeave and its ilk have turned around and taken out debt to buy Nvidia chips to put in their data centers, putting up the chips themselves as loan collateral — and in the process effectively turning $1 in Nvidia investment into $5 in Nvidia purchases. This is great for Nvidia. I’m not convinced it’s great for anyone else.

Do you have information about loans in the AI industry? You can reach Liz anonymously at lopatto.46 on Signal using a non-work device.

There has been a lot of talk about the raw technical details of how these chips depreciate, and specifically whether these chips lose value so fast they make these loans absurd. While I am impressed by the sheer amount of nerd energy put into this question, I do feel this somewhat misses the point: the loans mean that Nvidia has an incentive to bail out this industry for as long as it can because the majority of GPU-backed loans are made using Nvidia’s own chips as collateral.

Of course, that also means that if something goes wrong with Nvidia’s business, this whole sector is in trouble. And judging by the increasing competition its chips face, something could go wrong soon.

Loans based on depreciating assets are nothing new. For the terminally finance-brained, products like GPUs register as interchangeable widgets (in the sense of “an unnamed article considered for purposes of hypothetical example,” not “gadget” or “software application”) not substantively different from trucks, airplanes, or houses. So a company like CoreWeave can package some chips up with AI customer contracts and a few other assets and assemble a valuable enough bundle to secure debt, typically for buying more chips. If it defaults on the loan, the lender can repossess the collateral, the same way a bank can repossess a house.

One way lenders can hedge their bets against risky assets is by pricing the risk into the interest rate. (There is another way of understanding debt, and we will get there in a minute.) A 10-year mortgage on a house is currently 5.3 percent. CoreWeave’s first GPU-backed loan, made in 2023, had 14 percent interest in the third quarter of this year. (The rate floats.)

“You have so many forces acting in making them a natural monopoly, and this amplifies that.”

Another way lenders can try to reduce their risk is by asking for a high percentage of collateral relative to the loan. This is expressed as a loan-to-value ratio (LTV). If I buy a house for $500,000, I usually have to contribute a downpayment — call it 20 percent — and use my loan for the rest. That loan, for $400,000, means I have a (LTV) ratio of 80 percent.

GPU loans’ LTV vary widely, based on how long the loan is, faith in companies’ management teams, and other contract factors, says Ryan Little, the senior managing director of equipment financing at Trinity Capital, who has made GPU loans. Some of these loans have LTVs as low as 50 percent; others are as high as 110 percent. GPU-backed loans are competitive, and Trinity Capital has occasionally lost deals to other lenders as well as vendor financing programs.

The majority of these loans are made on Nvidia chips, which could solidify the company’s hold on the market, says Vikrant Vig, a professor of finance at Stanford University’s graduate school of business. If a company needs to buy GPUs, it might get a lower cost of financing on Nvidia’s, because Nvidia GPUs are more liquid. “You have so many forces acting in making them a natural monopoly,” Vig says, “and this amplifies that.”

Figuring out how much GPUs are worth and how long they’ll last is not as clear as it is with a house

Nvidia declined to comment. CoreWeave declined to comment.

Not everyone is sold on the loans. “At current market prices, we don’t do them and we don’t evaluate them,” says Keri Findley, the CEO of Tacora Capital. With a car, she knows the depreciation curve over time. But she’s less sure about GPUs. For now, she guesses GPUs will depreciate very, very quickly. First, the chip’s power might be leased to Microsoft, but it might need to be leased a second or third time to be worth investing in. It’s not yet clear how much of a secondary or tertiary market there will be for old chips.

Figuring out how much GPUs are worth and how long they’ll last is not as clear as it is with a house. In a corporate filing, CoreWeave notes that how much it can borrow depends on how much the GPUs are worth, and that will decrease as the GPUs have less value. The value, however, is fixed — and so if the value of the GPUs deteriorates faster than projected, CoreWeave will have to top off its loans.

Some investors, including famed short-seller Michael Burry, claim that many companies are making depreciation estimates that are astonishingly wrong — by claiming GPUs will be valuable for longer than they will be in reality. According to Burry, the so-called hyperscalers (Google, Meta, Microsoft, Oracle, and Amazon) are understating depreciation of their chips by $176 billion between 2026 and 2028.

Little is betting that even if some of the AI companies vanish, there will still be plenty of demand for the chips that secure the loan

Burry isn’t primarily concerned with neoclouds, but they are uniquely vulnerable. The hyperscalers can take a write-down without too much damage if they have to — they have other lines of business. The neoclouds can’t. At minimum they will have to take write-downs; at maximum, there will be write-downs and complications on their expensive loans. They may have to provide more collateral at a time when there’s less demand for their services, which also can command less cash than before.

Trinity Capital is keeping its loans on its books; Little is betting that even if some of the AI companies vanish, there will still be plenty of demand for the chips that secure the loans. Let’s say one of the neoclouds is forced into bankruptcy because it’s gotten its chips’ depreciation wrong, or for some other reason. Most of their customers may very well continue running their programs while banks repossess the servers and then sell them for pennies on the dollar. This is not the end of the world for the neocloud’s lenders or customers, though it’s probably annoying.

That situation will, however, bite Nvidia twice: first by flooding the market with its old chips, and second by reducing its number of customers. And if something happens that makes several of these companies fail at once, the situation is worse.

Part of what’s fueling the AI lending boom is private credit firms, which both need to produce returns for their investors and outcompete each other. If they miscalculate how risky the GPU loans are, they may very well get hit — and the impact could ripple out to banks. That could lead to widespread chaos in the broader economy.

Earlier, we talked about understanding interest rates as pricing risk. There is another, perhaps more nihilistic, way of understanding interest rates: as the simple result of supply and demand. Loans are a product like any other. Particularly for lenders that don’t plan on keeping them on their own books, pricing risk may not be a primary concern — making and flipping the loans are.

AI spending is exorbitant — analysts from Morgan Stanley expect $3 trillion in spending by the end of 2028

Here’s a way of thinking about it: Let’s say a neocloud startup called WarSieve comes to my private credit agency, Problem Child Holdings, and says, “Hey, there’s a global shortage of GPUs, and we have a bunch. Can we borrow against them?” I might respond, “Well, I don’t really know if there’s a market for these and I’m scared you might be riff raff. Let’s do a 15 percent interest rate.” WarSieve doesn’t have better options, so it agrees.

Now, I happen to know some clients who love high-yield debt. So I sell my loans. But my competitor, Night Prowler Credit, notices my cool deal. So when the next company comes to me, trying to get a GPU-backed loan, I offer them 15 percent as an interest rate, and they tell me Night Prowler has offered them 13 percent. Well, I have to remain competitive, so I make a counter offer of 12.5 percent, and the startup agrees, and we are all happy except Night Prowler, which got shot down in flames.

The thing about the model I’ve just outlined — loans as a product — is that I’m not really thinking that hard about risk, except as a negotiating tactic. And as more of my competitors get wind of what I’m up to, as well as how juicy my returns look, I start having to lower my rates, because if I keep offering 15 percent, Night Prowler and other firms will make better offers.

Private credit is deploying “mountains of cash” into AI

There are some conditions fueling the boom in AI-related lending. AI spending is exorbitant — analysts from Morgan Stanley expect $3 trillion in spending by the end of 2028 on just data centers. This is happening at the same time that private credit managers have pulled in a great deal of cash but “are falling short on dealmaking,” writes Bloomberg’s Shuli Ren. That means deploying “mountains of cash” into AI.

You’re never going to guess who’s been leading the market in GPU-backed loans. The $2.3 billion CoreWeave loan that started it all had a bunch of private credit behind it: Magnetar, Blackstone, Coatue, BlackRock, and PIMCO. Besides its initial loan, CoreWeave took out another $7.5 billion in 2024, and a third loan, for $2.6 billion, in July. The third loan listed a number of actual banks, including Goldman Sachs, JPMorganChase, and Wells Fargo.

It’s not just CoreWeave. In April, Fluidstack took out a $10 billion loan. Other companies, such as Crusoe and Lambda, have taken out about half a billion each. Even the medium-size GPU-backed loans Trinity Capital is seeing are tens of millions of dollars, Little says.

Many of the companies taking out these loans are startups. They appear to be mimicking CoreWeave, too — not just in taking out the loans the company pioneered, but in growing fast by taking out debt. Fluidstack, the company with the largest loan, made only $65 million in 2024 revenue, according to The Information. But as private credit funds have flourished — they were about 10 times larger in 2023 than in 2009, according to McKinsey — more finance companies have been seeking big returns. And the interest rates on the GPU-backed loans are higher than those on some junk bonds, making the GPU-backed loans particularly attractive.

The tech sector has taken out more debt than it did during the ’90s dot-com bubble

Private credit also has an advantage for established companies: they can help create special-purpose vehicles that let companies take out debt without touching their credit rating or putting debt on the balance sheet. Blue Owl’s SPV with Meta is the most obvious example. Private credit is also essentially unregulated, says Sarah Bloom Raskin, a former deputy secretary of the US Treasury and professor at Duke University School of Law.

Data centers are also creating their own asset-backed securities, and data center debt is creating derivative financial products, such as credit default obligations, Raskin notes. If that sounds familiar, “they’re like the derivatives we saw with the mortgages” in the 2008 financial crisis, she says. SPVs also proliferated in the run-up to that crisis, because keeping debt off the books hid how vulnerable firms really were.

The GPU slice of debt is relatively small compared to the bond issuances from Big Tech. But the issues there may reflect broadly on tech lending. The tech sector has taken out more debt than it did during the ’90s dot-com bubble, says Mark Zandi, the chief economist at Moody’s Analytics.

Generally speaking, private debt is riskier than bank debt; the loans are larger, are later in line for being paid back than bank loans, have higher interest rates, and take longer to mature, according to financial research from the Federal Deposit Insurance Corp. About half of private debt borrowers also get bank loans. Companies that get both types of loans draw heavily on them during moments of financial distress, the paper notes. So private debt indirectly affects banks — because companies that borrow from both have higher drawdown and default risks, especially at times of market distress.

“Borrowing by AI companies should be on the radar screen as a mounting potential threat to the financial system and broader economy.”

The AI companies indirectly link private credit and real banks. That means there are higher stakes on AI lending than just “will Magnetar look stupid.” CoreWeave, for instance, has — in addition to its GPU-backed loans — a $2.5 billion revolving credit line with JPMorgan Chase.

Private debt also directly affects banks, because banks often lend to private credit providers, according to a special report from Moody’s. In fact, bank loans to private credit are part of what’s been driving their growth. As of June, banks had lent $300 billion to private credit providers. “Aggressive growth and competition could weaken underwriting standards and elevate credit risk,” the report warns.

“Borrowing by AI companies should be on the radar screen as a mounting potential threat to the financial system and broader economy,” Zandi said. In the ’90s dot-com boom, the exuberance was mostly in equity — and so the people who felt the most pain were those who’d invested in the hot new companies that went belly up. But debt means that if AI falters, the damage will be widespread, Zandi warned.

Speaking of equity, The Wall Street Journal reported that AI business investments may have been about half of the GDP growth in the first half of the year, and have buoyed both the stock market and, indirectly, consumer spending. “It’s certainly plausible that the economy would already be in a recession” if not for the AI investments, Peter Berezin, BCA Research’s chief global strategist, told the WSJ. AI is “the only source of investment right now,” a Bank of America economist told the paper. So if things go wrong for AI spending, the otherwise weak economy may be headed for a recession, Berezin said. There is some good news, though: Berezin doesn’t think that the current AI debt load could directly cause an actual financial crisis.

Part of what makes the AI sector particularly vulnerable is how interconnected all the players are. And Nvidia, though its investments and chip sales, is central to the entire ecosystem.

Generally speaking, debt is about math, and equity is about feelings. This is one reason why so many people are worried that GPUs actually lose value faster than companies claim. And while Michael Burry’s concerns have primarily to do with accounting and earnings, rather than debt, I’m not sure he’s thinking about risks correctly. It just isn’t the biggest thing that can go wrong.

The core of the argument about GPU depreciation is whether the old chips are no longer worth running after three years or longer. Many companies depreciate them over the course of five or six years. Obviously, this matters for earnings — depreciation is one of the line items public tech companies report — but it also matters for GPU-backed loans, which have some assumptions about depreciation baked in. I did not find consensus on how long GPUs remain economically viable to run.

The money part is the issue. Six years is probably too long to depreciate a GPU over, says CJ Trowbridge, an AI researcher. One thing that throws people off is that Google’s TPUs — more about those in a minute — do depreciate over six years, but those chips are custom-built for AI, Trowbridge says. On the other hand, OpenAI CFO Sarah Friar says the company is still using Nvidia’s Ampere chips, released in 2020; CoreWave’s Michael Intrator says his Ampere chips are fully booked. (Both companies count Nvidia as an investor and use Deloitte as an auditor.) IBM’s Arvind Krishna puts the depreciation of a GPU at five years.

Let’s imagine I am running a company, Live Wire Server Farms. I have just sourced myself a number of Nvidia Tesla V100s, released in 2017, which cost around $10,000 apiece; I am pricing the rental cost per hour per chip between $2 and $3. Assuming those chips are being used 100 percent of the time, I recoup my chip investment in four to seven months. For the newer B200, it’ll take me about six months to make my money back, even though I can price those 8-GPU nodes at more than $100 per hour. For the P100, launched in 2016, it takes less than four months. (These are not theoretical numbers — I am drawing them from an October 2025 paper written by Hugging Face’s Sasha Luccioni and Yacine Jernite.)

But Live Wire Server Farms isn’t just a pile of GPUs. I need a place to put them, a way to cool them, and power to run them. Let’s start with power. Assume I have purchased a cluster of eight V100s and plonked them down in Virginia, which is home to about a third of all hyperscaler data centers. Running them would cost me another $3,660 a year, at recent energy prices, according to Luccioni and Jernite’s analysis.

Any risk that hits the whole sector at once is a major problem for lenders

Newer chips are more efficient, and able to run more processes for clients more quickly, but they also require more power. Power is an important limitation for the industry; it takes time to build out. New data centers will need an additional 44GW of capacity by 2028, according to S&P Global Energy. But only about 25GW of new power is coming online in that timeframe, The Financial Times reports. Does that extend the life of old chips? Maybe.

Chips exist in data centers, and data centers for GPUs need to be purpose-built; I can’t just stick a bunch of servers in a warehouse and call it a day. The constraints of power and construction may be why there’s an argument for older chips sticking around longer — there are significant hurdles to deploying new chips. Those investments also depreciate more slowly than the chips do.

Still, at some point, my older GPUs cost more to operate than I can charge my customers. Live Wire Server Farms needs to plan for the future; I’d better put my new infrastructure in place before that happens. My new facility isn’t going to come online right away — I have to build it and get the power agreements secured — so I go to Problem Child Holdings and get myself a GPU loan to build out infrastructure for the next generation of chips I buy, using that GPU as my collateral along with, I don’t know, my contract with Microsoft or whomever.

As long as things keep ticking along without any major changes, this is fine. But! As we all know, life contains surprises. Obviously, any risk that hits the whole sector at once is a major problem for lenders. In 2022, people who’d made loans to Bitcoin miners when the times were good suddenly got stuck with the rigs that had been used as collateral — and their value had dropped by 85 percent since a year earlier. (Some firms simply couldn’t make their payments; others realized that their mining rigs were worth less than what they had to repay.) By January 2023, the resale market was saturated and crypto lenders had repossessed so many rigs they simply started mining themselves.

Nvidia has a strong incentive to keep the neoclouds afloat

Something like this could play out for the GPU-backed loans, too. However, the situation is slightly different, and not just because crypto miners only had $4 billion in debt and the GPU-backed debt is significantly larger. Crypto lending was mostly done by highly specialized firms that dealt exclusively with the crypto space. By contrast, AI debt is connected to normal banks.

When Bitcoin mining went belly-up, Nvidia got stuck with more than $1 billion in inventory — since it had ramped up chip production to keep up with the increased demand. That delayed their introduction of new GPUs. Net income in that fiscal year (which for Nvidia, ended on January 29, 2023) plummeted 55 percent from the year before. But in December of 2022, OpenAI introduced ChatGPT, kicking off the AI arms race. Net income in the following financial year increased by a factor of 7.

Sure, Nvidia’s business has changed since then. There’s been a broader data center buildout — not just AI — since the 2020 pandemic. And it’s Nvidia’s ambition to transfer the traditional CPU-based data center to GPUs, Nvidia CFO Collette Kress said in remarks at the UBS Global Technology and AI Conference earlier this month. In Kress’s view, the GPUs for AI are only one part of the market.

Well, maybe. But GPUs are fungible; if a data center full of GPUs comes on the market because a neocloud goes belly-up, it’s possible it could be repurposed by its buyer. In fact, the fungibility of GPUs is one reason why Big Tech are less concerned about overbuilding data centers than their competition. If they build too much compute for AI, they can simply pause spending for a few years and use their existing data centers for other purposes — running ads or whatever.

That means that in some sense, the question of depreciation is beside the point

So Nvidia has a strong incentive to keep the neoclouds afloat. It is, of course, an investor in several. But keeping their customers in business is good for their bottom line, too. If something goes wrong, Nvidia may swoop in to save several companies — or the entire field — from bankruptcy. Nvidia already rescued CoreWeave’s IPO, after all.

That means that in some sense, the question of depreciation is beside the point; if a company like CoreWeave has to take a massive write-down, or top off its loans with more capital, Nvidia can help them out. For something to go seriously wrong with the neoclouds, Nvidia has to be unwilling or unable to bail them out.

And that time could be coming, because Nvidia faces increasing competitive pressure.

The entire market of neoclouds exists primarily because Nvidia wants them to. Its revenue is highly concentrated — in its most recent financial documents, it notes that sales to two direct customers represented 21 percent and 13 percent of revenue in the first nine months of Nvidia’s fiscal 2026. Bolstering the field of customers by backing neoclouds gives Nvidia more leverage over its large buyers.

Meanwhile, its large buyers started making their own chips. Take Google’s TPUs, which are designed specifically for AI work — unlike GPUs, which were designed for computer graphics and happen to be useful for a bunch of other things, such as mining cryptocurrency and, yes, AI.

Google’s been making noises about AI-specific chips since 2006; in 2016, it announced it had been running TPUs for “more than a year.” When Gemini 3 was released in November, it effectively clobbered everything else on a series of industry benchmarks — so much so that our fearless leader okayed swearing in a headline. That model was trained on TPUs and only TPUs.

The feat was impressive enough that even Sam Altman says there are “rough vibes” ahead for OpenAI. Nvidia put out a condescending statement — never a good sign. “We’re delighted by Google’s success — they’ve made great advances in AI and we continue to supply to Google,” the statement read. “NVIDIA is a generation ahead of the industry — it’s the only platform that runs every AI model and does it everywhere computing is done.” Between this and the “I’m not Enron” memo, Nvidia is sending some weird signals. This isn’t how a confident company behaves.

Google’s TPUs are operationally cheaper than Nvidia’s GPUs, requiring less power to run similar processes. Now, maybe Nvidia’s little stable of neoclouds won’t adopt them — that might upset Huang, and upsetting him could reduce the chances of an Nvidia bailout. But everywhere else, Nvidia customers can snap up a new product that may be both better and cheaper to operate. And who knows? Perhaps some crypto miner might decide to get into the neocloud game without Nvidia.

Remember how we talked about the GPU loans also requiring contracts from Microsoft or whomever? Frequently, that “whomever” is Nvidia

That’s why Google’s deals with Anthropic, Salesforce, Midjourney, and Safe Superintelligence, plus the rumored deal with Meta, are so significant. Anyone who buys — or even just threatens to buy — TPUs can negotiate better prices with Nvidia. OpenAI has saved 30 percent of its total cost of ownership on Nvidia GPUs without even deploying TPUs, according to modeling done by SemiAnalysis.

That SemiAnalysis estimate, however, relies on an assumption I’m not sure is good news for Nvidia: that Nvidia’s equity investment in neoclouds is a way to offer a rebate without actually cutting prices, “which would lower gross margins and cause widespread investor panic,” SemiAnalysis writes. Whether or not you take that modeling seriously, the basic point stands: competition could cut into Nvidia’s margins. It also may threaten the value of Nvidia’s older chips, which are even less energy-efficient than the new ones.

What’s interesting is the incentive program SemiAnalysis doesn’t include as part of a discount program. Remember how we talked about the GPU loans also requiring contracts from Microsoft or whomever? Frequently, that “whomever” is Nvidia.

Take CoreWeave. Its contracts guarantee a certain amount of income; the creditworthiness of the entity — Microsoft, say, or Nvidia — on the other side of that contract is part of what makes the lenders comfortable. CoreWeave’s second biggest customer in 2024 was Nvidia, which “agreed to spend $1.3 billion over four years to rent its own chips from CoreWeave,” according to The Information. In September, Nvidia signed another $6.3 billion contract with CoreWeave, which is often interpreted as Nvidia backstopping demand for CoreWeave’s services.

CoreWeave is very excited about all this! There’s a whole 8-K filing with the SEC about it, and it was part of the company’s case that Core Scientific shareholders should vote to let CoreWeave buy their company.

Nvidia, on the other hand, is coy. In the company’s most recent 10-Q, there’s a note about “Nvidia Cloud Service Agreements.” Nvidia is paying $26 billion for cloud services, $22 billion of it by 2031. This is supposedly for “R&D and DGX cloud offerings.” This does not entirely explain the outlays, said Jay Goldberg, an analyst at Seaport Research partners, in a November 30th research note. That gives Nvidia the option for $6 billion in cloud compute next year — enough for the chipmaker to build its own foundation model to compete with its biggest customers.

Goldberg thinks that number actually represents Nvidia’s “backstop” agreements. The timing of CoreWeave’s $6 billion contract lines up with a $13 billion sequential increase in cloud compute services. But that only explains about half of it. “The practice started growing in 2022,” Goldberg told me in an interview. In the last quarter, the number doubled. And it isn’t included on the balance sheet — it’s tucked away in a note. At a small scale it might be fine, Goldberg told me, but “$26 billion is a big number.” If it had been included as cost-of-goods-sold, it would have reduced Nvidia’s margin to 68 percent from 72 percent and earnings per share to $5.97 from $6.28.

So Nvidia may already be bailing out the neoclouds to some extent. That would explain the jump in cloud compute services. “Something changed in the last six months where the scale got so big it’s warping things,” Goldberg told me. That worries me. If Nvidia is deploying more and more cash to boost the field, things may already be shakier than we realize. One thing that may be squeezing data center operators? Nvidia.

Neoclouds, loaded with debt and rapidly depreciating assets, need to get as much money out of their chips as possible. But Nvidia also needs to sell as many chips as it can. For Nvidia, in fact, it doesn’t even really matter if those chips end up in data centers — which creates just one more way their incentives aren’t aligned.

Nvidia’s product cycle sped up recently, going from new architecture every two years to every one, making it even harder to squeeze more money out of last-gen chips. “I said before that when Blackwell starts shipping in volume, you couldn’t give Hoppers away,” Nvidia’s Huang said at the company’s 2025 developer conference. “There are circumstances where Hopper is fine. Not many.”

“If the current generation costs half as much to run, why would anyone pay twice as much for older cards?”

If this isn’t just a CEO hyping his new product, my pretend business Live Wire Server Farms may be in trouble. Like most neoclouds, I had to go into debt to build the stuff I have now. A shortened product cycle may mean I have to build faster in order to stay current, even as my original data center deteriorates in value. But my debt load remains the same; I have the down payment blues.

“In the last couple generations you had a doubling or close to a doubling in efficiency,” says Trowbridge, the AI analyst. If Nvidia manages to keep this up at a yearly cadence, that places serious pressure on every neocloud.

Neoclouds aren’t just helpful as Nvidia customers. They lower capital expenditures for companies such as Microsoft and Google that use their services. Those companies are paying basically for power and rent, with a little bit of margin on top. So they may be incentivized to ask for the most recent chips, because that keeps their spending down, Trowbridge says. “If the current generation costs half as much to run, why would anyone pay twice as much for older cards?”

So that’s what neoclouds compete on — the stuff their big clients will write down as “operating expenses.” The company that spends less on power per operation is the one that can price the most competitively and thus win contracts, Trowbridge says. That means Live Wire Server Farms, like every neocloud, has to keep building indefinitely in order to keep up with the newest tech.

“We’re bumping up against the limit of what it’s possible for them to support and finance.”

Building has risks — and one risk of data centers is stranded assets. Take, for instance, CoreWeave, which announced a delay on its new data center build-out. An unexpectedly rainy summer caused a delay of about 60 days on a Texas build, according to The Wall Street Journal. Coupled with other delays from design changes, the data center now will open several months late. That could potentially take some time off the very brief time the chips CoreWeave purchased for the data center can earn at their maximum value.

That’s not all. The delayed data center in question is for OpenAI, which has terms in its contract that allow it to yank its contract from CoreWeave if the neocloud can’t meet the AI company’s needs. And CoreWeave has an astonishing amount of debt, some of it predicated on the OpenAI contract — so losing that contract is potentially catastrophic.

There are some risks for Nvidia, directly. If customers change their minds, scale back on their builds, or can’t get enough power, Nvidia might get stuck with extra inventory. If customers can’t get financing, perhaps because investors get cold feet about the data center buildout, that’s trouble for Nvidia, too. The company acknowledges as much in its most recent quarterly filing.

CoreWeave and the other neoclouds have to keep upgrading to stay current, Goldberg says. For Nvidia to keep its sales number up, the neoclouds have to keep buying. “We’re bumping up against the limit of what it’s possible for them to support and finance,” Goldberg says. “It can’t go on forever. I don’t know if it stops next year or the year after, but it can’t go on at this pace. Something’s gotta give.”

With competition nipping at its heels, Nvidia may have less freedom to throw cash at neoclouds

The forcing function may be competition. Because it isn’t just Google’s TPUs. Amazon is making its own chips and is in talks with OpenAI about letting it use them. Microsoft is making its own AI chips, too. So is Meta, and even OpenAI. Lurking behind some of these chips is Broadcom, which Goldberg calls “formidable.” And this isn’t just happening in the US. In China, Huawei, ByteDance, and Alibaba are building their own, too.

Then there’s AMD, which is starting to catch up with Nvidia. “By 2027, their roadmap and Nvidia’s converge in terms of performance,” Goldberg says. “And they’re willing to price cheaper.” And Nvidia may be rattled. The company made some late changes to Feinman, its 2027 chip, that suggest they looked at what AMD was doing and tweaked their own designs to stay ahead. “On the timelines we’re dealing with, that’s pretty late in the game to change,” Goldberg says.

Nvidia — and everyone else — are now locked into an annual cadence, which is brutal for the neoclouds. With competition nipping at its heels, Nvidia may have less freedom to throw cash at these companies. But that in and of itself isn’t quite enough to knock everything over.

Maybe the precarity I’m outlining here never becomes dangerous. I am, after all, speculating. But there are a few factors to think about when it comes to systemic financial crises, says Raskin: interconnectedness of the players, concentration of risk, uncertain valuations, gaps in regulatory oversight, and the extent of government investment are among them. The AI industry is highly interconnected, with many companies taking out loans on assets no one can agree on the depreciation schedule for. Many of those loans are coming from private credit firms, which are less regulated than banks. That’s a lot of dry tinder.

So what’s the match? Goldberg outlined to me his pet theory. The deals for building data centers are complex and involve a lot of players. Someone wants to open a data center, and one of the smaller parties takes out loans. The data center gets delayed, maybe because of weather or because a power source doesn’t get built on time. Nvidia doesn’t care. A bigger player like CoreWeave might be able to survive. But if it’s a smaller player, they might go bankrupt, which means someone has to recognize the loss. The complexity of the transactions and the degree to which the players are interlocked means that the tiny company collapsing could potentially cascade up to a point where a much larger company such as Microsoft winds up assuming $20 billion of debt it would prefer not to have on its balance sheet. “That seems like the house of cards scenario,” Goldberg told me.

“Regardless of the loan terms, a lot of these business plans are going to come down to: Is there a strategic reason a bigger player wants you to exist?”

The size and number of the players that collapse, of course, will determine how much damage spreads through the industry. There are a lot of tiny neoclouds that could vanish tomorrow without anyone noticing, though if they all vanished at once, that might raise eyebrows. If one or several of the big ones go down, that might spread fear through the AI ecosystem. Even if it’s not enough money to cause real problems, it can spook investors, and spooked investors behave in insane ways — just ask Silicon Valley Bank.

Trowbridge, the AI researcher, wrote an MBA thesis suggesting that something like CoreWeave should exist — and then CoreWeave made its deal with Nvidia a month later, he told me. By supporting neoclouds, Nvidia effectively prevents the biggest players (Microsoft, Amazon, Google, Meta) from buying everything and leaving all others fighting over scraps.

So Trowbridge also thinks it’s possible that Nvidia might facilitate consolidation among the neoclouds — because their continuing existence does give Nvidia more control over the market for AI compute. If he’s right, then there may not be a catastrophic failure cascade. “It’s scary to see the direction it’s going,” he told me. “Regardless of the loan terms, a lot of these business plans are going to come down to: Is there a strategic reason a bigger player wants you to exist?”

It’s still not really clear how risky GPU loans are. But what does seem clear is that an awful lot of GPU loans are an indirect bet on Nvidia’s continued prowess and willingness to support neoclouds. Nvidia has been ramping up its spending on cloud compute lately. No one really knows how long Nvidia can continue to subsidize the neoclouds in the way it’s been doing. If there’s an exogenous shock — an economic downturn, an act of God — several neoclouds may fail at once.

“The parallels to the financial crisis are interesting — it’s rhyming in a number of ways.”

There are other ways these loans can go south. On a longer timescale, it’s not clear how long neoclouds’ biggest customers will continue to need them. No one in AI is currently making money off of inference, the industry slang for the process of a model actually generating something. That may lead to budgetary shifts among Big Tech players. Or maybe, once all the data centers under construction are built, Big Tech won’t need overflow compute anymore. Maybe there will be some massive technology shift — someone has a breakthrough and the size of frontier models shrinks substantially. Or Nvidia’s competitors start making the most in-demand chips, undercutting demand for the neoclouds with data centers full of the chips no one wants. Or open-source models get so good that there’s no need for OpenAI, which is connected to virtually everything in the field and will cause serious damage if it fails.

What I do know is this: If several neoclouds collapse, the market is flooded with whole data centers of chips. Nvidia took a hit during the crypto bust of 2022, but that will look like sea-foam compared to the tidal wave of chips that might surface if multiple large neoclouds default on their GPU-backed loans. And Nvidia will be in no position to bail anyone out.

So that’s a problem for private lenders and for everyone whose money they’re using — universities, pension funds, family offices, hedge funds, endowments. Those losses mean effects on other parts of the economy. And since private lenders are connected directly or indirectly to banks, it’s also a problem for the banks. “Couple it with gaps in regulation and transparency, and you can see immediately how this becomes a risk to the banking sector itself,” says Duke’s Raskin. “The parallels to the financial crisis are interesting — it’s rhyming in a number of ways.”

Maybe the question isn’t how the music stops. It’s when — and what happens afterwards.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-25')">
            <div class="source">The Verge</div>
            <div class="title">Samsung &#8216;Wide Fold&#8217; rumored to rival Apple’s foldable next year</div>
            <div class="meta">2025-12-22</div>
        </div>
        
        <div id="content-25" style="display:none;">
            <h2>Samsung &#8216;Wide Fold&#8217; rumored to rival Apple’s foldable next year</h2>
            <p><strong>The Verge | 2025-12-22</strong></p>
            <a class="original-link" href="https://www.theverge.com/news/848934/samsung-wide-fold-apple-iphone-foldable-4-3">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">﻿Both devices reportedly share a similar display size and aspect ratio.

﻿Both devices reportedly share a similar display size and aspect ratio.

Apple’s long-rumored foldable iPhone is set to arrive next year, and already faces some preemptive competition from Samsung. Korea’s ET News reports that Samsung’s upcoming “Wide Fold” is also set to launch in 2026, and will closely mirror the display size and 4:3 aspect ratio of Apple’s first foldable.

The machine-translated report says the Wide Fold is expected to feature an OLED display that measures 5.4 inches in its folded position, and 7.6 inches when unfolded. “It will be a ‘passport’ type with a 4:3 screen ratio when unfolded,” according to an unnamed industry source cited by ET News.

Last week, The Information reported that Apple’s upcoming foldable will feature a 5.3-inch display that increases to 7.7 inches when open, and will have an aspect ratio “similar to that of Apple’s largest iPads when viewed in landscape mode,” and will be “more wide than tall when unfolded.” Most iPad models sport a near 4:3 aspect ratio. This was the latest rumor that pointed to Apple’s first foldable iPhone having a wide aspect ratio in portrait mode, though Bloomberg’s Mark Gurman said in September that the device would look like two iPhone Airs stuck together.

Both Samsung and Apple’s upcoming foldables are expected to launch in Fall 2026. The 4:3 aspect ratio is better for reading e-books and documents, viewing photographs, or creative tasks like design and image editing, but would result in traditional landscape and portrait videos having ugly black bars at the top and bottom of the screen. This is something that’s already noticeable on Samsung’s squarish Z Fold 7.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-26')">
            <div class="source">The Verge</div>
            <div class="title">It’s finally time to retire the word ‘podcast’</div>
            <div class="meta">2025-12-22</div>
        </div>
        
        <div id="content-26" style="display:none;">
            <h2>It’s finally time to retire the word ‘podcast’</h2>
            <p><strong>The Verge | 2025-12-22</strong></p>
            <a class="original-link" href="https://www.theverge.com/entertainment/842457/podcast-show-name-change">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">With podcasting pivoting to video this year, the word used to describe an audio-only show is becoming meaningless.

With podcasting pivoting to video this year, the word used to describe an audio-only show is becoming meaningless.

According to YouTube’s 2025 Recap feature, the podcast I consumed the most on its platform was Seth Meyers’ recurring segment “A Closer Look” on his show Late Night.

Last year, I would have argued that this is not a podcast. That it is, in fact, a clip of a TV show. But in 2025, with almost every major podcast now having a video component, the definition of the word “podcast” has become pretty meaningless. A decades-old TV show talk show format is now almost indistinguishable from podcasts like Good Hang with Amy Poehler, Armchair Expert with Dax Shepard, Club Shay Shay with Shannon Sharpe, and other shows at the top of Spotify’s podcast charts. In fact, they are now on the same playing field.

The definition of the word “podcast” has become pretty meaningless

Scrolling though my YouTube feed, most of the suggestions in the Podcast tab are late-night talk show interviews, host-driven video essays, food reviews, and cable news segments — very far from what we used to use the term for: narrative audio journalism and roundtable discussions.

So in 2026, instead of trying to define what a podcast is, I think we need to stop using the word altogether. “Podcast” is becoming an outdated or even a potentially cringe internet relic, similar to how the phrase “web series” faded from use online.

So what do we call these formats instead? I don’t think we’re going to invent a new word, but instead repurpose an old one.

Bloomberg’s Ashley Carman noticed this change in her coverage of The Podcast Show in London this past May:

...two separate panelists made it clear they do not call their podcasts “podcasts.” Georgie Holt, chief executive at FlightStory, the company behind Steven Bartlett’s Diary of a CEO , said the team calls their programming “shows.” In a conversation on stage with me, Max Cutler, founder of Pave Studios, said exactly the same thing.

Anecdotally I have heard this change of nomenclature from “podcasts” to “shows” internally here at Vox Media too, and echoed from my colleagues at other media companies as well.

Using the word “show” seems to be a more marketable term for advertising, especially when attaching celebrity names to the project. Pitching podcasts to advertisers sounds limiting and niche, but pitching a “show” — hey, that’s a place where they can get ears and eyes, and a definitive platform where the shows will live. Podcast creators want that Seth Meyers money.

Because of this, fans will likely begin calling them “shows” as well, the same way consumers started claiming internal marketing terms like “influencers” and “creators.”

We’re seeing the word fade from the hosts, too. There’s a recurring bit on The Adam Friedland Show now where guests call the show a podcast, and the titular host corrects them instantly, claiming it’s a talk show. Instead of the cliche “Find us wherever you get podcasts” sign-off, I’ve noticed many hosts are now pivoting more to the “like-and-subscribe” phrasing of YouTube culture.

These podcast shows are all starting to live together with non-podcast shows like Hot Ones, Chicken Shop Date, the Criterion Closet series, Tonight Show clips, etc. — so why limit them to a term that used to go hand-in-hand with iPods?

Unfortunately, all this also means that a lot of the openness of podcasting is slowly going away and becoming more centralized on platforms like YouTube and Netflix. YouTube says more than one billion people watch podcasts on its platform every month. It was reported by Bloomberg that Netflix is going to add podcasts to its streaming platform, developing its own shows and working with major networks like Spotify, iHeartMedia, and Sirius.

In fact, YouTube is starting to look more like Netflix. “Talk show–style podcasts” on YouTube are already considered to be the next generation of late night TV, especially with CBS signaling an end to investing in the genre by cancelling The Late Show with Stephen Colbert in 2026 (I can imagine a cheaper-made podcast going into CBS’s late night lineup instead) and celebrity press tours prioritizing YouTube over traditional network TV.

Next year, you probably won’t be recommending your favorite new podcast to your friend, but instead something you “watched on TV.”

Despite all this, I still think the audio-only format will stick around. After all, people still drive cars, and they aren’t typically looking at a screen for the whole three hours of a podcast. In fact, according to Edison Research, most podcast listening is done at home. It’s likely, though, that most audio-only podcasts will be from more independently run shows. Media companies will still publish audio versions of their video shows for the podcatcher apps, but they’re not the priority anymore.

As a result (and long overdue from the era of the iPod), I think the era of the term “podcast” is ending. Perhaps in the future, the question “What is a podcast?” will disappear in favor of “What was a podcast?”

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-27')">
            <div class="source">MIT Technology Review</div>
            <div class="title">Welcome to Kenya’s Great Carbon Valley: a bold new gamble to fight climate change</div>
            <div class="meta">2025-12-22</div>
        </div>
        
        <div id="content-27" style="display:none;">
            <h2>Welcome to Kenya’s Great Carbon Valley: a bold new gamble to fight climate change</h2>
            <p><strong>MIT Technology Review | 2025-12-22</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2025/12/22/1130153/geothermal-energy-carbon-capture-kenya-climate-solution/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The earth around Lake Naivasha, a shallow freshwater basin in south-central Kenya, does not seem to want to lie still.

Ash from nearby Mount Longonot, which erupted as recently as the 1860s, remains in the ground. Obsidian caves and jagged stone towers preside over the steam that spurts out of fissures in the soil and wafts from pools of boiling-hot water—produced by magma that, in some areas, sits just a few miles below the surface.

It’s a landscape born from violent geologic processes some 25 million years ago, when the Nubian and Somalian tectonic plates pulled apart. That rupture cut a depression in the earth some 4,000 miles long—from East Africa up through the Middle East—to create what’s now called the Great Rift Valley.

This volatility imbues the land with vast potential, much of it untapped. The area, no more than a few hours’ drive from Nairobi, is home to five geothermal power stations, which harness the clouds of steam to generate about a quarter of Kenya’s electricity. But some energy from this process escapes into the atmosphere, while even more remains underground for lack of demand.

In June, just north of the lake in the small but strategically located town of Gilgil, the startup began running a high-stakes test. It’s harnessing some of that excess energy to power four prototypes of a machine that promises to remove carbon dioxide from the air in a manner that the company says is efficient, affordable, and—crucially—scalable.

In the short term, the impact will be small—each device’s initial capacity is just 60 tons per year of CO2—but the immediate goal is simply to demonstrate that carbon removal here is possible. The longer-term vision is far more ambitious: to prove that direct air capture (DAC), as the process is known, can be a powerful tool to help the world keep temperatures from rising to ever more dangerous levels.

“We believe we are doing what we can here in Kenya to address climate change and lead the charge for positioning Kenya as a climate vanguard,” Specioser Mutheu, Octavia’s communications lead, told me when I visited the country last year.

The United Nations’ Intergovernmental Panel on Climate Change has stated that in order to keep the world from warming more than 1.5 °C over preindustrial levels (the threshold set out in the Paris Agreement), or even the more realistic but still difficult 2 °C, it will need to significantly reduce future fossil-fuel emissions—and also pull from the atmosphere billions of tons of carbon that have already been released.

Some argue that DAC, which uses mechanical and chemical processes to suck carbon dioxide from the air and store it in a stable form (usually underground), is the best way to do that. It’s a technology with immense promise, offering the possibility that human ingenuity and innovation can get us out of the same mess that development caused in the first place.

Last year, the world’s largest DAC plant, Mammoth, came online in Iceland, offering the eventual capacity to remove up to 36,000 tons of CO₂ per year—roughly equal to the emissions of 7,600 gas-powered cars. The idea is that DAC plants like this one will remove and permanently store carbon and create carbon credits that can be purchased by corporations, governments, and local industrial producers, which will collectively help keep the world from experiencing the most dangerous effects of climate change.

Now, Octavia and a growing number of other companies, politicians, and investors from Africa, the US, and Europe are betting that Kenya’s unique environment holds the keys to reaching this lofty goal—which is why they’re pushing a sweeping vision to remake the Great Rift Valley into the “Great Carbon Valley.” And they hope to do so in a way that provides a genuine economic boost for Kenya, while respecting the rights of the Indigenous people who live on this land. If they can do so, the project could not just give a needed jolt to the DAC industry—it could also provide proof of concept for DAC across the Global South, which is particularly vulnerable to the ravages of climate change despite bearing very little responsibility for it.

But DAC is also a controversial technology, unproven at scale and wildly expensive to operate. In May, an Icelandic news outlet published an investigation into Climeworks, which runs the Mammoth plant, finding that it didn’t even pull in enough carbon dioxide to offset its own emissions, let alone the emissions of other companies.

Critics also argue that the electricity DAC requires can be put to better use cleaning up our transportation systems, heating our homes, and powering other industries that still rely largely on fossil fuels. What’s more, they say that relying on DAC can give polluters an excuse to delay the transition to renewables indefinitely. And further complicating this picture is shrinking demand from governments and corporations that would be DAC’s main buyers, which has left some experts questioning whether the industry will even survive.

Carbon removal is a technology that seems always on the verge of kicking in but never does, says Fadhel Kaboub, a Tunisian economist and advocate for an equitable green transition. “You need billions of dollars of investment in it, and it’s not delivering, and it’s not going to deliver anytime soon. So why do we put the entire future of the planet in the hands of a few people and a technology that doesn’t deliver?”

Layered on top of concerns about the viability and wisdom of DAC is a long history of distrust from the Maasai people who have called the Great Rift Valley home for generations but have been displaced in waves by energy companies coming in to tap the land’s geothermal reserves. And many of those remaining don’t even have access to the electricity generated by these plants.

It’s an immensely complicated landscape to navigate. But if the project can indeed make it through, Benjamin Sovacool, an energy policy researcher and director of the Boston University Institute for Global Sustainability, sees immense potential for countries that have been historically marginalized from climate policy and green energy investment. Though he’s skeptical about DAC as a near-term climate solution, he says these nations could still see big benefits from what could be a multitrillion-dollar industry.

“[Of] all the technologies we have available to fight climate change, the idea of reversing it by sucking CO2 out of the air and storing it is really attractive. It’s something even an ordinary person can just get,” Sovacool says. “If we’re able to do DAC at scale, it could be the next huge energy transition.”

But first, of course, the Great Carbon Valley has to actually deliver.

The “Great Carbon Valley” is both a broad vision for the region and a company founded to shepherd that vision into reality.

Bilha Ndirangu, a 42-year-old MIT electrical engineering graduate who grew up in Nairobi, has long worried about the impacts of climate change on Kenya. But she doesn’t want the country to be a mere victim of rising temperatures, she tells me; she hopes to see it become a source of climate solutions. So in 2021, Ndirangu cofounded Jacob’s Ladder Africa, a nonprofit with the goal of preparing African workers for green industries.

She also began collaborating with the Kenyan entrepreneur James Irungu Mwangi, the CEO of Africa Climate Ventures, an investment firm focused on building and accelerating climate-smart businesses. He’d been working on an idea that spoke to their shared belief in the potential for the country’s vast geothermal capacity; the plan was to find buyers for Kenya’s extra geothermal energy in order to kick-start the development of even more renewable power. One energy-hungry, climate-positive industry stood out: direct air capture of carbon dioxide.

The Great Rift Valley was the key to this vision. The thinking was that it could provide the cheap energy needed to power affordable DAC at scale while offering an ideal geology to effectively store carbon deep underground after it was extracted from the air. And with nearly 90% of the country’s grid already powered by renewable energy, DAC wouldn’t be siphoning power away from other industries that need it. Instead, attracting DAC to Kenya could provide the boost needed for energy providers to build out their infrastructure and expand the grid—ideally connecting the roughly 25% of people in the country who lack electricity and reducing scenarios in which power has to be rationed.

“This push for renewable energy and the decarbonization of industries is providing us with a once-in-a-lifetime sort of opportunity,” Ndirangu tells me.

So in 2023, the pair founded Great Carbon Valley, a project development company whose mission is attracting DAC companies to the area, along with other energy-intensive industries looking for renewable power.

It has already brought on high-profile companies like the Belgian DAC startup Sirona Technologies, the French DAC company Yama, and Climeworks, the Swiss company that operates Mammoth and another DAC plant in Iceland (and was on MIT Technology Review’s 10 Breakthrough Technologies list in 2022, and the list of Climate Tech Companies to Watch in 2023). All are planning on launching pilot projects in Kenya in the coming years, with Climeworks announcing plans to complete its Kenyan DAC plant by 2028. GCV has also partnered with Cella, an American carbon-storage company that works with Octavia, and is facilitating permits for the Icelandic company Carbfix, which injects the carbon from Climeworks’ DAC facilities.

“Climate change is disproportionately impacting this part of the world, but it’s also changing the rules of the game all over the world,” Cella CEO and cofounder Corey Pattison tells me, explaining the draw of Mwangi and Ndirangu’s concept. “This is also an opportunity to be entrepreneurial and creative in our thinking, because there are all of these assets that places like Kenya have.”

Not only can the country offer cheap and abundant renewable energy, but supporters of Kenyan DAC hope that the young and educated local workforce can supply the engineers and scientists needed to build out this infrastructure. In turn, the business could open opportunities to the country’s roughly 6 million un- or under-employed youths.

“It’s not a one-off industry,” Ndirangu says, highlighting her faith in the idea that jobs will flow from green industrialization. Engineers will be needed to monitor the DAC facilities, and the additional demand for renewable power will create jobs in the energy sector, along with related services like water and hospitality.

“You’re developing a whole range of infrastructure to make this industry possible,” she adds. “That infrastructure is not just good for the industry—it’s also just good for the country.”

In June of last year, I walked up a dirt path to the HQ of Octavia Carbon, just off Nairobi’s Eastern Bypass Road, on the far outskirts of the city.

The staffers I met on my tour exuded the kind of boundless optimism that’s common in early-stage startups. “People used to write academic articles about the fact that no human will ever be able to run a marathon in less than two hours,” Octavia CEO Martin Freimüller told me that day. The Kenyan marathon runner Eliud Kipchoge broke that barrier in a race in 2019. A mural of him features prominently on the wall, along with the athlete’s slogan, “No human is limited.”

“It’s impossible, until Kenya does it,” Freimüller added.

Although not an official partner of Ndirangu’s Great Carbon Valley venture, Octavia aligns with the larger vision, he told me. The company got its start in 2022, when Freimüller, an Austrian development consultant, met Duncan Kariuki, an engineering graduate from the University of Nairobi, in the OpenAir Collective, an online forum devoted to carbon removal. Kariuki introduced Freimüller to his classmates Fiona Mugambi and Mike Bwondera, and the four began working on a DAC prototype, first in lab space borrowed from the university and later in an apartment. It didn’t take long for neighbors to complain about the noise, and within six months, the operation had moved to its current warehouse.

That same year, they announced their first prototype, affectionately called Thursday after the day it was unveiled at a Nairobi Climate Network event. Soon, Octavia was showing off its tech to high-profile visitors including King Charles III and President Joe Biden’s ambassador to Kenya, Meg Whitman.

Three years later, the team has more than 40 engineers and has built its 12th DAC unit: a metal cylinder about the size of a large washing machine, containing a chemical filter using an amine, an organic compound derived from ammonia. (Octavia declined to provide further details about the arrangement of the filter inside the machine because the company is awaiting approval of a patent for the design.)

Hannah Wanjau, an engineer at the company, explained how it works: Fans draw air from the outside across the filter, causing carbon dioxide (which is acidic) to react with the basic amine and form a carbonate salt. When that mixture is heated inside a vacuum to 80 to 100 °C, the CO2 is released, now as a gas, and collected in a special chamber, while the amine can be reused for the next round of carbon capture.

The amine absorption method has been used in other DAC plants around the world, including those operated by Climeworks, but Octavia’s project stands apart on several key fronts. Wanjau explained that its technology is tailored to suit the local climate; the company has adjusted the length of time for absorption and the temperature for CO2 release, making it a potential model for other countries in the tropics.

And then there’s its energy source: The device operates on more than 80% thermal energy, which in the field will consist of the extra geothermal energy that the power plants don’t convert into electricity. This energy is typically released into the atmosphere, but it will be channeled instead to Octavia’s machines. What’s more, the device’s modular design can fit inside a shipping container, allowing the company to easily deploy dozens of these units once the demand is there, Mutheu told me.

This technology is being tested in the field in Gilgil, where Mutheu told me the company is “continuing to capture and condition CO₂ as part of our ongoing operations and testing cycles.” (She declined to provide specific data or results at this stage.)

Once the CO2 is captured, it will be heated and pressurized. Then it will be pumped to a nearby storage facility operated by Cella, where the company will inject the gas into fissures underground. The region’s special geology again offers an advantage: Much of the rock found underground here is basalt, a volcanic mineral that contains high concentrations of calcium and magnesium ions. They react with carbon dioxide to form substances like calcite, dolomite, and magnesite, locking the carbon atoms away in the form of solid minerals.

This process is more durable than other forms of carbon storage, making it potentially more attractive to buyers of carbon credits, says Pattison, the Cella CEO. Non-geologic carbon mitigation methods, such as cookstove replacement programs or nature-based solutions like tree planting, have recently been rocked by revelations of fraud or exaggeration. The money for Cella’s pilot, which will see the injection of 200 tons of CO2 this year, has come mainly from the Frontier advance market commitment, under which a group of companies including Stripe, Google, Shopify, Meta, and others has collectively pledged to spend $1 billion on carbon removal by 2030.

These projects have already opened up possibilities for young Kenyans like Wanjau. She told me there were not a lot of opportunities for aspiring mechanical engineers like her to design and test their own devices; many of her classmates were working for construction or oil companies, or were unemployed. But almost immediately after graduation, Wanjau began working for Octavia.

“I’m happy that I’m trying to solve a problem that’s a real-world issue,” she told me. “Not many people in Africa get a chance to do that.”

Despite the vast enthusiasm from partners and investors, the Great Carbon Valley faces multiple challenges before Ndirangu and Mwangi’s vision can be fully realized.

Since its start, the venture has had to contend with “this perception that doing projects in Africa is risky,” says Ndirangu. Of the dozens of DAC facilities planned or in existence today, only a handful are in the Global South. Indeed, Octavia has described itself as the first DAC plant to be located there. “Even just selling Kenya as a destination for DAC was quite a challenge,” she says.

So Ndirangu played up Kenya’s experience developing geothermal resources, as well as local engineering talent and a lower cost of labor. GCV has also offered to work with the Kenyan government to help companies secure the proper permits to break ground as soon as possible.

Ndirangu says that she’s already seen “a real appetite” from power producers who want to build out more renewable-energy infrastructure, but at the same time they’re waiting for proof of demand. She envisions that once that power is in place, lots of other industries—from data centers to producers of green steel, green ammonia, and sustainable aviation fuels—will consider basing themselves in Kenya, attracting more than a dozen projects to the valley in the next few years.

But recent events could dampen demand (which some experts already worried was insufficient). Global governments are retreating from climate action, particularly in the US. The Trump administration has dramatically slashed funding for development related to climate change and renewable energy. The Department of Energy appears poised to terminate a $50 million grant to a proposed Louisiana DAC plant that would have been partially operated by Climeworks, and in May, not long after that announcement, the company said it was cutting 22% of its staff.

At the same time, many companies that would have likely been purchasers of carbon credits—and that a few years ago had voluntarily pledged to reduce or eliminate their carbon emissions—are quietly walking back their commitments. Over the long term, experts warn, there are limits to the amount of carbon removal that companies will ever voluntarily buy. They argue that governments will ultimately have to pay for it—or require polluters to do so.

Further compounding all these challenges are costs. Critics say DAC investments are a waste of time and money compared with other forms of carbon drawdown. As of mid-December, carbon removal credits in the European Union’s Emissions Trading System, one of the world’s largest carbon markets, were priced at around $84 per ton. The average price per DAC credit, for comparison, is nearly $450. Natural processes like reforestation absorb millions of tons of carbon annually and are far cheaper (though programs to harness them for carbon credits are beset with their own controversies). Ultimately, DAC continues to operate on a small scale, removing only about 10,000 metric tons of CO2 each year.

Even if DAC suppliers do manage to push past these obstacles, there are still thorny questions coming from inside Kenya. Groups like Power Shift Africa, a Nairobi-based think tank that advocates for climate action on the continent, have derided carbon credits as “pollution permits” and blamed them for delaying the move toward electrification.

“The ultimate goal of [carbon removal] is that you can say at the end, well, we can actually continue our emissions and just recapture them with this technology,” says Kaboub, the Tunisian economist, who has worked with Power Shift Africa. “So there&#39;s no need to end fossil fuels, which is why you get a lot of support from oil countries and companies.”

Another problem he sees is not limited to DAC but extends to the way that Kenya and other African nations are pursuing their goal of green industrialization. While Kenyan President William Ruto has courted international financial investment to turn Kenya into a green energy hub, his administration’s policies have deepened the country’s external debt, which in 2024 was equal to around 30% of its GDP. Geothermal energy development in Kenya has often been financed by loans from international institutions or other governments. As its debt has risen, the country has enacted national austerity measures that have sparked deadly protests.

Kenya may indeed have advantages over other countries, and DAC costs will most likely go down eventually. But some experts, such as Boston University’s Sovacool, aren’t quite sold on the idea that the Great Carbon Valley—or any DAC venture—can significantly mitigate climate change. Sovacool’s research has found that at best, DAC will be ready to deploy on the necessary scale by midcentury, much too late to make it a viable climate solution. And that’s if it can overcome additional costs—such as the losses associated with corruption in the energy sector, which Sovacool and others have found is a widespread problem in Kenya.

Nevertheless, others within the carbon removal industry remain more optimistic about DAC’s overall prospects and are particularly hopeful that Kenya can address some of the challenges the technology has encountered elsewhere. Cost is “not the most important thing,” says Erin Burns, executive director of Carbon180, a nonprofit that advocates for the removal and reuse of carbon dioxide. “There’s lots of things we pay for.” She notes that governments in Japan, Singapore, Canada, Australia, the European Union, and elsewhere are all looking at developing compliance markets for carbon, even though the US is stagnating on this front.

The Great Carbon Valley, she believes, stands poised to benefit from these developments. “It’s big. It’s visionary,” Burns says. “You’ve got to have some ambition here. This isn’t something that is like deploying a technology that’s widely deployed already. And that comes with an enormous potential for huge opportunity, huge gains.”

More than any external factor, the Great Carbon Valley’s future is perhaps most intimately intertwined with the restless earth on which it’s being built, and the community that has lived here for centuries.

To the Maasai people, nomadic pastoralists who inhabit swathes of Eastern Africa, including Kenya, this land around Lake Naivasha is “ol-karia,” meaning “ochre,” after the bright red clay found in abundance.

South of the lake is Hell’s Gate National Park, a 26-square-mile nature reserve where the region’s five geothermal power complexes—with a sixth under construction—churn on top of the numerous steam vents. The first geothermal power plant here was brought into service in 1981 by KenGen, a majority-state-owned electricity company; it was named Olkaria.

But for decades most of the Maasai haven’t had access to that electricity. And many of them have been forced off the land in a wave of evictions. In 2014, construction on a KenGen geothermal complex expelled more than 2,000 people and led to a number of legal complaints. At the same time, locals living near a different, privately owned geothermal complex 50 miles north of Naivasha have complained of noise and air pollution; in March, a Kenyan court revoked the operating license of one of the project’s three plants.

Neither Octavia or Cella is powered by output from these two geothermal producers, but activists have warned that similar environmental and social harms could resurface if demand for new geothermal infrastructure grows in Kenya—demand that could be driven by DAC.

Ndirangu says she believes some of the complaints about displacement are “exaggerated,” but she nonetheless acknowledges the need for stronger community engagement, as does Octavia. In the long term, Ndirangu says, she plans to provide job training to residents living near the affected areas and integrate them into the industry, although she also says those plans need to be realistic. “You don’t want to create the wrong expectation that you will hire everyone from the community,” she says.

That’s part of the problem for Maasai activists like Agnes Koilel, a teacher living near the Olkaria geothermal field. Despite past promises of employment at the power plants, the jobs that are offered are lower-paying positions in cleaning or security. “Maasai people are not [as] employed as they think,” she says.

DAC is a small industry, and it can’t do everything. But if it’s going to become as big as Ndirangu, Freimüller, and other proponents of the Great Carbon Valley hope it will be, creating jobs and driving Kenya’s green industrialization, communities like Koilel’s will be among those most directly affected—much as they are by climate change.

When I asked Koilel what she thought about DAC development near her home, she told me she had never heard of the Great Carbon Valley idea, or of carbon removal in general. She wasn’t necessarily against geothermal power development on principle, or opposed to any of the industries that might push it to expand. She just wants to see some benefits, like a health center for her community. She wants to reverse the evictions that have pushed her neighbors off their land. And she wants electricity—the same kind that would power the fans and pumps of future DAC hubs.

Power “is generated from these communities,” Koilel said. “But they themselves do not have that light.”

Diana Kruzman is a freelance journalist covering environmental and human rights issues around the world. Her writing has appeared in New Lines Magazine, The Intercept, Inside Climate News, and other publications. She lives in New York City.

As early electric cars age out, hundreds of thousands of used batteries are flooding the market, fueling a gray recycling economy even as Beijing and big manufacturers scramble to build a more orderly system.

We got a sneak peek inside Found Energy’s lab, just as it gears up to supply heat and hydrogen to its first customer.

And why many scientists are freaked out about the first serious for-profit company moving into the solar geoengineering field.

Omar Yaghi thinks crystals with gaps that capture moisture could bring technology from “Dune” to the arid parts of Earth.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-28')">
            <div class="source">MIT Technology Review</div>
            <div class="title">This company is developing gene therapies for muscle growth, erectile dysfunction, and “radical longevity”</div>
            <div class="meta">2025-12-22</div>
        </div>
        
        <div id="content-28" style="display:none;">
            <h2>This company is developing gene therapies for muscle growth, erectile dysfunction, and “radical longevity”</h2>
            <p><strong>MIT Technology Review | 2025-12-22</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2025/12/22/1130288/gene-therapies-muscle-growth-erectile-dysfunction-radical-longevity/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">At some point next month, a handful of volunteers will be injected with two experimental gene therapies as part of an unusual clinical trial. The drugs are potential longevity therapies, says Ivan Morgunov, the CEO of Unlimited Bio, the company behind the trial. His long-term goal: to achieve radical human life extension.

The 12 to 15 volunteers—who will be covering their own travel and treatment costs—will receive a series of injections in the muscles of their arms and legs. One of the therapies is designed to increase the blood supply to those muscles. The other is designed to support muscle growth. The company hopes to see improvements in strength, endurance, and recovery. It also plans to eventually trial similar therapies in the scalp (for baldness) and penis (for erectile dysfunction).

But some experts are concerned that the trial involves giving multiple gene therapies to small numbers of healthy people. It will be impossible to draw firm conclusions from such a small study, and the trial certainly won’t reveal anything about longevity, says Holly Fernandez Lynch, a lawyer and medical ethicist at the University of Pennsylvania in Philadelphia.

Unlimited Bio’s muscle growth therapy is already accessible at clinics in Honduras and Mexico, says Morgunov—and the company is already getting some publicity. Khloe Kardashian tagged Unlimited Bio in a Facebook post about stem-cell treatments she and her sister Kim had received at the Eterna clinic in Mexico in August. And earlier this week, the biohacking influencer Dave Asprey posted an Instagram Reel of himself receiving one of the treatments in Mexico; it was shared with 1.3 million Instagram followers. In the video, Eterna’s CEO, Adeel Khan, says that the therapy can “help with vascular health systemically.” “I’m just upgrading my system for a little while to reduce my age and reduce my vascular risk,” Asprey said.

Gene therapies typically work by introducing new genetic code into the body’s cells. This code is then able to make proteins. Existing approved gene therapies have typically been developed for severe diseases in which the target proteins are either missing or mutated.

But several groups are exploring gene therapies for healthy people. One of these companies is Minicircle, which developed a gene therapy to increase production of follistatin, a protein found throughout the body that has many roles and is involved in muscle growth. The company says this treatment will increase muscle mass—and help people live longer. Minicircle is based in Próspera, a special economic zone in Honduras with its own bespoke regulatory system. Anyone can visit the local clinic and receive that therapy, for a reported price of $25,000. And many have, including the wealthy longevity influencer Bryan Johnson, who promoted the therapy in a Netflix documentary.

Unlimited Bio’s Morgunov, a Russian-Israeli computer scientist, was inspired by Minicircle’s story. He is also interested in longevity. Specifically, he’s committed to radical life extension and has said that he could be part of “the last generation throughout human history to die from old age.” He believes the biggest “bottleneck” slowing progress toward anti-aging or lifespan-extending therapies is drug regulation. So he, too, incorporated his own biotech company in Próspera.

“A company like ours couldn’t exist outside of Próspera,” says Unlimited Bio’s chief operating officer, Vladimir Leshko.

There, Morgunov and his colleagues are exploring two gene therapies. One of these is another follistatin therapy, which the team hopes will increase muscle mass. The other codes for a protein called vascular endothelial growth factor, or VEGF. This compound is known to encourage the growth of blood vessels. Morgunov and his colleagues hope the result will be increased muscle growth, enhanced muscle repair, and longer life. Neither treatment is designed to alter a recipient’s DNA, and therefore it won’t be inherited by future generations.

The combination of the two therapies could benefit healthy people and potentially help them live longer, says Leshko, a former electrical engineer and professional poker player who retrained in biomedical engineering. “We would say that it’s a preventive-slash-enhancing indication,” he says. “Potentially participants can experience faster recovery from exercise, more strength, and more endurance.”

Of the 12 to 15 volunteers who participate in the trial, half will receive only the VEGF therapy. The other half will receive both the VEGF and the follistatin therapies. The treatments will involve a series of injections throughout large muscles in the arms and legs, says Morgunov.

He is confident that the VEGF therapy is safe. It was approved in Russia over a decade ago to treat lower-limb ischemia—a condition that can cause pain, numbness, and painful ulcers in the legs and feet. Morgunov reckons that around 10,000 people in Russia have already had the drug, although he says he hasn’t “done deep fact-checking on that.”

VEGF is a powerful compound, says Seppo Ylä-Herttuala, a professor of molecular medicine at the University of Eastern Finland who has been studying VEGF and potential VEGF therapies for decades. He doesn’t know how many people have had VEGF gene therapy in Russia. But he does know that the safety of the therapy will depend on how much is administered and where. Previous attempts to inject the therapy into the heart, for example, have resulted in edema, a sometimes fatal buildup of fluid. Even if the therapy is injected elsewhere, VEGF can travel around the body, he says. If it gets to the eye, for example, it could cause blindness. Leshko counters that the VEGF should remain where it is injected, and any other circulation in the body, if it occurs, should be short-lived.

And while the therapy has been approved in Russia, there’s a reason it hasn’t been approved elsewhere, says Ylä-Herttuala: The clinical trials were not as rigorous as they could have been. While “it probably works in some patients,” he says, the evidence to support the use of this therapy is weak. At any rate, he adds, VEGF will only support the growth of blood vessels—it won’t tackle aging.  “VEGF is not a longevity drug,” he says.

Leshko points to a 2021 study in mice, which suggested that a lack of VEGF activity might drive aging in the rodents. “We’re convinced it qualifies as a potential longevity drug,” he says.

There is even less data about follistatin. Minicircle, the company selling another follistatin gene therapy, has not published any rigorous clinical trial data. So far, much of the evidence for follistatin’s effects comes from research in rodents, says Ylä-Herttuala.

Clinical trials like this one should gather more information, both about the therapies and about the methods used to get those therapies into the body. Unlimited Bio’s VEGF therapy will be delivered via a circular piece of genetic code called a plasmid. Its follistatin therapy, on the other hand, will be delivered via an adeno-associated virus (AAV). Plasmid therapies are easier to make, and they have a shorter lifespan in the body—only a matter of days. They are generally considered to be safer than AAV therapies. AAV therapies, on the other hand, tend to stick around for months, says Ylä-Herttuala. And they can trigger potentially dangerous immune reactions.

It’s debatable whether healthy people should be exposed to these risks, says Fernandez Lynch. The technology “still has serious questions about its safety and effectiveness,” even for people with life-threatening diseases, she says. “If you are a healthy person, the risk of harm is more substantial because it’ll be more impactful on your life.”

But Leshko is adamant. “Over 120,000 humans die DAILY from age-related causes,” he wrote in an email. “Building ‘ethical’ barriers around ‘healthy’ human (in fact, aging human) trials is unethical.” Morgunov did not respond to a request for comment.

Some people want to take those risks anyway. In his video, the biohacker influencer Asprey—who has publicly stated that he’s “going to live to 180”—described VEGF as a “longevity compound,” and Eterna’s CEO Khan, who delivered the treatment, described it as “the ultimate upgrade.” Neither Asprey nor Khan clinic responded to requests for comment.

Michael Gusmano, a professor of health policy at Lehigh University in Bethlehem, Pennsylvania, worries that this messaging might give trial participants unrealistic expectations about how they might benefit. There is “huge potential for therapeutic misconception when you have some kind of celebrity online influencer touting something about which there is relatively sparse scientific evidence,” he says. In reality, he adds, “the only thing you can guarantee is that [the volunteers] will be contributing to our knowledge of how this intervention works.”

“I would certainly not recommend that anyone I know enter into such a trial,” says Gusmano.

The muscle study is only the first step. The Unlimited Bio team hopes to trial the VEGF therapy for baldness and erectile dysfunction, too. Leshko points to research in mice that links high VEGF levels to larger, denser hair follicles. He hopes to test a series of VEGF therapy injections into the scalps of volunteers. Morgunov, who is largely bald, has already started to self-experiment with the approach.

An erectile dysfunction trial may follow. “That one we think has great potential because injecting gene therapy into the penis sounds exciting,” says Leshko. A protocol for that trial has not yet been finalized, but he imagines it would involve “five to 10” injections.

Ylä-Herttuala isn’t optimistic about either approach. Hair growth is largely hormonal, he says. And injecting anything into a penis risks damaging it (although Leshko points out that a similar approach was taken by another company almost 20 years ago). Injecting a VEGF gene therapy into the penis would also risk edema there, Ylä-Herttuala adds.

And he points out that we already have some treatments for hair loss and erectile dysfunction. While they aren’t perfect, their existence does raise the bar for any potential future therapies—not only do they have to be safe and effective, but they must be safer or more effective than existing ones.

That doesn’t mean the trials will flop. No small trial can be definitive, but it could still provide some insight into how these drugs are working. It is possible that the therapies will increase muscle mass, at least, and that this could be beneficial to the healthy recipients, says Ylä-Herttuala.

Before our call, he had taken a look at Unlimited Bio’s website, which carries the tagline “The Most Advanced Rejuvenation Solution.” “They promise a lot,” he said. “I hope it’s true.”

The sunshine vitamin could affect your immune system and heart health.

Yes, you can pay $50,000 to clone a pet. But others are using the technology to rescue endangered species.

Preventing the common cold is extremely tricky—but not impossible.

Entrepreneurs say it’s time to safety-test designer baby technology.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-29')">
            <div class="source">MIT Technology Review</div>
            <div class="title">The Download: China’s dying EV batteries, and why AI doomers are doubling down</div>
            <div class="meta">2025-12-19</div>
        </div>
        
        <div id="content-29" style="display:none;">
            <h2>The Download: China’s dying EV batteries, and why AI doomers are doubling down</h2>
            <p><strong>MIT Technology Review | 2025-12-19</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2025/12/19/1130167/the-download-chinas-dying-ev-batteries-and-why-ai-doomers-are-doubling-down/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">This is today&#39;s edition of The Download, our weekday newsletter that provides a daily dose of what&#39;s going on in the world of technology.

China figured out how to sell EVs. Now it has to bury their batteries.

In the past decade, China has seen an EV boom, thanks in part to government support. Buying an electric car has gone from a novel decision to a routine one; by late 2025, nearly 60% of new cars sold were electric or plug-in hybrids.But as the batteries in China’s first wave of EVs reach the end of their useful life, early owners are starting to retire their cars, and the country is now under pressure to figure out what to do with those aging components.The issue is putting strain on China’s still-developing battery recycling industry and has given rise to a gray market that often cuts corners on safety and environmental standards. National regulators and commercial players are also stepping in, but so far these efforts have struggled to keep pace with the flood of batteries coming off the road. Read the full story.—Caiwei Chen

It’s a weird time to be an AI doomer.This small but influential community believes, in the simplest terms, that AI could get so good it could be bad—very, very bad—for humanity.The doomer crowd has had some notable success over the past several years: including helping shape AI policy coming from the Biden administration. But a number of developments over the past six months have put them on the back foot. Talk of an AI bubble has overwhelmed the discourse as tech companies continue to invest in multiple Manhattan Projects’ worth of data centers without any certainty that future demand will match what they’re building.So where does this leave the doomers? We decided to ask some of the movement’s biggest names to see if the recent setbacks and general vibe shift had altered their views. See what they had to say in our story.—Garrison Lovely

This story is part of our new Hype Correction package, a collection of stories designed to help you reset your expectations about what AI makes possible—and what it doesn’t. Check out the rest of the package.

Take our quiz on the year in health and biotechnology

In just a couple of weeks, we’ll be bidding farewell to 2025. And what a year it has been! Artificial intelligence is being incorporated into more aspects of our lives, weight-loss drugs have expanded in scope, and there have been some real “omg” biotech stories from the fields of gene therapy, IVF, neurotech, and more.Jessica Hamzelou, our senior biotech reporter, is inviting you to put your own memory to the test. So how closely have you been paying attention this year?

This article first appeared in The Checkup, MIT Technology Review’s weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first, sign up here.

I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.

1 TikTok has signed a deal to sell its US unit Its new owner will be a joint venture controlled by American investors including Oracle. (Axios)+ But the platform is adamant that its Chinese owner will retain its core US business. (FT $)+ The deal is slated to close on January 22 next year. (Bloomberg $)+ It means TikTok will sidestep a US ban—at least for now. (The Guardian)2 A tip on Reddit helped to end the hunt for the Brown University shooterThe suspect, who has been found dead, is also suspected of killing an MIT professor. (NYT $)+ The shooter’s motivation is still unclear, police say. (WP $)3 Tech leaders are among those captured in newly-released Epstein photosBill Gates and Google’s Sergey Brin are both in the pictures. (FT $)+ They’ve been pulled from a tranche of more than 95,000. (Wired $)

4 A Starlink satellite appears to have explodedAnd it’s now falling back to earth. (The Verge)+ On the ground in Ukraine’s largest Starlink repair shop. (MIT Technology Review)

5 YouTube has shut down two major channels that share fake movie trailersScreen Culture and KH Studio uploaded AI-generated mock trailers with over a billion views. (Deadline)+ Google is treading a thin line between embracing and shunning generative AI. (Ars Technica)

6 Trump is cracking down on investment in Chinese tech firmsLawmakers are increasingly worried that US money is bolstering the country’s surveillance state. (WSJ $)+ Meanwhile, China is working on boosting its chip output. (FT $)

7 ICE has paid an AI agent company to track down targetsIt claims to be able to rapidly trace a target’s online network. (404 Media)8 America wants to return to the Moon by 2028And to build some nuclear reactors while it’s up there. (Ars Technica)+ Southeast Asia seeks its place in space. (MIT Technology Review)

9 Actors in the UK are refusing to be scanned for AIThey’re reportedly routinely pressured to consent to creating digital likenesses of themselves. (The Guardian)+ How Meta and AI companies recruited striking actors to train AI. (MIT Technology Review)

10 Indian tutors are explaining how to use AI over WhatsAppLessons are cheap and personalized—but the teachers aren’t always credible. (Rest of World)+ How Indian health-care workers use WhatsApp to save pregnant women. (MIT Technology Review)

&quot;Trump wants to hand over even more control of what you watch to his billionaire buddies. Americans deserve to know if the president struck another backdoor deal for this billionaire takeover of TikTok.&quot;

—Democratic senator Elizabeth Warren queries the terms of the deal that TikTok has made to allow it to continue operating in the US in a post on Bluesky.

Synthesia’s AI clones are more expressive than ever. Soon they’ll be able to talk back.

Earlier this summer, I visited the AI company Synthesia to create a hyperrealistic AI-generated avatar of me. The company’s avatars are a decent barometer of just how dizzying progress has been in AI over the past few years, so I was curious just how accurately its latest AI model, introduced last month, could replicate me.I found my avatar as unnerving as it is technically impressive. It’s slick enough to pass as a high-definition recording of a chirpy corporate speech, and if you didn’t know me, you’d probably think that’s exactly what it was.My avatar shows how it’s becoming ever-harder to distinguish the artificial from the real. And before long, these avatars will even be able to talk back to us. But how much better can they get? And what might interacting with AI clones do to us? Read the full story.

A place for comfort, fun and distraction to brighten up your day. (Got any ideas? Drop me a line or skeet &#39;em at me.)

+ You can keep your beef tallow—here are the food trends that need to remain firmly in 2025.+ The Library of Congress has some lovely images of winter that are completely free to use.+ If you’ve got a last minute Christmas work party tonight, don’t make these Secret Santa mistakes.+ Did you realize Billie Eilish’s smash hit Birds of a Feather has the same chord progression as Wham’s Last Christmas? They sound surprisingly good mashed together.

Plus: OpenAI is sounding the &quot;code red&quot; alarm

Plus: China is considering cutting its native data centers a deal

Plus: how influential tech figures hope to influence US AI regulation

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-30')">
            <div class="source">The Next Web</div>
            <div class="title">Engineering’s AI reality check</div>
            <div class="meta">2025-12-19</div>
        </div>
        
        <div id="content-30" style="display:none;">
            <h2>Engineering’s AI reality check</h2>
            <p><strong>The Next Web | 2025-12-19</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/engineerings-ai-reality-check">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Most engineering leaders cannot answer the one question their CFO is about to ask: “Can you prove this AI spend is changing outcomes, not just activity?”

Every December, roadmaps get locked, budgets get approved, and board decks are polished until everything looks precise and under control. Underneath, many CTOs and VPs are still working with partial visibility. They have a feel for their teams, but not a reliable view of how work moves through the system, how AI is really changing delivery, or where time and money actually go.

For a while, that was survivable. Experience, pattern recognition, and cheap capital covered the gaps. You could hire around bottlenecks, overstaff critical teams, or quietly pivot away from the messiest parts of the system. Then AI showed up and became the perfect distraction. Pilots, PoCs, Copilot seats, and “AI initiatives” created visible activity and bought time.

In 2026, that grace period ends. Boards and CFOs are shifting from “show me you are experimenting” to “show me measurable impact, this year.” Not because they stopped believing in AI, but because the market no longer rewards vague promises. Every AI dollar will need a traceable path to productivity, quality, or customer value.

TNW City Coworking space - Where your best work happens

A workspace designed for growth, collaboration, and endless networking opportunities in the heart of tech.

If you run engineering, you probably recognise this scene. You present a slide with AI highlights. Adoption is up. Developers say they like the tools. You share a few anecdotes about faster coding and smoother reviews. Then the CFO asks a simple question: “Exactly how is this budget changing output and outcomes?”

What is almost always missing is a clear breakdown of:

So the conversation slips back to learning curves, compounding benefits, and talent attraction. All true, but too soft for a tough budget review. That will not be enough.

AI vendors love task-level numbers. A coding task completed 55 percent faster looks impressive on a slide. But once you zoom out to teams and systems, the picture changes.

Large datasets across thousands of developers show a consistent pattern:

The problem is not the tools. It is the lack of a system for where the “extra” capacity goes.

Most organisations still frame AI productivity in terms of speed: more story points, more tickets, higher deployment frequency. That misses the bigger question:

How much of our engineering capacity goes to net new value versus maintenance, incidents, and rework, and is AI improving that mix?

High-level benchmarks are blunt but helpful. On average, about 45 percent of developer time is spent on maintenance, minor enhancements, and bug fixes rather than on genuinely new, customer-facing work. If AI helps you produce more code inside an unchanged system, you risk:

That is how you end up with impressive local metrics and a leadership team that still feels like engineering is slowing down.

If you want to walk into a 2026 budget conversation with objective evidence, you need to be deliberate about how AI-driven time savings are used. Two moves matter.

AI is already good at boilerplate, tests, documentation, and simple refactors. The trap is treating the saved time as unstructured “extra” capacity that disappears into the noise. Instead:

When teams systematically reduce technical debt and improve tests around critical flows, they cut future incidents and rework. Over a year, that frees more capacity for new work than shaving a few minutes off each ticket ever will.

2. Point AI at the ugly, high-friction work that commonly blows up roadmaps

The biggest productivity wins are not in everyday code generation. They are in:

These activities steal weeks or months of capacity and stall strategic initiatives. Using AI to understand legacy code faster, propose refactoring plans, generate migration scaffolding, and highlight recurring failure patterns can dramatically compress timelines for this work.

In parallel, there is real leverage upstream in the problem space. Teams that reach higher levels of AI adoption report better gains when they:

That reduces wasted builds and focuses effort on changes customers actually care about. The most significant gains do not come from replacing human creativity, but from amplifying it and aiming it at better-defined problems.

DORA metrics are not the enemy. Deployment frequency, lead time, MTTR, and change failure rate remain among the best signals we have for delivery performance. The risk is mistaking them for the whole picture.

Leading organisations are already expanding their scorecard to include:

In 2026, the question in the boardroom will shift from “Are we elite on DORA?” to “How much of our capacity is going into things customers notice, and is AI improving that mix or not?” To answer that cleanly, DORA is necessary but not sufficient. You need a way to connect AI usage, workflow, quality, and business outcomes across the system.

This is where engineering intelligence platforms move from a nice-to-have to mandatory. The organisations that win in 2026 will not do it with one more AI tool or one more disconnected dashboard. They will do it by pulling together data they already have but rarely use in one coherent view:

From there, leaders can answer the questions that actually matter:

Instead of defending AI spend with anecdotes, you walk in with:

That is the difference between “we believe in AI” and “here is how AI changed our delivery engine in measurable ways.”

To be ready for the more complex questions coming next year, use this planning cycle to do four things.

Do this, and you will not just have “AI activity” to show in 2026. You will have a credible, data-backed story from AI spend to business outcomes.

The leaders who thrive next year will not be the ones with the flashiest AI demos or the loudest “AI strategy” slide. They will be the ones who:

Engineering intelligence platforms is a key part of that shift. They give you the complex data to show where time and money go, how AI is really changing delivery, and whether your current pace is sustainable. The shift to data-backed engineering leadership is happening either way.

The gap in 2026 will be between teams still guessing and teams that can prove, in detail, how their engineering organisation works.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-31')">
            <div class="source">The Next Web</div>
            <div class="title">Letter from the Editor-in-Chief</div>
            <div class="meta">2025-12-16</div>
        </div>
        
        <div id="content-31" style="display:none;">
            <h2>Letter from the Editor-in-Chief</h2>
            <p><strong>The Next Web | 2025-12-16</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/letter-from-the-editor-in-chief">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Not long ago, like many of you, I read what I feared might be The Next Web’s final article. In late September, TNW’s co-founder announced that the tech conference and news site would be winding down, no more events, no new stories. It felt like the end of an era; the news hit hard!

Yet, just a few weeks ago, a twist arrived: the tech platform Tekpon acquired 100% of TNW’s media and events brand from the Financial Times, ensuring that this nearly two-decade legacy will continue to thrive.

While, myself, trying to read people’s opinions on this topic, I read this comment in one article, from one former TNW editor-in-chief that said: “The Next Web shaped my career, my life… it’s very sad to see it die”.

The latest rumblings from the EU tech scene, a story from our wise ol&#39; founder Boris, and some questionable AI art. It&#39;s free, every week, in your inbox. Sign up now!

I asked myself: Why do we always assume that just because one chapter ends, the whole story is over? Yes, taking over TNW is a heavy inheritance, especially with all eyes on us and expectations sky-high.

And I’ll admit, doubts crept in: Am I too small for this? Could someone more experienced do it better? Probably. But here I am, stepping up regardless. Because this isn’t just another blog or brand; TNW is a living ecosystem, a vital community. Its story deserves to continue, and I’m determined to help write the next chapter.

I also know some of you might be wondering: Who is she? What does she know? How many articles has she written? What recommends her?

Before reading all sorts of titles and, let me briefly introduce myself.

I’ve been writing since high school, with thousands of articles under my belt; covering everything from culture, art, and hip hop to design, politics, history, and food. I landed my first content writer job at 18, and alongside writing I pursued another passion: becoming a chef.

(Fun fact: I even made it to the semifinals of MasterChef, a journey that taught me about creativity under pressure and staying cool when the heat is on.)

Now, I channel my storytelling skills into helping businesses better understand technology and use it to their advantage. I help companies tell their stories, the real ones, finding meaning and flow in every word.

Over the years, I’ve specialized in blending creative storytelling with the technical precision of a chef’s knife. (My colleagues at Tekpon might say I can be as sharp as that knife – true to my values and quick to cut through the nonsense.) I am also the “No, we have to do it right” person in the team.

I’ve reviewed countless software products, interviewed founders, and explored how digital innovation can be a force for good in society. Or not. In other words, I’ve always cared about the why behind the tech, the real impact on people’s lives, not just the buzz. That perspective will be behind every story we will publish at TNW.

If there’s a place for those who still think stories written by humans matter, tell me where it is. I’m already on my way.

I’m not here to change TNW’s DNA; I’m here to reinforce it with fresh energy and a clear vision for the future.

To the loyal TNW readers, to the startup founders who looked to us for inspiration, to the healthy tech skeptics who counted on us for a reality check, and to our global audience spread across continents: we hear you.

We all know the world of tech news has changed dramatically. Today, everyone has a megaphone, social media overflows with hot takes, and AI algorithms can crank out content in seconds. It’s easy to feel overwhelmed by this sea of opinions and auto-generated articles. In such a world, the role of a publication like TNW is more critical than ever: to be a filter, not just another firehose of content.

We will focus on curation and clarity, distilling the noise so you don’t have to.

Here’s the good news: despite the deluge of AI-written text out there, readers are actively looking for authentic, human journalism. Every article we will publish will be created by a human writer who is accountable for the facts and who brings context, analysis, and yes, a bit of personality too.

Our mission isn’t to chase every trending headline algorithmically; it’s to help you understand which innovations actually matter, and why.

If a story is everywhere but lacks substance, we won’t regurgitate it; we’ll analyze it or debunk it. If a breakthrough is genuinely promising, we’ll explain why it’s important and how it impacts real people. Being a thoughtful filter in this age of information overload (and AI-generated noise) isn’t just a catchy slogan for us; it’s a responsibility we embrace.

You’ll also notice something different in our approach: an emphasis on storytelling and the human side of tech. Technology doesn’t exist in a vacuum; it’s built and used by people with dreams, dilemmas, and diverse backgrounds.

I believe, and I suspect many of you do too, that the best tech journalism zooms out from the gadgets and code to highlight those human stories. Practically speaking, expect to see more features, interviews, and narrative-driven pieces on TNW.

We’ll talk to founders about the messy, human journey of building a startup, not just the press releases or funding announcements. We’ll spotlight the engineers, designers, and thinkers who are trying to solve big problems (or even small ones that make a big difference). We’ll explore tech’s impact on society: the good, the bad, and the complicated.

This won’t be a place for recycled press releases or surface-level takes. It will be a place for conversation and insight.

Importantly, none of this focus on storytelling means we’ll skimp on rigor. Being engaging doesn’t mean sacrificing accuracy or depth. My team will continue to prioritize thorough research and fact-checking, those good old-school journalism values, even as we experiment with new formats and new voices. In short, we won’t publish anything we wouldn’t want to read ourselves.

Today, looking forward means acknowledging that how we cover tech is as important as what we cover. It means committing to journalism that cuts through the clutter, to storytelling that puts people first, and to a vision of tech’s future that is both hopeful and honest. That’s my vision for TNW as I step into this role, and I hope it resonates with you.

Now, I’d like to turn it over to you, our community. This is your TNW as much as it is ours. I invite you to join the conversation. Tell us what you want to see more of (or less of). Hold us accountable,if we ever fall short, let us know. Share your stories and perspectives with us, because they can inspire our coverage.

In the coming weeks, you’ll start to see this vision take shape on the site. You’ll see familiar faces and new voices. You’ll find articles that make you think, others that make you smile, and hopefully quite a few that make you proud to be a TNW reader.

Whether you’re a long-time follower who’s stuck with us through thick and thin, a startup founder looking for insight, a skeptic keeping us honest, or a curious mind tuning in from anywhere in the world – thank you. We do this for you, and we couldn’t do it without you.

The Next Web is back. We’re here to inform you, inspire you, challenge you, and occasionally even surprise you. I’m honored to have you with us on this journey. Here’s to the road ahead, to storytelling, to journalism (the real kind), and to making sense of the future together.

Thank you for reading, and welcome to TNW’s next chapter. Let’s build it, day by day, story by story, together.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-32')">
            <div class="source">The Next Web</div>
            <div class="title">Is ChatGPT’s New Shopping Research Solving a Problem, or Creating One?</div>
            <div class="meta">2025-12-11</div>
        </div>
        
        <div id="content-32" style="display:none;">
            <h2>Is ChatGPT’s New Shopping Research Solving a Problem, or Creating One?</h2>
            <p><strong>The Next Web | 2025-12-11</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/is-chatgpts-new-shopping-research-solving-a-problem-or-creating-one">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">When OpenAI announced its new shopping search capabilities, I took the news with a grain of salt (perhaps the whole shaker).
For the past decade, we have watched the slow evolution of traditional search engines. What began as tools for pure information discovery gradually morphed into ecosystems dominated by SEO-optimized content and sponsored results. My initial fear with ChatGPT’s update was simple: Are we seeing the beginning of a similar shift? Is the purity of the “reasoning engine” being diluted by the necessity of commerce?
After testing the new shopping integration, the results suggest that we are at a pivotal moment in the user experience of Generative AI, one that requires an open discussion about what we actually want these tools to be.

The defining characteristic of Large Language Models (LLMs) is their ability to handle nuance. When we interact with ChatGPT, we expect a Socratic dialogue. We expect the AI to ask clarifying questions to narrow down our intent.
To test this, I entered a simple prompt: “I want to buy a vacuum.”
I anticipated a conversation, questions about my home’s square footage, my floor type, or my budget. Instead, the conversational nuance was replaced by a display that felt familiar: a grid of product photos, names, prices, and direct links to retailers.

While efficient, this experience felt like a regression. It mirrored the “keyword search” experience of Web 2.0 rather than the “intent-based” promise of GenAI. It replied to my prompt, but it stripped away the intelligence.

The latest rumblings from the EU tech scene, a story from our wise ol&#39; founder Boris, and some questionable AI art. It&#39;s free, every week, in your inbox. Sign up now!

Scrolling down, I engaged with the new feature in a call to action: “Research the best vacuums.”
This is where the user experience (UX) friction became most apparent. Rather than synthesizing data or comparing technical specifications in a chat format, the tool presented a polling interface designed to filter results.

The experience is oddly time-sensitive; pause too long to think or drink water, and the screens will skip forward, dumping you back into a list of product cards.
The interface presents products with a binary choice: “More like this” or “Not interested.” It offers brand names and price tags, but virtually no information to help the user actually make a choice.

For a user seeking genuine research, being presented with a list of brands and prices without deep comparative analysis feels like a missed opportunity.
It raises a question: If I wanted to filter products by price and brand, wouldn’t I use a traditional retailer? The value proposition of Gen AI should be synthesis, not just aggregation.

The Tension Between Reasoning and Revenue
This update highlights the inevitable tension facing major AI companies: the balance between user utility and business sustainability.
As OpenAI scales, the pressure to demonstrate revenue models to investors is natural. However, there is a risk in prioritizing transactional features before the core product, reasoning and logic, is fully matured. By introducing a shopping experience that feels closer to a “click-through” engine than a “knowledge” engine, the platform risks blurring its own identity.
Is ChatGPT a research partner that helps me think? Or is it a shopping assistant trying to speed me to checkout?

To be clear, I believe there is a place for shopping within AI. But the execution matters.
A truly Generative AI shopping experience shouldn’t just list products; it should understand the user. It should read between the lines of a prompt to understand that a user asking for a vacuum might actually be solving a problem about pet hair or allergies.

The current iteration feels like a beta test of a business model rather than an evolution of intelligence. As we move forward, the hope is that OpenAI will refine this tool to prioritize the “Chat” over the transaction. We don’t want it to be just another place to see ads. We need a better way to make decisions.

Viviane Mendes is a growth strategist and innovation leader with more than 20 years of experience driving technology-enabled transformation across global markets. She has led initiatives integrating AI-driven strategies, digital transformation, and scalable business innovation for companies such as PSINet, MP3.com, Match.com, UOL and Best Buy Canada, and founded Vitrinepix, one of the first print-on-demand e-commerce platform, later acquired by Spreadshirt. Committed to lifelong learning, Viviane is now focusing on applying emerging technologies to foster digital literacy, responsible AI adoption, and positive human impact.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        </div>

        <div id="reader-modal">
            <div id="close-btn" class="control-btn" onclick="closeModal()">X</div>
            
            <div id="scroll-controls">
                <button class="scroll-btn" onclick="scrollPage(-1)">&#9650;</button> <button class="scroll-btn" onclick="scrollPage(1)">&#9660;</button>  </div>

            <div id="modal-inner"></div>
        </div>

        <script>
            // 1. RANDOMIZE ORDER
            const list = document.getElementById('feed-list');
            const cards = Array.from(document.querySelectorAll('.card'));
            cards.sort(() => Math.random() - 0.5);
            cards.forEach(card => list.appendChild(card));

            // 2. DARK MODE
            const btn = document.getElementById('theme-toggle');
            btn.addEventListener('click', () => document.body.classList.toggle('dark-mode'));

            // 3. MODAL & SCROLL LOGIC
            const modal = document.getElementById('reader-modal');
            const modalInner = document.getElementById('modal-inner');

            function openModal(contentId) {
                const content = document.getElementById(contentId).innerHTML;
                modalInner.innerHTML = content;
                modal.style.display = 'block';
                document.body.style.overflow = 'hidden'; 
            }

            function closeModal() {
                modal.style.display = 'none';
                document.body.style.overflow = 'auto';
            }

            function scrollPage(direction) {
                // Scroll by 80% of the screen height to keep context
                const scrollAmount = window.innerHeight * 0.8;
                modal.scrollBy(0, direction * scrollAmount);
            }
        </script>
    </body>
    </html>
    