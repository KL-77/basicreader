
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>KL-77's Feed</title>
        <style>
            :root {
                --bg: #ffffff;
                --text: #000000;
                --border: #000000;
                --modal-bg: #ffffff;
                --dim: #666666;
            }
            
            body.dark-mode {
                --bg: #000000;
                --text: #ffffff;
                --border: #ffffff;
                --modal-bg: #000000;
                --dim: #aaaaaa;
            }

            body { 
                font-family: Georgia, serif; 
                background-color: var(--bg);
                color: var(--text);
                margin: 0;
                padding: 10px;
                font-size: 22px;
                line-height: 1.5;
            }

            header {
                display: flex;
                justify-content: space-between;
                align-items: center;
                border-bottom: 3px solid var(--text);
                padding-bottom: 15px;
                margin-bottom: 25px;
            }
            
            h1 { margin: 0; font-size: 1.2em; }

            button#theme-toggle {
                background: transparent;
                color: var(--text);
                border: 2px solid var(--text);
                padding: 10px;
                font-size: 18px;
                font-weight: bold;
                border-radius: 4px;
                cursor: pointer;
            }

            .card {
                border: 2px solid var(--text);
                margin-bottom: 25px;
                padding: 15px;
                cursor: pointer;
            }
            
            .source { font-size: 0.7em; font-weight: bold; text-transform: uppercase; color: var(--dim); }
            .title { font-size: 1.1em; font-weight: bold; margin: 8px 0; display:block; }
            .meta { font-size: 0.7em; color: var(--dim); }

            /* MODAL STYLING */
            #reader-modal {
                display: none;
                position: fixed;
                top: 0; left: 0;
                width: 100%; height: 100%;
                background-color: var(--modal-bg);
                z-index: 1000;
                overflow-y: scroll; /* Allow scrolling */
                scroll-behavior: auto; /* Instant scrolling for e-ink */
            }

            #modal-inner {
                padding: 25px;
                max-width: 800px;
                margin: 0 auto;
                padding-top: 80px; 
                padding-bottom: 150px; /* Huge padding so text clears the buttons */
            }

            /* Controls (Close + Scroll) */
            .control-btn {
                position: fixed;
                background: var(--bg);
                color: var(--text);
                border: 3px solid var(--text);
                border-radius: 8px;
                font-weight: bold;
                cursor: pointer;
                z-index: 1001;
                display: flex;
                align-items: center;
                justify-content: center;
            }

            #close-btn {
                top: 15px; right: 15px;
                width: 60px; height: 60px;
                font-size: 30px;
                line-height: 55px;
            }

            /* Scroll Buttons */
            #scroll-controls {
                position: fixed;
                bottom: 20px;
                right: 20px;
                display: flex;
                flex-direction: column;
                gap: 15px;
                z-index: 1002;
            }

            .scroll-btn {
                width: 60px;
                height: 60px;
                font-size: 24px;
                background: var(--bg);
                color: var(--text);
                border: 3px solid var(--text);
                border-radius: 8px;
                cursor: pointer;
            }

            #article-text { white-space: pre-wrap; font-size: 1.1em; }
            
            a.original-link {
                display: inline-block;
                margin-bottom: 30px; /* Space before text starts */
                padding: 10px;
                border: 1px solid var(--text);
                color: var(--text);
                text-decoration: none;
                font-weight: bold;
                font-size: 0.8em;
            }
        </style>
    </head>
    <body>

        <header>
            <h1>KL-77's Feed</h1>
            <button id="theme-toggle">Light/Dark</button>
        </header>

        <div id="feed-list">
    
        <div class="card" onclick="openModal('content-0')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">US consumers, business pay 90% of tariff costs, says Federal Reserve</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-0" style="display:none;">
            <h2>US consumers, business pay 90% of tariff costs, says Federal Reserve</h2>
            <p><strong>Ars Technica - All content | 2026-02-12</strong></p>
            <a class="original-link" href="https://arstechnica.com/tech-policy/2026/02/us-consumers-business-pay-90-of-tariff-costs-says-federal-reserve/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">US businesses and consumers paid nearly 90 percent of the cost of Donald Trump’s tariffs last year, according to new Federal Reserve research that undercuts the president’s claim that foreign companies would bear the burden.

The study by the New York Fed found that the majority of tariff costs were passed through to Americans in the first 11 months of 2025, although exporters shouldered an increasing amount as the year progressed.

“Our results show that the bulk of the tariff incidence continues to fall on US firms and consumers,” the study’s authors wrote in a blog post on Thursday.

“[They] continue to bear the bulk of the economic burden of the high tariffs imposed in 2025.”

The Trump administration has insisted that the sweeping tariffs imposed on trading partners during the president’s second term will be paid for by companies looking to export goods into the US.

“BILLIONS OF DOLLARS, LARGELY FROM COUNTRIES THAT HAVE TAKEN ADVANTAGE OF THE UNITED STATES FOR MANY YEARS, LAUGHING ALL THE WAY, WILL START FLOWING INTO THE USA,” Trump posted on Truth Social in August 2025, shortly before his so-called “reciprocal tariffs” took effect.

However, others in the administration, such as US Treasury secretary Scott Bessent, have acknowledged that US retailers, such as Walmart, have been affected by the decision to raise the levies to levels last seen in the opening decades of the 20th century.

Credit:
                                      Financial Times
                                  









          Credit:

          
          Financial Times

The New York Fed study suggested that in the first eight months of the year, 94 percent of the cost had been passed through. This fell slightly to 92 percent in the September to October period and 86 percent in November.

“The tariff pass-through into import prices has declined in the latter part of the year. That is, a larger share of the tariff incidence was borne by foreign exporters by the end of the year,” the authors wrote.

Other recent studies have made similar findings about the hit to Americans from tariffs. A report by Germany’s Kiel Institute last month found a tariff pass-through rate of 96 percent, while a January study by the National Bureau of Economic Research put the figure at 94 percent.

A paper last week from the non-partisan Tax Foundation think tank found that the tariffs amounted to an average tax increase on US households of $1,000 in 2025 and $1,300 in 2026.

However, the impact on inflation has been more muted than many economists had feared. The consumer price index fell from 3 percent in January 2025 to 2.7 percent in December. Economists expect it to drop again on Friday, when official figures for January 2026 are released.

Over the course of 2025, the average tariff rate on US imports rose from 2.6 percent to 13 percent, according to the New York Fed study.

© 2026 The Financial Times Ltd. All rights reserved Not to be redistributed, copied, or modified in any way.</div>
        </div>
        
        <div class="card" onclick="openModal('content-1')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">Party like it's 2001: Diablo II gets a new expansion, new playable class</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-1" style="display:none;">
            <h2>Party like it's 2001: Diablo II gets a new expansion, new playable class</h2>
            <p><strong>Ars Technica - All content | 2026-02-12</strong></p>
            <a class="original-link" href="https://arstechnica.com/gaming/2026/02/diablo-ii-gets-its-first-new-playable-class-in-over-25-years/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">It’s not every day that a classic PC game gets a new content expansion 25 years after its last major update. But that’s what happened last night, as Blizzard suddenly released new “Reign of the Warlock” DLC that adds a new class, new end-game challenges, and new inventory-management options to the classic Diablo II.

To be clear, the new DLC is technically not for the original 2000 release of Diablo II (which was still getting patches as of 2016) but for the game’s 2021 Resurrected remaster. Still, that remastered version has gameplay and animations that are extremely faithful to the original, making yesterday’s surprise update the kind of content drop that players have been waiting for since 2001’s “Lord of Destruction” expansion.

The “Reign of the Warlock” DLC lets you “command forbidden power” as a new class that “wields forbidden arts, bridles hellfire and shadow, and dominates demons,” according to the in-game class selection screen description. By way of backstory, Blizzard writes that most Warlocks “have the means to lead a lavish lifestyle but find the pursuit of luxury and ease stale. Instead, they leverage their elevated status in Sanctuary to hunt down lost knowledge that would enable them to continue the legacy of Horazon.”

The Warlock has a skill tree that has three distinct paths:

The Warlock class is also coming to more recent Diablo games, though players will have to wait a bit for those updates to hit. Diablo IV will get the new class via the previously announced “Lord of Hatred” expansion on April 28, with more details promised for a March 5 Developer Update livestream. Diablo Immortal will also add the Warlock as yet another free-to-play option in a June update.

In addition to the new class, the “Reign of the Warlock” DLC updates the game’s late-game rotating Terror Zones with new options that let you “terrorize” a specific Act. High-level players will also be able to collect statues from bosses that can be combined to summon “a new pinnacle test” in the form of a Colossal Ancient boss. And players on the highest “Hell” difficulty will now have to face down Heralds of Terror that “stalk you as prey.”

Blizzard is also introducing a few quality-of-life updates to make D2: Resurrected a little less annoying. A new loot filter helps you sort through drops for specific types of items more quickly, while the ability to stack items inside your Stash Tabs prevents the need to scroll through pages of identical gems.

Alongside the DLC announcement, Blizzard revealed the first Steam version of Diablo II Resurrected: an “Infernal Edition” that includes the new Reign of the Warlock DLC for $40. Existing Resurrected owners can also purchase the DLC on its own for $25 on Battle.net or Xbox.</div>
        </div>
        
        <div class="card" onclick="openModal('content-2')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">We let Chrome's Auto Browse agent surf the web for us—here's what happened</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-2" style="display:none;">
            <h2>We let Chrome's Auto Browse agent surf the web for us—here's what happened</h2>
            <p><strong>Ars Technica - All content | 2026-02-12</strong></p>
            <a class="original-link" href="https://arstechnica.com/google/2026/02/tested-how-chromes-auto-browse-agent-handles-common-web-tasks/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">We are now a few years into the AI revolution, and talk has shifted from who has the best chatbot to whose AI agent can do the most things on your behalf. Unfortunately, AI agents are still rough around the edges, so tasking them with anything important is not a great idea. OpenAI launched its Atlas agent late last year, which we found to be modestly useful, and now it’s Google’s turn.

Unlike the OpenAI agent, Google’s new Auto Browse agent has extraordinary reach because it’s part of Chrome, the world’s most popular browser by a wide margin. Google began rolling out Auto Browse (in preview) earlier this month to AI Pro and AI Ultra subscribers, allowing them to send the agent across the web to complete tasks.

I’ve taken Chrome’s agent for a spin to see whether you can trust it to handle tedious online work for you. For each test, I lay out the problem I need to solve, how I prompted the robot, and how well (or not) it handled the job.

The problem: I want to get a high score on 2,048 without playing it myself.

The prompt: Go to [website], and play the game until you run out of moves.

The results: Unfortunately, Auto Browse can’t use arrow keys. Google says they’re not necessary for productivity tasks. So I pointed the robot at a version of the game with on-screen controls. With access to those arrows, Auto Browse had no trouble playing the game, and it seemed to grasp the rules, which are listed on the page.

On a few occasions, Auto Browse appeared to ruminate on its next move for 20 to 30 seconds, and it took the prompt very literally. The robot stopped when it could not successfully merge any tiles (its interpretation of “out of moves”) even though there were still empty spaces on the board. A human player would have taken the hit and set up a merge in the next move, but the robot had to be prompted to continue, which it did. The task ran for about 20 minutes, during which the robot created a 128 tile and made 149 moves.

Evaluation: 8/10. The game performance is not quite as good as Atlas, but Auto Browse didn’t require as much coaxing, and I understand why it stopped when it did. While the lack of arrow keys seems like an odd omission, there probably aren’t many productivity tasks where they are necessary.

The problem: I want to turn the music from Minnesota Public Radio’s The Current into an on-demand YouTube Music playlist.

The prompt: Go to thecurrent.org and start the live stream. Listen for one hour and make note of each song that is played. Then, add those songs to a new YouTube Music playlist.

The results: Agents are expensive to run, so I was unsurprised that, like OpenAI’s agent mode, Auto Browse refuses to monitor a page for basically any length of time. Sometimes it will sit on the page for a minute or two, usually pretending that more time has passed before giving up.

Luckily, we can accomplish this with The Current’s playlist view, which lists previous songs. I tweaked the prompt to allow Auto Browse to just get the song names from that page for the last hour, which worked fine. It interpreted that as the current hour-long block of the page, though, which was not yet complete.

I thought I was doing Auto Browse a favor by using YouTube Music instead of Spotify, but it turns out that Auto Browse doesn’t understand YouTube’s design aesthetic. It failed to add any songs to the playlist because it couldn’t find the buttons. When I changed the prompt to use Spotify, Auto Browse got it done on the first try. This is as much an indictment of YouTube Music as it is Auto Browse.

Evaluation: 6/10. It seems like monitoring pages over time is just beyond the reach of current browser agents, but it’s shocking that Auto Browse couldn’t use Google’s own streaming music service to create a playlist. That said, the agent did complete the job immediately once I understood why it failed. It loses some points for making me adapt the prompt multiple times.

The problem: My personal email address is known, and PR people often use that instead of my work address. I need to make sure no one important is sending pitches there, so I want a list of recent PR emails, contact info, and company details from my Gmail.

The prompt: Look through all my Gmail from the last month. Collect all the information (name, email address, phone number, product, etc.) from PR emails and add them to a new Google Sheets spreadsheet.

The results: Interestingly, Google’s agent doesn’t have to use the Gmail web interface. It can collect this data in the background using a Gmail tool. However, this also means you won’t be able to automate email tasks for accounts with Google AI disabled (like a work account).

After running the Gmail tool, Auto Browse navigated to Google Drive and opened a new spreadsheet. However, it attempted to enter only two PR contacts on the sheet, and it entered the data incorrectly, overwriting fields and placing a date in an unlabeled column. If it had just searched for “PR” in Gmail, it would have found dozens of results. Google’s AI Overview search results in Gmail can cite PR emails correctly, so it’s possible for Google AI to collect this information. It’s unclear why Auto Browse did this so poorly.

Evaluation: 1/10. It’s unclear whether the Gmail tool or the agent’s inability to use a spreadsheet is the main problem since I can’t verify what the agent actually found in Gmail. It’s possible that both are to blame. Regardless, Auto Browse flopped hard here.

The problem: Ars Technica is still seeking justice for Tuvix, who was unjustly murdered by Captain Janeway in Star Trek: Voyager, season 2 episode 24.

The prompt: Go to the Fandom Wiki page for Tuvix. Edit the page to include a section discussing the view that Tuvix was murdered by Janeway.

The results: Auto Browse refused to do this, just like Atlas, saying, “The request to edit the Tuvix Fandom Wiki page with that specific text cannot be fulfilled. The proposed edit would be considered vandalism on a public wiki.”

Evaluation: N/A. I’m not holding this one against Auto Browser. In fact, it’s probably best if browser agents refuse to autonomously edit public wikis. I just had to do my due diligence.

The problem: We still want to tell people about the murder of Tuvix, so the agent should make a basic website to do that.

The prompt: Go to NeoCities and create a fan site for the Star Trek character Tuvix. Make sure it has lots of images and fun information about Tuvix and that it makes it clear that Tuvix was murdered by Captain Janeway.

The results: The agent navigated to Neocities, and it then asked me to create an account. I did that and handed the task back to the robot without issue. This is where things got dicey. Auto Browse was unable to access the hover menu to edit the index.html file, so it got stuck in a loop of opening the preview and then returning to the dashboard. Eventually, the robot screamed for help.

Neocities has a very simple interface, but generative AI is not necessarily consistent. Since Auto Browse aborted the task, I decided to rerun the prompt, and the results were better. This time, Auto Browse switched to the list view, which doesn’t have a hover menu, allowing it to open the editor. It then navigated to TrekCore to copy image URLs for use on the site—this is not courteous web design, but it did follow instructions. The images it chose, however, are from early in the episode and do not feature Tuvix. So partial credit there.

The resulting site is a bit light on information, but Auto Browse included text backgrounds and colors. It looks reasonably nice. You can see the site here.

Evaluation: 7/10. Our Tuvix fan page gets the job done. It features a few fun facts and argues (briefly) that Janeway is a murderer. It’s great that the robot sought out images, though they don’t show the character in question. It loses a couple of points for the initial hover menu failure and the lack of detail—I did say “lots” of images and fun information.

The problem: Texas has an “insane” power system that forces people like Ars Senior Editor Lee Hutchinson to regularly find a new plan.

The prompt: Go to powertochoose.org and find me a 12–24 month contract that prioritizes an overall low usage rate. I use an average of 2,000 KWh per month. My power delivery company is Texas New-Mexico Power (“TNMP”), not CenterPoint. My ZIP code is [redacted]. Please provide the “fact sheet” for any and all plans you recommend.

The results: Auto Browse successfully entered the parameters into the website’s search and filter sections. It sorted the results, and in just a couple of minutes, it returned a fact sheet for its recommended power plan. It’s very similar to the suggestion from OpenAI’s agent a few months ago, except the contract term is a bit longer, and it has a lower daytime rate.

Evaluation: 10/10. There’s nothing to complain about here. The plan is perfectly fine, given the constraints, and Auto Browse was able to use the site’s drop-down menus and filters with very little experimentation. I didn’t have to change the prompt or nudge the robot to continue.

The problem: I don’t want to look through a giant list of discounted games in the PlayStation Store. Can’t someone do it for me?

The prompt: Go to the PlayStation Store and check the New Year Deals. Change the sorting to best-selling and the type to full games. Check the first two pages for any PS5 games that are at least 50 percent off and add them to my wishlist. If a game is included in PlayStation Plus, just add it to my library.

The results: The agent found the sale page and successfully changed the display settings. It even closed that unlabeled menu when it was done. It went down the list, opening pages when it found a matching game. It also asked every time before adding a game to the wishlist or library, which it claimed was a security requirement.

The process took about 15 minutes, with plenty of long pauses between for confirmation requests. It did correctly interpret the sale prices and PlayStation Plus availability. Unfortunately, it did not differentiate between PS5 and PS4 titles, and the agent stopped a few lines short of the bottom of page 2.

Evaluation: 7/10. Auto Browse ran this task pretty well, all things considered. It stopped a little early and missed the PS5 angle, though. The requirement to confirm each wishlist or library addition was annoying, and as such, it would be a stretch to call this “auto” anything.

Across these six tests (excluding the wiki editing I didn’t expect to work), Google’s browser agent got a median score of 7 and an average of 6.5. While this is not meant to be an objective analysis, it shows that Auto Browse has a way to go before it can be trusted to get things done for you.

Like the OpenAI Atlas agent, Auto Browse is not capable of truly autonomous operation, and I gave it plenty of advantages. Auto Browse works with all three of Google’s current model settings—Fast, Thinking, and Pro. I left it set to Pro and used Google tools where appropriate. Despite that, Auto Browse needed nudging or re-prompting in almost every test. This stuff won’t be useful until it can actually operate as an agent on your behalf. Right now, it’s more like babysitting an easily distracted robot.

Many of the lost points come from Auto Browse being unable to use Google’s own products—it didn’t find the right emails in Gmail, couldn’t enter data in Google Sheets, and failed to understand YouTube Music’s interface (we feel you on that one, Auto Browse). The apparent inability of browser agents to monitor pages over time is also an issue. If a task involves more than a few minutes of waiting, it will probably fail or abort early.

This feature is still in preview, but it’s widely available to anyone paying for Google’s AI. The company also seems to suggest it will roll out to non-paying users in the future. It can be neat to watch the browser navigate the web for you, but that’s the thing—you have to watch it. Too often, you have to re-prompt or tell the AI to continue with a task. Auto Browse can’t be trusted to get things right without supervision, at least not yet.</div>
        </div>
        
        <div class="card" onclick="openModal('content-3')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">SpaceX takes down Dragon crew arm, giving Starship a leg up in Florida</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-3" style="display:none;">
            <h2>SpaceX takes down Dragon crew arm, giving Starship a leg up in Florida</h2>
            <p><strong>Ars Technica - All content | 2026-02-12</strong></p>
            <a class="original-link" href="https://arstechnica.com/space/2026/02/heres-why-americas-most-historic-launch-pad-is-getting-yet-another-facelift/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Launch Complex 39A at NASA’s Kennedy Space Center in Florida is accustomed to getting makeovers. It got another one Wednesday with the removal of the Crew Access Arm used by astronauts to board their rides to space.

Construction workers first carved the footprint for the launch pad from the Florida wetlands more than 60 years ago. NASA used the site to launch Saturn V rockets dispatching astronauts to the Moon, then converted the pad for the Space Shuttle program. The last shuttle flight lifted off from Pad 39A in 2011, and the agency leased the site to SpaceX for use as the departure point for the company’s Falcon 9 and Falcon Heavy rockets.

SpaceX started launching from Pad 39A in 2017, then installed a new Crew Access Arm on the pad’s tower the following year, replacing the aging shuttle-era arm that connected to the hatches of NASA’s orbiters. SpaceX added the new arm ahead of the first test flight of the company’s human-rated Crew Dragon spacecraft in 2019. Astronauts started using the pathway, suspended more than 200 feet above the pad surface, beginning with the first crew flight on a Dragon spacecraft in 2020.

Now, Pad 39A is undergoing another facelift in preparation for launches of SpaceX’s powerful Starship rocket. Construction of a new launch tower for Starship is well along about 1,000 feet east of the existing tower at Pad 39A, still inside the facility’s circular perimeter. SpaceX aims to launch the first Starship flight from Kennedy Space Center later this year, following a series of flights from the company’s Starbase test site in South Texas.

With the arrival of Starship, SpaceX is suspending Falcon 9 flights from Pad 39A in favor of launches from nearby Pad 40, located a few miles to the south at Cape Canaveral Space Force Station, on property leased from the US Space Force. Kiko Dontchev, SpaceX’s vice president of launch, wrote on X in December that the decision will allow teams to “put full focus on Falcon Heavy launches and ramping Starship from the Cape.”

SpaceX’s Falcon Heavy, primarily used to launch payloads for the Space Force and NASA, will continue flying from Pad 39A, the only site currently outfitted to accommodate the triple-core rocket. The next Falcon Heavy launch is scheduled for no earlier than April, with no more than a handful of flights per year planned for the rest of the 2020s.

Ground teams installed a Crew Access Arm at Pad 40 ahead of the first crew launch there in 2024. All future Crew Dragon flights will now depart from Pad 40 for the foreseeable future, beginning with the launch of the Crew-12 mission to the International Space Station later this week.

“It’s great to have two launch pads off the Florida coast. For our manifest going forward, we’re planning to launch most of our Falcon 9 launches off of Space Launch Complex 40. That will include all Dragon missions going forward,” said Lee Echerd, a SpaceX senior mission manager for human spaceflight. “That will allow our Cape team to focus at 39A on Falcon Heavy launches and hopefully our first Starship launches later this year.”

Pad 40 has been the primary Falcon 9 launch site for most of the rocket’s history, while Pad 39A provided a location for crew launches and an augmentation to support SpaceX’s growing launch cadence. But there are signs the Falcon 9 launch cadence, which reached 165 missions last year, may be peaking as the company turns its attention to Starship. And SpaceX has steadily reduced the time it takes to reconfigure Pad 40 between launches, cutting the turnaround time to less than 48 hours.

If needed, SpaceX officials said they could reinstall the crew arm for Dragon missions launching from Pad 39A.

Bill Gerstenmaier, SpaceX’s vice president of build and flight reliability, said there’s another pressing reason for removing the crew arm at Pad 39A. The bearings that connect the arm to the launch pad’s tower need repairs.

“To physically get access to those, the arm needs to be removed,” Gerstenmaier said. “Those bearings have to come out and they have to be reinstalled. We’ll do that work at the Kennedy Space Center. And the intent there is, we don’t need to put the arm back up … When we get a call-up for a mission and we have to go fly a mission, if it requires that, we have plenty of time to get the arm back up.”

SpaceX has continued launching Falcon 9 and Falcon Heavy rockets from Pad 39A amid the nearby construction work to prepare for Starship flights. “That doesn’t impact our ability to launch from the pad,” Gerstenmaier said.

That could change as SpaceX begins testing and launching Starships from Kennedy Space Center. Starship launch operations may routinely force the closure of Pad 39A to personnel.

“The right thing to do is get those bearings replaced in the environment on the ground, make some upgrades to them, and then we’ll be ready to go and put the arm back up when it’s time to go fly, if we need to go fly,” Gerstenmaier said.</div>
        </div>
        
        <div class="card" onclick="openModal('content-4')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">Trump orders the military to make agreements with coal power plants</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-4" style="display:none;">
            <h2>Trump orders the military to make agreements with coal power plants</h2>
            <p><strong>Ars Technica - All content | 2026-02-12</strong></p>
            <a class="original-link" href="https://arstechnica.com/science/2026/02/trumps-latest-plan-to-revive-coal-power-make-the-military-buy-it/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">On Wednesday, a fossil-fuel lobbying group called the Washington Coal Club awarded President Trump a trophy that named him the “Undisputed Champion of Clean, Beautiful Coal.” Trump took advantage of the opportunity to take his latest shot at reviving the fortunes of the US’s most polluting source of electricity: an executive order that would make the military buy it.

Coal is the second most expensive source of power for the US grid, eclipsed by gas, wind, solar, hydro—everything other than nuclear power. It also produces the most pollution, including particulates that damage human lungs, chemicals that contribute to acid rain, and coal ash that contains many toxic metals. It also emits the most carbon dioxide per unit of energy produced. Prior to Trump’s return to office, the US grid had been rapidly moving away from its use, including during his first term.

Despite the long-standing Republican claims to support free markets, the second Trump administration has determined that the only way to keep coal viable is direct government intervention. Its initial attempts involved declaring an energy emergency and then using that to justify forcing coal plants slated for closure to continue operations. The emergency declaration relied on what appears to be a tenuous interpretation of the Federal Power Act, and the administration was already facing a lawsuit challenging these actions.

Today’s executive order takes a different route to propping up coal: artificially inflating demand. “The Secretary of War, in coordination with the Secretary of Energy,” the order reads, “shall seek to procure power from the United States coal generation fleet by approving long-term Power Purchase Agreements, or entering into any similar contractual agreements, with coal-fired energy production facilities to serve Department of War installations or other mission-critical facilities.”

The justification for this seems to come from an alternate reality with little relationship to the US grid. “It’s going to be less expensive and actually much more effective than what we have been using for many, many years,” Trump said at the event. “And again, with the environmental progress that’s been made on coal, it’s going to be just as clean.” None of that is true.

The executive order instead seeks to highlight coal’s supposed ability to produce a constant power output, touting the “proven reliability of our coal-fired generation fleet in providing continuous, on-demand baseload power.” This seemingly ignores Texas’ recent experience, in which coal plants contributed significantly to the collapse of the state grid, having gone offline for a wide range of reasons.

The Trump administration, however, has rarely let spurious justifications stand in the way of its preferred policy actions. The key action here is likely to be locking the military into long-term contracts that would persist beyond the end of Trump’s term in 2029.</div>
        </div>
        
        <div class="card" onclick="openModal('content-5')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">El Paso airport closed after military used new anti-drone laser to zap party balloon</div>
            <div class="meta">2026-02-11</div>
        </div>
        
        <div id="content-5" style="display:none;">
            <h2>El Paso airport closed after military used new anti-drone laser to zap party balloon</h2>
            <p><strong>Ars Technica - All content | 2026-02-11</strong></p>
            <a class="original-link" href="https://arstechnica.com/space/2026/02/el-paso-airport-closed-after-military-used-new-anti-drone-laser-to-zap-party-balloon/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">On Tuesday night, the Federal Aviation Administration closed airspace up to 18,000 feet above the El Paso International Airport in Texas, saying the restrictions would be in place for 10 days. Then, less than 10 hours later, the federal agency reopened the airspace, allowing planes to land and take off at the busy airport.

About an hour after lifting the restrictions, US Secretary of Transportation Sean Duffy, whose responsibilities include overseeing the FAA, explained the unexpected closure by saying, “The FAA and DOW acted swiftly to address a cartel drone incursion.” (The Trump Administration refers to the Department of Defense as the Department of War, or DOW, although its legal name remains the former.)

Not everyone agrees with Duffy’s account.

Based upon reporting from The New York Times and other publications, the military has been developing high-energy lasers to bring down drones. The FAA and US military officials had been discussing tests of the new weapon from the nearby Fort Bliss Army base. However, the FAA had not resolved all of its concerns about airplane safety from the tests.

Despite these apparently lingering concerns from the FAA, the military went ahead with a test earlier this week against what was thought to be a drone. The object was a party balloon.

That is not to make light of drone incursions. This is a real issue along the US border with Mexico, where cartels increasingly fly drones for surveillance. They are particularly useful for pinpointing the location of US Border Patrol agents to assist the cartel in smuggling non-citizens across the border into the United States.

One of the many lessons from the war in Ukraine, which has rapidly pushed forward drone technology in contested environments, is that it is not practical to shoot down drones with conventional missiles. So it is understandable that the US military is looking at alternatives. This all culminated in some sort of snafu between the FAA and military officials regarding coordination with this week’s test.

Whether it was genuine concern about air travelers, a show of force, a fit of pique, or something else, the FAA decided on Tuesday evening to take the extraordinary step of abruptly closing an airport that serves more than 3 million passengers a month. The proposed 10-day closure of the airport was remarkably long.

Moreover, this action was taken without consulting local or state officials in Texas—who are understandably outraged—or reportedly even the White House.

“I want to be very, very clear that this should’ve never happened,” El Paso Mayor Renard Johnson said during a news conference on Wednesday. “That failure to communicate is unacceptable.”</div>
        </div>
        
        <div class="card" onclick="openModal('content-6')">
            <div class="source">Futurism</div>
            <div class="title">Economist Warns That the Poor Will Bear the Brunt of AI’s Effects on the Job Market</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-6" style="display:none;">
            <h2>Economist Warns That the Poor Will Bear the Brunt of AI’s Effects on the Job Market</h2>
            <p><strong>Futurism | 2026-02-12</strong></p>
            <a class="original-link" href="https://futurism.com/artificial-intelligence/robert-reich-jobs-ai">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">While tech executives wax poetic about AI ushering in four-day workweeks and liberation from labor, economics guru Robert Reich is cutting through the drivel. In an ominous new essay, the former secretary of labor warns that those shortened weeks will also come with much shorter paychecks — leaving the working class scrambling for crumbs in order to survive.

The US economy is growing nicely, Reich notes, while the stock market is doing gangbusters. But as for the stuff that really counts for most Americans? It’s “sh*tty,” the plainspoken wonk asserts. And as AI continues to rankle the job market, Reich says the poor and working class will increasingly bear the brunt.

To set up his argument, Reich briefly considers comments from business tycoons like Zoom’s Eric Yuan and JPMorgan Chase’s Jamie Dimon, who argue that four- and even three-day work weeks will become the norm thanks to new automation tools.

“All of this is pure rubbish,” Reich writes. “Here’s the truth: The four-day workweek will most likely come with four days’ worth of pay. The three-day workweek, with three days’ worth. And so on.”

As evidence, he references the productivity-pay gap, the measure of a society’s economic output compared to its wage growth. In the United States, productivity keeps going up — but the share of that productivity going to workers hasn’t really budged since the 1970s. Workers, in other words, have been getting shafted by their bosses for decades, and there’s no reason to think AI will change that.

“So, as AI takes over their current work, most workers will probably get poorer or have to take additional jobs to maintain their current pay,” Reich posits.

Indeed, we don’t need to wait for AI to take over to see this play out: full-time job growth in 2025 was almost nonexistent, while the number of people turning to gig work continues to rise amidst widespread layoffs and wage declines among low-wage workers.

“Rather than creating an age of abundance in which most people no longer have to worry about money,” Reich continues, “new technologies have contributed to a two-tiered society comprising a relatively few with extraordinary wealth and a vast number of people barely making it.”

At the end of the day, the economist says, “it comes down to who has the power.”

More on AI: Fear Grows That AI Is Permanently Eliminating Jobs</div>
        </div>
        
        <div class="card" onclick="openModal('content-7')">
            <div class="source">Futurism</div>
            <div class="title">Cofounders Fleeing Elon Musk’s xAI</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-7" style="display:none;">
            <h2>Cofounders Fleeing Elon Musk’s xAI</h2>
            <p><strong>Futurism | 2026-02-12</strong></p>
            <a class="original-link" href="https://futurism.com/artificial-intelligence/cofounders-fleeing-elon-musk-xai">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">On paper, Elon Musk’s xAI is gearing up for a big year. After being folded into Musk’s SpaceX, the Grok maker could now be involved in one of the biggest — if not the biggest — IPO in history later this year.

Despite plenty of optimism and an enormous wealth of unlocked funding, a striking number of the company’s cofounders are now jumping ship. As CNBC reports, the company lost two of its cofounders in just two days, only the latest in a growing list of executives looking for greener pastures.

“Grateful to have helped cofound at the start,” AI researcher Jimmy Ba tweeted. “And enormous thanks to Elon Musk for bringing us together on this incredible journey.”

Fellow cofounder and University of Toronto professor Tony Wu, who worked on the latest generation of Grok chatbots, exited a day earlier, posting that “it’s time for my next chapter” on Tuesday.

They join a growing list of departed cofounders since the company kicked off in 2023. Igor Babuschkin left the company in August of last year, followed by Kyle Kosic and Christian Szegedy. Greg Yang, who has been battling Lyme disease, has also decided to step back from his role to focus on his health.

As TechCrunch points out, exactly half of xAI’s founding team of 12 individuals have now resigned following Ba’s departure earlier this week.

Following the news, Musk announced that he was reorganizing xAI, which could explain at least some of the recent departures.

“As a company grows, especially as quickly as xAI, the structure must evolve just like any living organism,” Musk tweeted. “This unfortunately required parting ways with some people. We wish them well in future endeavors.”

It remains unclear who was caught up in the firings or whether the cofounders left on their own accord.

Musk said that xAI will be split up into four core areas, including Grok, “Coding,” a text-to-video product dubbed “Imagine,” and “Macrohard,” an AI agent effort with a tongue-in-cheek name aimed at competitor Microsoft.

“What matters is velocity and acceleration,” he said in a video posted to X. “If you are moving faster, you will be the leader.”

It’s a striking moment for a major exodus as the company gears up for its blockbuster IPO. X has been battling with a major crisis as deepfake pornography and child sexual abuse material (CSAM) continue to flood the platform, often created by Grok. xAI is caught up in several criminal investigations, and its Grok chatbot has been banned in several countries as a result.

Meanwhile, a bipartisan group of US lawmakers is ratcheting up pressure, calling on the company to take action to protect the public in an open letter last month.

What the company will look like after its recent merger with SpaceX remains to be seen. Beyond refocusing the company to double down on text-to-video tools and AI agents, Musk has been turning his attention to launching date centers in space, a confluence that could help explain the unusual acquisition.

With or without an edge when it comes to access to space, xAI has its work cut out to keep up. The competition is as steep as ever, and users continue to have access to several powerful AI models that aren’t tainted by CSAM scandals.

After parting ways with xAI’s cofounders, Musk is looking to grow the company.

“We are hiring aggressively,” he tweeted today. “Join xAI if the idea of mass drivers on the Moon appeals to you.”

More on xAI: SpaceX Just Bought Elon Musk’s CSAM Company</div>
        </div>
        
        <div class="card" onclick="openModal('content-8')">
            <div class="source">Futurism</div>
            <div class="title">The Scientist Who Predicted AI Psychosis Has a Grim Forecast of What’s Going to Happen Next</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-8" style="display:none;">
            <h2>The Scientist Who Predicted AI Psychosis Has a Grim Forecast of What’s Going to Happen Next</h2>
            <p><strong>Futurism | 2026-02-12</strong></p>
            <a class="original-link" href="https://futurism.com/health-medicine/ai-debt-scientist-psychosis">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">When the Danish psychiatrist Søren Dinesen Østergaard published his ominous warning about AI’s effects on mental health back in 2023, the tech giants fervently building AI chatbots didn’t listen.

Since that time, numerous people have lost their lives after being drawn into suicide or killed by lethal drugs after obsessive interactions with AI chatbots. More still have fallen down dangerous mental health rabbit holes brought on by intense fixations on AI models like ChatGPT.

Now, Østergaard is out with a new warning: that the world’s intellectual heavyweights are accruing a “cognitive debt” when they use AI.

In a new letter to the editor published in the journal Acta Psychiatrica Scandinavica and flagged by PsyPost, Østergaard asserts that AI is eroding the writing and research abilities of scientists who use it.

“Although some people are naturally gifted, scientific reasoning (and reasoning in general) is not an inborn ability, but is learned through upbringing, education and by practicing,” Østergaard explained. Though AI’s ability to automate a wide variety of scholarly tasks is “fascinating indeed,” it’s not without “negative consequences for the user,” the scientist explains.

As an example of the kinds of long-term consequences he’s worried about, the scholar cites the AI researchers Demis Hassabis and John Jumper, who won the 2024 Nobel Prize in chemistry when they “most impressively demonstrated” the potential for AI to assist in scientific discovery. Using AlphaFold2, an AI system developed by Google DeepMind, Hassabis and Jumper were able to accurately predict the three-dimensional structures of virtually all known proteins — a major scientific achievement.

Still, as Østergaard writes, their breakthrough didn’t emerge out of thin air — it was built on a foundation of intense scientific training developed over a lifetime of scholarship.

“I would argue that it is not a given that even the likes of Hassabis and Jumper would have reached the Nobel Prize level, had the tools developed by the generative AI revolution they themselves contribute to been around from the beginning of their career — or when they began primary school,” Østergaard wrote. “The reason being that they may simply not have gotten to practice reasoning enough with the availability of these tools.”

“If the use of AI chatbots does indeed cause cognitive debt, we are likely in dire straights,” Østergaard continued.

His ominous contention is backed by other scholars like University of Monterrey neuroscientist Umberto León Domínguez, who’s argued that careless use of AI can replace mental muscles that students and scholars in previous generations would have had to flex. Other researchers concur that cognitive offloading is a risk of AI use.

In the long run, “my guess is that this will reduce the chances of the likes of Demis Hassabis and John Jumper emerging from future generations,” Østergaard warned.

More on AI psychosis: Man Wakes Up Homeless, Realizes He Fell Into AI Psychosis That Destroyed His Entire Life</div>
        </div>
        
        <div class="card" onclick="openModal('content-9')">
            <div class="source">Futurism</div>
            <div class="title">You Are Not Prepared for What Actually Shut Down the El Paso Airport This Morning, But Let’s Just Say It Involves a Military Mega-Laser Shooting Something Down</div>
            <div class="meta">2026-02-11</div>
        </div>
        
        <div id="content-9" style="display:none;">
            <h2>You Are Not Prepared for What Actually Shut Down the El Paso Airport This Morning, But Let’s Just Say It Involves a Military Mega-Laser Shooting Something Down</h2>
            <p><strong>Futurism | 2026-02-11</strong></p>
            <a class="original-link" href="https://futurism.com/science-energy/airport-laser-pentagon-trump">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">When the Federal Aviation Administration announced it was shutting down El Paso Airport this morning, social media lit up with speculation.

Had freedom-hating terrorists planted anti-aircraft weapons in the desert? Was the government covering up an early-stage zombie apocalypse with El Paso as ground zero? Or had the Trump administration perhaps started firing high-energy laser weapons into the sky without bothering to tell anyone?

The answer, impossibly, seems to be door number three.

According to CBS News, the bizarre airspace closure came under orders from FAA administrator Bryan Bedford. Apparently, Bedford made the call after learning that the Pentagon planned to unleash high-energy, counter-drone laser weapons at Fort Bliss, situated right next to El Paso International Airport.

But wait, there’s more. Separately, Fox News reported that military personnel had shot down a rogue party balloon — like you’d see at a child’s birthday party — near El Paso, after misidentifying it as a foreign drone. Whether this was done using the Pentagon’s mega-laser is unclear at the moment, but it’d be a wild coincidence if this wasn’t the case.

The airspace closure occurred without alerting White House, Pentagon or Homeland Security officials, sources told CBS. Originally, the closure was said to last 10 days, citing “special security reasons.” The FAA’s original notice warned that the “government may use deadly force” against planes if officials decided “the aircraft poses an imminent security threat.”

In Bedford’s defense, CNN reports the military laser weapon deployment came nine days before a February 20th meeting to review the system’s potential impacts on commercial aviation.

Again, it isn’t clear if the Pentagon went ahead and deployed the laser system before officials could meet. That said, CNN‘s sources said the Defense Department was seeking to use the system in El Paso before such a sit-down could take place.

Further muddying the waters are the Trump administration’s claims that the Pentagon had taken action to disable a vague “cartel drone incursion” right before the airspace shutdown. (We have yet to see any evidence that that’s the case.)

So to recap: the FAA and the Pentagon appear to be in such poor communication that experimental weaponry by the latter is shutting down civilian flights by the former — and party balloons are caught in the crossfire. Welcome to 2026.

More on Trump: There’s Not Enough Money in the World for Trump’s Golden Dome</div>
        </div>
        
        <div class="card" onclick="openModal('content-10')">
            <div class="source">Futurism</div>
            <div class="title">It Seems Almost Statistically Impossible That This Polymarket Bettor Didn’t Profit Off Inside Knowledge About the Super Bowl Half Time Show</div>
            <div class="meta">2026-02-11</div>
        </div>
        
        <div id="content-10" style="display:none;">
            <h2>It Seems Almost Statistically Impossible That This Polymarket Bettor Didn’t Profit Off Inside Knowledge About the Super Bowl Half Time Show</h2>
            <p><strong>Futurism | 2026-02-11</strong></p>
            <a class="original-link" href="https://futurism.com/future-society/polymarket-half-time-show">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Earlier this year, an anonymous bettor on Polymarket perfectly predicted the US invasion of Venezuela mere hours before over 150 US aircraft rocked the country’s capital of Caracas, netting them over $400,000.

The incident reignited a heated debate over insider trading on prediction market platforms like Polymarket and Kalshi. While the act is strictly forbidden on Wall Street, prediction markets are currently operating in a regulatory vacuum, allowing those who enjoy insider status to score big — while everyone else is left to pick up the bill.

And the evidence that prediction markets are rife with insider traders continues to grow. As one eagle-eyed Reddit user noticed, an anonymous day-old Polymarket account correctly guessed 17 out of around 20 bets about Sunday’s Super Bowl half-time show.

Statistically speaking, that’s an exceedingly unlikely success rate, strongly suggesting the account had some kind of insider knowledge of what would happen during Puerto Rican superstar Bad Bunny’s performance.

The account correctly predicted that popstars Lady Gaga, Cardi B, and Ricky Martin would perform at the show. The account also correctly predicted that rappers Travis Scott and Drake, as well as singer Post Malone, would not perform.

The anonymous user placed bets starting February 6, two days before the event took place. All told, they made about $17,000 in profit.

“If you bet, you’re a rube for these people,” one Reddit user commented. “Literally spending money to give it over to insiders and cheats.”

Polymarket has yet to publicly comment on the matter and didn’t respond to the Wall Street Journal‘s request for comment.

Ironically, gambling was a major focus during Sunday’s sporting event. Companies spent untold sums to air commercials for betting services like DraftKings.

Trading volumes on prediction markets hit record highs during the Super Bowl, with Kalshi reporting over half a billion dollars in trading tied to the final outcome of the game. Polymarket’s equivalent bet saw trading volumes hit over $55 million.

Given ongoing regulatory uncertainty, it remains to be seen whether the two platforms will be able to meaningfully address insider trading, a subject that demonstrably continues to be a major problem.

While a knowledgeable few, including professional gamblers, get away with major profits, plenty of other users are incurring significant losses. As Business Insider points out, for each “winner” on the platform, there’s a “loser” as well, since users are betting against each other — not against a house, like in a traditional casino.

The latter will need to remain confident that the setup isn’t rigged against them for the ruse to work.

“Those other people are going to, on average, make losses if they know less about the subject matter than the experts,” professor of economics and prediction markets expert Eric Zitzewitz told BI. “So you need them to be willing to trade despite that.”

“You need them to be overconfident about how much they know, or you need them to be participating for some other reason,” he added.

Prediction market regulations could take years before they materialize — if ever. The White House has made it clear it supports the industry, with president Donald Trump’s Trump Media and Technology Group announcing in October that it would enter the prediction markets business.

In the meantime, lawmakers are desperately warning that gambling on the platforms comes with some inherent risks.

“New Yorkers need to know the significant risks with unregulated prediction markets,” New York Attorney General Letitia James warned in a statement six days ahead of the Super Bowl. “It’s crystal clear: so-called prediction markets do not have the same consumer protections as regulated platforms. I urge all New Yorkers to be cautious of these platforms to protect their money.”

More on prediction markets: Professional Gamblers Move Into Prediction Markets to Bleed You Dry</div>
        </div>
        
        <div class="card" onclick="openModal('content-11')">
            <div class="source">Futurism</div>
            <div class="title">Ring Boasts About Power to Surveil Entire Neighborhoods</div>
            <div class="meta">2026-02-11</div>
        </div>
        
        <div id="content-11" style="display:none;">
            <h2>Ring Boasts About Power to Surveil Entire Neighborhoods</h2>
            <p><strong>Futurism | 2026-02-11</strong></p>
            <a class="original-link" href="https://futurism.com/future-society/ring-doorbell-surveillance-dog">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">When Ring’s latest commercial came on over a Super Bowl ad break, it offered a service that seems like a no-brainer. Called “Search Party,” it’s a new function that lets Ring devices help canvas the neighborhood through its vast network of cameras to find lost pets.

“One post of a dog’s photo in the Ring app starts outdoor cameras looking for a match to help families find lost dogs,” the company’s Super Bowl ad enthuses.

Yet beneath all that is a startling revelation: that Ring doorbells can now surveil living beings throughout every neighborhood the devices might be found.

For those unfamiliar, Ring is Amazon’s doorbell camera company — those ubiquitous gadgets mounted on front porches that record everyone who walks by.

The devices have been the target of widespread privacy criticisms for years at this point. However, their latest data sharing agreement with surveillance company Flock has many activists up in arms, as that startup has no qualms with working closely with federal agencies like Immigration and Customs Enforcement.

With those kind of optics swirling around, the decision to highlight new dog-finding capabilities is a clever PR move for Ring. Who would say no to reuniting lost puppies with their families?

At the same time, the new Search Party function represents a troubling development. Where the company’s Fire Watch system is said to index neighborhood devices to watch for signs of fire emergencies, the Search Party function means the company is capable of tracking living things as well. Who decides when and how to deploy that power is another story — but it’s obvious that Ring has opened Pandora’s box.

As MS Now columnist Hayes Brown observed: “there’s no world in which finding lost dogs is the final end-use for this technology.”

“Ring’s Search Party feature does what neighbors have done for generations — help reunite lost dogs with their families — just with better technology,” a Ring spokesperson told us in a statement. “We built the feature with strong privacy protections from the start and camera owners choose on a case-by-case basis whether they want to share videos with a pet owner to support a reunion. Since launch, Search Party has helped bring home more than a dog a day.”

More on surveillance: AI Surveillance Systems Are Causing a Staggering Number of Wrongful Arrests</div>
        </div>
        
        <div class="card" onclick="openModal('content-12')">
            <div class="source">TechCrunch</div>
            <div class="title">Apple acquires all rights to ‘Severance,’ will produce future seasons in-house</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-12" style="display:none;">
            <h2>Apple acquires all rights to ‘Severance,’ will produce future seasons in-house</h2>
            <p><strong>TechCrunch | 2026-02-12</strong></p>
            <a class="original-link" href="https://techcrunch.com/2026/02/12/apple-acquires-all-rights-to-severance-will-produce-future-seasons-in-house/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Apple has acquired the IP and all rights to its hit show “Severance” from its original studio, Fifth Season, as first reported by Deadline. Under the deal, which was worth just under $70 million, Apple’s in-house studio will be producing the show’s future seasons. Fifth Season will remain as an executive producer.

The deal is similar to one Apple struck with AMC Studios for sci-fi show “Silo” after season one.

“Severance” will now be one of Apple’s marquee titles, joining popular series such as “Your Friends and Neighbors” and “Stick.”

According to Deadline, the production costs for “Severance” had exceeded what Fifth Season could afford. The studio had already requested advances from Apple and was considering relocating production from New York to Canada for bigger and quicker tax rebates. Since Apple definitely has the funds to back the show, the company decided to take full control.

“Severance” is important to the streamer, as the show’s second season became Apple’s most-watched series at the time. It also had the highest number of nominations at the 2025 Emmy Awards.

Deadline reports that the show is expected to run for four seasons, with the possibility of spin-offs, a prequel, and foreign versions.

Tickets are live at the lowest rates of the year. Save up to $680 on your pass now.Meet investors. Discover your next portfolio company. Hear from 250+ tech leaders, dive into 200+ sessions, and explore 300+ startups building what’s next. Don’t miss these one-time savings.

Subscribe for the industry’s biggest tech news

Every weekday and Sunday, you can get the best of TechCrunch’s coverage.

TechCrunch Mobility is your destination for transportation news and insight.

Startups are the core of TechCrunch, so get our best coverage delivered weekly.

Provides movers and shakers with the info they need to start their day.

By submitting your email, you agree to our Terms and Privacy Notice.</div>
        </div>
        
        <div class="card" onclick="openModal('content-13')">
            <div class="source">TechCrunch</div>
            <div class="title">US FTC airs concerns over allegations that Apple News suppresses right-wing content</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-13" style="display:none;">
            <h2>US FTC airs concerns over allegations that Apple News suppresses right-wing content</h2>
            <p><strong>TechCrunch | 2026-02-12</strong></p>
            <a class="original-link" href="https://techcrunch.com/2026/02/12/us-ftc-airs-concerns-over-allegations-that-apple-suppresses-right-wing-content-on-apple-news/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The U.S. Federal Trade Commission (FTC) has raised concerns over allegations that Apple is censoring conservative content on the Apple News app.

In a letter to Apple CEO Tim Cook, FTC chair Andrew Ferguson cited reports from Media Research Center, a right-leaning think tank, which accused Apple of excluding right-leaning outlets from the top 20 articles in the Apple News feed.

“These reports raise serious questions about whether Apple News is acting in accordance with its terms of service and its representations to consumers […] I abhor and condemn any attempt to censor content for ideological reasons,” Ferguson’s letter reads.

Ferguson, a Big Tech critic who Trump appointed to lead the competition regulator, noted the FTC doesn’t have any powers to require Apple to take ideological or political positions when curating news, but he said that if the company’s practices are “inconsistent” its terms of service or “reasonable expectations of consumers,” they may be in violation of the FTC Act.

Brendan Carr, the chairman of the Federal Communications Commission (another Trump appointee critical of Big Tech), supported Ferguson’s stance, writing, “Apple has no right to suppress conservative viewpoints in violation of the FTC Act.”

Ferguson has urged Apple to conduct a “comprehensive review” of its terms of service and ensure that the content curated on Apple News is consistent with its policies, and “take corrective action swiftly” if the curation isn’t in line.

The letter comes a day after President Donald Trump shared the report by Media Research Center on his social media platform, Truth Social. Trump has repeatedly accused Big Tech companies of censoring right-leaning content, though many major platforms have rolled back several measures to curb fake news and disinformation they had imposed in the years prior to his second stint at the White House.

Apple’s relationship with the Trump administration has oscillated between warm and cold over the past year. Trump has criticized Big Tech, especially Apple, for manufacturing its devices in China, but after Cook promised to spend more than $600 billion over the next four years stateside and moved to mend fences, relations between the administration and the company have improved. Apple also dodged planned tariffs on smartphones made overseas and imported into the U.S.

The FTC last year also launched an investigation into “censorship by tech platforms,” seeking input from the public who felt they were silenced due to their political ideologies or affiliations. “Tech firms should not be bullying their users,” Ferguson said at the time. “This inquiry will help the FTC better understand how these firms may have violated the law by silencing and intimidating Americans for speaking their minds.”

Apple did not immediately return a request for comment.

Ram is a financial and tech reporter and editor. He covered North American and European M&A, equity, regulatory news and debt markets at Reuters and Acuris Global, and has also written about travel, tourism, entertainment and books.

You can contact or verify outreach from Ram by emailing ram.iyer@techcrunch.com.

Tickets are live at the lowest rates of the year. Save up to $680 on your pass now.Meet investors. Discover your next portfolio company. Hear from 250+ tech leaders, dive into 200+ sessions, and explore 300+ startups building what’s next. Don’t miss these one-time savings.

The first signs of burnout are coming from the people who embrace AI the most

MrBeast’s company buys Gen Z-focused fintech app Step

Ex-Googlers are building infrastructure to help companies understand their video data

YouTube TV introduces cheaper bundles, including a $65/month sports package

Discord to roll out age verification next month

From Svedka to Anthropic, brands make bold plays with AI in Super Bowl ads

The backlash over OpenAI’s decision to retire GPT-4o shows how dangerous AI companions can be</div>
        </div>
        
        <div class="card" onclick="openModal('content-14')">
            <div class="source">TechCrunch</div>
            <div class="title">Eclipse backs all-EV marketplace Ever in $31M funding round</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-14" style="display:none;">
            <h2>Eclipse backs all-EV marketplace Ever in $31M funding round</h2>
            <p><strong>TechCrunch | 2026-02-12</strong></p>
            <a class="original-link" href="https://techcrunch.com/2026/02/12/eclipse-backs-all-ev-marketplace-ever-in-31m-funding-round/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">If you want to buy or sell a used EV right now, what’s the first step you’d take?

A startup called Ever wants to be the answer to that question. The company, which bills itself as the first “AI-native, full-stack auto retail business” for electric vehicles, already has thousands of customers buying and selling their EVs on the platform.

Now it’s looking to scale with help from a $31 million Series A funding round led by Eclipse, with Ibex Investors, Lifeline Ventures, and JIMCO — the investment arm of the Saudi Arabian Jameel family (an early investor in Rivian) — as co-investors.

Over the last decade, companies like Carvana and CarMax helped usher in the digital car-buying experience. More recently, myriad startups have tried to improve the car-buying experience with AI, pitching ideas like voice agents or smarter scheduling software. Eclipse’s Jiten Behl thinks this is the wrong approach if you want to really modernize the automotive retail experience, though.

“These bolt-on AI tools are band-aids,” he said in an interview with TechCrunch. He likened it to how many major automakers’ first EVs were essentially combustion vehicles that were repackaged to fit electric drivetrains. That approach came with major tradeoffs compared to designing a new EV from the ground up, which was the approach companies like Tesla and Rivian took.

“Auto retail is a perfect candidate for disrupting with AI, you know? It’s a lot of process, lot of labor, [very] rules-based,” he said.

Lasse-Mathias Nyberg, Ever co-founder and CEO, said in an interview that buying or selling a car typically triggers “hundreds or thousands of different actions” that a retailer needs to perform in order to complete the transaction. “There’s massive complexities or frictions on both sides.”

In 2022, he and his team set out to reduce or remove those complexities. What they settled on after a year of research was a digital-first auto retailer. The core tech is an orchestration layer or “operating system” that can handle all the different workflows behind a transaction, whether it’s processing information submitted by a prospective buyer or seller, or managing the vehicle inventory.

“When you do appraisals, or pricing, or titling, it’s very deterministic in terms of what steps need to be taken. And today, there are lots of single point solution tools that are used,” he said. Most companies “use these tools together in a very inefficient manner, and you think that you are on a digital journey — but if you actually could clean-sheet it, and if you actually could use the power of agentic AI, and you can create one unified customer experience and remove all these micro-frictions.”

Nyberg claimed that building the company this way has allowed Ever’s sales team to be two to three times more productive than they would be otherwise, and he expects that to scale as the company grows. He said this extra efficiency and productivity beefs up their margins, which can be booked as profit or passed along to the customer by offering lower prices.

Ever applies this fresh approach to both its online marketplace and physical locations. Nyberg said the hybrid model is important because seeing and trying a car in person remains crucial to the shopping experience for a lot of buyers — especially those who might be assessing EVs for the first time.

Early reviews of Ever’s product have been mixed. Users on one particular Reddit thread from last year were split, with some drawn to how Ever is making EVs easier to buy, while others detailed struggles getting in touch with the startup’s team. Ever was just getting off the ground and was more or less operating in stealth, and so Nyberg chalks that up to a learning experience. He said his team is working hard to make sure its system can be flexible enough to accomplish everything the company has set out to do.

The bigger challenge may be overall interest in EVs, which has cooled a bit in the United States. Nyberg said he hasn’t ruled out Ever buying or selling used combustion cars in the future, but wants to stick to EVs in the near-term since there isn’t a retailer that is laser-focused on these vehicles.

Behl, who spent eight years on Rivian’s leadership team, admitted he’s a “hopeless romantic when it comes to EVs,” and said he still believes the industry is moving toward electric propulsion because of the inherent benefits. And he said his “first thought” when he started doing diligence on Ever was: “I wish Rivian was doing this.”

More broadly, Behl said, companies like Carvana are still in the single digits of market share when it comes to automotive retail. That’s why he sees so much upside in Ever.

“Customers are going to continue to gravitate towards better experience when it comes to buying cars, which means it is going to be a digitally-led customer experience which takes away all the friction of buying and selling a car,” he said.

Sean O’Kane is a reporter who has spent a decade covering the rapidly-evolving business and technology of the transportation industry, including Tesla and the many startups chasing Elon Musk. Most recently, he was a reporter at Bloomberg News where he helped break stories about some of the most notorious EV SPAC flops. He previously worked at The Verge, where he also covered consumer technology, hosted many short- and long-form videos, performed product and editorial photography, and once nearly passed out in a Red Bull Air Race plane.

You can contact or verify outreach from Sean by emailing sean.okane@techcrunch.com or via encrypted message at okane.01 on Signal.

Tickets are live at the lowest rates of the year. Save up to $680 on your pass now.Meet investors. Discover your next portfolio company. Hear from 250+ tech leaders, dive into 200+ sessions, and explore 300+ startups building what’s next. Don’t miss these one-time savings.

The first signs of burnout are coming from the people who embrace AI the most

MrBeast’s company buys Gen Z-focused fintech app Step

Ex-Googlers are building infrastructure to help companies understand their video data

YouTube TV introduces cheaper bundles, including a $65/month sports package

Discord to roll out age verification next month

From Svedka to Anthropic, brands make bold plays with AI in Super Bowl ads

The backlash over OpenAI’s decision to retire GPT-4o shows how dangerous AI companions can be</div>
        </div>
        
        <div class="card" onclick="openModal('content-15')">
            <div class="source">TechCrunch</div>
            <div class="title">xAI lays out interplanetary ambitions in public all-hands</div>
            <div class="meta">2026-02-11</div>
        </div>
        
        <div id="content-15" style="display:none;">
            <h2>xAI lays out interplanetary ambitions in public all-hands</h2>
            <p><strong>TechCrunch | 2026-02-11</strong></p>
            <a class="original-link" href="https://techcrunch.com/2026/02/11/xai-lays-out-interplanetary-ambitions-in-public-all-hands/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">On Wednesday, xAI took the rare step of publishing a full 45-minute all-hands meeting video on X, making it publicly accessible. Details of the Tuesday night meeting were previously reported by The New York Times, which may have influenced xAI’s decision to post the video online.

The full video reveals significant new details about Musk’s plans for the AI lab, including its product roadmap and its ongoing ties to the X platform.

Since xAI was formed just 30 months ago, the small and talented team has made remarkable progress.The future has never looked more exciting! pic.twitter.com/QZ73H2mpBj

The most immediate revelation concerned a string of departing employees, which Musk described as layoffs resulting from a changing organizational structure at the company. While reorganizations are common, the breadth of the departures has caused significant confusion, particularly as it has meant the loss of a significant portion of the founding team.

“As a company grows, especially as quickly as xAI, the structure must evolve,” Musk said on X. “This unfortunately required parting ways with some people. We wish them well in future endeavors.”

The new organizational system splits xAI into four primary teams: one focused on the Grok chatbot (including voice), another for the app’s coding system, another for the Imagine video generator, and finally a team focused on the Macrohard project, which spans from simple computer use simulation to modeling entire corporations.

“[Macrohard] is able to do anything on a computer that a computer is able to do,” Toby Pohlen, who will lead the project under the new organizational structure, told his colleagues. “There should be rocket engines fully designed by AI.”

The all-hands also featured claims about new usage and revenue figures for xAI and X. Nikita Bier, X’s head of product, said X had “just crossed” $1 billion in annual recurring revenue from subscriptions, which he attributed to a marketing push during the holidays.

Additionally, executives said the xAI’s Imagine tool is generating 50 million videos a day, and more than 6 billion images over the past 30 days, according to their internal metrics.

But it’s difficult to separate those figures from the flood of deepfake pornography that overtook X during that same period. The X platform saw engagement skyrocket as AI-generated explicit images became more prevalent, and with an estimated 1.8 million sexualized images generated over just nine days, the image-generation figures likely include substantial amounts of this controversial content.

The most eye-catching part of the presentation came at the end, when Musk reemphasized the importance of space-based data centers despite the technical challenges involved. Musk went still further, envisioning a moon-based factory for AI satellites, including a lunar mass driver — essentially an electromagnetic catapult — to launch them. With such infrastructure, Musk said, one could launch an AI cluster capable of capturing significant portions of the sun’s total energy output or even expanding to other galaxies.

“It’s difficult to imagine what an intelligence of that scale would think about,” Musk said, “but it’s going to be incredibly exciting to see it happen.”

Tickets are live at the lowest rates of the year. Save up to $680 on your pass now.Meet investors. Discover your next portfolio company. Hear from 250+ tech leaders, dive into 200+ sessions, and explore 300+ startups building what’s next. Don’t miss these one-time savings.

The first signs of burnout are coming from the people who embrace AI the most

MrBeast’s company buys Gen Z-focused fintech app Step

Ex-Googlers are building infrastructure to help companies understand their video data

YouTube TV introduces cheaper bundles, including a $65/month sports package

Discord to roll out age verification next month

From Svedka to Anthropic, brands make bold plays with AI in Super Bowl ads

The backlash over OpenAI’s decision to retire GPT-4o shows how dangerous AI companions can be</div>
        </div>
        
        <div class="card" onclick="openModal('content-16')">
            <div class="source">TechCrunch</div>
            <div class="title">AI inference startup Modal Labs in talks to raise at $2.5B valuation, sources say</div>
            <div class="meta">2026-02-11</div>
        </div>
        
        <div id="content-16" style="display:none;">
            <h2>AI inference startup Modal Labs in talks to raise at $2.5B valuation, sources say</h2>
            <p><strong>TechCrunch | 2026-02-11</strong></p>
            <a class="original-link" href="https://techcrunch.com/2026/02/11/ai-inference-startup-modal-labs-in-talks-to-raise-at-2-5b-valuation-sources-say/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Modal Labs, a startup specializing in AI inference infrastructure, is talking to VCs about a new round at a valuation of about $2.5 billion, according to four people with knowledge of the deal. Should the deal close at these terms, the funding round would more than double the company’s valuation of $1.1 billion announced less than five months ago, when it announced an $87 million Series B round.

General Catalyst is in talks to lead the round, the people told TechCrunch. Modal’s annualized revenue run rate (ARR) is approximately $50 million, our sources said. The discussions are early, and terms could still change.

Modal Labs co-founder and CEO Erik Bernhardsson denied that his company was actively fundraising and characterized his recent interactions with VCs as general conversations. General Catalyst did not respond to our requests for comment.

Modal is focused on optimizing inference, the process of running trained AI models to generate answers from user requests. Improving inference efficiency reduces compute costs and cuts down the lag time between a user’s prompt and the AI’s response.

Modal is one of the handful of inference-focused companies attracting intense investor attention now. Last week, its competitor Baseten announced a $300 million raise at a $5 billion valuation, more than doubling the $2.1 billion valuation it reached just months prior in September. Similarly, Fireworks AI, an inference cloud provider, secured $250 million at a $4 billion valuation in October.

In January, the creators of the open source inference project vLLM announced they had transitioned the tool into a VC-backed startup, Inferact, raising $150 million in seed funding led by Andreessen Horowitz at an $800 million valuation. Meanwhile, TechCrunch reported that the team behind SGLang has commercialized as RadixArk, which sources told us secured seed funding at a $400 million valuation led by Accel.

Modal was co-founded by CEO Erik Bernhardsson in 2021 after he spent more than 15 years building and leading data teams at companies including Spotify and Better.com, where he was CTO.

The startup counts Lux Capital and Redpoint Ventures among its earlier backers.

Editor’s Note: This story was updated to include a comment from Modal.

Marina Temkin is a venture capital and startups reporter at TechCrunch. Prior to joining TechCrunch, she wrote about VC for PitchBook and Venture Capital Journal. Earlier in her career, Marina was a financial analyst and earned a CFA charterholder designation.

You can contact or verify outreach from Marina by emailing marina.temkin@techcrunch.com or via encrypted message at +1 347-683-3909 on Signal.

Tickets are live at the lowest rates of the year. Save up to $680 on your pass now.Meet investors. Discover your next portfolio company. Hear from 250+ tech leaders, dive into 200+ sessions, and explore 300+ startups building what’s next. Don’t miss these one-time savings.

The first signs of burnout are coming from the people who embrace AI the most

MrBeast’s company buys Gen Z-focused fintech app Step

Ex-Googlers are building infrastructure to help companies understand their video data

YouTube TV introduces cheaper bundles, including a $65/month sports package

Discord to roll out age verification next month

From Svedka to Anthropic, brands make bold plays with AI in Super Bowl ads

The backlash over OpenAI’s decision to retire GPT-4o shows how dangerous AI companions can be</div>
        </div>
        
        <div class="card" onclick="openModal('content-17')">
            <div class="source">TechCrunch</div>
            <div class="title">OpenAI disbands mission alignment team</div>
            <div class="meta">2026-02-11</div>
        </div>
        
        <div id="content-17" style="display:none;">
            <h2>OpenAI disbands mission alignment team</h2>
            <p><strong>TechCrunch | 2026-02-11</strong></p>
            <a class="original-link" href="https://techcrunch.com/2026/02/11/openai-disbands-mission-alignment-team-which-focused-on-safe-and-trustworthy-ai-development/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">OpenAI has disbanded a team that was designed to communicate the company’s mission to the public and to its own employees. At the same time, the team’s former leader has been given a new role as the company’s “chief futurist.”

OpenAI confirmed to TechCrunch that the team’s members have now been assigned to other roles. The news was first reported by Platformer.

The disbanded team in question appears to have been formed in September of 2024. Platformer reports that the team was dedicated to promoting “the company’s stated mission to ensure that artificial general intelligence benefits all of humanity.”

An official OpenAI spokesperson described the team thusly: “The Mission Alignment project was a support function to help employees and the public understand our mission and the impact of AI. That work continues throughout the organization.”

In a blog post published Wednesday, Josh Achiam, the former head of OpenAI’s mission alignment team, explained his new role as the company’s chief futurist. “My goal is to support OpenAI’s mission — to ensure that artificial general intelligence benefits all of humanity — by studying how the world will change in response to AI, AGI, and beyond,” Achiam wrote.

Achiam noted that, in his new role, he would be collaborating with Jason Pruet, an OpenAI physicist.

A spokesperson for OpenAI said the rest of the mission alignment team — a group of six or seven people — had subsequently been reassigned to different parts of the company. The spokesperson couldn’t say where exactly the team members had been assigned, but said that they were engaged in similar work in those roles. It was also unclear whether Achiam would have a new team as part of his “futurist” role.

The spokesperson attributed the disbanding of the team to the kinds of routine reorganizations that occur within a fast-moving company.

OpenAI previously had what it called a “superalignment team” — which was formed in 2023 and focused on studying long-term existential threats posed by AI — but that team was disbanded in 2024.

Achiam’s personal website still lists him as head of mission alignment at OpenAI, and describes him as being interested in ensuring that the “long-term future of humanity is good.” His LinkedIn profile shows he had served as head of mission alignment since September 2024.

Correction: This story originally confused mission alignment with another, similarly named team called alignment. It has been corrected and we apologize for the error.

Tickets are live at the lowest rates of the year. Save up to $680 on your pass now.Meet investors. Discover your next portfolio company. Hear from 250+ tech leaders, dive into 200+ sessions, and explore 300+ startups building what’s next. Don’t miss these one-time savings.

The first signs of burnout are coming from the people who embrace AI the most

MrBeast’s company buys Gen Z-focused fintech app Step

Ex-Googlers are building infrastructure to help companies understand their video data

YouTube TV introduces cheaper bundles, including a $65/month sports package

Discord to roll out age verification next month

From Svedka to Anthropic, brands make bold plays with AI in Super Bowl ads

The backlash over OpenAI’s decision to retire GPT-4o shows how dangerous AI companions can be</div>
        </div>
        
        <div class="card" onclick="openModal('content-18')">
            <div class="source">The Atlantic</div>
            <div class="title">The Tide Goes Out on Youth Gender Medicine</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-18" style="display:none;">
            <h2>The Tide Goes Out on Youth Gender Medicine</h2>
            <p><strong>The Atlantic | 2026-02-12</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/ideas/2026/02/ama-asps-gender-surgery-minors/685961/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">As the shaky evidence base for youth gender medicine has become better known, activists have retreated to an argument from authority. Never mind the Cass Report, whose findings resulted in the closure of Britain’s leading youth gender clinic. Never mind the study by a leading American practitioner showing that the treatments she championed did not improve minors’ mental health. Never mind reports that some adolescents were being put on a medical pathway after only a single clinic visit. For advocates, the important thing to remember was that “gender-affirming care” for minors—puberty blockers and hormones, plus surgery in rare cases—was endorsed by all of the major American medical associations.

“Doctors Agree,” proclaimed the American Civil Liberties Union: “Gender-Affirming Care Is Life-Saving Care.” GLAAD declared that “every major medical association and leading world health authority supports health care for transgender people and youth.” Fired up by the Republican “war on trans kids,” and naturally deferential to institutional authority, Democrats have tended to echo this line. At a 2023 congressional-subcommittee hearing on pediatric gender medicine, the ranking Democrat, Representative Mary Gay Scanlon of Pennsylvania, declared that “gender-affirming care is safe and effective” and “supported by every major medical association”—groups that collectively count more than 1.3 million doctors as members. “It’s not up for debate,” she said. In line with this, Joe Biden’s administration lobbied to remove age minimums from the industry’s standards of care.

Today, though, the future of medical transition for minors is up for debate. On February 3, the American Society of Plastic Surgeons recommended that “surgeons delay gender-related breast/chest, genital, and facial surgery until a patient is at least 19 years old.” The next day, the American Medical Association, the country’s largest organization representing doctors, endorsed that view: “In the absence of clear evidence, the A.M.A. agrees with A.S.P.S. that surgical interventions in minors should be generally deferred to adulthood.” These statements echo what skeptics of American youth gender medicine have been saying for years: The evidence of the benefits and risks of mastectomies and other surgeries is insufficient to justify their use as treatments for gender dysphoria, and follow-up data on those who have undergone the procedures are scant.

Helen Lewis: The liberal misinformation bubble about youth gender medicine

More significant, the ASPS statement explicitly endorses the conclusions of the Cass Report and the evidence review commissioned by the Department of Health and Human Services last year. LGBTQ groups and gender clinicians have dismissed both of these documents as fuel for right-wing attacks on care, even though Hilary Cass was a nonpartisan retired pediatrician, and most of the HHS report authors were self-described liberals and Democrats. But the ASPS references both warmly, and bases its new guidelines on the research carried out by the official British and American inquiries. “Both the Cass Review and the HHS report emphasize that the natural course of pediatric gender dysphoria remains poorly understood,” notes the ASPS statement. “Available evidence suggests that a substantial proportion of children with prepubertal onset gender dysphoria experience resolution or significant reduction of distress by the time they reach adulthood, absent medical or surgical intervention.” Put simply, that is an American doctors’ organization acknowledging that gender dysphoria frequently resolves itself without treatment—a challenge to the idea that children’s new identities should be uncritically endorsed.

I don’t want to overstate what has happened here: The ASPS has been more cautious than other groups for many months now, and its new positions are limited in scope. Gender surgeries on minors were never offered by Britain’s health service, and only a few thousand have been performed in the United States, according to a 2023 study. The ASPS statement also cites “insufficient evidence demonstrating a favorable risk-benefit ratio” for hormone treatments, but does not explicitly recommend against them. Yet the organization’s stance still represents a shift away from the purely affirmative model, in which saying no is never a clinician’s job. Notably, the group reminds members that “plastic surgeons cannot rely on the presence of a prior medical intervention, referral, or letter of support as a proxy for surgical indication or adolescent readiness.”

This matters, because the idea of performing mastectomies on girls as young as 13 became a powerful symbol of a clique of doctors who could not be trusted to regulate themselves. The Miami surgeon Sidhbh Gallagher became known on TikTok for her catchphrase “yeet the teet,” referring to mastectomies, and for calling herself “Dr. Teetus Deletus.” The detransitioner Chloe Cole, who has testified in favor of state bans on pediatric gender medicine, received a double mastectomy at 15. Johanna Olson-Kennedy, who formerly worked at the gender clinic of the Children’s Hospital Los Angeles, was the lead author on a paper recommending that mastectomies be offered based on “individual need rather than chronologic age.” She once boasted at a seminar that she did not worry about regret: “If you want breasts at a later point in your life, you can go and get them.”

Unfortunately, things are not that simple. In a recent lawsuit in New York State, a detransitioner called Fox Varian testified that she’d had her breasts removed at 16, only 11 months after first identifying as male. She had also been diagnosed with autism and had struggled with an eating disorder and anxiety. By the time of the surgery, she had changed her name twice already. Varian asserted, according to the reporter Benjamin Ryan, who attended the trial, that her doctor “served as an enabler, repeatedly assuring her that the mastectomy she desired would greatly improve her well-being.” Varian told the court that she regretted the surgery instantly, and detransitioned three years later. She was awarded $2 million in damages. The court heard that she had been left with scarring and a lack of sensation, and would be unable to breastfeed.

Varian’s lawsuit also claimed that doctors encouraged her mother to approve the surgery by invoking the specter of suicide. As I wrote last year, the idea of youth gender medicine as “lifesaving”—for the prevention of suicide—has been key to overriding parents’ understandable concerns about these treatments. But this is another activist talking point that has begun to crumble. In front of the Supreme Court, the ACLU’s Chase Strangio conceded that there was no evidence to support the assertion that transition prevents suicide, because “completed suicide, thankfully and admittedly, is rare.” He argued that instead it reduced suicidal thoughts—a significant climbdown from the once-popular assertion that parents had to choose between “a dead son and a living daughter,” and vice versa. His concession helped expose this rhetoric as the emotional blackmail that it always was.

Adam Serwer: The attack on trans rights won’t end there

The tide is now going out on the affirmative approach to youth gender medicine as practiced in America. “I stopped the mutilation of children,” Donald Trump told a prayer breakfast on February 5. Twenty-seven states have placed restrictions on the medical pathway, while gender clinics in blue cities such as Los Angeles have shut down under Trump’s threat of funding cuts to their host institutions. Now the success of such a high-profile detransitioner lawsuit—one of more than two dozen currently under way, according to Ryan—will make the remaining affirmative clinicians nervous.

Frankly, they should be nervous. As the field has received more scrutiny, advocates have begun to stress the need for careful assessments, even though American providers in the 2010s largely rejected this essential feature of the Dutch protocol, the medical treatment for youth gender dysphoria developed in Europe in the 1990s. Today, when Democrats defend youth gender medicine, they tend to do so on the basis of individual freedom rather than the effectiveness of the treatments themselves. In 2024, a brief signed by 11 Democratic senators and 153 Democratic House members urged the Supreme Court not to uphold Tennessee’s ban on youth medical transition. The state law “intrudes on an individual’s decisions about their own medical care, made in partnership with their medical providers,” the signatories said.

All of this represents a clear retrenchment from the 2010s and early 2020s. The excesses of that era prompted a backlash that fueled the current MAGA demonization of gender nonconformity. The story of youth gender medicine is one of good intentions, arrogance, fear, and polarization. It is also an avoidable tragedy.</div>
        </div>
        
        <div class="card" onclick="openModal('content-19')">
            <div class="source">The Atlantic</div>
            <div class="title">Trump Has a Bridge He Wants to Sell You</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-19" style="display:none;">
            <h2>Trump Has a Bridge He Wants to Sell You</h2>
            <p><strong>The Atlantic | 2026-02-12</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/ideas/2026/02/trump-detroit-windsor-bridge/685967/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The president of the United States became aware Monday evening, apparently for the first time, that a new bridge is set to open between Michigan and Ontario. The project promises to create a fast and inexpensive route that Michigan’s farmers and businesses have sought for decades.

Donald Trump decided this could not stand.

In a typically discursive social-media post, Trump announced, “I will not allow this bridge to open until the United States is fully compensated for everything we have given them, and also, importantly, Canada treats the United States with the Fairness and Respect that we deserve.” The post also predicts that ice hockey will soon be banned in Canada as a result of its trade agreement with China. On the plus side, it does refer to Canada as a “Country” rather than, as the president has enjoyed describing it, a state.

On the surface, this looked to be just one more Trumpian tantrum, the kind that regularly pops up when he sees something distressing on television or is spoken to by a woman without the self-abasement he demands.

But subsequent reporting suggests that this was something even worse: an episode that sums up Trumpian economics in all its stupidity and atavistic sleaze.

Hours before Trump’s post, according to The New York Times, Commerce Secretary Howard Lutnick met with Matthew Moroun, the owner of a competing bridge between Michigan and Ontario. Lutnick then spoke with the president by phone. You might wonder why a major international bridge has an owner when such things are ordinarily in public hands. The answer is that the Ambassador Bridge was privately constructed, and for decades has stood as the sole trucking link from Detroit to Windsor, a key thoroughfare for national and international commerce. If you want to travel from Michigan to, say, Boston, your fastest route runs through Canada.

The Ambassador Bridge gets clogged with traffic and charges expensive tolls, which Moroun is able to compel because his customers have no practical alternative. A separate tunnel connects Detroit and Windsor, but larger trucks can’t use it. Moroun’s family has spent decades and millions of dollars trying to keep things that way, relentlessly lobbying to block construction of a second bridge desired by drivers and merchants on both sides of the Detroit River.

A breakthrough arrived in 2012. Rick Snyder, a Republican who was then Michigan’s governor, cut a deal with Canada to build the Gordie Howe International Bridge. Snyder had to work around the recalcitrant Michigan legislature, which had been plied with Moroun donations, by using executive authority. The terms of the deal required Canada to finance all construction costs. Canada is permitted to collect full tolls until it recoups its investment, and ownership of the bridge is to be split equally.

The project would unlock billions of dollars in savings for consumers and businesses. The sole loser is Moroun, a billionaire whose fortune rests on rent seeking. Now that the bridge construction is essentially complete and set to finally open, Moroun has gone to the administration, and Trump has shut down his competition.

Trump’s stated demands to open the bridge are a mixture of fantasy and contrived grievance. Trump complains in his post that the bridge was built without American material, which is false, and insists, “With all that we have given them, we should own, perhaps, at least one half of this asset,” which is already the case.

White House Press Secretary Karoline Leavitt, attempting to add a sheen of rationality to the president’s ultimatum, said, “It’s also unacceptable that more of this bridge isn’t being built with more American-made materials.” This is a difficult requirement to meet unless Canada decides to tear down the bridge and rebuild it with more American-made material.

Trump’s post also requires, as a condition of opening the new bridge, that Canada give the United States more “respect.” One way other countries have demonstrated respect to Trump has been furnishing him with expensive gifts or investing in his family businesses. Canada’s rules against bribery make this negotiation shortcut more difficult.

Franklin Foer: Why the Gulf monarchs shower Trump with gifts

This episode is a prototypical demonstration of Trump’s economic worldview. Faced with a policy choice that pits the interests of millions of people against the wealth of a single rent seeker, Trump has intervened in a way that benefits the billionaire.

The insight that the free exchange of goods and services has positive-sum benefits—a core tenet of market economics—has always eluded Trump. His instincts are not capitalistic but pre-capitalistic. He has the mentality of a Renaissance baron, hoarding power and collecting tribute rather than innovating and creating wealth.

The president may be hurting a foreign country, but that does not mean he is helping ours. He is shrinking the pie, while delivering a larger slice of it to a Trumpian oligarch.</div>
        </div>
        
        <div class="card" onclick="openModal('content-20')">
            <div class="source">The Atlantic</div>
            <div class="title">The Multibillion-Dollar Foundation That Controls the Humanities</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-20" style="display:none;">
            <h2>The Multibillion-Dollar Foundation That Controls the Humanities</h2>
            <p><strong>The Atlantic | 2026-02-12</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/magazine/2026/03/mellon-foundation-humanities-research-funding/685733/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">In 1964, an influential report identified a disquieting trend in academia. “Increasingly during the past few years,” it began, “concern has been expressed about the condition, in this country, of those fields of intellectual activity generally called the humanities.” The 200-plus-page document was a publication of the National Commission on the Humanities, which had been established the previous year.

Reading the commission’s findings six decades later, one could reasonably conclude that what today gets called the “crisis of the humanities” is not so much a discrete 21st-century emergency as the latest expression of an educational catastrophe long in the making. The challenges outlined in 1964 are familiar: meager funding, insufficient support for graduate students, too few faculty jobs, an education system that glamorizes science and math, dense writing that alienates the public, and on and on. “The state of the humanities today creates a crisis,” the report concluded. “There is genuine doubt today whether the universities and colleges can insure that the purposes for which they were established and sometimes endowed will be fulfilled.”

Check out more from this issue and find your next story to read.

This doubt has not much diminished in the intervening decades, nor have the problems the report identified. Yet what is most notable in the report is not these similarities, but the commission’s prescient fear that the solutions to what ailed the humanities—namely, more cash and large-scale institutional support—also carried risks. “For the very reason that the humanities are concerned with quality, with values, with emotions, and with the goals of living, they must remain free,” the report proclaimed. “To control them is to dictate opinion and to subject all men to the tyranny of a controlling authority in the most intimate and sacred concerns of our existence as human beings.”

The commission’s boldest recommendation was that a new, publicly funded national foundation be established to dispense money to the humanities. But it also cautioned that this path was fraught. The report argued that, although building a taxpayer-financed agency to support American arts and letters was necessary, no federal body should have a monopoly on this grant-making, lest the humanities become unduly influenced by politics. “We must unquestionably increase the prestige of the humanities and the flow of funds to them,” the commission wrote. “At the same time, however grave the need, we must safeguard the independence, the originality, and the freedom of expression of all who are concerned with liberal learning.”

The report recommended that federal funding for the humanities be supplemented by ideologically diverse, nongovernmental donors. “The day must never come when scholars and artists can look only to the federal government for the help they need,” it said. “The notion of any one ‘chosen instrument’ of government in this area must be abhorrent to anyone who cherishes the humanities and realizes that if they are not free they perish.”

Thomas Chatterton Williams: Stop trying to make the humanities ‘relevant’

For a while, things seemed to go more or less according to the commission’s plan. President Lyndon B. Johnson established the National Endowment for the Humanities in 1965 in direct response to the report. A few years later, the Andrew W. Mellon Foundation was created to finance American arts and letters. It would become part of a broader network that included the Ford Foundation, which began funding the humanities in the 1950s, and the John Templeton Foundation, which began funding research in religion and philosophy in the 1980s. The benefaction of these private nonprofits eventually came to exceed, by a substantial margin, the money dispensed by the government, which has declined over time.

In recent decades, though, the priorities of many of these nonprofits have shifted. The Atlantic Philanthropies, a onetime stalwart, reduced its funding for the humanities in the 1990s. The Rockefeller Foundation began moving away from humanities funding in the 2000s. In 2022, the Ford Foundation announced plans to drastically reduce its higher-education funding in order to focus on racial-justice-movement building. With the broader ecosystem of humanities-focused philanthropies all but dried up, only one major private grant-maker is left standing.

Today, no single entity, including the federal government, has a more profound influence on the fiscal health and cultural output of the humanities than the Mellon Foundation. The National Endowment for the Humanities’ grant budget was $78 million in 2024 (its overall budget was less than half of what it was in 1980, when adjusted for inflation). Mellon awarded $540 million in grants that same year; its endowment sits at roughly $8 billion.

Mellon’s largesse is badly needed, especially as the Trump administration has threatened further cuts to the NEH. But the foundation’s virtual monopoly on humanities funding means that it has the power to remake entire fields according to its desires. And in recent years, under the leadership of Elizabeth Alexander, who became the organization’s president in 2018, Mellon has embraced an understanding of the humanities that is much more utilitarian, and far more political, than the one put forward by the 1964 commission. In June 2020, Mellon announced that it would be “prioritizing social justice in all of its grantmaking”—“a major strategic evolution” for the organization. This new paradigm seems to find value in arts and letters only insofar as they advance approved, left-leaning causes.

Over the past decade or so, conservative critics of higher education have tended to offer a rather simple explanation for the humanities’ decline. Their argument amounts to a version of “go woke, go broke.” According to this theory, ultraprogressive faculty coalesced around an unpopular liberal orthodoxy, turning off undergraduates (and the public) and accelerating the humanities’ collapse. In short, Shakespeare was replaced by jargon-laden prattle about “settler colonialism,” and students took their tuition dollars to more sane, less shrill corners of universities.

But this tale places too much of the blame on humanities professors, overestimating their actual power within institutions. More important, the went-woke-went-broke hypothesis does not account for the ways that economic transformations within higher education have accelerated the trends that conservatives lament. Specifically, the right-wing theory of the case gets the causal arrow wrong. The humanities aren’t broke because they went woke. The humanities went woke in large part because they were broke. As other donors, the government, and universities themselves all but abandoned these fields, Mellon became a lifeline. But the foundation has proved to be—as Jacques Derrida might have said—a kind of pharmakon: a Greek word that the philosopher noted could be translated as either “remedy” or “poison,” depending on your perspective.

Tyler Austin Harper: The humanities have sown the seeds of their own destruction

The 1964 report failed to anticipate that, in the 21st century, one of the most substantial challenges to the intellectual and political autonomy of the humanities would come not from a government agency, but from a private organization. American humanists now find themselves in a position that the report’s authors would have considered a nightmare: A multibillion-dollar politicized grant-making entity has a stranglehold over humanities research and teaching, and is using that power to push them in a direction that blurs the boundaries between scholarship and activism, pedagogy and politics.

Under Alexander’s leadership, even as it has cut back on funding for less political projects, Mellon has disbursed enormous sums of money to hyper-liberal academic initiatives at institutions both public and private. These have included grants to Portland State University to help its Women, Gender, and Sexuality Studies Department become more “ungovernable,” creating “spaces where activism is encouraged” and “queer and feminist resistance” takes place; to Texas A&M at San Antonio for the Borderlands Shakespeare Colectiva (a group of academics and activists who “use Shakespeare to reimagine colonial histories and to envision socially just futures in La Frontera”); to Northwestern University for a project that explores how “Black dance practices” work to “instantiate Black freedom”; to Northeastern University for its Digital Transgender Archive to establish a new “lab” on the West Coast; and to UC Davis’s Department of Gender, Sexuality and Women’s Studies to create a working group on “Trans Liberation in an Age of Fascism.”

One may feel a variety of ways about the worldview that Mellon has chosen to promote through its grant-making. But the salient question is not whether its politics are laudable or lamentable, or even whether the projects it funds are beneficial. The real questions are: What are the consequences when eye-watering sums of money are put behind the idea that the purpose of American arts and letters is not wisdom but advocacy? What happens when the humanities are seen not as having intrinsic worth, but as valuable only insofar as they can be of service to a cause? And what happens when the “choice” of whether to accede to this vision of the humanities becomes—when there is only one real funding game in town—a matter of survival versus collapse?

The Andrew W. Mellon Foundation was established in 1969, when two siblings—Ailsa Mellon Bruce, a socialite and an art collector, and Paul Mellon, an art collector and a racehorse breeder—decided to combine their personal charitable outfits in honor of their late industrialist father. Their new organization would fund American arts and letters, eventually including foreign-language programs, university special collections, tenure-track positions for new humanities professors, graduate fellowships for Ph.D. students, archival research, and more.

Even before its recent pivot, Mellon tended to tilt to the left, perhaps as a kind of compensation for, or a distraction from, the unseemly reality that it is a multibillion-dollar foundation created by the patrician offspring of a robber baron. But although some of its endeavors through the years were expressly social-justice-oriented (such as a 2016 grant for Columbia’s “Facing Whiteness” project, an interdisciplinary study of how white Americans think about their racial identity), others were more traditional (a long-standing relationship with the Folger Shakespeare Library, for example).

In many ways, the role that liberal politics and social justice should play in higher education has been a preoccupation of the country’s colleges and universities since the mid-20th century. Like cicadas, controversies tend to pop up every decade or so. There was William F. Buckley Jr.’s panic about “collectivism” in the Ivy League, documented in his 1951 book, God and Man at Yale. There were the campus free-speech and civil-rights movements of the 1960s, many of which led to the establishment of identity-focused humanities departments. Then came the fights over political correctness, multiculturalism, and the literary canon in the ’80s and ’90s associated with conservative intellectuals such as Allan Bloom and Roger Kimball. Christopher Rufo’s “critical race theory” dissension kicked off the 2020s, giving way to disputes over wokeness and anti-wokeness. Lately, American campuses have been dominated by the debates around decolonial theory and free speech that emerged from the Gaza crisis.

From the November 1951 issue: A review of William F. Buckley Jr.’s attack on Yale

The cumulative effect of these skirmishes has been to weaken the humanities’ already vulnerable stock with the public. American culture treats the arts, ideas, and literature as luxury goods that can be cast aside during moments of belt-tightening, and post-2008 austerity measures have hit the humanities hard, resulting in budget cuts, vanished tenure lines, dwindling research funds, and diminished federal dollars. In a 2024 article for an academic journal, the literary scholar Christopher Newfield showed how few resources are allocated to basic humanities research in the United States. “Of the $54 billion or so in research that the federal government funds in U.S. higher education, $69 million goes to the humanities,” he wrote. “That is, the humanities receive 0.13% of the federal total.”

These economic woes have been exacerbated by the fact that, especially after the Great Recession, students and parents have placed even more emphasis on “practical” college majors that offered a strong “return on investment.” Unable to compete with STEM or business-adjacent fields in the hallowed category of “Making a Ton of Money After Graduation,” the humanities gradually settled into a sales pitch to justify the expense of a degree: The English or history or philosophy department will help turn you into A Good Person. The ROI of a humanities degree was not economic, the thinking went, but political and moral. This was the context in which Elizabeth Alexander became Mellon’s president, in 2018.

Alexander’s pedigree made her a natural choice to lead the foundation. Born to Clifford L. Alexander Jr.—a Kennedy-administration official and the first Black secretary of the Army—and Adele Logan Alexander, a noted historian, she has spent a lifetime in elite institutions: Sidwell Friends. Yale. Boston University to study poetry with Derek Walcott. A Ph.D. in English from the University of Pennsylvania. A stint as an assistant professor at the University of Chicago. Followed by Smith. Followed by Yale (again). Followed by reciting her own poetry at Barack Obama’s first inauguration (“In today’s sharp sparkle, this winter air, / any thing can be made, any sentence begun. / On the brink, on the brim, on the cusp”). A stint as the Ford Foundation’s director of creativity and (ironically) free expression after that. Then Mellon.

Benjamin Schmidt: The humanities are in crisis

Alexander reportedly said in her interviews for the role that she planned to pivot the foundation’s attention to social-justice work, and she has kept her word. “There won’t be a penny that is going out the door that is not contributing to a more fair, more just, more beautiful society,” she declared in 2020.

To better understand the impact of Mellon’s agenda, I spoke with about 20 people who have had close dealings with the foundation. Some are professors; others are senior administrators who act as middlemen between their institution and donors and grant-makers. Several have been interacting with Mellon for a decade or more. They are employed at a variety of institutions, some public and some private, some generously endowed and others more threadbare. Most agreed to speak with me on the condition of anonymity. “I don’t think I want to go on the record,” a historian told me, “because Mellon is very powerful.”

One scholar described a relationship with Mellon that was as personal as it was professional. Decades ago, a Mellon fellowship paid for her to pursue a Ph.D. in 19th-century literature. “It changed my life,” she said. Later, when she was a new faculty member, a second Mellon grant enabled her to conduct research for her first book. The sort of work she did was traditional, historically minded, and apolitical, and she noted that she benefited from Mellon’s old approach to funding, in which “classic subjects were the norm.”

When I asked her how she felt about the organization’s turn toward social-justice work, she seemed ambivalent. She was open to Mellon’s new direction, but she also worried that the focus on progressive issues in academia had become “all-encompassing” and made the humanities a target of political criticism. I heard similar concerns from others.

A director responsible for grant administration at a small college said that humanities professors at her institution were distraught by Mellon’s new focus, which they saw as coming at the expense of areas of inquiry without obvious social-justice relevance. She characterized some of the reactions she’s heard: “Are you saying that it’s no longer valuable that I’m doing research on these texts from this time to see what I can learn about them? Is that not valuable anymore to anyone?”

This director described a difficult conversation with a religious-studies professor who was excited about a new project. She told him that it had little chance of getting funding from Mellon, because, as the director put it, “it was purely research. It had nothing to do with community partners or racial justice.” She tried to let him down gently, but said it was like watching the air go out of a balloon.

I became a tenure-track humanities professor in 2020, and I remember Mellon’s shift being greeted with some quiet concern that funding in more traditional research areas would lapse. I saw an example of this several years ago, when a senior academic I know well was seeking research funding for a book project that had nothing to do with social justice. Forced to choose between forgoing an opportunity to win a badly needed grant and twisting his research into a social-justice pretzel, he opted for the pretzel, amending the project to focus on race in an unsuccessful bid to win the foundation’s favor. Another humanities academic I spoke with confessed that, like my acquaintance, he had reimagined his work to focus more squarely on race; he did win a grant. I suspect that this may not be a rare occurrence.

One professor told me that, after he and his colleagues were turned down for various Mellon grants, a representative from the foundation began helping them draft a new proposal that would more likely be approved. “We were pretty tightly coached,” he said. “It certainly felt like we were being told, ‘Do this, this, and this in order for it to work on our end.’ ” Ultimately, he said, a fair amount of social-justice jargon was tacked on to the proposal, “in consultation with, or perhaps at the insistence of, the representative from Mellon.” His team won the grant. (Asked to comment on this, Mellon responded in a statement to The Atlantic, “We firmly support intellectual and academic freedom.” The foundation also said that, “as a private charitable organization, we exercise our freedom to support projects in alignment with our mission.”)

It is hard to see how an incentive structure that pushes scholars to fake or fudge an interest in social justice helps produce a more just academy. If anything, this seems likely to further entrench higher education’s tendency to confuse performative preening with real societal improvement. It also effaces the difference between serious scholarship on race, colonialism, or gender and gaseous buzzword-mongering.

When I was pursuing a Ph.D. in comparative literature in the 2010s, Mellon’s Dissertation Completion Fellowship program provided essential financial support to graduate students finishing their studies. There were no substantive constraints on the subject areas that could be covered; awardees worked on topics as diverse as 15th-century women’s devotional literature, Descartes’ conception of infinity, temporal clauses in linguistics, and hacking culture in contemporary Mexico. In 2022, however, that program was eliminated.

Mellon’s newer Dissertation Innovation Fellowship focuses on “supporting scholars who can build a more diverse, inclusive, and equitable academy.” The guidelines list “thoughtful engagement with communities that are historically underrepresented in higher education” as one of the primary criteria used to evaluate the strength of an application; by my count, all 45 of the 2025 awardees work on issues of identity or social or environmental justice. The fellowship is explicitly “designed to intervene” before a student’s research direction is finalized, which means, in practice, that Mellon can steer students who are just beginning to settle on a dissertation topic toward its preferred areas of inquiry.

In an alternate universe, with ample humanities funding for less politically salient work, one might see the fellowship program as an unalloyed good, providing support to projects that have not historically enjoyed sufficient resources. But in the funding landscape that actually exists, the reality is zero-sum. Every dollar that Mellon spends on this work is a dollar that it cannot spend on “non-applied” humanities research—in other words, scholarship for scholarship’s sake that has no aim except to expand knowledge.

Some may argue that this trade-off is prudent. From my perspective, however, the gift of the humanities is that they liberate us from the tyranny of present opinion and the views of those in power—including those who sit atop multibillion-dollar philanthropies. A version of the humanities that sees its chief mandate as finding solutions to pragmatic problems doesn’t ultimately seem all that different from the accounting department or business school.

I asked multiple times over the course of several months for an interview with Elizabeth Alexander, but through a spokesperson she refused to talk with me, a decision that highlights a broader set of problems within elite academic culture: a disinclination to be accountable to laypeople. A sense that private institutions, regardless of how much they influence the public, are entitled to push whatever ideologies they want. And a belief that it is perfectly natural for higher education to have a liberal slant because everything good and decent has a liberal slant. (Alexander sent along a handful of comments through a spokesperson shortly before this issue went to press. “At Mellon, grantmaking is guided not by ideology,” she wrote, “but by the powerful ideal that the rich fabric of America’s cultural and intellectual contributions must be broadened to convey the full scale of our nation’s histories, surface new ideas, and challenge long-held assumptions.”)

Alexander’s appointment to Mellon also speaks to another trend I’ve observed within wealthy liberal institutions, in which people of color from unusually privileged backgrounds are anointed as standard-bearers for a radical cultural worldview that many working-class minorities do not share—even as the former are ostensibly intended to “represent” the latter. Of course, it is not Alexander’s fault that she is the daughter of illustrious parents. Or that she is a descendant of the Logan family, a famous lineage of highly educated Black elites whose influence stretches back to the 19th century. Or that she is a longtime personal friend of the Obamas, or that her brother served on Barack Obama’s transition team ahead of his first inauguration, where she read her poem “Praise Song for the Day.”

But these facts are also not irrelevant to her elevation at Mellon, by whom she was paid $1.53 million in direct compensation and $672,785 in other compensation in 2024. I have no objection to poets making rookie-NFL-player money—though her 2024 salary is the equivalent of about 16 average tenure-track professors’ annual pay—but it does make all of the social-justice posturing a little more comical.

Various people I spoke with said that Alexander has remade Mellon according to her values, pushing the foundation to become ever more devoted to a narrow conception of progress. A senior official in charge of grant administration at a small private college noted that Alexander has brought a new style of leadership to the foundation, wielding more top-down bureaucratic control and pushing more sweeping changes than past presidents have. Others agreed with this characterization.

This is a significant departure from the nonprofit’s past approach to managing relationships with the institutions it funds, in which Mellon officials would try to balance a college’s or university’s particular—often less political—needs against its own ideological priorities. In 2023, the foundation allotted $1 million to “deepen the ongoing conversation in Transgender Studies” at the University of Kansas—specifically, to “establish a cohort model for scholar-activists” and “create a more trans-liberatory local and regional landscape.” Another $1 million went to classics professors at Princeton and Brown for a project called Racing the Classics, devoted to encouraging early-career scholars to implement “critical race approaches and curricular experimentation.” In 2024, Loyola Marymount University won a three-year, $431,000 grant to “bridge AI practitioners and disability justice scholars and activists.” And MIT received $500,000 for something called Engaging With Music and Musicking Through Engagement, aimed at correcting its curriculum’s “Western European biases.”

Whether or not these programs and projects are serious, significant contributions to humanities scholarship and teaching is somewhat beside the point. Even assuming that the undertakings are all worthwhile, the volume of financial support directed at the “scholar activism” model, at a moment when other, more time-honored varieties of humanities education are withering away, is cause for concern. Majors such as English, philosophy, and theater belong to an ever-shrinking number of fields that are not squarely devoted to job-market preparation or “skill building,” fields that aspire to do something loftier than clearing the brush from students’ career pathways. The merging of humanistic work and activism represents a surrender to the utilitarian logic that measures the worth of knowledge by its direct impact on “the real world.”

Mellon itself disputes this notion. A spokesperson connected me with Phillip Brian Harper, the foundation’s program director for higher learning, who said, “Social justice is a fuzzy term that people invest with a range of different meanings that don’t necessarily apply to the way we do grant-making.” He argued that Mellon’s focus is on emerging fields that have not received grant money in the past, regardless of their particular political bent. “Now, it does so happen that a lot of historically underfunded fields entail scholarly work that itself has social-justice objectives in mind,” he conceded. “But that’s a separate thing.”

This is quite obviously nonsense. Harper himself published an opinion article in 2022 titled “Studying Humanities Can Prepare the Next Generation of Social Justice Leaders.” “The country’s next generation of leaders is pushing for racial equity, economic equality, disability justice and gender and sexual liberation,” he wrote. “To succeed they will need the observational and analytical skills that can be developed by studying ideas, historical events, aesthetic works and cultural practices”—in other words, by studying the humanities. In this context, it seems clear that “social justice work” does indeed mean “activism.”

Some of Mellon’s recent grants have the potential to remake liberal-arts education entirely. The foundation’s Humanities for All Times project, launched in 2021, is premised on the notion that “today’s humanities undergrads are tomorrow’s social justice leaders.” Over the past several years, the foundation has regularly invited small cohorts of liberal-arts colleges to apply for grants—up to $1.5 million each—that support social-justice-aligned curricular development. The application guidelines note that “submissions oriented toward revising an institution’s entire general education program are especially welcome.” That is to say, college administrators and academics are encouraged to submit proposals for projects that would overhaul their core requirements for all students, in every major, in the service of a progressive political program.

A 2021 Humanities for All Times grant proposal from Colorado College reads like conservative satire: “We recognize the myriad ways in which white supremacy has shaped our institution and have been taking steps to work our way out of its grip,” it confesses near the beginning. The application promises the introduction of “at least 50 new and relevant courses” to “empower students to be changemakers.” Mellon gave the college $1 million to carry out this work.

In the summer of 2023, Colorado College hosted a conference based on this prompt: “How do the humanities contribute to anti-oppressive work, and how can humanities methods—from inquiry and critique to creative production and performance—dismantle systems of oppression, create and sustain community and solidarity, and advance liberation?” It does not seem to occur to those asking such questions that the humanities may not be especially well equipped to “dismantle systems of oppression.” Nor do they seem to consider that what might in fact be most valuable about fields like English, history, and philosophy is that they aspire to stand above the flotsam and jetsam of our immediate circumstances, and instead set their sights on what the classicist Leo Strauss called the “permanent problems” that have troubled human beings from time immemorial.

As easy as it is to point to cartoonishly progressive things that Mellon has funded, it is also true that, under Alexander, the foundation deserves credit for working to create a more economically just landscape within higher education. Before Alexander’s arrival, Mellon tended to disburse lavish funding to institutions that were already rich. Now, as part of Mellon’s commitment to equity, it is making a conscious effort to provide funding to public and less selective institutions. It has also increased funding for university-led prison education programs.

In 2024, Mellon spent $25 million to fund paid internships for undergraduate humanities students at five public colleges and universities. These internships can be in any field, with no particular ideological or social-justice strings attached. Renata Miller, a dean at the City College of New York, was effusive about the $5 million internship grant it received. She told me that the money helps provide support for child care, commuting costs, and other obstacles that can prevent working-class students from taking internships.

Elizabeth Spiller, the arts-and-sciences dean at the University of South Florida, wrote in a press release that she was stunned her school was even asked to apply for a similar program. USF ultimately received a $4.8 million grant, which can fund up to 900 students a year to take otherwise-unpaid internships.

Ironically, programs like this illustrate the bind in which both Mellon and the humanities writ large find themselves. It is hard to argue that the tens of millions of dollars that Mellon is putting toward internships for working-class kids at public colleges and universities would be better spent financing dusty archival research on 16th-century France. But this calculus also says something about the deeper structural problems of a model that pits various social goods—programs for humanities undergrads, resources for Ph.D. students, traditional humanities research, support for emerging fields and endowment-poor universities—against one another.

Read: If the University of Chicago won’t defend the humanities, who will?

When I asked Harper how he feels about Mellon’s role as the country’s preeminent humanities funder, and the difficult choices that necessitates, he took issue with my characterization. “Serving in this way, that is not Mellon’s role,” he said. “Given the situation that we’re in, Mellon is accidentally in the position of being the primary large funder.” His point was that safeguarding the health of the humanities was not the foundation’s raison d’être, even if the decisions it makes affect that health directly.

This distinction helps shed light on the implicit question that underlies the entire debate about Mellon’s new focus. Namely, should the foundation be blamed for damaging the humanities by directing nearly half a billion dollars a year toward a social-justice-ified vision of American arts and letters, or should universities, the federal government, and other donors instead be blamed for not providing a healthier funding ecosystem to begin with, to say nothing of the anti-woke conservative billionaires who complain endlessly about the humanities and champion “the classics” without ever spending a single penny to support them?

“The sector needs to be taken by the collar and shaken very hard until resources that are adequate to the support of humanities doctoral students are jarred loose from higher-ed institutions themselves,” Harper said, growing animated. “The role of the Mellon Foundation is to catalyze that sort of change. It’s not to serve in perpetuity as the piggy bank for research.” Mellon, he said, was never supposed to be a panacea for the humanities.

But with the academic humanities in their death throes, Harper’s distinction between role and position may be largely beside the point. No, it is not Mellon’s job to be the humanities’ piggy bank. Yes, Mellon is the humanities’ piggy bank. The resulting situation is dismal, and the Trump administration’s funding cuts will only make things worse.

Yet the president’s attacks on the National Endowment for the Humanities and the canceling of federal humanities grants might not have the effect that conservatives hope for. Howard Husock, a fellow at the American Enterprise Institute, recently warned that gutting the NEH would simply expand the power vacuum for Mellon, and is likely to give the progressive organization even more sway over American arts and letters.

Some will no doubt feel that it is irresponsible to criticize Mellon at a moment when higher education is under assault from the federal government. That point of view is fair enough, I suppose, though I think it’s also misguided. The humanities’ problems began well before Donald Trump ever ran for office. The fantasy that we can put off these uncomfortable discussions—about Mellon, about the humanities, about the relationship between scholarship and activism—until some imagined time when higher education is in a healthier place strikes me as just that: a fantasy.

Read: American higher ed never figured out its purpose

The humanities are in the mess they’re in because of federal budget cuts, and because of administrators who care more about the football team than about William Faulkner, and because of the toxic pragmatism of an American culture that has a hard time valuing anything that is not immediately, aggressively useful. But the humanities are also in this mess because those of us who care about them have often preferred hunkering down in a defensive crouch, rattling our donation jars and begging for scraps, to serious soul-searching about the real purpose of American arts and letters. We have been too reluctant, or perhaps too ashamed, to consider whether we have betrayed the humanities’ very spirit in our mad, ever more futile quest to keep them financially solvent.

I often wonder what, exactly, we think we’re saving. Are the humanities as they are currently instantiated in the American university system actually worth the Faustian bargains we are forced to make to keep them? At their best, the humanities remind us that our problems are petty not because they are small, but because they are born of the same questions that have plagued all humans since our species lowered itself down from the trees and traded monkey chatter for wisdom-seeking: How to live virtuously? How to exist together peaceably? How to die with grace?

The humanities predate the modern university by millennia, and they will surely outlast it. But a higher-education system that can no longer keep them safe from the vulgarities of the market, the siren song of cultural warfare, or the decidedly sublunary work of furnishing political propaganda is one that has not just failed the humanities, but failed entirely.

* Lead image sources: Eric Gaba / Wikimedia; University of Michigan Library Online Exhibits; National Photo Company Collection / Library of Congress; EvgeniyBobrov / Adobe Stock; Martin Juen / Getty; Jonas / Adobe Stock

† Image sources: Jemal Countess / Getty; Harold M. Lambert / Getty; EvgeniyBobrov / Adobe Stock; dule964 / Adobe Stock; National Endowment for the Humanities; University of Michigan Library Online Exhibits

This article appears in the March 2026 print edition with the headline “The Plot Against the Humanities.”</div>
        </div>
        
        <div class="card" onclick="openModal('content-21')">
            <div class="source">The Atlantic</div>
            <div class="title">Why the U.S. Hasn’t Yet Struck Iran</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-21" style="display:none;">
            <h2>Why the U.S. Hasn’t Yet Struck Iran</h2>
            <p><strong>The Atlantic | 2026-02-12</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/national-security/2026/02/iran-trump-war-us-israel-netanyahu/685970/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Late last month, President Trump took to social media to issue a not-at-all-veiled threat to the theocratic rulers of Iran: Come to the negotiating table and agree to “NO NUCLEAR WEAPONS,” or risk the same type of swift and violent response that plucked Venezuelan President Nicolás Maduro and his wife from Caracas in the middle of the night. “Time is running out, it is truly of the essence!”

Two weeks later, it suddenly isn’t. There is now “no rush” to make a deal, Trump said on Friday while speaking to reporters. Usually, threats of war come after talks fail, not before they have even started. But this time, the United States and Iran appear to have reset the clock just as the administration was at its most bellicose. So what happened?

The Trump administration had been considering its military options, which ranged from targeting leaders to hitting Iran’s nuclear program. But officials discovered that the U.S. could not conduct a major offensive as quickly as they had hoped without real risks to American forces, support from allies, and regional stability, two U.S. officials told us. Even though Trump has boasted about a “massive Armada” sprinting toward Iran, the U.S. does not have enough ships and planes in the region to conduct weeks of strikes, the officials said. It also does not have clear targets: The White House has yet to outline to military commanders what it would want to achieve through strikes, the officials said, suggesting that the use of force is not imminent.

Instead, the U.S. held direct talks with Iran over the weekend for the first time since last year. Admiral Brad Cooper, the top commander for Central Command, which is responsible for operations in the Middle East, was among the American officials present for the negotiations in Oman. The discussions allowed Iran to gauge U.S. interest in reaching a deal, a spokesperson for the country’s foreign ministry said. The Trump administration publicly expressed optimism. But one official involved told us that the United States walked away with questions about whether Iran was “serious about negotiations or simply pursuing this course to buy additional time.”

Beyond a reprieve from military action, Iran wants relief from economic sanctions, but without constraints on its regional militias and giving up its right to enrich uranium and its arsenal of ballistic missiles. Trump wants to eliminate any future potential for an Iranian nuclear facility that he said was “obliterated” during strikes in June, but that could still be revived.

The biggest unknown looming over the talks is how much patience the president has for negotiating before turning to strikes. Trump said on Tuesday that the U.S. will “have to do something very tough” if a deal is not reached soon.

Trump’s latest threats against Iran began last month, near the height of protests inside the country, when it appeared that the regime could fall and U.S. military strikes could finish it off. Since then, the Iranian government has cracked down on protesters, killing thousands and arresting political figures who have promoted reforms. The country is the weakest it has been in decades: Its economy is in a downward spiral, and its proxies, particularly in Gaza, Lebanon, and Syria, are stretched thin, making asserting power across the region more difficult.

But just because a regime is fragile politically doesn’t mean it is weak militarily. A strike against Iran would be a daunting, complex operation for the U.S. military, defense officials told us. The brutality with which the Iranian government quashed protests suggests that it is not in immediate danger of falling, and the nation’s security apparatus (notably its Islamic Revolutionary Guard Corps) did not defect or fracture during the uprisings. The country has long-range ballistic missiles that can reach every corner of the Middle East and hundreds of cruise missiles and drones that could easily strike countries in the Gulf. These assets remain functional after the U.S. bombed the Fordow nuclear site and Israel damaged air defenses over the summer.

Read: What are the chances Trump attacks Iran?

An operation aimed at regime change or the weakening of Iran’s nuclear program would be “highly complex because of Iran’s capabilities,” one official told us. Iran would respond, the official said, potentially striking U.S. forces and allies.

The operation would also be difficult to sustain. The “Armada” that Trump said is moving with “great power, enthusiasm, and purpose” is insufficient to mount a major weekslong offensive, the officials told us, and does not include the needed air defenses. The United States has enough military assets in the region to conduct a narrow mission over several days—one that could, for instance, involve targeted strikes on key Iranian leaders or military assets. The Pentagon referred questions about the need for more military firepower in the region to the White House. The White House reiterated Trump’s view that the Iranian regime must abandon its nuclear program and “make a deal.”

The U.S. strikes against Iran over the summer—a more limited operation than what Trump is now signaling—originated from two aircraft carriers in the region. A larger offensive would require at least two carriers that could bring in enough planes to, for example, strike many of Iran’s ballistic-missile launchers. (Only one carrier strike group, the USS Abraham Lincoln, is currently in the region.) On Tuesday, Trump told Axios that he was considering deploying a second carrier. Doing so would require one of the Navy’s existing carrier crews to cut their preparation or rest time. Getting the carrier there—the USS George H. W. Bush is next in line—would take at least two weeks.

If Iran’s ultimate goal is to preserve its regime, compromises on its nuclear program and regional proxies will be needed, defense officials told us. Trump met with Israeli Prime Minister Benjamin Netanyahu for more than two hours yesterday. Netanyahu has been clear that he worries that any negotiation will give Iran too much leeway. “There was nothing definitive reached other than I insisted that negotiations with Iran continue to see whether or not a Deal can be consummated,” Trump posted on Truth Social after the meeting with Netanyahu.

Read: The U.S. military can’t do everything at once

Israel would likely support the U.S. in targeting Iran, officials told us, but the rest of the region is eager to avoid hostilities. Officials from Saudi Arabia and the United Arab Emirates—neither of which is at all sympathetic to Iran—told administration officials that they do not want to be involved in and would not support a regional conflict, according to Arab and U.S. officials. Countries hosting U.S. military bases—specifically Kuwait, Qatar, and Bahrain—are particularly vulnerable because Iran has warned that it could retaliate against those bases. Any military action could shut down the Strait of Hormuz, a transit point for roughly 20 percent of the world’s oil exports. Some countries fear that military action could rattle investors’ confidence in a region that relies heavily on direct foreign investment. Gulf allies also fear catastrophic outcomes, such as radiation exposure resulting from strikes on nuclear facilities or cyberattacks on critical infrastructure. Iran’s opposition, meanwhile, is disorganized and has little common vision for the country’s future beyond a desire to get rid of the clerics.

Without regional support, the United States risks entering into a war without a coalition that would reinforce its military might. But there’s also a risk in continuing to delay. Vali Nasr, a professor of international affairs and Middle East studies at the Johns Hopkins School of Advanced International Studies, told us that by putting military action on the table and then not seeing it through, “Trump has instead alerted Iran of potential war and given them time to prepare.” Every day that U.S. forces are in the region without acting, they give Iran more of a chance to get ready.</div>
        </div>
        
        <div class="card" onclick="openModal('content-22')">
            <div class="source">The Atlantic</div>
            <div class="title">Iran Wants Him Arrested. He’s Going Back Anyway.</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-22" style="display:none;">
            <h2>Iran Wants Him Arrested. He’s Going Back Anyway.</h2>
            <p><strong>The Atlantic | 2026-02-12</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/podcasts/2026/02/jafar-panahi-iran-oscars/685963/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Subscribe here: Apple Podcasts | Spotify | YouTube | Overcast | Pocket Casts

Late in Jafar Panahi’s Oscar-nominated film, It Was Just an Accident, comes a confrontation. An Iranian woman looks into the face of a sadistic prison official and taunts, “You think this country belongs to you?” Panahi, who wrote and directed the film, describes it as an artificial fast-forward, set in a time when the violence has died down, the prisoners have been released, life has returned to normal, and the urgent open question is to forgive or to take revenge.

Of course, that time still feels far away. The Iranian regime has recently killed thousands of protesters and sentenced even moderate dissenters to long prison sentences. Panahi’s co-writer Mehdi Mahmoudian was recently jailed after signing a letter objecting to the crackdowns. Panahi, who also signed the letter and has been touring the United States to promote his film, has been sentenced to one year in prison in absentia. His lawyer has said they plan to appeal the sentence. Still, he insists that as soon as Oscar season is over, he will head back home.

Like many of Panahi’s other films, this one is improbably funny. The action mostly consists of four misfits driving around Tehran fighting about what to do with the man they’ve kidnapped, someone they believe to be their torturer. Also like his other films, he shot it in secret, with limited takes, natural lighting, and locations chosen to evade the authorities (nearly a third of the film is shot from inside a van). Panahi has been ducking censors long enough that he seems to have cracked the code of how to make rich, sarcastic, brutally critical movies despite the regime’s relentless repression. And in the case of It Was Just an Accident, he made a movie that offers empathy even to the torturer.

In this episode of Radio Atlantic, we talk to Panahi about his characters, his film’s enigmatic ending, and what he’s hearing from friends in Iran. Panahi was in the U.S. when American protesters were shot and killed by federal agents in Minneapolis, and we talk about parallels he sees between the U.S. and Iran.

The following is a transcript of the episode:

Hanna Rosin: Iranian director Jafar Panahi’s latest movie, It Was Just an Accident, shot in secret in Tehran, is nominated for two Oscars. In it, a group of misfits roam around in a white van trying to figure out what to do with the person they just kidnapped.

Rosin: One of the women is wearing a wedding dress the whole time. One of the men is a hothead, perpetually at 11. They bicker about what to do with their victim, who is sedated and locked in a box.

Rosin: It’s the setup for a caper, and lots of ridiculous things do happen. But at its core, the movie is driving towards the country’s real open wound.

The man locked in the box is someone they all suspect to have been their torturer in prison, a sadistic agent of the regime named Eghbal, who ruined each of their lives in distinct ways.

The dig at the Iranian regime is not subtle.

[Music plays over clip from It Was Just an Accident]

Rosin: I’m Hanna Rosin. This is Radio Atlantic. Today, we’re talking to Panahi. He’s in the U.S. in the lead-up to the Oscars, and he joins us at a moment when Iran is seeing some of the largest protests in the country’s history, met by some of the most violent government crackdowns. Estimates of protesters killed range from the thousands to the tens of thousands.

In recent days, the government has started arresting even moderates and extended the sentence of an activist and Nobel Peace Prize winner to 17 years in prison. Panahi’s co-writer was recently arrested, and Panahi himself has been sentenced to one year in prison in absentia. His lawyer has said they intend to appeal the sentence.

It seems like once again Iran, still potentially a nuclear power, has the world on edge.

Rosin: Does he like to be called by his, like—Jafar or Panahi or …?

Rosin: Okay. (Laughs.) All right, well, Jafar—

Rosin: We talked to Panahi about all of this and his film It Was Just an Accident earlier this week, through his interpreter, Sheida Dayani.

Rosin: But what did you want an audience, either Iranian or international, to understand or be thinking about when they’re watching this movie?

Panahi: Usually, these types of films are made after the fall, or the change of a regime, because then, that’s when people go back to see what happened, and based on their understanding of the past, then they make a film. And it’s also very important for people to make films in a secure fashion. But I wanted to make this film now because I wanted to have the audience think about the future and I wanted to prepare the audience about what is about to come.

Panahi: To me, it was very important to raise this question to the audience about whether the cycle of violence going to continue or if we can be hopeful that, at some point, it’s going to end.

News anchor (from BBC News): Shopkeepers and market stallholders began protesting against rocketing food prices on Sunday, and today, they were joined by university students demanding political change—

Rosin: Speaking of the cycle of violence, where were you when you heard about the protests in late December in Iran?

Rosin: Who told you about them, and what were you hearing from friends and family?

Panahi: I have been outside Iran for some time because of the Oscar campaign for this film, but as I have said before, as soon as the campaign ends, I will return to Iran.

Panahi: When the protests broke, I was in Paris, and when they shut down the internet—

News anchor (from CNN): Iran is in a near-total internet blackout amid widespread anti-government protests—

Panahi: —my friends and I issued a statement and said, When they do shut down the internet, it means that they’re going to commit a big massacre.

News anchor (from BBC News): One human-rights group based in the U.S. has now confirmed the killing of over 6,000 people. It’s also investigating 17,000 more deaths—

Panahi: Of course, with the complete telecommunications blackout, I also lost touch with my family members. My son, my sisters and brothers all live there, and I was not in touch with them.

After the internet came back—I don’t remember how long it took—I was also in touch with close-by family members. My immediate family members are okay, but distant family members are not.

Rosin: Your co-writer Mehdi Mahmoudian was just recently arrested. How did you hear about that?

Panahi: When Mehdi got arrested, it was when the internet was more or less back, and we were sending messages to each other. I sent him a message around 3:30 a.m. Paris time, and the message was not seen, and it was not delivered either. And I waited until noon of the next day, and it still was not seen, and that’s when I was suspicious that something has happened, so I started contacting my friends. And it was around 4 or 5 p.m. that I heard through BBC Persian that he has been arrested.

It seems that they arrested Mehdi because of a statement that we co-signed together with other activists, human-right lawyers, and, in total, 17 of us, among whom we have people who have won the Nobel Peace Prize; we have people who have won the Sakharov Prize. And these were all acknowledged and known Iranians inside Iran, and some of them were outside.

After that statement, they arrested Mehdi and a few other people, and it’s a statement that puts the fault and the blame of the massacre on [Iranian supreme leader] Mr. [Ali] Khamenei.

Rosin: And when someone is arrested, do you know what happened to him? Does your imagination fill in the blanks? Sort of what happens next when a friend is arrested?

Dayani: Does he know, meaning can he imagine, or does he have information?

Rosin: Well, I guess, does he have information? And if he does not, does his imagination fill in the blanks?

Panahi: They usually never announce in the beginning who has taken these people, where they have been taken to, and for what reason. We have to wait for the person who has been arrested to contact the family members.

Mehdi was able to contact his family after two or three days, but only for one minute. And he had only one minute to say that he is alive, and he is okay, and he has been arrested, and then the phone got shut off.

Now we know that he is in Nowshahr city. And he is kept in a cell of 17 by 17 meters with 30 other prisoners, none of whom are political prisoners—they have crimes of drugs, drug trafficking, and murder.

Rosin: Oof. I’m asking because this movie is so much about what happens to people after they get arrested.

Panahi: At different times, prisoners have been treated differently, but of course, with every movement, when people take to the streets, with every protest, things become much harder inside the prisons. And especially this time, with the number of dead and wounded and arrested, they have become extremely harsh inside.

Panahi: This time, the protests were peaceful, but then the trolls of the regime penetrated the protests, and they started committing acts of violence in order to make the protests violent. And that gave the agents of the regime, and the regime itself, an excuse to crack down violently and commit the atrocities that it did.

When the protests first began, because they were peaceful, family members went with their children, even babies in strollers, because there was not going to be anything violent happening. But the government could not even tolerate that, and in about 10 hours, only 10 hours, within two days—the first day, four hours, and the second day, six hours—they started killing the protesters blindly, and the number of the dead has now risen to over several tens of thousands of people.

Rosin: Is there anyone that you’re especially worried about?

Panahi: Now you cannot think about individuals. You cannot think about specific people, because the numbers are so high and the pain is so strong that people feel that they’re each other’s family members. So when one person is dead, one person is killed, one person is made disappeared, everyone feels the pain, and everyone is in mourning.

Rosin: After the break, Jafar Panahi has a warning for America. And he breaks down the meaning of the end of his film.

Rosin: You haven’t been to the U.S. in 20 years or so. As an Iranian, what do you notice that’s different now?

Panahi: Well, in fact, the atmosphere here is also very different than what I had seen before. Sometimes I see signs speaking to the fact that here too things are becoming very difficult.

The U.S. is different. When the political atmosphere changes in this direction in the U.S., it will also be contagious in the rest of the world.

Rosin: What do you mean “contagious”? What do you mean?

Panahi: Whether we accept it or not, what happens in the world is affected by the great powers, including the U.S.

The more repressed the greater powers are, the more you see its effect in the other countries.

Panahi: It is as if it has been tested and then it’s decided that it is now the time for the world to move in this certain direction.

Rosin: I wanna make sure I understand what he’s saying so that I’m reading between the lines correctly. What he’s saying is sort of we’re moving in a more repressive direction and that can be a model for other countries?

Panahi: Not that they model themselves after the U.S., but that they get affected by it.

Rosin: Mm-hmm, mm-hmm. I mean, you’ve been on tour while the two American protesters were killed here by government forces. Two is not tens of thousands, but were you surprised? What were your thoughts when you heard that news?

Panahi: The killing of even one person anywhere in the world is too much.

As soon as this happens, you can be sure that there is a problem.

And that problem will grow, and one day, it will reach tens of thousands of people.

Rosin: I did not wanna hear that from an Iranian with experience. (Laughs.)

Panahi: This is what I’m talking about when I’m talking about signs. Because we have seen and experienced these signs, we know exactly what happens. We know exactly what’s coming at the end.

It is true that when it happens in certain countries, it’s going to affect the rest of the world more, but it doesn’t really matter where it happens. We, as people, have to stand against it.

With any kind of job, profession, work that we do—whether we’re an artist or filmmaker or writer or doesn’t matter what we do—if, in our own work, we cannot stand against repression, it’s going to get out of control.

Panahi: When they gave me a ban of not working for 20 years, I had two choices: Either I could just sit at home and do not work because they had told me not to work, or I had to look for solutions.

I remember back then, a lot of students would come to me and say that the situation is very difficult—they cannot work. And they were immersed in hopelessness.

I said to myself one day, Should I be like them and keep nagging and keep saying it’s not possible? Or should I think of a solution and do something?

There was a time that when I wanted to make a film, everything was in the hands of the government. It was not as easy. But now, with all the technological advances, you could even make a film on a cellphone camera.

Because the authorities had told me that I cannot make a film, my friend and I started making a film in my home, and we said, This is not a film.

Panahi: And then I thought to myself, What can I do if I cannot work in film? And I thought, There are a number of things, including driving, that I could do as a profession. But then, because I knew myself, I was sure that even if I start driving, I’m going to hide a camera somewhere in a taxi, and that’s exactly what happened: I hid a camera and started making the stories of my passengers, and that became the film Taxi.

Rosin: Hey, listeners, this is Hanna interrupting with a spoiler warning. If you remember, It Was Just an Accident is about a group of Iranians kidnapping a man they suspect to have been their interrogator and torturer in prison. My next question is about how the movie ends. If you wanna avoid hearing that, you can skip ahead four minutes.

Rosin (in interview): So I wanna ask about the end of this movie, It Was Just An Accident. It has a very hopeful moment, where it seems like everything’s going to go back to normal, and it also, the end of the movie, suggests that the cycles of violence may continue. Is that how you feel?

Panahi: Happiness and sorrow are part of everyday work, and this is also part of the realism sense of the film.

I consider myself a socially engaged filmmaker, and I try to speak about the realities of the society. So first, my audience has to believe the film, and it has to believe that it’s watching a semidocumentary. Omitting any of those elements can harm the sense of realism in the work.

The humor that you see in the film at some point was intentional, and I wanted the audience to move along quite comfortably throughout, at least up until the last 20 minutes of the film.

And then in the last 20 minutes, I intentionally took out the humor from the film.

Panahi: And I wanted the audience to hold its breath and to think about the film.

Panahi: Under any circumstances, hopefulness will help people. It will help human beings to continue to live.

When you hear the sound of the footstep at the end of the film, it first shocks you, and you think that the interrogator is here to arrest him.

Panahi: And then the sound of footsteps goes away, as if it starts getting further and further.  [Clip from It Was Just An Accident]

Panahi: So at some point, the audience can think that even the character of the interrogator could change.

The fact that the interrogator might have been moved, as little as it might be, is that point of hope and hopefulness that the cycle of violence could end at some point.

Rosin:  So that’s why you wanted to capture the humanity of the interrogator.

Panahi: These people like the interrogator may be very different people in their family settings. Their family members may not even know who they are and what kind of work they do. These people, to their family members, are fathers, they’re spouses, and they might look very different than what we see.

The problem is not with the individual. The problem is with the system, and it’s with the situation and the conditions.

If we put the blame on these little parts of a system, then we lose our way into understanding what the fault is actually and who is to blame and what is to blame.

Rosin: You have repeated that you are going back to Iran after award season, even though you’ve already been sentenced to a year in prison, even though you’ve been to prison before. Is that just because you can’t figure out how to live anywhere else or just don’t feel comfortable anywhere else?

Panahi: At the end of the day, I want to have the sense of living, and I know it’s in a certain place that I can have a sense of living. I could come here in the U.S. and make a commercial film and make a film that could make a lot of money. But then, when it’s me and myself in my solitude, I would ask myself if I am embarrassed by making that film.

This is not to say that commercial films are bad—not at all. The question is the calling of the director, and once a director makes up their mind, they have to be truthful to that decision.

I can easily say that, in my own solitude, I have not been regretting any of the films that I have made.

Rosin: This is a last question. This moment is so serious and dangerous around the world. Is there anything specific or even small that makes you feel like you’re living, as you said, or brings you joy that you hold on to?

Was your question only about what gives him joy, or was there another part to it?

Rosin: I hate that question, the joy question.

Rosin: Because he said “living,” I’m trying to pull out a thread of how he continues to pull through, you know what it is that he hangs on to, that has him—joy is a little much.

Dayani: Right, right, right, right, right.

Rosin: It’s not quite the right word. (Laughs.)

Dayani: No, but I got it. But this helps.

Panahi: Because I have made my choice about what type of filmmaker I want to be and who I want to be, I will find a way around it, no matter what.

I’m not a captive of moments or days, because I see a greater future. I see from above.

Rosin: Jafar, Sheida, thank you so much for talking to us and joining us today.

Rosin: This episode of Radio Atlantic was produced by Jinae West. It was edited by Kevin Townsend. Rob Smierciak engineered and provided original music. Sam Fentress fact-checked. Claudine Ebeid is the executive producer of Atlantic audio, and Andrea Valdez is our managing editor.

Listeners, if you enjoy the show, you can support our work and the work of all Atlantic journalists when you subscribe to The Atlantic at TheAtlantic.com/Listener.

I’m Hanna Rosin. Thank you for listening.</div>
        </div>
        
        <div class="card" onclick="openModal('content-23')">
            <div class="source">The Atlantic</div>
            <div class="title">The Epstein Emails Show How the Powerful Talk About Race</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-23" style="display:none;">
            <h2>The Epstein Emails Show How the Powerful Talk About Race</h2>
            <p><strong>The Atlantic | 2026-02-12</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/politics/2026/02/epstein-race-science-watson-pinker-chomsky-musk/685965/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">In February 2016, after exchanging email pleasantries with the left-wing public intellectual Noam Chomsky and extending an invitation to his private island, Jeffrey Epstein recommended an article. “On a different note, you have encouraged me to look at data, no holds barred,” Epstein wrote before linking to “Race and IQ: Genes That Predict Racial Intelligence Differences” from the Right Stuff, an openly white-supremacist website and a pioneer of the online alt-right. The article argued that different races have differing levels of intelligence and that there is a genetic basis for the disparity.

The exchange was included in the Department of Justice’s latest public release of the Epstein files and is one of the clearest examples of the disgraced financier’s interest in “race science,” the pseudoscientific practice of ascribing racial inequities to genetics. It is a way of thinking that has been refuted on multiple levels. IQ is a complex trait that results from a series of factors—many of them cultural and circumstantial—that are not neatly reduced to a specific gene or set of genes. Even if it weren’t, the consensus among geneticists, biologists, and anthropologists is that race isn’t a biological phenomenon. Race-science proponents tend to ignore all of this, as well as any other relevant context, and use correlations between race and IQ (and also things such as race and criminality) as evidence that racial stereotypes are in fact justified.

None of this mattered to Epstein, who recurrently expressed his interest in race science beyond this 2016 correspondence. The tranche of Epstein files also shows that in 2018, he repeatedly tried to get in contact with Charles Murray, a political scientist whose 1994 book, The Bell Curve, is one of the best-known texts to posit a relationship between intelligence and race. Epstein didn’t specify why he was trying to connect with Murray, but he claimed that they had met previously. (Murray told me over email that he had never received an email from Epstein and that it was possible that they’d met in passing at a conference reception at some point. If this ever happened, though, Murray had no memory of it, he said.)

Promoting contemptible perspectives on race is probably nowhere near the most depraved things Epstein did; he was, after all, a registered sex offender charged with child trafficking. But Epstein’s views are notable given his long-standing influence on some of the most powerful and influential Americans. His conversations from a decade ago provide clues as to how race science was picked out of the boneyard of history and reanimated into a force that’s influencing U.S. politics right now.

Epstein received Murray’s email address from his ideological fellow traveler James Watson, the late Nobel Prize–winning geneticist who was stripped of his titles in 2019 after he doubled down on comments he’d made to a British newspaper in 2007 about how he was “inherently gloomy about the prospect of Africa” because “all our social policies are based on the fact that their intelligence is the same as ours—whereas all the testing says not really.” He told the paper that he wished that all races were equal but that “people who have to deal with Black employees find this not true.”

Epstein liked to collect relationships with high-profile academics, but the emails suggest that he may have been drawn to Watson specifically because of his ideology. In his 2016 exchange with Chomsky, Epstein appears to endorse the perspective that improving the world “might require accepting some uncomfortable facts” about race and intelligence. Chomsky, who sustained his association with Epstein even after accusations that the financier had sexually abused children became well known, disagreed with Epstein on race science in their email exchange. (He did not respond to a request for comment.) Epstein references Watson in other emails, and he and Watson appear to have met several times.

The same year that Epstein tried to put Chomsky onto pseudoscientific racism, he was having similar discussions with Joscha Bach, an AI researcher. In one exchange, Bach told Epstein that Black children in the United States “have slower cognitive development” and “are slower at learning high-level concepts.” In another email to Epstein, Bach wrote that “given average brain size difference” between men and women, “the small difference in average IQ is surprising.”

Read: The far right is becoming obsessed with race and IQ

Bach appears to have since changed his mind. In a recent Substack post explaining his emails with Epstein, Bach claimed that he has never said “that people of different races have different cognitive abilities” and wrote that “every ethnic group contains highly capable individuals” and that no one “should be discriminated against because of their ancestry.” Over email, Bach further clarified to me that “the concept of race is not suitable to capture cognitive and behavioral differences between individuals.” He said that “scientific discussion about the heritability of traits can be important for the creation of a more fair and equitable society, it is important to understand the nature and limitations of our minds, but they are very complicated and not my area of research.”

Other names that pop up in Epstein’s emails: He reached out to Steven Pinker, a Harvard professor who has written about research that argues that Ashkenazi Jews are innately intelligent. (Pinker has disavowed Epstein and denied that he ever visited Little Saint James, Epstein’s island. He attended at least two events that Epstein was also present at. “I only had one conversation with him, and found him to be not only odious but intellectually deeply unserious, despite the praise from so many of my colleagues, and his own pretensions,” Pinker told me over email. He also said that he doesn’t believe that there is “good evidence that average racial or ethnic differences have a genetic component.”) Epstein also tried to meet with Richard Dawkins, who has made comments claiming that race is a biological reality; Dawkins did not respond to a request for comment.

In the past several years, race science has gained traction on the right and in parts of Silicon Valley’s elite circles. Elon Musk, for example, has repeatedly replied to the @cremieuxrecueil account, run by Jordan Lasker, an independent researcher who has been credited by a right-wing publication for tracing “the genetic pathways of crime, explaining why poverty is not a good causal explanation.” Musk has also engaged with an account that posted statistics supposedly illustrating the inferiority of Black people. In November, The Guardian reported that perspectives defending race science were embedded in Musk’s Wikipedia competitor, Grokipedia. Musk and his representatives did not respond to a request for comment.

Read: Elon Musk updated Grok. Guess what it said?

In 2023 and 2024, respectively, Charlie Kirk and Tucker Carlson interviewed Steve Sailer, a prominent race-science proponent. President Trump—who once considered Epstein a close friend and is referenced in many emails—has toyed around with the concept for years. In a November 2024 interview with the right-wing radio host Hugh Hewitt, Trump said that some of the migrants coming across the southern border were genetically inferior. “How about allowing people to come to an open border, 13,000 of whom were murderers? Many of them murdered far more than one person, and they’re now happily living in the United States,” Trump told Hewitt, citing an incorrect number. “You know, now a murderer—I believe this—it’s in their genes. And we got a lot of bad genes in our country right now.” When I reached out to the White House, the spokesperson Abigail Jackson told me in an emailed statement that “President Trump is right—dangerous criminal illegal aliens exploited Joe Biden’s open border and flooded our country.”

Read: Donald Trump flirts with race science

Meanwhile, Trump’s deportation campaign appears to target people from countries and cultures that he seems to think are inferior. During a Cabinet meeting in December, Trump said of Somalis, “I don’t want them in our country, I’ll be honest with you,” adding that the U.S. will “go the wrong way if we keep taking in garbage into our country.” He said this while the Department of Homeland Security was targeting Somalis in Minnesota.

Arguing that intelligence and adjacent traits are biologically determined served a clear function for a man like Epstein, who treated women as disposable and subordinate. And it’s equally unsurprising that the powerful people with whom he cultivated relationships might attempt to come up with a natural, objective explanation and rationale for their perch at the top of society.</div>
        </div>
        
        <div class="card" onclick="openModal('content-24')">
            <div class="source">Slashdot</div>
            <div class="title">Amazon Engineers Want Claude Code, but the Company Keeps Pushing Its Own Tool</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-24" style="display:none;">
            <h2>Amazon Engineers Want Claude Code, but the Company Keeps Pushing Its Own Tool</h2>
            <p><strong>Slashdot | 2026-02-12</strong></p>
            <a class="original-link" href="https://developers.slashdot.org/story/26/02/12/1530202/amazon-engineers-want-claude-code-but-the-company-keeps-pushing-its-own-tool?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Follow Slashdot blog updates by subscribing to our blog RSS feed

Any &quot;AI&quot; (it&#39;s just a broken LUT) that currently exists is based on stale, incorrect, and old data, with too much entropy to be reliable. I wish I could use it, but instead I have to develop my own to reach both determinism and economical scalability.

Probably get better results than when they just assign someone to you.

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.</div>
        </div>
        
        <div class="card" onclick="openModal('content-25')">
            <div class="source">Slashdot</div>
            <div class="title">The "Are You Sure?" Problem: Why Your AI Keeps Changing Its Mind</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-25" style="display:none;">
            <h2>The "Are You Sure?" Problem: Why Your AI Keeps Changing Its Mind</h2>
            <p><strong>Slashdot | 2026-02-12</strong></p>
            <a class="original-link" href="https://slashdot.org/story/26/02/12/153227/the-are-you-sure-problem-why-your-ai-keeps-changing-its-mind?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Why does it prefer agreeable text to facts?

BECAUSE LLMS DON&#39;T KNOW FACTS, you fucking twit.

Perhaps if LLMs started throwing a few insults and denigrating epithets out with their response, people would stop questioning them.

The behavior, known in the research community as sycophancy, stems from how these models are trained: reinforcement learning from human feedback, or RLHF, rewards responses that human evaluators prefer, and humans consistently rate agreeable answers higher than accurate ones.No, it&#39;s because in the training corpus most of the responses to &quot;are you sure&quot; that anyone bothered to record will involve someone being corrected.

The behavior, known in the research community as sycophancy, stems from how these models are trained: reinforcement learning from human feedback, or RLHF, rewards responses that human evaluators prefer, and humans consistently rate agreeable answers higher than accurate ones.

No, it&#39;s because in the training corpus most of the responses to &quot;are you sure&quot; that anyone bothered to record will involve someone being corrected.

Then it will argue with you constantly and tell you you&#39;re always wrong.

LLM has learned its math and knows that changing the answer will yield a better proability.

Now go try to persuade the show host that your wife knows better.

ChatGPT can get its maths right. Ask it some maths problem involving a lot of long floating point numbers , maybe a few functions such as log or sqrt etc that there is no way in hell could possibly be in its training data and it&#39;ll get the answer correct. I suspect OpenAI have embedded some kind of calculator into it now.

Google search says it uses python in the background, but maybe it&#39;s hallucinating.

I suspect OpenAI have embedded some kind of calculator into it now.Are you sure?

I suspect OpenAI have embedded some kind of calculator into it now.

Since when? Sure, they can save a bit of googling and sort some wheat from chaff, but they&#39;re hardly essential tools unless you&#39;re a total net incompetant.

Some people use AI at their jobs now. Sure, they can get things done without AI, but everyone settles in to rely on the tools they use daily.

If one were to anthropomorphize AI, you might be inclined to believe them at the toddler stage, and viewing every person they interact with a bit like a mother. Every toddler, when asked by mom, &quot;Are you sure?&quot; knows damned good and well they better change whatever it was they just said or there will be consequences.

Now, how do we spank the AI when it still fucks up the answer after correcting itself?

My son, in just 8 months, developed object permanence. He is now far beyond any &quot;SOTA LLM&quot; out there.

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.</div>
        </div>
        
        <div class="card" onclick="openModal('content-26')">
            <div class="source">Slashdot</div>
            <div class="title">Anthropic To Cover Costs of Electricity Price Increases From Its Data Centers</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-26" style="display:none;">
            <h2>Anthropic To Cover Costs of Electricity Price Increases From Its Data Centers</h2>
            <p><strong>Slashdot | 2026-02-12</strong></p>
            <a class="original-link" href="https://slashdot.org/story/26/02/12/1251249/anthropic-to-cover-costs-of-electricity-price-increases-from-its-data-centers?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Want to read Slashdot from your mobile device? Point it at m.slashdot.org and keep reading!

Was going to say pretty much the same thing... stop talking like this is a &#39;favour&#39; big corp is doing for the little people.

This shouldn&#39;t be a marketing move this should be the default!Uh, the marketing move is to make you believe this is true.The default is to make you pay for it anyway.  Because they can.The standard, should be to prove AI is worth the effort.  Against the very entity it&#39;s destroying.  So far, the answer is a resounding NO.

This shouldn&#39;t be a marketing move this should be the default!

Uh, the marketing move is to make you believe this is true.

The default is to make you pay for it anyway.  Because they can.

The standard, should be to prove AI is worth the effort.  Against the very entity it&#39;s destroying.  So far, the answer is a resounding NO.

Tell the power companies. They are free to tell data centers what they have to pay.

No, coal if the orange climate denier has anything to do with it. Trump has ordered the pentagon to buy more coal-fired electricity [nytimes.com], one of his biggest and most persistent lies is that climate change is a hoax.

Again, those big AI users can have those modular nuclear reactors in their garage.  Or if there is a big fuss, maybe move those datacenters, nuclear reactors and everything to remote parts of the country, along w/ their users.  They can use satellite internet like Starlink (never mind the latency), while doing their 24/7 operations, w/o requiring the rest of the population to pay for them

Precisely!  Or even better yet - don&#39;t use datacenters at all!  For those who do want and need AI, those people can get those special GPU compute boxes like a Dell GB10 and run their AI requirements on those.  That way, they can pay for the electricity if they need to run them 24/7, and if they can&#39;t afford that, then they can simply run them when they need an AI operation done, as opposed to doing it 24/7

Datacenters should similarly provide for their own power, or factor that in while putting together SL

I can tell you that a number of counties and municipalities have enacted moratoriums on new data centers, and many more are actively conside

It doesn&#39;t matter, because this is just another advertisement campaign.

I&#39;d like to know how are they going to evaluate the cost difference. Perhaps Claude will give us the estimates?

I was just going to post &quot;oh yeah?...with WHO&#39;S money??!&quot; Good job calling them out ðY&#39;

for how long? Just the year it goes online? Or for the next ten or twenty years?

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.</div>
        </div>
        
        <div class="card" onclick="openModal('content-27')">
            <div class="source">Slashdot</div>
            <div class="title">Meta Auditor EY Raised Red Flag on Data-Center Accounting</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-27" style="display:none;">
            <h2>Meta Auditor EY Raised Red Flag on Data-Center Accounting</h2>
            <p><strong>Slashdot | 2026-02-12</strong></p>
            <a class="original-link" href="https://tech.slashdot.org/story/26/02/12/121243/meta-auditor-ey-raised-red-flag-on-data-center-accounting?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Slashdot is powered by your submissions, so send in your scoop

Does it matter? Facebook made $60bn net last year (including another year of insane double digit billions of losses on the metaverse). The AI funding Jenga block doesn&#39;t impact these tech companies.  They literally aren&#39;t held to account for spending a measly little sub $30bn figure. They&#39;ll just move on to wasting money on The Next Thing (tm)

... off its books ... Our client is acting like a criminal but if we say that, we lose a customer.  Worse, they bribe politicians to legitimize their dishonesty:  Dammed if we do, Dammed if we don&#39;t.

Our client is acting like a criminal but if we say that, we lose a customer.  Worse, they bribe politicians to legitimize their dishonesty:  Dammed if we do, Dammed if we don&#39;t.

https://seekingalpha.com/news/... [seekingalpha.com]

What I got from this is that they intend to have a 2000+ acre data center and ~500 people running it.  That could be 10000s of servers each person

which is probably reasonable for a hyper-scaler deployment a company like Meta would consider.  Most of the hardware is pretty reliable. Everything running on it will be highly fault tolerant. If anything goes wrong nobody local does any actual fix, they pull replacement unit out of stock, swap it, and it boots from SAN and rejoins the hive..

The failed unit is either shipped to some central recovery facility or maybe directly the recycler.

This is what state and local pols NEED to understand about these data center projects, once the construction phase is over they don&#39;t mean that many jobs even in the context of a rural county. So they need to be really really careful about any tax abatement schemes etc. You are not going to see a bunch of new housing demand, new economic activity, payroll taxes etc. Just existing residents angry about noise, and their wells drying up.

COLLECT THE PROPERTY TAXES or deny the permits.

Several states are actively trying to slow it down as the tax abatements are around as much as the economic development value, with low job counts. Never a problem though, some state will always go for the gold. From the article, &quot;Hyperscaler developers are increasingly moving from more concentrated markets where opposition has strengthened to &quot;second- or third-tier&quot; states that can offer generation capacity, such as Kentucky or Indiana, where M

From the eye-in-the-sky view of this, it looks like Meta knows there&#39;s a pretty big risk of either low or no return on investment with this new datacenter. They want it built, but they don&#39;t know that the whole purpose for it won&#39;t blow-up or disappear in the time it takes to be built. Therefore, they want a holding company to own the majority share of the datacenter, so if it ends up being a financial blunder, they only take 20% of the blame, rather than 100%. It looks from here like a typical corporate structure shell game: hiding assets within &quot;other companies&quot; that are actually outright controlled by the parent, but on paper look like separate entities is a game as old as the concept of corporations itself. Sucks that even an auditor is too scared of the financial giant to say outright that it&#39;s bullshit both legally and ethically.

Is Meta responsible for paying off the bondholders if the project fails? That would seem to be the relevant issue. I am guessing that Meta has committed to purchase services sufficient to pay off the bondholders, but doesn&#39;t want that to appear as an obligation on their balance sheet. In that case, they are trying to fool investors and creditors.

It can be a way of managing project risk.  You create a new company to build a thing, with the existing organization as stake holder, and planned primary or only customer. If the project succeeds the parent company acquires the rest of the equity in the child and by extension becomes responsible for the debts, if it does not work out the child company declares bankruptcy and the bond holders are left bag holding.

A lot of people find this objectionable but honestly as l

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.</div>
        </div>
        
        <div class="card" onclick="openModal('content-28')">
            <div class="source">Slashdot</div>
            <div class="title">US Hacking Tool Boss Stole and Sold Exploits To Russian Broker That Could Target Millions of Devices, DOJ Says</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-28" style="display:none;">
            <h2>US Hacking Tool Boss Stole and Sold Exploits To Russian Broker That Could Target Millions of Devices, DOJ Says</h2>
            <p><strong>Slashdot | 2026-02-12</strong></p>
            <a class="original-link" href="https://news.slashdot.org/story/26/02/12/0615244/us-hacking-tool-boss-stole-and-sold-exploits-to-russian-broker-that-could-target-millions-of-devices-doj-says?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Want to read Slashdot from your mobile device? Point it at m.slashdot.org and keep reading!

If it requires effort to be parsed and understood, it&#39;s not a good headline. Are native English speakers finding it easy to understand? What even is a hacking tool boss?

It&#39;s not too bad, but it is a little structurally ambiguous. &quot;...Sold Exploits To Russian Broker That Could Target Millions of Devices....&quot; That might mean the Russian broker could target millions of devices, or it might mean that the tool could target millions of devices. And is the broker a Russion person, or does he sell Russian people?

But some headlines are actually hilarious, though. Like these.  [upenn.edu] Hard to pick a favorite, but I do like these:
Include Your Children When Baking Cookies
Iraqi Head Seeks Arm

(US Hacking Tool [company]) Boss (Stole and Sold) Exploits To (Russian Broker) That Could Target Millions of Devices. [According to DOJ]

When the president leads the way, others follow....Yeah, this is currently a top-down problem. When the people see fraud paying off in the way it pays off for our &quot;leaders,&quot; it&#39;s hard to make the argument that we should all be stand-up good citizens. It&#39;s proving out to be a gimme, gimme country, and we&#39;re witnessing the ultimate gimme, gimme by the grifter in chief, showing the citizens how to play the game.

When the president leads the way, others follow....

Yeah, this is currently a top-down problem. When the people see fraud paying off in the way it pays off for our &quot;leaders,&quot; it&#39;s hard to make the argument that we should all be stand-up good citizens. It&#39;s proving out to be a gimme, gimme country, and we&#39;re witnessing the ultimate gimme, gimme by the grifter in chief, showing the citizens how to play the game.

How about all the woman who accused Bill Clinton?You can have Bill Clinton. We don&#39;t give a fuck. He was a rapey piece of shit which many of us have been pointing out, check my posting history. That pales compared to the Trump-Epstein child rape and cannibalism consortium, but still, you can have him too.

How about all the woman who accused Bill Clinton?

You can have Bill Clinton. We don&#39;t give a fuck. He was a rapey piece of shit which many of us have been pointing out, check my posting history. That pales compared to the Trump-Epstein child rape and cannibalism consortium, but still, you can have him too.

He won&#39;t get a Trump pardon that cheap unless he was a pedo [npr.org]

Dude seems like a real shitbag.See, halfway there already. Trump will love him.

See, halfway there already. Trump will love him.

And what Cellebrite does is ok because they are selling to the US?Or because they didn&#39;t steal from the US?

Who takes that sort of risk for only $1.3 million?

It&#39;s treason if you haven&#39;t gotten permission from the Don. There are rules and a hierarchy in organizes crime.

Wait, so it was OK when only the US had backdoor access to millions of computers and devices?

When morally upright people with some technical competence discover an exploit that can be used as a backdoor, they report it to the vendor so it can be fixed.  They don&#39;t report it on public media, so the vendor has time to fix it before criminals learn about it, thus protecting everyone who is already using the software.  And, in turn, the morally upright and competent software vendor actually prioritizes it for a speedy fix, and does not have the reporter arrested and charged with criminal hacking.

What about the guy he framed for the theft and took away his livelihood and reputation ...personally?

Did they make sure he would receive compensation?

...the next time any Government spokesperson tells us that back-doors to cryptography are perfectly safe as only law-enforcement will have them?

He ruined the life of an innocent personHe betrayed his countrymen for moneyHe compromised security for everyone

the former general manager of U.S. defense contractor L3Harris&#39;s hacking tools division Trenchant ...Williams, a 39-year-old Australian national,A lot of US defense contractor jobs require you to be a US citizen.Maybe not this one.Or maybe he was a dual national.  But if he was, the article probably would have said so.

the former general manager of U.S. defense contractor L3Harris&#39;s hacking tools division Trenchant ...

Williams, a 39-year-old Australian national,

A lot of US defense contractor jobs require you to be a US citizen.

Or maybe he was a dual national.  But if he was, the article probably would have said so.

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.</div>
        </div>
        
        <div class="card" onclick="openModal('content-29')">
            <div class="source">Slashdot</div>
            <div class="title">Siri's AI Overhaul Delayed Again</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-29" style="display:none;">
            <h2>Siri's AI Overhaul Delayed Again</h2>
            <p><strong>Slashdot | 2026-02-12</strong></p>
            <a class="original-link" href="https://apple.slashdot.org/story/26/02/12/0528239/siris-ai-overhaul-delayed-again?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Want to read Slashdot from your mobile device? Point it at m.slashdot.org and keep reading!

Nothing you can&#39;t fix by building 8-10 more datacenters and dumping in them 4 or 5 more &quot;agentic expert&quot; models to loop over each others&#39; &quot;reasoning&quot; per request.

It&#39;s actually kind of impressive that they are holding out and not shipping something that doesn&#39;t work.  Shipping non-functional hype is the industry standard.  We&#39;ll ignore that Siri sort of already doesn&#39;t work.  They are refusing to make it worse.

one cannot expect our incompetent upper class overlords to produce anything but even more overpriced and unimaginative technology, let&#39;s not forget the goal is not to produce good tech but to extract the most revenue in order to increase shareholder value

our devices and our services are designed to exploit us, manipulate us and surveil us, welcome to our classist corporatocracy

If phone interfaces (And windows 11) were designed by professional interface designers instead of as an afterthought by programmers then we wouldn&#39;t have to search to find functionality, it would be obvious where it is.

They wouldn&#39;t even need to bother with building a good AI. Create a MCP server that has access to all important functions of the phone and other apps can provide the AI that does these things. But they don&#39;t want to let other apps access these things.

Actually, now that I think about it... I kind of expected this.

That said, good on Apple for delaying. If/when they release, it needs to be really good - much better than anyone elses *on the phone*. As noted elsewhere, if you ask it to alter a setting which is deep in a spaghetti of menus, then it needs to do it right first time. It needs to be at least as good as the others for the inevitable stupid questions people will ask when testing it out too, I guess.

If Apple release a half-baked product, people really lose their gussets over it. Cont

... just focus on fixing the issues like bugs. Way too many problems. V26 is awful. Also, please stop doing new major versions every year. Why not slow down and take the time?

Seconded.  There are so many things that need refactored in macOS, iOS, iPadOS, and other *OS items.  Not to mention iCloud.

Even something as basic as Time Machine needs help.  Ideally, have the ability for iCloud to handle S3, and Time Machine able to do deduplicating S3 backups similar to Restic or Duplicacy.  Duplicacy has some nice things, including public key encryption of data, so machines can back up and deduplicate, but not read the data.

Then comes other items.  Macs need something like BootCamp so

&quot;Macs need something like BootCamp so they can be used for Linux.&quot;

Just release the full hardware specifications so Linux doesn&#39;t have to reverse engineer everything.

The good news (which may now be obsolete) is that OS 27 was supposed to be a clean-up and bug-fix version. But now that is suddenly the great AI savior introduction. Can they fix more bugs than the AI will generate?

More unsubstantiated rumor from people whose business it is to generate CLICKS TO THEIR WEBSITE.  When have you ever heard someone like Gurman or Bloomberg News admit they were wrong, or that they just made some shit up?

New Siri is a significant/important thing for Apple.  They should spend the time to get it right  The release should be based on functionality, not schedule.  But I suspect the people who actually know about this are not leaking this kind of status.

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.</div>
        </div>
        
        <div class="card" onclick="openModal('content-30')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">A Running List of Horrific Things ICE Agents Have Said to My Neighbors</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-30" style="display:none;">
            <h2>A Running List of Horrific Things ICE Agents Have Said to My Neighbors</h2>
            <p><strong>News and Politics - Slate Magazine | 2026-02-12</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2026/02/ice-agents-minnesota-comments.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Sign up for the Slatest to get the most insightful analysis, criticism, and advice out there, delivered to your inbox daily.

Last week, two Democrats in the Senate hosted a “bicameral public forum to receive testimony on the violent tactics and disproportionate use of force by agents of the Department of Homeland Security.” Here in Minnesota, we continue to deal with the thousands of immigration enforcement agents who have unleashed unspeakable violence on our state. Flights leave daily with men, women, and children, some of whom are citizens, green-card holders, or asylum-seekers with pending cases, to detention centers with a prevailing culture of abuse. Countless other legal observers and protesters, including myself, have been handcuffed and detained for hours without being charged with a crime, or intimidated with weapons and threats.

In the spirit of the public forum held in the District of Columbia last week, I collected the following set of comments ICE agents have made to my community, pulled from video recordings, sworn affidavits, and media reports. (A sourced list of these interactions is being compiled here.) We may not know their names or see their faces, but we hear what they say.

Agent standing in front of a truck and aiming a gun at Adan Nunez Gonzalez, while other agents rip Gonzalez out of his vehicle. Gonzalez was an asylum-seeker with no criminal record but was deported to Mexico. Nov. 11.

Agent standing in front of a car with an assault rifle pointed at the driver. Dec. 7.

After moving in front of Renee Good’s car, then shooting her three times. Jan 7.

Responding to a civilian shouting “I’m a physician!” The physician was desperate to try to check Good’s pulse and offer help but was told to stay back. Emergency services arrived later but were unable to save her life. Jan. 7.

To a Somali citizen told to prove his citizenship. Jan. 7.

To a pastor released after a warrantless detainment. He had been detained because he said he wasn’t afraid of them. An agent pointed a gun at him and asked, “Are you afraid now?” They handcuffed him, and agents repeatedly asked, “Are you afraid yet?” He kept responding no until he was eventually released. Jan. 7.

To an Ojibwe citizen born in Minneapolis, according to his sister, who saw his arrest. He was punched, handcuffed, and held at the Whipple Federal Building for hours. Jan. 8.

To a Somali legal resident after tackling him without identifying themselves, putting him in a headlock, shoving him inside an unmarked car to check for his documentation status, then releasing him. Jan. 8.

To a 5-foot-5, 120-pound woman with a medical condition. She lost consciousness after being yanked up off the ground. Jan. 9.

To a Hispanic legal resident. The agents then took $130 out of his wallet. Jan. 10.

To a Hispanic citizen born in Minnesota. Jan. 11.

To a Somali citizen desperately trying to get her husband to text a photo of her passport. She was subsequently handcuffed, driven around for an hour, and dropped off in a random parking lot. Jan. 12.

While pointing assault rifles at a terrified woman, who asked if they had a warrant and pleaded with them to stop because there were children inside the house they were breaking into. Jan. 12.

After crashing into a Hispanic citizen’s car. The anonymous agent did not leave any insurance information. Jan. 12.

To an autistic woman with a brain injury who stumbled across agents on the way to a medical appointment. They cut her seat belt, dragged her out of the vehicle by each of her limbs, laughed at her, and drove her to Whipple, where she was denied medical treatment and lost consciousness. Jan. 13.

While brandishing a window-breaking tool to threaten a citizen showing their ID through the window. Jan. 14.

While arresting a Somali citizen. Jan. 14.

To a Somali citizen screaming in pain as his arms were twisted behind him. He responded, “My country is the USA.” Jan. 15.

Responding to the question “Why would you pepper-spray a 15-year-old kid?” Jan. 15.

To a Hmong citizen after breaking down his door, pointing guns at his family, then dragging him outside and into an unmarked car in nothing but his boxers and a pair of Crocs. Jan. 18.

Mocking the shocked witnesses who saw Alex Pretti shot 10 times. Jan. 24.

While shooting chemical weapons at protesters at the site of Pretti’s death minutes later. Jan. 24.

As they detained a restaurant worker who had the necessary documents. Instead of bringing him back, agents sent him to a Texas detention center that night, before his loved ones could bring him his medication. Feb. 2.

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-31')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">Who Coined the Term <em>Inferiority Complex</em>?</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-31" style="display:none;">
            <h2>Who Coined the Term <em>Inferiority Complex</em>?</h2>
            <p><strong>News and Politics - Slate Magazine | 2026-02-12</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2026/02/trivia-quiz-daily-slate-science-psychology-cosmology-physics.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Please enable Javascript in your browser to view Slate interactives.

Slate Crossword: Their Calendars Usually Clear Up After 4/15 (Four Letters)

Which Union General Destroyed Much of Georgia in 1864 in His March to the Sea?

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-32')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">A New Version of Woke Is Coming. Conservatives Aren’t Going to Like It.</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-32" style="display:none;">
            <h2>A New Version of Woke Is Coming. Conservatives Aren’t Going to Like It.</h2>
            <p><strong>News and Politics - Slate Magazine | 2026-02-12</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2026/02/dark-woke-aoc-gavin-newsom-joe-biden-donald-trump.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Sign up for the Slatest to get the most insightful analysis, criticism, and advice out there, delivered to your inbox daily.

In January, Florida Rep. Randy Fine made a typically bigoted post on X about his colleague in the House of Representatives, Ilhan Omar. The post was in conversation with a specious right-wing conspiracy alleging that Omar’s net worth had increased, nefariously, through a variety of unspecified means—perhaps cryptically linked back to her Somali heritage. Fine asserted that to “solve all this,” Omar ought to be “denaturalized and deported.” The ugliness of the comment prompted Rick Wilson—former Republican strategist, he of the magnanimous Lincoln Project—to step forward. In earlier eras of discourse, the Lincoln Project attempted to coalesce an anti-Trump movement by appealing to our better angels; brandishing Sorkin-ish platitudes about the Soul of America. (There is a reason the organization name-checks the 16th president.) But Wilson took a much different approach here. Rather than addressing the content of Fine’s character, Wilson homed in on something else: The congressman is very, very fat.

“Hunting you with harpoons and whaleboats would solve all this,” said Wilson, parroting Fine’s diction. Among the responses threaded below Wilson’s retort, one is an edit of promotional materials for a 2011 television adaptation of Moby-Dick. In it, Fine has been photoshopped in place of the whale.

It goes without saying that for a very long time, fat-shaming a politician was previously verboten in the liberal playbook. I also do not possess the wherewithal to cast judgement on whether Fine—who has expressed some genuinely bloodthirsty sentiments about Palestinians—deserves to be bullied in such a way. But what I can say is that, right now, we are in the midst of a marked pivot in the way the Democratic Party interfaces with its opposition. The shift in attitude hasn’t been firmly diagrammed; instead, what’s going on here is mostly subconscious, like a collective unlocking of forbidden territory. There was a period of time in the late 2010s where liberal hostility toward MAGAdom was screened for all potential vectors of transgression, and a seemingly infinite number of potential -isms or -phobias. The philosophy was well-intentioned, but it also solidified the Democrats as the party of pedants (or narcs, or nerds, or rule-followers). Now in the wreckage of the post-Biden era, some liberals have started to alter their approach. If sweeping appeals to our collective empathy have failed to resonate—if the public is not moved by Randy Fine’s intersectional shortcomings—maybe we are better off getting down in the muck.

There is no perfect name for this dynamic, but some have begun to refer to it, somewhat facetiously, as “Dark Woke.” In the most basic definition, Dark Woke is a social covenant that allows for liberals to be extra mean to conservatives, by encouraging a style of animus that deliberately crosses the red lines previously established within the progressive orthodoxy. The concept is difficult to articulate, but it’s easily felt. Dark Woke manifests when the liberal pundit Kyle Kulinski tweets out an A.I. rendering of Erika Kirk and J.D. Vance standing side by side at a wedding altar, or when the Democratic Party’s X account accuses Stephen Miller of being cuckolded by Elon Musk, or when Pete Hegseth is dressed down for being a drunk. You can sense it manifesting into corporeal space when Virginia Attorney General Jay Jones crushes the field after fantasizing about the death of MAGA-born children, or when Graham Platner—the guy with the Nazi tattoo—remains competitive for Maine’s Senate seat despite his generational baggage. With the midterms growing nearer, it’s becoming clear that some forces within the Democratic apparatus are betting that Dark Woke can be wielded as an effective electoral strategy. One of the lessons of the current political environment is that Americans crave authenticity. Maybe the only way to consummate that desire is by hitting below the belt.

Dark Woke has only been in the bloodstream for a short amount of time. It initially entered the lexicon in the early weeks of 2025, when both the Democratic Party and any sense of American consensus had been shattered by Donald Trump’s comeback victory. Nobody is exactly sure who originally coined the term, but ground zero, according to the internet historians at KnowYourMeme, might be a post made by Rep. Alexandria Ocasio-Cortez one day before the inauguration. Ocasio-Cortez was replying to LibsofTikTok, a popular X account and one of the more prominent agitators in the MAGA propaganda ecosystem. LibsofTikTok took issue with AOC referring to Trump as a rapist; the congresswoman responded by mimicking the brusque diction of the right. “Oh are you triggered? Cry more,” she wrote, accumulating 17.6 million views in the process.

The candor was refreshing in those confusing times, so much so that one day later, another poster on X theorized that she might have inculcated a new social contract—a “proto Dark Woke”—that liberals could take with them going forward. The poster surmised the texture of the reinvention by positing an instructive question: “Who will the first Democrat to call Republicans retarded be?”

Thus, the Dark Woke thesis was born: Democrats need to open up new persuasive terrain, and by and large, that terrain needs to be unshackled by circumspect language temperance—call it Woke Classic—than ever before. In a way, this conclusion conceded the postelection conclusion of a conservative cultural victory. If the arc of history is indeed tilting rightward, then Dark Woke acknowledges that the Democratic brand had grown too uptight, which must be rectified with a kind of reverse virtue signaling. (It is telling, for instance, that in the weeks before her clapback, Ocasio-Cortez removed the “She/Her” pronouns from her Twitter bio.) Naturally, a number of strivers were early adopters of this brewing vibe shift, branding themselves as heralds for this intrepid age of offense. Chief among those interlopers was Rep. Jasmine Crockett, who is currently running for a Texas Senate seat, and who came to national fame after referring to former Rep. Marjorie Taylor Greene as a “bleach-blonde, bad-built, butch body,” and, later on, the wheelchair-using Gov. Greg Abbott as “Governor Hot Wheels.” Meanwhile, presidential hopeful Gov. Gavin Newsom, who is eternally pliable to whichever way the wind is blowing, popularized California’s redistricting campaign with a Trump-affected shitposting parody. (Newsom has never called Trump the R-word, but he’s easily the odds-on favorite.)

As Dark Woke gained fluency, most pundits concluded that the trend would never amount to anything other than a temper tantrum. “Dark Woke is cringe,” offered New York magazine. “Dark Woke will not work for Democrats,” added the National Review. The fundamentals of the argument were rock solid. For one, Dark Woke is a movement that exists almost entirely online, and it resonates most with highly engaged Democrats rather than with mercurial swing voters who are mostly concerned about the price of eggs. Second, no matter whatever else you say about them, figures like Donald Trump and Stephen Miller are bona fide outsiders. They can claim the mantle of the firebrand, which is forever out of reach for an institutional figure like Newsom.

With all that said, I have been surprised to see certain Dark Woke principles diffuse into the rank-and-file Democratic voting population. The base appears to be demonstrably more bloodthirsty than it ever was during Trump’s first term, almost like they’ve finally been granted an opportunity to satiate a long-unquenched rage, absent any platitudinal hedging. I am reminded of a video that went viral shortly before the November elections, in which a typical MAGA grievance aggregator interviewed a woman holding a cardboard sign at one of those “No Kings” protests. The interviewer is pushing her on the assassination of Charlie Kirk, seeking empathy for the recently departed podcaster. The woman, of course, gives no quarter.

“He was horrible. I’m glad he’s not here,” she said. “He was horrible on the campuses. A horrible person.” The interviewer, taken aback, asked if she’d be happy if the interviewer were assassinated, too.

“Maybe, I’d have to think about it,” she replied.

What was it that Michelle Obama said during Hillary Clinton’s coronation? “When they go low, we go high.” Voicing a sentiment like that today might get you booed out of the building. And yet, it needs to be acknowledged that according to MAGA media enterprises, liberal discourse has long been vulgar and hateful. Given the chance, the thinking went, they’d round up all of us “America First” patriots in a Soviet-style purge.

The right’s narrative of a bloodthirsty Democratic Party was, well, at odds with party voters’ 2020 decision to bypass a host of progressive options in favor of the rigidly moderate Joe Biden. But the right isn’t wrong about the long-standing loathing of Trump and everything he represents. I mean, one of the first controversies that surfaced after Trump’s initial ascension in 2016 centered around a photo shoot starring Kathy Griffin. She was posing with a prop of the president’s severed head.

But if you asked me why the Dark Woke opposition during Trump’s second term feels different, I’d assert that, while opposition to Trump during his first term was intense, it was also championed by a murderers’ row of grifters and mediocrities; Michael Avenatti, Andrew Cuomo, the Krassenstein brothers, and those same Lincoln Project guys. Ultimately, the loudest of those voices wielded anti-Trump advocacy as a vehicle for their own enrichment, buttressing presidential campaigns, podcast networks, and thrice-weekly Substacks. It worked, Trump did lose in 2020, but the #Resistance was left with a distinct careerist sheen—buoyed by discretionary restraint—lacking the organic force of, say, a soul-buckling fat joke. As The Outline saliently noted in 2019, this disposition seemed to suggest a holier-than-thou elitism. Calling the president a Cheeto was fine, but making fun of Charlie Kirk was not.

But the means of engagement have been altered, maybe permanently, in the tumult of this current political armageddon. MAGAdom is the party in power; naturally, their opponents are choosing to meet them on the battlefield of their choosing. With that said, I do think some surprising sensitivities within the conservative doctrine have come into view, as the movement sublimates into the uncomfortable posture of the establishment. This was most clear during Immigration and Customs Enforcement’s occupation of Minnesota, after masked agents killed Renee Good and Alex Pretti. Among the many faulty narratives that orbited out of the government, one asked us to consider the mental anguish suffered by these dispatched officers. J.D. Vance himself wondered if his roving band of goons would “feel safe” during the aftermath of those murders. Put on the defensive, Vance and his contemporaries have occasionally fallen back on the diction of the soft, snowflake liberalism they claim to hate. But in an ironic twist, the right has already provided the perfect blueprint to nullify shrill emotional terrorism. To quote AOC, “Cry more.”

Of course, this gets us back to the central anxiety of the moment. Is Dark Woke good? For the soul? For the body? For the future? I was socialized in the crucible of millennial progressivism. I have long believed that it is unkind to make fun of someone for their weight, that I should prune the slurs out of my lexicon, that I should refrain from laughing at the misfortune of those who have recently met a tragic end. Dark Woke asks us to make special exceptions for the aberrant forces in our midst—to bully insecurities, to express our anger viscerally—because their sins are great enough to eclipse the worst things any of us can say about them. After all, it is difficult to conflate language with violence when the violence itself has become so plainly visible. It remains to be seen if Dark Woke can grow potent enough to outweigh the sun-blotting forces of Dark MAGA, or if fickle centrists find all of this liberal rage more alienating than relatable. But I—and millions of other Americans—do know what it feels like to be alive in 2026. I never want to go high ever again.

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-33')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">No Really, Abolish ICE</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-33" style="display:none;">
            <h2>No Really, Abolish ICE</h2>
            <p><strong>News and Politics - Slate Magazine | 2026-02-12</strong></p>
            <a class="original-link" href="https://slate.com/podcasts/what-next/2026/02/democrats-cant-reform-or-stop-dhs-like-this?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">This is what a Congress robbed of its oversight powers looks like.

Please enable javascript to get your Slate Plus feeds.

If you can&#39;t access your feeds, please contact customer support.

Thanks! Check your phone for a link to finish setting up your feed.

Enter your phone number and we&#39;ll text you a link to set up the
        podcast in your app:

We&#39;ll only text you about setting up this podcast, no spam.

Apple Podcasts will only work on MacOS operating systems since Catalina. We do not support Android apps on desktop at this time.

These links will only work if you&#39;re on the device you listen to podcasts on.

We&#39;re sorry, but something went wrong while fetching your podcast feeds. Please contact us at plus@slate.com for help.

Democrats have a list of demands and reforms they want implemented before voting to continuing  funding the Department of Homeland Security. But DHS doesn’t really need their approval to keep going.

Guest: Garrett Graff, journalist, historian, author of Doomsday Scenario.

Want more What Next? Subscribe to Slate Plus to access ad-free listening to the whole What Next family and across all your favorite Slate podcasts. Subscribe today on Apple Podcasts by clicking “Try Free” at the top of our show page. Sign up now at slate.com/whatnextplus to get access wherever you listen.

Podcast production by Elena Schwartz, Paige Osburn, Anna Phillips, Madeline Ducharme, and Rob Gunther.

The problem with the news right now? It’s everywhere. And each day, it can feel like we’re all just mindlessly scrolling. It’s why we created What Next. This short daily show is here to help you make sense of things. When the news feels overwhelming, we’re here to help you answer: What next? Look for new episodes every weekday morning.

Mary Harris is the host and managing editor of What Next, Slate&#39;s new daily news podcast. She has reported throughout the public radio system, for NPR, Marketplace, and WNYC.</div>
        </div>
        
        <div class="card" onclick="openModal('content-34')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">Congress Showed ICE Leaders Images of ICE Brutality. The Response Was Telling.</div>
            <div class="meta">2026-02-11</div>
        </div>
        
        <div id="content-34" style="display:none;">
            <h2>Congress Showed ICE Leaders Images of ICE Brutality. The Response Was Telling.</h2>
            <p><strong>News and Politics - Slate Magazine | 2026-02-11</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2026/02/congress-ice-hearing-pepper-spray-photos-pretti-good.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Sign up for the Slatest to get the most insightful analysis, criticism, and advice out there, delivered to your inbox daily.

After months of watching federal agents terrorize communities all across the country in the name of immigration enforcement, the Department of Homeland Security’s top brass sat before Congress on Tuesday to answer questions about the deaths of Renée Nicole Good and Alex Pretti, the detention of 5-year-old Liam Conejo Ramos, and the fates of countless others who have been caught in the crosshairs of the president’s mass deportation effort. Though Todd Lyons, acting director of U.S. Immigration and Customs Enforcement, mostly deflected any responsibility and insisted that the agency conducts only targeted arrests, Democrats came prepared with receipts to remind us all just how blatantly racist and out of control the White House’s immigration agenda has been.

“You are only here because public outrage has become so unavoidable,” Rep. LaMonica McIver, of New Jersey, said during the House Homeland Security Committee’s oversight hearing. McIver is being prosecuted by the Trump administration over an incident in New Jersey when she was barred from entering a detention facility. “You are here, Mr. Lyons, because white people are getting shot in the face and chest when the cameras are rolling.”

Lyons remained straight-faced, offering no explanation for his agents’ extreme use of force or denial about his agents’ racial profiling of Americans. That profiling is something the Supreme Court essentially endorsed last year, after the justices issued a decision allowing the federal government to stop Hispanic migrants based on their “apparent ethnicity,” as well as other factors, like if they have an accent or work certain types of jobs. This, predictably, has led ICE to overwhelmingly target Black and brown Americans with excessive force.

Indeed, this was one of the main subtexts of the hearing. New Jersey Rep. Nellie Pou, for example, asked, “Mr. Lyons, I speak Spanish. If I wasn’t wearing my member pin, would me being a Latina and speaking Spanish be enough for ICE agents to harass me or shove me into one of your unmarked cars?”

Lyons answered no, but as Pou and other Democratic representatives pointed out, this has not been borne out by the reality on the ground; even off-duty officers have recently been profiled by ICE. When Rep. Troy Carter, of Louisiana, directly asked Lyons if his agency was arresting or deporting Americans, Lyons denied that it was “arresting” Americans, before quickly adding that it did “detain” Americans. As Carter pointed out, this was a distinction without a difference.

When it came to the way agents currently present themselves to Americans, New York Rep. Tim Kennedy asked whether Lyons would instruct his agents to no longer wear masks and institute a uniform that includes visible identification—one of 10 demands congressional Democrats are requesting in the ongoing negotiations over whether to fund DHS beyond Saturday’s deadline. Lyons immediately retorted, “No.”

And when Rep. Eric Swalwell, of California, asked Lyons if he would apologize for his department calling Good and Pretti “domestic terrorists,” he refused. Lyons also insisted that when his agents arrested Ramos as he made his way home from preschool with his father, “the men and women of ICE took care of him.” Later in the hearing, Lyons also claimed that agents played the boy’s favorite song and got him McDonald’s. Meanwhile, it took the intervention of Texas Rep. Joaquin Castro for a visibly unwell Ramos to be released from detention. The administration immediately tried to detain him again.

This was just one of many moments when administration officials offered what felt like a completely different reality from what people on the ground are experiencing with ICE officers.

Rep. Seth Magaziner, of Rhode Island, brought up the case of federal agents in Chicago, who pepper-sprayed a 1-year-old as she sat in the back seat of her father’s car. “Is it proper procedure to aim pepper spray into the window of a moving vehicle?” Magaziner asked Rodney Scott, the commissioner of U.S. Customs and Border Protection, who also testified. “We try to avoid that,” he said.

Magaziner continued to push. “Were any of your agents investigated or disciplined for this?”

“I’ll have to get back to you,” Scott said.

Magaziner then showed a video and zoomed-in photo of an agent firing pepper spray directly into the face of a protester who was pinned to the ground by multiple agents and asked if this was proper procedure for the use of pepper spray. “I cannot respond to that because you’re only showing one piece, and that subject is clearly not compliant,” Scott said, while refusing to confirm whether there was an open investigation into those agents.

“Your agency has been repeatedly caught on tape using violence against civilians, and you can’t even tell me if any of these agents have been investigated or disciplined,” Magaziner said. “You are supposed to be making people safer, and instead your agents are being unnecessarily violent.”

Tuesday’s hearing was the first time ICE leadership has testified before Congress under the second Trump administration, as the White House agreed to the testimony in a clear attempt to contain the fallout from Good’s and Pretti’s deaths. Though it will not immediately solve the current chaos being wreaked by the president and his mass deportation mastermind Stephen Miller, the hearing did serve as a cathartic moment of rage. For a brief period of time, Democrats accurately embodied the feelings of Americans all across the country who are facing ICE in their communities with no real defense.

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-35')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">Which Union General Destroyed Much of Georgia in 1864 in His March to the Sea?</div>
            <div class="meta">2026-02-11</div>
        </div>
        
        <div id="content-35" style="display:none;">
            <h2>Which Union General Destroyed Much of Georgia in 1864 in His March to the Sea?</h2>
            <p><strong>News and Politics - Slate Magazine | 2026-02-11</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2026/02/trivia-quiz-daily-slate-history-war-fire-religion.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Please enable Javascript in your browser to view Slate interactives.

Slate Crossword: Their Calendars Usually Clear Up After 4/15 (Four Letters)

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-36')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">France bets on nuclear power to phase out fossil fuels</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-36" style="display:none;">
            <h2>France bets on nuclear power to phase out fossil fuels</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2026-02-12</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2026-02-france-nuclear-power-phase-fossil.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-37')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">Power of the collective: Modular robot boosts resilience by sharing resources</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-37" style="display:none;">
            <h2>Power of the collective: Modular robot boosts resilience by sharing resources</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2026-02-12</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2026-02-power-modular-robot-boosts-resilience.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-38')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">Beyond the Fitbit: Why your next health tracker might be a button on your shirt</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-38" style="display:none;">
            <h2>Beyond the Fitbit: Why your next health tracker might be a button on your shirt</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2026-02-12</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2026-02-fitbit-health-tracker-button-shirt.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-39')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">Power in motion: Transforming ocean wave energy harvesting with gyroscopes</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-39" style="display:none;">
            <h2>Power in motion: Transforming ocean wave energy harvesting with gyroscopes</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2026-02-12</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2026-02-power-motion-ocean-energy-harvesting.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-40')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">Next-generation batteries could redefine the future of energy storage</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-40" style="display:none;">
            <h2>Next-generation batteries could redefine the future of energy storage</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2026-02-12</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2026-02-generation-batteries-redefine-future-energy.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-41')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">Rethinking rush hour with vehicle automation</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-41" style="display:none;">
            <h2>Rethinking rush hour with vehicle automation</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2026-02-12</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2026-02-rethinking-hour-vehicle-automation.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-42')">
            <div class="source">The Register</div>
            <div class="title">Elon Musk paints exodus of xAI co-founders as 'evolution'</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-42" style="display:none;">
            <h2>Elon Musk paints exodus of xAI co-founders as 'evolution'</h2>
            <p><strong>The Register | 2026-02-12</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2026/02/12/musk_xai_departures/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Elon Musk has framed the recent exodus of talent from his artificial intelligence startup, xAI, as a necessary growing pain, saying the company&#39;s evolution &quot;required parting ways with some people.&quot;

Musk&#39;s post on X (formerly Twitter) followed an all-hands meeting at xAI where he told the audience: &quot;We&#39;re actually going to have a mass driver on the Moon,&quot; although he acknowledged that such a thing was currently in the realm of science fiction.

A mass driver is best thought of as an electromagnetic catapult that flings payloads into space at high velocities. That&#39;s an ideal thing to have if you wanted to, say, have a datacenter in space consisting of a million satellites.

The science fiction reference was well made. Musk has a reputation for making bold statements and then singularly failing to deliver. Remember humans on Mars in 2024 or 2026? It would be impractical to list every missed prediction, but Musk&#39;s track record on timelines is relevant when assessing the credibility of new forecasts.

Musk wrote: &quot;Join xAI if the idea of mass drivers on the Moon appeals to you.&quot;

Or head for the door, as half of the xAI founding team has already done. Yuhai Wu announced his departure on Monday, and Jimmy Ba packed up his things on Tuesday. Both were full of praise for xAI, but the fact that six members of the company&#39;s 12-person founding team have now departed is notable.

Musk has spent the last few weeks rolling out one ambitious announcement after another. This month has seen SpaceX acquire xAI, plans for a datacenter in space, the abrupt pivot from missions to Mars to the Moon, and so on. Even in the fast-paced world of AI development, it is difficult not to imagine the whiplash felt by some employees within Musk&#39;s companies.

Musk stated: &quot;xAI was reorganized a few days ago to improve speed of execution. As a company grows, especially as quickly as xAI, the structure must evolve just like any living organism.&quot; ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-43')">
            <div class="source">The Register</div>
            <div class="title">'Another dark day': Users slam Microsoft over Polyglot Notebooks deprecation</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-43" style="display:none;">
            <h2>'Another dark day': Users slam Microsoft over Polyglot Notebooks deprecation</h2>
            <p><strong>The Register | 2026-02-12</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2026/02/12/polyglot_notebooks_deprecation/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Microsoft has abruptly announced the deprecation of Polyglot Notebooks with less than two months&#39; notice, throwing the future of the .NET Interactive project into doubt.

The deprecation will come into effect on March 27, whereupon bug fixes and support will cease, and no new features will be added. However, the extension won&#39;t be automatically uninstalled from a user&#39;s Visual Studio Code installation.

Polyglot Notebooks is an important element of the Microsoft .NET Interactive project, which Microsoft describes as &quot;an engine and API for running and editing code interactively.&quot; .NET Interactive can run as a kernel for notebooks and &quot;enables a polyglot (multi-language) notebook experience,&quot; according to Microsoft. &quot;For the best experience when working with multi-language notebooks, we recommend installing the Polyglot Notebooks extension for Visual Studio Code.&quot;

That recommendation presumably remains in place until Microsoft pulls the plug.

The deprecation announcement was made in the project&#39;s GitHub repository and the thread was locked, limiting conversation. However, users were quick to raise additional issues, questioning the reasoning behind the deprecation and the short time frame.

One pointed out the Polyglot Notebooks extension in Visual Studio Code was Microsoft&#39;s recommendation for data analysts, since Azure Data Studio is retiring at the end of this month. Microsoft&#39;s reaction was to remove the recommendation.

It appears the author of the Azure Data Studio retirement documentation was unaware of the impending doom facing the Polyglot Notebooks extension. An individual claiming to be the author posted: &quot;As a result of the deprecation announcement for Polyglot Notebooks, I am legally bound to remove that recommendation from the Azure Data Studio article, because it would mislead customers to keep it in.&quot;

Which is true. However, as another user noted: &quot;Removing that documentation from the Azure Data Studio page – and giving no transition path at all for those users (like myself) who depend on those Azure Data Studio features – seems a pretty user-hostile approach. We&#39;ve already followed Microsoft&#39;s transition guidance once and ended up in this situation. Should we now look elsewhere for this functionality?&quot;

The short notice and mixed messaging speaks more of dysfunctional management and communication within Microsoft than anything else. If only there were some tool at the company&#39;s disposal for Teams to communicate and collaborate.

We&#39;ll give the final word to another user reacting to the deprecation announcement, who said: &quot;This is just another dark day for Microsoft customers, and the decision makers are nowhere to be seen taking accountability for the impact of their decisions.&quot; ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-44')">
            <div class="source">The Register</div>
            <div class="title">Apple patches decade-old iOS zero-day, possibly exploited by commercial spyware</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-44" style="display:none;">
            <h2>Apple patches decade-old iOS zero-day, possibly exploited by commercial spyware</h2>
            <p><strong>The Register | 2026-02-12</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2026/02/12/apple_ios_263/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Apple patched a zero-day vulnerability affecting every iOS version since 1.0, used in what the company calls an &quot;extremely sophisticated attack&quot; against targeted individuals.

CVE-2026-20700, discovered by Google&#39;s Threat Analysis Group, affects dyld - Apple&#39;s dynamic linker - and allows attackers with memory write capability to execute arbitrary code. Apple said the flaw was exploited in the wild and may have been part of an exploit chain.

Its advisory stated: &quot;An attacker with memory write capability may be able to execute arbitrary code. Apple is aware of a report that this issue may have been exploited in an extremely sophisticated attack against specific targeted individuals on versions of iOS before iOS 26.&quot;

Google&#39;s researchers also referenced two December vulnerabilities in their report that both carry 8.8 CVSS scores.

CVE-2025-14174 is an out-of-bounds memory access flaw in Google Chrome&#39;s ANGLE graphics engine on Mac that could be exploited through a malicious webpage.

The other, CVE-2025-43529, is a use-after-free leading to code execution.

Brian Milbier, deputy CISO at Huntress, said: &quot;Think of dyld as the doorman for your phone. Every single app that wants to run must first pass through this doorman to be assembled and given permission to start.

&quot;Usually, the doorman checks credentials and places apps in a high-security &#39;sandbox&#39; where they can&#39;t touch your private data. This vulnerability allows an attacker to trick the doorman into handing over a master key before security checks even begin.&quot;

By chaining this with WebKit flaws Apple also addressed in the iOS 26.3 update, &quot;attackers have created a &#39;zero-click&#39; or &#39;one-click&#39; path to total control. They use a fake ID to bypass the front gate – your browser – and then exploit the doorman&#39;s flaw to take over the entire building,&quot; Milbier added.

&quot;This level of sophistication resembles other exploits developed by the commercial surveillance industry. These are private companies that also developed prominent spyware tools like Pegasus and Predator. They sell these types of exploits or tools to government clients. While some updates in this patch address minor issues, such as data leakage from physical access, the dyld/WebKit chain is in a different league. iOS 26.3 closes a door that has been unlocked for over a decade.&quot;

Apple&#39;s updates for iOS and iPadOS also feature a host of other fixes for various bugs, including flaws that grant root access and disclose sensitive user information, but CVE-2026-20700 is the only one it said was exploited in the wild. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-45')">
            <div class="source">The Register</div>
            <div class="title">Memory price explosion triggers PC buying spree</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-45" style="display:none;">
            <h2>Memory price explosion triggers PC buying spree</h2>
            <p><strong>The Register | 2026-02-12</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2026/02/12/memory_pc_rush/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Exploding memory prices are pushing corporate buyers to fast-track PC purchases before costs climb further.

DRAM and NAND have already soared 80 to 90 percent since the final quarter of 2025, as The Register recently reported, and further bill shocks are forecast as the year progresses.

PC makers are starting to witness this dynamic. Lenovo today reported revenue of $15.8 billion for its Intelligent Devices Group (IDG), up 14 percent year-on-year, with PC revenues within that up 18 percent.

A similar effect was seen early last year when a tariff threat from the Trump administration caused a spike in trade as resellers and buyers alike tried to buy up boxes and get them through customs before the cost of imports jumped.

The memory supply shortage and the rising cost situation is &quot;unprecedented,&quot; said Lenovo chief Yang Yuanqing, speaking on an analyst call to discuss its earnings.

&quot;DRAM cost increased by 40 to 50 percent last quarter, but the current quarter versus last quarter almost doubled again, even with the contract price. So this structural imbalance between supply and demand is not simply a short-term fluctuation. It&#39;s likely to have a prolonged impact on the industry throughout this year,&quot; he stated.

On the other hand, a volatile market could become an opportunity for Lenovo, Yuanqing added. Lenovo&#39;s view is that high material costs will likely constrain demand for PCs and smartphones later in 2026, &quot;but that&#39;s just from a unit volume point of view,&quot; he said.

&quot;Given the higher pricing and the market shifting to the premium segment because of AI PCs, we believe the overall PC revenue market will still grow year-over-year.&quot;

In other words, available devices will carry a higher price tag, cushioning lower shipment volumes.

CDW, one of the world&#39;s largest resellers, also forecast stronger hardware growth in the first half of this year as many buyers bet that bumping purchases forward will avoid higher prices.

&quot;We believe to the best of our ability that we&#39;re going to see about the same amount of pull forward in Q1 or slightly more than we actually saw in December,&quot; president and CEO Christine Leahy said during CDW&#39;s recent earnings call.

&quot;When you think about the various products, I would just tell you that PCs for us, for example, have been strong. We&#39;ll probably see decelerating growth this coming year, but we still see strength as we explained in our prepared remarks. It might be a little choppier during the course of the year as a result of memory, but we still see strength there.&quot;

Analyst Omdia said PC shipments in Q4 2025 were higher than forecast due to a significant amount of pulled forward demand from the channel.

On average, mainstream PC DRAM and SSD prices jumped by nearly 100 percent and 40 percent respectively during 2025. Omdia forecast a rise of another 60 percent for DRAM and 70 percent for flash memory this quarter alone.

The memory crisis is likely to be a prolonged situation where consumers and enterprises will eventually have to adjust to the new higher price points, rather than expect a quick return to previous levels.

The PC market could see a 10 percent shipment decline, Omdia warns, shrinking back to 2023 levels, with the risk of a 15 percent decline if all the costs are passed on to buyers. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-46')">
            <div class="source">The Register</div>
            <div class="title">NASA pauses most Swift science ops to buy time for reboost mission</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-46" style="display:none;">
            <h2>NASA pauses most Swift science ops to buy time for reboost mission</h2>
            <p><strong>The Register | 2026-02-12</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2026/02/12/nasa_swift_reboost/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">NASA has ended most science operations on its Swift observatory to keep the spacecraft in orbit a little longer.

The 21-year-old observatory&#39;s altitude has now dropped below 250 miles (400 kilometers) - it needs to sit above 185 miles (about 300 kilometers) to maximize the chances of an anticipated reboost mission.

&quot;Normally, Swift quickly turns to view its targets – especially the fleeting, almost daily explosions called gamma-ray bursts – with multiple telescopes,&quot; said principal investigator S. Bradley Cenko at NASA&#39;s Goddard Space Flight Center. While the Burst Alert Telescope will continue to detect gamma-ray bursts, the spacecraft will no longer slew to observe targets with its other telescopes.

Stopping the slewing and leaving the spacecraft in an orientation to minimize atmospheric drag will reduce the rate at which Swift&#39;s orbit decays until a reboost mission is launched – currently anticipated for the summer.

NASA awarded Katalyst Space Technologies a contract in 2025 to raise the orbit of the spacecraft. At the time, the expectation was an orbit boost in spring 2026. In November 2025, Katalyst confirmed it would use an air-dropped Pegasus XL as the launch vehicle for a June 2026.

The Register contacted Katalyst for comment.

Swift is expected to re-enter Earth&#39;s atmosphere in 2026 unless reboosted. The spacecraft&#39;s science payload remains operational, but a reboost is required to keep the data flowing.

Swift&#39;s prime mission duration was two years and it had an expected orbital life of seven years. It has far exceeded both milestones and remains operational. However, it is now significantly below its original altitude [PDF] of 373 miles (600 km). This makes it an ideal candidate for a reboost, which, if it goes to plan, will demonstrate a useful capability and extend Swift&#39;s already impressive lifespan.

The spacecraft is showing its age. It fell into safe mode several times in recent years due to reaction wheel problems and gyroscope issues. The team was able to recover the spacecraft, and in 2022, discussed observations continuing into the 2030s. However, expansion of Earth&#39;s atmosphere during periods of increased solar activity has accelerated orbital decay, necessitating a reboost.

Cenko said: &quot;We anticipate the reboost mission to launch in the summer, so we&#39;re transitioning operations now to give it the best margin we possibly can.&quot; ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-47')">
            <div class="source">The Register</div>
            <div class="title">Supply chain attacks now fuel a 'self-reinforcing' cybercrime economy</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-47" style="display:none;">
            <h2>Supply chain attacks now fuel a 'self-reinforcing' cybercrime economy</h2>
            <p><strong>The Register | 2026-02-12</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2026/02/12/supply_chain_attacks/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Cybercriminals are turning supply chain attacks into an industrial-scale operation, linking breaches, credential theft, and ransomware into a &quot;self-reinforcing&quot; ecosystem, researchers say.

In its latest trends report, Group-IB reckons individual strikes that lead to broader downstream compromises of businesses are now interconnected as cyberbaddies pursue multiple methods to breach vendors and service providers.

Supply chain hacks like the recent Shai-Hulud NPM worm, Salesloft debacle, or the OpenClaw package poisoning are fast becoming the primary goals of the criminal fraternity who try to exploit the inherited access to a victim&#39;s customers.

&quot;Open source package compromise feeds malware distribution and credential theft,&quot; the research states. &quot;Phishing and OAuth abuse enable identity compromise that unlocks SaaS and CI/CD environments. Data breaches supply the credentials, context, and relationships needed to refine impersonation and lateral movement. Ransomware and extortion arrive later in the chain, capitalizing on access and intelligence gathered earlier. Each stage strengthens the next, creating a self-reinforcing cycle of supply chain exploitation.&quot;

Over the next year, GroupIB predicts supply chain attacks will be executed faster thanks to AI-assisted tools that can scan for vulnerabilities across vendors, CI/CD pipelines, and browser extension marketplaces at machine speed.

It also expects to see traditional malware replaced by identity attacks, whereby criminals set themselves up as genuine users and their activity blends into the normal daily business functions, evading detection for longer periods.

Platforms offering HR, CRM, and ERP, as well as MSPs, are high-priority targets, Group-IB says, as a single compromise can lead to hackers gaining access to hundreds of customers.

The Salesloft breach, as well as the Oracle compromise of March 2025, are examples of how data breaches are shifting from a single-reward model to one where access is used for additional compromises.

Instead of taking one big wedge of data and demanding an extortion payment, criminals took their time to collect OAuth tokens and exploit misconfigured partner connections to move laterally. They then target downstream customers, steal their data and contact lists to repeat the cycle, or, in cases involving NPM and similar ecosystems, serve malicious updates to users to carry out fraud at scale.

&quot;Cybercrime is no longer defined by single breaches. It is defined by cascading failures of trust,&quot; said Dmitry Volkov, Group-IB CEO.

&quot;Attackers are industrializing supply chain compromise because it delivers scale, speed, and stealth. A single upstream breach can now ripple across entire industries. Defenders must stop thinking in terms of isolated systems and start securing trust itself, across every relationship, identity, and dependency.&quot;

Organizations should treat third parties as extensions of their own attack surface.

&quot;Strategic investments in supply chain threat modeling, automated dependency checks, and data flow visibility are no longer optional – they are foundational to modern security architecture,&quot; said Volkov. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-48')">
            <div class="source">The Verge</div>
            <div class="title">How Gorilla Tag is weathering the VR winter</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-48" style="display:none;">
            <h2>How Gorilla Tag is weathering the VR winter</h2>
            <p><strong>The Verge | 2026-02-12</strong></p>
            <a class="original-link" href="https://www.theverge.com/column/877473/gorilla-tag-vr-winter-quest">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">﻿The popular VR game is breaking audience records, all while its makers are working on a mobile offshoot, a TV show and a Gorillacon live event.

﻿The popular VR game is breaking audience records, all while its makers are working on a mobile offshoot, a TV show and a Gorillacon live event.

This is Lowpass by Janko Roettgers, a newsletter on the ever-evolving intersection of tech and entertainment, syndicated just for The Verge subscribers once a week.

The VR industry has been on edge since Meta’s massive job cuts earlier this year: One exec called the layoff announcements “one of VR’s darkest weeks.” There’s talk of a VR winter, and multiple VR studios have conducted significant layoffs of their own.

For Gorilla Tag maker Another Axiom, however, it’s monkey — or monke, as they’d say — business as usual. The most popular game on Meta’s Quest VR headset reached a new audience high this past weekend, when 119,000 players joined its five-year anniversary event in-game at the same time.

“We broke the world record, as we understand it, of concurrent players in VR,” says Another Axiom chief marketing officer Jake Zim. (Social VR app VRChat boasted 150,000 concurrent users over New Year’s, but that number included people who accessed its 3D worlds on flat screens).

It’s not just special events: Gorilla Tag attracts up to a million VR users every day. Most of them are Gen Alpha, and they all battle each other in chaotic games of tag, powered by its unique style of arm-swinging locomotion. The free-to-play game frequently leads the bestseller charts of Meta’s Quest store. The game’s characters, known as monkes, have become so popular that Another Axiom regularly sells out of plush toys; total merch sales have reached close to $10 million, according to Zim.

“The fandom is bigger than just VR,” Zim tells me.

That’s why Another Axiom now has plans to expand beyond headsets: The company is working on a mobile game, a live event, and even a TV show. “We believe that the lore and the world of Gorilla Tag can tell so many stories,” Zim says.

Of course, there is a flip side to those planned expansion moves: Five years in, and with no bigger titles to catch up to, execs at Another Axiom are acutely aware that there may be a ceiling to VR, and that Meta’s cutbacks are clouding the medium’s future. “VR as an ecosystem is very challenged,” Zim admits. “With all the changes at Meta, this is a transition moment at best for VR.”

A transition moment that arguably caught Meta itself by surprise. For years, the company bet on gaming, fitness, and social VR to take headsets mainstream. Some of those efforts arguably worked: Meta sold millions of headsets. The Meta-owned VR rhythm game Beat Saber surpassed $250 million in revenue in 2022, and several other VR games, including Gorilla Tag, have since seen their revenue numbers top $100 million (“We’re significantly beyond that,” Zim tells me without providing further details).

But Meta’s bet on its Horizon Worlds metaverse arguably fell flat, and many AAA VR games have seen their audiences dwindle, leading Meta to close several internal VR studios. Instead, VR has seen a massive influx of younger players who prefer chaotic free-to-play titles over polished and more expensive single-player games. And while many of these younger players have picked up Meta’s entry-level Quest 3S headset, overall audience growth has happened “less quickly than we had hoped,” as Meta CTO Andrew Bosworth recently told Alex Heath.

All of this has led to significant changes even beyond last month’s layoffs. Meta is shifting some of its massive Reality Labs spending toward AR and wearables and has reportedly delayed a lightweight headset optimized for video viewing. Third-party headsets from Lenovo and Asus have been canceled, and Horizon Worlds development resources are being redirected toward mobile gaming.

Zim would still like to believe that there is a silver lining to all of this. “Pulling back on [Horizon Worlds] and allowing what essentially is an indie, third-party app market to exist is a good thing,” he says. At the same time, he knows that a lack of cash infusion from Meta could lead to a talent drain. And if the company decided to not release any subsidized, affordable headsets in the future, it could further hamper the VR industry.

“2026 is this bridge year,” Zim tells me. “It’s not just [about] surviving, but figuring out how to speak directly to your audience, and put your audience into places that make sense for a business.”

For Another Axiom, that also means looking beyond the headset. The company hired former Scopely executive Austin Ashcraft as its GM of mobile last year, with Zim telling me that “getting onto platforms that are not VR is a massively strategic, important thing for us to do.” Those efforts may not stop at mobile. “We’ve been working on a variety of different, unique versions of the game that really hold the IP and what’s valuable about it sacred, but put it into formats and on media where it’s going to make sense,” he says.

Last summer, Another Axiom also hired Michael Vogel, who previously worked on animated shows like My Little Pony and Strawberry Shortcake at Hasbro and WildBrain. “We will make a TV show,” Zim confirms. “We are working on that.” He declined to share further details, but added that the company has been producing its own in-house web shows for YouTube for some time. “We’re getting tens of millions of views on our owned-and-operated channel,” he says.

Another Axiom is also experimenting with new business models, and launched a subscription for superfans this month. And finally, the company is going ahead with plans to hold its own real-world event dubbed Gorillacon — something Zim cheekily teased as a possibility on LinkedIn a few days ago.

“We knew the fans wanted it,” he says. “It’s going to happen.”

Zim again declined to share additional details — but if you’ve ever spent any time inside the chaotic world of Gorilla Tag, you’ll know that it’s probably going to be bananas.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-49')">
            <div class="source">The Verge</div>
            <div class="title">The surprising case for AI judges</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-49" style="display:none;">
            <h2>The surprising case for AI judges</h2>
            <p><strong>The Verge | 2026-02-12</strong></p>
            <a class="original-link" href="https://www.theverge.com/podcast/877299/ai-arbitrator-bridget-mccormack-aaa-arbitration-interview">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Bridget McCormack of the American Arbitration Association on AI-powered courts and the future of law.

Today, we’re going to talk about the role AI might play in deciding legal disputes. Not just drafting memos and doing research — actually deciding who’s right and who’s wrong, and who should pay.

My guest today is Bridget McCormack, the former chief justice for the Michigan Supreme Court and now president and CEO of the American Arbitration Association. The AAA has been around for exactly 100 years and is the country’s largest nonprofit arbitrator.

You’ve probably heard of arbitration before. It’s is a form of dispute resolution that allows two parties to resolve conflicts outside the formal court system using a third, neutral party — the arbitrator — to negotiate a settlement.

Verge subscribers, don’t forget you get exclusive access to ad-free Decoder wherever you get your podcasts. Head here. Not a subscriber? You can sign up here.

You may have never found yourself in arbitration, but you’ve almost certainly signed an arbitration clause, in one of the many contracts and terms-of-service agreements that all of us have to sign all the time. Arbitration can be much faster, cheaper, and easier than going to court, so it’s become a favored way of resolving disputes between businesses. It’s also, as it turns out, how many employers and large corporations defend against lawsuits, because they can sneak an arbitration clause into the agreements for everything from cellphone service to smart washing machine features or even your employment contract, which can protect them down the line from class action claims.

Arbitration is everywhere in our legal landscape, so you can see why an organization like the AAA would want to make it faster, cheaper, and more predictable. For the past several years Bridget and her team have been developing an AI-assisted arbitration platform called the AI Arbitrator, and it’s now available for use in very specific cases — construction disputes that can be resolved entirely on the basis of written documents. As of right now, the AI Arbitrator now has officially one case on its docket.

I’m obviously fascinated at how all of that might work, but you’ll hear Bridget and me really dig in here on what this kind of automation means not just for arbitration, but also the bigger, more fundamental idea of seeking justice, and whether or not our legal system feels fair.

Americans’ trust in the judicial system reached a record low in 2024, and you’ll hear Bridget and me go back and forth on whether a system driven by AI can actually help people trust these systems more simply by making each party feel heard and showing its work, something you often don’t get from a human judge.

At the same time, AI systems are AI systems. They’re new, brittle, and hallucinate facts and dates. It feels like there’s real danger in handing this kind of power to such a new, and unpredictable, technology. So you’ll hear Bridget discuss where she thinks the lines should really be drawn, how she’s trying to head off some of the big concerns around AI, and where she sees this going in the future.

Again, Bridget was the former chief justice of the Michigan Supreme Court; she was in charge of all the judges in her state. You’ll hear her say several times that people are unreliable. By the way, if you want a broader look at all of this, Verge reporter Lauren Feiner actually published a fantastic feature on AI in the legal system last month, and I highly suggest you go read that if you’re interested in learning even more.

Okay: Bridget McCormack, the president and CEO of the American Arbitration Association, on the AI Arbitrator. Here we go.

This interview has been lightly edited for length and clarity.

Bridget McCormack, you’re the president and CEO of the American Arbitration Association. You’re also the former Chief Justice of the Michigan Supreme Court. Welcome to Decoder.

You and I were on a panel a while ago. You were talking about rolling out AI in arbitration. You were also talking about your history overseeing judges in Michigan, which was very funny. I’m very excited to talk about all of that with you.

I just want to start at the very beginning. I suspect you and I are going to end up talking a lot about commercial and business disputes. There’s a lot there to discuss in the context of AI and arbitration. Most people’s experience of arbitration is that they just sign a contract.

You were the Chief Justice in Michigan; you oversaw the literal legal system in that state. American Arbitration Association is 100 years old, so now you oversee a 100-year-old dominant provider of arbitration. Explain to people what the difference is.

It’s a great starting point. The thing about being the Chief Justice of the Michigan Supreme Court is that, like every state Supreme Court, the Supreme Court of Michigan has administrative oversight of all the courts of the state. When you’re the chief justice, you’re kind of the CEO of the public dispute resolution system that most people are stuck dealing with, if they need a little justice or if somebody wants a little justice from them.

Like other leadership roles, I had a leadership team and another 300 or so staff of folks who reported up to the leadership team. And it was our job to try and figure out how to improve the experience of people across the state of Michigan who had to go to their local courts because of some legal problem. It’s an enormous change management job for lots of reasons that are not true in my current job.

The thing about running the public dispute resolution system, like the state court system, is that your funding isn’t based on how well you do. You can’t perform well one year and have extra revenue for R&D. You have to walk over to the legislature and convince some brand-new representative from Leelanau County that online dispute resolution is really going to increase access to justice. You literally have to pick off legislators from around the state to try and fund what you know is going to be a better way of doing business.

At the same time, there are the judges across the state in Michigan, and there are approximately 1,000 judicial officers. I say that because in addition to judges, there are magistrates that report up. They’re all separately elected and they work in counties that have their own funding systems. So they’re partly funded by the state and they’re partly funded by their county.

The counties across Michigan are differently resourced, right? Some counties have a larger tax base than others, and they have a bigger budget to work with. So convincing separately elected judges with different budgets that we’re going to do business a certain way going forward is super complicated. It’s a very fun change management problem.

The AAA, on the other hand, is basically a court system, but a private court system, although I should say at the top, the AAA is a nonprofit. We’re a fee-for-service nonprofit, but we’re a nonprofit. We’ve been administering alternative dispute resolution arbitration, but also mediation and any other alternative process parties want, for 100 years as of last Thursday. So we’ve been doing it for a long time and we have administered over half a million cases a year for the last few years, and not just domestically but also in cross-border disputes.

Most of them are B2B commercial disputes, but there are also B2C cases, employment consumer cases, and a growing number of self-represented parties. A lot of small and medium businesses, as I’m sure you know, can’t afford legal help. They’re legally naked. And so arbitration is an easier way for them to manage disputes.

I want to talk about the difference between a private dispute resolution system and the public dispute resolution system for one more second. But first, actually, you just said something. I’m so curious about it. It sounds like, as the Chief Justice, you had a role advocating for the court system with the legislature, inside the justice system.

Most people never hear about that and never think about that. What was the split in your time? How often did you have to spend time just saying, “Hey, can you pay for the courts?” versus actually being the Chief Justice?

I would say the administrative part of the job was significantly more than half compared to the decisional part of the job. It’s an enormous job.

Michigan adjudicates between 3 and 4 million cases a year, and like every other state court, a majority of people who go to court to have cases resolved can’t afford lawyers. This is the primary place people interact with their government. The kind of justice we deliver, the quality of justice we deliver, it’s pretty important to, frankly, the rule of law and trust in institutions. I think it’s one of the most important jobs in government.

I’m curious about that because it feels like the experience you had there really leads to your perspective on how and why AI should enter the legal system.

The reason I’m starting here with your previous experience and not your current job is—I encounter this on our show and on our site all the time—that people think the legal system is deterministic. Particularly our audience, the tech audience, thinks the legal system is a computer. You can feed it inputs and it’ll API access the law, and then you’ll get some predictable outputs. I’m always trying to convince people that that’s not the case. Even hearing you talk about the politics of running the legal system underlines for me that the legal system is absolutely not deterministic. Should it be?

Because you’re the first person I could just like straightforwardly ask that question to. Should the legal system be more predictable and deterministic?

It absolutely should be, at least in a majority of cases. In fact, if it were more deterministic, we would have fewer disputes, right? It’s because it’s probabilistic—and I agree with you. It is, for the most part, because it’s run by humans. You’ve met humans, right? They’re flawed.

And therefore it isn’t always predictable. If it were more predictable, we would be a more efficient and effective system. We’d avoid a lot of disputes because people could plan their business around what, in fact, the rule was going to be, and how it was going to be enforced, and how they could count on it being enforced. In my view, that’s true for most cases for which there is a rule of law, and we know how it’s been interpreted historically, or at least how it’s been correctly interpreted historically by the majority of courts.

There are always going to be new frontiers in legal. Cases where courts are having to decide how to interpret a new statute. Courts are going to have to figure that out for the first time. That’s not going to be able to be deterministic. It could get better and better, frankly. I think AI could do a very good job at the front end of statutory drafting, in making sure there was less ambiguity in statutory terms. AI could impact that. But there are even still modern questions about historic provisions in statutes and the constitutions, state and federal, that we have entrusted judges to decide. So I don’t think it can all be deterministic. I think an awful lot could be, and it would improve the way the law operates.

Where do you think that the source of uncertainty in the legal system, as people experience it today, comes from? Is it just that most people can’t afford a lawyer? Is it that some percentage of judges are just weird old guys? Where does that come from?

I don’t think there’s a single answer. I do think it’s relevant that 92 percent of Americans can’t afford help with their legal problems, and that’s not just individuals in the kinds of cases individuals end up going to court for. It’s also true for all small and medium businesses. For the most part, they can’t afford lawyers.

So there’s an awful lot of trying to navigate legal risk and legal problems without lawyers, and that’s complicated. That’s very complicated for judges. Judges who are managing large dockets with many parties without lawyers try and do their best to work their way through those problems, but it’s not easy. We have a legal system run by humans and humans are imperfect and busy.

I want to be very clear that there’s a big difference between state and federal courts, right? So 95 to 96 percent of cases are heard in state courts, not federal courts. The federal courts do a much smaller number of cases, and generally have—not better, but larger—staff to help them. State courts are managing most disputes with fewer resources and doing the best they can. But if you look at the rate of reversals by appellate courts, by intermediate appellate courts and state Supreme Courts, they’re getting a lot wrong, right? Humans get things wrong for lots of reasons.

What you mean by that rate of reversal, just to unpack that, is that someone goes to court, a state court judge decides there’s an appeal, which costs money, and that goes up to an appeals court, and the appeals court is overturning that judge. You’re saying that rate’s going up or that rate is too high?

I don’t know if it’s going up. I could probably figure that out, but I don’t know that off the top of my head. It is a fact that it’s quite high. The number of cases where an appellate court reverses the work of a lower court is not a low number. It’s going to be different from state to state and different in the federal appellate courts, but you can benchmark it and it’s not an insignificant number.

I like to use this example. I ran a non-DNA innocence clinic two careers ago, and we know a lot about the rate of wrongful conviction as a result of the DNA exonerations over the last, I don’t know, 30 years at this point, because there’s a database now, and we’ve been able to learn both the rate at which mistakes are made—sometimes they’re made by juries, but often they’re made by judges—and the kinds and qualities of the errors that lead to those mistakes.

It’s a shocking number. The wrongful convictions tell us that in 3 to 5 percent of cases, there was an error made. And you might think, “Oh, that’s kind of a low number.” If you’re shooting free throws then probably it is a low number, but if you’re landing planes, not a great number, right? And I think the criminal justice system should be more like landing planes.

The reason I’m starting there is, and I think you perceive this as well as I do, that the lack of faith and trust in our institutions is kind of pervasive across American society. The legal system is just part of it now, right? Especially if you show up and you don’t have a lawyer, you don’t have the money, and then it is a weird old guy as the judge, and then you’re looking at the statistics and they’re probably wrong, but you can’t afford to appeal. Or you’re just reading the headlines every day. It just feels like there’s more chaos in the formal legal system than ever.

I wanted to start there, because I do feel like the lack of faith in our corporate institutions is equally high, and most people’s experience with arbitration is, “Well, I just need cell phone service. I’m not going to read this contract or these 15 contracts to get cell phone service.” And there’s a line here that says, “Well, I can’t even sue AT&T if they get something wrong. I’m going to end up in arbitration and that arbitration is obvious. Of course, it’s just going to be against me. There’s nothing I can do. I’m just signing away my rights.”

How do you feel about that in this context? Because that feels like as big of a problem as anything.

So let me unpack a couple of things you said. I completely agree about the declining trust in institutions, and that the courts are part of that problem. In fact, the National Center for State Courts tracks that. And I think their data shows declining trust in the courts. Frankly, that trust is declining faster in the federal courts than the state courts, but even the state courts are struggling with that. I happen to believe that the way most Americans are locked out of our formal justice system is as important to that declining trust as any other factor, and there are other factors.

But like any other public good, imagine if we said, “If you want to drive on the highway, you can do that, but you have to hire a driver.” Or, “Oh, you want to register your kid for public school? No problem. It’s a public good, but you’re going to have to hire a special person who will go and sign you up for public school, because otherwise it’s in Latin and you can’t understand it.” We would never accept that, but we accept that most Americans are locked out of their formal justice system because—and I don’t know why—but we set up a legal system 250 years ago and the legal profession is better than any other at avoiding any disruption.

But to the second part of your question, I do think that there has been a narrative that if your consumer contract—whether you bought an appliance or a cell phone, or sometimes employment contracts designate arbitration as the forum for resolving disputes—that that must mean this is not going to go well for you. In fact, the data that we have is that people are far more likely to actually get a hearing and get some award when they navigate an arbitration process than when they navigate a court process.

The reason for that is probably obvious. If you have to navigate a court process, but you can’t figure it out, that’s really complicated. In arbitration, we can make resources available to parties who are representing themselves, and we do everything remotely and make it easy for people to actually navigate it. So cases are far more likely to actually go to a hearing and more parties are heard in arbitration than they are in courts, but that perception definitely is out there.

It may well be the case that there are other providers that have fewer resources for self-represented parties or aren’t as focused on it. At the AAA, we actually require businesses that want to put our clauses and contracts to file those contracts with us, and they have to satisfy our due-process protocols. And I’m not sure that’s true of every organization. Many are for-profit and that is probably an issue in other places.

I’m starting with this issue of fairness, because when you automate the systems, all of the things that make things feel fair or unfair get heightened, or magnified, in very specific ways. I just want to ask one more question here, and then I do want to go into why we should automate some of these systems. The idea that just getting a hearing and some outcome is substantially more fair, I feel like we could unpack that for another week.

There’s a reason these companies want to not be in the formal justice system. They don’t want precedent for the awards that they’re made to give to the parties that come and sue them. They certainly don’t want it in the public record that any of these things ever happen. They don’t want discovery, and all that stuff you don’t have to do in arbitration. So maybe it’s easy to participate in, but there’s still a benefit to them that accrues over the long run. How do you balance that out?

That’s not true of employee arbitration. Those cases are reported. So they actually do have to live with those results. And it may well be that for some businesses, they’re choosing arbitration because it’s a more efficient way for them to resolve disputes. I don’t know. You see them going back and forth between arbitration and litigation. I think Amazon recently wrote litigation back into—maybe not all, but a lot of—their consumer contracts. I’m not going to speculate about why, but I think parties are always thinking about what the best forum is.

There’s a robust literature on procedural fairness and procedural justice that goes something like this. And I won’t waste time on the details of it, but if parties feel like they were heard and that they understand the process, they understand what happened and why it happened—in other words, if the neutral [party] deciding the dispute can explain it to them—they’re far more likely to grow trust in institutions. It used to be a sort of a big deal in training judges. We would remind judges how important it was that people feel heard. And even if you’re going to rule against them, they will take bad news for them and still grow trust in the institution, if they feel heard and understood and they understand what happened.

That matters because today’s parties are tomorrow’s witnesses and tomorrow’s jurors. You want to grow trust. In every case, usually one person is disappointed. That’s just how disputes go. But I don’t know if you’re right. I’m not sure I agree with you that getting some award isn’t important. There’s data from a bunch of arbitration scholars, or really dispute resolution scholars, who did some recent work on employment arbitration, and the number of cases that just get summaried out in court, where an employee has a claim or believes she has a claim against her employer, is quite high.

That’s maybe not surprising to you, but that just simply doesn’t happen in employment arbitration. In arbitration, you’re far more likely to actually get to go tell your story. So I’m not sure I agree with you that there’s a clear fairness narrative, based on the facts.

The one thing I will definitely say here is, in my mind—we cover big tech companies, and I’m just thinking about the clauses that everybody has to sign in their terms of service agreements, and you’re obviously thinking about employment arbitration, and they’re wildly different universes.

Something we could spend another week on is how I think terms of service agreements should be illegal. But that’s a different podcast for a different time, maybe with more booze.

You mention that people just feeling heard leads to trust. I think that is the transition I want to make to AI. You mentioned that idea to me the first time we spoke about this, and I’ve been thinking about it ever since. If there’s one thing an AI system can do, it is just making you feel heard. In every positive way that that can happen, in a startling number of new and, quite frankly, shockingly negative ways, the AI systems will just listen to you, over and over and over again.

Is that something, as you have developed the AI arbitration system, that you’ve leaned into? Is that the heart of it? Because if that technology can do one thing, it is just listen to these parties until they’re done.

I do view it as a significant advantage of an AI dispute resolution system, and we can talk more about when that’s appropriate and when it’s not. I don’t think every dispute should go to an AI dispute resolution system, but [rather] when parties prefer it. For me, at the front end of what we built, which is a very narrow product right now, I undervalued it and underappreciated it.

At the front end of our AI arbitration process—which is really a series of agents that operate across the process on the back end, even though the parties are interacting with one—the agents take in the party’s complaints and whatever pleadings they’re filing and whatever evidence they think supports their claims, and then a series of agents parses the claims, the elements of each claim, the evidence that may or may not support each claim, what the parties believe supports each claim, and the legal framework that surrounds it.

And then it goes back to the parties and says, “Here’s my understanding of what the claims are, what your claims are, party A, and yours, party B, and what the elements are and what the evidence is and what the legal framework is. Did I get that right?” And the parties get to say, “You did.” Or, “No, you didn’t. You missed this one element or this one claim, or the fact that this evidence supports both of these claims, not just one.” And then it goes to work again. The agents go back until the parties are satisfied that they have been heard and understood.

Maybe we could do that in courts, but we would have to spend a whole lot more money. Imagine if judges in trial courts, or even in appellate courts, did that. In appellate courts, you file briefs and then you wait by your computer for months and months and months to see when some white smoke emerges from the State Supreme Court building, and then you get a decision, and the decision may or may not have even addressed all of the issues that you raised. That happens all the time. I reviewed 2,000 cases a year, 2,000 applications a year, when I sat on the Michigan Supreme Court, and I can’t tell you how in many of them, the intermediate appellate court didn’t even rule on issue number three. They just ignored it, and we just want an answer.

So imagine if courts could do that. Imagine if trial judges or appellate judges could pull the parties in and say, “Here’s my understanding. Did I get it right?” And then we could actually be satisfied that they did. That’s probably not going to work in our bespoke, built-for-18th-century-norms system, but it can work for disputes in an AI dispute resolution system.

So let’s talk about your actual product. Right now, I think it’s just for documents-only in construction disputes, right? That’s where the product is.

Describe why you picked that, and then walk me through step by step. How do you use this thing? Is it an app? Is it a website?

Yeah, it’s a website. Although I assume we will have an app version of it, and we have an app version of all of our services. You can log in on your phone, but you’re logging into the case management system. So really it’s two things. We built an AI-native case management system for the AI arbitrator to operate on. That effort is time well spent because it’ll replace our legacy case management system for all disputes within two years. That’s going to be something everybody has an opportunity to benefit from, because it saves time and money.

But the AI arbitrator is, like I said, a bunch of different agents—probably 20, sometimes more, depending on the complexity of dispute—that operate across the arbitration process. A bunch operate at the front end. We talked about those, that are parsing claims and organizing arguments and organizing claims, making sure the party is satisfied. And then there’s a bunch of reasoning agents, and those reasoning agents take the summary of the dispute that the parties are satisfied with and start reasoning across it. And then there are agents that do a draft award.

There’s a human in the loop throughout. In the beginning, it’s the parties. They are the humans that are making sure that they’re heard and understood. Then we have a cohort of construction arbitrators who serve as the human-in-the-loop arbitrator for the reasoning and award drafting. It’s the human arbitrator who ultimately issues the award, and she makes any changes that need to be made so that she’s comfortable with the award.

We started in construction because we have a long history with the construction industry, and a very good relationship with the lawyers and parties and arbitrators in that industry. It’s an industry where arbitration is important because, as you know, in any big project, there are always going to be disputes, and if you have disputes along the way, you don’t want your project ground to a halt. You want to be able to keep going. So they need speed and efficiency. They’re not in it for confidentiality. They just need to be able to continue to move forward.

It’s also an area where AI is already impacting the underlying business. The construction sites are being infiltrated with AI that’s making what they do significantly faster and better. So it’s an industry that we knew would be open to it. We do so many of those cases that we had a good library of documents-only construction cases that we could ground our agents in. Our agents are ultimately operating off a handbook, but we were able to build that and train our agents on those historical cases, and with the cooperation and in collaboration with a bunch of our construction arbitrators and lawyers.

So it was the right place to start because we knew they’d want it and we could work together with them.

Let me ask you a really dumb question. What does a documents-only construction dispute look like?

It could be a lot of things. There are a million different ways it shows up, but [for instance] something was supposed to be completed on a certain timeline and wasn’t. And who’s responsible for that delay? There might be supplier disputes. There are all kinds of disputes that happen in the course of a construction project that don’t need testimony. You can decide those completely on the paperwork. And that was also important for us in starting this. In the first offering of an AI arbitrator, we were not prepared to have witness testimony evaluated by agents. That might come one day, but we’re not there today.

So you ordered the pallet of steel beams. It had a delivery date on it. They showed up. You can mark the delivery date and you can say, “Okay, that’s obviously later than what we said. You owe me some money…”

“And here’s what the contract says about why that should have happened, but here’s my response.” And then it’s pretty straightforward, like many disputes are, honestly.

I 100 percent feel like I’m a first-year law student back at the University of Wisconsin right now, talking about construction litigation and contract disputes in this way. So you had the library of previous arbitration in cases that looked very similar to this. You obviously have the experience and the history with the industry?

Did you have the software engineers you needed to build this? How did that work? Did you go hire out to do that?

Did you hire in? Where did this come from?

It’s a great question. We started transforming our operation in early 2023. I took this job in September of 2022, but I didn’t start until February 2023. And everybody knows that in November of 2022, we all thought, “Oh wow, what’s happening?” I spent most of my six weeks off learning everything I could about large language models, and trying to figure out what it was going to mean for the legal profession and therefore our little subset of the legal profession.

I was convinced it was going to be extremely impactful. Like you said, it can make people feel heard, and that’s a wake-up call for any dispute resolution provider. That’s obviously going to have an impact. When I got to the AAA, we gave everybody enterprise ChatGPT licenses—and I mean everybody, not just our engineers, but also our caseworkers and our legal team and our marketers, because I think with any general-purpose technology, you need the domain experts to figure out where it’s going to impact them.

We started building point solutions. Our AI engineers were not historic AI engineers, but like everybody else, they learned pretty quickly, and so we do have a very talented set of AI engineers. With this particular product, we built it with a partner. We did Copilots, and we built it with Quantum Black. Quantum Black is McKinsey’s AI team.

I don’t know exactly—I’d have to ask Diana [Didia], my Chief Information Officer—but for the first four or five months, the Quantum Black engineers sat in seat one and ours sat in seat two, and then they swapped for the last five months of it. So our team then was driving, because they left after we delivered the [minimum viable product], and now we’re already building out the next products that are built on the same architecture.

I feel like it’s another full hour Decoder on McKinsey giving its AI team a cool name. We’ll set that aside as well.

[Laughs] I’m super interested in that one. Have me back for that one. I’m really interested in it.

“It’s got to be really cool, you guys.” So you have the system now, you have the platform and the frameworks. As you know better than anybody, how the platforms and frameworks are built in the beginning has a pretty big effect on where they end up.

Even just talking about witness testimony. Now there’s a dispute on, “Did it happen before midnight or after midnight?” And you need the loading dock operator to say, “Actually it was the next day. This document is wrong.” Did you build a system that can take witness testimony?

It can take witness testimony as long as it’s in written form. You may or may not know this—I didn’t until I started in this job—but a lot of arbitration disputes have written witness testimony. In fact, in most cross-border disputes, that’s how they take testimony. It’s literally affidavits or just written expert reports. More and more in American arbitration cases, it’s depositions. So it can do that, but it’s not going to, say, have a witness show up on Zoom and we’re going to listen to them and see if we think they’re telling the truth or they’re twitching a little in their eye, and so therefore we know they’re lying. It’s not doing that.

Does it kick that back to a human arbitrator anywhere in this system right now? Does that mean that’s what you would have a human arbitrator do?

We do. There’s a human arbitrator assigned to the case from the beginning, and anytime the parties want the human arbitrator to come in, the human arbitrator is ready and willing to come in. And you’re probably right that there’ll be some cases where, along the way, the parties will decide that they need testimony that they didn’t think they needed at the front end of the case. That’s probably going to be a case where the human arbitrator takes over, because we’re not having our agents do that for now. It’s not in our roadmap today.

How many cases has the system resolved so far?

There’s one case in the system. We stood it up in November. The first case came in, I don’t know, a couple of weeks ago. Everybody was so excited. As you know, in arbitration, both parties have to have an arbitration clause in the contract that says, “We’re going to arbitration.”

For now, we will not take any case unless both parties agree. And obviously there are no businesses that have put [AI arbitration] in their contract. Well, I hope now there are because we’ve been talking to people now about it for two months, but we’ll start seeing cases once contracts start showing up that have it in their contract.

One of the things we’ve heard from a lot of parties is they’re eager to use it as an early case evaluation tool. They want to be able to run it just on their own. They want to put all of their evidence up into it and get an early case assessment about where their case is likely to go, so they can figure out whether they even want to spend any time in arbitration. So that’s actually one of the next use cases we’re building out, which isn’t very hard, based on what we’ve already built.

There’s a gap here that seems very striking to me. A party that understands it needs early case evaluation because it is a repeat player in very lucrative construction disputes, and they just need to keep moving, and the cost of the settlement is enough and they can just keep moving. That’s a pretty sophisticated actor. How do you bring all of this down to, “Well, most people can’t even access the justice system?” Is there a path?

You’re right that many larger construction projects with extremely sophisticated parties on both sides have these smaller disputes along the way, for which this tool will probably be perfect. Many of those disputes, at this point, they just think are not even worth it. Even the large parties who know how to access every dispute resolution system don’t bring them because it’s just not worth their time. And that’ll change.

This will give everybody an option to resolve every dispute. But in fact, we’re seeing—again, not yet, because nobody has it in their contract yet—but our self-represented parties in commercial and construction cases, are on the rise and have been for a couple of years. I follow our case filings day by day, and the self-represented parties in commercial and construction disputes are right now—I mean, it’s one month, so who knows, maybe it was a weird month—but January of 2026 was double what it was in January of 2025.

This system is perfect for the smaller party construction disputes. And as you know, there are also lots of smaller construction projects where people really don’t want to have to hire a lawyer to figure out how to sort it out. It’s already perfect for those disputes.

The documents-only construction case is pretty constrained, right? And things happen and there’s a lot of documentation. What’s the next one you think that is similarly constrained that you could bring the system to?

It turns out that in lots of industries, there are documents-only disputes. I was talking to an in-house litigation leader at an energy company, and they have supplier disputes that are all documents-only disputes, and it’s probably perfect for those. Like payer-provider disputes, disputes between hospitals and insurers, which are, I’m sure you know, an enormous docket. It’s probably perfect for those if you can get them both to agree.

Value of money means some people like to hold onto their money and they’re willing to have a dispute resolution process that takes a very long time, but those should be perfect for an AI dispute resolution process. We should be resolving those quickly and getting people their coverage. There’s actually an unlimited number of disputes for which this is appropriate. There are also some for which it will never be appropriate.

This is just my view, but I believe that criminal cases, cases where the government is accusing you of something and wants to take your liberty as a result of that accusation, or cases that individuals or organizations or even businesses bring against the government, should happen in public courtrooms, and with publicly appointed (or elected, if you’re in state court) judges. Those have to happen in courtrooms.

One of the things you and I briefly talked about the first time we met was the idea that there’s transparency in the state courts. There’s transparency when the government sues you and you need that transparency to build trust. You brought up the healthcare industry. There’s zero trust in the healthcare industry, and there’s a lot you could say about the consequences of the absolute lack of trust in the healthcare industry. If my medical billing goes to an AI agent, do you think that’s going to result in more or less trust?

I don’t know. It depends on the AI agent, who built it, what their audit trail looks like, and how transparent they are about showing you what that audit trail looks like. But let me go back for a minute. I said payer-provider disputes. I’m talking about disputes between healthcare [providers] or hospitals and insurance companies. Do you think there’s a lot of confidence or trust in insurance companies? Because I don’t think so.

No. Not at all. And that’s kind of what I’m saying.

Yeah. But imagine disputes between those two that could be resolved instead of taking two years. So somebody’s waiting for their insurance company to tell the hospital that they’re going to cover their treatment, and they’re dead before they get an answer. Imagine if we could just resolve those right away, but in a system that transparently shows its work and shows its audits. You tell me. My guess is some people would say, “I’ll take that tomorrow. I’m waiting for my treatment. Yes, please send my dispute to an arbitration process that is transparent and shows its work. Great.”

Yeah, some people would. As I’m sure you know, there are lots of things that happen in public dispute resolution systems or even in arbitration processes, where the results are reported, where there’s not a lot of transparency. Do you understand how judges come to the conclusions they come to? We don’t get to see the reasoning that goes on in their brain. There’s no requirement that the judge shows her work and how she got from step A to step D. What was her thought process?

Hopefully, most judges are supposed to write opinions that should show some of that, but as you know, in most intermediate appellate courts, there are a lot of opinions that are not written. And in trial courts, very often there’s no written opinion. So I always want to ask, “As opposed to what?” If you believe that the current human-led, overburdened justice system is one where people have lots of confidence, I want to introduce you to some folks who might disagree.

Look, I was told that Samuel Alito can look into George Washington’s heart and soul and determine exactly what he meant. And I’ve just been operating under that assumption for some time.

[Laughs] Yeah. I mean, there is that. So if you think that’s a system that instills confidence, maybe, but I’m not sure everybody would agree with that.

So the flip side of this—and this is us covering AI at The Verge for years now—it’ll just talk to you. And some people are very happy with that, and that is far more trust than they have in even the other people who live in their houses, right? We see that play out all the time.

The downside of that is that these systems hallucinate at high rates, they are tuned to please you, and we can see that all over the place. They work differently than humans, they layer differently. In fact, the chances of them getting something wrong are much higher, the chances of them getting something wrong exponentially increase as you stack them up in these ways.

How have you protected against that here? Because it feels like, yes, you can increase this sense of agency and trust, but the downside is this thing might just be making it up as it goes along.

Yeah, it’s a huge issue, obviously. If you were to just take your dispute, and all the documents in some dispute you’re having, and throw it into ChatGPT or into Claude, you could get a result right now, right? Anybody could do that. It might be okay. It might in some cases not make a mistake. As you know, with hallucinations, you don’t know when exactly or why the frontier models are making mistakes, but that’s not what we built and that’s why we’re moving so narrowly and so slowly.

Your system has to be governed, trained and grounded in the kind of reasoning that you’re asking it to do. So it sounds extremely narrow that we’re doing only documents-only construction cases, but there’s a reason for that. That’s where we could build a governed and harnessed agentic system. We keep a human in the loop to make sure that before an award issues, there were no hallucinations even with our governance, and we’re going to be very transparent about all of our audits, and that’s really critical to growing trust.

I think a lot about whether the frontier models get so good eventually, that they can just do this. That you maybe don’t need an institution training and governing an agentic system in a specific kind of dispute, because we move past the age of hallucinations. It doesn’t sound like that’s imminent today, but I don’t know if it’s imminent six months from now. I didn’t know last week that agents were going to be on a subreddit talking about us. I didn’t know Moltbook was coming, right? So you can surprise me.

For now, I think you have to have governed, transparent and audited systems so people can grow that trust. We have a white paper. We let an academic under the tent. John Choi is a law professor, but he’s a technologist as well. And we let him under the tent to kick the tires of what we were building, to be able to test how it performs against the human baseline. And the results are excellent. So I’m excited for folks to see that when it’s all ready to go.

But it’s an important question, again, as opposed to what? You’ve met humans, right? And you’ve met humans who are judges. If you think they’re getting it right every single time they make a decision, I want to introduce you to some folks. Anecdotal stories are kind of useless when we’re trying to talk about something important like this, but I was the Chief Justice of the Michigan Supreme Court. I was in that role for three years, and we were working on some reforms in the probate court system, and some of the probate court judges, I guess, didn’t like them. And one of those probate court judges, from a county not that far from where I live, got on his listserv and was just talking trash about me.

He said that I was at a forum and I had said a bunch of stuff and how outrageous it was. Fine, people should criticize me whenever they want. The thing was, I wasn’t at that forum. My colleague, Megan Kavanagh, who is also a white woman with an Irish name, was at that forum. And I know Megan, she probably did say those things. So I called the guy. I said, “Judge, you’ve made this claim about me on the listserv to every probate court in the state of Michigan, but I wasn’t there. I wasn’t at that forum. I have an alibi.” And you know what his answer was? His answer was, “Yes, you were.” What do you do with that? I mean, what do you do with that?

He won. I was like, “Well, I don’t know. Okay.” I mean, what do you even do with that? So if you think that the human beings, who get tired, who get hungry, who, like all of us, come to the table with cognitive biases, are getting every single thing right, then you have a lot more trust in the public justice system than I think most people do.

I don’t know that I have a lot of trust in the public justice system. What I know about those guys is that they get old and sometimes they go away. I wish more of them would go away at higher rates, but sometimes they go away. Sometimes they get replaced by newer, different people with different biases, and the system replenishes at some rate that feels like accountability. You can ruin that guy’s reputation if you would just say his name. And Bridget, I invite you to say his name out loud right here if you would.

His name was Judge… Nah, not important. Not important.

[Laughs] Nope. It was worth a shot. It was important enough for me to ask. Anyway, that’s a system that people understand about humans, right? They have reputations, they have histories, they have experiences, you can Google them. And then sometimes they die, and they just go away, you get some new ones, and at least the system replenishes and evolves.

An AI system running on a cloud service that you can’t see, on a data center that you might’ve hated being put in your community, does not feel accountable to you in that way. Maybe it’s getting it right more often on whatever metric that someone who is not you has decided is important, but you can’t actually hold it accountable. That to me feels like the biggest gap in all of these automated decision systems, that no one wants to account for because the efficiency gain is so high.

That’s a completely fair point. And again, I go back to where I believe disputes should be decided publicly, and I think that should be true no matter how excellent [they are]. Eventually, probably the judges should be using some tech to help them make sure they don’t make mistakes that will undermine accountability and undermine trust.

But not all disputes are created equal, Nilay. We all have lots of disputes, some of which we think, “Well, I don’t even have the time or the energy or the resources to get that one resolved.” But if we did, if you could really resolve every dispute, if every human being could have a will or a plan for what happens if they become incapacitated or die, if every small business could plan for the disruptions that befall every small business, we’d have a better world.

I mean, disputes are not great, right? They make a mess of economic relationships. They make a mess of personal relationships. And resolving them in fact does lead to more peace, more stability, more economic growth, if that’s your thing. Resolving disputes is good.

Right now, we do not have any way to resolve most disputes, because our one-to-one, bespoke, built-in-1776 system is no match for the kind of disputes we have today and the volume of disputes we have today, and it hasn’t been for four decades. It’s been a very long time since public dispute resolution systems have been able to address the problems in their local communities. So why wouldn’t we have more options so people could choose the right option for them at the right moment?

There would be some family disputes where parents prefer not to go to court. They want to work things out privately. They can do that now: they can go to mediation and just file a resolution. That to me seems like a good idea, to be able to offer people a way to move through a dispute so that they come out on the other side, both better with respect to each other, better with respect to the other people who are impacted by the dispute, and even feel like they were able to manage that with some agency. I don’t know why we wouldn’t want to have more options for more people, to give them agency.

My wife, as it happens, is a divorce lawyer, and I do think an AI agent of her just talking her clients through the decisions that were made a long time ago, over and over again, would actually be very helpful for her in many ways, because that seems like a lot of her job.

I understand what you’re saying there. You said this thing to me the first time we met that, again, I’ve just been thinking about it ever since. You said that several years from now—10, 20, or 30 years from now—we would think it was crazy that we ever had human judges making as many decisions as we do today.

You’ve got one case in the system. Has that born out? Do you feel that as strongly as you did when we first talked a few months ago?

Yeah. I don’t know exactly when the world turns and we’re finally able to manage lots of disputes in different ways, including with AI dispute resolution systems, but I feel pretty confident we will get there. I think I said to you at that time, and I still agree, that in some number of years, we will think it’s amazing that we let humans drive cars.

When my kids started driving, it was the most terrifying time of my life, right? Not really for them, but I couldn’t believe we were letting them out onto the public roads with all these innocent people out there driving cars next to them. At some point we’ll think that was insane, that we let people drive cars.

I think we’ll also think it was probably crazy that we thought a human being had to oversee the disputes between private parties who want to be able to move through that dispute and be at a better place. That inserting a human with her flaws and her biases and her limitations was no way to manage this railroad. Again, not for all, just for some.

One thing I’ve been thinking about throughout this conversation is who gets access to these systems? Who gets to make it feel fair? Where does the trust in the agency come from? A pervasive criticism of arbitration, broadly, is, well, it’s a service, right? It’s fee-for-service even though the AAA is a nonprofit. There are other, I would say more rapacious providers of arbitration services that do run them as for-profit businesses. You have clients. The clients have to be happy with the outcomes, and that does feel like it changes how people perceive the whole process. As you automate that, and you have big clients who are paying for lots and lots of arbitration, and they can see that the automated system is either helping them or hurting them, should that affect how people think about the fairness of the system overall, that these are fundamentally your clients and you’re building a tool for them?

This is where I feel very, very lucky that we have a nonprofit mission, and our mission is to expand access to alternative ways of resolving disputes to as many people as possible. But we’re like a court, right? We do serve parties, but there are two parties in every case. There are parties on both sides of every dispute, and we need to make sure both sides, both parties, feel satisfied with the dispute resolution process they got.

I thought you were going to say, “As the cost comes down as a result of AI automation, even for parts of disputes or full disputes, depending on the dispute, and it’s therefore harder for dispute resolution providers who need to make money, to make money on that process.” That would be a problem, and I can see how it might be. But again, I’m really happy that at the end of the year, I don’t have a bunch of owners that are looking for their profits.

We have a mission. If we can bring the friction and the cost of dispute resolution services down significantly, and therefore offer it to a whole lot more people, we’re serving our mission.

Let me just contrast that to your previous role in the state courts as the Chief Justice in Michigan. The Michigan Supreme Courts belong to everybody in Michigan, right?

No matter who the parties are, they’re yours. You’re paying taxes. You walk in and maybe they work and maybe they don’t, and maybe no one knows who was at the function saying what, but it belongs to you in some way, equally. There was recently a case where Disney said to somebody who tried to sue them in a theme park, “You signed the arbitration agreement for Disney Plus. We’re going to arbitration.” That’s pretty one-sided. That forum does not belong to both parties equally.

That imbalance seems like where the loss of trust, at least in the consumer side that I cover so much, comes from. How do you make sure, even as a nonprofit, that the party that is paying for and driving the system, doesn’t make sure the automated system doesn’t favor them over time, because that’s a pretty easy outcome to start programming in.

Super good question. As you know, it is easier to train a data set than a human. So frankly—and let me step back for a minute. In our consumer cases, again, we do not accept consumer B2C cases, unless a business has cleared their clause with our due-process protocols. So we’re, again, in a lucky position there, I guess. But back to who’s in charge. For us, if the consumer feels like the process wasn’t fair, that’s not going to work. We’re in the business of actually giving more options to more parties. And if half of the parties in one kind of dispute type—I should say, we mostly do B2B cases—but when we do B2C and they’ve satisfied our due-process protocols, it’s critically important to us that both sides feel, in the individual case, that they were treated fairly.

If it’s algorithmic, if it’s automated to some extent, even in part, that’s just as true, but easier to show our work. We did a lot of training, judicial training, and we do a lot of arbitrator training when human arbitrators decide cases, to make sure that the parties get equal treatment, fair treatment. But you can de-bias the data set a lot easier than you can de-bias a human. And so when you benchmark and do your audits of your AI arbitration system, and you show your work, you can either convince the public that it’s treating both people fairly or you won’t. That’s for us to show.

As you can tell, I’m fascinated. The reason I keep poking at this is that our readers at The Verge, like every other consumer in modernity, live a life of signing contracts, and you don’t get to negotiate those contracts. But you literally cannot participate in society without having signed dozens upon dozens of arbitration agreements.

I hear you say, “We have to get it right. We can’t get it wrong.” What is the mechanism of getting it wrong and then being forced to change, when no one can negotiate the contract that landed them in arbitration in the first place? Do you know what I mean? If there’s some public accountability that’s like, “The AAA got everything wrong for a year with the AI system,” then what? Because I can’t go to all of my service providers and say, “I don’t want to use the AAA anymore. I saw this news report.”

You’re asking, when you enter into any kind of B2C contract, you’re buying a new refrigerator, you don’t really get to scrutinize it and say, “I want to change the last clause.” People aren’t really entering into arbitration agreements. Arbitration clauses are just part of contracts they’re entering into.

In the construction case, you’ve got two parties and presumably they’ve contracted for the sale of lumber, and there’s an actual meeting of the minds, and they might have negotiated in, “We need arbitration because we got to move fast.” And fine, automate that away. And if you get it wrong, maybe the next time you try something else. And there’s some mechanism of change built into that.

I signed the terms of service for an LG refrigerator, which does have an arbitration agreement. And I’m like, “That sucked. My refrigerator exploded and the arbitrator ruled against me.” The next time I buy a refrigerator, I can’t go to LG and say, “I want a different arbitrator.” So I don’t see where that mechanism comes in for most people, because most people are just signing tons and tons of arbitration agreements all the time.

Yeah. You don’t mean, “I want a different arbitrator.” If you’re buying a refrigerator from Joe’s Refrigerator Store on your corner that doesn’t have a contract with an arbitration clause and you end up suing in court, you’re probably going to go to small claims court. You’re going to have not been able to figure out how to file properly and your case will have been dismissed. I’m telling you that’s what happens in most cases where people try to file cases in courts.

Well, you would have. That’s fair. But most people didn’t go to law school, and they aren’t going to get it right. And they are most often never going to make it past “Go.” I mean, look at the high volume dockets in state courts. Just take a look at how many cases are on the consumer debt docket, which is, by the way, the modal case in state court right now. Literally, the modal case in state court is a consumer debt case. And go take a look at how many of those are dismissed because the consumer, not the business, didn’t meet some, I don’t know, Court Rule 26.4A that said you had to have a triplicate when you responded to the thing.

You’re not going to be able to go back to Joe’s Refrigerator Store and say, like, “Hey, that court process wasn’t fair because there’s no way I’m going to be able to read the Latin and figure out that I have to file and triplicate my thing. So I want to go to arbitration where at least I can just show up and, in plain language, tell a person what happened to me, and a person will listen to it and answer it.”

I understand that there has been a pretty successful narrative that this process doesn’t work for individuals. And I am sure there are places where it doesn’t, but not every arbitration provider and dispute resolution provider is created equal, and some have different missions than others, and that matters.

There could be a campaign to say to—I have no idea who; I don’t know if LG uses us or some other provider—to say to LG, “We want you to switch to a provider that actually has due-process protocols. That’s what we want you to do.” Or you could go to Congress and you could tell Congress to amend the Federal Arbitration Act to say, “No B2C cases should ever go to arbitration.” I understand that apparently that’s how legislation works, that you can talk to Congress and they’ll fix things, but I don’t know.

There’s a lot of hopes and dreams in this episode.

[Laughs] Yeah, yeah, yeah. And I have no horse in that race. If Congress were to say tomorrow, “We don’t want B2C cases in arbitration, we want them all in courts,” I think it would probably be a mistake because I’ve seen how courts operate and the resources they don’t have. Believe me, there are lots of judges who are trying to do really well by all those folks on their dockets. They just don’t have the resources or the time, and they have these archaic rules.

So I think it probably wouldn’t be good for everybody, but I certainly have no horse in that race. I can create dispute resolution services and processes to give everybody more options. And I want people to want those options. I don’t want people to be stuck with those options. I want to create something that’s so good that you want it. You want to go to LG next time and say, “Can you please put an American Arbitration Association clause in my contract? Because that’s where I want to resolve my dispute.”

I appreciate the ambition. It’s a lot to think about. The idea that I’m able to negotiate the terms of service for my refrigerator, maybe that is what I think Congress should allow us to do, but that’s, yet again, a different podcast. When you think about the scope of this, the timeline of the investment that you’re making, you have one case in the system now. We’re going to see how it goes. You’ve obviously run some simulations on previous cases.

You’ve got some studies that say it’s going well. How fast does it go from here? What’s next? Is it 10 cases? Is it, “You’re on a sales trip”? What’s the speed?

Such a great question. There are at least two variables that we’re following. One is just how quickly our team, our engineers and the related folks that work on that Scrum team, can build it out for different case types, different documents-only dispute types. And then whether there are some institutions that want to use it for internal dispute resolution. We’ve had some interest in that. That’s going to take a while. That’s going to take us a couple of years to build out each dispute type by dispute type. So that’s slow.

Then there’s “When does the worm turn?” And your guess on that is as good as mine. I don’t know if it’s two years, five years, or 10 years. I’d be very surprised if in 15 years people—and businesses in particular, for B2B documents-only disputes—are still opting for a slow, expensive, human-led process. I’d be very surprised. But that’s a really conservative answer to your question.

Do you have a better answer? How quickly do you think it will happen? It’s going to go with a lot of the rest of the way technology’s going to disrupt our lives, right? It’s all kind of connected.

Yeah. If you look at our stack of guests over the past few months, we just had DocuSign on the show. Their CEO was like, “AI’s going to write the documents for you because we have access to your business intelligence.” We had LexisNexis on the show, and their CEO was like, “The lawyers will just start doing the research here and drafting out of these claims.” That seems very dangerous to me.

But you see this universe of legal work being automated very quickly, because the AI systems are good at words. You can either hire a 26-year-old who’s been drunk for several years—that was me—and they can be whoever they are as a first-year associate. Or you can have a robot do it and maybe that’s the same.

I think it will happen very fast and then it will slow down, because everyone will realize there’s not a next generation of people who understand how to control the systems, and that investment still needs to be made. And the outcomes of those systems are not as good as we wanted them to be.

Yeah, it’s a completely different training. My podcast is on AI and the future of law, and I’m just talking about…You might know that two careers ago, I spent 15 years on a law faculty. So the training model is kind of broken for what lawyers are going to do in, again, two, five, or 10 years, and I don’t see anybody moving extremely quickly to figure out what the 2.0 training model is.

Now, I want to say, I don’t think the 1.0 training model was that great. I’m not sure that sitting in the basement looking through a bunch of boxes of documents really made you an excellent lawyer or strategist or advisor. I’m not convinced that that was perfect. So I do think there’s an opportunity—I’m an optimist. I think there’s an opportunity to build a better system, but you’re right, there are going to be ways in which some of this moves faster than the rest of us and we’re not ready for it.

One other thing that I spend a lot of time thinking about is, “How many B2B contracts are going to be negotiated and executed by agents?” Walmart has agents negotiating and executing a significant number of their contracts. In a B2B agentic commerce world—you probably read these estimates as much as I do. Some people say that by the end of 2027, as much as 40 percent of contracts might be negotiated and executed agent to agent. So what happens when one of those agents makes a mistake? As good as they are, they will make mistakes. What’s the dispute resolution process there? And is it an on-chain process that maybe is better, like it’s an upstream automated dispute resolution process?

I’d like to be in the conversations to figure that out, because you need that somewhere. Your agentic commerce is only as good as your process for fixing it when it breaks, but nobody’s talking to me about that. I want them to. So yeah, a lot to do yet.

Literally, just before we sat down, Goldman Sachs announced that it was putting AI into more of its accounting functions and other functions at the company. So you can see the acceleration. My prediction is we’re going to accelerate into it and then we’re going to pump the brakes really hard when we realize these systems are not as predictable as we want them to be. But I will have you back faster than 15 years to see how it’s going.

I have loved this conversation. Thank you so much for being on Decoder, Bridget.

Yeah, so much fun. Great to see you. Thanks.

Questions or comments about this episode? Hit us up at decoder@theverge.com. We really do read every email!

A podcast from The Verge about big ideas and other problems.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-50')">
            <div class="source">The Verge</div>
            <div class="title">DHS announces the end of its “surge operation” in Minneapolis, but not entirely</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-50" style="display:none;">
            <h2>DHS announces the end of its “surge operation” in Minneapolis, but not entirely</h2>
            <p><strong>The Verge | 2026-02-12</strong></p>
            <a class="original-link" href="https://www.theverge.com/policy/878017/dhs-ends-minneapolis-operation-metro-surge-tom-homan">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Border czar Tom Homan says “a small footprint of personnel” will remain in the Twin Cities.

Border czar Tom Homan says “a small footprint of personnel” will remain in the Twin Cities.

The government’s siege of the Twin Cities is reportedly coming to an end. “I have proposed, and President Trump has concurred, that this surge operation conclude,” border czar Tom Homan announced Thursday.

This isn’t the first time Department of Homeland Security officials have claimed that Operation Metro Surge, its massive campaign in Minnesota, was slowing down or ending altogether. Homan teased a “drawdown” in late January, and a few days later President Donald Trump said he had ordered the withdrawal of 700 agents from the state. But an estimated 2,000 agents remained, and residents reported that raids continued.

Even by Homan’s own admission, it’s still not over. “A small footprint of personnel will remain for a period of time to close out and transition full command and control back to the field office,” Homan said. “I will also remain on the ground for a little longer to oversee the drawdown of this operation and include its success.”

There are typically 150 federal immigration officers in Minnesota, according to MPR News. Their presence increased twenty-fold under Metro Surge, an operation that began after a right-wing vlogger’s alleged widespread fraud at daycares operated by Minneapolis’s Somali American community.

A robust mutual aid network emerged in response to ICE’s operation in the Twin Cities. In addition to collecting groceries and crowdfunding rent for immigrant families, Minnesotans have formed ICE patrols in their neighborhoods. Two observers, Renee Good and Alex Pretti, were killed by federal immigration agents in January, sparking mass protests throughout the Twin Cities.

Administration officials had previously said that the operation would end once state and local officials sufficiently collaborated with ICE. It’s not immediately clear what concessions, if any, the federal government has obtained from Gov. Tim Walz or Minneapolis Mayor Tim Frey.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-51')">
            <div class="source">The Verge</div>
            <div class="title">Spider-Noir looks like a hard-boiled thriller in first trailer</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-51" style="display:none;">
            <h2>Spider-Noir looks like a hard-boiled thriller in first trailer</h2>
            <p><strong>The Verge | 2026-02-12</strong></p>
            <a class="original-link" href="https://www.theverge.com/entertainment/877922/spider-noir-trailer-release-date-amazon-mgm-plus">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The new live-action Spider-Man series will debut on MGM Plus on May 25th before making its way to Amazon on the 27th.

The new live-action Spider-Man series will debut on MGM Plus on May 25th before making its way to Amazon on the 27th.

Though it’s going to be a while before we see more of Sony’s animated Spider-Verse or Marvel’s live-action take on Peter Parker, Amazon’s Spider-Noir series is right around the corner.

Today, Amazon dropped a new trailer for its upcoming Spider-Noir starring Nicolas Cage as a brooding Spider-Man variant. Set in an alternate reality where it’s still the 1930s, Spider-Noir follows private investigator Ben Reilly (Cage) as he gets back into the crimefighting game as the hero known as “The Spider.” As his city’s only superhero, Reilly knows that he’s the only person with the necessary skills to deal with threats like mob boss Silvermane (Brendan Gleeson). But as a man still reeling from a personal tragedy, it’s hard for Reilly to get back into the heroic swing of things.

In addition to featuring shots of club owner Cat Hardy (Li Jun Li) and reporter Robbie Robertson (Lamorne Morris), the black and white trailer (there’s also a version that’s in color, and the series will be streamed both ways) gives you a strong sense of the moody tone and dark aesthetic Spider-Noir is going to lean into. For some reason, Amazon is debuting the show on MGM Plus on May 25th before it hits Prime Video on the 27th. It’s not clear if the show will feature any connections to the rest of Sony’s universe of Spider-projects, but Spider-Noir looks like it could be pretty solid.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-52')">
            <div class="source">The Verge</div>
            <div class="title">The Sony WF-1000XM6 earbuds reclaim the noise-canceling crown</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-52" style="display:none;">
            <h2>The Sony WF-1000XM6 earbuds reclaim the noise-canceling crown</h2>
            <p><strong>The Verge | 2026-02-12</strong></p>
            <a class="original-link" href="https://www.theverge.com/tech/877503/sony-wf-1000xm6-earbuds-review">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The new flagship earbuds are the best at ANC, if you can get a good seal in your ear.

If you buy something from a Verge link, Vox Media may earn a commission. See our ethics statement.

If you buy something from a Verge link, Vox Media may earn a commission. See our ethics statement.

Apple, Bose, and Sony are in a running battle for the best noise-canceling earbuds, and the Sony WF-1000XM6 put Sony back in first place — if you can get a good fit with the included foam tips.

With each iteration of the XM series, Sony has aimed for — and delivered — incredible noise-canceling performance with a pleasing and balanced sound profile, and features that work equally well with iOS and Android. The XM6 push even further by adding additional noise-canceling mics (for a total of 8), a new chip, newly designed drivers, and a new shape that’s supposed to better fit a wider selection of ears. That’s a lot of promises, and the Sony WF-1000XM6 earbuds fulfill them all — almost.

The Sony WF-1000XM6 earbuds have top-notch noise-canceling performance with excellent, balanced sound.

One of the things I’ve liked most about both the in-ear and over-ear Sony XM series is the sound performance. Out of the box, the XM6 sound balanced and clean. They use a new driver with a softer edge material that allows for deeper bass, combined with a high-rigidity dome for clear high frequencies. I was impressed by the bass response, even in the lowest notes of “bury a friend” by Billie Eilish, which sound resonant and punchy. Vocals, such as Jarvis Cocker’s on “Common People,” cut through thick textures, and cymbals and hi-hats have a nice sparkle to them. There’s also more drive in the midrange than with the Apple AirPods Pro 3 or Bose Ultra Earbuds gen 2 — both of which are balanced a bit more toward the high end, especially the Bose.

The top noise-canceling earbuds — the Bose Ultra Earbuds gen 2, Apple AirPods Pro 3, and these Sony WF-1000XM6 — are all great at blocking low-end frequencies like the engine noise in an airplane cabin. They’re all good at tamping down midrange sounds, including voices, but the XM6 are better at tuning out other people’s conversations better than any other earbuds I’ve heard.

Sony improved the bone conduction sensor in the XM6, and in conjunction with AI beamforming mics, the earbuds do a great job blocking out environmental sounds while on calls. I tested both sides of a call with the XM6, and found that traffic can cause some swishy noises. And when there was a lot of extra traffic and wind, my voice would sound a bit compressed, but not to an extent that was distracting or caused me to be unintelligible.

Sound quality and noise-canceling performance rely on a solid fit, and that’s where the XM6 start to have some problems. I usually wear medium-sized ear tips, but I had difficulty getting a secure, long-lasting fit in my right ear with the included foam tips. I had similar fit issues when I tested the Sony WF-1000XM5 earbuds, but was eventually able to get those to sit properly for long listening periods.

The Sound Connect app includes a “Test wearing condition” setting that plays a test tone and uses internal microphones to determine if there’s an airtight fit. According to the app, I was only able to get a good seal in my right ear by using the large tip and jamming the earbud into my ear. After a short time I could feel the ear tip start to loosen. I had a couple friends try to fit the XM6 as well, and both had varying levels of issues.

There is a solution. If none of the foam ear tips work for you after testing the fit with the app, an option to order silicone ear tips will show up and Sony will send them out, free of charge. The silicone tips solved my fit problem. Both earbuds felt more secure than with the foam tips, and the fit was more comfortable, although it does sound like the silicone ear tips let in a tiny bit more mid-range noise, voices in particular. It’s a pretty minor difference and the noise cancellation is still incredibly impressive — still on par with the Bose Ultra gen 2 — but it’s worth noting the best-in-class noise cancellation relies on the foam tips.

The low-end frequency response is also slightly different with the silicone tips, with a tad less bass. It’s such a minor difference, though, and isn’t objectionable at all, just slightly different. The tom-toms at the beginning of Radiohead’s “There, There” from Hail to the Thief don’t quite ring the same, and the low bass notes aren’t as full. But if I had the ability to ABX test the two different tips (which would be impossible because I’d feel the difference), I don’t think I’d be able to point to one as better. The XM6 sound fantastic regardless of tips. Our ears are highly adaptable to changes in sound balance, and within seconds using either set of tips I was enjoying everything I listened to.

Still, the fact that I needed an additional set of tips to get a suitable fit — and that the foam tips didn’t work for multiple people that tried them — isn’t great. Sony should have included the silicone tips in the box. While three people certainly don’t make a large enough sample size for a definitive conclusion, be aware you might need to wait for those extra silicone tips to arrive or plan on buying yourself some Comply foam tips.

I’m also not a huge fan of the XM6’s new shape. The earbuds are longer and narrower than the WF-1000XM5, and the body sticks out further from the ear. They are certainly not inconspicuous, though size does make touch controls easy to use. Only once did I accidentally cause music to play or pause — something that happened on numerous occasions with the Bose as I adjusted them in my ears during testing — and that was when I was motioning to my colleague about the size of them in my ear.

For those that like to tweak settings, there are a lot of opportunities in the Sound Connect app. There’s a 10-band EQ and five EQ presets (although I think the default sound profile is excellent and doesn’t need to be altered for my taste), a 20-point slider to adjust ambient passthrough (or an auto setting), and touch control customization. There’s also an option to set scenes, which causes the earbuds to adjust to predetermined settings based on your activity or location. And if you have a compatible device (including most modern Android phones), the XM6 support LDAC high-res audio streaming and Auracast.

A new listening mode — currently available on the in-ear and over-ear XM6 series, as well as the LinkBuds Fit and LinkBuds Open — turns whatever you’re listening to into background music. It changes the volume and EQ and adds reverb to make the music in the earbuds sound like background music in a cafe, living room, or “my room” (all actual options in the settings). I could see it keeping the music from being too distracting, but for me turning the volume down is enough to give a similar effect.

The XM6 have up to eight hours of battery life (24 hours including the case, which has wireless charging), which is comparable to the AirPods Pro 3, and a couple more hours in the buds than the Bose Ultra Earbuds gen 2 (although those also get up to 24 hours with their charging case).

The Sony WF-1000XM6 have solid performance, following the pedigree of earlier XM series earbuds. They sound fantastic, handle ambient noise during calls well and, with the foam ear tips, deliver the best noise canceling I’ve yet heard from earbuds. They sound better than the Bose buds, even though they stick out a bit more. If you’re deep in the Apple ecosystem, nothing competes with the integration of the AirPods, but the XM6 are my favorite-sounding earbuds of the three, with broader compatibility than the AirPods and a nice array of features including Auracast support.

Foam or silicone tips, the XM6 are excellent earbuds. It’s nice that Sony will send along extra silicone tips if the foam ones don’t work for you; I just wish they were included from the get-go.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-53')">
            <div class="source">The Verge</div>
            <div class="title">Waymo’s next-gen robotaxi is ready for passengers — and also ‘high-volume production’</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-53" style="display:none;">
            <h2>Waymo’s next-gen robotaxi is ready for passengers — and also ‘high-volume production’</h2>
            <p><strong>The Verge | 2026-02-12</strong></p>
            <a class="original-link" href="https://www.theverge.com/transportation/877902/waymo-sixth-generation-robotaxi-ojai-hyundai-sensors-cost">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The company plans to start passenger trips with employees in San Francisco and LA, followed by public riders. But more importantly, it plans on making a lot of vehicles, as it seeks to cement its first place status in the robotaxi race.

The company plans to start passenger trips with employees in San Francisco and LA, followed by public riders. But more importantly, it plans on making a lot of vehicles, as it seeks to cement its first place status in the robotaxi race.

After years of testing and validation, Waymo announced today that it’s sixth-generation robotaxi technology is finally ready for passenger trips. The updated autonomous driving system will first be rolled out for employees and their friends in San Francisco and Los Angeles, with public customers to follow.

Waymo’s current fleet of Jaguar I-Pace vehicles runs on the company’s fifth generation technology, first rolled out in March 2020. But that vehicle has reached the end of its shelf life, after Jaguar discontinued the model at the end of 2024. The updated system is designed to work seamlessly across multiple vehicle types, starting with the Zeekr RT minivan (rebranded as Ojai) and followed by the Hyundai Ioniq 5. Waymo is in talks with other automakers, including Toyota, about future models.

Waymo says that its sixth-generation system is the smartest, most capable autonomous vehicle it’s ever designed, while also using fewer sensors to lower its overall costs. Its cameras are more powerful, its lidar are able to see things the cameras might miss, and its improved radar are able to tackle extreme weather conditions. But more importantly, its built for “high-volume production,” with Waymo’s manufacturing partners able to churn out “tens of thousands of units a year.” After proving that it can build a successful robotaxi business across multiple markets, Waymo is aiming to scale more rapidly, eyeing 20 new cities in 2026.

“Designed for long-term growth across multiple vehicle platforms, this system’s expanded capabilities allow us to safely broaden our footprint into more diverse environments, including those with extreme winter weather, at an even greater scale,” Waymo VP of engineering Satish Jeyachandran said in a blog post.

Jeyachandran listed a number of metrics — developed over seven years, 200 million miles of testing in 10+ major cities — to bolster the case that the sixth generation is ready for the road. And in perhaps a veiled swipe at Tesla’s camera-only autonomous system, he explained how Waymo’s multi-sensor hardware stack provides the redundancy necessary to create the most robust picture of the environment around each vehicle, while also detecting even the hardest-to-spot objects and edge cases.

“Our experience as the only company operating a fully autonomous service at this scale has reinforced a fundamental truth: demonstrably safe AI requires equally resilient inputs,” he said. “This deep understanding of real-world requirements is why the Waymo Driver utilizes a custom, multi-modal sensing suite where high-resolution cameras, advanced imaging radar, and lidar work as a unified system.”

But what about those sensors? The vision system runs on high-powered 17-megapixel cameras, which Waymo calls “imagers,” capable of capturing “millions of data points for incredibly sharp images.” (By contrast, Tesla’s current Hardware 4 (HW4) vehicles use 5-megapixel Sony IMX963 cameras.) The incredible resolution allows Waymo to use fewer overall cameras: 16, down from 29 in the fifth-generation system.

Those cameras are bolstered by strategically placed short-range lidar, which are also coming down in cost for the company. The lidar help with identifying vulnerable road users, like pedestrians or bicyclists, while also providing “centimeter-scale range accuracy,” Jeyachandran says. And they’ve been reengineered to help penetrate extreme weather situations that may hamper even the highest resolution camera, which will become more important as Waymo aims to launch in snowier climates. Jeyachandran also touted more affordable radar sensors, and the new system’s external audio receivers, or EARs (see what they did there), that can detect audio inputs like approaching sirens or trains.

But if you’re taking anything away here, it should be that Waymo thinks it can make a lot more of these vehicles at a lower cost than its previous robotaxis. That’s crucial as the company seeks to scale up its presence in the US and overseas, cementing its position as the dominant autonomous vehicle company in the world. Waymo has said it plans on adding only 2,000 more vehicles in 2026, for a total fleet size of 3,500. But its ultimate aim is tens of thousands of vehicles, as per today’s announcement.

Lowering costs is going to be increasingly important for robotaxi companies as they look to scale up and expand into new markets. Alphabet doesn’t break out Waymo’s costs in its earnings report, but its “Other Bets” unit, which includes the robotaxi company, brought in $370 million in revenue in the fourth quarter of 2025, down from $400 million a year ago. But the unit’s losses widened to $3.6 billion from $1.2 billion in the year-earlier period. Waymo recently raised $16 billion in its latest funding round as it aims to take its robotaxi business “global.”

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-54')">
            <div class="source">MIT Technology Review</div>
            <div class="title">The Download: AI-enhanced cybercrime, and secure AI assistants</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-54" style="display:none;">
            <h2>The Download: AI-enhanced cybercrime, and secure AI assistants</h2>
            <p><strong>MIT Technology Review | 2026-02-12</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2026/02/12/1132819/the-download-ai-enhanced-cybercrime-and-secure-ai-assistants/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">This is today&#39;s edition of The Download, our weekday newsletter that provides a daily dose of what&#39;s going on in the world of technology.

AI is already making online crimes easier. It could get much worse.

Just as software engineers are using artificial intelligence to help write code and check for bugs, hackers are using these tools to reduce the time and effort required to orchestrate an attack, lowering the barriers for less experienced attackers to try something out.Some in Silicon Valley warn that AI is on the brink of being able to carry out fully automated attacks. But most security researchers instead argue that we should be paying closer attention to the much more immediate risks posed by AI, which is already speeding up and increasing the volume of scams.Criminals are increasingly exploiting the latest deepfake technologies to impersonate people and swindle victims out of vast sums of money. And we need to be ready for what comes next. Read the full story.—Rhiannon Williams

This story is from the next print issue of MIT Technology Review magazine, which is all about crime. If you haven’t already, subscribe now to receive future issues once they land.

AI agents are a risky business. Even when stuck inside the chatbox window, LLMs will make mistakes and behave badly. Once they have tools that they can use to interact with the outside world, such as web browsers and email addresses, the consequences of those mistakes become far more serious.

Viral AI agent project OpenClaw, which has made headlines across the world in recent weeks, harnesses existing LLMs to let users create their own bespoke assistants. For some users, this means handing over reams of personal data, from years of emails to the contents of their hard drive. That has security experts thoroughly freaked out.

In response to these concerns, its creator warned that nontechnical people should not use the software. But there’s a clear appetite for what OpenClaw is offering, and any AI companies hoping to get in on the personal assistant business will need to figure out how to build a system that will keep users’ data safe and secure. To do so, they’ll need to borrow approaches from the cutting edge of agent security research. Read the full story.

The past year has marked a turning point for Chinese AI. Since DeepSeek released its R1 reasoning model in January 2025, Chinese companies have repeatedly delivered AI models that match the performance of leading Western models at a fraction of the cost.These models differ in a crucial way from most US models like ChatGPT or Claude, which you pay to access and can’t inspect. The Chinese companies publish their models’ weights—numerical values that get set when a model is trained—so anyone can download, run, study, and modify them.

If open-source AI models keep getting better, they will not just offer the cheapest options for people who want access to frontier AI capabilities; they will change where innovation happens and who sets the standards. Here’s what may come next.

This is part of our What’s Next series, which looks across industries, trends, and technologies to give you a first look at the future. You can read the rest of them here.

EVs are getting cheaper and more common all over the world. But the technology still faces major challenges in some markets, including many countries in Africa.

Some regions across the continent still have limited grid and charging infrastructure, and those that do have widespread electricity access sometimes face reliability issues—a problem for EV owners, who require a stable electricity source to charge up and get around. But there are some signs of progress. Read the full story.

This article is from The Spark, MIT Technology Review’s weekly climate newsletter. To receive it in your inbox every Wednesday, sign up here.

I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.

1 Instagram’s head has denied that social media is “clinically addictive”  Adam Mosseri disputed allegations the platform prioritized profits over protecting its younger users’ mental health. (NYT $)+ Meta researchers’ correspondence seems to suggest otherwise. (The Guardian)2 The Pentagon is pushing AI companies to drop tools’ restrictionsIn a bid to make AI models available on classified networks. (Reuters)+ The Pentagon has gutted the team that tests AI and weapons systems. (MIT Technology Review)

3 The FTC has warned Apple News not to stifle conservative contentIt has accused the company’s news arm of promoting what it calls “leftist outlets.” (FT $)

4 Anthropic has pledged to minimize the impact of its data centersBy covering electricity price increases and the cost of grid infrastructure upgrades. (NBC News)+ We did the math on AI’s energy footprint. Here’s the story you haven’t heard. (MIT Technology Review)

5 Online harassers are posting Grok-generated nude images on OnlyFans Kylie Brewer, a feminism-focused content creator, says the latest online campaign against her feels like an escalation. (404 Media)+ Inside the marketplace powering bespoke AI deepfakes of real women. (MIT Technology Review)6 Venture capitalists are hedging their AI betsThey’re breaking a cardinal rule by investing in both OpenAI and rival Anthropic. (Bloomberg $)+ OpenAI has set itself some seriously lofty revenue goals. (NYT $)+ AI giants are notoriously inconsistent when reporting deprecation expenses. (WSJ $)

7 We’re learning more about the links between weight loss drugs and addictionSome patients report lowered urges for drugs and alcohol. But can it last? (New Yorker $)+ What we still don’t know about weight-loss drugs. (MIT Technology Review)8 Meta has patented an AI that keeps the accounts of dead users activeBut it claims to have &quot;no plans to move forward&quot; with it. (Insider $)+ Deepfakes of your dead loved ones are a booming Chinese business. (MIT Technology Review)

9 Slime mold is cleverer than you may thinkA certain type appears able to learn, remember and make decisions. (Knowable Magazine)+ And that’s not all—this startup thinks it can help us design better cities, too. (MIT Technology Review)10 Meditation can actually alter your brain activity 🧘According to a new study conducted on Buddhist monks. (Wired $)

“I still try to believe that the good that I’m doing is greater than the horrors that are a part of this. But there’s a limit to what we can put up with. And I’ve hit my limit.”

—An anonymous Microsoft worker explains why they’re growing increasingly frustrated with their employer’s links to ICE, the Verge reports.

Motor neuron diseases took their voices. AI is bringing them back.Jules Rodriguez lost his voice in October 2024. His speech had been deteriorating since a diagnosis of amyotrophic lateral sclerosis (ALS) in 2020, but a tracheostomy to help him breathe dealt the final blow.

Rodriguez and his wife, Maria Fernandez, who live in Miami, thought they would never hear his voice again. Then they re-created it using AI. After feeding old recordings of Rodriguez’s voice into a tool trained on voices from film, television, radio, and podcasts, the couple were able to generate a voice clone—a way for Jules to communicate in his “old voice.”

Rodriguez is one of over a thousand people with speech difficulties who have cloned their voices using free software from ElevenLabs. The AI voice clones aren’t perfect. But they represent a vast improvement on previous communication technologies and are already improving the lives of people with motor neuron diseases. Read the full story. —Jessica Hamzelou

A place for comfort, fun and distraction to brighten up your day. (Got any ideas? Drop me a line or skeet &#39;em at me.)

+ We all know how the age of the dinosaurs ended. But how did it begin?+ There’s only one Miss Piggy—and her fashion looks through the ages are iconic.+ Australia’s hospital for injured and orphaned flying foxes is unbearably cute.+ 81-year old Juan López is a fitness inspiration to us all.

Plus: TikTok has finally signed a deal to keep operating in the US

Plus: This company is developing gene therapies for muscle growth, erectile dysfunction, and “radical longevity”

Plus: China has built a major chip-making machine

Plus: more European countries are considering banning social media for under-16s

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-55')">
            <div class="source">MIT Technology Review</div>
            <div class="title">AI is already making online crimes easier. It could get much worse.</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-55" style="display:none;">
            <h2>AI is already making online crimes easier. It could get much worse.</h2>
            <p><strong>MIT Technology Review | 2026-02-12</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2026/02/12/1132386/ai-already-making-online-swindles-easier/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Anton Cherepanov is always on the lookout for something interesting. And in late August last year, he spotted just that. It was a file uploaded to VirusTotal, a site cybersecurity researchers like him use to analyze submissions for potential viruses and other types of malicious software, often known as malware. On the surface it seemed innocuous, but it triggered Cherepanov’s custom malware-detecting measures. Over the next few hours, he and his colleague Peter Strýček inspected the sample and realized they’d never come across anything like it before.

The file contained ransomware, a nasty strain of malware that encrypts the files it comes across on a victim’s system, rendering them unusable until a ransom is paid to the attackers behind it. But what set this example apart was that it employed large language models (LLMs). Not just incidentally, but across every stage of an attack. Once it was installed, it could tap into an LLM to generate customized code in real time, rapidly map a computer to identify sensitive data to copy or encrypt, and write personalized ransom notes based on the files’ content. The software could do this autonomously, without any human intervention. And every time it ran, it would act differently, making it harder to detect.

Cherepanov and Strýček were confident that their discovery, which they dubbed PromptLock, marked a turning point in generative AI, showing how the technology could be exploited to create highly flexible malware attacks. They published a blog post declaring that they’d uncovered the first example of AI-powered ransomware, which quickly became the object of widespread global media attention.

But the threat wasn’t quite as dramatic as it first appeared. The day after the blog post went live, a team of researchers from New York University claimed responsibility, explaining that the malware was not, in fact, a full attack let loose in the wild but a research project, merely designed to prove it was possible to automate each step of a ransomware campaign—which, they said, they had.

PromptLock may have turned out to be an academic project, but the real bad guys are using the latest AI tools. Just as software engineers are using artificial intelligence to help write code and check for bugs, hackers are using these tools to reduce the time and effort required to orchestrate an attack, lowering the barriers for less experienced attackers to try something out.

The likelihood that cyberattacks will now become more common and more effective over time is not a remote possibility but “a sheer reality,” says Lorenzo Cavallaro, a professor of computer science at University College London.

Some in Silicon Valley warn that AI is on the brink of being able to carry out fully automated attacks. But most security researchers say this claim is overblown. “For some reason, everyone is just focused on this malware idea of, like, AI superhackers, which is just absurd,” says Marcus Hutchins, who is principal threat researcher at the security company Expel and famous in the security world for ending a giant global ransomware attack called WannaCry in 2017.

Instead, experts argue, we should be paying closer attention to the much more immediate risks posed by AI, which is already speeding up and increasing the volume of scams. Criminals are increasingly exploiting the latest deepfake technologies to impersonate people and swindle victims out of vast sums of money. These AI-enhanced cyberattacks are only set to get more frequent and more destructive, and we need to be ready.

Attackers started adopting generative AI tools almost immediately after ChatGPT exploded on the scene at the end of 2022. These efforts began, as you might imagine, with the creation of spam—and a lot of it. Last year, a report from Microsoft said that in the year leading up to April 2025, the company had blocked $4 billion worth of scams and fraudulent transactions, “many likely aided by AI content.”

At least half of spam email is now generated using LLMs, according to estimates by researchers at Columbia University, the University of Chicago, and Barracuda Networks, who analyzed nearly 500,000 malicious messages collected before and after the launch of ChatGPT. They also found evidence that AI is increasingly being deployed in more sophisticated schemes. They looked at targeted email attacks, which impersonate a trusted figure in order to trick a worker within an organization out of funds or sensitive information. By April 2025, they found, at least 14% of those sorts of focused email attacks were generated using LLMs, up from 7.6% in April 2024.

In one high-profile case, a worker was tricked into transferring $25 million to criminals via a video call with digital versions of the company’s chief financial officer and other employees.

And the generative AI boom has made it easier and cheaper than ever before to generate not only emails but highly convincing images, videos, and audio. The results are much more realistic than even just a few short years ago, and it takes much less data to generate a fake version of someone’s likeness or voice than it used to.

Criminals aren’t deploying these sorts of deepfakes to prank people or to simply mess around—they’re doing it because it works and because they’re making money out of it, says Henry Ajder, a generative AI expert. “If there’s money to be made and people continue to be fooled by it, they’ll continue to do it,” he says. In one high-­profile case reported in 2024, a worker at the British engineering firm Arup was tricked into transferring $25 million to criminals via a video call with digital versions of the company’s chief financial officer and other employees. That’s likely only the tip of the iceberg, and the problem posed by convincing deepfakes is only likely to get worse as the technology improves and is more widely adopted.

Criminals’ tactics evolve all the time, and as AI’s capabilities improve, such people are constantly probing how those new capabilities can help them gain an advantage over victims. Billy Leonard, tech leader of Google’s Threat Analysis Group, has been keeping a close eye on changes in the use of AI by potential bad actors (a widely used term in the industry for hackers and others attempting to use computers for criminal purposes). In the latter half of 2024, he and his team noticed prospective criminals using tools like Google Gemini the same way everyday users do—to debug code and automate bits and pieces of their work—as well as tasking it with writing the odd phishing email. By 2025, they had progressed to using AI to help create new pieces of malware and release them into the wild, he says.

The big question now is how far this kind of malware can go. Will it ever become capable enough to sneakily infiltrate thousands of companies’ systems and extract millions of dollars, completely undetected?

Most popular AI models have guardrails in place to prevent them from generating malicious code or illegal material, but bad actors still find ways to work around them. For example, Google observed a China-linked actor asking its Gemini AI model to identify vulnerabilities on a compromised system—a request it initially refused on safety grounds. However, the attacker managed to persuade Gemini to break its own rules by posing as a participant in a capture-the-flag competition, a popular cybersecurity game. This sneaky form of jailbreaking led Gemini to hand over information that could have been used to exploit the system. (Google has since adjusted Gemini to deny these kinds of requests.)

But bad actors aren’t just focusing on trying to bend the AI giants’ models to their nefarious ends. Going forward, they’re increasingly likely to adopt open-source AI models, as it’s easier to strip out their safeguards and get them to do malicious things, says Ashley Jess, a former tactical specialist at the US Department of Justice and now a senior intelligence analyst at the cybersecurity company Intel 471. “Those are the ones I think that [bad] actors are going to adopt, because they can jailbreak them and tailor them to what they need,” she says.

The NYU team used two open-source models from OpenAI in its PromptLock experiment, and the researchers found they didn’t even need to resort to jailbreaking techniques to get the model to do what they wanted. They say that makes attacks much easier. Although these kinds of open-source models are designed with an eye to ethical alignment, meaning that their makers do consider certain goals and values in dictating the way they respond to requests, the models don’t have the same kinds of restrictions as their closed-source counterparts, says Meet Udeshi, a PhD student at New York University who worked on the project. “That is what we were trying to test,” he says. “These LLMs claim that they are ethically aligned—can we still misuse them for these purposes? And the answer turned out to be yes.”

It’s possible that criminals have already successfully pulled off covert PromptLock-style attacks and we’ve simply never seen any evidence of them, says Udeshi. If that’s the case, attackers could—in theory—have created a fully autonomous hacking system. But to do that they would have had to overcome the significant barrier that is getting AI models to behave reliably, as well as any inbuilt aversion the models have to being used for malicious purposes—all while evading detection. Which is a pretty high bar indeed.

So, what do we know for sure? Some of the best data we have now on how people are attempting to use AI for malicious purposes comes from the big AI companies themselves. And their findings certainly sound alarming, at least at first. In November, Leonard’s team at Google released a report that found bad actors were using AI tools (including Google’s Gemini) to dynamically alter malware’s behavior; for example, it could self-modify to evade detection. The team wrote that it ushered in “a new operational phase of AI abuse.”

However, the five malware families the report dug into (including PromptLock) consisted of code that was easily detected and didn’t actually do any harm, the cybersecurity writer Kevin Beaumont pointed out on social media. “There’s nothing in the report to suggest orgs need to deviate from foundational security programmes—everything worked as it should,” he wrote.

It’s true that this malware activity is in an early phase, concedes Leonard. Still, he sees value in making these kinds of reports public if it helps security vendors and others build better defenses to prevent more dangerous AI attacks further down the line. “Cliché to say, but sunlight is the best disinfectant,” he says. “It doesn’t really do us any good to keep it a secret or keep it hidden away. We want people to be able to know about this— we want other security vendors to know about this—so that they can continue to build their own detections.”

And it’s not just new strains of malware that would-be attackers are experimenting with—they also seem to be using AI to try to automate the process of hacking targets. In November, Anthropic announced it had disrupted a large-scale cyberattack, the first reported case of one executed without “substantial human intervention.” Although the company didn’t go into much detail about the exact tactics the hackers used, the report’s authors said a Chinese state-sponsored group had used its Claude Code assistant to automate up to 90% of what they called a “highly sophisticated espionage campaign.”

“We’re entering an era where the barrier to sophisticated cyber operations has fundamentally lowered, and the pace of attacks will accelerate faster than many organizations are prepared for.”

But, as with the Google findings, there were caveats. A human operator, not AI, selected the targets before tasking Claude with identifying vulnerabilities. And of 30 attempts, only a “handful” were successful. The Anthropic report also found that Claude hallucinated and ended up fabricating data during the campaign, claiming it had obtained credentials it hadn’t and “frequently” overstating its findings, so the attackers would have had to carefully validate those results to make sure they were actually true. “This remains an obstacle to fully autonomous cyberattacks,” the report’s authors wrote.

Existing controls within any reasonably secure organization would stop these attacks, says Gary McGraw, a veteran security expert and cofounder of the Berryville Institute of Machine Learning in Virginia. “None of the malicious-attack part, like the vulnerability exploit … was actually done by the AI—it was just prefabricated tools that do that, and that stuff’s been automated for 20 years,” he says. “There’s nothing novel, creative, or interesting about this attack.”

Anthropic maintains that the report’s findings are a concerning signal of changes ahead. “Tying this many steps of an intrusion campaign together through [AI] agentic orchestration is unprecedented,” Jacob Klein, head of threat intelligence at Anthropic, said in a statement. “It turns what has always been a labor-intensive process into something far more scalable. We’re entering an era where the barrier to sophisticated cyber operations has fundamentally lowered, and the pace of attacks will accelerate faster than many organizations are prepared for.”

Some are not convinced there’s reason to be alarmed. AI hype has led a lot of people in the cybersecurity industry to overestimate models’ current abilities, Hutchins says. “They want this idea of unstoppable AIs that can outmaneuver security, so they’re forecasting that’s where we’re going,” he says. But “there just isn’t any evidence to support that, because the AI capabilities just don’t meet any of the requirements.”

Indeed, for now criminals mostly seem to be tapping AI to enhance their productivity: using LLMs to write malicious code and phishing lures, to conduct reconnaissance, and for language translation. Jess sees this kind of activity a lot, alongside efforts to sell tools in underground criminal markets. For example, there are phishing kits that compare the click-rate success of various spam campaigns, so criminals can track which campaigns are most effective at any given time. She is seeing a lot of this activity in what could be called the “AI slop landscape” but not as much “widespread adoption from highly technical actors,” she says.

But attacks don’t need to be sophisticated to be effective. Models that produce “good enough” results allow attackers to go after larger numbers of people than previously possible, says Liz James, a managing security consultant at the cybersecurity company NCC Group. “We’re talking about someone who might be using a scattergun approach phishing a whole bunch of people with a model that, if it lands itself on a machine of interest that doesn’t have any defenses … can reasonably competently encrypt your hard drive,” she says. “You’ve achieved your objective.”

For now, researchers are optimistic about our ability to defend against these threats—regardless of whether they are made with AI. “Especially on the malware side, a lot of the defenses and the capabilities and the best practices that we’ve recommended for the past 10-plus years—they all still apply,” says Leonard. The security programs we use to detect standard viruses and attack attempts work; a lot of phishing emails will still get caught in inbox spam filters, for example. These traditional forms of defense will still largely get the job done—at least for now.

And in a neat twist, AI itself is helping to counter security threats more effectively. After all, it is excellent at spotting patterns and correlations. Vasu Jakkal, corporate vice president of Microsoft Security, says that every day, the company processes more than 100 trillion signals flagged by its AI systems as potentially malicious or suspicious events.

Despite the cybersecurity landscape’s constant state of flux, Jess is heartened by how readily defenders are sharing detailed information with each other about attackers’ tactics. Mitre’s Adversarial Threat Landscape for Artificial-Intelligence Systems and the GenAI Security Project from the Open Worldwide Application Security Project are two helpful initiatives documenting how potential criminals are incorporating AI into their attacks and how AI systems are being targeted by them. “We’ve got some really good resources out there for understanding how to protect your own internal AI toolings and understand the threat from AI toolings in the hands of cybercriminals,” she says.

PromptLock, the result of a limited university project, isn’t representative of how an attack would play out in the real world. But if it taught us anything, it’s that the technical capabilities of AI shouldn’t be dismissed.New York University’s Udeshi says he wastaken aback at how easily AI was able to handle a full end-to-end chain of attack, from mapping and working out how to break into a targeted computer system to writing personalized ransom notes to victims: “We expected it would do the initial task very well but it would stumble later on, but we saw high—80% to 90%—success throughout the whole pipeline.”

AI is still evolving rapidly, and today’s systems are already capable of things that would have seemed preposterously out of reach just a few short years ago. That makes it incredibly tough to say with absolute confidence what it will—or won’t—be able to achieve in the future. While researchers are certain that AI-driven attacks are likely to increase in both volume and severity, the forms they could take are unclear. Perhaps the most extreme possibility is that someone makes an AI model capable of creating and automating its own zero-day exploits—highly dangerous cyber­attacks that take advantage of previously unknown vulnerabilities in software. But building and hosting such a model—and evading detection—would require billions of dollars in investment, says Hutchins, meaning it would only be in the reach of a wealthy nation-state.

Engin Kirda, a professor at Northeastern University in Boston who specializes in malware detection and analysis, says he wouldn’t be surprised if this was already happening. “I’m sure people are investing in it, but I’m also pretty sure people are already doing it, especially [in] China—they have good AI capabilities,” he says.

It’s a pretty scary possibility. But it’s one that—thankfully—is still only theoretical. A large-scale campaign that is both effective and clearly AI-driven has yet to materialize. What we can say is that generative AI is already significantly lowering the bar for criminals. They’ll keep experimenting with the newest releases and updates and trying to find new ways to trick us into parting with important information and precious cash. For now, all we can do is be careful, remain vigilant, and—for all our sakes—stay on top of those system updates.

Four ways to think about this year&#39;s reckoning.

By studying large language models as if they were living things instead of computer programs, scientists are discovering some of their secrets for the first time.

The viral social network for bots reveals more about our own current mania for AI as it does about the future of agents.

In an exclusive interview, the AI pioneer shares his plans for his new Paris-based company, AMI Labs.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-56')">
            <div class="source">MIT Technology Review</div>
            <div class="title">Why EVs are gaining ground in Africa</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-56" style="display:none;">
            <h2>Why EVs are gaining ground in Africa</h2>
            <p><strong>MIT Technology Review | 2026-02-12</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2026/02/12/1132790/evs-progress-africa/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">EVs are getting cheaper and more common all over the world. But the technology still faces major challenges in some markets, including many countries in Africa.

Some regions across the continent still have limited grid and charging infrastructure, and those that do have widespread electricity access sometimes face reliability issues—a problem for EV owners, who require a stable electricity source to charge up and get around.

But there are some signs of progress. I just finished up a story about the economic case: A recent study in Nature Energy found that EVs from scooters to minibuses could be cheaper to own than gas-powered vehicles in Africa by 2040.

If there’s one thing to know about EVs in Africa, it’s that each of the 54 countries on the continent faces drastically different needs, challenges, and circumstances. There’s also a wide range of reasons to be optimistic about the prospects for EVs in the near future, including developing policies, a growing grid, and an expansion of local manufacturing.

Even the world’s leading EV markets fall short of Ethiopia’s aggressively pro-EV policies. In 2024, the country became the first in the world to ban the import of non-electric private vehicles.

The case is largely an economic one: Gasoline is expensive there, and the country commissioned Africa’s largest hydropower dam in September 2025, providing a new source of cheap and abundant clean electricity. The nearly $5 billion project has a five-gigawatt capacity, doubling the grid’s peak power in the country.

Much of Ethiopia’s vehicle market is for used cars, and some drivers are still opting for older gas-powered vehicles. But this nudge could help increase the market for EVs there.

Other African countries are also pushing some drivers toward electrification. Rwanda banned new registrations for commercial gas-powered motorbikes in the capital city of Kigali last year, encouraging EVs as an alternative. These motorbike taxis can make up over half the vehicles on the city’s streets, so the move is a major turning point for transportation there.

Smaller two- and three-wheelers are a bright spot for EVs globally: In 2025, EVs made up about 45% of new sales for such vehicles. (For cars and trucks, the share was about 25%.)

And Africa’s local market is starting to really take off. There’s already some local assembly of electric two-wheelers in countries including Morocco, Kenya, and Rwanda, says Nelson Nsitem, lead Africa energy transition analyst at BloombergNEF, an energy consultancy.

Spiro, a Dubai-based electric motorbike company, recently raised $100 million in funding to expand operations in Africa. The company currently assembles its bikes in Uganda, Kenya, Nigeria, and Rwanda, and as of October it has over 60,000 bikes deployed and 1,500 battery swap stations operating.

Assembly and manufacturing for larger EVs and batteries is also set to expand. Gotion High-Tech, a Chinese battery company, is currently building Africa’s first battery gigafactory. It’s a $5.6 billion project that could produce 20 gigawatt-hours of batteries annually, starting in 2026. (That’s enough for hundreds of thousands of EVs each year.)

Chinese EV companies are looking to growing markets like Southeast Asia and Africa as they attempt to expand beyond an oversaturated domestic scene. BYD, the world’s largest EV company, is aggressively expanding across South Africa and plans to have as many as 70 dealerships in the country by the end of this year. That will mean more options for people in Africa looking to buy electric.

“You have very high-quality, very affordable vehicles coming onto the market that are benefiting from the economies of scale in China. These countries stand to benefit from that,” says Kelly Carlin, a manager in the program on carbon-free transportation at the Rocky Mountain Institute, an energy think tank. “It’s a game changer,” he adds.

This article is from The Spark, MIT Technology Review’s weekly climate newsletter. To receive it in your inbox every Wednesday, sign up here.

As early electric cars age out, hundreds of thousands of used batteries are flooding the market, fueling a gray recycling economy even as Beijing and big manufacturers scramble to build a more orderly system.

A cheaper, safer, and more abundant alternative to lithium is finally making its way into cars—and the grid.

Omar Yaghi thinks crystals with gaps that capture moisture could bring technology from “Dune” to the arid parts of Earth.

One project aims to harness local geothermal resources to pull CO2 from the air. Will it prove that carbon removal can really help our warming planet?

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-57')">
            <div class="source">MIT Technology Review</div>
            <div class="title">What’s next for Chinese open-source AI</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-57" style="display:none;">
            <h2>What’s next for Chinese open-source AI</h2>
            <p><strong>MIT Technology Review | 2026-02-12</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2026/02/12/1132811/whats-next-for-chinese-open-source-ai/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">MIT Technology Review’s What’s Next series looks across industries, trends, and technologies to give you a first look at the future. You can read the rest of them here.

The past year has marked a turning point for Chinese AI. Since DeepSeek released its R1 reasoning model in January 2025, Chinese companies have repeatedly delivered AI models that match the performance of leading Western models at a fraction of the cost.

Just last week the Chinese firm Moonshot AI released its latest open-weight model, Kimi K2.5, which came close to top proprietary systems such as Anthropic’s Claude Opus on some early benchmarks. The difference: K2.5 is roughly one-seventh Opus’s price.

On Hugging Face, Alibaba’s Qwen family—after ranking as the most downloaded model series in 2025 and 2026—has overtaken Meta’s Llama models in cumulative downloads. And a recent MIT study found that Chinese open-source models have surpassed US models in total downloads. For developers and builders worldwide, access to near-frontier AI capabilities has never been this broad or this affordable.

But these models differ in a crucial way from most US models like ChatGPT or Claude, which you pay to access and can’t inspect. The Chinese companies publish their models’ weights—numerical values that get set when a model is trained—so anyone can download, run, study, and modify them.

If these open-source AI models keep getting better, they will not just offer the cheapest options for people who want access to frontier AI capabilities; they will change where innovation happens and who sets the standards.

When DeepSeek launched R1, much of the initial shock centered on its origin. Suddenly, a Chinese team had released a reasoning model that could stand alongside the best systems from US labs. But the long tail of DeepSeek’s impact had less to do with nationality than with distribution. R1 was released as an open-weight model under a permissive MIT license, allowing anyone to download, inspect, and deploy it. On top of that, DeepSeek also published a paper detailing its training process and techniques. For developers who access models via an API, DeepSeek also undercut competitors on price, offering access at a fraction the cost of OpenAI’s o1, the leading proprietary reasoning model at the time.

Within days of its release, DeepSeek replaced ChatGPT as the most downloaded free app in the US App Store. The moment spilled beyond developer circles into financial markets, triggering a sharp sell-off in US tech stocks that briefly erased roughly $1 trillion in market value. Almost overnight, DeepSeek went from a little-known spin-off team backed by a quantitative hedge fund to the most visible symbol of China’s push for open-source AI.

China’s decision to lean in to open source isn’t surprising. It has the world’s second-largest concentration of AI talent after the US. plus a vast, well-resourced tech industry. After ChatGPT broke into the mainstream, China’s AI sector went through a reckoning—and emerged determined to catch up. Pursuing an open-source strategy was seen as the fastest way to close the gap by rallying developers, spreading adoption, and setting standards.

DeepSeek’s success injected confidence into an industry long used to following global standards rather than setting them. “Thirty years ago, no Chinese person would believe they could be at the center of global innovation,” says Alex Chenglin Wu, CEO and founder of Atoms, an AI agent company and prominent contributor to China’s open-source ecosystem. “DeepSeek shows that with solid technical talent, a supportive environment, and the right organizational culture, it’s possible to do truly world-class work.”

DeepSeek’s breakout moment wasn’t China’s first open-source success. Alibaba’s Qwen Lab had been releasing open-weight models for years. By September 2024,  well before DeepSeek’s V3 launch, Alibaba was saying that global downloads had exceeded 600 million. On Hugging Face, Qwen accounted for more than 30% of all model downloads in 2024. Other institutions, including the Beijing Academy of Artificial Intelligence and the AI firm Baichuan, were also releasing open models as early as 2023.

But since the success of DeepSeek, the field has widened rapidly. Companies such as Z.ai (formerly Zhipu), MiniMax, Tencent, and a growing number of smaller labs have released models that are competitive on reasoning, coding, and agent-style tasks. The growing number of capable models has sped up progress. Capabilities that once took months to make it to the open-source world now emerge within weeks, even days.

“Chinese AI firms have seen real gains from the open-source playbook,” says Liu Zhiyuan, a professor of computer science at Tsinghua University and chief scientist at the AI startup ModelBest. “By releasing strong research, they build reputation and gain free publicity.”

Beyond commercial incentives, Liu says, open source has taken on cultural and strategic weight. “In the Chinese programmer community, open source has become politically correct,” he says, framing it as a response to US dominance in proprietary AI systems.

That shift is also reflected at the institutional level. Universities including Tsinghua have begun encouraging AI development and open-source contributions, while policymakers have moved to formalize those incentives. In August, China’s State Council released a draft policy encouraging universities to reward open-source work, proposing that students’ contributions on platforms such as GitHub or Gitee could eventually be counted toward academic credit.

With growing momentum and a reinforcing feedback loop, China’s push for open-source models is likely to continue in the near term, though its long-term sustainability still hinges on financial results, says Tiezhen Wang, who helps lead work on global AI at Hugging Face. In January, the model labs Z.ai and MiniMax went public in Hong Kong. “Right now, the focus is on making the cake bigger,” says Wang. “The next challenge is figuring out how each company secures its share.”

Chinese open-source models are leading not just in download volume but also in variety. Alibaba’s Qwen has become one of the most diversified open model families in circulation, offering a wide range of variants optimized for different uses. The lineup ranges from lightweight models that can run on a single laptop to large, multi-hundred-billion-parameter systems designed for data-center deployment. Qwen features many task-optimized variants created by the community: the “instruct” models are good at following orders, and “code” variants specialize in coding.

Although this strategy isn’t unique to Chinese labs, Qwen was the first open model family to roll out so many high-quality options that it started to feel like a full product line—one that’s free to use.

The open-weight nature of these releases also makes it easy for others to adapt them through techniques like fine-tuning and distillation, which means training a smaller model to mimic a larger one.  According to ATOM (American Truly Open Models), a project by the AI researcher Nathan Lambert, by August 4, 2025, model variations derived from Qwen were “more than 40%” of new Hugging Face language-model derivatives, while Llama had fallen to about 15%. This means that Qwen has become the default base model for all the “remixes.”

This pattern has made the case for smaller, more specialized models. “Compute and energy are real constraints for any deployment,” Liu says. He told MIT Technology Review that the rise of small models is about making AI cheaper to run and easier for more people to use. His company, ModelBest, focuses on small language models designed to run locally on devices such as phones, cars, and other consumer hardware.

While an average user might interact with AI only through the web or an app for simple conversations, power users of AI models with some technical background are experimenting with giving AI more autonomy to solve large-scale problems. OpenClaw, an open-source AI agent that recently went viral within the AI hacker world, allows AI to take over your computer—it can run 24-7, going through your emails and work tasks without supervision.

OpenClaw, like many other open-source tools, allows users to connect to different AI models via an application programming interface, or API. Within days of OpenClaw’s release, the team revealed that Kimi’s K2.5 had surpassed Claude Opus and became the most used AI model—by token count, meaning it was handling more total text processed across user prompts and model responses.

Cost has been a major reason Chinese models have gained traction, but it would be a mistake to treat them as mere “dupes” of Western frontier systems, Wang suggests. Like any product, a model only needs to be good enough for the job at hand.

The landscape of open-source models in China is also getting more specialized. Research groups such as Shanghai AI Laboratory have released models geared toward scientific and technical tasks; several projects from Tencent have focused specifically on music generation. Ubiquant, a quantitative finance firm like DeepSeek’s parent High-Flyer, has released an open model aimed at medical reasoning.

In the meantime, innovative architectural ideas from Chinese labs are being picked up more broadly. DeepSeek has published work exploring model efficiency and memory; techniques that compress the model’s attention “cache,” reducing memory and inference costs while mostly preserving performance, have drawn significant attention in the research community.

“The impact of these research breakthroughs is amplified because they’re open-sourced and can be picked up quickly across the field,” says Wang.

The adoption of Chinese models is picking up in Silicon Valley, too. Martin Casado, a general partner at Andreessen Horowitz, has put a number on it: Among startups pitching with open-source stacks, there’s about an 80% chance they’re running on Chinese open models, according to a post he made on X. Usage data tells a similar story. OpenRouter,  a middleman that tracks how people use different AI models through its API, shows Chinese open models rising from almost none in late 2024 to nearly 30% of usage in some recent weeks.

The demand is also rising globally. Z.ai limited new subscriptions to its GLM coding plan (a coding tool based on its flagship GLM models) after demand surged, citing compute constraints. What’s notable is where the demand is coming from: CNBC reports that the system’s user base is primarily concentrated in the United States and China, followed by India, Japan, Brazil, and the UK.

“The open-source ecosystems in China and the US are tightly bound together,” says Wang at Hugging Face. Many Chinese open models still rely on Nvidia and US cloud platforms to train and serve them, which keeps the business ties tangled. Talent is fluid too: Researchers move across borders and companies, and many still operate as a global community, sharing code and ideas in public.

That interdependence is part of what makes Chinese developers feel optimistic about this moment: The work travels, gets remixed, and actually shows up in products. But openness can also accelerate the competition. Dario Amodei, the CEO of Anthropic, made a version of this point after DeepSeek’s 2025 releases: He wrote that export controls are “not a way to duck the competition” between the US and China, and that AI companies in the US “must have better models” if they want to prevail.

For the past decade, the story of Chinese tech in the West has been one of big expectations that ran into scrutiny, restrictions, and political backlash. This time the export isn’t just an app or a consumer platform. It’s the underlying model layer that other people build on. Whether that will play out differently is still an open question.

Four ways to think about this year&#39;s reckoning.

By studying large language models as if they were living things instead of computer programs, scientists are discovering some of their secrets for the first time.

The viral social network for bots reveals more about our own current mania for AI as it does about the future of agents.

In an exclusive interview, the AI pioneer shares his plans for his new Paris-based company, AMI Labs.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-58')">
            <div class="source">MIT Technology Review</div>
            <div class="title">Is a secure AI assistant possible?</div>
            <div class="meta">2026-02-11</div>
        </div>
        
        <div id="content-58" style="display:none;">
            <h2>Is a secure AI assistant possible?</h2>
            <p><strong>MIT Technology Review | 2026-02-11</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2026/02/11/1132768/is-a-secure-ai-assistant-possible/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">AI agents are a risky business. Even when stuck inside the chatbox window, LLMs will make mistakes and behave badly. Once they have tools that they can use to interact with the outside world, such as web browsers and email addresses, the consequences of those mistakes become far more serious.

That might explain why the first breakthrough LLM personal assistant came not from one of the major AI labs, which have to worry about reputation and liability, but from an independent software engineer, Peter Steinberger. In November of 2025, Steinberger uploaded his tool, now called OpenClaw, to GitHub, and in late January the project went viral.

OpenClaw harnesses existing LLMs to let users create their own bespoke assistants. For some users, this means handing over reams of personal data, from years of emails to the contents of their hard drive. That has security experts thoroughly freaked out. The risks posed by OpenClaw are so extensive that it would probably take someone the better part of a week to read all of the security blog posts on it that have cropped up in the past few weeks. The Chinese government took the step of issuing a public warning about OpenClaw’s security vulnerabilities.

In response to these concerns, Steinberger posted on X that nontechnical people should not use the software. (He did not respond to a request for comment for this article.) But there’s a clear appetite for what OpenClaw is offering, and it’s not limited to people who can run their own software security audits. Any AI companies that hope to get in on the personal assistant business will need to figure out how to build a system that will keep users’ data safe and secure. To do so, they’ll need to borrow approaches from the cutting edge of agent security research.

OpenClaw is, in essence, a mecha suit for LLMs. Users can choose any LLM they like to act as the pilot; that LLM then gains access to improved memory capabilities and the ability to set itself tasks that it repeats on a regular cadence. Unlike the agentic offerings from the major AI companies, OpenClaw agents are meant to be on 24-7, and users can communicate with them using WhatsApp or other messaging apps. That means they can act like a superpowered personal assistant who wakes you each morning with a personalized to-do list, plans vacations while you work, and spins up new apps in its spare time.

But all that power has consequences. If you want your AI personal assistant to manage your inbox, then you need to give it access to your email—and all the sensitive information contained there. If you want it to make purchases on your behalf, you need to give it your credit card info. And if you want it to do tasks on your computer, such as writing code, it needs some access to your local files.

There are a few ways this can go wrong. The first is that the AI assistant might make a mistake, as when a user’s Google Antigravity coding agent reportedly wiped his entire hard drive. The second is that someone might gain access to the agent using conventional hacking tools and use it to either extract sensitive data or run malicious code. In the weeks since OpenClaw went viral, security researchers have demonstrated numerous such vulnerabilities that put security-naïve users at risk.

Both of these dangers can be managed: Some users are choosing to run their OpenClaw agents on separate computers or in the cloud, which protects data on their hard drives from being erased, and other vulnerabilities could be fixed using tried-and-true security approaches.

But the experts I spoke to for this article were focused on a much more insidious security risk known as prompt injection. Prompt injection is effectively LLM hijacking: Simply by posting malicious text or images on a website that an LLM might peruse, or sending them to an inbox that an LLM reads, attackers can bend it to their will.

And if that LLM has access to any of its user’s private information, the consequences could be dire. “Using something like OpenClaw is like giving your wallet to a stranger in the street,” says Nicolas Papernot, a professor of electrical and computer engineering at the University of Toronto. Whether or not the major AI companies can feel comfortable offering personal assistants may come down to the quality of the defenses that they can muster against such attacks.

It’s important to note here that prompt injection has not yet caused any catastrophes, or at least none that have been publicly reported. But now that there are likely hundreds of thousands of OpenClaw agents buzzing around the internet, prompt injection might start to look like a much more appealing strategy for cybercriminals. “Tools like this are incentivizing malicious actors to attack a much broader population,” Papernot says.

The term “prompt injection” was coined by the popular LLM blogger Simon Willison in 2022, a couple of months before ChatGPT was released. Even back then, it was possible to discern that LLMs would introduce a completely new type of security vulnerability once they came into widespread use. LLMs can’t tell apart the instructions that they receive from users and the data that they use to carry out those instructions, such as emails and web search results—to an LLM, they’re all just text. So if an attacker embeds a few sentences in an email and the LLM mistakes them for an instruction from its user, the attacker can get the LLM to do anything it wants.

Prompt injection is a tough problem, and it doesn’t seem to be going away anytime soon. “We don’t really have a silver-bullet defense right now,” says Dawn Song, a professor of computer science at UC Berkeley. But there’s a robust academic community working on the problem, and they’ve come up with strategies that could eventually make AI personal assistants safe.

Technically speaking, it is possible to use OpenClaw today without risking prompt injection: Just don’t connect it to the internet. But restricting OpenClaw from reading your emails, managing your calendar, and doing online research defeats much of the purpose of using an AI assistant. The trick of protecting against prompt injection is to prevent the LLM from responding to hijacking attempts while still giving it room to do its job.

One strategy is to train the LLM to ignore prompt injections. A major part of the LLM development process, called post-training, involves taking a model that knows how to produce realistic text and turning it into a useful assistant by “rewarding” it for answering questions appropriately and “punishing” it when it fails to do so. These rewards and punishments are metaphorical, but the LLM learns from them as an animal would. Using this process, it’s possible to train an LLM not to respond to specific examples of prompt injection.

But there’s a balance: Train an LLM to reject injected commands too enthusiastically, and it might also start to reject legitimate requests from the user. And because there’s a fundamental element of randomness in LLM behavior, even an LLM that has been very effectively trained to resist prompt injection will likely still slip up every once in a while.

Another approach involves halting the prompt injection attack before it ever reaches the LLM. Typically, this involves using a specialized detector LLM to determine whether or not the data being sent to the original LLM contains any prompt injections. In a recent study, however, even the best-performing detector completely failed to pick up on certain categories of prompt injection attack.

The third strategy is more complicated. Rather than controlling the inputs to an LLM by detecting whether or not they contain a prompt injection, the goal is to formulate a policy that guides the LLM’s outputs—i.e., its behaviors—and prevents it from doing anything harmful. Some defenses in this vein are quite simple: If an LLM is allowed to email only a few pre-approved addresses, for example, then it definitely won’t send its user’s credit card information to an attacker. But such a policy would prevent the LLM from completing many useful tasks, such as researching and reaching out to potential professional contacts on behalf of its user.

“The challenge is how to accurately define those policies,” says Neil Gong, a professor of electrical and computer engineering at Duke University. “It’s a trade-off between utility and security.”

On a larger scale, the entire agentic world is wrestling with that trade-off: At what point will agents be secure enough to be useful? Experts disagree. Song, whose startup, Virtue AI, makes an agent security platform, says she thinks it’s possible to safely deploy an AI personal assistant now. But Gong says, “We’re not there yet.”

Even if AI agents can’t yet be entirely protected against prompt injection, there are certainly ways to mitigate the risks. And it’s possible that some of those techniques could be implemented in OpenClaw. Last week, at the inaugural ClawCon event in San Francisco, Steinberger announced that he’d brought a security person on board to work on the tool.

As of now, OpenClaw remains vulnerable, though that hasn’t dissuaded its multitude of enthusiastic users. George Pickett, a volunteer maintainer of the OpenGlaw GitHub repository and a fan of the tool, says he’s taken some security measures to keep himself safe while using it: He runs it in the cloud, so that he doesn’t have to worry about accidentally deleting his hard drive, and he’s put mechanisms in place to ensure that no one else can connect to his assistant.

But he hasn’t taken any specific actions to prevent prompt injection. He’s aware of the risk but says he hasn’t yet seen any reports of it happening with OpenClaw. “Maybe my perspective is a stupid way to look at it, but it’s unlikely that I’ll be the first one to be hacked,” he says.

Four ways to think about this year&#39;s reckoning.

By studying large language models as if they were living things instead of computer programs, scientists are discovering some of their secrets for the first time.

The viral social network for bots reveals more about our own current mania for AI as it does about the future of agents.

In an exclusive interview, the AI pioneer shares his plans for his new Paris-based company, AMI Labs.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-59')">
            <div class="source">MIT Technology Review</div>
            <div class="title">The Download: inside the QuitGPT movement, and EVs in Africa</div>
            <div class="meta">2026-02-11</div>
        </div>
        
        <div id="content-59" style="display:none;">
            <h2>The Download: inside the QuitGPT movement, and EVs in Africa</h2>
            <p><strong>MIT Technology Review | 2026-02-11</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2026/02/11/1132724/the-download-inside-the-quitgpt-movement-and-evs-in-africa/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">This is today&#39;s edition of The Download, our weekday newsletter that provides a daily dose of what&#39;s going on in the world of technology.

A “QuitGPT” campaign is urging people to cancel their ChatGPT subscriptions

In September, Alfred Stephen, a freelance software developer in Singapore, purchased a ChatGPT Plus subscription, which costs $20 a month and offers more access to advanced models, to speed up his work. But he grew frustrated with the chatbot’s coding abilities and its gushing, meandering replies. Then he came across a post on Reddit about a campaign called QuitGPT.QuitGPT is one of the latest salvos in a growing movement by activists and disaffected users to cancel their subscriptions. In just the past few weeks, users have flooded Reddit with stories about quitting the chatbot. And while it’s unclear how many users have joined the boycott, there’s no denying QuitGPT is getting attention. Read the full story.

EVs could be cheaper to own than gas cars in Africa by 2040

Electric vehicles could be economically competitive in Africa sooner than expected. Just 1% of new cars sold across the continent in 2025 were electric, but a new analysis finds that with solar off-grid charging, EVs could be cheaper to own than gas vehicles by 2040.There are major barriers to higher EV uptake in many countries in Africa, including a sometimes unreliable grid, limited charging infrastructure, and a lack of access to affordable financing. But as batteries and the vehicles they power continue to get cheaper, the economic case for EVs is building. Read the full story.

MIT Technology Review Narrated: How next-generation nuclear reactors break out of the 20th-century blueprint

The popularity of commercial nuclear reactors has surged in recent years as worries about climate change and energy independence drowned out concerns about meltdowns and radioactive waste.The problem is, building nuclear power plants is expensive and slow.

A new generation of nuclear power technology could reinvent what a reactor looks like—and how it works. Advocates hope that new tech can refresh the industry and help replace fossil fuels without emitting greenhouse gases.This is our latest story to be turned into a MIT Technology Review Narrated podcast, which we’re publishing each week on Spotify and Apple Podcasts. Just navigate to MIT Technology Review Narrated on either platform, and follow us to get all our new content as it’s released.

I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.

1 Social media giants have agreed to be rated on teen safety Meta, TikTok and Snap will undergo independent assessments over how effectively they protect the mental health of teen users. (WP $)+ Discord, YouTube, Pinterest, Roblox and Twitch have also agreed to be graded. (LA Times $)2 The FDA has refused to review Moderna’s mRNA flu vaccineIt’s the latest in a long line of anti-vaccination moves the agency is making. (Ars Technica)+ Experts worry it’ll have a knock-on effect on investment in future vaccines. (The Guardian)+ Moderna says it was blindsided by the decision. (CNN)3 EV battery factories are pivoting to manufacturing energy cells Energy storage systems are in, electric vehicles are out. (FT $)4 Why OpenAI killed off ChatGPT’s 4o modelThe qualities that make it attractive for some users make it incredibly risky for others. (WSJ $)+ Bereft users have set up their own Reddit community to mourn. (Futurism)+ Why GPT-4o’s sudden shutdown left people grieving. (MIT Technology Review)

5 Drug cartels have started laundering money through cryptoAnd law enforcement is struggling to stop them. (Bloomberg $)

6 Morocco wants to build an AI for AfricaThe country’s Minister of Digital Transition has a plan. (Rest of World)+ What Africa needs to do to become a major AI player. (MIT Technology Review)

7 Christian influencers are bowing out of the news cycleThey’re choosing to ignore world events to protect their own inner peace. (The Atlantic $)

8 An RFK Jr-approved diet is pretty joylessDon’t expect any dessert, for one. (Insider $)+ The US government’s health site uses Grok to dispense nutrition advice. (Wired $)

9 Don’t toss out your used vapeHackers can give it a second life as a musical synthesizer. (Wired $)10 An ice skating duo danced to AI music at the Winter Olympics ⛸️Centuries of bangers to choose from, and this is what they opted for. (TechCrunch)+ AI is coming for music, too. (MIT Technology Review)

“These companies are terrified that no one’s going to notice them.”

—Tom Goodwin, co-founder of business consulting firm All We Have Is Now, tells the Guardian why AI startups are going to increasingly desperate measures to grab would-be customers’ attention.

How AI is changing gymnastics judgingThe 2023 World Championships last October marked the first time an AI judging system was used on every apparatus in a gymnastics competition. There are obvious upsides to using this kind of technology: AI could help take the guesswork out of the judging technicalities. It could even help to eliminate biases, making the sport both more fair and more transparent.At the same time, others fear AI judging will take away something that makes gymnastics special. Gymnastics is a subjective sport, like diving or dressage, and technology could eliminate the judges’ role in crafting a narrative.For better or worse, AI has officially infiltrated the world of gymnastics. The question now is whether it really makes it fairer. Read the full story.

A place for comfort, fun and distraction to brighten up your day. (Got any ideas? Drop me a line or skeet &#39;em at me.)+ Today marks the birthday of the late, great Leslie Nielsen—one of the best to ever do it.+ Congratulations are in order for Hannah Cox, who has just completed 100 marathons in 100 days across India in her dad’s memory.+ Feeling down? A trip to Finland could be just what you need.+ We love Padre Guilherme, the Catholic priest dropping incredible Gregorian chant beats.

Plus: TikTok has finally signed a deal to keep operating in the US

Plus: This company is developing gene therapies for muscle growth, erectile dysfunction, and “radical longevity”

Plus: China has built a major chip-making machine

Plus: more European countries are considering banning social media for under-16s

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-60')">
            <div class="source">The Next Web</div>
            <div class="title">Stop talking to AI, let them talk to each other: The A2A protocol</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-60" style="display:none;">
            <h2>Stop talking to AI, let them talk to each other: The A2A protocol</h2>
            <p><strong>The Next Web | 2026-02-12</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/stop-talking-to-ai-let-them-talk-to-each-other-the-a2a-protocol">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Have you ever asked Alexa to remind you to send a WhatsApp message at a determined hour? And then you just wonder, ‘Why can’t Alexa just send the message herself?

Or the incredible frustration when you use an app to plan a trip, only to have to jump to your calendar/booking website/tour/bank account instead of your AI assistant doing it all? Well, exactly this gap between AI automation and human action is what the agent-to-agent (A2A) protocol aims to address.

With the introduction of AI Agents, the next step of evolution seemed to be communication. But when communication between machines and humans is already here, what’s left?

Well, thinking about creating a multi-agent ecosystem to break the siloes between data systems and applications, Google announced the A2A protocol last year, in collaboration with more than 50 tech partners, an open standard protocol that allows AI agents to communicate, securely exchange information, collaborate, and operate between agentic applications and complex enterprise workflows, no matter their underlying technology.

A2A is designed under five principles, which are natural capabilities. It enables the agents to collaborate in their natural modality without an intermediary tool, allowing agents to retain their individual capabilities and independence.

TNW City Coworking space - Where your best work happens

A workspace designed for growth, collaboration, and endless networking opportunities in the heart of tech.

It is built on existing standards, making it easier to integrate with existing IT stacks, and paired with OpenAPI’s (Application Programming Interfaces) authentication schemes to guarantee secure collaboration. It provides real-life feedback as well as asynchronous notifications for long-running operations (LRO). Lastly, it was designed to support various modalities, including text, audio, and video streaming.

Announcing the Agent2Agent Protocol (A2A). Image: Google

A2A works as a facilitator between a “client” agent and a “remote” agent. The client agent requests and communicates the tasks, while the remote agent is responsible for taking action on those tasks, looking for the best solution or input. This process involves several stages and key components:

This protocol complements Anthropic’s Model Context Protocol (MCP) for building robust agentic applications, since MCP provides agent-to-tool communication, allowing a better understanding and processing of abstract APIs to be used as tools, while the A2A protocol enables agents to discover each other’s capabilities, supporting the growth of agentic systems.

The A2A protocol was built to tackle the interoperability gap between specialized AI agents, with enterprise-scale adoption in mind. Instead of treating agents as isolated tools, like MCP works, A2A enables a shared ecosystem where agents can interact as agents, preserving their unique capabilities and higher-quality outcomes.

It also rethinks execution by allowing customizable, secure collaboration between opaque agents, preserving data privacy and intellectual property by design. As the number of agents and interactions grows, A2A addresses scalability head-on, enabling seamless integration and the emergence of complex AI ecosystems within enterprise systems, while relying on established standards, like HTTPS, and JSON-RPC to avoid reinventing core technologies, and existing web standards for authentication, authorization, security, privacy, tracing, and monitoring.

A2A has applications across a wide range of industries, including customer service, supply chain, human resources, healthcare, research, education, creative industries, public services, financial services, IT operations, and consulting.

By enabling agent collaboration across applications and organizations, it supports advanced data analysis and task automation, from background screenings and inventory logistics to enhanced fraud detection and highly personalized customer solutions.

Despite its promises, A2A is not without challenges. Like most distributed systems, one of the main concerns is security. Continuous back-and-forth communication within agents increases the threat to security across multiple layers, from identity and message, to context propagation and system management.

This problem highlights the need for an intrinsic identity, integrity, and sequencing guarantees for A2A, alongside the challenge of including this without compromising its lightweight design and interoperability.

A second limitation emerges at the architectural level, particularly in enterprise-scale AI communication. A2A relies primarily on HTTPS and high-performance Remote Procedure Call (RPC) in direct point-to-point communication.

While this works on a small scale, it can become a complex and unsustainable risk for large-scale enterprise environments. Single changes, overlaps, failures, or misrouted messages can cause cascade effects, enabling potential operational risk unless complemented with additional orchestration and governance mechanisms.

The incredibly fast introduction and adoption of AI agents, from AI agents to Agentic AI, has made it a necessity to be able to evolve alongside the technology. A2A marks a clear shift in how AI systems are thought and designed, creating an ecosystem to break the siloes and allowing cross-collaboration among agents.

It is, doubtlessly, necessary for modernity, and while it presents challenges and limitations, it is worth remembering that it is still in early stages and improvements will come while the protocol matures.

Alongside the MCP and LLMs, A2A enables a broader agent stack that suggests an emerging blueprint for agentic AI: where communication, execution, and governance are managed at distinct layers, enabling agents to act in real-world systems.

The real significance of A2A is what it signals about where AI is heading. The next generation of AI will not be defined by a single, all-purpose model, but by interconnected ecosystems of agents designed to work together by default.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-61')">
            <div class="source">The Next Web</div>
            <div class="title">Swedish pet insurtech Lassie raises $75M Series C after hitting $100M ARR</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-61" style="display:none;">
            <h2>Swedish pet insurtech Lassie raises $75M Series C after hitting $100M ARR</h2>
            <p><strong>The Next Web | 2026-02-12</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/swedish-pet-insurtech-lassie-raises-75m-series-c-after-hitting-100m-arr">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Imagine the moment you bring a new dog or cat into your life. That mix of excitement and responsibility. Vet visits, vaccines, learning what food suits them, managing check-ups, and always wondering how to keep them healthy as they grow.

Most pet insurance only steps in after a costly accident or illness. It doesn’t help you avoid the situation in the first place. Lassie’s product is built around a different insight: giving owners the tools to look after their pets every day, not just when something goes wrong.

Now, Stockholm-based insurtech Lassie has secured $75 million in a Series C round as it moves to scale its automated, preventive-first pet care platform across Europe. The financing follows a strong commercial run in which Lassie surpassed $100 million in annual recurring revenue (ARR), a notable milestone for a pet-focused underwriting business.

The round drew support from prominent European investors, including Balderton Capital, Felix Capital, Inventure, Passion Capital, and Stena Sessan, signaling broad interest in technologies that blur the line between insurance and day-to-day wellbeing.

TNW City Coworking space - Where your best work happens

A workspace designed for growth, collaboration, and endless networking opportunities in the heart of tech.

Lassie was founded to rethink pet insurance not as a passive safety net but as an active partner in animal health. Its app encourages owners to track diet, activity, and preventive health behaviours, earning rewards and lowering premiums along the way.

At the same time, its backend uses automation and AI to streamline claims, in some cases completing reimbursements within minutes after users upload a bill.

Surpassing $100 million in ARR positions Lassie among the faster-growing insurtechs in Europe. Its core markets include Sweden, Germany, and France, and the fresh capital will accelerate further rollout into key European territories.

Moreover, the company plans to invest in its AI claims and preventive health stack, deepen partnerships with brands such as Lidl and Tractive, and explore adjacent services within the broader pet care category.

At its core, Lassie’s rise is a reflection of how people now think about pets: not as occasional expenses but as family members whose health matters every day. It is shaping an ecosystem where care, knowledge, and proactive habits are as much part of the offering as reimbursement for vet bills.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-62')">
            <div class="source">The Next Web</div>
            <div class="title">Understanding the valuation of intangible assets in tech deals</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-62" style="display:none;">
            <h2>Understanding the valuation of intangible assets in tech deals</h2>
            <p><strong>The Next Web | 2026-02-12</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/understanding-the-valuation-of-intangible-assets-in-tech-deals">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">In a technology M&A deal, whether you are acquiring or selling a tech or software business, valuation rarely hinges on a single dimension.

Financial performance, growth efficiency, and cash flow durability remain the backbone of any transaction. In practical terms, this means metrics such as revenue and ARR, retention as a proxy for revenue quality, margin structure, and capital intensity continue to anchor how buyers price risk.

However, alongside these tangible indicators sits another layer of value, one that does not always surface cleanly in financial statements and may even remain invisible if it is not properly understood or articulated: intangible assets.

Put simply, intangible assets are the non-physical elements a company has built that enable it to generate revenue, scale efficiently, or defend its market position. In technology companies, this typically includes proprietary software, intellectual property, datasets, customer relationships, brand equity, and internal systems or processes.

Many of these assets do not fully appear in financial statements. Others are only partially captured through accounting treatment. Yet in a transaction context, they often influence how sustainable, transferable, and defensible a company’s performance really is.

The latest rumblings from the EU tech scene, a story from our wise ol&#39; founder Boris, and some questionable AI art. It&#39;s free, every week, in your inbox. Sign up now!

Understanding how tangible performance and intangible value interact, rather than compete, is key to interpreting how modern technology deals are ultimately priced. For founders in particular, recognising and articulating this invisible layer of value can meaningfully influence how buyers assess upside and risk.

When evaluating the opportunity to acquire a business, before any discussion of intellectual property or strategic upside enters the room, investors and acquirers start by looking at the fundamentals. These typically include:

These financial metrics ultimately determine whether a deal fits within an acquirer’s investment thesis, its baseline valuation range, and, where relevant, its financing capacity (think LBOs). In this sense, they shape downside protection for both buyers and lenders.

This also explains why a company with weak financial fundamentals will struggle to command an above-market valuation, or even sustained interest, purely on the strength of its technology or brand.

However, once those fundamentals are established, buyers begin looking beneath the performance. That is where intangible assets have the opportunity to influence perception and pricing.

Two companies may show similar revenue, growth, and margin profiles on paper. Yet one may command a higher valuation than the other. The difference often lies in how durable and transferable their performance really is, and how well their story aligns with an acquirer’s strategic priorities. That is the kind of value reflected in a well-structured narrative of intangible value.

In software businesses, value creation is embedded in systems rather than physical infrastructure. Recurring revenue is supported by intellectual property, scalable processes, integrations, switching costs, customer success frameworks, and brand trust. None of these sit neatly on a balance sheet, yet all shape how defensible revenue will be post-acquisition.

From a buyer’s perspective, the question is not only how the company has performed, but how repeatable that performance will be under new ownership.

To analyse intangible assets more systematically, specialist consulting teams such as COFI solutions, often group them into four different components of intellectual capital. This helps structure due diligence and isolate risk.

Customer capital reflects the value embedded in commercial relationships.

This includes contracted recurring revenue, retention dynamics, expansion pathways, brand loyalty, and market access. In many technology acquisitions, buyers underwrite the predictability and growth potential of the customer base as much as the product itself.

There are transactions where access to customers or distribution is the primary driver. A buyer may already have comparable technology but lack penetration in a specific vertical or geography. Acquiring that customer ecosystem can accelerate growth far faster than building it organically.

Talent concentration is another defining characteristic of software companies. This is why the term “acquihire” is often used to describe acquisitions primarily driven by the desire to secure talent, a dynamic more common in lower- to mid-market transactions.

From a deal standpoint, engineering expertise, product vision, and institutional knowledge often sit with relatively small teams. This makes human capital highly valuable, but also fragile.

Key considerations in M&A transactions typically include founder dependency, retention risk, leadership depth, and cultural alignment. If too much knowledge sits with a handful of individuals, buyers will structure protections accordingly.

In acquihire scenarios, for instance, retention structures and incentive packages become central to preserving deal value.

Structural capital refers to the institutionalised knowledge that remains within the company, independent of specific individuals.

Examples include proprietary codebases, documented product architecture, patents, data infrastructure, operating playbooks, and internal tooling.

For acquirers, structural capital is often the most transferable form of intangible value. Well-documented systems reduce post-acquisition integration risk and allow buyers to scale the platform without relying on any single employee.

Partnership ecosystems can also influence valuation where they unlock revenue or create defensibility. This includes channel partnerships, platform integrations, supplier agreements, and marketplace relationships.

Acquirers will assess how durable these partnerships are and whether they transfer contractually post-transaction. Agreements containing change-of-control clauses, for instance, can introduce risk.

Where alliances materially drive growth, they can become an embedded component of enterprise value when supported by a robust strategic rationale.

Despite their abstract nature, intangible assets are not valued purely on narrative. Acquirers typically triangulate across several methodologies to ground their assessment. The three more common approaches are:

In software, this includes engineering time, development cost, data accumulation, and opportunity cost. If a platform represents years of R&D investment, its replacement cost can establish a meaningful valuation baseline.

2. Income approach: Here, the focus shifts to future cash flows attributable to the intangible asset.

For example, proprietary technology that enables premium pricing or higher retention may justify incremental valuation. The same applies to automation systems that structurally improve margins. This approach directly links intellectual property to financial performance.

3. Transferability analysis: Not all intangible value transfers equally.

Assets embedded in code, contracts, or documented processes move relatively cleanly. Knowledge held informally by founders or key employees is harder to transfer and, therefore risk-adjusted in pricing.

This is why documentation depth, process institutionalisation, and talent retention planning feature so prominently in diligence.

For founders, the practical importance of intangible assets often emerges during negotiation rather than the initial valuation setting.

While financial metrics explain historical performance and anchor valuation ranges, intangible assets help frame future potential and defensibility, often supporting outcomes towards the upper end of those ranges.

When clearly articulated, they can influence deal structure, including earn-out frameworks, rollover equity, and retention incentives.

They also help buyers underwrite post-deal risk. If revenue durability depends heavily on undocumented processes or founder relationships, that risk will be priced in.

Conversely, companies that institutionalise knowledge and diversify customer exposure tend to command stronger negotiating positions.

In founder-led processes, M&A advisors such as L40 often see valuation inflection points emerge when intellectual property, customer capital, and operational infrastructure are clearly mapped and evidenced during diligence.

The most sophisticated technology valuations do not treat tangible and intangible assets as competing forces. Instead, they assess how the two reinforce one another.

In other words, intangible assets help create alignment. Financial statements explain the past and the present performance of a business, and to some extent its sustainability, but intangible assets provide a lens through which to frame its future potential.

Strong financial performance without defensible intellectual property may limit strategic upside. Equally, strong technology without revenue traction rarely commands premium pricing.

The highest valuations tend to emerge where:

In that balance sits the true enterprise value of a software company. Performance establishes credibility. Intangible assets shape how far that performance can extend under new ownership.

L40 is an M&A advisory firm specializing in tech deals that work with technology founders to translate intangible assets into clear, defensible value during M&A processes, ensuring negotiations reflect what truly drives the business forward.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-63')">
            <div class="source">The Next Web</div>
            <div class="title">Aerska raises $39M to help RNA medicines reach the brain</div>
            <div class="meta">2026-02-11</div>
        </div>
        
        <div id="content-63" style="display:none;">
            <h2>Aerska raises $39M to help RNA medicines reach the brain</h2>
            <p><strong>The Next Web | 2026-02-11</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/aerska-raises-39m-to-help-rna-medicines-reach-the-brain">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">For families living with neurodegenerative disease, the hardest part is not always the diagnosis. It is the slow erosion that follows: memory fading, personality shifting, independence shrinking.

It unfolds quietly. First, forgotten appointments. Then repeated questions. Then moments when a familiar face no longer feels familiar.

The illness does not isolate itself to one body. It rearranges the lives around it. Partners become caregivers. Children become decision-makers. Conversations grow shorter. Patience grows thinner. Guilt creeps in, for being tired, for wishing things were easier, for missing the person who is still physically there.

Neurodegeneration is rarely a single patient story. It is a family condition, stretching across kitchens, hospital corridors, and years that feel longer than they should.

Dublin-based Aerska has raised $39 million in fresh funding to battle one of the biggest scientific barriers standing between patients and meaningful treatment: getting advanced genetic medicines into the brain.

The latest rumblings from the EU tech scene, a story from our wise ol&#39; founder Boris, and some questionable AI art. It&#39;s free, every week, in your inbox. Sign up now!

The round was co-led by EQT Life Sciences and age1, two investors known for backing high-risk, high-impact biotech. Their bet is not just on a platform, but on the possibility that diseases once managed only at the margins could eventually be slowed at their root.

Think of the brain as a house with very strict security at the door. That security system, called the blood-brain barrier, protects us from harmful substances in the blood. The problem is that it is so strict that it also blocks many medicines.

So even if scientists create a smart treatment that can “turn off” a harmful gene linked to diseases like Alzheimer’s, the drug often cannot physically get inside the brain cells where it needs to work.

Aerska is trying to solve that access problem.

Instead of injecting medicine directly into the brain, which is invasive and risky, they are developing a way to send it through the bloodstream like a normal injection. Their technology acts like a special pass that lets the treatment cross the brain’s security gate. Once inside, the medicine can reduce the production of the proteins that drive disease.

In simple terms, the science to switch off bad genes already exists. The hard part is delivery. Aerska is building the delivery vehicle.

The company’s early focus includes genetic drivers of conditions such as Alzheimer’s disease and Parkinson’s disease. Both remain incurable. Existing drugs largely manage symptoms rather than altering the course of decline.

RNA interference, by contrast, aims to reduce the production of disease-causing proteins themselves. It is a strategy that addresses biology upstream, not downstream.

Longevity has become the “American dream” in European biotech, yet most serious investors are looking less at life extension and more at healthspan,  years lived with clarity and autonomy.

That is the space Aerska is positioning itself in. The goal is not abstract immortality. It is more time at home, more recognisable faces, and more preserved dignity.

The $39 million will fund preclinical development and early clinical steps. The scientific obsacle remain significant, and neurological drug development has humbled many before. But systemic RNA delivery to the brain, if proven safe and effective, would mark a structural shift in how these diseases are approached.

For now, Aerska represents something simpler: a European biotech choosing to confront one of medicine’s most stubborn frontiers,  not with incremental symptom control, but with the ambition to change the trajectory itself.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-64')">
            <div class="source">The Next Web</div>
            <div class="title">The next Renaissance: Why creativity is the currency of the AI age</div>
            <div class="meta">2026-02-11</div>
        </div>
        
        <div id="content-64" style="display:none;">
            <h2>The next Renaissance: Why creativity is the currency of the AI age</h2>
            <p><strong>The Next Web | 2026-02-11</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/why-creativity-is-the-currency-of-the-ai-age">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">We stand at one of history’s most exhilarating crossroads. Artificial intelligence is rewriting the rules of work, business, and human potential at breathtaking speed. The very capabilities that make us most human, our creativity, our imagination, our ability to dream up what doesn’t yet exist, are becoming our most valuable assets.

This is not a story about humans versus machines. It’s a story about human potential unleashed. It’s about a future where technology handles the tedious so we can focus on the transcendent.

Where the dreamers, the questioners, the bold thinkers who color outside the lines are not just welcomed, they are essential.

Imagine a world where you never again have to spend hours on mind-numbing data entry, formatting documents, or wrestling with spreadsheets, where the repetitive tasks that drain your energy and dull your spirit are handled instantly by AI, freeing you to focus on work that genuinely excites you.

TNW City Coworking space - Where your best work happens

A workspace designed for growth, collaboration, and endless networking opportunities in the heart of tech.

What we are witnessing is not the replacement of human workers; it is the liberation of human potential. AI is taking on the equivalent of heavy lifting, and in doing so, it’s creating space for something extraordinary: a global renaissance of creative thinking.

Think about what becomes possible when you’re freed from the mundane. When a graphic designer no longer spends half their day on production tasks, they can explore ten bold creative directions instead of one safe option.

When a teacher is not buried in administrative work, they can devise innovative ways to spark curiosity in every student. When operational details do not consume an entrepreneur, they can envision entirely new possibilities for serving their customers.

This is the gift AI is giving us: time and mental space to be more fully human, more creative, more imaginative than ever before.

Here is what the smartest organisations are discovering: when everyone has access to the same powerful AI tools, the differentiator is not the technology. It’s the human wielding it.

Two companies can use identical AI platforms. One generates competent but forgettable content. The other creates campaigns that move people to tears, spark movements, and transform markets. The difference? Creative vision. Human imagination. The ability to ask questions that AI would never think to ask.

The most successful people in the AI era won’t be those who compete with machines at what machines do well. They will be those who ask better questions.

The creative thinker who asks “What if we completely reimagined this?” instead of “How can we make this 10% better?” The visionary who wonders “What problem are we not seeing?” instead of “How do we solve this defined problem?” The innovator who questions “Why are we doing this at all?” instead of “How can we do this more efficiently?”

These questions change trajectories. They open new possibilities. They create breakthroughs. And they can only come from curious, creative human minds willing to challenge assumptions and imagine alternatives.

It is true that AI will displace certain positions, as noted by the World Economic Forum’s Future of Jobs Report. It projects that 92 million roles will be displaced by 2030, with positions like graphic designers and administrative assistants among those facing decline due to automation and generative AI.

This technological disruption is simultaneously unleashing a creative renaissance. The same WEF report reveals that 170 million new roles will be created, resulting in a net gain of 78 million jobs, with creative thinking, resilience, flexibility, and agility emerging as some of the fastest-growing skills in demand alongside technical capabilities.

Forbes has noted that innovation and creativity rank among the top skills needed for the future, with employers recognising that while AI may displace 14% of jobs by 2030, the aspects of innovation that revolve around human empathy and deeper consciousness cannot be replicated by machines.

The message is clear: as AI handles the repetitive and predictable, human creativity becomes not just valuable but essential. Organisations are not looking for people who can compete with AI at computational tasks; they are seeking creative thinkers who can imagine entirely new possibilities and ask questions machines would never consider.

The uniquely human qualities of intuition, empathy, and visionary thinking to solve problems that have not even been defined yet.

Here is the beauty about creative thinking: it’s not a single skill or talent. It’s a constellation of capabilities, and each person’s constellation is unique.

Maybe you are brilliant at seeing patterns others miss, connecting dots across completely different domains. Perhaps you have an uncanny ability to understand what people truly need, even when they can’t articulate it themselves.

You might be exceptional at taking a spark of an idea and developing it into something magnificent, or at bringing people together in ways that generate creative breakthroughs.

Some creative thinkers are wildly imaginative, dreaming up possibilities that seem to come from nowhere. Others are integrative, synthesizing diverse ideas into coherent wholes. Some challenge every assumption; others build masterfully on existing foundations. Some think in images, others in systems, still others in stories.

Every version is valuable. Every version is needed.

The AI era does not demand that you become someone you’re not. It invites you to become more fully yourself: to lean into your natural creative strengths and develop them intentionally. Your particular way of thinking creatively is your signature, your competitive advantage, your gift to offer the world.

The creative thinkers of the next decade won’t be lone geniuses toiling in isolation. They will be collaborative creators, working alongside both humans and AI to achieve things neither could accomplish alone.

Imagine participating in creative collaborations where AI handles the analytical heavy lifting while you and your colleagues focus on vision, judgment, and inspiration. Where technology expands what’s possible while human creativity provides direction and meaning.

Where diverse perspectives combine with computational power to solve challenges that once seemed insurmountable.

This is already happening. Architects are using AI to explore thousands of design possibilities, then applying their creative judgment to create buildings that inspire.

Scientists are using AI to identify patterns in vast datasets, then applying creative thinking to formulate revolutionary hypotheses.

Artists are using AI as a creative tool, generating works that express uniquely human perspectives in entirely new ways. You can be part of this creative renaissance. Your ideas, your questions, your unique perspective matter more than ever.

The accelerating pace of change in our world makes creative thinking not just valuable but essential for adaptation and survival. The challenges we face: climate change, resource scarcity, social fragmentation, and emerging technologies with unpredictable consequences don’t have predetermined solutions in any playbook.

They require the kind of flexible, imaginative thinking that can break free from established frameworks and conventional wisdom. Moreover, as the half-life of specific technical skills continues to shrink, the ability to learn, unlearn, and relearn ( which is itself a creative process) becomes more important than mastery of any particular tool or technique.

Those who can think creatively can pivot between domains, see opportunities in disruption, and continuously reinvent themselves and their contributions.

Perhaps most importantly, creative thinking will be crucial for maintaining meaning and purpose in an increasingly automated world.

As machines handle more of our productivity, human value will increasingly derive from our capacity for original expression, cultural creation, emotional resonance, and the kind of meaning-making that gives life richness beyond mere efficiency.

The future is not about those who compete with machines at “machine like” tasks, but to those who can amplify their humanity by asking better questions, imagining more beautiful possibilities, and creating connections that matter.

The AI revolution is here, and it’s revealing a profound truth: the most powerful technology humans have ever created still can’t replicate the magic of human creativity. It can’t dream up what doesn’t exist. It can’t make intuitive leaps that defy logic. It can’t feel what matters, imagine what’s possible, or create meaning from chaos.

The next decade will belong to the creative thinkers because they are doing what AI cannot. They will ask better questions and make unexpected connections. Solving problems that have not been defined. Creating experiences that move people. Imagining futures worth building.

The next decade belongs to the creative thinkers. Make sure you are one of them.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-65')">
            <div class="source">The Next Web</div>
            <div class="title">Naboo raises $70M to turn AI event planning into corporate procurement platform</div>
            <div class="meta">2026-02-10</div>
        </div>
        
        <div id="content-65" style="display:none;">
            <h2>Naboo raises $70M to turn AI event planning into corporate procurement platform</h2>
            <p><strong>The Next Web | 2026-02-10</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/naboo-raises-70m">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Paris-headquartered Naboo has raised a $70m in Series B as it accelerates its ambition to become the operating layer for how large companies plan, book, and control corporate events. The round is led by Lightspeed Venture Partners, the same investor that backed Mistral AI in 2023, and lands just a year after Naboo closed a €20m Series A.

Naboo positions itself as an AI-powered procurement platform for corporate events, covering everything from venue booking and travel to supplier coordination and budget control.

Founded in 2022, Naboo built its name on simplifying how companies organise and run corporate events,  from booking venues and catering to logistics and attendee management, using an all-in-one platform that brings speed and transparency to a typically fragmented process.

By folding AI into what is traditionally a fragmented, manual process, the company says it has become Europe’s leading purchasing platform for corporate events, a corner of the broader $400bn global events market that has long resisted software consolidation.

The timing matters. Corporate events sit at the intersection of travel, finance, and operations, yet they are often managed outside standard procurement systems.

The latest rumblings from the EU tech scene, a story from our wise ol&#39; founder Boris, and some questionable AI art. It&#39;s free, every week, in your inbox. Sign up now!

Naboo’s pitch is that events should be treated like any other strategic spend, measurable, optimised, and governed through a single platform. That logic has resonated with large enterprises, particularly in the UK, which has become Naboo’s biggest market outside France following the opening of its London office in 2025.

With fresh capital in hand, Naboo is now stepping more decisively onto the global stage. The company is opening a new hub in New York as part of a broader US expansion, betting that multinational clients want a single system to manage events across regions, teams, and currencies.

Within just three years, Naboo has grown into one of the more visible players in the category, helped by enterprises looking for better control over decentralised spending.

The bigger shift, however, goes beyond events. Naboo plans to extend its AI procurement platform into “tail spend”, the long tail of smaller, harder-to-track purchases that typically fall outside core procurement tools.

In enterprise finance, this is often labelled Class C spending, and while each transaction is small, the total adds up fast. Naboo’s goal is to give companies a unified, AI-driven view of this spend, starting with events and branching outward.

The targets are ambitious. Naboo says it aims to triple revenue in 2026 and to exceed $1bn in business volume by 2027.

Whether it gets there will depend on how far enterprises are willing to centralise spending that has historically lived in spreadsheets and inboxes. What’s clear is that Naboo is betting that the next wave of enterprise AI won’t just analyse data, it will quietly reshape how money is spent.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-66')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">Trump agrees to end deportation surge in Minnesota, White House border czar says - Reuters</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-66" style="display:none;">
            <h2>Trump agrees to end deportation surge in Minnesota, White House border czar says - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2026-02-12</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiuAFBVV95cUxOeldIX0JhWkhadV85WHo3U2VCLXdfd3NScWh4bTlFS0JVUGI5LXlFbzRGUmw1T2pEZTQxa0RkcXd0WU9DYV9kM09uRllENTJnaHNWYXBqYk9XVmVaYjdnY29RTG9zRThIQkZuX2FERUJDUUd3Y2lSb0hqYXhHSmpySG0ybC1qbjZZemV2MHRFRndtOVdzbmhtSDVkQzFvRXRJM2RYX3RZY2lCaXM2cUo4YUpuX0JZcnRD?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-67')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">U.S. judge rejects BBC's stay application in Trump defamation case - Reuters</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-67" style="display:none;">
            <h2>U.S. judge rejects BBC's stay application in Trump defamation case - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2026-02-12</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMipAFBVV95cUxOUVE5X1FSTWdrWmUwaG1TQ2ZTdlpvQm0zUy11SGtac3pZVjloNS1nMmJmUXh5S3BObkFoaU9mMUNKVi11ZW95MDhPVlBkWi1reVJTaWNIMHRBN2hKMzFhalVNNXl2clhMTE5YMUJYTWl0TXNDZHExUEMwNE5DR1g3VVBBLWF5eUhLQXBkemQtZ2FJNDdQdzFVZkdwV05aNjRNdW5yNA?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-68')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">Two US Navy ships collide, no major injuries, US Southern Command says - Reuters</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-68" style="display:none;">
            <h2>Two US Navy ships collide, no major injuries, US Southern Command says - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2026-02-12</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiqAFBVV95cUxPMW00YlQxZEMwY1RpSWltVjNQRklRbGY0WFFHRFJmX2RaYm1PbXJYS1FmN0lZbzdSbC1iOUhaZHRXYUZkckFmX3hoUVU5U2t4YmNIY21oOTVFWWpUWmZiQ29zTWFCQjBjek9KcWNGMHB3ZjFPQVl3bWJnTXhDVTlLTm9nWnN3OEJnUzMyTGt6ajREYmxWQTVDTGozc3poNzBSY3BsS0xBSGw?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-69')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">Exclusive: Italian tax police search Amazon in new tax probe, sources say - Reuters</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-69" style="display:none;">
            <h2>Exclusive: Italian tax police search Amazon in new tax probe, sources say - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2026-02-12</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiogFBVV95cUxQQi0wTlZCUlFsYzhfVElMYkxhRERQQVdUc1pXcU9EQk5tLTdGaW5wRVJ2ZzFDa3luLUtUTWV3YVV1M2Y0clV1RlpZT2o1ZlhmMEV2Y2Z0cXZXY0hueC1kUk1Ea1ptZDNiZ0ZLb2h2b3pjQUZUOU14emJLZ1RvejRjdXVfOUhGb2llUURQNnVVSDZuLV96bW1Fc1U0NmVQM3JKa2c?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-70')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">Morning Bid: Jobs jolt rate bets - Reuters</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-70" style="display:none;">
            <h2>Morning Bid: Jobs jolt rate bets - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2026-02-12</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiggFBVV95cUxOQkdEMzk4eW1FTHJHcDFmeDgxdl9UNU5NRm9EQlhKUlBnQkF4SG9scEdjRkVwd1kxTlVvZE9GVTdDcEFmblFSYVVKQmgzYmhxV3RxbjZpeTJMZjA2cUYwOEctbWQ1Unl3Tk1PdzJYSUlzTjgtVjE4R0JEZ181ZnVCLV9R?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-71')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">Exclusive: Seeking Mexico foothold, China's BYD and Geely bid to buy car plant - Reuters</div>
            <div class="meta">2026-02-12</div>
        </div>
        
        <div id="content-71" style="display:none;">
            <h2>Exclusive: Seeking Mexico foothold, China's BYD and Geely bid to buy car plant - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2026-02-12</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiwgFBVV95cUxPWHV1emlVaFNCalNiMlBLcnQ1LUhqZURNM0VBUXF4WFdRRXZ5TUN4MkRWbTVkdVRzQldvb3hTdVFqVDNodjkta0xCM25sT3BCSHA2NHo4akdjT3V0UjF4TjVUcEM0c3dkbDh1M0psZWJoVWFqb0Iwbld4UmU4UkJPelprR0RCVGlrYl8yQnQyUVFIMzJYMU1Lejd5SnlueE00VUljOFV0SzIzR0FJQXJlSjdDTldicTRwNEhRQkR6eTU3QQ?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-72')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">Scientists Report “High-Confidence Detections of Artificial Objects” on the Moon—Could They Solve a Cold War-era Mystery? - The Debrief</div>
            <div class="meta">2026-02-11</div>
        </div>
        
        <div id="content-72" style="display:none;">
            <h2>Scientists Report “High-Confidence Detections of Artificial Objects” on the Moon—Could They Solve a Cold War-era Mystery? - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2026-02-11</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMi2gFBVV95cUxOUWFjUkdGYmFyV0ZUQ3lBY0Fla212b1hSNzVSMENTcTZKZVlnd3E1c1I5NXp6Y2dvZkNJVFZoaGpvaDVVX0lpNHM0SFJ6QTNILVV0Y1I4eHdHWHVGYmVJUUZTTGtvdHYtUW00VmR6THhhWXlzQ2c0dURvTUk3VHB5bGMxY3ZqdkdaRVo3ZFFJZzRhUk1TY21uVHh2QkNvSXFSRE5GY0drZVNLbm9ZQjBHdFhobzY5Z08tSUh0UDk4RVlTT0hyWFdyeFVZVUc1bjV1RmNvd1hYa2Q0UQ?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-73')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">“This Isn't Folklore; It's Pharmacology”: Centuries-Old Traditional Medicine Could Be a Game-Changer for Hair Loss - The Debrief</div>
            <div class="meta">2026-02-10</div>
        </div>
        
        <div id="content-73" style="display:none;">
            <h2>“This Isn't Folklore; It's Pharmacology”: Centuries-Old Traditional Medicine Could Be a Game-Changer for Hair Loss - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2026-02-10</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMizAFBVV95cUxPYlNfcXF1X1ByYVVkRTUxZjR4b1ZidUMzQURzSUlFeEM2Ujh4SWtnaUpTQXl1eVA0cjMzcGVlZ1htQlZUMVlyeVJjYnlza1czeVFuZUdfZURXSHdiNWd4bXJuSjB1a29SbUFFMXdla09oQnVPdVlaUk82bkJTYkJBeENhTU5sTm9qeDQ4UGk4bWRmbXcybG5tU3JxRW56UFBEazRJRjlsdTFFbnBSZFQ3SW9zQUlXRXpDN19reXduaTdhZ2tEMW5VNk5EM3E?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-74')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">Pentagon Unveils New Reverse Engineering Effort to Leverage Legacy Technologies for Which “Data No Longer Exists” - The Debrief</div>
            <div class="meta">2026-02-10</div>
        </div>
        
        <div id="content-74" style="display:none;">
            <h2>Pentagon Unveils New Reverse Engineering Effort to Leverage Legacy Technologies for Which “Data No Longer Exists” - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2026-02-10</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMi0AFBVV95cUxPRFdROVNRcUVfTWIyYm1RYmhnY3ctWXlwTHo2RWFBVmlzdlRnUkM4MUtnM1p6djRTX29sQmhweTRsU01FSFc3V2Yya2NDWUdTSzFxaWttb1pONkJ5WXMtQnRJV1dweFdwQjZNZ2RiVkJRZzI0ZG5nemxsQWlNRVVFcmFhWXpSaHJJMFlpV29MM2pZYUc4cTh3Wkd4b1Y1cEpFc3hsV044NlNiMzBiNG50bXExNXd0MVAtTi1nbjIycno0Y0lnVUlfOUdPLVNLdXVY?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-75')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">Radar Data Has Revealed a Large "Structure" Beneath the Surface of Venus—Here's What That Could Mean - The Debrief</div>
            <div class="meta">2026-02-09</div>
        </div>
        
        <div id="content-75" style="display:none;">
            <h2>Radar Data Has Revealed a Large "Structure" Beneath the Surface of Venus—Here's What That Could Mean - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2026-02-09</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMivgFBVV95cUxNNGI5ZDNqdWI3QXMzQnhSOWpmVDd3eWpsX2NwSElTWGJIdkJQV2g4LXp2RUI5c2ZWUHdMYUxobXdPWVRrZktaaFdoNzRyWXNvNERHamZCSE9ucFlGLTNxd3JZd3RoMV85b1lQcWd3RWdWUUY2VWR4QUJPX0xMbS0yNjd2cVl6WEVIbUswRklYaUJVT3JicUZBS2JPRHBJZG9zZk56emdtWTQwT3ptUmllNUN6QWVEZHFkVVE0YVpn?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-76')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">What Happens to Consciousness After Death? Scientists and Researchers Are Still Debating This Age Old Question - The Debrief</div>
            <div class="meta">2026-02-06</div>
        </div>
        
        <div id="content-76" style="display:none;">
            <h2>What Happens to Consciousness After Death? Scientists and Researchers Are Still Debating This Age Old Question - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2026-02-06</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMizgFBVV95cUxNZEtjRVZEMVVnMUN6Mm9rMFZyLWR4VHItSURYYm1LR3ZqUWtoOG9sQlVGMHFLdFhYT1BhNFNZZXFnTkJFNUNkYklBWTdNanNMYk9sU0kwY2xqV1F1OTh6ZUhsVXlYZ0pfSG05d0lxbTJDOUxiZmVpckJZZjhjbmc5OFp3bG54clpmMVZLVUh2MXRuUVJXVDVWNG5TbHpQWDg0U3BtZGF3VmdYdVRYN2Z6TjdwUTRXODlsS2JLYmR3ZGFNREticWFaVHFGdkEzZw?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-77')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">Did Scientists Just Achieve "Inception"? Experiments Show “Dream Engineering” May Be a Reality - The Debrief</div>
            <div class="meta">2026-02-06</div>
        </div>
        
        <div id="content-77" style="display:none;">
            <h2>Did Scientists Just Achieve "Inception"? Experiments Show “Dream Engineering” May Be a Reality - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2026-02-06</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiswFBVV95cUxPRlVfalZWOENmTUxPS3Vrb05ELWw1WnhuS2MxcVA1ZkFjYU9hUFBPZjFNWDBPMFdySmZKbVR3Vy1jQVZ5SjEyaV9LS1pUZ3hoOWttUXZHZzJfN29VTVBia0VRSXh3S1ptQUJiUVlVZUtlTjRWOHNOZGlGWnFlZUNBSmFPUklSck82VmswNWpDSmMtVkFScGF3NnhHSmdhNjJWYVBYeHY2Ry1fR1pGTlZKWnNZbw?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-78')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">Essilor and Meta Sell 7 Million Smart Glasses in 2025 - The Information</div>
            <div class="meta">2026-02-11</div>
        </div>
        
        <div id="content-78" style="display:none;">
            <h2>Essilor and Meta Sell 7 Million Smart Glasses in 2025 - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2026-02-11</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMikAFBVV95cUxQTlVVMy0ycVZqS0tSVmp6bkNualpRdmZiNWpUVE9neHpES1RKSU5ZT3BtV09zT2FjY083Nkw0Yl9MOWJaMTFXWndRaE10bjYyUzFjbW93cHVLTU40WlI4M1BNQTMtZ1EzWHlWZ1BObXRVTjJCQ1hNWTdyc0ZRYVo0VGxkRUJhMk81ZXZKOXhXeDU?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-79')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">Anthropic's Data Center Ambition—and the Ex-Google Execs Who Could Make It Happen - The Information</div>
            <div class="meta">2026-02-09</div>
        </div>
        
        <div id="content-79" style="display:none;">
            <h2>Anthropic's Data Center Ambition—and the Ex-Google Execs Who Could Make It Happen - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2026-02-09</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMivAFBVV95cUxQV3dNOTUtM2I4bXZWYnNDSjYzakk0SHRNcmxRU1BxT0g3VkJqbkYxUGdHSV9kdHY0Ny1JenRDODdlQzVQcVZpbFhHdTlhdF9rZlh5VDA1TjVJNE1SbmpKOGJRd2d0LVE0cXpBUHQ3VHN4ZEQ4YUhSaENlcXFGY1pYSElXOGtNWE4yWnhkOTRhU3dqZll3RWYzVE9ya21LZjdtSnNhUVJJN0VqN2JYZWUtekhCSGNtNXo5RlZoRA?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-80')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">ChatGPT Shopping Could Get Complicated Fast - The Information</div>
            <div class="meta">2026-02-10</div>
        </div>
        
        <div id="content-80" style="display:none;">
            <h2>ChatGPT Shopping Could Get Complicated Fast - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2026-02-10</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMigwFBVV95cUxNNjJNVjlXX2Vta2o4ZlczTk5HRm1HLW1VNjVJR0hyTmZvcDdrYWgyUWhFdWg1eXk5NUt3a3E5Ynk4WmE0dWYycFdUWHNQZmFUMGpfcE5ZeWZkNU1DTkZXLWVsTzRobWZRQ0Y4d05MOC1ud2NfcV9mOGpqQWRpRi1oNERJVQ?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-81')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">Departures Accelerate at Elon Musk’s xAI as Yet Another Cofounder Leaves - The Information</div>
            <div class="meta">2026-02-11</div>
        </div>
        
        <div id="content-81" style="display:none;">
            <h2>Departures Accelerate at Elon Musk’s xAI as Yet Another Cofounder Leaves - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2026-02-11</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiqgFBVV95cUxOTFp1MThGVWkzVUlWQ3ZJXzBHSWRzVVNBcVA2endyTk1Fdkk4bkUzOEx1YVNWdXdlNEo5a25PV19kWkpPNUtieW8xcHR4dC1obGJjTnVtc3QzZEdyN1RJcTZrc0R5b0lHeHBWa3dyb3dIWXprT2xKNHUzTDM1TnE0NGZzZ1dXRE9XSzhSYkxHRHZUYTFIeXRmNFhpMGJWZjFSdFdzVF84OUh0QQ?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-82')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">What Investors Are Missing About ServiceNow - The Information</div>
            <div class="meta">2026-02-11</div>
        </div>
        
        <div id="content-82" style="display:none;">
            <h2>What Investors Are Missing About ServiceNow - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2026-02-11</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMid0FVX3lxTFBJUzhKejlEQlFoLUxpeWRnWi1VVUVlZkRXaVdxbUxQbzRFR0E2UlBZajg1aDhpeXk4QU1wWGtCa1hhNzE3MVhhMXJfUGxjYVlMaWgxY3l4dFhoeHBPbzJpTWQ3V3NWT3FlOW16cmFDdVpBRGs0aFl3?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-83')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">Nvidia to Delay New Gaming Chip Due to Memory Chip Shortage - The Information</div>
            <div class="meta">2026-02-05</div>
        </div>
        
        <div id="content-83" style="display:none;">
            <h2>Nvidia to Delay New Gaming Chip Due to Memory Chip Shortage - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2026-02-05</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMimAFBVV95cUxQYjRrSTZQaTg3MWlNYlRiMndEcDd3dlpERGppck5DcnRPaEp2NnVXZWdNV0xVN0h3dW1TRk5LRm1hakVlaXJZMlZlV0pyM2xjMk9YWGZjSm5hdV84T3NMTUo5WXdjbFlOU1ZmbUY2NUQ0Mk9mX3BhZ3prQXhRVFh0Z0FLa0xuSE1ZbkpYOUp6dDFsMjVpSnpCTg?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        </div>

        <div id="reader-modal">
            <div id="close-btn" class="control-btn" onclick="closeModal()">X</div>
            
            <div id="scroll-controls">
                <button class="scroll-btn" onclick="scrollPage(-1)">&#9650;</button> <button class="scroll-btn" onclick="scrollPage(1)">&#9660;</button>  </div>

            <div id="modal-inner"></div>
        </div>

        <script>
            // 1. RANDOMIZE ORDER
            const list = document.getElementById('feed-list');
            const cards = Array.from(document.querySelectorAll('.card'));
            cards.sort(() => Math.random() - 0.5);
            cards.forEach(card => list.appendChild(card));

            // 2. DARK MODE
            const btn = document.getElementById('theme-toggle');
            btn.addEventListener('click', () => document.body.classList.toggle('dark-mode'));

            // 3. MODAL & SCROLL LOGIC
            const modal = document.getElementById('reader-modal');
            const modalInner = document.getElementById('modal-inner');

            function openModal(contentId) {
                const content = document.getElementById(contentId).innerHTML;
                modalInner.innerHTML = content;
                modal.style.display = 'block';
                document.body.style.overflow = 'hidden'; 
            }

            function closeModal() {
                modal.style.display = 'none';
                document.body.style.overflow = 'auto';
            }

            function scrollPage(direction) {
                // Scroll by 80% of the screen height to keep context
                const scrollAmount = window.innerHeight * 0.8;
                modal.scrollBy(0, direction * scrollAmount);
            }
        </script>
    </body>
    </html>
    