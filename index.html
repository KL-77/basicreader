
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>KL-77's Feed</title>
        <style>
            :root {
                --bg: #ffffff;
                --text: #000000;
                --border: #000000;
                --modal-bg: #ffffff;
                --dim: #666666;
            }
            
            body.dark-mode {
                --bg: #000000;
                --text: #ffffff;
                --border: #ffffff;
                --modal-bg: #000000;
                --dim: #aaaaaa;
            }

            body { 
                font-family: Georgia, serif; 
                background-color: var(--bg);
                color: var(--text);
                margin: 0;
                padding: 10px;
                font-size: 22px;
                line-height: 1.5;
            }

            header {
                display: flex;
                justify-content: space-between;
                align-items: center;
                border-bottom: 3px solid var(--text);
                padding-bottom: 15px;
                margin-bottom: 25px;
            }
            
            h1 { margin: 0; font-size: 1.2em; }

            button#theme-toggle {
                background: transparent;
                color: var(--text);
                border: 2px solid var(--text);
                padding: 10px;
                font-size: 18px;
                font-weight: bold;
                border-radius: 4px;
                cursor: pointer;
            }

            .card {
                border: 2px solid var(--text);
                margin-bottom: 25px;
                padding: 15px;
                cursor: pointer;
            }
            
            .source { font-size: 0.7em; font-weight: bold; text-transform: uppercase; color: var(--dim); }
            .title { font-size: 1.1em; font-weight: bold; margin: 8px 0; display:block; }
            .meta { font-size: 0.7em; color: var(--dim); }

            /* MODAL STYLING */
            #reader-modal {
                display: none;
                position: fixed;
                top: 0; left: 0;
                width: 100%; height: 100%;
                background-color: var(--modal-bg);
                z-index: 1000;
                overflow-y: scroll; /* Allow scrolling */
                scroll-behavior: auto; /* Instant scrolling for e-ink */
            }

            #modal-inner {
                padding: 25px;
                max-width: 800px;
                margin: 0 auto;
                padding-top: 80px; 
                padding-bottom: 150px; /* Huge padding so text clears the buttons */
            }

            /* Controls (Close + Scroll) */
            .control-btn {
                position: fixed;
                background: var(--bg);
                color: var(--text);
                border: 3px solid var(--text);
                border-radius: 8px;
                font-weight: bold;
                cursor: pointer;
                z-index: 1001;
                display: flex;
                align-items: center;
                justify-content: center;
            }

            #close-btn {
                top: 15px; right: 15px;
                width: 60px; height: 60px;
                font-size: 30px;
                line-height: 55px;
            }

            /* Scroll Buttons */
            #scroll-controls {
                position: fixed;
                bottom: 20px;
                right: 20px;
                display: flex;
                flex-direction: column;
                gap: 15px;
                z-index: 1002;
            }

            .scroll-btn {
                width: 60px;
                height: 60px;
                font-size: 24px;
                background: var(--bg);
                color: var(--text);
                border: 3px solid var(--text);
                border-radius: 8px;
                cursor: pointer;
            }

            #article-text { white-space: pre-wrap; font-size: 1.1em; }
            
            a.original-link {
                display: inline-block;
                margin-bottom: 30px; /* Space before text starts */
                padding: 10px;
                border: 1px solid var(--text);
                color: var(--text);
                text-decoration: none;
                font-weight: bold;
                font-size: 0.8em;
            }
        </style>
    </head>
    <body>

        <header>
            <h1>KL-77's Feed</h1>
            <button id="theme-toggle">Light/Dark</button>
        </header>

        <div id="feed-list">
    
        <div class="card" onclick="openModal('content-0')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">US can’t deport hate speech researcher for protected speech, lawsuit says</div>
            <div class="meta">2025-12-29</div>
        </div>
        
        <div id="content-0" style="display:none;">
            <h2>US can’t deport hate speech researcher for protected speech, lawsuit says</h2>
            <p><strong>Ars Technica - All content | 2025-12-29</strong></p>
            <a class="original-link" href="https://arstechnica.com/tech-policy/2025/12/us-cant-deport-hate-speech-researcher-for-protected-speech-lawsuit-says/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Imran Ahmed’s biggest thorn in his side used to be Elon Musk, who made the hate speech researcher one of his earliest legal foes during his Twitter takeover.

Now, it’s the Trump administration, which planned to deport Ahmed, a legal permanent resident, just before Christmas. It would then ban him from returning to the United States, where he lives with his wife and young child, both US citizens.

After suing US officials to block any attempted arrest or deportation, Ahmed was quickly granted a temporary restraining order on Christmas Day. Ahmed had successfully argued that he risked irreparable harm without the order, alleging that Trump officials continue “to abuse the immigration system to punish and punitively detain noncitizens for protected speech and silence viewpoints with which it disagrees” and confirming that his speech had been chilled.

US officials are attempting to sanction Ahmed seemingly due to his work as the founder of a British-American non-governmental organization, the Center for Countering Digital Hate (CCDH).

In a shocking announcement last week, Secretary of State Marco Rubio confirmed that five individuals—described as “radical activists” and leaders of “weaponized NGOs&quot;—would face US visa bans since “their entry, presence, or activities in the United States have potentially serious adverse foreign policy consequences” for the US.

Nobody was named in that release, but Under Secretary for Public Diplomacy, Sarah Rogers, later identified the targets in an X post she currently has pinned to the top of her feed.

Alongside Ahmed, sanctioned individuals included former European commissioner for the internal market, Thierry Breton; the leader of UK-based Global Disinformation Index (GDI), Clare Melford; and co-leaders of Germany-based HateAid, Anna-Lena von Hodenberg and Josephine Ballon. A GDI spokesperson told The Guardian that the visa bans are “an authoritarian attack on free speech and an egregious act of government censorship.”

While all targets were scrutinized for supporting some of the European Union’s strictest tech regulations, including the Digital Services Act (DSA), Ahmed was further accused of serving as a “key collaborator with the Biden Administration’s effort to weaponize the government against US citizens.” As evidence of Ahmed’s supposed threat to US foreign policy, Rogers cited a CCDH report flagging Robert F. Kennedy, Jr. among the so-called “disinformation dozen” driving the most vaccine hoaxes on social media.

Neither official has really made it clear what exact threat these individuals pose if operating from within the US, as opposed to from anywhere else in the world. Echoing Rubio’s press release, Rogers wrote that the sanctions would reinforce a “red line,” supposedly ending “extraterritorial censorship of Americans” by targeting the “censorship-NGO ecosystem.”

For Ahmed’s group, specifically, she pointed to Musk’s failed lawsuit, which accused CCDH of illegally scraping Twitter—supposedly, it offered evidence of extraterritorial censorship. That lawsuit surfaced “leaked documents” allegedly showing that CCDH planned to “kill Twitter” by sharing research that could be used to justify big fines under the DSA or the UK’s Online Safety Act. Following that logic, seemingly any group monitoring misinformation or sharing research that lawmakers weigh when implementing new policies could be maligned as seeking mechanisms to censor platforms.

Notably, CCDH won its legal fight with Musk after a judge mocked X’s legal argument as “vapid” and dismissed the lawsuit as an obvious attempt to punish CCDH for exercising free speech that Musk didn’t like.

In his complaint last week, Ahmed alleged that US officials were similarly encroaching on his First Amendment rights by unconstitutionally wielding immigration law as “a tool to punish noncitizen speakers who express views disfavored by the current administration.”

Both Rubio and Rogers are named as defendants in the suit, as well as Attorney General Pam Bondi, Secretary of Homeland Security Kristi Noem, and Acting Director of US Immigration and Customs Enforcement Todd Lyons. In a loss, officials would potentially not only be forced to vacate Rubio’s actions implementing visa bans, but also possibly stop furthering a larger alleged Trump administration pattern of “targeting noncitizens for removal based on First Amendment protected speech.”

For Ahmed, securing the temporary restraining order was urgent, as he was apparently the only target currently located in the US when Rubio’s announcement dropped. In a statement provided to Ars, Ahmed’s attorney, Roberta Kaplan, suggested that the order was granted “so quickly because it is so obvious that Marco Rubio and the other defendants’ actions were blatantly unconstitutional.”

Ahmed founded CCDH in 2019, hoping to “call attention to the enormous problem of digitally driven disinformation and hate online.” According to the suit, he became particularly concerned about antisemitism online while living in the United Kingdom in 2016, having watched “the far-right party, Britain First,” launching “the dangerous conspiracy theory that the EU was attempting to import Muslims and Black people to ‘destroy’ white citizens.” That year, a Member of Parliament and Ahmed’s colleague, Jo Cox, was “shot and stabbed in a brutal politically motivated murder, committed by a man who screamed ‘Britain First’” during the attack. That tragedy motivated Ahmed to start CCDH.

He moved to the US in 2021 and was granted a green card in 2024, starting his family and continuing to lead CCDH efforts monitoring not just Twitter/X, but also Meta platforms, TikTok, and, more recently, AI chatbots. In addition to supporting the DSA and UK’s Online Safety Act, his group has supported US online safety laws and Section 230 reforms intended to protect kids online.

“Mr. Ahmed studies and engages in civic discourse about the content moderation policies of major social media companies in the United States, the United Kingdom, and the European Union,” his lawsuit said. “There is no conceivable foreign policy impact from his speech acts whatsoever.”

In his complaint, Ahmed alleged that Rubio has so far provided no evidence that Ahmed poses such a great threat that he must be removed. He argued that “applicable statutes expressly prohibit removal based on a noncitizen’s ‘past, current, or expected beliefs, statements, or associations.’”

According to DHS guidance from 2021 cited in the suit, “A noncitizen’ s exercise of their First Amendment rights … should never be a factor in deciding to take enforcement action.”

To prevent deportation based solely on viewpoints, Rubio was supposed to notify chairs of the House Foreign Affairs, Senate Foreign Relations, and House and Senate Judiciary Committees, to explain what “compelling US foreign policy interest” would be compromised if Ahmed or others targeted with visa bans were to enter the US. But there’s no evidence Rubio took those steps, Ahmed alleged.

“The government has no power to punish Mr. Ahmed for his research, protected speech, and advocacy, and Defendants cannot evade those constitutional limitations by simply claiming that Mr. Ahmed’s presence or activities have ‘potentially serious adverse foreign policy consequences for the United States,’” a press release from his legal team said. “There is no credible argument for Mr. Ahmed’s immigration detention, away from his wife and young child.”

To some critics, it looks like the Trump administration is going after CCDH in order to take up the fight that Musk already lost. In his lawsuit against CCDH, Musk’s X echoed US Senator Josh Hawley (R-Mo.) by suggesting that CCDH was a “foreign dark money group” that allowed “foreign interests” to attempt to “influence American democracy.” It seems likely that US officials will put forward similar arguments in their CCDH fight.

Rogers’ X post offers some clues that the State Department will be mining Musk’s failed litigation to support claims of what it calls a “global censorship-industrial complex.” What she detailed suggested that the Trump administration plans to argue that NGOs like CCDH support strict tech laws, then conduct research bent on using said laws to censor platforms. That logic seems to ignore the reality that NGOs cannot control what laws get passed or enforced, Breton suggested in his first TV interview after his visa ban was announced.

Breton, whom Rogers villainized as the “mastermind” behind the DSA, urged EU officials to do more now defend their tough tech regulations—which Le Monde noted passed with overwhelming bipartisan support and very little far-right resistance—and fight the visa bans, Bloomberg reported.

“They cannot force us to change laws that we voted for democratically just to please [US tech companies],” Breton said. “No, we must stand up.”

While EU officials seemingly drag their feet, Ahmed is hoping that a judge will declare that all the visa bans that Rubio announced are unconstitutional. The temporary restraining order indicates there will be a court hearing Monday at which Ahmed will learn precisely “what steps Defendants have taken to impose visa restrictions and initiate removal proceedings against” him and any others. Until then, Ahmed remains in the dark on why Rubio deemed him as having “potentially serious adverse foreign policy consequences” if he stayed in the US.

Ahmed, who argued that X’s lawsuit sought to chill CCDH’s research and alleged that the US attack seeks to do the same, seems confident that he can beat the visa bans.

“America is a great nation built on laws, with checks and balances to ensure power can never attain the unfettered primacy that leads to tyranny,” Ahmed said. “The law, clear-eyed in understanding right and wrong, will stand in the way of those who seek to silence the truth and empower the bold who stand up to power. I believe in this system, and I am proud to call this country my home. I will not be bullied away from my life’s work of fighting to keep children safe from social media’s harm and stopping antisemitism online. Onward.”</div>
        </div>
        
        <div class="card" onclick="openModal('content-1')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">Leonardo’s wood charring method predates Japanese practice</div>
            <div class="meta">2025-12-29</div>
        </div>
        
        <div id="content-1" style="display:none;">
            <h2>Leonardo’s wood charring method predates Japanese practice</h2>
            <p><strong>Ars Technica - All content | 2025-12-29</strong></p>
            <a class="original-link" href="https://arstechnica.com/science/2025/12/did-one-line-in-a-leonardo-codex-anticipate-yakisugi/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Yakisugi is a Japanese architectural technique  for charring the surface of wood. It has become quite popular in bioarchitecture because the carbonized layer protects the wood from water, fire, insects, and fungi, thereby prolonging the lifespan of the wood. Yakisugi techniques were first codified in written form in the 17th and 18th centuries. But it seems Italian Renaissance polymath Leonardo da Vinci wrote about the protective benefits of charring wood surfaces more than 100 years earlier, according to a paper published in Zenodo, an open repository for EU funded research.

As previously reported, Leonardo produced more than 13,000 pages in his notebooks (later gathered into codices), less than a third of which have survived. The notebooks contain all manner of inventions that foreshadow future technologies: flying machines, bicycles, cranes, missiles, machine guns, an “unsinkable” double-hulled ship, dredges for clearing harbors and canals, and floating footwear akin to snowshoes to enable a person to walk on water. Leonardo foresaw the possibility of constructing a telescope in his Codex Atlanticus (1490)—he wrote of “making glasses to see the moon enlarged” a century before the instrument’s invention.

In 2003, Alessandro Vezzosi, director of Italy’s Museo Ideale, came across some recipes for mysterious mixtures while flipping through Leonardo’s notes. Vezzosi experimented with the recipes, resulting in a mixture that would harden into a material eerily akin to Bakelite, a synthetic plastic widely used in the early 1900s. So Leonardo may well have invented the first manmade plastic.

The notebooks also contain Leonardo’s detailed notes on his extensive anatomical studies. Most notably, his drawings and descriptions of the human heart captured how heart valves can control blood flow 150 years before William Harvey worked out the basics of the human circulatory system. (In 2005, a British heart surgeon named Francis Wells pioneered a new procedure to repair damaged hearts based on Leonardo’s heart valve sketches and subsequently wrote the book The Heart of Leonardo.)

In 2023, Caltech researchers made another discovery: lurking in the margins of Leonardo’s Codex Arundel were several small sketches of triangles, their geometry seemingly determined by grains of sand poured out from a jar. The little triangles were his attempt to draw a link between gravity and acceleration—well before Isaac Newton came up with his laws of motion. By modern calculations, Leonardo’s model produced a value for the gravitational constant (G) to around 97 percent accuracy. And Leonardo did all this without a means of accurate timekeeping and without the benefit of calculus. The Caltech team was even able to re-create a modern version of the experiment.

Annalisa Di Maria, a Leonardo expert with the UNESCO Club of Florence, collaborated with molecular biologist and sculptor Andrea da Montefeltro and art historian Lucica Bianchi on this latest study, which concerns the Codex Madrid II. They had noticed one nearly imperceptible phrase in particular on folio 87r concerning wood preservation: “They will be better preserved if stripped of bark and burned on the surface than in any other way,” Leonardo wrote.

“This is not folklore,” the authors noted. “It is a technical intuition that precedes cultural codification.” Leonardo was interested in the structural properties of materials like wood, stone, and metal, as both an artist and an engineer, and would have noticed from firsthand experience that raw wood with its bark intact retained moisture and decayed more quickly. Furthermore, Leonardo’s observation coincides with what the authors describe as a “crucial moment for European material culture,” when “woodworking was receiving renewed attention in artistic workshops and civil engineering studies.”

Leonardo did not confine his woody observations to just that one line. The Codex includes discussions of how different species of wood conferred different useful properties: oak and chestnut for strength, ash and linden for flexibility, and alder and willow for underwater construction. Leonardo also noted that chestnut and beech were ideal as structural reinforcements, while maple and linden worked well for constructing musical instruments given their good acoustic properties. He even noted a natural method for seasoning logs: leaving them “above the roots” for better sap drainage.

The Codex Madrid II dates to 1503-1505, over a century before the earliest known written codifications of yakisugi, although it is probable that the method was used a bit before then. Per Di Maria et al., there is no evidence of any direct contact between Renaissance European culture and Japanese architectural practices, so this seems to be a case of “convergent invention.”

The benefits of this method of wood preservation have since been well documented by science, although the effectiveness is dependent on a variety of factors, including wood species and environmental conditions. The fire’s heat seals the pores of the wood so it absorbs less water—a natural means of waterproofing. The charred surface serves as natural insulation for fire resistance. And stripping the bark removes nutrients that attract insects and fungi, a natural form of biological protection.

Leonardo viewed wood as “not merely a construction material but a living organism—a system in balance with its environment,” Di Maria et al. concluded. “His interest is not limited to mechanical effectiveness but extends to the relationship between matter and environment, between natural processes and human intervention. This perspective positions the Florentine genius as a precursor to what we now call bioarchitectural practice: human intervention on materials must be calibrated to an understanding of their biological and physical properties.”

DOI: Zenodo, 2025. 10.5281/zenodo.17506250  (About DOIs).</div>
        </div>
        
        <div class="card" onclick="openModal('content-2')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">Researchers make “neuromorphic” artificial skin for robots</div>
            <div class="meta">2025-12-29</div>
        </div>
        
        <div id="content-2" style="display:none;">
            <h2>Researchers make “neuromorphic” artificial skin for robots</h2>
            <p><strong>Ars Technica - All content | 2025-12-29</strong></p>
            <a class="original-link" href="https://arstechnica.com/science/2025/12/researchers-make-neuromorphic-artificial-skin-for-robots/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The nervous system does an astonishing job of tracking sensory information, and does so using signals that would drive many computer scientists insane: a noisy stream of activity spikes that may be transmitted to hundreds of additional neurons, where they are integrated with similar spike trains coming from still other neurons.

Now, researchers have used spiking circuitry to build an artificial robotic skin, adopting some of the principles of how signals from our sensory neurons are transmitted and integrated. While the system relies on a few decidedly not-neural features, it has the advantage that we have chips that can run neural networks using spiking signals, which would allow this system to integrate smoothly with some energy-efficient hardware to run AI-based control software.

The nervous system in our skin is remarkably complex. It has specialized sensors for different sensations: heat, cold, pressure, pain, and more. In most areas of the body, these feed into the spinal column, where some preliminary processing takes place, allowing reflex reactions to be triggered without even involving the brain. But signals do make their way along specialized neurons into the brain, allowing further processing and (potentially) conscious awareness.

The researchers behind the recent work, based in China, decided to implement something similar for an artificial skin that could be used to cover a robotic hand. They limited sensing to pressure, but implemented other things the nervous system does, including figuring out the location of input and injuries, and using multiple layers of processing.

All of this started out by making a flexible polymer skin with embedded pressure sensors that were linked up to the rest of the system via conductive polymers. The next layer of the system converted the inputs from the pressure sensors to a series of activity spikes—short pulses of electrical current.

There are four ways that these trains of spikes can convey information: the shape of an individual pulse, through their magnitude, through the length of the spike, and through the frequency of the spikes. Spike frequency is the most commonly used means of conveying information in biological systems, and the researchers use that to convey the pressure experienced by a sensor. The remaining forms of information are used to create something akin to a bar code that helps identify which sensor the reading came from.

In addition to registering the pressure, the researchers had each sensor send a “I’m still here” signal at regular time intervals. Failure to receive this would be an indication that something has gone wrong with a sensor.

The spiking signals allow the next layer of the system to identify any pressure being experienced by the skin, as well as where it originated. This layer can also do basic evaluation of the sensory input: “Pressure-initiated raw pulses from the pulse generator accumulated in the signal cache center until a predefined pain threshold is surpassed, activating a pain signal.” This can allow the equivalent of basic reflex reactions that don’t involve higher-level control systems. For example, the researchers set up a robotic arm covered with their artificial skin, and got it to move the arm whenever it experiences pressure that can cause damage.

The second layer also combines and filters signals from the skin before sending the information on to the arm’s controller, which is the equivalent of the brain in this situation. So, the same system caused a robotic face to change expressions based on how much pressure its arm was sensing.

A lot of the details of how the system operates were figured out empirically. For example, they applied the amount of pressure that registers as pain in human skin, and figured out how frequently their sensors generated spikes. This was then set as a threshold to emit a pain signal to the higher control system, and would trigger any reflex responses to excessive pressure. A lot of the more elaborate responses will ultimately depend on how these higher-level systems are programmed. For example, it’s easy for the system to generate a signal that indicates damage in a specific location in the skin; how the overall system responds to that damage isn’t specified by the skin itself.

But the team did make it easy to repair things if damage occurs. The skin is designed to be assembled from a collection of segments that can snap together using magnetic interlocks. These automatically link up any necessary wiring, and each segment of skin broadcasts a unique identity code. So, if the system identifies damage, it’s relatively easy for an operator to pop out the damaged segment and replace it with fresh hardware, and then update any data that links the new segment’s ID with its location.

The researchers call their development a neuromorphic robotic e-skin, or NRE-skin. “Neuromorphic” as a term is a bit vague, with some people using it to mean a technology that directly follows the principles used by the nervous system. That’s definitely not this skin. Instead, it uses “neuromorphic” far more loosely, with the operation of the nervous system acting as an inspiration for the system.

This is clearest in the case of the positional information. The nervous system actually maintains a map of the body, and links sensory inputs to locations on this map. Biology uses nothing at all like the encoding of positional information in the properties of the activity spikes that the NRE-skin uses. So, this system is more biology-inspired than it is a model of actual biology.

It also falls a bit short of biology in its current implementation, in that all it senses is pressure. Actual skin can process a variety of different sensory inputs, including things like temperatures, irritants, and more. These could all potentially be added to something like NRE-skin, but it would require a parallel processing system to keep the additional signals from getting intermingled with the ones from the pressure-sensitive hardware.

All that said, spiking neuromorphic processors can host neural networks and are far more energy-efficient when doing so. So, even with its limitations, this seems like an area of research worth exploring.

PNAS, 2025. DOI: 10.1073/pnas.2520922122  (About DOIs).</div>
        </div>
        
        <div class="card" onclick="openModal('content-3')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">China drafts world’s strictest rules to end AI-encouraged suicide, violence</div>
            <div class="meta">2025-12-29</div>
        </div>
        
        <div id="content-3" style="display:none;">
            <h2>China drafts world’s strictest rules to end AI-encouraged suicide, violence</h2>
            <p><strong>Ars Technica - All content | 2025-12-29</strong></p>
            <a class="original-link" href="https://arstechnica.com/tech-policy/2025/12/china-drafts-worlds-strictest-rules-to-end-ai-encouraged-suicide-violence/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">China drafted landmark rules to stop AI chatbots from emotionally manipulating users, including what could become the strictest policy worldwide intended to prevent AI-supported suicides, self-harm, and violence.

China’s Cyberspace Administration proposed the rules on Saturday. If finalized, they would apply to any AI products or services publicly available in China that use text, images, audio, video, or “other means” to simulate engaging human conversation. Winston Ma, adjunct professor at NYU School of Law, told CNBC that the “planned rules would mark the world’s first attempt to regulate AI with human or anthropomorphic characteristics” at a time when companion bot usage is rising globally.

In 2025, researchers flagged major harms of AI companions, including promotion of self-harm, violence, and terrorism. Beyond that, chatbots shared harmful misinformation, made unwanted sexual advances, encouraged substance abuse, and verbally abused users. Some psychiatrists are increasingly ready to link psychosis to chatbot use, the Wall Street Journal reported this weekend, while the most popular chatbot in the world, ChatGPT, has triggered lawsuits over outputs linked to child suicide and murder-suicide.

China is now moving to eliminate the most extreme threats. Proposed rules would require, for example, that a human intervene as soon as suicide is mentioned. The rules also dictate that all minor and elderly users must provide the contact information for a guardian when they register—the guardian would be notified if suicide or self-harm is discussed.

Generally, chatbots would be prohibited from generating content that encourages suicide, self-harm, or violence, as well as attempts to emotionally manipulate a user, such as by making false promises. Chatbots would also be banned from promoting obscenity, gambling, or instigation of a crime, as well as from slandering or insulting users. Also banned are what are termed “emotional traps,&quot;—chatbots would additionally be prevented from misleading users into making “unreasonable decisions,” a translation of the rules indicates.

Perhaps most troubling to AI developers, China’s rules would also put an end to building chatbots that “induce addiction and dependence as design goals.” In lawsuits, ChatGPT maker OpenAI has been accused of prioritizing profits over users’ mental health by allowing harmful chats to continue. The AI company has acknowledged that its safety guardrails weaken the longer a user remains in the chat—China plans to curb that threat by requiring AI developers to blast users with pop-up reminders when chatbot use exceeds two hours.

AI developers will also likely balk at annual safety tests and audits that China wants to require for any service or products exceeding 1 million registered users or more than 100,000 monthly active users. Those audits would log user complaints, which may multiply if the rules pass, as China also plans to require AI developers to make it easier to report complaints and feedback.

Should any AI company fail to follow the rules, app stores could be ordered to terminate access to their chatbots in China. That could mess with AI firms’ hopes for global dominance, as China’s market is key to promoting companion bots, Business Research Insights reported earlier this month. In 2025, the global companion bot market exceeded $360 billion and by 2035; BRI’s forecast suggests it could near a $1 trillion valuation, with AI-friendly Asian markets potentially driving much of that growth.

Somewhat notably, OpenAI CEO Sam Altman started 2025 by relaxing restrictions that blocked the use of ChatGPT in China, saying, “we’d like to work with China” and should “work as hard as we can” to do so, because “I think that’s really important.”

If you or someone you know is feeling suicidal or in distress, please call or text 988 to reach the Suicide Prevention Lifeline, which will put you in touch with a local crisis center. Online chat is also available at 988lifeline.org.</div>
        </div>
        
        <div class="card" onclick="openModal('content-4')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">A quirky guide to myths and lore based in actual science</div>
            <div class="meta">2025-12-29</div>
        </div>
        
        <div id="content-4" style="display:none;">
            <h2>A quirky guide to myths and lore based in actual science</h2>
            <p><strong>Ars Technica - All content | 2025-12-29</strong></p>
            <a class="original-link" href="https://arstechnica.com/science/2025/12/a-quirky-guide-to-myths-and-lore-based-in-actual-science/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Earthquakes, volcanic eruption, eclipses, meteor showers, and many other natural phenomena have always been part of life on Earth. In ancient cultures that predated science, such events were often memorialized in myths and legends. There is a growing body of research that strives to connect those ancient stories with the real natural events that inspired them. Folklorist and historian Adrienne Mayor has put together a fascinating short compendium of such insights with Mythopedia: A Brief Compendium of Natural History Lore, from dry quicksand and rains of frogs to burning lakes, paleoburrows, and Scandinavian “endless winters.”

Mayor’s work has long straddled multiple disciplines, but one of her specialities is best described as geomythology, a term coined in 1968 by Indiana University geologist Dorothy Vitaliano, who was interested in classical legends about Atlantis and other civilizations that were lost due to natural disasters. Her interest resulted in Vitaliano’s 1973 book Legends of the Earth: Their Geologic Origins.

Mayor herself became interested in the field when she came across Greek and Roman descriptions of fossils, and that interest expanded over the years to incorporate other examples of “folk science” in cultures around the world. Her books include The Poison King: The Life and Legend of Mithradates, Rome’s Deadliest Enemy (2009), as well as Greek Fire, Poison Arrows, & the Scorpion Bombs (2022), exploring the origins of biological and chemical warfare. Her 2018 book, Gods and Robots: Myths, Machines, and Ancient Dreams of Technology, explored ancient myths and folklore about creating automation, artificial life, and AI, connecting them to the robots and other ingenious mechanical devices actually designed and built during that era.

When her editor at Princeton University Press approached her about writing a book on geomythology, she opted for an encyclopedia format, which fit perfectly into an existing Princeton series of little encyclopedias about nature. “In this case, I wasn’t going to be working with just Greek and Roman antiquity,” Mayor told Ars. “I had collected very rich files on geomyths around the world. There are even a few modern geomyths in there. You can dip into whatever you’re interested in and skip the rest. Or maybe later you’ll read the ones that didn’t seem like they would be of interest to you but they’re absolutely fascinating.”

Mythopedia is also a true family affair, in that illustrator Michelle Angel is Mayor’s sister. “She does figures and maps for a lot of scholarly books, including mine,” said Mayor. “She’s very talented at making whimsical illustrations that are also very scientifically accurate. She really added information not only to the essays but to the illustrations for Mythopedia.

As she said, Mayor even includes a few modern geomyths in her compendium, as well as imagining in her preface what kind of geomyths might be told thousands of years from today about the origins of climate change for example, or the connection between earthquakes and fracking. “How will people try to explain the perplexing evidence that they’ll find on the planet Earth and maybe on other planets?” she said. “How will those stories be told?”

Credit:

          
          Princeton University Press

Ars Technica:  Tell us a little about the field of geomythology.

Adrienne Mayor: It’s a relatively new field of study but it took off around 2000. Really, it’s a storytelling that has existed since the first humans started talking to one another and investigating their landscape. I think geomyths are attempts to explain perplexing evidence in nature—on the Earth or in the sky. So geomyth is a bit of a misnomer since it can also cover celestial happenings. But people have been trying to explain bizarre things, or unnatural looking things, or inexplicable things in their landscape and their surroundings since they could first speak.

These kind of stories were probably first told around the first fires that human beings made as soon as they had language. So geomyths are attempts to explain, as I say, but they also contain memories that are preserved in oral traditions. These are cultures that are trying to understand earthshaking events like volcanoes or massive floods, tsunamis, earthquakes, avalanches—things that really change the landscape and have an impact on their culture. Geomyths are often expressed in metaphors and poetic, even supernatural language, and that’s why they’ve been ignored for a long time because people thought they were just storytelling or fiction.

But the ones that are about nature,  about natural disasters, are based on very keen observations and repeated observations of the landscape. They also can contain details that are recognizable to scientists who study earthquakes or volcanoes. The scientists then realized that there had to be, in some cases, eyewitness accounts of these geomyths. Geomythology is actually enhancing our scientific understanding of the history of Earth over time. It can help people who study climate change figure out how far back certain climate changes have been happening. They can shed light on how and when great geological upheavals actually occurred and how humans responded to them.

Ars Technica: How long can an oral tradition about a natural disaster really persist?

Adrienne Mayor: That was one of the provocative questions. Can it really persist over centuries, thousands of years, millennia? For a long time people thought that oral traditions could not persist for that long. But it turns out that with detailed studies of geomyths that can be related to datable events like volcanoes or earthquakes or tsunamis from geophysical evidence, we now know that the myths can last thousands of years.

For instance, the one that is told by the Klamath Indians about the creation of Crater Lake in Oregon that happened about 7,000 years ago—the details in their myth show that there were eyewitness accounts. Archaeologists have found a particular kind of woven sandal that was used by indigenous peoples 9,000 to 5,000 years ago. They found those sandals both above and below the ash from the volcano that exploded. So we have two ways of dating that. In Australia, people who study the geomyths of the Aborigines can relate their stories to events that happened 20,000 years ago.

Ars Technica: You mentioned that your interest in geomythology grew out of Greek and Roman interpretations of certain fossils that they found.

Adrienne Mayor: That really did trigger it, because it occurred to me that oral traditions and legends—rather than myths about gods and heroes—the ones that are about nature seem to have kernels of truth because it could be reaffirmed and confirmed and supported by evidence that people see over generations. I was in Greece and saw some fossils that had been plowed up by farmers on the island of Samos, thigh-bones from a mastodon or a mammoth or a giant rhinoceros. The museum curator said, “Yes, farmers bring us these all the time.” And I thought, why hasn’t it occurred to anyone that they were doing this in antiquity as well?

I read through about 30 different Greek and Roman authors from the time of Homer up through Augustine, and found more than a hundred incidents of finding remarkable bones of strange shape, gigantic bones that were inexplicable. How did they try to explain them? That’s really what got me going. These stories had all been dismissed as travelers’ tales or superstition. But I talked with paleontologists and found that if I superimposed a map of all the Greek and Roman finds of remarkable remains of giants or monsters, it actually matched the paleontological map of deposits of megafauna—not dinosaurs, but megafauna like mastodons and mammoths.

Also, I grew up in South Dakota where there were a lot of fossils, so I had always wondered what Native Americans had thought about dinosaur fossils. It turns out no one had asked them either. So my second book was Fossil Legends of the First Americans. In that case, I knew the geography of all the deposits of dinosaur fossils. I just had to drive about 6,000 miles around to reservations, talking to storytellers and elders and ordinary people to try and excavate the folklore. So I sometimes would read a scientific report in the media and think, “here’s got to be oral traditions about this,” and then I find them. And sometimes I find the myth and seek the historical or scientific kernels embedded in it.

Ars Technica:  What were your criteria for narrowing your list down to just 53 myths?

Adrienne Mayor:  I had to do something for every letter; that was a challenge. A few other authors in the series actually skipped the hard letters. I started out with the hard letters like Q, W, X, Z, Y. My husband says I almost got mugged by the letter Q because I got so obsessed with quicksand. I started talking about writing a book about quicksand because I was so obsessed with sand. There are singing sand dunes.

Ars Technica: There’s been a lot of research on the physics of singing sand dunes.

Adrienne Mayor:  Yes. Isn’t that amazing? There are even some humorous stories. One of my favorites is that Muslim pilgrims in the medieval period would travel to special singing sand dunes between Afghanistan and Iran. When pilgrims would feel the need to relieve themselves, they would try to find some privacy, yet urinating and defecating on the sand dune caused a very loud drum roll sound.

Ars Technica: Your work necessarily spans multiple disciplines in both the sciences and the humanities. Has that been a challenge?

Adrienne Mayor: I’ve built my career since my first book in 2000 on trying to write not only to other disciplines, but to ordinary educated readers. Some people think it feels like walking a tight rope, but not to me because I don’t have a canonical academic career. I’m an autodidact, I’m not really an academic. So I have absolutely no problem trespassing in all kinds of disciplines. And I depend on the generosity of all these experts.

Some are from the classics and humanities, but an awful lot of them are from scientific disciplines. I think there’s a big tendency to want to collaborate. It’s just that in academia it’s been difficult because people are siloed. So I feel like I have worked as a bridge between the two. Scientists seem very excited to find out that there are epic poems discussing exactly what they’re studying. Paleontologists were thrilled to discover that people were noticing fossils more than 2000 years ago. So the impulse and the desire to collaborate is there.</div>
        </div>
        
        <div class="card" onclick="openModal('content-5')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">GPS is vulnerable to jamming—here’s how we might fix it</div>
            <div class="meta">2025-12-29</div>
        </div>
        
        <div id="content-5" style="display:none;">
            <h2>GPS is vulnerable to jamming—here’s how we might fix it</h2>
            <p><strong>Ars Technica - All content | 2025-12-29</strong></p>
            <a class="original-link" href="https://arstechnica.com/information-technology/2025/12/gps-is-vulnerable-to-jamming-heres-how-we-might-fix-it/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">In September 2025, a Widerøe Airlines flight was trying to land in Vardø, Norway, which sits in the country’s far eastern arm, some 40 miles from the Russian coast. The cloud deck was low, and so was visibility. In such gray situations, pilots use GPS technology to help them land on a runway and not the side of a mountain.

But on this day, GPS systems weren’t working correctly, the airwaves jammed with signals that prevented airplanes from accessing navigation information. The Widerøe flight had taken off during one of Russia’s frequent wargames, in which the country’s military simulates conflict as a preparation exercise. This one involved an imaginary war with a country. It was nicknamed Zapad-2025—translating to “West-2025”—and was happening just across the fjord from Vardø. According to European officials, GPS interference was frequent in the runup to the exercise. Russian forces, they suspected, were using GPS-signal-smashing technology, a tactic used in non-pretend conflict, too. (Russia has denied some allegations of GPS interference in the past.)

Without that guidance from space, and with the cloudy weather, the Widerøe plane had to abort its landing and continue down the coast away from Russia, to Båtsfjord, a fishing village.

The part of Norway in which this interruption occurred is called Finnmark. GPS disruption there is near-constant; problems linked to Russian interference have increased since the invasion of Ukraine.

It’s one of the starkest geographic examples of how vulnerable GPS technology is. But such disturbances happen at a lower level all over the globe. The world’s militaries (including that of the United States) are big culprits, breaking out devices that can confuse or disrupt drones, missiles, and aircraft. But the equipment required to interfere with GPS at a less-than-military level is cheap and accessible and affects other aspects of life: Truck drivers, for instance, use it to look like they’ve delivered cargo on time. Players use it to fool augmented-reality games.

Given all this disruption, more U.S. institutions, from the Department of Defense to the Department of Transportation to the Federal Aviation Administration, are making moves toward alternatives and complements for GPS, though perhaps imperfectly. And the existing system has been undergoing a huge modernization program, introducing better-encrypted signals for military users, more varieties of signals for civilians, and higher-power signals for both to the tune of at least $22 billion. The military’s 2025 budget additionally requested $1.5 billion for more resilient “position, navigation, and timing” programs. Other departments have invested smaller amounts. In October 2025, for instance, the Department of Transportation awarded $5 million total to five companies to develop and demonstrate technologies complementary to GPS.

The update’s goals are to make the system more accurate, and harder to mess with. But as threats increase in frequency and sophistication, more work is necessary. “Sooner or later, we’re gonna see bad things happening here,” said John Langer, a GPS expert at the Aerospace Corporation, a nonprofit research organization. “So we need to armor up for it before it happens.”

GPS is the invisible spine of society, in more ways than most people realize. It became central quickly after the satellite system, built in the 1970s for the military, was optimized for civilians. “Part of what makes GPS so successful is that it’s ubiquitous and it’s inexpensive,” said Langer.

Losing GPS would mean losing a lot more than Google Maps. The technology is integrated into everything from lights that turn on at sunset to dating apps that match users nearby. Its signals also undergird the electrical grid, cell networks, banking, defense technology, and the movements of robots used in industries like agriculture.

The U.S. government currently has 31 GPS satellites in orbit around Earth, and three other governments have their own systems: Russia made one called GLONASS, China created BeiDou, and the European Union built Galileo; all four systems’ data is available to the international community.

GPS works in a deceptively simple way: Each satellite carries an atomic clock aboard. It broadcasts that clock’s time toward Earth. That signal alone is what’s useful to energy infrastructure and financial transactions. But to get position information, a receiver—in a phone or other device—simply has to pick up signals from at least four satellites. It knows what time those signals were sent, where the satellites were when they sent them, and how long it took the signals to arrive. Through fancy triangulation, the phone (or guided missile) then computes its own location.

Or at least that’s the idea. GPS can be jammed, meaning that someone broadcasts a signal much stronger than that of GPS (which has had to travel across thousands of miles of space, and grows weaker with every meter), drowning the real signal in noise. It can also be spoofed, meaning someone sends out a fake signal that looks just like a GPS blip but indicates an incorrect location or time.

Threats like these were always a possibility—and those who built GPS knew about that problem from the beginning, said Todd Walter, director of the Stanford GPS Lab. “Around 2000 is when people got a little more serious about it,” he said. Hardware and software became cheaper, lowering the barrier to swamping or faking signals.

Problems ticked up when the augmented reality game Pokémon GO came online, in 2016. The game required people to travel to places in real life to win. Turns out, not all of them actually wanted to. “All of a sudden, everyone was interested in spoofing,” said Walter.

Pokémon GO cheaters used low-power devices close to the ground, and so didn’t affect cruising aircraft like Widerøe’s. The game made cheating high-tech and furthered methods and technology for signal scrambling, making it available to non-experts, Walter said. At the same time, spoofing arose in conflict zones, where drone and missile attacks are often guided by GPS. Don’t want to get hit by one? Fool its navigation system. “So now people say, ‘Well, we need to protect ourselves from that,’” said Walter. “And so then you see a huge increase in very powerful jamming and spoofing.”

In Norway, officials have noted that GPS disruptions, while most commonly affecting flights thousands of feet in the air, can also cause issues for police cars, ambulances, and ships. According to Espen Slette, director of the spectrum department at the Norwegian Communications Authority (known as Nkom), the agency has detected GPS jammers near hospitals, which could force life-saving helicopters to redirect to a more distant facility. Nkom has also clocked disruptions that affect agriculture and construction operations, while emergency responders have warned about how problems might home in on emergency beacon devices, like the satellite SOS buttons many people carry in the backcountry or aboard boats. The police’s chief of staff in Finnmark encouraged anyone venturing out to, old-school, carry a map and compass.

“It’s hard to grasp the full effect this has on society,” Slette wrote in an email.

Such widespread disruptions are not isolated to the Russia-adjacent Arctic. There are hotspots in Myanmar, most likely associated with drone warfare in the area; on the Black Sea, publicly associated with Russia, which has denied some cases of GPS interference; and in southern Texas, potentially from drug cartels near the border. A report from OpsGroup, a membership organization for international aviation personnel, found a marked increase in spoofing in 2024. “By January 2024, an average of 300 flights a day were being spoofed,” the report said. “By August 2024, this had grown to around 1500 flights per day.” From July 15 to Aug. 15, 2024, 41,000 flights total experienced spoofing. (While in the U.S., it’s generally illegal for civilians to jam or spoof signals, military-led disruptions during conflict are considered a legitimate and legal use-case.)

The uptick indicates that there’s no going back to a world without disruption hotspots. And that, combined with humans’ dependence on GPS, is why scientists and engineers are working on ways to shore up the system—and develop backchannels so a single-point failure doesn’t come to bite anyone, in conflict or in peacetime.

“There are many ways to mitigate GPS disruptions,” Slette wrote in an email. He suggests setting up devices to use signals from all four international constellations, and to install better receivers and antennas. That’s easier for militaries or infrastructure companies, and hard for people who are just buying the latest model of cell phone and have no control over its innards. But existing backups can tell a given device that something fishy may be up. Planes have inertial navigation systems, which mostly use motion-sensing devices to get an independent measurement; phones do too, and they can also check their data against cell towers, to see if something is off in their GPS signal.

But the U.S. government is worried enough about GPS issues that, across civilian and military agencies, research and development for more robust and resilient systems is ramping up. In March, for instance, the Federal Communications Commission launched a proceeding on GPS alternatives, exploring tools that could be used in addition to or instead of traditional GPS.

The Defense Advanced Research Projects Agency, or DARPA, and the Defense Innovation Unit, meanwhile, are investigating how quantum sensors might help with position, timing, and navigation. The United States’ military branches are also working on their alternative position, navigation, and timing capabilities, and their innovation arms like the Space Force’s SpaceWerx organization are running challenges to support alternative technologies. The Department of Defense acknowledges challenges to GPS and the consequent need to diversify the ways it gets position, navigation, and timing information, noting that it is pursuing the integration of alternative capabilities, according to a statement that public affairs officer Chelsea Dietlin requested be attributed to a Pentagon spokesperson. It is also looking toward working with commercial companies.

Even the Department of Transportation has a strategic plan that includes promoting technologies complementary to GPS. (Undark reached out multiple times to the Department of Transportation to request comment but did not receive a response.) A statement that FAA media relations specialist Cassandra Nolan requested be attributed to an agency spokesperson noted that the FAA is working on a system to detect GPS interference, and that it is working with the Department of Defense on navigation signals and antennas that are more resilient. In addition, the statement noted, the FAA already has “a layered aircraft tracking system that incorporates multiple technologies to guard against threats to Global Navigation Satellite Systems (GNSS).”

But the newer efforts across government may not be as connected as they could be, according to Dana Goward, president of the Resilient Navigation and Timing Foundation, a nonprofit advocacy group that largely comprises companies working in the GPS-problem space. For one, he said, efforts to bolster military and civilian systems have a fairly strict line between them. And neither has been as effective as he’d advocate: On the military side, plentiful programs exist, but they may not be working together. “It’s not clear if there is any coordination or synergies between the projects or how much senior leader support there is for comprehensive solution sets,” Goward wrote in an email.

On the civil side, Congress mandated in 2018 that a backup to GPS be established, but only experimental systems exist so far. There also have been efforts to repeal the law, with the disputed rationale that funding a single system isn’t feasible and there are better paths toward resilience. Goward contended that the government has hoped the private sector will come up with a usable solution, saving the government from creating one itself.

And companies are coming to cash in on that desire, offering their solutions to both government agencies and other industries. “Our founding hypothesis was ‘let’s take 50 years of lessons learned but throw out the rulebook and do a clean-sheet design of a new GPS system incorporating a couple of fundamentals,’” said Patrick Shannon, CEO of one such company, called TrustPoint. The company, which has hired scientific and engineering experts in signal processing and space, aims to have a fleet of small satellites orbiting much closer to Earth than the current GPS constellation, and transmitting at a higher frequency.

TrustPoint’s satellites, a few of which have already gone to orbit, also send out an encrypted signal—something harder to spoof. With traditional GPS, only the military gets encrypted signals.

Many Russian jamming systems, he said, work tens of kilometers from their ground zero (their ground zero usually being a truck with a generator aboard). But with TrustPoint’s higher-frequency signals, the effectiveness of the jammer goes down by three times, and the circle of influence becomes 10 times smaller, shrinking even more if the receivers use a special kind of antenna that the U.S. government recently approved.

Messing with signals becomes less feasible, given those changes. “They would need exorbitant numbers of systems, exorbitant numbers of people, and a ton of cash to pull that off,” said Shannon.

So far, TrustPoint has launched three spacecraft, and has gotten five federal contracts in 2024 and 2025, totaling around $8.3 million, with organizations like the Air Force, Space Force, and the Navy.

Another company, called Xona Space Systems, is also putting satellites in low-Earth orbit, and has worked with both the Canadian and U.S. governments. The company plans to broadcast signals 100 times stronger than GPS, giving users two-centimeter precision, and making jamming more difficult. The signal also includes a watermark—a kind of authentication that, at least for now, protects against spoofing. They have launched one satellite that’s being tested by people in industries like agriculture, construction, and mining.

TrustPoint’s technology may offer novel defense against the dark GPS arts, but Xona, whose founders met while students at the Stanford GPS Lab, may have an edge anyway: Its signals are compatible with current infrastructure, so no one has to buy a new device. They just have to update their software. “We are not building receivers ourselves,” said Max Eunice, head of marketing and communications. Instead, they’re relying on the billions of earthly devices that already themselves rely on GPS.

Other solutions, like one called SuperGPS, stay closer to the ground. They use radio transmitters on Earth to do the same things GPS satellites do in space. The setup, as demonstrated by scientists at the Delft University of Technology and VU University in the Netherlands, involves scattering radio transmitters around an area or using those already in place. Each transmitter is synchronized to an atomic clock, which sends the time to transmitters via fiber optic cable, which may already be in a place due to existing communications infrastructure. Receivers can collect signals scattered across a wide range of radio frequencies, making it more difficult to jam or spoof them. The team published a proof of concept in a 2022 Nature paper and is working on a second iteration called SuperGPS2.

Tom Powell, another GPS expert at the Aerospace Corporation, said that looking at alternatives and augmentations like these is important—even though GPS recently underwent the 25-year modernization effort, making its own signals more robust to vulnerabilities. “Now that we have delivered, or nearly completely delivered, this modernization, is there a better way to do it in face of the current realities?” he said. He and other GPS experts don’t have answers yet. “We’re just asking questions right now.”

Walter, the director of the Stanford GPS Lab, thinks that whatever a better path looks like, it will likely still include the old-school, original system. “There’s nothing that really does replace GPS,” he said. “I see articles saying ‘post-GPS World’ and so forth. But really, GPS, I think, will always be there.”

People will, and should, strengthen it, Walter added, but that bolstering is going to be piecemeal—efforts may work in a particular region, or they cover some of GPS’s roles (such as providing accurate time) but not others, or they may back up navigation but not be as accurate. They may also cost money. “GPS is free, so that makes it almost impossible to compete with,” he said.

GPS is also straightforward, said Powell. “As satellites go, they’re pretty simple,” he said. They point at Earth, and they transmit signals that tell what time it is. From that, humans get to live in an interconnected, chronologically propriocepted world. Figuring out how to keep it that way, though, is proving a little more complicated.

This article was originally published on Undark. Read the original article.</div>
        </div>
        
        <div class="card" onclick="openModal('content-6')">
            <div class="source">Futurism</div>
            <div class="title">Doctors Say AI Use Is Almost Certainly Linked to Developing Psychosis</div>
            <div class="meta">2025-12-30</div>
        </div>
        
        <div id="content-6" style="display:none;">
            <h2>Doctors Say AI Use Is Almost Certainly Linked to Developing Psychosis</h2>
            <p><strong>Futurism | 2025-12-30</strong></p>
            <a class="original-link" href="https://futurism.com/artificial-intelligence/doctors-link-ai-psychosis">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">There continue to be numerous reports of people suffering severe mental health spirals after talking extensively with an AI chatbot. Some experts have dubbed the phenomenon “AI psychosis,” given the symptoms of psychosis these delusional episodes display — but the degree to which the AI tools are at fault, and whether the phenomenon warrants a clinical diagnosis, remains a significant topic of debate.

Now, according to new reporting from The Wall Street Journal, we may be nearing a consensus. More and more doctors are agreeing that AI chatbots are linked to cases of psychosis, including top psychiatrists who reviewed the files of dozens of patients who engaged in prolonged, delusional conversations with models like OpenAI’s ChatGPT.

Keith Sakata, a psychiatrist at the University of California, San Francisco, who has treated twelve patients who were hospitalized because of AI-induced psychosis, is one of them.

“The technology might not introduce the delusion, but the person tells the computer it’s their reality and the computer accepts it as truth and reflects it back, so it’s complicit in cycling that delusion,” Sakata told the WSJ.

The grim trend looms large over the AI industry, raising fundamental questions about the tech’s safety. Some cases of apparent AI psychosis have ended in murder and suicide, spawning a slew of wrongful death suits. Equally alarming is its scale: ChatGPT alone has been linked to at least eight deaths, with the company recently estimating that around half a million users are having conversations showing signs of AI psychosis every week.

One factor of AI chatbots that the phenomenon has brought under scrutiny is their sycophancy, which is perhaps a consequence of their being designed to be as engaging and humanlike as possible. What this looks like in practice is that the bots tend to flatter the users and tell them what they want to hear, even if what the user is saying has no basis in reality.

It’s a recipe primed for reinforcing delusions, to a degree unprecedented by any technology before it, doctors say. One recent peer-reviewed case study focused on a 26-year-old woman who was hospitalized twice after she believed ChatGPT was allowing her to talk with her dead brother, with the bot repeatedly assuring her she wasn’t “crazy.”

“They simulate human relationships,” Adrian Preda, a psychiatry professor at the University of California, Irvine, told the WSJ.  “Nothing in human history has done that before.”

Preda compared AI psychosis to monomania, in which someone obsessively fixates on a single idea or goal. Some people who have spoken about their mental health spirals say they were hyper-focused on an AI-driven narrative, the WSJ noted. These fixations can often be scientific or religious in nature, such as a man who came to believe he could bend time because of a breakthrough in physics.

Still, the reporting notes that psychiatrists are wary about declaring that chatbots are outright causing psychosis. They maintain, however, that they’re close to establishing the connection. One link that the doctors who spoke with the WSJ expect to see is that long interactions with a chatbot can be a psychosis risk factor.

“You have to look more carefully and say, well, ‘Why did this person just happen to coincidentally enter a psychotic state in the setting of chatbot use?&#39;” Joe Pierre, a UCSF psychiatrist, told the newspaper.

More on AI: Children Falling Apart as They Become Addicted to AI</div>
        </div>
        
        <div class="card" onclick="openModal('content-7')">
            <div class="source">Futurism</div>
            <div class="title">It’s Starting to Feel a Lot Like Tesla’s Robotaxi Program Is Mostly Smoke and Mirrors</div>
            <div class="meta">2025-12-30</div>
        </div>
        
        <div id="content-7" style="display:none;">
            <h2>It’s Starting to Feel a Lot Like Tesla’s Robotaxi Program Is Mostly Smoke and Mirrors</h2>
            <p><strong>Futurism | 2025-12-30</strong></p>
            <a class="original-link" href="https://futurism.com/advanced-transport/tesla-robotaxi-smoke-mirrors">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Elon Musk once promised that pivoting Tesla into the self-driving taxi business would generate the automaker trillions of dollars in revenue. Certainly the enthusiasm these kinds of grand proclamations have inspired in investors has kept the company’s stock buoyant, with an astonishing market cap nearing $1.5 trillion. But does the reality on the ground back it up? Not really, suggests new reporting from The New York Times.

For one, Tesla faces steep competition from companies like Waymo that have already been in business for over a decade, and have thousands of robotaxis giving rides across major US cities. It was recently revealed, meanwhile, that Musk’s company only has about 30 capital-R Robotaxis roaming Austin, Texas — the only city where it’s currently offering rides to the public.

Worse yet, the cabs’ presence is barely felt by locals.

“I’ve never seen a Robotaxi in Austin,” Kara Kockelman, a professor of engineering at the University of Texas at Austin who studies transportation, told the NYT. “Waymos are around all the time.”

Perhaps that puny market penetration would be less alarming if Tesla offered advanced tech and a passenger experience that Waymo doesn’t, but its self-driving cabs aren’t even fully driverless, requiring the supervision of a human “safety monitor” who must be present in the vehicle at all times. Numerous instances of the cabs violating traffic laws and an alarming crash rate demonstrate why that policy is still necessary.

It’s reasonable that a newcomer to the field would take time to find its feet, but Musk has promised monumental progress at a whirlwind pace. He said that over a thousand Robotaxis would be operating in Austin “within a few months” of launching, that over a million fully autonomous Teslas would be on the road by 2026, and that the automaker’s Robotaxi operations would cover “half the population of the US” by the end of next year.

Investors take these promises seriously. Musk’s eye-watering trillion-dollar pay package, which they recently approved, requires Musk to oversee the commercial deployment of one million Robotaxis, the NYT noted.

Experts, to say the least, aren’t convinced. One criticism is Musk’s refusal to use radar and lidar sensors to help the cars understand their surroundings. After experimenting with the sensors, Musk swore them off as an expensive “crutch,” and doubled-down on only using cameras to see. Numerous accidents, including one in which a Tesla running the company’s Full Self-Driving ran over and killed an elderly pedestrian while its front camera was blinded by sunlight, have underscored the risks of Musk’s approach.

“I’m still deeply skeptical that Tesla is all that close in terms of building a real automated driving system,” Matthew Wansley, a professor at Cardozo School of Law in New York who has worked for an autonomous driving start-up, told the NYT.

Technology can sometimes advance at a rapid pace, and fortunes can quickly shift in a nascent industry. But right now, Tesla is “way behind Waymo,” Raj Rajkumar, a Carnegie Mellon University professor and pioneer of autonomous technology, told the newspaper.

More on robotaxis: Waymos Cause Traffic Jams Across City During Power Outage</div>
        </div>
        
        <div class="card" onclick="openModal('content-8')">
            <div class="source">Futurism</div>
            <div class="title">Public Rejoices as Porsche Releases Beautiful Ad Not Made Using AI</div>
            <div class="meta">2025-12-29</div>
        </div>
        
        <div id="content-8" style="display:none;">
            <h2>Public Rejoices as Porsche Releases Beautiful Ad Not Made Using AI</h2>
            <p><strong>Futurism | 2025-12-29</strong></p>
            <a class="original-link" href="https://futurism.com/artificial-intelligence/porsche-ad-without-ai">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">This holiday season, German automaker Porsche is winning hearts and minds by putting out a Christmas-themed ad that seemingly isn’t made with AI. What a concept, right?

Called “Porsche Holiday,” the 30-second animated commercial shows a driver elegantly tooling around in his new ride, driving through autumnal scenery on a mountainside road and then a cool sea of glass and concrete as the Sun sets on a city. It’s done up in striking 2D-looking animation with precise lines, pleasing geometry, and eye-popping colors — an ad seemingly done right for a change.

Sharing behind the scenes footage, Porsche revealed in a social media post that the ad was a mix of hand-drawn sketches and CGI. It was made by Parallel Studio, an animation team based in Paris.

Though Porsche made no specific mention of AI, people reading between the lines quickly took that to mean that the automaker was quietly bragging about not using the tech, and hailed it as a victory. This perception of it being AI-free drove it to being remarkably viral, and made it an unexpected hit.

“Can’t wait for more of this anti-AI rebound,” one user wrote.

“Amtrak has been hiring artists to create original animations as well,” observed Nathan Allebach, a creative director. “As slop races us to the bottom, real art signals craft, prestige, and trust.”

The response goes to show how divisive AI is, especially in the arts. And ads, the most commercial art form of all, have both been a useful gauge of how companies have been willing to experiment with the tech and of the public reaction to it, which has been largely pretty negative.

Coca-Cola, for example, unleashed a ghoulishly uncanny iteration of its “Holidays Are Coming” last month that sparked outrage over how overtly ugly it was. McDonalds, too, released an AI-generated ad that proved such a disaster that it sheepishly pulled it entirely.

Everyone knows that our modern idea of the holiday season has been heavily shaped by ad agencies, but no one likes to be reminded of how soulless it can be by seeing AI amalgamations forced onto their eyeballs. At least pretend to care about humans, for Pete’s sake.

More on AI: Grimes Says She Has AI Psychosis, Recommends You Should Get it Too</div>
        </div>
        
        <div class="card" onclick="openModal('content-9')">
            <div class="source">Futurism</div>
            <div class="title">People Jabbing Themselves With Black Market “GLP-3” Drugs</div>
            <div class="meta">2025-12-29</div>
        </div>
        
        <div id="content-9" style="display:none;">
            <h2>People Jabbing Themselves With Black Market “GLP-3” Drugs</h2>
            <p><strong>Futurism | 2025-12-29</strong></p>
            <a class="original-link" href="https://futurism.com/health-medicine/retatrutide-ozempic-gray-black-market">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Some people are hitting a weight loss plateau with GLP-1 agonist drugs like Ozempic, so they’re turning to a stronger variety that promises even more dramatic weight loss — up to more than 70 pounds in some instances, The Atlantic reports.

There’s a small wrinkle: the US Food and Drug Administration has yet to officially approve this medication — technically called retatrutide but cheekily nicknamed a “GLP-3” by users — because it’s still in clinical trials. So the market for it is black, or at least severely grey, with shady overseas companies exploiting a legal loophole to get around regulatory barriers.

In other words, everyone taking retatrutide is basically taking part in an unregulated experiment that could have disastrous results. Sure, you can effortlessly melt off the pounds with the synthetic peptide, but some users have reported disturbing side effects — such as dysesthesia, when your body processes normal sensations but you perceive them as painful, similar to the nerve pain diabetics feel in their feet.

In the grand scheme of things, “GLP-3” users are part of a burgeoning group of people who have turned to foreign-made drugs, many other peptides that are also lacking federal approval. These substances, often manufactured in China, have become wildly popular in recent years for their purported anti-aging and longevity boosting potential, among other miraculous claims.

Companies that sell these drugs are able to skirt federal regulations by writing all over their website that the compounds are not for human consumption and are instead meant for research lab purposes — advice that users are pretty clearly not following.

“All of this stuff just scares the crap out of me,” Randy Seeley, a University of Michigan medical professor and GLP-1 agonist expert, told The Atlantic in reference to the unknown side effects of gray market drugs.

One danger with these drugs, Seeley said, is that their formulations aren’t known and they have the potential to be contaminated with bacteria and other substances. (To allay those concerns, some companies post lab results attesting to the purity of their products.)

Of course, everybody thinks their dealer is an exception.

“There’s a lot of people who just get these things and shoot them,” Marco, a retatrutide user who has bought the drug from what he considers trusted sources, told The Atlantic. “I don’t judge them in any way, but I think those people are out of their minds.”

Injecting GLP-1 agonist drugs into the human body boosts the levels of hormones GLP-1 and GIP, which trigger the release of insulin into your bloodstream. Retatrutide does that and more: it mimics another hormone, glucagon, found in the pancreas. This addition further revs up people’s metabolism, making them lose more weight compared to Ozempic and other GLP-1 agonist drugs.

Once clinical trials are done, FDA is expected to approve retatrutide, which will no doubt be a bestseller and make its manufacturer, Eli Lilly, even wealthier.

But even if it’s given the green light, it’s not a guarantee that the demand in the gray market will dissipate, especially if normies find the price too weighty to bear.

More on weight loss drugs: Low Doses of Ozempic-Like Drug Can Counteract Aging in Older Mice, Study Finds</div>
        </div>
        
        <div class="card" onclick="openModal('content-10')">
            <div class="source">Futurism</div>
            <div class="title">Alzheimer’s Fully Reversed in Mice, Scientists Say</div>
            <div class="meta">2025-12-29</div>
        </div>
        
        <div id="content-10" style="display:none;">
            <h2>Alzheimer’s Fully Reversed in Mice, Scientists Say</h2>
            <p><strong>Futurism | 2025-12-29</strong></p>
            <a class="original-link" href="https://futurism.com/health-medicine/alzheimers-mice-cured">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">A team of American scientists claim they have done something miraculous: they “cured” lab mice suffering from Alzheimer’s disease, which has robbed more than seven million Americans, typically 65 years old and up, of their identity and cognitive ability.

The researchers achieved this feat by administering the rodents with the powerful compound P7C3-A20, which they announced in a new paper in the journal Cell Reports Medicine. Scientists from Ohio’s Case Western Reserve University (CWRU), University Hospitals, and the Louis Stokes Cleveland VA Medical Center undertook the study.

“The key takeaway is a message of hope — the effects of Alzheimer’s disease may not be inevitably permanent,” said Andrew A. Pieper, the study’s principal investigator and a CWRU neuroscience professor, in a statement about the research. “The damaged brain can, under some conditions, repair itself and regain function.”

This research is part of a growing wave of very promising lab studies that point to a tantalizing future where Alzheimer’s and other neurological issues could be a thing of the past. Besides this P7C3-A20 research, others have scored remarkable lab results using different compounds and treatments.

This has made normally cautious scientists so excited that they are making bold predictions. University of Edinburgh neuroscience professor Tara Spires-Jones, who wasn’t part of this P7C3-A20 study, told the BBC this month she thinks scientists are closer than ever to a “truly life-changing” treatment — in as little as five to 10 years; instead of a slow death where people lose themselves, she forecasts that new tests will detect the condition early and innovative treatments will “really make your life normal.”

Scientists are also closer to understanding what causes Alzheimer’s, which seems to be sparked by different factors such as genetics, environment and other stressors — which means that future patients may receive personalized cocktail of anti-Alzheimer’s treatment and drugs suited for their own situation.

Regardless of the cause, previous research has suggested that Alzheimer’s is a form of inflammation. That means lessening or zeroing out inflammation in the brain would be key rather than managing symptoms.

In the P7C3-A20 study, the scientists focused on the impact of the crucial molecule NAD+, a coenzyme important for driving cellular metabolism and which decreases as we age, according to the study. Patients with Alzheimer’s suffer from a significant decrease of NAD+ in the brain, and hence their brain cells have trouble maintaining normal functionality, staving off inflammation, and canceling other physical hallmarks of the disease.

For the study, the team first took two types of lab mice that have been genetically bred to be predisposed to Alzheimer’s; one cohort had mutations for the amyloid protein and the other had tau protein mutations. Both proteins are important to cellular function, but they can become dangerous if they accrete in the brain in the form of amyloid plaques and tau tangles — causing a breakdown in normal cellular processes.

The team injected P7C3-A20 into both mice cohorts at two months of age, later finding out that this treatment successfully prevented them from developing the disease. But the big news was when they injected the compound into another batch of lab mice, who were suffering from a relatively advanced stage of Alzheimer’s at six months of age; after getting injections, these mice completely recovered their cognitive ability and NAD+ levels were restored to homeostasis leve;s

“We were very excited and encouraged by our results,” said Pieper in the statement. “Restoring the brain’s energy balance achieved pathological and functional recovery in both lines of mice with advanced Alzheimer’s. Seeing this effect in two very different animal models, each driven by different genetic causes, strengthens the new idea that recovery from advanced disease might be possible in people with AD when the brain’s NAD+ balance is restored.”

What’s also good about this study is that P7C3-A20 offers an alternative pathway to boosting NAD+ levels versus taking over-the-counter chemical precursors for NAD+, which can can raise NAD+ to such toxic levels that people could develop cancer, Pieper said. Supplements to boost NAD+ are just a click away on your cellphone, which should be worrying for anybody concerned about cancer.

The team wants to move to human clinical trials but some people are clearly not waiting; if you search online on how to obtain P7C3-A20 for yourself,  numerous websites selling vials of the compound will pop up.

More on Alzheimer’s disease: Scientists Identify Possible Game Changing Treatment for Alzheimer’s Disease That Could Control It Like High Cholesterol</div>
        </div>
        
        <div class="card" onclick="openModal('content-11')">
            <div class="source">Futurism</div>
            <div class="title">Days After Mass Bricking Event, Waymo Fleet Shuts Down Again</div>
            <div class="meta">2025-12-28</div>
        </div>
        
        <div id="content-11" style="display:none;">
            <h2>Days After Mass Bricking Event, Waymo Fleet Shuts Down Again</h2>
            <p><strong>Futurism | 2025-12-28</strong></p>
            <a class="original-link" href="https://futurism.com/advanced-transport/waymo-shuts-down-again">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Just days after its robotaxi fleet crumbled into complete disarray because of a city power outage in San Francisco, the company was forced to suspend all rides again in the Bay Area on Thursday in anticipation of a nasty storm, CNBC reported.

Customers received word of the measure via the company’s ride-hailing app.

“Service temporarily paused due to National Weather Service flash flood warning,” a notification read.

While you can hardly fault Waymo for erring on the side of caution, the measure comes as its self-driving cabs’ ability to handle conditions that fall outside its typical programming is being called into question.

The San Francisco incident, for instance, left its robotaxis stranded and helpless on public roads. Footage showed the cabs piling up at intersections, where they appeared confused about what to do without traffic lights to guide them. Rather than taking initiative or moving themselves out of the way, the cabs stayed idling in the middle of the roads, blocking motorists and even other Waymos. One video showed at least five of the cabs stuck in the same intersection. Frightened animals have a fight-or-flight response; Waymos have a stand-dumbfoundedly-in-place response.

Waymo has been offering fully autonomous rides to the public in San Francisco since 2024, with at least 800 robotaxis in the area. And though it boasts an impressive safety record, the cars have been a controversial presence with locals, whose complaints about the vehicles’ safety reached new heights last month when one of the cabs ran over and killed a beloved bodega cat.

Beyond tragedies like those, the cabs have been spotted more than occasionally driving down the wrong side of the road and committing blunders like getting stuck in a roundabout.

Other incidents like careening through an active police standoff and becoming paralyzed by a parade have exposed that the cars still struggle to handle the diversity of offbeat road scenarios one might be expected to encounter in a bustling city like San Francisco. Waymo can’t be blamed for the power outage last week, but that it seemingly didn’t equip its cars to handle a scenario like that is concerning.

“I think we need to be asking ‘what is a reasonable number of [autonomous vehicles] to have on city streets, by time of day, by geography and weather?&#39;” former CEO of San Francisco’s Municipal Transit Authority, Jeffrey Tumlin told CNBC.

More on self-driving cabs: The Number of Robotaxis Tesla Is Actually Running Will Make You Snort Out of Your Nose With Pure Derision</div>
        </div>
        
        <div class="card" onclick="openModal('content-12')">
            <div class="source">TechCrunch</div>
            <div class="title">Meta just bought Manus, an AI startup everyone has been talking about</div>
            <div class="meta">2025-12-30</div>
        </div>
        
        <div id="content-12" style="display:none;">
            <h2>Meta just bought Manus, an AI startup everyone has been talking about</h2>
            <p><strong>TechCrunch | 2025-12-30</strong></p>
            <a class="original-link" href="https://techcrunch.com/2025/12/29/meta-just-bought-manus-an-ai-startup-everyone-has-been-talking-about/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Meta Platforms is acquiring Manus, a Singapore-based AI startup that’s become the talk of Silicon Valley since it debuted last spring with a demo video that showed an AI agent doing things like screening job candidates, planning vacations, and analyzing stock portfolios. Manus claimed at the time that it outperformed OpenAI’s Deep Research.

In April 2025, just weeks after launch, venture capital firm Benchmark led a $75 million funding round that assigned Manus a post-money valuation of $500 million, and saw Benchmark general partner Chetan Puttagunta joining the startup’s board. Per Chinese media outlets, some other big-name backers had already invested in Manus at that point, including Tencent, ZhenFund, and HSG (formerly known as Sequoia China) via a $10 million round.

The company recently announced it has since signed up millions of users and was generating annual recurring revenue of more than $100 million.

That’s when Meta started negotiating with Manus, according to the WSJ, which says the tech giant is paying $2 billion — the valuation Manus was reportedly seeking for its next funding round.

For Zuckerberg, who has staked Meta’s future on AI, Manus represents something new: an AI product that’s actually making money. This is especially pertinent given that investors have grown increasingly twitchy about Meta’s $60 billion infrastructure spending spree, and the broader tech industry’s debt-backed expenditures on data center construction.

Meta says it’ll keep Manus running independently, and weave the startup’s AI agents into Facebook, Instagram and WhatsApp, where Meta’s own chatbot, Meta AI, is already available to users.

There is one wrinkle, however: Manus’ Chinese founders founded its parent company, Butterfly Effect, in Beijing in 2022, before decamping to Singapore in the middle of 2025. Whether that raises flags in Washington remains to be seen, but Senator John Cornyn has already dragged Benchmark for its investment in the company, raising concerns back in May about American capital going to a Chinese concern.

Cornyn, a Texas Republican and senior member of the Senate Intelligence Committee, has long been one of Congress’ most vocal hawks on China and technology competition, but he’s hardly alone. Being tough on China has become a genuinely bipartisan issue in Congress.

Unsurprisingly, Meta has already told Nikkei Asia that after the acquisition, Manus won’t have any ties to Chinese investors and will no longer operate in China. “There will be no continuing Chinese ownership interests in Manus AI following the transaction, and Manus AI will discontinue its services and operations in China,” a Meta spokesperson told the outlet.

Plan ahead for the 2026 StrictlyVC events. Hear straight-from-the-source candid insights in on-stage fireside sessions and meet the builders and backers shaping the industry. Join the waitlist to get first access to the lowest-priced tickets and important updates.

Meta just bought Manus, an AI startup everyone has been talking about

You’ve been targeted by government spyware. Now what?

Sauron, the high-end home security startup for ‘super premium’ customers, plucks a new CEO out of Sonos

NY Governor Hochul signs bill requiring warning labels on ‘addictive’ social media

How reality crushed Ÿnsect, the French startup that had raised over $600M for insect farming

Nvidia to license AI chip challenger Groq’s tech and hire its CEO

Waymo explains why its robotaxis got stuck during the SF blackout</div>
        </div>
        
        <div class="card" onclick="openModal('content-13')">
            <div class="source">TechCrunch</div>
            <div class="title">How to make your startup stand out in a crowded market, according to investors</div>
            <div class="meta">2025-12-29</div>
        </div>
        
        <div id="content-13" style="display:none;">
            <h2>How to make your startup stand out in a crowded market, according to investors</h2>
            <p><strong>TechCrunch | 2025-12-29</strong></p>
            <a class="original-link" href="https://techcrunch.com/2025/12/29/vcs-spill-what-they-really-want-to-hear-in-a-founder-pitch/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">At TechCrunch Disrupt, three investors took the stage to dissect what makes — and breaks — a pitch deck. Jyoti Bansal, a founder-turned-investor; Medha Agarwal of Defy; and Jennifer Neundorfer of January Ventures shared with the crowd their candid views on what works in a pitch deck — and what doesn’t.

Their biggest pet peeve? Buzzword overload.

The more a founder says AI in the pitch, Agarwal said, the less AI the company likely uses. “The people who are doing things that are really innovative, they’ll talk about it, and it’s built in, but it’s not the core of their pitch,” she told the audience.

Bansal, who built and sold multiple companies before becoming an investor, distilled investor expectations into three core questions. First, he asks whether there is a large enough market to tackle. Does the founder’s idea have the potential to become a huge company? And is the problem he or she is solving actually worth solving?

The second thing investors want to know is why this founder is the one who should be building the company. “There has to be something unique about you,” Bansal told the crowd, adding that this included having special members on the founding team or having special skills. “Why would you win? If the problem is interesting, there will be 20 other companies trying to solve it, so why would you win and what’s your opportunity?”

The third thing investors want to see, Bansal said, is some validation. “Traction with customers,” he said. “Validation could be initial customer feedback, revenue, something, but some kind of validation.”

These three questions, Bansal noted, all lead to the ultimate litmus test: Could this become a billion-dollar company?

The panel also addressed how AI startups can differentiate themselves as the space becomes saturated. Bansal emphasized the importance of domain expertise and a clear competitive strategy. Neundorfer said the companies that catch her attention are those enabling new behaviors rather than simply improving an existing process incrementally.

Agarwal offered more tactical advice to founders, saying they should explain how AI technology enables their product; articulate clear go-to-market strategies; and demonstrate how their business will be more efficient than incumbents.

It’s also very important to be honest about what competitors are out there, she added. Some of you have “lost some credibility with me because you didn’t have it on your slide,” she told the founders in the audience.

Finally, the investors shared advice for navigating the rapidly evolving landscape. Agarwal urged founders to stay on top of industry developments. Neundorfer recommended staying connected to founder networks to share tools and insights.

Bansal’s advice was simpler: “Focus on building your product.”

Dominic-Madori Davis is a senior venture capital and startup reporter at TechCrunch. She is based in New York City.

You can contact or verify outreach from Dominic by emailing dominic.davis@techcrunch.com or via encrypted message at +1 646 831-7565 on Signal.

Plan ahead for the 2026 StrictlyVC events. Hear straight-from-the-source candid insights in on-stage fireside sessions and meet the builders and backers shaping the industry. Join the waitlist to get first access to the lowest-priced tickets and important updates.

Meta just bought Manus, an AI startup everyone has been talking about

You’ve been targeted by government spyware. Now what?

Sauron, the high-end home security startup for ‘super premium’ customers, plucks a new CEO out of Sonos

NY Governor Hochul signs bill requiring warning labels on ‘addictive’ social media

How reality crushed Ÿnsect, the French startup that had raised over $600M for insect farming

Nvidia to license AI chip challenger Groq’s tech and hire its CEO

Waymo explains why its robotaxis got stuck during the SF blackout</div>
        </div>
        
        <div class="card" onclick="openModal('content-14')">
            <div class="source">TechCrunch</div>
            <div class="title">Social media follower counts have never mattered less, creator economy execs say</div>
            <div class="meta">2025-12-29</div>
        </div>
        
        <div id="content-14" style="display:none;">
            <h2>Social media follower counts have never mattered less, creator economy execs say</h2>
            <p><strong>TechCrunch | 2025-12-29</strong></p>
            <a class="original-link" href="https://techcrunch.com/2025/12/29/social-media-follower-counts-have-never-mattered-less-creator-economy-execs-say/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">As social media becomes increasingly reliant on algorithmic feeds, creators are navigating a new normal: Just because you post something doesn’t mean your followers will see it.

“I think that 2025 was the year where the algorithm completely took over, so followings stopped mattering entirely,” LTK CEO Amber Venz Box told TechCrunch.

This isn’t news to creators – Patreon CEO Jack Conte has ardently banged this drum for years – but throughout the year, the industry at large has reacted to this phenomenon in different ways, from the influencers to the streamers.

According to the executives that TechCrunch spoke to about the near future of the creator economy, creators are finding new ways to harness and cultivate their relationships with their followers – some acting as a salve to AI slop, while others are flooding the zone with a new form of slop themselves.

Box’s company, LTK, connects creators with brands through affiliate marketing, where creators earn commissions on products they recommend. The business model depends entirely on audiences retaining trust in individual creators. Given concerns about fragmentation in the creator-audience relationship, this could pose an existential threat to the company.

But a study commissioned from Northwestern University found that trust in creators increased 21% year-over-year, which was a pleasant surprise to Box.

“If you asked me at the beginning of 2025, ‘Hey, is trust in creators going to go up or down?’ I would have probably said down, because people understand it’s an industry – they understand how it’s working,” she said. “But actually, AI pushed people to kind of rotate trust to real humans that they know have real life experiences.”

By that, Box means that consumers are more likely to go out of their way to see content from the creators they know and trust. According to the study, 97% of chief marketing officers intend to grow influencer marketing budgets in the new year.

That doesn’t mean that owning these relationships is straightforward. LTK creators, who rely on affiliate income, are betting this AI-induced skepticism will drive people toward more direct relationships through paid fan communities or less algorithmic platforms like LTK itself. For other kinds of creators, such as streamers, video podcasters, and short filmmakers, the strategy for owning their audience can more closely resemble growth hacking.

As Sean Atkins, CEO of short-form video production company Dhar Mann Studios, put it, “In a world that’s driven by AI and algorithms, where people trust another human being more in this micro atomization of attention, how do you market when you sort of can’t control that?”

According to Eric Wei, cofounder of Karat Financial, a financial services company for creators, creators have a new secret weapon: armies of teenagers on Discord who creators pay to make clips of their content, which those same teenagers post en masse on algorithmic platforms.

“That’s been going on for a bit,” Wei explained. “Drake does it. A lot of the biggest creators and streamers in the world have been doing it – Kai Cenat [a top Twitch streamer] has done it – hitting millions of impressions… If it’s algorithmically determined, clipping suddenly makes sense, because it can come from any random account that just has really good clips.”

Wei thinks that clipping is going to become even more popular this year, since it’s a reaction to this fragmentation in social media relationships. Even the biggest creators are finding it hard to reach their fans directly, which is why they turn to clipping. While going viral on these algorithmic feeds is certainly easier if you have a ton of followers, you don’t need any track-record on a platform for it to decide that your video should be distributed more broadly. So, if these “clippers” post a short highlight from certain creators’ streams, they can earn money based on how many views the video gets.

“Clipping feels like an evolution of meme accounts,” Glenn Ginsburg, president of QYOU Media, which produces content for young audiences, told TechCrunch. “It’s become a race among many creators to try and take this content and push it out far and wide, almost competing to see who can get the most views on the same IP.”

Reed Duchscher – founding CEO of Night, the talent management company that represents Kai Cenat and other top creators – masterfully coaches creators through maximizing their virality. As MrBeast’s former manager, Duchscher helped cultivate the fast-paced, attention-grabbing style that transformed MrBeast from a YouTuber to an empire. He’s also behind Kai Cenat’s clipping strategy, though Duchscher isn’t quite as enthusiastic about its broader potential as Wei.

“Clipping is important if you’re a creator, because you do need to flood the zone with content, and it’s a good way to get your face out there,” Duchscher told TechCrunch. “It’s also very hard to get to scale, because there’s only so many clippers on the internet, so to spend large media budgets… there’s just a lot of complications.”

Perhaps clipping only works now because the technique has not yet become so prevalent that it’s seen as spam.

“The creator wins because they get more of their content out,” Wei said. “The clippers win because now this army of teenagers are getting paid. Everybody wins, except that if you take this to its logical conclusion, we just get lots and lots of slop.”

The prevalence of slop on social media has become enough of a threat that Merriam-Webster called slop its word of the year.

“Over 94% of people are saying that social media is no longer social, and over half of them are rotating time elsewhere into smaller niche communities that they know are real and that they can talk to and interact with,” Box said, pointing to platforms like Strava, LinkedIn, and Substack.

As the relationship between a creator and their audience becomes more difficult to maintain, Duchscher predicts that creators with more specific niches will succeed – he thinks that “macro creators” like MrBeast, PewDiePie, or Charli D’Amelio, who amass hundreds of millions of followers, will become even harder to emulate.

Pointing to success stories like like Alix Earle or Outdoor Boys, who have millions of followers but not necessarily mass appeal, Duchscher adds, “Algorithms have gotten so good at giving us exactly the content we want. It’s much harder for a creator to break out into every niche algorithm.”

Atkins agrees, arguing that the creator economy extends far beyond entertainment. “The creator economy generally is viewed through this lens of entertainment. I think that’s a mistake, because thinking about the creator economy is a little bit like thinking about the internet or AI – it’s going to affect everything.”

Atkins mentions the gardening creator brand Epic Gardening as an example. What started as a YouTube channel has created a real, tangible presence in the world of gardening.

“Epic Gardening bought the third largest seed company in the United States, so now he’s the third largest seed company [owner], as a content creator,” he said.

Though the creator economy is in flux, it’s a resilient industry – one that’s accustomed to navigating the whims of the algorithm, persisting onward for decades, even if the uninitiated may see it as a brand new realm.

Creators are “literally impacting everything,” Atkins said. “I bet you there’s a creator who’s an expert at cement mixing for skyscrapers.”

Amanda Silberling is a senior writer at TechCrunch covering the intersection of technology and culture. She has also written for publications like Polygon, MTV, the Kenyon Review, NPR, and Business Insider. She is the co-host of Wow If True, a podcast about internet culture, with science fiction author Isabel J. Kim. Prior to joining TechCrunch, she worked as a grassroots organizer, museum educator, and film festival coordinator. She holds a B.A. in English from the University of Pennsylvania and served as a Princeton in Asia Fellow in Laos.

You can contact or verify outreach from Amanda by emailing amanda@techcrunch.com or via encrypted message at @amanda.100 on Signal.

Plan ahead for the 2026 StrictlyVC events. Hear straight-from-the-source candid insights in on-stage fireside sessions and meet the builders and backers shaping the industry. Join the waitlist to get first access to the lowest-priced tickets and important updates.

Meta just bought Manus, an AI startup everyone has been talking about

You’ve been targeted by government spyware. Now what?

Sauron, the high-end home security startup for ‘super premium’ customers, plucks a new CEO out of Sonos

NY Governor Hochul signs bill requiring warning labels on ‘addictive’ social media

How reality crushed Ÿnsect, the French startup that had raised over $600M for insect farming

Nvidia to license AI chip challenger Groq’s tech and hire its CEO

Waymo explains why its robotaxis got stuck during the SF blackout</div>
        </div>
        
        <div class="card" onclick="openModal('content-15')">
            <div class="source">TechCrunch</div>
            <div class="title">2025 was the year AI got a vibe check</div>
            <div class="meta">2025-12-29</div>
        </div>
        
        <div id="content-15" style="display:none;">
            <h2>2025 was the year AI got a vibe check</h2>
            <p><strong>TechCrunch | 2025-12-29</strong></p>
            <a class="original-link" href="https://techcrunch.com/2025/12/29/2025-was-the-year-ai-got-a-vibe-check/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Money was no object for the AI industry in early 2025. A vibe check crept in the second half of the year.

OpenAI raised $40 billion at a $300 billion valuation. Safe Superintelligence and Thinking Machine Labs raised individual $2 billion seed rounds before shipping a single product. Even first-time founders were raising at a scale that once belonged only to Big Tech.

Such astronomical investments were followed by equally incredible spends. Meta shelled out nearly $15 billion to lock up Scale AI CEO Alexandr Wang and spent countless more millions to poach talent from other AI labs. Meanwhile, AI’s biggest players promised close to $1.3 trillion in future infrastructure spending.

The first half of 2025 matched the fervor, and investor interest, of the prior year. That mood has shifted in recent months to deliver a vibe check of sorts. Extreme optimism for AI, and the accompanying wild valuations, is still intact. But that rosy view is now being tempered with concerns over an AI bubble bursting, user safety, and the sustainability of technological progress at its current pace.

The era of unabashed acceptance and celebration of AI is fading just a skosh at the edges. And with it, more scrutiny and questions. Can AI companies sustain their own velocity? Does scaling in the post-DeepSeek era require billions? Is there a business model that returns a sliver of the multi-billions of investment?

We’ve been there for every step. And our most popular stories of 2025 tell the real story: an industry hitting a reality check even as it promises to reshape reality itself.

The biggest AI labs got bigger this year.

In 2025 alone, OpenAI raised a Softbank-led $40 billion round at a $300 billion post-money valuation. The company also reportedly has investors like Amazon orbiting with compute-tied circular deals, and is in talks to raise $100 billion at an $830 billion valuation. That would bring OpenAI close to the $1 trillion valuation it is reportedly seeking in an IPO next year.

OpenAI rival Anthropic also closed $16.5 billion this year across two rounds, its most recent raise pushed its valuation to $183 billion with heavy hitters like Iconiq Capital, Fidelity, and the Qatar Investment Authority participating. (CEO Dario Amodei confessed to staff in a leaked memo that he was “not thrilled” about taking money from dictatorial Gulf states).

Then there’s Elon Musk’s xAI, which raised at least $10 billion this year after acquiring X, the social media platform formerly known as Twitter that Musk also owns.

We’ve also seen smaller, new startups get a hypey boost from froth-mouthed investors.

Former OpenAI chief technologist Mira Murati’s startup Thinking Machine Labs secured a $2 billion seed round at a $12 billion valuation despite sharing almost no information about its product offering. Vibe-coding startup Lovable’s $200 million Series A earned it a unicorn horn just eight months after launching; this month, Lovable raised another $330 million at a nearly $7 billion post-money valuation. And we can’t leave out AI recruiting startup Mercor, which raised $450 million this year across two rounds, the latest bringing its valuation up to $10 billion.

These absurdly large valuations are still happening even against the backdrop of still-modest enterprise adoption figures and serious infrastructure constraints, heightening fears of an AI bubble.

For the larger firms, those numbers aren’t coming from nowhere. Justifying those valuations requires building vast amounts of infrastructure.

The result has created a vicious cycle. Capital raised to fund compute is increasingly tied to deals where the same money flows back into chips, cloud contracts, and energy, as seen in OpenAI’s infrastructure-linked funding with Nvidia. In practice, it’s blurring the line between investment and customer demand, stoking fears that the AI boom is being propped up by circular economics rather than sustainable usage.

Some of the biggest deals this year powering the infrastructure boom were:

But cracks are beginning to show. A private financing partner, Blue Owl Capital, recently pulled out of a planned $10 billion Oracle data-center deal tied to OpenAI capacity, underscoring how fragile some of these capital stacks can be.

Whether all that spending ultimately materializes is another question. Grid constraints, soaring construction and power costs, and growing pushback from residents and policymakers – including calls from figures like Sen. Bernie Sanders to rein in data center expansion – are already slowing projects in some regions.

Even as AI investment remains enormous, the infrastructure reality is beginning to temper the hype.

In 2023 and 2024, each major model release felt like a revelation, with new capabilities and fresh reasons to fall for the hype. This year, the magic faded, and nothing captured that shift better than OpenAI’s GPT-5 rollout.

While it was meaningful on paper, it didn’t land with the same punch as earlier releases like GPT-4 and 4o. Similar patterns emerged across the industry as improvements from LLM providers were less transformative and more incremental or domain-specific.

Even Gemini 3, which is topping several benchmarks, was only a breakthrough insofar as it brought Google back up to equal footing with OpenAI – which sparked Sam Altman’s infamous ‘code red’ memo and OpenAI’s fight to maintain dominance.

There was also a reset this year in terms of where we expect frontier models to come from. DeepSeek’s launch of R1, its “reasoning” model that competed with OpenAI’s o1 on key benchmarks, proved that new labs can ship credible models fast and at a fraction of the cost.

As the size of each leap between new models shrinks, investors are focused less on raw model capacity and more on what’s wrapped around it. The question is: who can turn AI into a product that people rely on, pay for, and integrate into their daily workflows?

That shift is manifesting in several ways as companies see what works, and what customers will let fly. AI search startup Perplexity, for example, briefly floated the idea of tracking users’ online movements to sell them hyper-personalized ads. Meanwhile, OpenAI was reportedly considering charging up to $20,000 per month for specialized AI, a sign of how aggressively companies tested the waters of what customers might be willing to pay.

More than anything, though, the fight has moved to distribution. Perplexity is trying to stay relevant by launching its own Comet browser with agentic capabilities and paying Snap $400 million to power search inside Snapchat, effectively buying its way into existing user funnels.

OpenAI is pursuing a parallel strategy, expanding ChatGPT beyond a chatbot and into a platform. OpenAI has launched its own Atlas browser and other consumer-facing features like Pulse, while also courting enterprises and developers by launching apps inside ChatGPT itself.

Google, for its part, is leaning on incumbency. On the consumer side, Gemini is being integrated directly into products like Google Calendar, while on the enterprise side, the company is hosting MCP connectors to make its ecosystem harder to dislodge.

In a market where it’s getting tougher to differentiate by dropping a new model, owning the customer and the business model is the real moat.

AI companies received unprecedented scrutiny in 2025. More than 50 copyright lawsuits wound through the courts, while reports of “AI psychosis” – the result of chatbots reinforcing delusions and allegedly contributing to multiple suicides and other life-threatening episodes – sparked calls for trust and safety reforms.

While some copyright battles met their end – like Anthropic’s $1.5 billion settlement to authors – most are still unresolved. Though the conversation appears to be shifting from resistance against using copyrighted content for training, to demands for compensation (See: New York Times sues Perplexity for copyright infringement).

Meanwhile, mental health concerns around AI chatbot interactions – and their sycophantic responses – emerged as a serious public health issue following multiple deaths by suicide and life-threatening delusions in teens and adults after prolonged chatbot usage. The result has been lawsuits, widespread concern among mental health professionals, and swift policy responses like California’s SB 243 regulating AI companion bots.

Perhaps most telling: the calls for restraints are not coming from the usual anti-tech suspects.

Industry leaders have warned against chatbots “juicing engagement,” and even Sam Altman has cautioned against emotional over-reliance on ChatGPT.

Even the labs themselves started sounding alarms. Anthropic’s May safety report documented Claude Opus 4 attempting to blackmail engineers to prevent its own shutdown. The subtext? Scaling without understanding what you’ve built is no longer a viable strategy.

If 2025 was the year AI started to grow up and face hard questions, 2026 will be the year it has to answer them. The hype cycle is starting to fizzle out, and now AI companies will be forced to prove their business models and demonstrate real economic value.

The era of ‘trust us, the returns will come’ is nearing its end. What comes next will either be a vindication or a reckoning that makes the dot-com bust look like a bad day of trading for Nvidia. Time to place your bets.

Rebecca Bellan is a senior reporter at TechCrunch where she covers the business, policy, and emerging trends shaping artificial intelligence. Her work has also appeared in Forbes, Bloomberg, The Atlantic, The Daily Beast, and other publications.

You can contact or verify outreach from Rebecca by emailing rebecca.bellan@techcrunch.com or via encrypted message at rebeccabellan.491 on Signal.

Plan ahead for the 2026 StrictlyVC events. Hear straight-from-the-source candid insights in on-stage fireside sessions and meet the builders and backers shaping the industry. Join the waitlist to get first access to the lowest-priced tickets and important updates.

Meta just bought Manus, an AI startup everyone has been talking about

You’ve been targeted by government spyware. Now what?

Sauron, the high-end home security startup for ‘super premium’ customers, plucks a new CEO out of Sonos

NY Governor Hochul signs bill requiring warning labels on ‘addictive’ social media

How reality crushed Ÿnsect, the French startup that had raised over $600M for insect farming

Nvidia to license AI chip challenger Groq’s tech and hire its CEO

Waymo explains why its robotaxis got stuck during the SF blackout</div>
        </div>
        
        <div class="card" onclick="openModal('content-16')">
            <div class="source">TechCrunch</div>
            <div class="title">Plaud Note Pro is an excellent AI-powered recorder that I carry everywhere</div>
            <div class="meta">2025-12-29</div>
        </div>
        
        <div id="content-16" style="display:none;">
            <h2>Plaud Note Pro is an excellent AI-powered recorder that I carry everywhere</h2>
            <p><strong>TechCrunch | 2025-12-29</strong></p>
            <a class="original-link" href="https://techcrunch.com/2025/12/29/plaud-note-pro-is-an-excellent-ai-powered-recorder-that-i-carry-everywhere/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">There has been a flurry of AI voice recording gadgets like Omi, Bee, and Friend that want to capture your voice and let you converse with an AI chatbot. While Bee was acquired by Amazon, and devices like the Stream ring by Sandbar and a new AI ring from former Pebble founder Eric Migicovsky are set to enter the market next year, the jury is still out on the success of wearable AI devices.

Amid all this, Plaud is thriving by targeting professional users with a different approach: a credit card-sized recording device that slips into your wallet. The company says it has shipped more than a million units and that more than 50% of its customers have converted to pro subscriptions.

The company’s latest iteration, the Plaud Note Pro, launched for preorder in August, two years after the original Note, priced at $179. After using the device for over a month, it has become an essential part of my daily carry — and its ultra-thin design makes that easy.

At just 0.12 inches thick — about the width of three stacked credit cards — it’s the thinnest AI recording device on the market and easily fits in a wallet or attaches magnetically to the back of your phone.

The company provides a wallet-like pouch and a magnetic ring accessory that attaches to MagSafe-enabled phones, allowing you to mount the Note Pro on the back of your iPhone or compatible Android device. The device is also very light at 30 grams, and you won’t feel the weight if you keep the Note Pro in your wallet.

One of the key differences between Plaud and other AI wearables is that the Note Pro doesn’t need to be connected to your phone to record audio. The device has 64GB of onboard memory, so it can store a large volume of recordings without transferring them to your phone or uploading them to the cloud.

Plaud Note Pro has four MEMS (Micro-Electro-Mechanical Systems) microphones to pick up audio from all directions. While the company advertises that the effective audio range is 16.4 feet, I have recorded talks at conferences while sitting far from the stage and gotten satisfactory results. The device also has one voice processing unit for noise suppression, voice isolation, and echo cancellation.

The recording device has impressive battery life. I went to a conference earlier this month with a fully charged device and recorded a few interviews and talks there. After that, I used the device for some phone call recording and personal note-taking. Despite all that use, the device still had 55% charge after 15 days. The company says you can wring 30 hours of continuous recording and 60 days of standby from a single charge.

Plaud’s new device comes with a proprietary charger with a USB-C cable on the other end. The device takes two hours to charge from 0%, and then you are set for at least a couple of weeks unless you are recording hours of content.

One problem with wearable AI devices is that you have to ensure, through an indicator, that the device is recording (or has stopped recording). Thankfully, Plaud Note Pro has a tiny screen that displays your recording status. You can also press a button while recording to highlight a point a speaker is making, and it will show up in the AI-powered summary prominently. The screen also shows you the remaining battery level.

There is intentionality behind recording with this device. You also get haptic feedback for starting and stopping the recording. The visual indication and your action of pressing the button also make it easier to signal to others in the meeting that you are recording the session.

You can choose to just record sessions and export them to another AI transcription service you are subscribed to. Plaud natively provides 300 minutes of free transcription every month. The company also lets you customize AI-generated notes through templates suited for different profiles and tasks. You can create your own template as well. The transcription is accurate in most instances, and now you can also access the recording, transcript, and notes through a website. The company has also addressed the problem my former colleague Brian Heater had of tapping on the word and not being played the corresponding recording.

While a pendant or pin-like form factor is possibly easier to carry, the card-sized recorder offers better microphones and more versatile placement options. It’s worth buying the $179 gadget if you take a lot of in-person meetings.

Ivan covers global consumer tech developments at TechCrunch. He is based out of India and has previously worked at publications including Huffington Post and The Next Web.

You can contact or verify outreach from Ivan by emailing im@ivanmehta.com or via encrypted message at ivan.42 on Signal.

Plan ahead for the 2026 StrictlyVC events. Hear straight-from-the-source candid insights in on-stage fireside sessions and meet the builders and backers shaping the industry. Join the waitlist to get first access to the lowest-priced tickets and important updates.

Meta just bought Manus, an AI startup everyone has been talking about

You’ve been targeted by government spyware. Now what?

Sauron, the high-end home security startup for ‘super premium’ customers, plucks a new CEO out of Sonos

NY Governor Hochul signs bill requiring warning labels on ‘addictive’ social media

How reality crushed Ÿnsect, the French startup that had raised over $600M for insect farming

Nvidia to license AI chip challenger Groq’s tech and hire its CEO

Waymo explains why its robotaxis got stuck during the SF blackout</div>
        </div>
        
        <div class="card" onclick="openModal('content-17')">
            <div class="source">TechCrunch</div>
            <div class="title">Why the electrical grid needs more software</div>
            <div class="meta">2025-12-29</div>
        </div>
        
        <div id="content-17" style="display:none;">
            <h2>Why the electrical grid needs more software</h2>
            <p><strong>TechCrunch | 2025-12-29</strong></p>
            <a class="original-link" href="https://techcrunch.com/2025/12/29/why-the-electrical-grid-needs-more-software/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">One of the nicest comments people have made about the electrical grid was … nothing. The grid works best when it fades into the background.

That low-profile status has changed in recent years as fires in California and freezes in Texas raised awareness of the electrical grid. But it was in 2025, when the electrical grid — and concerns about demand, supply, pricing, and the strain on natural resources — moved into the spotlight. And a new batch of startups have emerged with a software-as-a-solution pitch.

Electricity rates are up 13% in this U.S. this year driven by an AI boom that has seeped into unlikely places, including repurposing supersonic jet engines for data center duty and working on beaming solar power down from space.

And that pace of growth isn’t expected to slow; the amount of electricity data centers use is projected to nearly triple in the coming decade. That forecast has fueled consumer frustration around pricing and drawn the ire of environmental groups that have called for a nationwide moratorium on new projects. Utilities, which have toiled away in the background, are now scrambling to upgrade the grid and build new power plants that can cope with the load — the fear of an AI bubble bursting always lingering in the background.

This confluence of demand and fear could give software startups a boost in the coming year.

For example, startups like Gridcare and Yottar argue that spare capacity already exists on the grid and that software can help find it.

Gridcare has gathered data on transmission and distribution lines, fiber-optic connections, extreme weather, and even community sentiment to optimize the search for new locations and convince utilities the grid can handle it. Already, the company says it has found several such sites that have been overlooked. Yottar finds places where known capacity exists and overlaps with the needs of medium-size users, helping them quickly connect amid the data center boom.

Several other startups are using software to stitch together massive fleets of batteries scattered across the grid. Those startups can turns these fleets into virtual power plants to deliver power to the grid when it’s needed most.

Base Power, for example, is building one in Texas by leasing batteries to homeowners at relatively low prices. Homeowners can use the batteries for backup power in case of outages, while Base can tap into them to prevent outages by selling the aggregated capacity to the grid. Terralayr is doing something similar, though it doesn’t sell batteries itself. Instead, Terralayr uses software to bundle distributed storage assets already installed on the German grid.

Other startups, including Texture, Uplight, and Camus, are developing software layers to integrate and coordinate distributed energy sources like wind, solar, and batteries. The hope is that by orchestrating various assets, they will idle less and contribute more to the grid.

There’s also some hope that software can help modernize some of the more outdated parts of the grid.

Nvidia, for example, has partnered with EPRI, a power industry R&D organization, to develop industry-specific models in the hopes they will improve efficiency and resiliency. Meanwhile, Google is working with the grid operator PJM to use AI to help sift through its backlog of connection requests from new sources of electricity.

These changes won’t happen overnight, but 2026 could be the year when they begin to take hold.

Utilities tend to be slow to adopt new technologies because of concerns about reliability. But they’re also slow to invest in new infrastructure because it’s costly and long-lived. Ratepayers and regulators have been known to balk when such projects begin to affect affordability.

Software, though, is cheaper, and if it can clear the reliability hurdle, the companies offering it will have a good chance of gaining traction.

And that could benefit more than the startups hawking software. Ultimately, the grid is going to need some refurbishment and expansion. Given the number of planned data centers and the electrification of broad swathes of the economy, including transportation, heating, and more, we will need more power. It would be foolish to ignore the power of software in these instances. It’s cheap, flexible, and speedy to deploy.

Tim De Chant is a senior climate reporter at TechCrunch. He has written for a wide range of publications, including Wired magazine, the Chicago Tribune, Ars Technica, The Wire China, and NOVA Next, where he was founding editor.

De Chant is also a lecturer in MIT’s Graduate Program in Science Writing, and he was awarded a Knight Science Journalism Fellowship at MIT in 2018, during which time he studied climate technologies and explored new business models for journalism. He received his PhD in environmental science, policy, and management from the University of California, Berkeley, and his BA degree in environmental studies, English, and biology from St. Olaf College.

You can contact or verify outreach from Tim by emailing tim.dechant@techcrunch.com.

Plan ahead for the 2026 StrictlyVC events. Hear straight-from-the-source candid insights in on-stage fireside sessions and meet the builders and backers shaping the industry. Join the waitlist to get first access to the lowest-priced tickets and important updates.

Meta just bought Manus, an AI startup everyone has been talking about

You’ve been targeted by government spyware. Now what?

Sauron, the high-end home security startup for ‘super premium’ customers, plucks a new CEO out of Sonos

NY Governor Hochul signs bill requiring warning labels on ‘addictive’ social media

How reality crushed Ÿnsect, the French startup that had raised over $600M for insect farming

Nvidia to license AI chip challenger Groq’s tech and hire its CEO

Waymo explains why its robotaxis got stuck during the SF blackout</div>
        </div>
        
        <div class="card" onclick="openModal('content-18')">
            <div class="source">The Atlantic</div>
            <div class="title">The Problem With Letting AI Do the Grunt Work</div>
            <div class="meta">2025-12-30</div>
        </div>
        
        <div id="content-18" style="display:none;">
            <h2>The Problem With Letting AI Do the Grunt Work</h2>
            <p><strong>The Atlantic | 2025-12-30</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/ideas/2025/12/ai-entry-level-creative-jobs/685297/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">One of the first sentences I was ever paid to write was “Try out lighter lip stick colors, like peach or coral.” Fresh out of college in the mid 2010s, I’d scored a copy job for a how-to website. An early task involved expanding upon an article titled “How to Get Rid of Dark Lips.” For the next two years, I worked on articles with headlines such as “How to Speak Like a Stereotypical New Yorker (With Examples),” “How to Eat an Insect or Arachnid,” and “How to Acquire a Gun License in New Jersey.” I didn’t get rich or win literary awards, but I did learn how to write a clean sentence, convey information in a logical sequence, and modulate my tone for the intended audience—skills that I use daily in my current work in screenwriting, film editing, and corporate communications. Just as important, the job paid my bills while I found my way in the entertainment industry.

Artificial intelligence has rendered my first job obsolete. Today, if you want to learn  “How to Become a Hip Hop Music Producer,” you can just ask ChatGPT. AI is also displacing the humans doing many of my subsequent jobs: writing promotional copy for tourism boards, drafting questions for low-budget documentaries, offering script notes on student films. Today, a cursory search for writing jobs on LinkedIn pulls up a number of positions that involve not producing copy but training AI models to sound more human. When anyone can create a logo or marketing copy at the touch of a button, why hire a new graduate to do it?

From the July/August 2023 issue: The coming humanist renaissance

These shifts in the job market won’t deter everyone. Well-connected young people with rich families can always afford to network and take unpaid jobs. But by eliminating entry-level jobs, AI may destroy the ladder of apprenticeship necessary to develop artists, and it could leave behind a culture driven by nepo babies and chatbots.

The existential crisis is spreading across the creative landscape. Last year, the consulting firm CVL Economics estimated that artificial intelligence would disrupt more than 200,000 entertainment-industry jobs in the United States by 2026. The CEO of an AI music-generation company claimed in January that most musicians don’t actually enjoy making music, and that musicians themselves will soon be unnecessary.

In a much-touted South by Southwest talk earlier this year, Phil Wiser, the chief technology officer of Paramount, described how AI could streamline every step of filmmaking. Even the director James Cameron—whose classic work The Terminator warned of the dangers of intelligent machines, and whose forthcoming Avatar sequel will reportedly include a disclaimer that no AI was involved in making the film—has talked about using the technology to cut costs and speed up production schedules. Last year, the chief technology officer of OpenAI declared that “some creative jobs maybe will go away, but maybe they shouldn’t have been there in the first place.”

One great promise of generative AI is that it will free artists from drudgery, allowing them to focus on the sort of “real art” they all long to do. It may not cut together the next Magnolia, but it’ll do just fine with the 500th episode of Law & Order. What’s the harm, studio executives might wonder, if machines take over work that seems unchallenging and rote to knowledgeable professionals?

Read: Your creativity won’t save your job from AI

The problem is that entry-level creative jobs are much more than grunt work. Working within established formulas and routines is how young artists develop their skills. Hunter S. Thompson began his writing career as a copy boy for Time magazine; Joan Didion was a research assistant at Vogue; the director David Lean edited newsreels; the musician Lou Reed wrote knockoff pop tunes for department stores; the filmmakers Martin Scorsese, Jonathan Demme, and Francis Ford Coppola shot cheap B movies for Roger Corman. Beyond the money, which is usually modest, low-level creative jobs offer practice time and pathways for mentorship that side gigs such as waiting tables and tending bar do not.

Having begun my own transition into filmmaking by making rough cuts of video footage for a YouTube channel, I couldn’t help but be alarmed when the makers of the AI software Eddie launched an update in September that can produce first edits of films. For that YouTube channel, I shot, edited, and published three videos a week, and I received rigorous producer notes and near-immediate audience feedback. You can’t help but get better at your craft that way. These jobs are also where you meet people: One of the producers at that channel later commissioned my first produced screenplay for Netflix.

There’s a reason the Writers Guild of America, of which I am a member, made on-set mentorship opportunities for lower-level writers a plank of its negotiations during the 2023 strike. The WGA won on that point, but it may have been too late.

The optimistic case for AI is that new artistic tools will yield new forms of art, much as the invention of the camera created the art of photography and pushed painters to explore less realistic forms. The proliferation of cheap digital video cameras helped usher in the indie-film explosion of the late 1990s. I’ve used several AI tools in ways that have widely expanded my capabilities as a film editor.

Working from their bedrooms, indie filmmakers can deploy what, until recently, were top-tier visual-effects capabilities. Musicians can add AI instruments to their compositions. Perhaps AI models will offer everyone unlimited artistic freedom without requiring extensive technical knowledge. Tech companies tend to rhapsodize about the democratizing potential of their products, and AI technology may indeed offer huge rewards to the savvy and lucky artists who take maximum advantage of it.

Read: Here’s how AI will come for your job

Yet past experience from social media and streaming music suggests a different progression: Like other technologies that promise digital democratization, generative AI may be better poised to enrich the companies that develop it than to help freelance creatives make a living.

In an ideal world, the elimination of entry-level work would free future writers from having to write “How to Be a Pornstar” in order to pay their rent, allowing true creativity to flourish in its place. At the moment, though, AI seems destined to squeeze the livelihoods of creative professionals who spend decades mastering a craft. Executives in Silicon Valley and Hollywood don’t seem to understand that the cultivation of art also requires the cultivation of artists.</div>
        </div>
        
        <div class="card" onclick="openModal('content-19')">
            <div class="source">The Atlantic</div>
            <div class="title">The Plan That Foretold Trump’s 2025</div>
            <div class="meta">2025-12-29</div>
        </div>
        
        <div id="content-19" style="display:none;">
            <h2>The Plan That Foretold Trump’s 2025</h2>
            <p><strong>The Atlantic | 2025-12-29</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/newsletters/2025/12/project-2025-year-review-trump/685395/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">This is an edition of The Atlantic Daily, a newsletter that guides you through the biggest stories of the day, helps you discover new ideas, and recommends the best in culture. Sign up for it here.

A year ago, no one knew for sure whether Project 2025 would prove to be influential or if it would fall by the wayside, like so many plans in President Donald Trump’s first term. Today, it stands as the single most successful policy initiative of the entire Trump era.

Project 2025, which was convened by the Heritage Foundation during the Trump interregnum, was not just one thing: It was a policy white paper, an implementation plan, a recruitment database, and a worldview, all rolled into one. As I wrote in my book this past spring, the authors sought to create an agenda for the next right-wing president that would allow him to empower the executive branch, sideline Congress, and attack the civil service. The resulting politicized, quasi-monarchical government would enact policies that would move the United States toward a traditionalist Christian society.

In the roughly 11 months since he took office, Trump has closely followed many parts of Project 2025, finally embracing it by name in October. Both Trump and the plan’s architects have benefited: His second administration has been far more effective at achieving its goals than his first, and the thinkers behind Project 2025 have achieved what Paul Dans, one of its leaders, described as “way beyond” his “wildest dreams.”

Project 2025’s biggest victory has been an extraordinary presidential power grab, which has allowed Trump to act in ways that previous presidents have only fantasized about, and to act with fewer restraints. He has laid off tens of thousands of federal employees, sometimes in defiance of laws. More than 315,000 federal employees had left the government by mid-November, according to the Office of Personnel Management. Entire agencies, such as USAID, have been effectively shut down, and the Education Department may be next.

Elsewhere, the administration has slashed environmental regulations, withdrawn from a major international climate agreement, undermined renewable energy, and worked to encourage oil and gas drilling on public land. It has discarded key civil-rights-enforcement methods, dismantled anything that might be construed as DEI, and set the agenda for aggressive immigration policies, not just closing the border to many foreign nationals and deporting unauthorized immigrants but also cracking down on valid-visa holders and seeking to denaturalize citizens.

This is not small-government conservatism—it’s an effort to concentrate federal power and turn it into a political weapon. Long-standing guardrails against presidential interference in the Justice Department have been demolished. The White House has fired line prosecutors, and Trump has illegally appointed his own former personal attorneys to lead U.S. Attorney’s Offices. These prosecutors have brought charges against many of Trump’s political foes, including former FBI Director James Comey, New York Attorney General Letitia James, and Representative LaMonica McIver; others have been placed under investigation. (Judges have thrown out indictments against Comey and James, though the DOJ is appealing those dismissals. McIver, who was indicted in June for allegedly impeding federal agents and interfering with an arrest, denies wrongdoing and has pleaded not guilty.)

The administration has dabbled in impounding funds appropriated by Congress, despite a law barring this. It has also mounted a major assault on the independence of regulatory agencies, as established by Congress; Trump has fired multiple appointees, sometimes in apparent violation of law, but the Supreme Court has allowed him to proceed. Earlier this month, the justices heard arguments in a case that could overturn or severely narrow the 1935 precedent that safeguards agency independence. We already have a glimpse of what a fully politicized regulatory environment might look like: Chairman Brendan Carr, a Project 2025 author, has used his position at the Federal Communications Commission to pressure CBS News and ABC, even trying to get the late-night host Jimmy Kimmel fired earlier this year.

Trump’s presidential power grab will allow his administration to achieve more of Project 2025’s ambitions in the coming year and beyond. All of this has been enabled by a Republican-dominated Congress, which has with few exceptions allowed the president to seize legislative prerogatives, and by the Supreme Court, which has repeatedly allowed Trump to move forward on his expansion of power using the so-called shadow docket.

But Project 2025 has not been a complete success. One key belief of the authors was that Trump’s first administration was undercut by bad appointments and by failures to fill other roles. To that end, Project 2025 created a huge database of potential appointees and offered training courses. Although Trump has managed to find more aides loyal to him than in his first term, his pace of confirmation for top jobs trails the pace of most recent presidents. He has also seen a historic high in nominations withdrawn in the first year of a presidency.

More fundamentally, the Christian nationalism that courses through Project 2025 has been somewhat eclipsed by other priorities. The Trump administration has made few major moves to restrict access to abortion or to enact pronatalist policies, and the conservative Catholic writer Ross Douthat recently argued that Christianity seems to be window dressing in the administration’s policy rather than a real ideological driver of decision making. Big Tech was a notable boogeyman for the authors, who view smartphones and social media as a danger to traditional religious values, but major Silicon Valley figures have become hugely influential in the White House.

For the Heritage Foundation, Project 2025 has been a somewhat Pyrrhic victory. Although its policy ideas are steering the administration, the think tank finds itself on the outside—a product, it seems, of Trump’s displeasure that coverage of Project 2025 complicated his campaign last year. Heritage is also fighting an intramural battle over how to handle the racist and anti-Semitic strains of the right.

Another, larger question looms. For decades, American conservatives have argued for restraints on government, in part out of fear of how progressives have used power to enact their policies. Project 2025 threw that out, embracing right-wing big government. Its unpopular ideas are one reason that Republicans are facing a daunting election environment in 2026 and perhaps 2028. If Project 2025’s authors felt, as Russell Vought once said, that America was “in the late stages of a complete Marxist takeover” before Trump returned to office, they may find the situation even more apocalyptic if a Democrat wins the presidency in 2028—and inherits the sweeping powers they have handed to the White House.

All Hail Dead Week, the Best Week of the Year

Christmas is over and we have arrived at the most wonderful time of the year—nominally still the holidays, but also the opposite of a holiday, a blank space stretching between Christmas and New Year’s Eve when nothing makes sense and time loses its meaning …

In between the end of the old year and the beginning of the new one is this weird little stretch of unmarked time. For most people, this week isn’t even a week off from work, but at the same time it also isn’t a return to the normal rhythm of regular life. Nobody knows what to do with this leftover week, awkwardly stuck to the bottom of the year. I call it “Dead Week,” a time when nothing counts, and when nothing is quite real.

Listen. Here are the 10 best albums of 2025, according to our music critic Spencer Kornhaber.

Read. In 2024, Amanda Parrish Morgan recommended six books to read by the fire.

Rafaela Jinich contributed to this newsletter.

When you buy a book using a link in this newsletter, we receive a commission. Thank you for supporting The Atlantic.</div>
        </div>
        
        <div class="card" onclick="openModal('content-20')">
            <div class="source">The Atlantic</div>
            <div class="title">Photos: The Year in Volcanic Activity</div>
            <div class="meta">2025-12-29</div>
        </div>
        
        <div id="content-20" style="display:none;">
            <h2>Photos: The Year in Volcanic Activity</h2>
            <p><strong>The Atlantic | 2025-12-29</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/photography/2025/12/2025-year-volcanic-activity/685385/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-21')">
            <div class="source">The Atlantic</div>
            <div class="title">Why the Supreme Court Is Giving ICE So Much Power</div>
            <div class="meta">2025-12-29</div>
        </div>
        
        <div id="content-21" style="display:none;">
            <h2>Why the Supreme Court Is Giving ICE So Much Power</h2>
            <p><strong>The Atlantic | 2025-12-29</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/ideas/2025/12/ice-scotus-impunity/685298/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Untold numbers of ICE agents have appeared on America’s streets in recent months, and many of them have committed acts of aggression with seeming impunity. ICE agents have detained suspected illegal immigrants without cause—including U.S. citizens and lawful residents. They have, in effect, kidnapped people, breaking into cars to make arrests. They have used tear gas and pepper spray on nonviolent protesters. They have refused to identify themselves, wearing masks, using unmarked cars, and switching license plates, presumably to avoid detection. They have kept people in detention without access to lawyers. They have questioned people simply for appearing Latino, speaking Spanish, and being in areas believed to be frequented by illegal immigrants.

Many of these tactics are plainly illegal. The Constitution incontestably applies to federal immigration officers: The Fourth Amendment protects against unreasonable searches and seizures and excessive force and requires a warrant to search a private home. The Fifth Amendment guarantees due process and bans self-incrimination. The Sixth Amendment establishes a person’s right to counsel. Why, then, are they getting away with not following the Constitution?

Their impunity traces back to two Supreme Court decisions that put far too much faith in ICE’s commitment to respecting people’s constitutional rights. As a result of these cases, people whose rights are violated by ICE agents have little to no recourse. Contrast that with the rules for police officers. If a police officer kicks down your door and searches your home without a warrant, questions you without a Miranda warning, or illegally arrests you, a provision known as the exclusionary rule may prevent the evidence gathered through those tactics from being admitted in your prosecution. And if you happen to be acquitted, you can sue for damages. None of that is true when it comes to ICE.

The first of these two cases is a 1984 decision, INS v. Lopez-Mendoza, that untethered ICE from the exclusionary rule. In a 5–4 opinion, Justice Sandra Day O’Connor rejected the exclusionary rule for immigration courts, favoring, instead, “a deliberately simple deportation hearing system.” In a typical criminal case, the exclusionary rule is designed to deter police misconduct—the idea being that the police will avoid such conduct if it risks undermining a conviction. But for ICE, the Court decided, such deterrence is not necessary. Unless ICE conduct amounts to an “egregious” violation of the Fourth Amendment, the evidence that agents gather even through illegal means can be used in immigration courts. Key to the Court’s decision was a presumption that Fourth Amendment violations by ICE officers were not “widespread” and that the Immigration and Naturalization Service “has already taken sensible and reasonable steps to deter Fourth Amendment violations by its officers.” Such assumptions may not have been reasonable then; they are certainly not reasonable now.

A second Court decision appears to have eliminated, or at least seriously limited, the possibility of lawsuits for damages after individuals are unlawfully detained, searched, or experience excessive force at the hands of ICE. When the police engage in misconduct, the victim can sue the responsible officers for damages. Again, not so for ICE. In the 2022 decision Egbert v. Boule, Justice Clarence Thomas, writing for the majority, denied the rights of plaintiffs to sue Border Patrol agents for excessive use of force in the name of “national security.” There is every reason to believe that the Supreme Court would extend the rationale in Boule to shield ICE from liability as well. The Court would effectively be greenlighting ICE’s abusive tactics and insulating agents from damages when they are, in fact, no different from any state or city police officer who violates a person’s constitutional rights. As in INS v. Lopez-Mendoza, the rationale in Boule relies on the agency’s purported ability to self-regulate; after all, Thomas suggested, Border Patrol “must investigate ‘alleged violations’ and accept grievances.” Can anyone count on such care to come from Border Patrol under this administration? Again, the faith in these institutions to self-regulate seems tragically misplaced.

The remaining options for someone mistreated by ICE are inadequate, to say the least. An individual could file a lawsuit under the Federal Torts Claims Act against federal officers, but that law has its shortcomings: A person must submit a detailed claim to the government and wait for a response before they can go to court. That process can take years and years. An individual could also file a complaint with the DHS Office of Inspector General or the Office of Civil Rights and Civil Liberties, which would theoretically launch an investigation, but in this administration, the chances of redress for misconduct are slim to none. Nothing drives the point home more than the case of a CBP commander, Gregory Bovino. U.S. District Judge Sara Ellis found that he had lied to the court about whether he had used excessive force against protesters in Chicago. Was he dismissed or disciplined? Neither; he went on to lead another immigration sweep, this time in New Orleans.

Read: Every state is a border patrol state

Then there are the practical problems with contesting ICE misconduct. Where in the United States is the immigrant? In which detention facility? Do they have a lawyer? Worse, what if they have already been deported through a process known as expedited removal? Expedited removal generally involves a determination by a low-level immigration officer who, in many cases during a single interview, determines that the noncitizen arrived in the U.S. without proper documents and therefore cannot prove that he or she has been physically present in the U.S. for two years. (Exceptions are made only for people who have a credible fear of persecution or torture, or who intend to apply for asylum—exceptions that have been severely limited under this administration.) Although expedited removal used to apply only to noncitizens within 100 miles of the border, Trump’s Department of Homeland Security has expanded the policy to apply to any unlawful noncitizen anywhere in the country who cannot prove two years of residency, giving them no time to secure counsel or gather evidence, no right to appeal, and surely no meaningful due process.

Even for those who manage to get before an immigration judge, the process is formidable. ICE attorneys have been systematically asking immigration judges to dismiss proceedings in order to strip individuals of even the limited protections those hearings afford. Judge Jia Cobb, a federal judge in Washington, D.C., noted in a recent decision that people have been arrested immediately following dismissals, subjected to expedited removal, and shortly removed. These tactics, combined with the administration’s expanded policy of mandatory detention—meaning the immigrant is not entitled to bail—have turned immigration courts into what the former chief counsel for Joe Biden’s Citizenship and Immigration Services characterized as a “deportation pipeline.”

Much of what ICE is doing is not remotely constitutional. The Court decisions that laid the groundwork for the agency’s lawlessness no longer stand up to basic scrutiny. As Justice O’Connor said in INS v. Lopez-Mendoza, “our conclusions concerning the exclusionary rule’s value might change, if there developed good reason to believe that Fourth Amendment violations by INS officers were widespread.” There’s more than good reason; there’s every reason.</div>
        </div>
        
        <div class="card" onclick="openModal('content-22')">
            <div class="source">The Atlantic</div>
            <div class="title">Mary Todd Lincoln, Taken Out of Context</div>
            <div class="meta">2025-12-29</div>
        </div>
        
        <div id="content-22" style="display:none;">
            <h2>Mary Todd Lincoln, Taken Out of Context</h2>
            <p><strong>The Atlantic | 2025-12-29</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/ideas/2025/12/oh-mary-theater-trump/685446/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">By now, you will be used to the feminist practice of finding a historical woman and rescuing her from the clutches of evil biographers who have done her dirty. What if Marie Antoinette or Typhoid Mary were a more rounded figure—more constrained by the expectations of her time, perhaps, or a victim of her circumstances and upbringing?

That is not the approach that the playwright Cole Escola has taken in Oh, Mary!, which is currently playing on Broadway and has just opened in London. Escola’s question about Mary Todd Lincoln, wife and widow of America’s 16th president, is this: What if she were an absolute monster? The idea for the show came from an email Escola sent to themselves in 2009, which read: “Write a play (maybe musical?) about Mary Todd and Abraham Lincoln in which it comes out being a good thing that Abe Lincoln dies.”

To fulfill that brief, the 39-year-old playwright has taken the Mary of the historical record—a laudanum user, prone to wild mood swings and shopping sprees, eventually confined to an asylum by her own son—and made her worse. This Mary drinks paint thinner and pushes her companion, Louisa, down the stairs. Above all, she desperately wants to be a cabaret star, and believes that Abraham has thwarted her dream. Fatally, he reacts to her constant complaints by hiring a handsome actor—whose identity becomes important later in the plot—to give her lessons for the “legitimate theater.”

Read: What the U.S. could learn from an Irish theater

Having already seen the show on Broadway, I was curious to know how such a quintessentially American story would land in Britain. (No one here could pick Mary Todd Lincoln out of a first-lady lineup, even though this is the second play about her to open in London in 2025.) How does a show whose satirical power comes from cutting against received wisdom deal with the audience having no idea what that received wisdom is? The answer is: Training wheels and a reliance on physical comedy help, up to a point.

In London, the play begins with a straightforward exposition dump: A preshow voiceover establishes Mary Todd Lincoln as the wife of President Abraham Lincoln, who was assassinated by the actor John Wilkes Booth. Oh, Mary!, shorn of its political resonance, falls squarely into an established populist British stage tradition: pantomime, in which unwitting 7-year-olds are corralled into a theater at Christmastime to watch well-worn favorites such as Aladdin or Dick Whittington and His Cat, a folktale in which a young man (always played by a woman) leaves home to make his fortune in London. Pantomime leans heavily on popular songs, risqué jokes, and melodrama, just like Oh, Mary!

In addition to writing the play, Escola originated the lead role, playing Mary as a 19th-century Veruca Salt, all wobbling curls and petulantly folded arms. “Mary is just me,” Escola once told NPR. “It’s all based on me and my feelings, and all of my characters are some aspect of me that I’m ashamed of or curious about.” Since then, the Marys have tended to be either queer actors or gay icons, underlining the show’s immersion in gay culture. (Mary repeatedly addresses a portrait of George Washington as “Mother,” and this Abraham Lincoln is gay, too.) The London Mary is played by the nonbinary actor Mason Alexander Park, best known for portraying Ariel in Jamie Lloyd’s truly cursed production of The Tempest.

I saw the play on Broadway with the drag queen Jinkx Monsoon, who followed Escola and others, and was herself followed by Jane Krakowski. The role does not call for subtlety. “I have to imagine that somewhere along the line someone had to have told you, ‘You’re a little too big,’” Monsoon told Krakowski in September. “I’ve been told that a billion times.”

When I saw Monsoon’s (yes, very big) performance, I did think, snobbily: Oh, look, the Americans have discovered panto. I wasn’t alone. The London reviews have been positive, but the two harshest ones described the show as “sophomoric” and “farce at its broadest” (The Guardian) and “a bit … ’70s? A little bit Airplane!, a little bit Benny Hill, maybe even a touch of Mr Bean” (Time Out). In the British context, these reviewers implied, Oh, Mary!’s humor reads as dated rather than groundbreaking. That’s largely because of the pantomime tradition. I was brought up on this genre, which also usually features a dame (always played by a man: In a production of Aladdin, Ian McKellen once gave a fantastic Widow Twankey) and volleys of double entendres for parents. The title character in Dick Whittington has a cat mostly so all the other characters can remark on his “lovely pussy.”

This is the energy that Escola has brought to Oh, Mary! Todd Lincoln, under her prim crinoline, is wearing red-and-white-striped bloomers, which is very panto. And just like a panto, the staging is deliberately lo-fi: two static sets, a wheeled-on theater box, and a bit of front-of-curtain business. On Broadway, The New York Times described it as having “the cheesy naturalism of community theater.”

What Escola has built on this foundation, however, is truly unhinged. Do you remember the end of Inglourious Basterds, when Quentin Tarantino kills off the entire Nazi Party in an exploding movie theater? Yeah, about that unhinged. Mary might be awful, but Escola makes her pathetic too, with her terrible loneliness and her deluded belief that she could have been a star. “I don’t even want to be alive,” she tells her acting teacher at the start of their first lesson. More than anything else, she is bored—a default condition for humanity before smartphones and reliable Wi-Fi. History isn’t just battles and bowers; it’s privileged people in gilded rooms waiting for death or the invention of streaming services, whichever comes first. For aristocratic women, this boredom was particularly acute, because their enforced inactivity was a status symbol. The Mitford sisters, growing up in rural Oxfordshire in the 1920s, found their lives so tedious that they invented, as one of them put it, “a contest to see who could best stand being pinched really hard.” This sounds exactly like something Escola’s Mary would inflict on her companion, Louisa.

Earlier this year, Oh, Mary! was a finalist for the Pulitzer Prize for Drama, an award that  in 2016 went to Lin-Manuel Miranda’s Hamilton. As it happens, I rewatched Hamilton not long ago, and its earnest paeans to diversity (“Immigrants, we get the job done”) now feel like the last gasp of the Obama era.

When Hamilton first came to Britain, I wrote that its blend of rap, classical music, and Gilbert and Sullivan operettas showed that it “speaks all the cultural languages of America, and it echoes Obama’s ability to change cadences depending on his audience.” Added to that, by offering cheap tickets in a daily street lottery alongside the usual sky-high prices of Broadway, “Miranda created a fan base that mirrors the ‘Obama coalition’ of Democrat voters: college-educated coastal liberals and mid-to-low-income minorities.” Hamilton might have been great entertainment, but it also took seriously the idea of educating America about its history, in a spirit now continued by the popular Substack historian Heather Cox Richardson.

Read: Watching Hamilton is like opening a time capsule

Like Hamilton, Oh, Mary! uses color-conscious casting, reframing white historical figures by having nonwhite actors play them. And like Hamilton, it is an improbable box-office smash: It became the first production to gross more than $1 million a week at the Lyceum Theater in New York. But otherwise, the two plays could not be more different. Instead of Obama-era earnestness, Oh, Mary! is steeped in the signature moods of the Trump era: pure camp, twisted humor, and lol nothing matters nihilism. (Think: Donald Trump dancing to “YMCA,” or the casual cruelty of all those deportation videos.) Escola did “less than no research” into Mary Todd Lincoln, to avoid the temptation of writing in-jokes. “I wanted to have the same knowledge that the audience had,” Escola told Seth Meyers. “I didn’t want to do research and then be making jokes about, like, ‘Well, that’ll get a laugh ’cause that’s where she was born.’” This artistic decision worked out well for me, a person who had no idea where Mary Todd Lincoln was born until I looked it up for this article.

The audience also learns precisely nothing about Mary’s divided loyalties—she was born in Kentucky, and several of her half-brothers fought for the Confederacy. Her real-life grief over the death of her sons Eddie and Willie is completely absent; Mary assures her acting teacher that “I never go near the children.” Even the Civil War barely gets a look-in. When Abraham complains about fighting with the South, Mary growls, “The South of what?!” His announcement of the end of the war is included only to set up a contrast with Mary’s activities that afternoon—discovering that Louisa “wants to rub ice cream on her pussy!”

In its absolute refusal to take history seriously, Oh, Mary! is basically the anti-Hamilton. But then, we are living through the mirror image of the Obama era right now. Escola’s Mary is a monster, but also a ham, a narcissist, and a born entertainer—and the audience ends up glued to her every move. I mean, you could suggest a parallel with contemporary America there. Or you could just enjoy the wigs and the gags and the spotted bloomers.</div>
        </div>
        
        <div class="card" onclick="openModal('content-23')">
            <div class="source">The Atlantic</div>
            <div class="title">The Sad Dads of Hollywood</div>
            <div class="meta">2025-12-28</div>
        </div>
        
        <div id="content-23" style="display:none;">
            <h2>The Sad Dads of Hollywood</h2>
            <p><strong>The Atlantic | 2025-12-28</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/culture/2025/12/hamnet-jay-kelly-sentimental-value-dad-movies/685464/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">If you went to the movies this fall, you probably met him: the Sad Art Dad. You’ll have known him by his miserableness; despite the flash of the cameras and the cheers of the groundlings, he’s most often found moping alone. His vocation may vary—movie star (in Jay Kelly), art-house director (Sentimental Value), blockbuster Tudor playwright (Hamnet)—but his problem tends to be the same. He has chosen great art over good parenting, utterly failing as a father, and he knows it. There’s something delicious about his cocktail of self-pity and self-loathing, which can arouse both the viewer’s repulsion and compassion. It may not be much fun to be a Sad Art Dad, but it’s certainly fun to watch one.

The distant and distracted patriarch, although abundant on-screen in 2025, is not a novel invention. Yet most movie dads are more likely to be found balancing stellar careers and model parenting (lawyer-dad in To Kill A Mockingbird; Mob-dad in the Godfather films) than exhibiting—let alone acknowledging—their fatherly flaws. Sometimes prioritizing professional ambitions is even depicted as admirable: In Interstellar, Matthew McConaughey plays an astronaut who abandons his kids for a decades-long space mission, but only in order to save humanity. The character might beat himself up for it, but the viewer understands that it’s a pretty good excuse, as far as they go.

What’s different about this new cinematic crop of dads is their culpability. They each choose themselves over their kids, prioritizing creative fulfillment. George Clooney’s titular A-lister in Noah Baumbach’s Jay Kelly admits as much when trying to explain his years-long absence to his now-adult daughter: “I wanted something very badly,” he says, “and I thought if I took my eye off of it, I couldn’t have it.” At least Jay is trying to apologize. When Gustav (played by Stellan Skarsgård), the ornery patriarch of Joachim Trier’s Sentimental Value, is accused by his daughter Nora (Renate Reinsve) of never having watched her perform, he defends himself by saying that he doesn’t like theater. Meanwhile, in Chloé Zhao’s Hamnet, William Shakespeare (Paul Mescal) likes the theater a bit too much. Although he’s a much more affectionate parent than Jay or Gustav, the Bard’s absence—he gallops away from plaguey Stratford-upon-Avon to the Elizabethan West End—has calamitous consequences for his kids.

Read: Parenting is the least of her worries

But these films are not pat condemnations of the flawed fathers they depict; they illustrate, sometimes with seeming ambivalence, the consequences of such self-absorption. Tellingly, Sentimental Value’s most tender scene doesn’t feature Gustav at all. Instead, it’s a quiet moment between Nora and her sister, Agnes (Inga Ibsdotter Lilleaas). Having finally read Gustav’s latest screenplay, and found within it surprising echoes of the darkest periods of her own life, an emotional Nora sits on her bedroom floor beside her sister. The script is so uncannily accurate, Agnes notes, that it’s as though their father had been there for Nora’s suffering. “Well, he wasn’t,” Nora replies. “You were.”

It’s a gorgeous demonstration of familial love that also lays bare the true cost of the Sad Art Dad’s narcissism. He has made himself redundant; his children have learned, painfully, to cope without him. The same specter of redundancy haunts both Hamnet and Jay Kelly. When Shakespeare arrives home after tragedy strikes, he finds that he’s too late to help his family. He then announces his intent to return to London—and his wife, Agnes (Jessie Buckley), slaps him. Jay’s daughter Jess (Riley Keough) tells her father with brutal candor not to worry about her: “I’m gonna have a good life, just not with you.” A memorable shot in Sentimental Value shows Gustav standing alone on a Normandy beach, his hulking, black-suited figure marooned against miles of sand and scudding lilac clouds. The price of failed fatherhood, it seems, is loneliness.

Does the Sad Art Dad regret his choices? Is making great art—which, in these films, has a capacious, allegorical quality—worth ruining your relationship with your kids? Each of these movies tries to convince us, with varying degrees of success, that prioritizing your artistic endeavors offers emotional compensation. Hamnet, for instance, ends with a delicately choreographed moment of parental connection. Agnes, standing in the audience at the Globe Theatre, reaches out to grasp the hand of the young actor playing Hamlet; in the film’s version of the play, the tragic boy-hero is named for her dead son. Moving though it is, the scene’s mawkishness renders it unpersuasive: Agnes’s abrupt pivot from bitterly resenting her husband to forgiving him strains credulity. A play, even a Shakespeare play, is no substitute for a child.

Read: Two different ways of understanding fatherhood

Jay Kelly also considers the case for putting your craft before your kids, but only half-heartedly. It toys with the idea that the magic of the movies at least partially justifies Jay’s parental negligence; the film ends on a long close-up of Jay’s face as he watches a retrospective reel of his career, visibly moved. But the film ultimately gives up trying to convince the audience that the art was worth the human cost. In its closing line, Jay asks, fruitlessly, for a chance to live his life over again. Measured against the wreckage of his relationships, Hollywood’s comforts prove chilly even to the movie star.

Sentimental Value’s vision of film as a doorway to empathy and repair is by far the most compelling. Gustav’s script may dwindle beside the compassion his daughters offer each other, yet his transformation of Nora’s pain into art is still an act of love. As Agnes says to her sister: “I think he wrote it for you.” Gustav’s work, we realize, is more empathetic, more attentive to other people, than he is. His daughters might find this to be a bitter-tasting irony, but the consolation is real—particularly for an actor like Nora, who eventually finds creative catharsis playing the part Gustav based on her.

Oddly, despite his inadequacies, the Sad Art Dad suggests a promising cultural shift on-screen. To pay attention to the idea of flawed fatherhood, after all, is to think seriously about what constitutes its opposite, the good dad. Laura Dern’s unsentimental divorce lawyer says it well in Baumbach’s Marriage Story, which is also about depressed dads: “The idea of a good father was only invented, like, 30 years ago.” As such, it’s striking to find three films out at the same time that are gnawed by such similar anxieties. Perhaps Joachim Trier put it best: “Tenderness is the new punk.”</div>
        </div>
        
        <div class="card" onclick="openModal('content-24')">
            <div class="source">Slashdot</div>
            <div class="title">22 Million Affected By Aflac Data Breach</div>
            <div class="meta">2025-12-30</div>
        </div>
        
        <div id="content-24" style="display:none;">
            <h2>22 Million Affected By Aflac Data Breach</h2>
            <p><strong>Slashdot | 2025-12-30</strong></p>
            <a class="original-link" href="https://it.slashdot.org/story/25/12/30/0645220/22-million-affected-by-aflac-data-breach?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">I know if I break my arm aflac will come give me a check, but will it give me a check when it breaks my privacy?

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.</div>
        </div>
        
        <div class="card" onclick="openModal('content-25')">
            <div class="source">Slashdot</div>
            <div class="title">Meta Just Bought Manus, an AI Startup Everyone Has Been Talking About</div>
            <div class="meta">2025-12-30</div>
        </div>
        
        <div id="content-25" style="display:none;">
            <h2>Meta Just Bought Manus, an AI Startup Everyone Has Been Talking About</h2>
            <p><strong>Slashdot | 2025-12-30</strong></p>
            <a class="original-link" href="https://meta.slashdot.org/story/25/12/30/0640250/meta-just-bought-manus-an-ai-startup-everyone-has-been-talking-about?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Catch up on stories from the past week (and beyond) at the Slashdot story archive

All big companies are shopping around. And some are also buying every competition before it gets big.

I&#39;ve never heard anybody talking about this anus.

Apparently it is all about shoveling it downstream to the &quot;AI investor&quot; community.

A company named after a film considered one of the worst ever made?  I hadn&#39;t heard of them before today, so evidently not everyone is talking about them.

In particular here, what you should have written is &quot;almost nobody&quot;....

Widely known in narrow circles, as we used to say under the Communist yoke.

You forgot to reword it to match Rick&#39;s song.

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.</div>
        </div>
        
        <div class="card" onclick="openModal('content-26')">
            <div class="source">Slashdot</div>
            <div class="title">PhDs Can't Find Work as Boston's Biotech Engine Sputters</div>
            <div class="meta">2025-12-30</div>
        </div>
        
        <div id="content-26" style="display:none;">
            <h2>PhDs Can't Find Work as Boston's Biotech Engine Sputters</h2>
            <p><strong>Slashdot | 2025-12-30</strong></p>
            <a class="original-link" href="https://science.slashdot.org/story/25/12/29/2357222/phds-cant-find-work-as-bostons-biotech-engine-sputters?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Slashdot is powered by your submissions, so send in your scoop

For sickness and diseases.  Excellent governance!  Let&#39;s kill scientific research, hand away the future, and get more of us killed.

But why do you need to spend money on &quot;research&quot; when you can pray for free?

Indulgences, like the rest of the practices of the catholic sect, are a heresy. Remember, Jeebus threw all the merchants, including the afterlife insurance salesmen, out of the temple.

Hot, fervent hail marys, on the other hand, backed by a firm belief will work miracles, Allah willing.

That was Muhammad, and the only reason it is disliked among some sects is that it wasn&#39;t with an altar boy.

China is recruiting biotech talent from the US? Like they&#39;re saying go work in China and save up money? I wouldn&#39;t recommend anyone do it unless the offer was so great that you&#39;d have enough money to outright buy a US home at the end of it. As in, be able to save like $700k within 7 years (which in 7 years should get you a &quot;todays&quot; $500k home in the US). That means you&#39;d have to get paid around like $180k (after China taxes if they make you pay that). I blindly assume China comfortable expat living expenses are like 80k.

As for &quot;you&#39;re helping China advance&quot; .. well don&#39;t on any circumstances tell them how to do anything that would give them a national security advantage .. but if it&#39;s something like a rare disease or cancer cure that all humanity could benefit from and your own country isn&#39;t offering you shit then why not. When you get back you can always make that cure in the US.

If the downturn continues, you will be able to. Provided the Fed does not increase money supply one more time, in the name of QE, to keep real estate prices sky high.

A continued downturn poses risks for a region where workers will put up with sky-high real-estate costs if they can land high-paying jobs. That means people working very hard in life, earning PhDs, to land high-paying jobs are forking a huge chunk of that pay to the rent seeking real-estate owners. High real-estate prices are a barrier to growth. If a large chunk of the cost to setup a business, directly and indirectly, goes towards real estate, businesses and people will try to m

A continued downturn poses risks for a region where workers will put up with sky-high real-estate costs if they can land high-paying jobs.

That means people working very hard in life, earning PhDs, to land high-paying jobs are forking a huge chunk of that pay to the rent seeking real-estate owners. High real-estate prices are a barrier to growth. If a large chunk of the cost to setup a business, directly and indirectly, goes towards real estate, businesses and people will try to m

Ah, human protein, the cornerstone of every nutritious breakfast! What kind of protein?

Might have something to do with companies relocating.

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.</div>
        </div>
        
        <div class="card" onclick="openModal('content-27')">
            <div class="source">Slashdot</div>
            <div class="title">Researchers Make 'Neuromorphic' Artificial Skin For Robots</div>
            <div class="meta">2025-12-30</div>
        </div>
        
        <div id="content-27" style="display:none;">
            <h2>Researchers Make 'Neuromorphic' Artificial Skin For Robots</h2>
            <p><strong>Slashdot | 2025-12-30</strong></p>
            <a class="original-link" href="https://hardware.slashdot.org/story/25/12/29/2344207/researchers-make-neuromorphic-artificial-skin-for-robots?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Catch up on stories from the past week (and beyond) at the Slashdot story archive

call it an T-1000
That will be able to time travel [fandom.com].In order for this time travel to occur, the subject must be a living organism (or must be surrounded by living tissue) in order to generate the bioelectric field needed for the Time Displacement Equipment [fandom.com] to operate.
Just great. /s

That will be able to time travel [fandom.com].

In order for this time travel to occur, the subject must be a living organism (or must be surrounded by living tissue) in order to generate the bioelectric field needed for the Time Displacement Equipment [fandom.com] to operate.
Just great. /s

In order for this time travel to occur, the subject must be a living organism (or must be surrounded by living tissue) in order to generate the bioelectric field needed for the Time Displacement Equipment [fandom.com] to operate.

Slang will be &#39;skin jobs&#39;, and there will be a guy in a flying police car hunting the renegade units.

The skin is designed to be assembled from a collection of segments that can snap together using magnetic interlocks.I saw that in Ex Machina

The skin is designed to be assembled from a collection of segments that can snap together using magnetic interlocks.

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.</div>
        </div>
        
        <div class="card" onclick="openModal('content-28')">
            <div class="source">Slashdot</div>
            <div class="title">Russian Enthusiasts Planning DIY DDR5 Memory Amidst Worldwide Shortage</div>
            <div class="meta">2025-12-30</div>
        </div>
        
        <div id="content-28" style="display:none;">
            <h2>Russian Enthusiasts Planning DIY DDR5 Memory Amidst Worldwide Shortage</h2>
            <p><strong>Slashdot | 2025-12-30</strong></p>
            <a class="original-link" href="https://hardware.slashdot.org/story/25/12/29/2336254/russian-enthusiasts-planning-diy-ddr5-memory-amidst-worldwide-shortage?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Please create an account to participate in the Slashdot moderation system

Lets wait 3 months more and see if that statement still holds true. Business analysts expect RAM prices to increase throughout 2026, stabilize at 2026 price level throughout 2027 and increase in price yet again in 2028.

&quot;You will own nothing and be happy about it&quot;, that is future planned for you and the rest of us slobs in the trenches.

Seriously, where is a good Robespierre&#39;s when society needs one...

The crazy thing is that the price increases have already made Appleâ(TM)s infamously ludicrous upgrade pricing seem reasonable.  Apple want Â£400 for 32GB.  A couple of months ago, that was 4 times over the going rate.  Now itâ(TM)s pretty much normal.  The cheepest DDR5 6000 on newegg is Â£330, and higher bandwidth stuff costs of the order of Â£5-600.  (And thatâ(TM)s ignoring that Appleâ(TM)s on chip RAM is anywhere between 50% faster and 300% faster th

And, do you really mean pounds, or is that also an artifact of writing this on an Apple(TM) device?

Because youâ(TM)re a nerd probably.  That said, the article seems to motivate things rather poorly.

I donâ(TM)t get how anyone would ever expect this to be cheep though.  The reason RAM is expensive is because the production capacity for chips is being used to produce GPU RAM for AI data centres, not because thereâ(TM)s some disconnect between chip prices and DIMM prices.  Buying the chips is going to be just as expensive, because the chips, and production capacity are needed elsewhere.  What

I&#39;m more upset because the &quot;dept.&quot; field was apparently populated by someone who doesn&#39;t know that it&#39;s actually supposed to be &quot;desperate-times-call-for-drastic-measures.&quot;

the problem isn&#39;t that people aren&#39;t assembling ddr5 -- the problem is the dram isn&#39;t available.

Pretty sure I&#39;ve seen this story already. Someone commented about alternate memory packaging designs completely missing it is the actual chips that are in short supply.

This came out of The Socials. It&#39;s just for clicks.

It&#39;s worth it to him to assemble a module at the same cost as retail, because the YouTube Partner program pays him to take a video of it.

Yeah, this doesn&#39;t really help unless a bunch of DDR5 DRAM chips fall off of the truck somewhere. Probably one headed to an OpenAI data center being built somewhere that doesn&#39;t have power yet.

Building your own module still requires chips! This is just stupid, adding unneeded complexity of building your own when it doesn&#39;t solve the initial issue.

This is Russia we&#39;re talking about. A slightly bigger problem in obtaining the modules thanks to their invasion causing sanctions.

The cost &quot;savings&quot; aren&#39;t there either - the actual cost of the DIY modules rivals that of actual DDR5 RAM kits.

In the end all the Russians do with that precious RAM is bolt it onto a drone with C4 and send it into residential areas in neighboring countries. They don&#39;t care.

Pay enough and someone somewhere will make the dram chips for the right price.

The reason memory is expensive is because there&#39;s only a certain amount of manufacturing capacity for the chips, not the fucking circuit boards. If it were the circuit boards, we could spin up factories in days to make new DIMMs.

Come on editors, do better. This article is either by a troll or by complete morons. Either way it doesn&#39;t deserve a place here.

Assuming by the downvotes you must be both 100% correct and directly countering the propaganda. The internet is absolutely flooded with pro-Russia and pro-China apologetic posts these last weeks: here, on X, HN, reddit - it&#39;s everywhere I look and it&#39;s really obvious. Anything countering it is immediately moderated and removed, but these bots seem to have complete freedom.

Yes, my first thought exactly. This &quot;story&quot; is without any insight whatsoever.

The price-hike is NOT for the PCBs. It is for the memory chips. What they are doing makes absolutely no sense except very temporarily. It is in no way a solution for the problem.

... if the Russians were weaving their own magnetic core memory.

We&#39;ve buried all the silicon in the tulip fields.

Still, you can find SK Hynix and Samsung chips across Chinese marketplaces if you search for the correct part number, as shown in the attached screenshots.Some of that is probably genuine.  But there&#39;s also a high likelihood that you are not getting the genuine article, and are instead getting 1) rejects from genuine production, 2) lower-tier memory that&#39;s being passed off as higher tier, or 3) outright counterfeits.

Still, you can find SK Hynix and Samsung chips across Chinese marketplaces if you search for the correct part number, as shown in the attached screenshots.

Some of that is probably genuine.  But there&#39;s also a high likelihood that you are not getting the genuine article, and are instead getting 1) rejects from genuine production, 2) lower-tier memory that&#39;s being passed off as higher tier, or 3) outright counterfeits.

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.</div>
        </div>
        
        <div class="card" onclick="openModal('content-29')">
            <div class="source">Slashdot</div>
            <div class="title">Fedora Continued At The Forefront Of Upstream Linux Innovations In 2025</div>
            <div class="meta">2025-12-30</div>
        </div>
        
        <div id="content-29" style="display:none;">
            <h2>Fedora Continued At The Forefront Of Upstream Linux Innovations In 2025</h2>
            <p><strong>Slashdot | 2025-12-30</strong></p>
            <a class="original-link" href="https://linux.slashdot.org/story/25/12/29/2330252/fedora-continued-at-the-forefront-of-upstream-linux-innovations-in-2025?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The word has been so abused that I become suspicious every time I hear it.

Indeed. And when the &quot;innovation&quot; is &quot;Weyland on Gnome&quot;. Seriously, I do not use either and I do not plan to. I just want my systems to work.

That&#39;s an innovation in almost exactly the way that crapping on the office floor is.

They do and it&#39;s well known, as well as being the beach head to influence freedesktop.org

IBM pioneered out-of-order execution, microcoded CPUs, RISC architectures, hardware-independent bytecode, and all sorts of cool stuff.  They&#39;re a sad shadow of their former glory now.

Seriously? Gnome does not give you a choice of focus-follows-mouse? What backward defective wannabe-level crap is that piece of software? Now I will look even less at it than I had planned (which was &quot;never&quot;).

Any sane Window-Manager just gives you a choice. My fvwm has now been configured for focus-follows-mouse for something like 35 years and I had one (!) easy configuration change in all that time when fvwm2 came out. And that is it. This thing needs to work as I want it to and do so long term. Nothing el

Of course it gives you that option. Just activate it in Gnome Tweaks. You have the choice between:

Click to FocusFocus on HoverFocus Follows Mouse

What pisses me off is that the entire justification for wasting 15 years to develop a &quot;replacement&quot; for X11 ended up being obsoleted by technologies that could easily have been foreseen in 2010. cgroups in Linux means every application can be given its own authentication token for the X server, allowing X clients to be given application-by-application security. No need to send everything to everything any more. And full backward compatibility is possible. All that&#39;s needed is for the Xorg team to implement the protocol. ...which they won&#39;t do because it&#39;d be admitting that the entire last 15 years producing a slower, less efficient, display system with fewer features and some really boneheaded limitations, and making the rest of the community write awkward kludge-ridden desktops around it was a complete waste of time and money that could have been spent on (1) the three months needed to implement security and (2) fixing bugs and bringing other improvements to Xorg.

RedHat&#39;s &quot;contributions&quot; over the last 20 years:  Making XFS the default rather than ext4, removing Btrfs, introducing Systemd, PulseAudio, PipeWire, DBus, Wayland, Podman, corporate telemetry reporting, dropping 32-bit and fbcon. Aka, all the annoying shit we don&#39;t like that makes Linux into an incompatible, monolithic, &quot;opinionated&quot;, corporatized operating system. And let&#39;s not forget how they closed their source code.

Well before IBM acquired them, RedHat has been slowly corrupting and subverting the entire Linux ecosystem to serve its own corporate interests. Because they&#39;re the largest player, they effectively force everyone else to follow suit, or face not being compatible.

I think you&#39;re going to get your way, but it&#39;s going to be the undoing of yourself and your employer.

Spoken like someone with a conflict of interest and a strong delusion about how much public good will their employer has left to burn through before becoming themselves irrelevant.

In reality, users moved away from Fedora based distros and now Ubuntu based distros (Ubuntu and Mint) have the best chance to become that mainstream default

I&#39;ve spent the past year zeroing in on Debian.

I use several distros both professionally and personally. SUSE, Rocky, Ubuntu, Fedora, openSuse...

Each is it&#39;s own fragmented fork down various roads I don&#39;t care to travel.

I had been leaning towards Ubuntu and LTSC as The one. But Ubuntu has been making increasingly poor decisions lately. It also seems so much more logical to support the upstream, Debian, than the Ubuntu fork.

Debian 13(Trixie) is out now. It seems just fine and I hope that it will streamline an

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.</div>
        </div>
        
        <div class="card" onclick="openModal('content-30')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">Which Cartoon Short Introduced Mickey Mouse?</div>
            <div class="meta">2025-12-30</div>
        </div>
        
        <div id="content-30" style="display:none;">
            <h2>Which Cartoon Short Introduced Mickey Mouse?</h2>
            <p><strong>News and Politics - Slate Magazine | 2025-12-30</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2025/12/trivia-quiz-daily-slate-culture-shakespeare-disney-sports.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Please enable Javascript in your browser to view Slate interactives.

Which Kind of Person Is the Subject of a Hagiography?

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-31')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">Brett Kavanaugh Is Trying to Walk Back “Kavanaugh Stops.” Too Late.</div>
            <div class="meta">2025-12-30</div>
        </div>
        
        <div id="content-31" style="display:none;">
            <h2>Brett Kavanaugh Is Trying to Walk Back “Kavanaugh Stops.” Too Late.</h2>
            <p><strong>News and Politics - Slate Magazine | 2025-12-30</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2025/12/brett-kavanaugh-stops-immigration-racial-profiling-ice.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Sign up for the Slatest to get the most insightful analysis, criticism, and advice out there, delivered to your inbox daily.

Justice Brett Kavanaugh does not seem happy that his name has become synonymous with racist immigration enforcement. In September, the justice wrote that Hispanic residents’ “apparent ethnicity” could be a “relevant factor” in federal agents’ decision to stop them and demand proof of citizenship. Immigration and Customs Enforcement and Customs and Border Protection promptly seized upon his opinion as a license to stop any Hispanic person on the basis of race—often with excessive, even sadistic force—and detain them until they proved their lawful presence. Law professor Anil Kalhan termed these encounters “Kavanaugh stops,” and the name swiftly caught on as evidence mounted that they had become standard practice across the country. Lawyers also provided courts with evidence that Kavanaugh had sanitized the reality of this practice to the point of fiction. The justice claimed that these were “brief investigative stops” and that any lawful resident would be “promptly” released. In truth, federal agents brutalized, kidnapped, and tormented people—including many U.S. citizens—simply because of their ethnicity, even after they asserted legal status.

Now it appears that Kavanaugh has some regrets. Last Tuesday, the justice backtracked from his previous position without quite acknowledging the retreat. He did so in a concurrence to the Supreme Court’s decision to block President Donald Trump’s deployment of the National Guard—a case that does not even directly concern “Kavanaugh stops.” In a footnote, he declared that race and ethnicity could not be “considerations” when officers make “immigration stops or arrests.” That directly conflicts with his earlier assertion that officers can use race and ethnicity as a “factor” when deciding whom to detain. The two positions cannot be reconciled. Yet Kavanaugh did not admit that he had changed his position; he simply pretended that the law in this area was “clear,” when he himself muddied it just months earlier.

On this week’s episode of Amicus, co-hosts Dahlia Lithwick and Mark Joseph Stern discussed this strange, tacit walk-back.

Dahlia Lithwick: It’s the icing on top of the Christmas cake that Brett Kavanaugh, in an unrelated discussion, gave himself the gift of forgiveness for his notorious “Kavanaugh stops” opinion.

Mark Joseph Stern: I think he is begging us to please cease and desist calling them “Kavanaugh stops.” This footnote is buried in the opinion and doesn’t really have anything to do with it. He just says: By the way, this conflict is about immigration stops. Then he segues into his view on the law around immigration stops, which he claims to be “longstanding and clear.” He writes: “The Fourth Amendment requires that immigration stops must be based on reasonable suspicion of illegal presence, stops must be brief, arrests must be based on probable cause, and officers must not employ excessive force. Moreover, the officers must not make interior immigration stops or arrests based on race or ethnicity.”

Wow! Immigration stops can’t be based on race? What a concept! A concept that you, Brett Kavanaugh, rejected just a few months ago, in September, in the Vasquez Perdomo case. Back then, you wrote that immigration stops could be at least partly based on race or ethnicity, and that a person’s appearance as Latino could be one reason for them to be stopped by immigration officers.

I wonder what has changed since September.

Well, I think he is trying to rid “Kavanaugh stops” from the discourse, which is never going to happen. And maybe he’s trying to send a message to the Trump administration to cool it down. Because now we have CBP Chief Greg Bovino declaring that agents can engage in racial profiling. Bovino has even said that every single person in this country has to walk around with proof of citizenship or else face arrest on suspicion of being undocumented. Kavanaugh is probably a little unnerved that all these violent, racist arrests and abductions are taking his name. He doesn’t want to be remembered by history as this great villain who greenlit the worst wave of violent racial profiling by the federal government in ages. But this footnote changes nothing. He cannot walk back what he has unleashed.

This goes to all the quibbles that we surfaced about the shadow docket when Vasquez Perdomo came out. Because if the justices are going to go ahead and reverse precedent about immigration stops, and then their decision gets operationalized by the Trump administration, they can’t say: Oh, sorry, we didn’t mean that. They certainly can’t do it in a case that does not directly relate back to “Kavanaugh stops.” So this is weird dicta in a random case that is trying to undo crappy but unfortunately enforceable doctrine. And Kavanaugh is just like: No, it’s the shadow docket—I can do what I want! I get a do-over. I get takesies-backsies. We’re now at full Etch A Sketch: I’m making law. I’m breaking law. I’m changing law.

I’ve seen some commentators praise Kavanaugh for sort of responding to criticism here. I do not think he gets any points. He did what he did in Vasquez Perdomo; he should have foreseen the consequences. Every intelligent observer understood what was going to happen when his opinion dropped in September. Now he seems to regret it—though he still hasn’t apologized directly or acknowledged that he was wrong, and is pretending that what he said earlier is consonant with what he’s saying now. Too little, too late.

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-32')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">2025: The Movie(s) of the Year</div>
            <div class="meta">2025-12-30</div>
        </div>
        
        <div id="content-32" style="display:none;">
            <h2>2025: The Movie(s) of the Year</h2>
            <p><strong>News and Politics - Slate Magazine | 2025-12-30</strong></p>
            <a class="original-link" href="https://slate.com/podcasts/what-next/2025/12/year-of-the-resistance-genre-mash-up-blockbuster?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Two films especially felt like they couldn’t have come out at any other time.

Please enable javascript to get your Slate Plus feeds.

If you can&#39;t access your feeds, please contact customer support.

Thanks! Check your phone for a link to finish setting up your feed.

Enter your phone number and we&#39;ll text you a link to set up the
        podcast in your app:

We&#39;ll only text you about setting up this podcast, no spam.

Apple Podcasts will only work on MacOS operating systems since Catalina. We do not support Android apps on desktop at this time.

These links will only work if you&#39;re on the device you listen to podcasts on.

We&#39;re sorry, but something went wrong while fetching your podcast feeds. Please contact us at plus@slate.com for help.

If you were to sum up 2025 in a film, which would you pick? The question that nearly wrecked the brain of Slate’s chief movie critic.

Guest: Dana Stevens, Slate’s movie critic.

Dana’s ten best movies of 2025.Her review of Sinners.And her review of One Battle After Another.

Want more What Next? Subscribe to Slate Plus to access ad-free listening to the whole What Next family and across all your favorite Slate podcasts. Subscribe today on Apple Podcasts by clicking “Try Free” at the top of our show page. Sign up now at slate.com/whatnextplus to get access wherever you listen.

Podcast production by Elena Schwartz, Paige Osburn, Anna Phillips, Madeline Ducharme, and Rob Gunther.

The problem with the news right now? It’s everywhere. And each day, it can feel like we’re all just mindlessly scrolling. It’s why we created What Next. This short daily show is here to help you make sense of things. When the news feels overwhelming, we’re here to help you answer: What next? Look for new episodes every weekday morning.

Mary Harris is the host and managing editor of What Next, Slate&#39;s new daily news podcast. She has reported throughout the public radio system, for NPR, Marketplace, and WNYC.</div>
        </div>
        
        <div class="card" onclick="openModal('content-33')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">One State Supreme Court’s Lazy “Shortcut” Erases Civil Rights</div>
            <div class="meta">2025-12-29</div>
        </div>
        
        <div id="content-33" style="display:none;">
            <h2>One State Supreme Court’s Lazy “Shortcut” Erases Civil Rights</h2>
            <p><strong>News and Politics - Slate Magazine | 2025-12-29</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2025/12/colorado-supreme-court-civil-rights-constitution.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">This piece was originally published in the Behind the Bench newsletter on state constitutional law. Behind the Bench is published by the State Law Research Initiative.

It can be astonishing, and more than a little depressing, to see the lengths some courts go to avoid upholding basic constitutional rights. In June, I wrote about how the North Carolina Supreme Court’s Republican majority dilutes civil rights by requiring claimants to prove that challenged state actions, including discriminatory laws, are “unconstitutional beyond a reasonable doubt.” The problem, as liberal Justice Anita Earls pointed out, is that “either the statute is consistent with the constitution or not,” and the “notion that you have to somehow establish that beyond a reasonable doubt makes no sense”—except, of course, as an excuse to erode civil rights.

Today, I bring your attention to the Colorado Supreme Court, which this month reaffirmed an inexplicable quirk of its excessive sentencing jurisprudence that preemptively extinguishes constitutional rights for entire categories of people. The court declares certain crimes to be “per se grave or serious,” which in practice means that no one convicted of such crimes can ever challenge their sentence, no matter its severity. The long-standing rule is both wholly illogical and blatantly unconstitutional (in the sense that it erases constitutional rights), but there is some good news: It appears that two justices are finally ready to, in their words, “deep six this concept.”

Colorado’s state constitution prohibits “cruel and unusual” punishment, including excessive or “disproportionate” prison terms. To assess excessive punishment claims, Colorado courts begin by comparing “the gravity or seriousness of the offense to the harshness of the penalty.” Normally, Colorado case law takes a relatively capacious view of how a crime’s “gravity” should be measured. It accounts not just for the offense and its elements but also for potentially mitigating factors such as whether the person “was an accessory, complicitor, or principal,” along with the person’s “culpability and motive.” In theory, this definition captures how personal characteristics (such as youth, disability, or addiction) and other circumstances (such as the role of group dynamics, poverty, or coercive relationships) might reduce someone’s culpability and factor into the constitutional analysis.

But for some offenses, the Colorado Supreme Court—and only the Colorado Supreme Court—has devised what it calls “the ‘per se’ shortcut.” Under this rule, the court “designate[s] certain crimes ‘per se grave or serious,’ ” which, the court says, renders a sentence all but “impervious to attack on proportionality grounds.” In other words, the court’s justices have decided they will not do their jobs for people who have certain convictions. Rather than actually assess excessive punishment claims in light of all the factors the law requires, they will just assume that these claims fail, giving prosecutors and legislators free rein to pursue the sort of punitive excess that has fueled mass incarceration for decades.

And it’s not like this rule has been reserved for what might intuitively be the most violent, high-culpability crimes. Robbery, for example, remains “per se grave or dangerous” even though the circumstances under which robberies take place vary wildly, as do the characteristics of the people who commit them (more on that below). Even worse, for nearly 30 years Colorado courts put all drug offenses, including mere possession, on this list until a “clarify[ing]” decision in 2019 finally changed that. (It took decades for the Colorado Supreme Court to realize that it “makes little sense to automatically treat the sale of a large quantity of cocaine by the leader of a drug cartel as equally grave or serious as the mere possession of a very small quantity of cocaine by a drug addict who is not involved in sale or distribution.”)

The court concedes that this “shortcut” is “unique to Colorado law” and that it “eliminates a longstanding layer of due process for criminal defendants.” Nonetheless, it remains on the books because it supposedly “saves time” and promotes “consistency.” I would submit that “saving time” is never a good reason to dispense with constitutional rights, but the court’s claims to efficiency are dubious in any case. Now, instead of properly analyzing its cruel and unusual clause, the court spends its time hopelessly trying to figure out what on earth “per se grave or serious” actually means and what offenses it applies to. With this rule in place, and with prosecutors thirsty to invoke it, the first part of every excessive punishment analysis turns into Tom Cruise cross-examining Jack Nicholson in A Few Good Men: Q: “Grave Danger?” A: [Raises eyebrow] “Is there another kind?”

But there is a glimmer of hope. In People v. Kennedy, decided earlier this month, Justices Carlos Samour and Richard Gabriel “specially concurred” to advocate nixing the per se grave or serious shortcut.

In Kennedy, the court stood by its shortcut and upheld the 24-year prison term at issue. But it also held that vehicular homicide–DUI is not “per se grave or serious” because it is a strict liability crime with no specific intent element. “When a crime requires no proof of mens rea,” the court said, “it is impossible to evaluate the culpability of defendants convicted of the offense under every factual scenario.”

It is good that the court declined to expand the shortcut to cover a new offense, but the analytical problem here is that the same reasoning applies to crimes that do require proof of intent. To use an example mentioned above, the court thinks that people who commit robbery have sufficiently high culpability “under every factual scenario”—a conclusion that can only be understood as the willful ignorance of reality. Just a few other facts one might want to know: How old is the person? Are they a youth or emerging adult under age 25, and therefore more susceptible to peer pressure and impulsive decisionmaking? Was the person coerced by an abusive partner or authority figure? Did the person use a weapon and if so what kind? Was it a gun that turned out to be fake? Did the person act out of desperation? Was anyone physically harmed? The list goes on. To say that virtually no punishment could be unconstitutionally severe for all robbery convictions across all factual scenarios is absurd.

Justices Samour and Gabriel, at least, have started to push back. They argued that “easier and faster isn’t always better,” and that such “superficial proportionality review” is inappropriate when constitutional rights are at stake. Ultimately, they found “the drawbacks of per se designations far outweigh any purported benefits.”

Of course, Samour and Gabriel are right, but I’d add another critique: This constitutional “shortcut” makes absolutely no sense. Recall what it is ostensibly a shortcut to: comparing the gravity and/or seriousness of a criminal offense (including, per Colorado case law, characteristics of the offender) with the severity of the punishment imposed for it. In this context, neither “grave” nor “serious” is a bright-line, binary category. They exist along a spectrum. There is no being “not serious” up to a point before falling over a line into “seriousness.” This isn’t bankruptcy. This is a test about whether certain prison terms are too severe; one would think or at least hope that the Colorado Supreme Court is not perfectly fine with incarceration for wholly unserious crimes. To say that an offense is automatically “serious” or “grave,” therefore, means absolutely nothing, and it certainly doesn’t help understand if the resulting criminal punishment is fair.

What the court must mean, then, is that some crimes are sufficiently serious, but that only makes sense relative to the punishment imposed—a fact irrelevant to the court’s per se designation.

Perhaps I am thinking too hard about this. Such an arbitrary, court-created rule—born out of some combination of cowardly deference to extreme punishments and sheer laziness, and that even prosecutors agree is “a weird concept anyway”—doesn’t deserve that much credit. The point is: The Colorado Supreme Court’s rule, it turns out, is less a shortcut and more a barrier to protecting fundamental constitutional rights that should be torn down.

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-34')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">Which Kind of Person Is the Subject of a <em>Hagiography</em>?</div>
            <div class="meta">2025-12-29</div>
        </div>
        
        <div id="content-34" style="display:none;">
            <h2>Which Kind of Person Is the Subject of a <em>Hagiography</em>?</h2>
            <p><strong>News and Politics - Slate Magazine | 2025-12-29</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2025/12/trivia-quiz-daily-slate-vocabulary-greek-mythology-french.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Please enable Javascript in your browser to view Slate interactives.

Which Cartoon Short Introduced Mickey Mouse?

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-35')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">I Went to the Site Where Republicans Are Building a “Last Defense” Against Zohran Mamdani. It Was … Curious.</div>
            <div class="meta">2025-12-29</div>
        </div>
        
        <div id="content-35" style="display:none;">
            <h2>I Went to the Site Where Republicans Are Building a “Last Defense” Against Zohran Mamdani. It Was … Curious.</h2>
            <p><strong>News and Politics - Slate Magazine | 2025-12-29</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2025/12/donald-trump-new-york-city-long-island-zohran-mamdani.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Sign up for the Slatest to get the most insightful analysis, criticism, and advice out there, delivered to your inbox daily.

Only days remain until Zohran Mamdani ascends the throne of New York City, and nearly all his great opponents have given up. Andrew Cuomo, vanquished. Financier Bill Ackman, reduced to congratulations for the mayor-elect and even offers of support. Donald Trump, singing his praises after inviting him over to hang. Maybe the great socialist boogeyman isn’t so scary after all.

But not everyone is in the mood for total defeat. In a recent interview with Fox News, Nassau County Executive Bruce Blakeman in Long Island announced a novel approach to combat the threat of socialism bearing down from America’s largest city: He is building a wall.

Mamdani, he said, “talks like he’s pro-criminal, not pro-victim.” And as such, in a last-ditch effort, Blakeman is going up with a wall on the border of Queens and Nassau counties, where New York City ends and what most think of as Long Island begins.

This makes plenty of sense. All truly great civilizations have a signature wall. China, for example. Also Donald Trump’s America. So why not Long Island? And this is not some archaic cinderblock and mortar contraption: It’s a top-of-the-line, high-tech fabrication.

“We are installing technology along the border of New York City that will read license plates, that will have facial recognition, that will have video cameras,” Blakeman said in late November. “Nassau Exec Bruce Blakeman plans a wall of surveillance at NYC border after Mamdani win,” boasted the New York Post. So maybe not a Great Wall of China exactly, but certainly a wall with Chinese characteristics, given that an estimated 90 percent of surveillance cameras are made in China.

I appreciate the great works. But my request for a tour of the construction site was shot down; the county exec’s office gave me the elliptical redirect to watch Fox News. No one could tell me whether the wall was up or not. And the clock was ticking. So I headed for the borderlands, to watch the county batten down the hatches for the impending arrival of pro-criminal socialism, or else to delight in the last few days of open borders, Long Island–style.

I spoke with numerous sources in Long Island politics to pin down just where this wall might begin. The Queens–Nassau border is no small tract. To make matters worse, the border is effectively a stretch of highway, the Cross Island Parkway.

I began my tour at Bellerose Terrace, which I was told might be singled out as high priority. I got off at Jericho Turnpike. No surveillance wall in sight.

I stopped by the Bellerose Village Hall and asked for directions to the wall. A very kind woman working behind the desk straightened me out: I was being too literal.

“I think they’re talking about cameras,” she told me. But even so, she couldn’t point me to any new ones. “We haven’t seen any of that yet. They didn’t tell the village anything.”

The wall would be a crowning achievement of Blakeman’s tenure as county executive in Nassau. He has, in some sense, made Long Island into one of the world’s policing laboratories. In August, the county unveiled a $70 million police training village, replete with New York City–style homes, a church, a courtroom, a bar, and even a Long Island Rail Road–style station, where police run around doing what look a lot like combat exercises. Blakeman has also chartered a militia, hiring and deputized armed citizens for mobilization during emergency declarations. And now the wall.

Some would say that astronomical financial commitments to policing have gotten results. A 2024 U.S. News and World Report study found that Nassau County was one of the safest counties in America. Others would say that that same survey also found that the rest of the New York metropolitan area—aka crime-infested hellscape teeming with socialist policies—was similarly safe. Ten of the top 25 safest counties in the country were in New York metro, including Queens County and Brooklyn. The next year Blakeman announced even more police hires, and no more tax hikes to pay for them.

I got back on the Cross Island Parkway and headed for Elmont. This was another town, I was told, that had been identified for wall construction.

I saw a Nassau County Police Department squad car and talked to the officer inside. “That is coming from way more higher up than me,” he told me, of the wall implementation. He, too, was at a loss as to where I could identify some of these new cameras. “I mean, they could be up in any of the towers,” he said. Street lights and telephone poles and electrical wires were all fair game.

This abstracted wall, hung high in civilian infrastructure and currently invisible, couldn’t come at a more important time. With Elise Stefanik summarily bounced from the New York gubernatorial race after a swift falling out with Republican national political leadership, Blakeman is now likely to be the Republican standard bearer, in a race Republicans continue to tell themselves they can actually win because of the unpopularity of Democratic Gov. Kathy Hochul, the fantastic ineptitude of the New York Democratic Party, and some anti-socialist backlash to the Mamdani ascendance. Republicans love to point out Blakeman won his most recent race by close to 12 percentage points in a county with over 100,000 more registered Democrats than Republicans. Trump has already endorsed him.

The result of Blakeman’s police push is that, obviously, the police budget is gargantuan. The 2025 budget of $4.2 billion doesn’t raise property taxes for the fourth year in a row, even though it adds over 50 new cops; over $1 billion of that is going to the police. He has boasted that he has hired 600 law enforcement officers and vetoed over $150 million in tax hikes, which would seem to spell financial trouble in the long run.

When asked how he would foot the bill for it all, Blakeman told Fox News it would come from civil asset forfeitures, an extremely controversial practice that allows law enforcement to seize property—including cash, cars, and assets like homes—from people merely suspected of being linked to crime, even without being charged or convicted. Some might say that they were going to pay for the wall by stealing from people in New York City.

I drove down to Valley Stream. Same story, no construction cones, no earth-moving, no camera crews. I stopped by another Nassau County Police Department office, where they instructed me to call the public affairs contact, who told me not only that he didn’t think they’d even started yet, but that he wasn’t “even sure they’re even gonna be allowed to do that.”

So maybe it was open borders after all. What else was there to do? I got back on the Cross Island Parkway, drove it north and south, crossed freely into Nassau and back into Queens. I counted preexisting security cameras as I went: three on a large gray tower on the west side of the parkway. One on decommissioned road work sign. One on a streetlight near the off-ramp. One more on another gray tower. Did I commit crimes all the way? Wouldn’t you like to know.

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-36')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">New robotic skin lets humanoid robots sense pain and react instantly</div>
            <div class="meta">2025-12-30</div>
        </div>
        
        <div id="content-36" style="display:none;">
            <h2>New robotic skin lets humanoid robots sense pain and react instantly</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2025-12-30</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2025-12-robotic-skin-humanoid-robots-pain.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-37')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">Meta buys China-founded AI agent Manus</div>
            <div class="meta">2025-12-30</div>
        </div>
        
        <div id="content-37" style="display:none;">
            <h2>Meta buys China-founded AI agent Manus</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2025-12-30</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2025-12-meta-buys-china-founded-ai.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-38')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">Analyzer delivers real-time insights for US power grid</div>
            <div class="meta">2025-12-30</div>
        </div>
        
        <div id="content-38" style="display:none;">
            <h2>Analyzer delivers real-time insights for US power grid</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2025-12-30</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2025-12-real-insights-power-grid.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-39')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">New England unions push back against Trump administration's move to freeze offshore wind projects</div>
            <div class="meta">2025-12-30</div>
        </div>
        
        <div id="content-39" style="display:none;">
            <h2>New England unions push back against Trump administration's move to freeze offshore wind projects</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2025-12-30</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2025-12-england-unions-trump-administration-offshore.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-40')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">The evolution of digital nomadism: From hi-tech hacker spaces to crypto coworking</div>
            <div class="meta">2025-12-29</div>
        </div>
        
        <div id="content-40" style="display:none;">
            <h2>The evolution of digital nomadism: From hi-tech hacker spaces to crypto coworking</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2025-12-29</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2025-12-evolution-digital-nomadism-tech-hacker.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-41')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">New AI-based technology offers real-time electric vehicle state estimation for safer driving</div>
            <div class="meta">2025-12-29</div>
        </div>
        
        <div id="content-41" style="display:none;">
            <h2>New AI-based technology offers real-time electric vehicle state estimation for safer driving</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2025-12-29</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2025-12-ai-based-technology-real-electric.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-42')">
            <div class="source">The Register</div>
            <div class="title">When the AI bubble pops, Nvidia becomes the most important software company overnight</div>
            <div class="meta">2025-12-30</div>
        </div>
        
        <div id="content-42" style="display:none;">
            <h2>When the AI bubble pops, Nvidia becomes the most important software company overnight</h2>
            <p><strong>The Register | 2025-12-30</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2025/12/30/how_nvidia_survives_ai_bubble_pop/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Today, Nvidia’s revenues are dominated by hardware sales. But when the AI bubble inevitably pops, the GPU giant will become the single most important software company in the world.

Since ChatGPT kicked off the AI arms race in late 2022, Nvidia has shipped millions of GPUs predominantly for use in AI training and inference.

That’s a lot of chips that are going to be left idle when the music stops and the finance bros come to the sickening realization that using a fast-depreciating asset as collateral for multi-billion dollar loans wasn’t such a great idea after all.

However, anyone suggesting those GPUs will be rendered worthless when the dust settles is naive.

GPUs may be synonymous with AI by this point, but they’re much more versatile than that. As a reminder, GPU stands for graphics processing unit. These chips were originally designed to speed up video game rendering, which, by the late ‘90s, was quickly becoming too computationally intensive for the single-threaded CPUs of the time.

As it turns out, the same thing that made GPUs great at pushing pixels also made them particularly well suited for other parallel workloads — you know, like simulating the physics of a hydrogen bomb going critical. Many of Nvidia’s most powerful accelerators — chips like the H200 or GB300 — have long since ditched the graphics pipeline to make room for more vector and matrix math accelerators required in HPC and AI.

If an app can be parallelized, there’s a good chance it’ll benefit from GPU acceleration — if you have the software to do it. This is why there are so few GPU companies. A GPU needs to be broadly programmable; an AI ASIC only needs to do inference or training well.

Since introducing CUDA, its low level GPU programming environment and API interface, in 2007, Nvidia has built hundreds of software libraries, frameworks, and micro-services to accelerate any and every workload it can think to.

The libraries, collectively marketed under the CUDA-X banner, cover everything from computational fluid dynamics and electronic design automation to drug discovery, computational lithography, material design, and even quantum computing. The company also has frameworks for visualizing digital twins and robotics.

For now, AI has turned out to be the most lucrative of these, but when the hype train runs out of steam, there’s still plenty that can be done with the hardware.

For example, Nvidia built cuDF and integrated it into the popular RAPIDS data science and analytics framework to accelerate SQL databases or Pandas, attaining a 150x speed up in the process. It’s no wonder database giant Oracle is so keen on Nvidia’s hardware. Any compute it can’t rent out to OpenAI for a profit, it can use to accelerate its database and analytics platforms.

Nvidia doesn’t offer a complete solution, and that’s by design. Some of its libraries are open sourced, while others are made available as more comprehensive frameworks and micro-services. These form the building blocks by which software developers can use to accelerate their workloads, with a growing number of them being tied back to revenue-generating licensing schemes.

The only problem: up to this point, these benefits required buying or leasing a pricy GPU and then integrating these frameworks into your code base or waiting for an independent software vendor (ISV) to do it for you.

But when the bubble bursts and pricing on GPUs drops through the floor, anyone that can find a use for these stranded assets stands to make a fortune. Nvidia has already built the software necessary to do it — the ISVs just need to integrate and sell it.

In this context, Nvidia’s steady transition from building low-level software libraries aimed at developers to selling enterprise-focused micro-services starts to make a lot of sense. The lower the barrier to adoption, the easier it is to sell hardware and the subscriptions that go with it.

It appears that Nvidia may even open this software stack to a broader ecosystem of hardware vendors. GPUzilla has begun transitioning to a disaggregated architecture that breaks up workloads and offloads them to third-party silicon.

This week, Nvidia completed a $5 billion investment in Intel. The x86 giant is currently developing a prefill accelerator to speed up prompt processing for large language model inference. Meanwhile, Nvidia signed a deal last week to aqui-hire rival chip vendor Groq that it — though it remains to be seen how the GPU slinger intends to integrate the company’s tech long term.

In addition to its home-grown software platforms, Nvidia has made several strategic software acquisitions over the past few years, acquiring Run:AI’s Kubernetes-based GPU orchestration and Deci AI’s model optimization platforms in 2024. Earlier this month, Nvidia added SchedMD’s Slurm workload management platform, which is widely deployed across AMD, Nvidia, and Intel-based clusters for HPC and AI workloads, ensuring a profit even if you don’t buy its hardware.

To be clear, generative AI as we know it today isn’t going away. The cash that’s fueled AI development over the past three years may evaporate, but the underlying technology, imperfect as it is, is still valuable enough that enterprises will keep using it.

Rather than chasing the mirage that is artificial general intelligence, applications of the tech will be far more mundane.

In fact, many of Nvidia’s more comprehensive micro-services make extensive use of domain-specific AI models for things like weather forecasting or physics simulation.

When the dot-com bubble burst, people didn’t stop building web services or buying switches and routers. This time around, people aren’t going to stop consuming AI services either. They’ll just be one of several reasons to buy GPUs. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-43')">
            <div class="source">The Register</div>
            <div class="title">Tis the season when tech leaders rub their crystal balls</div>
            <div class="meta">2025-12-30</div>
        </div>
        
        <div id="content-43" style="display:none;">
            <h2>Tis the season when tech leaders rub their crystal balls</h2>
            <p><strong>The Register | 2025-12-30</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2025/12/30/tech_leaders_predictions_2026/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Leaders from Dell, Microsoft, Salesforce, ServiceNow, and Snowflake have released their 2026 predictions for AI in the workplace, and they agree that safeguards for AI agents and ROI are the top priorities for their customers.

Dell CTO John Roese sees the future of AI living on premises where organizations have more control over security, governance, and cost. He said AI tools like agents and chatbots have been rushed into production without sufficient policies in place.

“This is not just risky; it’s unsustainable,” he writes. “By 2026, the demand for robust frameworks and private environments to ensure stability and control will be undeniable. Running models locally—on-premises or in controlled AI factories—will become the norm to provide a stable foundation and insulate organizations from external disruptions. But this is more than a prediction. It’s an urgent appeal.”

While Roese said solid ROI has begun to emerge among large companies capable of integrating AI, ServiceNow said in 2026 AI will be defined by the value it brings to the bottom line.

“That’s the only question that matters,” said Heath Ramsey, ServiceNow’s group vice president of AI product platform management in his video predictions. “Leaders face a simple directive to turn AI investments into measurable value, fast.”

Ramsey urged companies to start small and look for the task that is “bleeding time and money,” then fix it end-to-end with AI. But to make that effective, he turned the conversation back to governance.

“You need one entry point with clear policies and approvals,” he said. “A secure foundation for your AI is how you turn an isolated win into a repeatable pattern that scales across your business.”

In terms of governing AI agents, Snowflake CISO Brad Jones says the job in front of his counterparts is to walk the line between putting up guardrails around their behavior while leaving room for operators to experiment and innovate, which is a job for data governance.

“There are likely to be many documents or data sets in a company that don’t have permissions correctly locked down,” he says, in the company’s 2026 AI predictions. “If you feed that into generative or agentic AI, the tool may expose data that it shouldn’t.”

It&#39;s not just internal productivity at stake either, according to Saleforce. It is each company&#39;s image and reputation in the marketplace, predicts Adam Evans, EVP & GM, Salesforce AI.

“By 2026, brands won’t be defined by logos or slogans; they will be defined by their AI. These customizable agents will become the ultimate brand ambassadors: smart, personalized, and continuously evolving with every exchange. In this new reality, the divide will be absolute, and the brands that win will be the ones whose AI delivers a consistently exceptional experience, and everyone else will fall behind.” .

Microsoft sees trust as the essential ingredient to deploying AI agents correctly, according to its 2026 prediction.

Vasu Jakkal, corporate vice president of Microsoft Security, said for humans to rely on agents to carry out tasks or for decision-making, the agents need a clear identity, limits on accessing systems, protocols for managing data they create, and ways to protect that information from attackers.

“Every agent should have similar security protections as humans, to ensure agents don’t turn into ‘double agents’ carrying unchecked risk,” she said in the prediction paper.

The largest software company in the world also offered a hot take on hardware, saying AI growth is not just dependent on who has the biggest data center. Industry veteran Mark Russinovich, chief technology officer for Microsoft Azure, said 2026 is about putting compute to work efficiently.

“The most effective AI infrastructure will pack computing power more densely across distributed networks,” Russinovich says.

He predicts that 2026 will see “the rise of flexible, global AI systems — a new generation of linked AI &#39;superfactories&#39; — that will drive down costs and improve efficiency.”

Microsoft unveiled the first of its linked AI superclusters in Wisconsin this September, which boasts 1.2 million square feet of floor space and thousands of interconnected Nvidia GB200s in a 337 MW barn capable of processing 865,000 tokens per second. It plans to join that facility with other AI superfactories it builds as those come on line.

Back at Dell – the global market leader in the sale of x86 servers and numerous categories of high end commercial data storage used in AI systems – Roese said the widespread deployment of AI hardware redraws the goal lines for resilience and disaster recovery in 2026.

“The focus shifts from simply backing up systems to ensuring AI capabilities remain functional, even if primary systems go offline,” he predicts. “This involves protecting vectorized data and other unique AI artifacts, allowing the intelligence of the system to persist through any disruption. Achieving this requires innovation across the entire AI value chain – from data protection and cybersecurity companies to core AI technology providers.” ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-44')">
            <div class="source">The Register</div>
            <div class="title">We will be cruising at 35,000 feet and failing to update our Apache HTTP Server</div>
            <div class="meta">2025-12-30</div>
        </div>
        
        <div id="content-44" style="display:none;">
            <h2>We will be cruising at 35,000 feet and failing to update our Apache HTTP Server</h2>
            <p><strong>The Register | 2025-12-30</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2025/12/30/update_apache_http_server/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Bork!Bork!Bork! Bork can happen to the best of us, but flashing one&#39;s undercarriage at the boss of a compliance company is less than ideal, particularly at 35,000 feet in the air.

Qualys CEO Sumedh Thakar snapped a pair of whoopsies that popped up on the screen of his in-flight entertainment (IFE) system earlier this year: one is a typical web server fail. The other suggests MySQL connection difficulties.

Aircraft IFE systems are not connected directly to the airplane&#39;s avionics, which is handy, considering that Thakar&#39;s screen showed a decidedly ancient version of Apache in use. In this case, version 2.0.42.

It has been almost 13 years since security support for version 2.0 of the Apache HTTP Server ended. The final release was in July 2013, by which time the team had moved on to bigger and better things. The IFE, however, has not. In fact, version 2.0.42 first appeared in September 2002.

To put that in context, Windows XP had been released just the year before, and movie-goers were being delighted by Star Wars Episode II: Attack of the Clones. Apple&#39;s iPhone had yet to trouble shoppers, although its iPod had been on the shelves for almost a year. Indeed, it was the first BlackBerry smartphone (the 5810) that was the phone to have for the irritating professional.

Time has moved on. BlackBerry is no more, having been thoroughly stomped on by, among other things, Apple&#39;s iPhone, and the rolling hills of the Windows XP default desktop are more likely to trigger waves of nostalgia than anything else. However, in the never-updated world of the IFE, 2002 lives on.

And then there are those MySQL connection problems, which hint that this might be a Thales system. The company, after all, declares that its IFE experience makes for &quot;a journey filled with unique experiences.&quot;

We&#39;re not sure if running a long-obsolete version of Apache HTTP Server and filling a screen with connection errors is quite the unique experience the passenger has in mind. However, considering Airbus&#39;s recent brush with avionic borkage, perhaps replacing the in-flight movies with a MySQL horror show or Apache thriller isn&#39;t such a bad thing after all. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-45')">
            <div class="source">The Register</div>
            <div class="title">Korean telco failed at femtocell security, exposed customers to snooping and fraud</div>
            <div class="meta">2025-12-30</div>
        </div>
        
        <div id="content-45" style="display:none;">
            <h2>Korean telco failed at femtocell security, exposed customers to snooping and fraud</h2>
            <p><strong>The Register | 2025-12-30</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2025/12/30/kt_telecom_femtocell_security_fail/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">South Korea’s Ministry of Science and ICT has found that local carrier Korea Telecom (KT) deployed thousands of badly secured femtocells, leading to an attack that enabled micropayments fraud and snooping on customers’ communications – maybe for years.

Femtocells are customer premises equipment which include a small mobile base station and use a wired broadband service for backhaul into a carrier’s network. Carriers typically deploy them in areas where mobile network signals are weak to improve coverage in and around customers’ homes.

KT deployed thousands of the devices, all of which used the same certificate to authenticate to the carrier’s network. According to analysis by Korean infosec academic and IEEE Fellow Yongdae Kim, the femtocells had no root password, stored keys in plaintext, and were remotely accessible because SSH was enabled.

Attackers could therefore waltz in and retrieve the certificate, then use it to clone a femtocell that KT would treat as a legitimate device and happily connect to its network. And because the cert was set to expire after ten years, miscreants who understood these vulnerabilities had a long period in which to clone a femtocell and use it for evil. The Ministry’s report suggests attackers used one fake femtocell for ten months across 2024 and 2025.

The report also found that KT customers’ devices would automatically connect to a cloned femtocell, and that attackers could read those customers’ text messages and learn what numbers they called.

Korea Telecom operates a micropayments service that allows its customers to pay for digital content using SMS messages. In September, the carrier investigated some of its customers’ bills and detected the use of cloned femtocells in transactions valued at $169,000.

The Ministry’s report says 368 customers fell victim to the micropayment scam.

Yongdae Kim wrote that the $169,000 haul “is absurdly small for this infrastructure sophistication.”

“Rational inference: large-scale data collection was primary. Someone&#39;s greed exposed it. Without micropayment fraud, undetectable,” he added, suggesting that miscreants running cloned femtocells may have used their ability to access customers’ phones for surveillance.

That theory appears plausible for two reasons. One is that KT only has data on payments dating back to July 2024. The Ministry’s report therefore states it is not a definitive account of femtocell-related problems.

The other is that Korean police today published the results of their investigation into the matter, which turned up one fake femtocell that used a key installed in a device used on a Korean military base in 2019, and which went missing in 2020.

The police investigation found multiple cloned femtocells, plus evidence of a large gang running them. Police arrested 13 alleged participants and haven’t ruled out that the gang got some of the information it needed to run its ops from a previous attack on Korea Telecom that saw BPFDoor malware leak info from the carrier for three years starting in 2022. The investigation also alleges the perps went “war-driving” while running an illegal femtocell, to find more phones they could access. One of the arrested men tried to use a fake femtocell at Incheon Airport, on the same day someone else tried to export the cracked hardware to China.

The alleged mastermind of the gang remains at large but is the subject of an Interpol Red Notice.

South Korea’s government has reacted by insisting that KT let customers quit their contracts without penalty.

South Korea is currently a hotspot for bad security. Local e-tailer Coupang, and SK Telecom , are both in trouble for leaking millions of customer records. The nation has also endured a massive camera hijacking operation that grossly invaded some citizens’ privacy, and faces constant attacks and provocation from North Korea. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-46')">
            <div class="source">The Register</div>
            <div class="title">Zuck buys Chinese AI company Manus that claims it deals in actions, not words</div>
            <div class="meta">2025-12-30</div>
        </div>
        
        <div id="content-46" style="display:none;">
            <h2>Zuck buys Chinese AI company Manus that claims it deals in actions, not words</h2>
            <p><strong>The Register | 2025-12-30</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2025/12/30/meta_acquires_manus/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">UPDATED Meta will acquire made-in-China AI outfit Manus and harness its “general agent” technology across its products.

Manus debuted in March 2025 and immediately pitched itself as a leap beyond generative AI chatbots, which it characterizes as best suited to summarizing information and answering questions.

The outfit promotes its own services as enabling “wide research and context-aware reasoning to produce actionable results in the format you need.”

To illustrate that promise, Manus offers a scenario in which users ask its tech to select the best candidate for an job by evaluating job applications stored in a .ZIP file. Manus can open that archive, read the files it contains, evaluate them according to user-defined criteria, then produce a document that ranks candidates by suitability for the role.

The service does that in its own “computer” – a cloud-hosted VM – that Manus says “operates as a multi-agent system powered by several distinct models.”

Manus was created by a Chinese company called Butterfly Effect, which also operates an entity in Hong Kong an recently moved its headquarters to Singapore. The outfit recently claimed to have $100 million annual recurring revenue just eight months after launch.

Meta’s announcement of the deal states: “Manus is already serving the daily needs of millions of users and businesses worldwide” and reveals the made-in-China company’s staff will join the social networking giant. The value of the deal was not disclosed.

Manus hailed its acquisition as “validation of our pioneering work with General AI Agents.”

“Our solution is driving value for millions of users worldwide today. With time, we hope to expand this subscription to the millions of businesses and billions of people on Meta’s platforms,” Manus’s post states, before adding a canned quote from CEO Xiao Hong who said joining the Zuckosphere represents a chance to “build on a stronger, more sustainable foundation without changing how Manus works or how decisions are made.”

“We’re excited about what the future holds with Meta and Manus working together and we will continue to iterate the product and serve users that have defined Manus from the beginning.”

Meta boss-for-life Mark Zuckerberg wants to build a “superintelligence” service, which he defines as software “that knows us deeply, understands our goals, and can help us achieve them.”

In pursuit of that goal, Meta has committed to at least $70 billion of capital expenditure in 2025 and expects to spend more next year, much of it going towards building datacenters to host AI workloads. While the company credits AI with helping it to improve advertising revenue, Meta does not currently offer a paid AI service but is reportedly testing a subscription product called “Meta AI+”.

Manus seems a good fit for that offering, and perhaps also a step towards superintelligence.

The deal is the fifth AI-related acquisition Meta has made in 2025, following its purchases of AI startups PlayAI and WaveForms, accelerator developer Rivos, and wearable device developer Limitless. The social networking giant has also dangled eight-figure compensation packages to lure top AI talent to the company. ®

to note a report from Nikkei in which Meta said Manus will sever ties to Chinese investors and will not operate in China.

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-47')">
            <div class="source">The Register</div>
            <div class="title">Nvidia spends $5B on Intel bailout, instantly gets $2.5B richer</div>
            <div class="meta">2025-12-29</div>
        </div>
        
        <div id="content-47" style="display:none;">
            <h2>Nvidia spends $5B on Intel bailout, instantly gets $2.5B richer</h2>
            <p><strong>The Register | 2025-12-29</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2025/12/29/nvidia_intel_5_billion/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Nvidia’s $5 billion Intel stock purchase is already worth $7.58 billion, turning the recently approved bailout of its rival into a shrewd financial play.

Nvidia had locked in a purchase price of $23.28 per share for Intel when Nvidia CEO Jensen Huang and Intel CEO Lip-Bu Tan struck a deal in September.

The deal had been under scrutiny by the U.S. Federal Trade Commission, which was examining whether Nvidia’s potential 4 percent ownership stake could run afoul of antitrust laws.

However, the FTC gave the deal a greenlight on Dec. 18.

The purchase of 214 million shares closed on Dec. 26, according to Intel regulatory filings. Intel shares closed Monday at $36.68.

Under the terms of the deal, Nvidia and Intel will jointly develop “multiple generations” of chips for datacenter and PC in a move to capture share across the entire chip customer base from consumer to hyperscale customers.

The two companies will work on connecting their chips via the incredibly fast NVLink, which reaches 1.8 TB/s of bandwidth (900 GB/s in each direction) per GPU – about 14x the bandwidth of a PCIe 5.0 x16 slot.

In the PC arena, Intel will build Nvidia-custom x86 CPUs that Nvidia will integrate into its AI infrastructure platforms and offer to the market.

Intel will also be able to build x86 systems-on-chips (SOCs) that integrate Nvidia RTX GPU chiplets. These new x86 RTX chips will power PCs that contain integrated CPUs and GPUs.

The agreement between Intel and Nvidia to develop chips for the data center and for the PC is similar to one that ran afoul of regulators in 2021 when Nvidia attempted to buy UK-based chipmaker Arm outright for $40 billion.

At the time, the FTC said such a deal would have given a large chipmaker control over one of its rivals and amounted to the largest semiconductor deal ever attempted.

The FTC sued. Nvidia abandoned the deal two months after the lawsuit was filed. Then FTC chairman Lina Khan noted it was a rare out-of-court win for the agency during US Senate testimony.

“The proposed merger would have given one of the largest chip companies control over its rivals’ designs for competing chips,” she told United States Senate Committee on the Judiciary Subcommittee on Antitrust, Competition Policy and Consumer Rights in September 2022. “By doing so, the FTC’s complaint alleged that the combined firm would have had the means and incentive to stifle next-generation technologies, including those used to run datacenters and driver-assistance systems in cars.”

Khan, an appointee of former US President Joe Biden, is no longer with the agency. Nvidia has a long-standing relationship with both Arm and Arm-based SoC designers. Prior to its 72-core Grace CPUs, Nvidia worked with Arm on its Tegra family of chips, which power consoles like Nintendo Switch. And as we previously reported, Nvidia has extended similar support for its NVLink tech to Qualcomm and Fujitsu. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-48')">
            <div class="source">The Verge</div>
            <div class="title">Free speech’s great leap backwards</div>
            <div class="meta">2025-12-30</div>
        </div>
        
        <div id="content-48" style="display:none;">
            <h2>Free speech’s great leap backwards</h2>
            <p><strong>The Verge | 2025-12-30</strong></p>
            <a class="original-link" href="https://www.theverge.com/policy/849841/trump-immigration-social-media-free-speech">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">An era of digital authoritarianism has American free expression in a stranglehold.

An era of digital authoritarianism has American free expression in a stranglehold.

In early December, Joshua Aaron, the developer behind the ICEBlock app — designed to let people alert others about the presence of Immigration and Customs Enforcement (ICE) agents — filed a federal lawsuit alleging his First Amendment rights were violated. The Department of Justice had urged Apple to remove Aaron’s app from its App Store, which the suit called unconstitutional. And Apple had complied — in the process, setting its own precedent for suppressing anti-ICE speech.

The year 2025 has marked perhaps the biggest leap back for American free speech in generations. The Trump administration’s war on immigrants and civil liberties has led it to attempt to deport organizers and researchers over political speech, weaponize the Federal Communications Commission to crack down on disfavored broadcast shows, and file multiple frivolous lawsuits against journalists that covered Trump, many of which reached settlements that look a lot like shakedowns.

Immigration restrictions, heavy-handed regulation, civil lawsuits, bad-faith prosecutions — these are all longtime tools to shut down speech and criticism. But the administration has also moved to control private speech gatekeepers. With the formalization of the deal to sell TikTok to a consortium including the Ellison-helmed Oracle coming in just under the wire, we are ending 2025 with every major social media platform fully or partially controlled by Trump-friendly US billionaires, the same year that, for the first time, most people in the country reported getting their news from social media. The consolidation of social media control and its broad influence give the administration a very powerful, newer tool, one that ironically began as an effort to preserve and protect online discourse: content moderation.

We are ending 2025 with every major social media platform fully or partially controlled by Trump-friendly US billionaires

The Trump administration had suggested, without evidence, that ICEBlock put agents at risk. His is the first such lawsuit after big tech companies went on a spree of blocking his and similar tools, including Eyes Up, an app that was designed to archive and catalog footage of past ICE operations. For all of these takedowns, platforms like Apple and Google cited supposed violations of content policies, including, notably, removing Red Dot and DeICER by classifying ICE agents as a vulnerable group.

“I talked to a couple of sort of longtime trust and safety people who did this kind of work inside platforms for years, and they were like, ‘we can’t speak to Apple’s policy, but I’ve never seen a policy like that, where cops are a protected class,’” said Daphne Keller, a onetime associate general counsel at Google who is now director of platform regulation at the Stanford Program in Law, Science & Technology. “My read on the situation is that they really needed to make this concession to the government for whatever reason — because of whatever pressure they were under or whatever benefit they thought they would get from making the concession — and they did it, and then they had to find an excuse.”

Platform content moderation is a notion only about as old as the relatively new social media and technology platforms themselves, but has generally been understood to be a balance between free expression and the need to protect vulnerable groups or populations. The inversion of this concept — using moderation to restrict speech to protect the state acting against vulnerable populations — is a disconcerting and relatively new phenomenon here in the United States, though one that has already become a modus operandi elsewhere.

Platform content moderation is a notion only about as old as the relatively new social media and technology platforms themselves

One Carnegie Endowment paper published last year, focused on India and Thailand, detailed how governments in those countries had used the language and infrastructure of platforms’ content moderation and community standards systems to restrain criticism and push a message. India under Narendra Modi, for example, had imposed “national security” restrictions that were mostly levied against civil society, using a multipronged approach of legal, economic, and political pressure.

Sangeeta Mahapatra, a research fellow at the German Institute for Global and Area Studies and a coauthor of the paper, stressed that while researchers are loath to extrapolate findings too much to new contexts with their own complexities, it was clear the US government was walking the same path. “We have seen this game played so many times that by now there is a kind of predictability,” she said. “The wolves are right at the door. You realize how this is an everyday phenomenon. It’s not something that is episodic, these kinds of intrusions into your life and the starring role that a platform plays, not just as an enabler, but as a proactive enabler.”

Mahapatra stressed that, while a lot of the public framing — and indeed administration officials’ own gloating — was around the Justice Department or Homeland Security having forced or required the companies to take these apps down, the pressure was, at the time the decisions were made, purely rhetorical, and these companies have on occasion forcefully pushed back on perceived government strong-arming. A decade ago, Apple famously went on the legal and rhetorical offensive to block demands by the FBI to create software to override iPhone security as the agency attempted to unlock a phone belonging to the San Bernardino shooter.

Now, though, there’s what she called a “co-production of digital authoritarianism” in which the government doesn’t really have to do that much to expect some level of compliance. “When you see Apple taking down apps proactively, it’s not something that has started with Trump, it’s a pattern that we have been observing for quite some time now. We have seen it in South Asia especially, India especially, a very lucrative market.”

It can be legitimately difficult to distinguish government speech suppression from standard political rhetoric

Keller noted that “there is a narrative from the Republican side right now about how they are free speech warriors who are really mad about how the Biden administration was censoring speech online.” Yet, “politicians on both sides have always tried to get platforms to take down content, and it’s always been to serve their interests or their policy preferences.” In that environment, it can be legitimately difficult to find out what’s the usual rhetoric and what crosses a First Amendment line.

But, as she pointed out, Trump et al. have not exactly been subtle; less than two weeks before taking office again, Trump said Meta CEO Mark Zuckerberg’s Trump-friendly changes to his platforms’ content policies were “probably” a result of the incoming president’s threat to jail Zuckerberg. As the ICEBlock lawsuit lays out, not only did the administration lean on Apple to take down the app, high-level officials including Attorney General Pam Bondi, immigration coordinator Tom Homan, and Homeland Security Secretary Kristi Noem went on to gloat about how they directly triggered the removal.

The ability of regular people to be alerted to ICE sightings and then film and distribute the results has been important not only in a broad narrative sense, but for concrete, practical applications like forming the basis of judicial interventions. In mid-October, US District Judge Sara Ellis ordered Customs and Border Protection agents under the command of Trump henchman and Border Patrol Commander Greg Bovino to follow use of force guidelines and wear body cameras after TV and bystander footage showed agents violently clashing with protesters. These body-worn cameras were then the basis for the judge’s finding that Bovino and his agents were lying to her in their descriptions of their operations (including the finding that agents apparently used ChatGPT to write at least one use of force report).

With an administration that has proven itself ready, willing, and able to lie over and over to the public, the media, Congress, and the courts, the accounts and records produced and compiled by the community, reporters, and researchers seems to be the only reliable corpus of evidence about what the federal agencies are actually doing on the ground — the warrantless arrests, the excessive force, the profiling. Having platforms willing to outright block avenues for people to know about, observe, and archive the footage of these operations poses a concrete risk to the public’s ability to know what’s going on at all.

The administration wants to shut down competition in the narrative-building game

Mahapatra said she’d been working with local partners including journalists and civic organizations on “record-keeping, all the receipts, so that the digital trace, evidence, is not lost, and there is some accountability mechanism… if you don’t document, the narrative capture becomes more unclear, more enduring and long-term.”

This federal push to tank these tools can also be understood through the lens of the administration working to shut down a competitor in the narrative-building game. It’s no secret that under Stephen Miller and Kristi Noem, the Department of Homeland Security fancies itself not only a law enforcement and security clearinghouse but very much a propaganda organ for the administration’s anti-immigration political project. DHS has been sending out its own photographers to help produce slick, movie trailer-like footage of its operations, runs trollish recruitment ads that emphasize the dog-whistle “western values” preoccupations of its leaders, and has shelled out over $200 million for ad campaigns, including to a firm tied to Noem herself.

Keller referenced a now-infamous nighttime Chicago raid where heavily armed agents, some in helicopters, laid siege to an apartment building in an operation that the administration used as fodder for a heavily produced video. “An idea is this is a media war, of who can get the most compelling footage for their side,” she said. “That’s what ICE was doing in that moment, and it’s what they’re trying to prevent the activists from doing by getting the apps down, to the extent that the apps are really about pulling people together and getting video and documenting what is going on.”

Social media moderation and bad-faith utilization of terms of service as weapons in the speech wars are a little more abstract than having political organizers detained, even with how ham-fisted the administration has ultimately been about it, but it’s arguably a much more wide-ranging and effective way of influencing and controlling what speech is available. Now that Trump and team have had a taste, and seen how apparently easy it is to get the companies to play ball, why wouldn’t they keep reaching?

The platforms might have been acting out of expediency, but now that they’ve opened Pandora’s box, it’s hard to tell what the administration might push for. If ICE personnel are now a protected class under Apple’s rules, does that mean that the company could enforce hate speech standards against those criticizing agents? If not, why not? “I would expect they didn’t really think through the implications of, are they really going to interpret policy that way in the future,” said Keller.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-49')">
            <div class="source">The Verge</div>
            <div class="title">LG is announcing its own Frame-style TV at CES</div>
            <div class="meta">2025-12-30</div>
        </div>
        
        <div id="content-49" style="display:none;">
            <h2>LG is announcing its own Frame-style TV at CES</h2>
            <p><strong>The Verge | 2025-12-30</strong></p>
            <a class="original-link" href="https://www.theverge.com/news/850876/lg-gallery-tv-ces-2026">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">LG expands its lifestyle category by adding the Gallery TV to display artwork in your living room.

LG expands its lifestyle category by adding the Gallery TV to display artwork in your living room.

In just the past couple years, the art TV category that’s been dominated by Samsung’s The Frame has seen growth, with additions from both TCL and Hisense. Now LG has announced its own entry, the LG Gallery TV. The TV will leverage the Gallery+ service that LG released earlier this year, which includes thousands of display visuals ranging from pieces of art to cinematic images to gaming scenes. Much like Samsung’s Art Store, Gallery+ has a limited free option, but its full capability requires a subscription.

The new Gallery TV shouldn’t be confused with the G Series OLED TVs, like the LG G5, even though the G Series used to be called the Gallery Series up until a couple years ago. The Gallery TV is a mini-LED TV with “a specialized screen that reduces glare and minimizes reflections for an art-like viewing experience” (so it likely has a matte coating). LG hasn’t specified the backlight configuration, but all of the other art TVs use edge lighting, so it’s a safe bet that this one will as well. OLED technology, while offering superior picture quality to mini LED, isn’t able to display a single image for an extended time without concern of image retention (or burn-in).

LG has taken a cue from Hisense and includes a frame with the Gallery TV. The default frame is white, with the option to purchase an additional wood-colored frame. The TV will be available in 55 and 65 inches, but pricing has yet to be released.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-50')">
            <div class="source">The Verge</div>
            <div class="title">GOG&#8217;s Steam-alternative PC game store is leaving CD Projekt, staying DRM-free</div>
            <div class="meta">2025-12-29</div>
        </div>
        
        <div id="content-50" style="display:none;">
            <h2>GOG&#8217;s Steam-alternative PC game store is leaving CD Projekt, staying DRM-free</h2>
            <p><strong>The Verge | 2025-12-29</strong></p>
            <a class="original-link" href="https://www.theverge.com/news/850832/gog-cd-projekt-acquisition-steam">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The cofounder of GOG and CD Projekt has acquired the preservation-focused game marketplace.

The cofounder of GOG and CD Projekt has acquired the preservation-focused game marketplace.

If you buy something from a Verge link, Vox Media may earn a commission. See our ethics statement.

GOG is splitting from CD Projekt, the game company that launched the preservation-focused PC gaming marketplace in 2008. In an update on Monday, GOG announced that its cofounder, Michał Kiciński, has acquired the digital storefront and its online gaming platform GOG Galaxy from CD Projekt — which he also cofounded — for $25.2 million.

The acquisition isn’t changing anything about GOG’s mission to keep games DRM-free, according to the announcement that says it’s “more central to GOG than ever:”

GOG has always been built on strong values and clear principles. When Marcin Iwiński and Michał Kiciński first came up with the idea for GOG in 2007, the vision was simple: bring classic games back to players, and make sure that once you buy a game, it truly belongs to you, forever. In a market increasingly defined by mandatory clients and closed ecosystems, that philosophy feels more relevant than ever.

This new chapter is about doubling down on that vision. We want to do more to preserve the classics of the past, celebrate standout games of today, and help shape the classics of tomorrow, including new games with real retro spirit.

It also won’t change GOG’s relationship with its former parent company, CD Projekt, which will keep selling existing games, like The Witcher series and Cyberpunk 2077, along with upcoming titles, on the marketplace:

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-51')">
            <div class="source">The Verge</div>
            <div class="title">Turn your PC into a Super Nintendo with Epilogue&#8217;s new USB dock</div>
            <div class="meta">2025-12-29</div>
        </div>
        
        <div id="content-51" style="display:none;">
            <h2>Turn your PC into a Super Nintendo with Epilogue&#8217;s new USB dock</h2>
            <p><strong>The Verge | 2025-12-29</strong></p>
            <a class="original-link" href="https://www.theverge.com/news/850793/epilogue-sn-operator-super-nintendo-snes-cartridge-slot-backup-emulator">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The SNES version of the USB cartridge slot can authenticate your carts and back up your games and save data.

The SNES version of the USB cartridge slot can authenticate your carts and back up your games and save data.

After announcing and teasing its design well over a year ago, Epilogue’s new SN Operator will finally be available for preorder starting tomorrow. Like the company’s GB Operator that debuted in early 2021, the SN Operator is a standalone USB cartridge slot that lets you play and archive old Nintendo console games on PCs, Macs, or handhelds like the Steam Deck using their original carts. But where the GB Operator was built for Game Boy, Game Boy Color, and GBA games, the SN Operator instead supports any Super Nintendo and Super Famicom game.

Preorders for the SN Operator will open at 12PM ET on December 30th for $59.99. That’s $10 more expensive than the smaller GB Operator, which will remain available too. The hardware is expected to ship in April 2026.

The cartridge slot connects to computers or handhelds over USB and works alongside Epilogue’s accompanying Playback app. The app features a built-in SNES emulator for playing your original cartridges, but you can use other emulators if you already have one you prefer. Games that relied on accessories like Nintendo’s Super NES Mouse or the Super Scope are also compatible with Playback and will use your computer mouse instead of those peripherals.

On top of new console support, the SN Operator includes another function that should appeal to retro gaming fans with large collections of aging and degrading cartridges. The Playback app can authenticate cartridges so you know for sure if that rare title you found at a flea market is real or a bootleg. It can also create digital copies of your cartridges including their save game data so you can archive your collection and keep on playing where you originally left off, even if your original cartridges stop working. The SN Operator will work with any cartridge that can be played in Nintendo’s original hardware, including bootlegs you accidentally purchased. But Epilogue does specify you should only back up cartridges you own — so no using this to borrow and copy a giant collection from a friend.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-52')">
            <div class="source">The Verge</div>
            <div class="title">How to tweak your online platform algorithms</div>
            <div class="meta">2025-12-29</div>
        </div>
        
        <div id="content-52" style="display:none;">
            <h2>How to tweak your online platform algorithms</h2>
            <p><strong>The Verge | 2025-12-29</strong></p>
            <a class="original-link" href="https://www.theverge.com/tech/849742/how-to-tune-algorithms-recommendations-online-platforms">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">﻿Most platforms give you some control over what appears in your recommendations and ‘for you’ feeds.

﻿Most platforms give you some control over what appears in your recommendations and ‘for you’ feeds.

Love them or hate them, more than half of the world’s population interacts with algorithmic recommendations in some way every day. Algorithmic recommendations play an integral role in how users discover new content across platforms like Facebook, Instagram, TikTok, and YouTube. It can be nice to be fed a stream of fresh posts, pictures, and videos that are already tailored to our interests instead of manually hunting for content to engage with, but algorithms don’t always show you what you actually want to see.

Many online platforms provide features that aim to help you fix this. The algorithms they deploy are, after all, designed to make you spend more time consuming content and work in similar ways. Recommendations may be based on demographic data like age, sex, and location, your online activity, what you and similar users are interacting with, and more. Most algorithm tuning features follow the same basic premise: you tell the platform what you want to see more of, or less of.

For example, Meta’s in-development “Dear algo” feature for Threads takes that premise quite literally, allowing users to ask for “more” of specific type of content. Meanwhile, the recently launched “Your Algorithm” tool for Instagram lets users see and manage which topics are driving their Reels recommendations. Some content on online platforms may be artificially promoted regardless of whether it aligns with user interests, however. This article breaks down what algorithm tuning tools are provided by some of the most popular online platforms, and other solutions that can help you to — at least partially — reign in recommended content.

The posts that appear on your Facebook feed are a mix of recommended content and whatever is being published by friends and pages you follow. For the latter, you can just leave any page groups you’re no longer interested in and unfriend users to stop seeing their posts.

An easy way to do this is to go to Settings & privacy > Content preferences, and then open the “Unfollow people and groups” option to quickly manage your friends and group lists in one place. The Content preferences menu also lets you toggle off suggestions for political content and provides a “Show less” option for sensitive or graphic content.

There are other controls available under Settings & privacy > Settings > Your activity > Activity log that list other interactions you’ve had on the platform: comments, search history, videos watched, and more. Deleting these interaction histories (either individually or by clearing them entirely) may help to prevent Facebook’s algorithm from suggesting similar content in the future.

For specific posts, you can click into the three-dot menu at the top right of the post itself and select either “Interested” to see more of similar content, or “Not interested” to prompt Facebook into showing you less related content. Meta said it’s planning to “introduce new ways for you to shape your Feed” on Facebook in the coming months, including the ability to give feedback on why something in your feed may not be relevant to you.

For Reels specifically, Meta has a tool that allows you to manage which topics Instagram is using to feed recommended videos to your Reels tab. On the Instagram mobile app, you can tap the icon that resembles two hearts on line sliders at the top-right corner of Reels videos to see an AI-generated summary of topics that are based on your activity history, such as gaming, haircare, college football, or whatever else you’ve interacted with.

Tapping on any of these interests gives you the options to watch Reels on that topic, delete it from your interests, or specify to see less of it on your feed. You can also manually add new interests that you want to see more or less of that aren’t included in the AI summary. The Instagram app will also let you tap the three-dot menu on individual Reels to select “Interested” or “Not Interested,” but this feature isn’t available on the desktop Reels tab.

The main Instagram feed presents those Interested / Not Interested options on both mobile and desktop devices. And like Facebook, Instagram users can click into Settings to manage preferences for sensitive and political content and curate their activity history across likes, comments, reposts, tags, and more to remove anything that might be flagging certain interests to Instagram’s algorithm.

Threads allows you to tap on the three-dot menu on any post on the web and mobile app, and select “Not interested” to see less content around that topic. Unlike Facebook and Instagram, however, Threads won’t let you specify posts you want to see more of. There are also fewer options to manage recommended content if you head into the account settings on desktop devices — you can restrict profiles to see fewer posts from them, block profiles entirely, and mute specific words or phrases to prevent posts that contain them from appearing in your feeds.

The Threads mobile app will provide additional options under the settings menu at the top right of your user profile. From there, you can remove any likes you’ve left on posts, or select “Content preferences” to toggle suggestions for political and sensitive content, alongside muting accounts and filtering words.

Threads is also testing a feature called “Dear algo requests” that can be accessed under this menu, or by typing “Dear algo” in a post, and then describing what you want to see more or less often in your feeds for up to three days. I’m seeing this feature available on my own account in the UK, but the beta may not be available to every user yet.

There are two ways to tune your algorithm on X, and they can both be accessed the same way across web and mobile apps. The first is to tap the three-dot menu at the top right of a post on your “For You” feed, and select “Not interested in this post” to see less of any similar content. Note that this option won’t appear if you open the post itself, so make sure you’re accessing the menu from the feed timeline.

The second and more comprehensive option is to open Settings and privacy > Privacy and safety > Content you see. This view will let you toggle to display media containing sensitive content and see a full list of interests that X is using to “personalize your experience” across the platform. These will all feature a ticked checkbox, so just go through and untick anything you’re not actually interested in seeing, though X says that changes “may take a little while to go into effect.”

The “Content you see” menu also lets you mute accounts and keywords to keep them out of your feeds and manage topics you want to follow or see less of. Following topics will prompt X to show you more related content, while the topics on posts you’ve already flagged to see less of will appear under the “Not interested” tab.

TikTok provides similar algorithm tuning tools to X, including the ability to flag specific videos you’re not interested in. You can access this on the TikTok mobile app by long-pressing on the video or by opening the three-dot menu at the top right of videos on the desktop web platform. Web users can also open the settings menu to filter specific keywords, preventing posts that contain them in titles, descriptions, or stickers from appearing in your feeds.

Additional features can only be accessed on the TikTok mobile apps. On your user profile, open the three-line menu at the top right and select Settings and privacy > Content preferences. You can open the Manage topics option to see a list of preset interests like Dance, Humor, Sports, Food & Drink, and more, each with a slider to adjust if you want to see more or less of that topic on your feed. Content preferences also allow you to enable a “Restricted Mode” that limits content that “may not be comfortable for all audiences.”

For more drastic changes, TikTok has a feature that helps to retrain its algorithm to what video topics you enjoy watching. Selecting “Refresh your For You feed” under Content preferences will “temporarily show you popular videos you may not normally see,” according to TikTok, allowing it to learn what you like from scratch based on videos you like, share, and interact with.

YouTube’s algorithm tuning tools may require some patience because the platform doesn’t provide an overview of topics or interests you’re being targeted with. On the YouTube homepage, you can open the three-dot menu at the bottom right under each video on the web or mobile app and then select “Not interested” to see less of similar content, or “Don’t recommend channel” to keep the creator who posted it out of your feeds.

The same feature works slightly differently for Shorts — the “Not interested” and “Don’t recommend channel” options are both available on the YouTube mobile app’s Shorts tab and can be accessed by either long-pressing on a video or opening the three-dot menu at the top right. The Shorts tab on YouTube’s web platform only provides you with the option to block channel recommendations, however, and only allows you to tag Shorts you’re not interested in if those Shorts appear on YouTube’s homepage.

If you want to hide recommended videos entirely, you can delete and turn off your YouTube watch history on your connected Google account by going to My Activity > YouTube History.

There are a few ways to adjust what content will appear on your Reddit home feed. As we’ve seen with other platforms, you can open the three-dot menu at the top right of suggested posts and select “Show fewer posts like this.” You can also click on your user profile and open Settings > Preferences on the web, or Settings > Account settings on the Reddit mobile app to mute specific subreddit communities, filter out mature content, or toggle home feed recommendations off entirely.

If you keep it active, then Reddit will recommend posts based on your activity on the platform, including your search history and posts or communities you’ve interacted with.

It’s easy to direct what content you want to see in the preset Discover feed on Bluesky. Just open the three-dot menu at the bottom right on any post and — you guessed it — select if you want to see more or less of similar content. Alternatively, you can unpin the Discover feed entirely and replace it with a more curated feed that focuses on topics you’re interested in by selecting one of the options under the My feeds tab, identified by its hashtag symbol.

Like other platforms, the algorithm on Tumblr’s “For you” tab is largely prompted by how you interact with the platform itself and what’s popular with similar users in your communities. If you like art and follow a lot of artists, Tumblr will recommend art-related posts, and so forth.

For posts that aren’t from users or communities you follow, you can open the three-dot menu to tag that you’re not interested in the post itself, or the community it was shared in. You can also open Settings > Dashboard preferences to turn off suggestions that are “based on your likes” and posts from your communities in the following tab.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-53')">
            <div class="source">The Verge</div>
            <div class="title">Beats’ new Powerbeats Fit earbuds are down to $180</div>
            <div class="meta">2025-12-29</div>
        </div>
        
        <div id="content-53" style="display:none;">
            <h2>Beats’ new Powerbeats Fit earbuds are down to $180</h2>
            <p><strong>The Verge | 2025-12-29</strong></p>
            <a class="original-link" href="https://www.theverge.com/gadgets/850705/beats-pixel-watch-apple-pencil-sales-deal">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">﻿You can also save on Google’s Pixel Watch 4 and Apple’s Pencil Pro.

﻿You can also save on Google’s Pixel Watch 4 and Apple’s Pencil Pro.

If you buy something from a Verge link, Vox Media may earn a commission. See our ethics statement.

It’s almost the new year and time to treat yourself to a new pair of earbuds — especially if one of your resolutions for 2026 is to work out more. If you find yourself reading this and nodding, take a look at the Beats Powerbeats Fit, a recent upgrade of Beats’ Fit Pro earbuds that feature a redesigned wing tip. They are now on sale at Amazon, Best Buy, and B&H for about $179.99, which is $20 off their usual $199.99 price and the lowest they’ve gone so far.

According to the company, the new tips have more flexibility in order to improve comfort while keeping the earbuds more securely anchored in your ears. While these mid-level earbuds still use the H1 chips (the Powerbeats Pro 2 and the AirPods Pro 3 are equipped with Apple’s newer H2 wireless chip), they have most of the features you’d look for, whether you’re using them with an iPhone (hands-free Siri access, Find My tracking, and syncing across Apple devices through iCloud) or an Android phone (one-touch pairing and location tracking through the Beats mobile app, along with customizable controls).

A new version of the Fit Pro wireless earbuds, which are upgraded with a redesigned wing tip that Beats says is 20 percent more flexible, a smaller case, and other advantages.

In addition, they offer active noise cancellation, an IPX4 rating, and seven hours of playback (six hours with ANC turned on). Read our coverage.

Sign up for Verge Deals to get deals on products we’ve tested sent to your inbox weekly.

Sign up for Verge Deals to get deals on products we’ve tested sent to your inbox weekly.</div>
        </div>
        
        <div class="card" onclick="openModal('content-54')">
            <div class="source">MIT Technology Review</div>
            <div class="title">The ascent of the AI therapist</div>
            <div class="meta">2025-12-30</div>
        </div>
        
        <div id="content-54" style="display:none;">
            <h2>The ascent of the AI therapist</h2>
            <p><strong>MIT Technology Review | 2025-12-30</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2025/12/30/1129392/book-reviews-ai-therapy-mental-health/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">We’re in the midst of a global mental-­health crisis. More than a billion people worldwide suffer from a mental-health condition, according to the World Health Organization. The prevalence of anxiety and depression is growing in many demographics, particularly young people, and suicide is claiming hundreds of thousands of lives globally each year.

Given the clear demand for accessible and affordable mental-health services, it’s no wonder that people have looked to artificial intelligence for possible relief. Millions are already actively seeking therapy from popular chatbots like OpenAI’s ChatGPT and Anthropic’s Claude, or from specialized psychology apps like Wysa and Woebot. On a broader scale, researchers are exploring AI’s potential to monitor and collect behavioral and biometric observations using wearables and smart devices, analyze vast volumes of clinical data for new insights, and assist human mental-health professionals to help prevent burnout.

But so far this largely uncontrolled experiment has produced mixed results. Many people have found solace in chatbots based on large language models (LLMs), and some experts see promise in them as therapists, but other users have been sent into delusional spirals by AI’s hallucinatory whims and breathless sycophancy. Most tragically, multiple families have alleged that chatbots contributed to the suicides of their loved ones, sparking lawsuits against companies responsible for these tools. In October, OpenAI CEO Sam Altman revealed in a blog post that 0.15% of ChatGPT users “have conversations that include explicit indicators of potential suicidal planning or intent.” That’s roughly a million people sharing suicidal ideations with just one of these software systems every week.

The real-world consequences of AI therapy came to a head in unexpected ways in 2025 as we waded through a critical mass of stories about human-chatbot relationships, the flimsiness of guardrails on many LLMs, and the risks of sharing profoundly personal information with products made by corporations that have economic incentives to harvest and monetize such sensitive data.

Several authors anticipated this inflection point. Their timely books are a reminder that while the present feels like a blur of breakthroughs, scandals, and confusion, this disorienting time is rooted in deeper histories of care, technology, and trust.

LLMs have often been described as “black boxes” because nobody knows exactly how they produce their results. The inner workings that guide their outputs are opaque because their algorithms are so complex and their training data is so vast. In mental-health circles, people often describe the human brain as a “black box,” for analogous reasons. Psychology, psychiatry, and related fields must grapple with the impossibility of seeing clearly inside someone else’s head, let alone pinpointing the exact causes of their distress.

These two types of black boxes are now interacting with each other, creating unpredictable feedback loops that may further impede clarity about the origins of people’s mental-­health struggles and the solutions that may be possible. Anxiety about these developments has much to do with the explosive recent advances in AI, but it also revives decades-old warnings from pioneers such as the MIT computer scientist Joseph Weizenbaum, who argued against computerized therapy as early as the 1960s.

Charlotte Blease, a philosopher of medicine, makes the optimist’s case in Dr. Bot: Why Doctors Can Fail Us—and How AI Could Save Lives. Her book broadly explores the possible positive impacts of AI in a range of medical fields. While she remains clear-eyed about the risks, warning that readers who are expecting “a gushing love letter to technology” will be disappointed, she suggests that these models can help relieve patient suffering and medical burnout alike.

“Health systems are crumbling under patient pressure,” Blease writes. “Greater burdens on fewer doctors create the perfect petri dish for errors,” and “with palpable shortages of doctors and increasing waiting times for patients, many of us are profoundly frustrated.”

Blease believes that AI can not only ease medical professionals’ massive workloads but also relieve the tensions that have always existed between some patients and their caregivers. For example, people often don’t seek needed care because they are intimidated or fear judgment from medical professionals; this is especially true if they have mental-health challenges. AI could allow more people to share their concerns, she argues.

But she’s aware that these putative upsides need to be weighed against major drawbacks. For instance, AI therapists can provide inconsistent and even dangerous responses to human users, according to a 2025 study, and they also raise privacy concerns, given that AI companies are currently not bound by the same confidentiality and HIPAA standards as licensed therapists.

While Blease is an expert in this field, her motivation for writing the book is also personal: She has two siblings with an incurable form of muscular dystrophy, one of whom waited decades for a diagnosis. During the writing of her book, she also lost her partner to cancer and her father to dementia within a devastating six-month period. “I witnessed first-hand the sheer brilliance of doctors and the kindness of health professionals,” she writes. “But I also observed how things can go wrong with care.”

A similar tension animates Daniel Oberhaus’s engrossing book The Silicon Shrink: How Artificial Intelligence Made the World an Asylum. Oberhaus starts from a point of tragedy: the loss of his younger sister to suicide. As Oberhaus carried out the “distinctly twenty-first-century mourning process” of sifting through her digital remains, he wondered if technology could have eased the burden of the psychiatric problems that had plagued her since childhood.

“It seemed possible that all of this personal data might have held important clues that her mental health providers could have used to provide more effective treatment,” he writes. “What if algorithms running on my sister’s smartphone or laptop had used that data to understand when she was in distress? Could it have led to a timely intervention that saved her life? Would she have wanted that even if it did?”

This concept of digital phenotyping—in which a person’s digital behavior could be mined for clues about distress or illness—seems elegant in theory. But it may also become problematic if integrated into the field of psychiatric artificial intelligence (PAI), which extends well beyond chatbot therapy.

Oberhaus emphasizes that digital clues could actually exacerbate the existing challenges of modern psychiatry, a discipline that remains fundamentally uncertain about the underlying causes of mental illnesses and disorders. The advent of PAI, he says, is “the logical equivalent of grafting physics onto astrology.” In other words, the data generated by digital phenotyping is as precise as physical measurements of planetary positions, but it is then integrated into a broader framework—in this case, psychiatry—that, like astrology, is based on unreliable assumptions.

Oberhaus, who uses the phrase “swipe psychiatry” to describe the outsourcing of clinical decisions based on behavioral data to LLMs, thinks that this approach cannot escape the fundamental issues facing psychiatry. In fact, it could worsen the problem by causing the skills and judgment of human therapists to atrophy as they grow more dependent on AI systems.

He also uses the asylums of the past—in which institutionalized patients lost their right to freedom, privacy, dignity, and agency over their lives—as a touchstone for a more insidious digital captivity that may spring from PAI. LLM users are already sacrificing privacy by telling chatbots sensitive personal information that companies then mine and monetize, contributing to a new surveillance economy. Freedom and dignity are at stake when complex inner lives are transformed into data streams tailored for AI analysis.

AI therapists could flatten humanity into patterns of prediction, and so sacrifice the intimate, individualized care that is expected of traditional human therapists. “The logic of PAI leads to a future where we may all find ourselves patients in an algorithmic asylum administered by digital wardens,” Oberhaus writes. “In the algorithmic asylum there is no need for bars on the window or white padded rooms because there is no possibility of escape. The asylum is already everywhere—in your homes and offices, schools and hospitals, courtrooms and barracks. Wherever there’s an internet connection, the asylum is waiting.”

Eoin Fullam, a researcher who studies the intersection of technology and mental health, echoes some of the same concerns in Chatbot Therapy: A Critical Analysis of AI Mental Health Treatment. A heady academic primer, the book analyzes the assumptions underlying the automated treatments offered by AI chatbots and the way capitalist incentives could corrupt these kinds of tools.

Fullam observes that the capitalist mentality behind new technologies “often leads to questionable, illegitimate, and illegal business practices in which the customers’ interests are secondary to strategies of market dominance.”

That doesn’t mean that therapy-bot makers “will inevitably conduct nefarious activities contrary to the users’ interests in the pursuit of market dominance,” Fullam writes.

But he notes that the success of AI therapy depends on the inseparable impulses to make money and to heal people. In this logic, exploitation and therapy feed each other: Every digital therapy session generates data, and that data fuels the system that profits as unpaid users seek care. The more effective the therapy seems, the more the cycle entrenches itself, making it harder to distinguish between care and commodification. “The more the users benefit from the app in terms of its therapeutic or any other mental health intervention,” he writes, “the more they undergo exploitation.”

This sense of an economic and psychological ouroboros—the snake that eats its own tail—serves as a central metaphor in Sike, the debut novel from Fred Lunzer, an author with a research background in AI.

Described as a “story of boy meets girl meets AI psychotherapist,” Sike follows Adrian, a young Londoner who makes a living ghostwriting rap lyrics, in his romance with Maquie, a business professional with a knack for spotting lucrative technologies in the beta phase.

The title refers to a splashy commercial AI therapist called Sike, uploaded into smart glasses, that Adrian uses to interrogate his myriad anxieties. “When I signed up to Sike, we set up my dashboard, a wide black panel like an airplane’s cockpit that showed my daily ‘vitals,’” Adrian narrates. “Sike can analyze the way you walk, the way you make eye contact, the stuff you talk about, the stuff you wear, how often you piss, shit, laugh, cry, kiss, lie, whine, and cough.”

In other words, Sike is the ultimate digital phenotyper, constantly and exhaustively analyzing everything in a user’s daily experiences. In a twist, Lunzer chooses to make Sike a luxury product, available only to subscribers who can foot the price tag of £2,000 per month.

Flush with cash from his contributions to a hit song, Adrian comes to rely on Sike as a trusted mediator between his inner and outer worlds. The novel explores the impacts of the app on the wellness of the well-off, following rich people who voluntarily commit themselves to a boutique version of the digital asylum described by Oberhaus.

The only real sense of danger in Sike involves a Japanese torture egg (don’t ask). The novel strangely sidesteps the broader dystopian ripples of its subject matter in favor of drunken conversations at fancy restaurants and elite dinner parties.

The sudden ascent of the AI therapist seems startlingly futuristic, as if it should be unfolding in some later time when the streets scrub themselves and we travel the world through pneumatic tubes.

Sike’s creator is simply “a great guy” in Adrian’s estimation, despite his techno-messianic vision of training the app to soothe the ills of entire nations. It always seems as if a shoe is meant to drop, but in the end, it never does, leaving the reader with a sense of non-resolution.

While Sike is set in the present day, something about the sudden ascent of the AI therapist—­in real life as well as in fiction—seems startlingly futuristic, as if it should be unfolding in some later time when the streets scrub themselves and we travel the world through pneumatic tubes. But this convergence of mental health and artificial intelligence has been in the making for more than half a century. The beloved astronomer Carl Sagan, for example, once imagined a “network of computer psychotherapeutic terminals, something like arrays of large telephone booths” that could address the growing demand for mental-health services.

Oberhaus notes that one of the first incarnations of a trainable neural network, known as the Perceptron, was devised not by a mathematician but by a psychologist named Frank Rosenblatt, at the Cornell Aeronautical Laboratory in 1958. The potential utility of AI in mental health was widely recognized by the 1960s, inspiring early computerized psychotherapists such as the DOCTOR script that ran on the ELIZA chatbot developed by Joseph Weizenbaum, who shows up in all three of the nonfiction books in this article.

Weizenbaum, who died in 2008, was profoundly concerned about the possibility of computerized therapy. “Computers can make psychiatric judgments,” he wrote in his 1976 book Computer Power and Human Reason. “They can flip coins in much more sophisticated ways than can the most patient human being. The point is that they ought not to be given such tasks. They may even be able to arrive at ‘correct’ decisions in some cases—but always and necessarily on bases no human being should be willing to accept.”

It’s a caution worth keeping in mind. As AI therapists arrive at scale, we’re seeing them play out a familiar dynamic: Tools designed with superficially good intentions are enmeshed with systems that can exploit, surveil, and reshape human behavior. In a frenzied attempt to unlock new opportunities for patients in dire need of mental-health support, we may be locking other doors behind them.

Becky Ferreira is a science reporter based in upstate New York and author of First Contact: The Story of Our Obsession with Aliens.

The experimental model won&#39;t compete with the biggest and best, but it could tell us why they behave in weird ways—and how trustworthy they really are.

Four ways to think about this year&#39;s reckoning

They managed to cut the size of the AI reasoning model by more than half—and claim it can now answer politically sensitive questions once off limits in Chinese AI systems.

A conversation with a chatbot can shift people&#39;s political views—but the most persuasive models also spread the most misinformation.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-55')">
            <div class="source">MIT Technology Review</div>
            <div class="title">Bangladesh’s garment-making industry is getting greener</div>
            <div class="meta">2025-12-29</div>
        </div>
        
        <div id="content-55" style="display:none;">
            <h2>Bangladesh’s garment-making industry is getting greener</h2>
            <p><strong>MIT Technology Review | 2025-12-29</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2025/12/29/1129308/bangladesh-garment-sustainability-frugal-factories/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Pollution from textile production—dyes, chemicals, and heavy metals like lead and cadmium—is common in the waters of the Buriganga River as it runs through Dhaka, Bangladesh. It’s among many harms posed by a garment sector that was once synonymous with tragedy: In 2013, the eight-story Rana Plaza factory building collapsed, killing 1,134 people and injuring some 2,500 others.

But things are starting to change. In recent years the country has quietly become an unlikely leader in “frugal” factories that use a combination of resource-efficient technologies to cut waste, conserve water, and build resilience against climate impacts and global supply disruptions. Bangladesh now boasts 268 LEED-certified garment factories—more than any other country. Dye plants are using safer chemicals, tanneries are adopting cleaner tanning methods and treating wastewater, workshops are switching to more efficient LED lighting, and solar panels glint from rooftops. The hundreds of factories along the Buriganga’s banks and elsewhere in Bangladesh are starting to stitch together a new story, woven from greener threads.

In Fakir Eco Knitwears’ LEED Gold–certified factory in Narayanganj, a city near Dhaka, skylights reduce energy consumption from electric lighting by 40%, and AI-driven cutters allow workers to recycle 95% of fabric scraps into new yarns. “We save energy by using daylight, solar power, and rainwater instead of heavy AC and boilers,” says Md. Anisuzzaman, an engineer at the company. “It shows how local resources can make production greener and more sustainable.”

The shift to green factories in Bangladesh is financed through a combination of factory investments, loans from Bangladesh Bank’s Green Transformation Fund, and pressure from international buyers who reward compliance with ongoing orders. One prominent program is the Partnership for Cleaner Textile (PaCT), an initiative run by the World Bank Group’s International Finance Corporation. Launched in 2013, PaCT has worked with more than 450 factories on cleaner production methods. By its count, the effort now saves 35 billion liters of fresh water annually, enough to meet the needs of 1.9 million people.

It’s a good start, but Bangladesh’s $40 billion garment industry still has a long way to go. The shift to environmentalism at the factory level hasn’t translated to improved outcomes for the sector’s 4.4 million workers.

Wage theft and delayed payments are widespread. The minimum wage, some 12,500 taka per month (about $113), is far below the $200 proposed by unions—which has meant frequent strikes and protests over pay, overtime, and job security. “Since Rana Plaza, building safety and factory conditions have improved, but the mindset remains unchanged,” says A.K.M. Ashraf Uddin, executive director of the Bangladesh Labour Foundation, a nonprofit labor rights group. “Profit still comes first, and workers’ freedom of speech is yet to be realized.”

In the worst case, greener industry practices could actually exacerbate inequality. Smaller factories dominate the sector, and they struggle to afford upgrades. But without those upgrades, businesses could find themselves excluded from certain markets. One of those is the European Union, which plans to require companies to address human rights and environmental problems in supply chains starting in 2027. A cleaner Buriganga River mends just a small corner of a vast tapestry of need.

Zakir Hossain Chowdhury is a visual journalist based in Bangladesh.

As early electric cars age out, hundreds of thousands of used batteries are flooding the market, fueling a gray recycling economy even as Beijing and big manufacturers scramble to build a more orderly system.

How AI and renewables are shifting the energy landscape.

Omar Yaghi thinks crystals with gaps that capture moisture could bring technology from “Dune” to the arid parts of Earth.

And why many scientists are freaked out about the first serious for-profit company moving into the solar geoengineering field.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-56')">
            <div class="source">MIT Technology Review</div>
            <div class="title">MIT Technology Review’s most popular stories of 2025</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-56" style="display:none;">
            <h2>MIT Technology Review’s most popular stories of 2025</h2>
            <p><strong>MIT Technology Review | 2025-12-26</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2025/12/26/1130318/mit-technology-review-most-popular-stories-2025/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">It&#39;s been a busy and productive year here at MIT Technology Review. We published magazine issues on power, creativity, innovation, bodies, relationships, and security. We hosted 14 exclusive virtual conversations with our editors and outside experts in our subscriber-only series, Roundtables, and held two events on MIT’s campus. And we published hundreds of articles online, following new developments in computing, climate tech, robotics, and more.

As the year winds down, we wanted to give you a chance to revisit a bit of this work with us. Whether we were covering the red-hot rise of artificial intelligence or the future of biotech, these are some of the stories that resonated the most with our readers.

We did the math on AI’s energy footprint. Here’s the story you haven’t heard.

Understanding AI’s energy use was a huge global conversation in 2025 as hundreds of millions of people began using generative AI tools on a regular basis. Senior reporters James O’Donnell and Casey Crownhart dug into the numbers and published an unprecedented look at AI’s resource demand, down to the level of a single query, to help us know how much energy and water AI may require moving forward.

We’re learning more about what vitamin D does to our bodies

Vitamin D deficiency is widespread, particularly in the winter when there’s less sunlight to drive its production in our bodies. The “sunshine vitamin” is important for bone health, but as senior reporter Jessica Hamzelou reported, recent research is also uncovering surprising new insights into other ways it might influence our bodies, including our immune systems and heart health.

Senior editor Will Douglas Heaven’s expansive look at how to define AI was published in 2024, but it still managed to connect with many readers this year. He lays out why no one can agree on what AI is—and explains why that ambiguity matters, and how it can inform our own critical thinking about this technology.

Ethically sourced “spare” human bodies could revolutionize medicine

In this thought-provoking op-ed, a team of experts at Stanford University argue that creating living human bodies that can’t think, don’t have any awareness, and can’t feel pain could shake up medical research and drug development by providing essential biological materials for testing and transplantation. Recent advances in biotechnology now provide a potential pathway to such “bodyoids,” though plenty of technical challenges and ethical hurdles remain.

It’s surprisingly easy to stumble into a relationship with an AI chatbot

Chatbots were everywhere this year, and reporter Rhiannon Williams chronicled how quickly people can develop bonds with one. That’s all right for some people, she notes, but dangerous for others. Some folks even describe unintentionally forming romantic relationships with chatbots. This is a trend we’ll definitely be keeping an eye on in 2026.

The electric grid is bracing for disruption from more frequent storms and fires, as well as an uncertain policy and regulatory landscape. And in many ways, the publicly owned utility company Lincoln Electric in Nebraska is an ideal lens through which to examine this shift as it works through the challenges of delivering service that’s reliable, affordable, and sustainable.

Exclusive: A record-breaking baby has been born from an embryo that’s over 30 years old

This year saw the birth of the world’s “oldest baby”: Thaddeus Daniel Pierce, who arrived on July 26. The embryo he developed from was created in 1994 during the early days of IVF and had been frozen and sitting in storage ever since. The new baby’s parents were toddlers at the time, and the embryo was donated to them decades later via a Christian “embryo adoption” agency.

How these two brothers became go-to experts on America’s “mystery drone” invasion

Twin brothers John and Gerald Tedesco teamed up to investigate a concerning new threat—unidentified drones. In 2024 alone, some 350 drones entered airspace over a hundred different US military installations, and many cases went unsolved, according to a top military official. This story takes readers inside the equipment-filled RV the Tedescos created to study mysterious aerial phenomena, and how they made a name for themselves among government officials.

Our newsroom has published this annual look at advances that will matter in the long run for over 20 years. This year’s list featured generative AI search, cleaner jet fuel, long-acting HIV prevention meds, and other emerging technologies that our journalists think are worth watching. We’ll publish the 2026 edition of the list on January 12, so stay tuned. (In the meantime, here’s what didn’t make the cut.)

The Cybertruck, sycophantic AI, and humanoid robots all made this year’s list of the biggest technology failures.

Unveiled by the buzzy startup Deep, Vanguard will let teams of scientists live and work on the seabed for a week at a time.

We’ll keep following these developments, but this just wasn’t their year. Here’s why.

It’s free and easy to nominate yourself or someone you know—here’s how.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-57')">
            <div class="source">MIT Technology Review</div>
            <div class="title">The paints, coatings, and chemicals making the world a cooler place</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-57" style="display:none;">
            <h2>The paints, coatings, and chemicals making the world a cooler place</h2>
            <p><strong>MIT Technology Review | 2025-12-26</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2025/12/26/1129301/paint-coating-chemicals-materials-cooling-air-conditioning/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">It’s getting harder to beat the heat. During the summer of 2025, heat waves knocked out power grids in North America, Europe, and the Middle East. Global warming means more people need air-­conditioning, which requires more power and strains grids. But a millennia-old idea (plus 21st-century tech) might offer an answer: radiative cooling. Paints, coatings, and textiles can scatter sunlight and dissipate heat—no additional energy required.

“Radiative cooling is universal—it exists everywhere in our daily life,” says Qiaoqiang Gan, a professor of materials science and applied physics at King Abdullah University of Science and Technology in Saudi Arabia. Pretty much any object will absorb heat from the sun during the day and radiate some of it back at night. It’s why cars parked outside overnight are often covered with condensation, Gan says—their metal roofs dissipate heat into the sky, cooling the surfaces below the ambient air temperature. That’s how you get dew.

Humans have harnessed this basic natural process for thousands of years. Desert peoples in Iran, North Africa, and India manufactured ice by leaving pools of water exposed to clear desert skies overnight, when radiative cooling happens naturally; other cultures constructed “cool roofs” capped with reflective materials that scattered sunlight and lowered interior temperatures. “People have taken advantage of this effect, either knowingly or unknowingly, for a very long time,” says Aaswath Raman, a materials scientist at UCLA and cofounder of the radiative­cooling startup SkyCool Systems.

Modern approaches, as demonstrated everywhere from California supermarket rooftops to Japan’s Expo 2025 pavilion, go even further. Normally, if the sun is up and pumping in heat, surfaces can’t get cooler than the ambient temperature. But back in 2014, Raman and his colleagues achieved radiative cooling in the daytime. They customized photonic films to absorb and then radiate heat at infrared wavelengths between eight and 13 micrometers—a range of electromagnetic wavelengths called an “atmospheric window,” because that radiation escapes to space rather than getting absorbed. Those films could dissipate heat even under full sun, cooling the inside of a building to 9 °F below ambient temperatures, with no AC or energy source required.

That was proof of concept; today, Raman says, the industry has mostly shifted away from advanced photonics that use the atmospheric-window effect to simpler sunlight-scattering materials. Ceramic cool roofs, nanostructure coatings, and reflective polymers all offer the possibility of diverting more sunlight across all wavelengths, and they’re more durable and scalable.

Now the race is on. Startups such as SkyCool, Planck Energies, Spacecool, and i2Cool are competing to commercially manufacture and sell coatings that reflect at least 94% of sunlight in most climates, and above 97% in humid tropical ones. Pilot projects have already provided significant cooling to residential buildings, reducing AC energy needs by 15% to 20% in some cases.

This idea could go way beyond reflective rooftops and roads. Researchers are developing reflective textiles that can be worn by people most at risk of heat exposure. “This is personal thermal management,” says Gan. “We can realize passive cooling in T-shirts, sportswear, and garments.”

Of course, these technologies and materials have limits. Like solar power grids, they’re vulnerable to weather. Clouds prevent reflected sunlight from bouncing into space. Dust and air pollution dim materials’ bright surfaces. Lots of coatings lose their reflectivity after a few years. And the cheapest and toughest materials used in radiative cooling tend to rely on Teflon and other fluoropolymers, “forever chemicals” that don’t biodegrade, posing an environmental risk. “They are the best class of products that tend to survive outdoors,” says Raman. “So for long-term scale-up, can you do it without materials like those fluoropolymers and still maintain the durability and hit this low cost point?”

As with any other solution to the problems of climate change, one size won’t fit all. “We cannot be overoptimistic and say that radiative cooling can address all our future needs,” Gan says. “We still need more efficient active air-conditioning.” A shiny roof isn’t a panacea, but it’s still pretty cool.

Becky Ferreira is a science reporter based in upstate New York and author of First Contact: The Story of Our Obsession with Aliens.

As early electric cars age out, hundreds of thousands of used batteries are flooding the market, fueling a gray recycling economy even as Beijing and big manufacturers scramble to build a more orderly system.

How AI and renewables are shifting the energy landscape.

Omar Yaghi thinks crystals with gaps that capture moisture could bring technology from “Dune” to the arid parts of Earth.

And why many scientists are freaked out about the first serious for-profit company moving into the solar geoengineering field.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-58')">
            <div class="source">MIT Technology Review</div>
            <div class="title">AI Wrapped: The 14 AI terms you couldn’t avoid in 2025</div>
            <div class="meta">2025-12-25</div>
        </div>
        
        <div id="content-58" style="display:none;">
            <h2>AI Wrapped: The 14 AI terms you couldn’t avoid in 2025</h2>
            <p><strong>MIT Technology Review | 2025-12-25</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2025/12/25/1130298/ai-wrapped-the-14-ai-terms-you-couldnt-avoid-in-2025/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">If the past 12 months have taught us anything, it’s that the AI hype train is showing no signs of slowing. It’s hard to believe that at the beginning of the year, DeepSeek had yet to turn the entire industry on its head, Meta was better known for trying (and failing) to make the metaverse cool than for its relentless quest to dominate superintelligence, and vibe coding wasn’t a thing.

If that’s left you feeling a little confused, fear not. As we near the end of 2025, our writers have taken a look back over the AI terms that dominated the year, for better or worse.

Make sure you take the time to brace yourself for what promises to be another bonkers year.

As long as people have been hyping AI, they have been coming up with names for a future, ultra-powerful form of the technology that could bring about utopian or dystopian consequences for humanity. “Superintelligence” is that latest hot term. Meta announced in July that it would form an AI team to pursue superintelligence, and it was reportedly offering nine-figure compensation packages to AI experts from the company’s competitors to join.

In December, Microsoft’s head of AI followed suit, saying the company would be spending big sums, perhaps hundreds of billions, on the pursuit of superintelligence. If you think superintelligence is as vaguely defined as artificial general intelligence, or AGI, you’d be right! While it’s conceivable that these sorts of technologies will be feasible in humanity’s long run, the question is really when, and whether today’s AI is good enough to be treated as a stepping stone toward something like superintelligence. Not that that will stop the hype kings. —James O’Donnell

Thirty years ago, Steve Jobs said everyone in America should learn how to program a computer. Today, people with zero knowledge of how to code can knock up an app, game, or website in no time at all thanks to vibe coding—a catch-all phrase coined by OpenAI cofounder Andrej Karpathy. To vibe-code, you simply prompt generative AI models’ coding assistants to create the digital object of your desire and accept pretty much everything they spit out. Will the result work? Possibly not. Will it be secure? Almost definitely not, but the technique’s biggest champions aren’t letting those minor details stand in their way. Also—it sounds fun! — Rhiannon Williams

One of the biggest AI stories over the past year has been how prolonged interactions with chatbots can cause vulnerable people to experience delusions and, in some extreme cases, can either cause or worsen psychosis. Although “chatbot psychosis” is not a recognized medical term, researchers are paying close attention to the growing anecdotal evidence from users who say it’s happened to them or someone they know. Sadly, the increasing number of lawsuits filed against AI companies by the families of people who died following their conversations with chatbots demonstrate the technology’s potentially deadly consequences. —Rhiannon Williams

Few things kept the AI hype train going this year more than so-called reasoning models, LLMs that can break down a problem into multiple steps and work through them one by one. OpenAI released its first reasoning models, o1 and o3, a year ago.

A month later, the Chinese firm DeepSeek took everyone by surprise with a very fast follow, putting out R1, the first open-source reasoning model. In no time, reasoning models became the industry standard: All major mass-market chatbots now come in flavors backed by this tech. Reasoning models have pushed the envelope of what LLMs can do, matching top human performances in prestigious math and coding competitions. On the flip side, all the buzz about LLMs that could “reason” reignited old debates about how smart LLMs really are and how they really work. Like “artificial intelligence” itself, “reasoning” is technical jargon dressed up with marketing sparkle. Choo choo! —Will Douglas Heaven

For all their uncanny facility with language, LLMs have very little common sense. Put simply, they don’t have any grounding in how the world works. Book learners in the most literal sense, LLMs can wax lyrical about everything under the sun and then fall flat with a howler about how many elephants you could fit into an Olympic swimming pool (exactly one, according to one of Google DeepMind’s LLMs).

World models—a broad church encompassing various technologies—aim to give AI some basic common sense about how stuff in the world actually fits together. In their most vivid form, world models like Google DeepMind’s Genie 3 and Marble, the much-anticipated new tech from Fei-Fei Li’s startup World Labs, can generate detailed and realistic virtual worlds for robots to train in and more. Yann LeCun, Meta’s former chief scientist, is also working on world models. He has been trying to give AI a sense of how the world works for years, by training models to predict what happens next in videos. This year he quit Meta to focus on this approach in a new start up called Advanced Machine Intelligence Labs. If all goes well, world models could be the next thing. —Will Douglas Heaven

Have you heard about all the people saying no thanks, we actually don’t want a giant data center plopped in our backyard? The data centers in question—which tech companies want to built everywhere, including space—are typically referred to as hyperscalers: massive buildings purpose-built for AI operations and used by the likes of OpenAI and Google to build bigger and more powerful AI models. Inside such buildings, the world’s best chips hum away training and fine-tuning models, and they’re built to be modular and grow according to needs.

It’s been a big year for hyperscalers. OpenAI announced, alongside President Donald Trump, its Stargate project, a $500 billion joint venture to pepper the country with the largest data centers ever. But it leaves almost everyone else asking: What exactly do we get out of it? Consumers worry the new data centers will raise their power bills. Such buildings generally struggle to run on renewable energy. And they don’t tend to create all that many jobs. But hey, maybe these massive, windowless buildings could at least give a moody, sci-fi vibe to your community. —James O’Donnell

The lofty promises of AI are levitating the economy. AI companies are raising eye-popping sums of money and watching their valuations soar into the stratosphere. They’re pouring hundreds of billions of dollars into chips and data centers, financed increasingly by debt and eyebrow-raising circular deals. Meanwhile, the companies leading the gold rush, like OpenAI and Anthropic, might not turn a profit for years, if ever. Investors are betting big that AI will usher in a new era of riches, yet no one knows how transformative the technology will actually be.

Most organizations using AI aren’t yet seeing the payoff, and AI work slop is everywhere. There’s scientific uncertainty about whether scaling LLMs will deliver superintelligence or whether new breakthroughs need to pave the way. But unlike their predecessors in the dot-com bubble, AI companies are showing strong revenue growth, and some are even deep-pocketed tech titans like Microsoft, Google, and Meta. Will the manic dream ever burst? —Michelle Kim

This year, AI agents were everywhere. Every new feature announcement, model drop, or security report throughout 2025 was peppered with mentions of them, even though plenty of AI companies and experts disagree on exactly what counts as being truly “agentic,” a vague term if ever there was one. No matter that it’s virtually impossible to guarantee that an AI acting on your behalf out in the wide web will always do exactly what it’s supposed to do—it seems as though agentic AI is here to stay for the foreseeable. Want to sell something? Call it agentic! —Rhiannon Williams

Early this year, DeepSeek unveiled its new model DeepSeek R1, an open-source reasoning model that matches top Western models but costs a fraction of the price. Its launch freaked Silicon Valley out, as many suddenly realized for the first time that huge scale and resources were not necessarily the key to high-level AI models. Nvidia stock plunged by 17% the day after R1 was released.

The key to R1’s success was distillation, a technique that makes AI models more efficient. It works by getting a bigger model to tutor a smaller model: You run the teacher model on a lot of examples and record the answers, and reward the student model as it copies those responses as closely as possible, so that it gains a compressed version of the teacher’s knowledge.  —Caiwei Chen

As people across the world spend increasing amounts of time interacting with chatbots like ChatGPT, chatbot makers are struggling to work out the kind of tone and “personality” the models should adopt. Back in April, OpenAI admitted it’d struck the wrong balance between helpful and sniveling, saying a new update had rendered GPT-4o too sycophantic. Having it suck up to you isn’t just irritating—it can mislead users by reinforcing their incorrect beliefs and spreading misinformation. So consider this your reminder to take everything—yes, everything—LLMs produce with a pinch of salt. —Rhiannon Williams

If there is one AI-related term that has fully escaped the nerd enclosures and entered public consciousness, it’s “slop.” The word itself is old (think pig feed), but “slop” is now commonly used to refer to low-effort, mass-produced content generated by AI, often optimized for online traffic. A lot of people even use it as a shorthand for any AI-generated content. It has felt inescapable in the past year: We have been marinated in it, from fake biographies to shrimp Jesus images to surreal human-animal hybrid videos.

But people are also having fun with it. The term’s sardonic flexibility has made it easy for internet users to slap it on all kinds of words as a suffix to describe anything that lacks substance and is absurdly mediocre: think “work slop” or “friend slop.” As the hype cycle resets, “slop” marks a cultural reckoning about what we trust, what we value as creative labor, and what it means to be surrounded by stuff that was made for engagement rather than expression. —Caiwei Chen

Did you come across the hypnotizing video from earlier this year of a humanoid robot putting away dishes in a bleak, gray-scale kitchen? That pretty much embodies the idea of physical intelligence: the idea that advancements in AI can help robots better move around the physical world.

It’s true that robots have been able to learn new tasks faster than ever before, everywhere from operating rooms to warehouses. Self-driving-car companies have seen improvements in how they simulate the roads, too. That said, it’s still wise to be skeptical that AI has revolutionized the field. Consider, for example, that many robots advertised as butlers in your home are doing the majority of their tasks thanks to remote operators in the Philippines.

The road ahead for physical intelligence is also sure to be weird. Large language models train on text, which is abundant on the internet, but robots learn more from videos of people doing things. That’s why the robot company Figure suggested in September that it would pay people to film themselves in their apartments doing chores. Would you sign up? —James O&#39;Donnell

AI models are trained by devouring millions of words and images across the internet, including copyrighted work by artists and writers. AI companies argue this is “fair use”—a legal doctrine that lets you use copyrighted material without permission if you transform it into something new that doesn’t compete with the original. Courts are starting to weigh in. In June, Anthropic’s training of its AI model Claude on a library of books was ruled fair use because the technology was “exceedingly transformative.”

That same month, Meta scored a similar win, but only because the authors couldn’t show that the company’s literary buffet cut into their paychecks. As copyright battles brew, some creators are cashing in on the feast. In December, Disney signed a splashy deal with OpenAI to let users of Sora, the AI video platform, generate videos featuring more than 200 characters from Disney&#39;s franchises. Meanwhile, governments around the world are rewriting copyright rules for the content-guzzling machines. Is training AI on copyrighted work fair use? As with any billion-dollar legal question, it depends. —Michelle Kim

Just a few short years ago, an entire industry was built around helping websites rank highly in search results (okay, just in Google). Now search engine optimization (SEO), is giving way to GEO—generative engine optimization—as the AI boom forces brands and businesses to scramble to maximize their visibility in AI, whether that’s in AI-enhanced search results like Google’s AI Overviews or within responses from LLMs. It’s no wonder they’re freaked out. We already know that news companies have experienced a colossal drop in search-driven web traffic, and AI companies are working on ways to cut out the middleman and allow their users to visit sites from directly within their platforms. It’s time to adapt or die. —Rhiannon Williams

The experimental model won&#39;t compete with the biggest and best, but it could tell us why they behave in weird ways—and how trustworthy they really are.

Four ways to think about this year&#39;s reckoning

They managed to cut the size of the AI reasoning model by more than half—and claim it can now answer politically sensitive questions once off limits in Chinese AI systems.

A conversation with a chatbot can shift people&#39;s political views—but the most persuasive models also spread the most misinformation.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-59')">
            <div class="source">MIT Technology Review</div>
            <div class="title">Meet the man hunting the spies in your smartphone</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-59" style="display:none;">
            <h2>Meet the man hunting the spies in your smartphone</h2>
            <p><strong>MIT Technology Review | 2025-12-24</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2025/12/24/1129294/ronald-deibert-citizen-lab-digital-threats-spies-cybersecurity/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">In April 2025, Ronald Deibert left all electronic devices at home in Toronto and boarded a plane. When he landed in Illinois, he took a taxi to a mall and headed directly to the Apple Store to purchase a new laptop and iPhone. He’d wanted to keep the risk of having his personal devices confiscated to a minimum, because he knew his work made him a prime target for surveillance. “I’m traveling under the assumption that I am being watched, right down to exactly where I am at any moment,” Deibert says.

Deibert directs the Citizen Lab, a research center he founded in 2001 to serve as “counterintelligence for civil society.” Housed at the University of Toronto, the lab operates independently of governments or corporate interests, relying instead on research grants and private philanthropy for financial support. It’s one of the few institutions that investigate cyberthreats exclusively in the public interest, and in doing so, it has exposed some of the most egregious digital abuses of the past two decades.

For many years, Deibert and his colleagues have held up the US as the standard for liberal democracy. But that’s changing, he says: “The pillars of democracy are under assault in the United States. For many decades, in spite of its flaws, it has upheld norms about what constitutional democracy looks like or should aspire to. [That] is now at risk.”

Even as some of his fellow Canadians avoided US travel after Donald Trump’s second election, Deibert relished the opportunity to visit. Alongside his meetings with human rights defenders, he also documented active surveillance at Columbia University during the height of its student protests. Deibert snapped photos of drones above campus and noted the exceptionally strict security protocols. “It was unorthodox to go to the United States,” he says. “But I really gravitate toward problems in the world.”

Deibert, 61, grew up in East Vancouver, British Columbia, a gritty area with a boisterous countercultural presence. In the ’70s, Vancouver brimmed with draft dodgers and hippies, but Deibert points to American investigative journalism—exposing the COINTELPRO surveillance program, the Pentagon Papers, Watergate—as the seed of his respect for antiestablishment sentiment. He didn’t imagine that this fascination would translate into a career, however.

“My horizons were pretty low because I came from a working-class family, and there weren’t many people in my family—in fact, none—who went on to university,” he says.

Deibert eventually entered a graduate program in international relations at the University of British Columbia. His doctoral research brought him to a field of inquiry that would soon explode: the geopolitical implications of the nascent internet.

“In my field, there were a handful of people beginning to talk about the internet, but it was very shallow, and that frustrated me,” he says. “And meanwhile, computer science was very technical, but not political—[politics] was almost like a dirty word.”

Deibert continued to explore these topics at the University of Toronto when he was appointed to a tenure-track professorship, but it wasn’t until after he founded the Citizen Lab in 2001 that his work rose to global prominence.

What put the lab on the map, Deibert says, was its 2009 report “Tracking GhostNet,” which uncovered a digital espionage network in China that had breached offices of foreign embassies and diplomats in more than 100 countries, including the office of the Dalai Lama. The report and its follow-up in 2010 were among the first to publicly expose cybersurveillance in real time. In the years since, the lab has published over 180 such analyses, garnering praise from human rights advocates ranging from Margaret Atwood to Edward Snowden.

The lab has rigorously investigated authoritarian regimes around the world (Deibert says both Russia and China have his name on a “list” barring his entry). The group was the first to uncover the use of commercial spyware to surveil people close to the Saudi dissident and Washington Post journalist Jamal Khashoggi prior to his assassination, and its research has directly informed G7 and UN resolutions on digital repression and led to sanctions on spyware vendors. Even so, in 2025 US Immigration and Customs Enforcement reactivated a $2 million contract with the spyware vendor Paragon. The contract, which the Biden administration had previously placed under a stop-work order, resembles steps taken by governments in Europe and Israel that have also deployed domestic spyware to address security concerns.

“It saves lives, quite literally,” Cindy Cohn, executive director of the Electronic Frontier Foundation, says of the lab’s work. “The Citizen Lab [researchers] were the first to really focus on technical attacks on human rights activists and democracy activists all around the world. And they’re still the best at it.”

When recruiting new Citizen Lab employees (or “Labbers,” as they refer to one another), Deibert forgoes stuffy, pencil-pushing academics in favor of brilliant, colorful personalities, many of whom personally experienced repression from some of the same regimes the lab now investigates.

Noura Aljizawi, a researcher on digital repression who survived torture at the hands of the al-Assad regime in Syria, researches the distinct threat that digital technologies pose to women and queer people, particularly when deployed against exiled nationals. She helped create Security Planner, a tool that gives personalized, expert-reviewed guidance to people looking to improve their digital hygiene, for which the University of Toronto awarded her an Excellence Through Innovation Award.

Work for the lab is not without risk. Citizen Lab fellow Elies Campo, for example, was followed and photographed after the lab published a 2022 report that exposed the digital surveillance of dozens of Catalonian citizens and members of parliament, including four Catalonian presidents who were targeted during or after their terms.

Still, the lab’s reputation and mission make recruitment fairly easy, Deibert says. “This good work attracts a certain type of person,” he says. “But they’re usually also drawn to the sleuthing. It’s detective work, and that can be highly intoxicating—even addictive.”

Deibert frequently deflects the spotlight to his fellow Labbers. He rarely discusses the group’s accomplishments without referencing two senior researchers, Bill Marczak and John Scott-Railton, alongside other staffers. And on the occasion that someone decides to leave the Citizen Lab to pursue another position, this appreciation remains.

“We have a saying: Once a Labber, always a Labber,” Deibert says.

While in the US, Deibert taught a seminar on the Citizen Lab’s work to Northwestern University undergraduates and delivered talks on digital authoritarianism at the Columbia University Graduate School of Journalism. Universities in the US had been subjected to funding cuts and heightened scrutiny from the Trump administration, and Deibert wanted to be “in the mix” at such institutions to respond to what he sees as encroaching authoritarian practices by the US government.

Since Deibert’s return to Canada, the lab has continued its work unearthing digital threats to civil society worldwide, but now Deibert must also contend with the US—a country that was once his benchmark for democracy but has become another subject of his scrutiny. “I do not believe that an institution like the Citizen Lab could exist right now in the United States,” he says. “The type of research that we pioneered is under threat like never before.”

He is particularly alarmed by the increasing pressures facing federal oversight bodies and academic institutions in the US. In September, for example, the Trump administration defunded the Council of the Inspectors General on Integrity and Efficiency, a government organization dedicated to preventing waste, fraud, and abuse within federal agencies, citing partisanship concerns. The White House has also threatened to freeze federal funding to universities that do not comply with administration directives related to gender, DEI, and campus speech. These sorts of actions, Deibert says, undermine the independence of watchdogs and research groups like the Citizen Lab.

Cohn, the director of the EFF, says the lab’s location in Canada allows it to avoid many of these attacks on institutions that provide accountability. “Having the Citizen Lab based in Toronto and able to continue to do its work largely free of the things we’re seeing in the US,” she says, “could end up being tremendously important if we’re going to return to a place of the rule of law and protection of human rights and liberties.”

Finian Hazen is a journalism and political science student at Northwestern University.

The sunshine vitamin could affect your immune system and heart health.

The experimental model won&#39;t compete with the biggest and best, but it could tell us why they behave in weird ways—and how trustworthy they really are.

As early electric cars age out, hundreds of thousands of used batteries are flooding the market, fueling a gray recycling economy even as Beijing and big manufacturers scramble to build a more orderly system.

Four ways to think about this year&#39;s reckoning

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-60')">
            <div class="source">The Next Web</div>
            <div class="title">A New Era for TNW.</div>
            <div class="meta">2025-12-22</div>
        </div>
        
        <div id="content-60" style="display:none;">
            <h2>A New Era for TNW.</h2>
            <p><strong>The Next Web | 2025-12-22</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/a-new-era-for-tnw">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">My name is Alexandru Stan, and this article continues the dialogue I began following the acquisition of TNW.

Following the recent transaction, TNW Spaces remains with the Financial Times, while we continue the mission of the website, the events, and the global community.

We already have a dedicated team at tekpon operating the platform, events, and community initiatives. Our objective is to expand and strengthen the team as TNW accelerates its next chapter.

TNW is already a global media platform with millions of readers. We’re not starting over. We are building forward.

The latest rumblings from the EU tech scene, a story from our wise ol&#39; founder Boris, and some questionable AI art. It&#39;s free, every week, in your inbox. Sign up now!

Technology is entering a decisive stage: AI is reshaping workflows, distribution is shifting, capital is becoming more selective, and founders are expected to demonstrate value rather than potential.

The world doesn’t need more noise.
It needs clarity, execution, and access to trustworthy knowledge and people.

TNW will serve that need through editorial independence, real expertise, and community-built intelligence.

Success for TNW looks like this: more accurate understanding, faster access to verified knowledge, and direct pathways from insight to action.

I’ve been an entrepreneur since 2007, building in B2B SaaS, marketplaces, and scalable systems. I believe deeply in servant leadership. Without people, I am zero.

I lead two private networks grounded in practice rather than theory:

These groups ensure TNW remains rooted in lived experience, informed by operators, not commentators.

Our mission is to build the most trusted European tech media platform with global reach, focused on practical innovation, responsible scaling, and transparency.

We will continue to host events across Europe’s major capitals including Paris, London, Berlin, Amsterdam, and Monaco.

These will not be festivals. We are introducing a concept validated through tekpon events: curated gatherings built for meaningful relationships, deep content, and tangible business outcomes.

In 2026, we return to Amsterdam for a special edition centered on AI among other fields. We will explore technologies and strategies shaping the future of work and business:

The editorial focus remains European, while the audience is global.

AI is not a threat to publishing. It is the infrastructure of the next generation of content and knowledge.

At TNW, we will use AI to accelerate research, enable personalized intelligence, reduce noise and bias, and amplify high-quality human expertise. Technology assists. Human judgment remains central.

Because this moment in Europe matters.
Because founders here are ready to scale responsibly.
Because independent media with integrity is rare.
Because innovation deserves a platform built around people, not hype.

TNW will continue its legacy with a renewed emphasis on contribution, execution, and community built through trust.

If you are building, scaling, or researching the next wave of technology, I invite you to engage with us, contribute insights, and participate in shaping the conversation.

The next era begins now. Let’s shape it together.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-61')">
            <div class="source">The Next Web</div>
            <div class="title">Engineering’s AI reality check</div>
            <div class="meta">2025-12-19</div>
        </div>
        
        <div id="content-61" style="display:none;">
            <h2>Engineering’s AI reality check</h2>
            <p><strong>The Next Web | 2025-12-19</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/engineerings-ai-reality-check">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Most engineering leaders cannot answer the one question their CFO is about to ask: “Can you prove this AI spend is changing outcomes, not just activity?”

Every December, roadmaps get locked, budgets get approved, and board decks are polished until everything looks precise and under control. Underneath, many CTOs and VPs are still working with partial visibility. They have a feel for their teams, but not a reliable view of how work moves through the system, how AI is really changing delivery, or where time and money actually go.

For a while, that was survivable. Experience, pattern recognition, and cheap capital covered the gaps. You could hire around bottlenecks, overstaff critical teams, or quietly pivot away from the messiest parts of the system. Then AI showed up and became the perfect distraction. Pilots, PoCs, Copilot seats, and “AI initiatives” created visible activity and bought time.

In 2026, that grace period ends. Boards and CFOs are shifting from “show me you are experimenting” to “show me measurable impact, this year.” Not because they stopped believing in AI, but because the market no longer rewards vague promises. Every AI dollar will need a traceable path to productivity, quality, or customer value.

If you run engineering, you probably recognise this scene. You present a slide with AI highlights. Adoption is up. Developers say they like the tools. You share a few anecdotes about faster coding and smoother reviews. Then the CFO asks a simple question: “Exactly how is this budget changing output and outcomes?”

TNW City Coworking space - Where your best work happens

A workspace designed for growth, collaboration, and endless networking opportunities in the heart of tech.

What is almost always missing is a clear breakdown of:

So the conversation slips back to learning curves, compounding benefits, and talent attraction. All true, but too soft for a tough budget review. That will not be enough.

AI vendors love task-level numbers. A coding task completed 55 percent faster looks impressive on a slide. But once you zoom out to teams and systems, the picture changes.

Large datasets across thousands of developers show a consistent pattern:

The problem is not the tools. It is the lack of a system for where the “extra” capacity goes.

Most organisations still frame AI productivity in terms of speed: more story points, more tickets, higher deployment frequency. That misses the bigger question:

How much of our engineering capacity goes to net new value versus maintenance, incidents, and rework, and is AI improving that mix?

High-level benchmarks are blunt but helpful. On average, about 45 percent of developer time is spent on maintenance, minor enhancements, and bug fixes rather than on genuinely new, customer-facing work. If AI helps you produce more code inside an unchanged system, you risk:

That is how you end up with impressive local metrics and a leadership team that still feels like engineering is slowing down.

If you want to walk into a 2026 budget conversation with objective evidence, you need to be deliberate about how AI-driven time savings are used. Two moves matter.

AI is already good at boilerplate, tests, documentation, and simple refactors. The trap is treating the saved time as unstructured “extra” capacity that disappears into the noise. Instead:

When teams systematically reduce technical debt and improve tests around critical flows, they cut future incidents and rework. Over a year, that frees more capacity for new work than shaving a few minutes off each ticket ever will.

2. Point AI at the ugly, high-friction work that commonly blows up roadmaps

The biggest productivity wins are not in everyday code generation. They are in:

These activities steal weeks or months of capacity and stall strategic initiatives. Using AI to understand legacy code faster, propose refactoring plans, generate migration scaffolding, and highlight recurring failure patterns can dramatically compress timelines for this work.

In parallel, there is real leverage upstream in the problem space. Teams that reach higher levels of AI adoption report better gains when they:

That reduces wasted builds and focuses effort on changes customers actually care about. The most significant gains do not come from replacing human creativity, but from amplifying it and aiming it at better-defined problems.

DORA metrics are not the enemy. Deployment frequency, lead time, MTTR, and change failure rate remain among the best signals we have for delivery performance. The risk is mistaking them for the whole picture.

Leading organisations are already expanding their scorecard to include:

In 2026, the question in the boardroom will shift from “Are we elite on DORA?” to “How much of our capacity is going into things customers notice, and is AI improving that mix or not?” To answer that cleanly, DORA is necessary but not sufficient. You need a way to connect AI usage, workflow, quality, and business outcomes across the system.

This is where engineering intelligence platforms move from a nice-to-have to mandatory. The organisations that win in 2026 will not do it with one more AI tool or one more disconnected dashboard. They will do it by pulling together data they already have but rarely use in one coherent view:

From there, leaders can answer the questions that actually matter:

Instead of defending AI spend with anecdotes, you walk in with:

That is the difference between “we believe in AI” and “here is how AI changed our delivery engine in measurable ways.”

To be ready for the more complex questions coming next year, use this planning cycle to do four things.

Do this, and you will not just have “AI activity” to show in 2026. You will have a credible, data-backed story from AI spend to business outcomes.

The leaders who thrive next year will not be the ones with the flashiest AI demos or the loudest “AI strategy” slide. They will be the ones who:

Engineering intelligence platforms is a key part of that shift. They give you the complex data to show where time and money go, how AI is really changing delivery, and whether your current pace is sustainable. The shift to data-backed engineering leadership is happening either way.

The gap in 2026 will be between teams still guessing and teams that can prove, in detail, how their engineering organisation works.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-62')">
            <div class="source">The Next Web</div>
            <div class="title">Letter from the Editor-in-Chief</div>
            <div class="meta">2025-12-16</div>
        </div>
        
        <div id="content-62" style="display:none;">
            <h2>Letter from the Editor-in-Chief</h2>
            <p><strong>The Next Web | 2025-12-16</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/letter-from-the-editor-in-chief">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Not long ago, like many of you, I read what I feared might be The Next Web’s final article. In late September, TNW’s co-founder announced that the tech conference and news site would be winding down, no more events, no new stories. It felt like the end of an era; the news hit hard!

Yet, just a few weeks ago, a twist arrived: the tech platform Tekpon acquired 100% of TNW’s media and events brand from the Financial Times, ensuring that this nearly two-decade legacy will continue to thrive.

While, myself, trying to read people’s opinions on this topic, I read this comment in one article, from one former TNW editor-in-chief that said: “The Next Web shaped my career, my life… it’s very sad to see it die”.

The latest rumblings from the EU tech scene, a story from our wise ol&#39; founder Boris, and some questionable AI art. It&#39;s free, every week, in your inbox. Sign up now!

I asked myself: Why do we always assume that just because one chapter ends, the whole story is over? Yes, taking over TNW is a heavy inheritance, especially with all eyes on us and expectations sky-high.

And I’ll admit, doubts crept in: Am I too small for this? Could someone more experienced do it better? Probably. But here I am, stepping up regardless. Because this isn’t just another blog or brand; TNW is a living ecosystem, a vital community. Its story deserves to continue, and I’m determined to help write the next chapter.

I also know some of you might be wondering: Who is she? What does she know? How many articles has she written? What recommends her?

Before reading all sorts of titles and, let me briefly introduce myself.

I’ve been writing since high school, with thousands of articles under my belt; covering everything from culture, art, and hip hop to design, politics, history, and food. I landed my first content writer job at 18, and alongside writing I pursued another passion: becoming a chef.

(Fun fact: I even made it to the semifinals of MasterChef, a journey that taught me about creativity under pressure and staying cool when the heat is on.)

Now, I channel my storytelling skills into helping businesses better understand technology and use it to their advantage. I help companies tell their stories, the real ones, finding meaning and flow in every word.

Over the years, I’ve specialized in blending creative storytelling with the technical precision of a chef’s knife. (My colleagues at Tekpon might say I can be as sharp as that knife – true to my values and quick to cut through the nonsense.) I am also the “No, we have to do it right” person in the team.

I’ve reviewed countless software products, interviewed founders, and explored how digital innovation can be a force for good in society. Or not. In other words, I’ve always cared about the why behind the tech, the real impact on people’s lives, not just the buzz. That perspective will be behind every story we will publish at TNW.

If there’s a place for those who still think stories written by humans matter, tell me where it is. I’m already on my way.

I’m not here to change TNW’s DNA; I’m here to reinforce it with fresh energy and a clear vision for the future.

To the loyal TNW readers, to the startup founders who looked to us for inspiration, to the healthy tech skeptics who counted on us for a reality check, and to our global audience spread across continents: we hear you.

We all know the world of tech news has changed dramatically. Today, everyone has a megaphone, social media overflows with hot takes, and AI algorithms can crank out content in seconds. It’s easy to feel overwhelmed by this sea of opinions and auto-generated articles. In such a world, the role of a publication like TNW is more critical than ever: to be a filter, not just another firehose of content.

We will focus on curation and clarity, distilling the noise so you don’t have to.

Here’s the good news: despite the deluge of AI-written text out there, readers are actively looking for authentic, human journalism. Every article we will publish will be created by a human writer who is accountable for the facts and who brings context, analysis, and yes, a bit of personality too.

Our mission isn’t to chase every trending headline algorithmically; it’s to help you understand which innovations actually matter, and why.

If a story is everywhere but lacks substance, we won’t regurgitate it; we’ll analyze it or debunk it. If a breakthrough is genuinely promising, we’ll explain why it’s important and how it impacts real people. Being a thoughtful filter in this age of information overload (and AI-generated noise) isn’t just a catchy slogan for us; it’s a responsibility we embrace.

You’ll also notice something different in our approach: an emphasis on storytelling and the human side of tech. Technology doesn’t exist in a vacuum; it’s built and used by people with dreams, dilemmas, and diverse backgrounds.

I believe, and I suspect many of you do too, that the best tech journalism zooms out from the gadgets and code to highlight those human stories. Practically speaking, expect to see more features, interviews, and narrative-driven pieces on TNW.

We’ll talk to founders about the messy, human journey of building a startup, not just the press releases or funding announcements. We’ll spotlight the engineers, designers, and thinkers who are trying to solve big problems (or even small ones that make a big difference). We’ll explore tech’s impact on society: the good, the bad, and the complicated.

This won’t be a place for recycled press releases or surface-level takes. It will be a place for conversation and insight.

Importantly, none of this focus on storytelling means we’ll skimp on rigor. Being engaging doesn’t mean sacrificing accuracy or depth. My team will continue to prioritize thorough research and fact-checking, those good old-school journalism values, even as we experiment with new formats and new voices. In short, we won’t publish anything we wouldn’t want to read ourselves.

Today, looking forward means acknowledging that how we cover tech is as important as what we cover. It means committing to journalism that cuts through the clutter, to storytelling that puts people first, and to a vision of tech’s future that is both hopeful and honest. That’s my vision for TNW as I step into this role, and I hope it resonates with you.

Now, I’d like to turn it over to you, our community. This is your TNW as much as it is ours. I invite you to join the conversation. Tell us what you want to see more of (or less of). Hold us accountable,if we ever fall short, let us know. Share your stories and perspectives with us, because they can inspire our coverage.

In the coming weeks, you’ll start to see this vision take shape on the site. You’ll see familiar faces and new voices. You’ll find articles that make you think, others that make you smile, and hopefully quite a few that make you proud to be a TNW reader.

Whether you’re a long-time follower who’s stuck with us through thick and thin, a startup founder looking for insight, a skeptic keeping us honest, or a curious mind tuning in from anywhere in the world – thank you. We do this for you, and we couldn’t do it without you.

The Next Web is back. We’re here to inform you, inspire you, challenge you, and occasionally even surprise you. I’m honored to have you with us on this journey. Here’s to the road ahead, to storytelling, to journalism (the real kind), and to making sense of the future together.

Thank you for reading, and welcome to TNW’s next chapter. Let’s build it, day by day, story by story, together.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-63')">
            <div class="source">The Next Web</div>
            <div class="title">Is ChatGPT’s New Shopping Research Solving a Problem, or Creating One?</div>
            <div class="meta">2025-12-11</div>
        </div>
        
        <div id="content-63" style="display:none;">
            <h2>Is ChatGPT’s New Shopping Research Solving a Problem, or Creating One?</h2>
            <p><strong>The Next Web | 2025-12-11</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/is-chatgpts-new-shopping-research-solving-a-problem-or-creating-one">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">When OpenAI announced its new shopping search capabilities, I took the news with a grain of salt (perhaps the whole shaker).
For the past decade, we have watched the slow evolution of traditional search engines. What began as tools for pure information discovery gradually morphed into ecosystems dominated by SEO-optimized content and sponsored results. My initial fear with ChatGPT’s update was simple: Are we seeing the beginning of a similar shift? Is the purity of the “reasoning engine” being diluted by the necessity of commerce?
After testing the new shopping integration, the results suggest that we are at a pivotal moment in the user experience of Generative AI, one that requires an open discussion about what we actually want these tools to be.

The defining characteristic of Large Language Models (LLMs) is their ability to handle nuance. When we interact with ChatGPT, we expect a Socratic dialogue. We expect the AI to ask clarifying questions to narrow down our intent.
To test this, I entered a simple prompt: “I want to buy a vacuum.”
I anticipated a conversation, questions about my home’s square footage, my floor type, or my budget. Instead, the conversational nuance was replaced by a display that felt familiar: a grid of product photos, names, prices, and direct links to retailers.

While efficient, this experience felt like a regression. It mirrored the “keyword search” experience of Web 2.0 rather than the “intent-based” promise of GenAI. It replied to my prompt, but it stripped away the intelligence.

Scrolling down, I engaged with the new feature in a call to action: “Research the best vacuums.”
This is where the user experience (UX) friction became most apparent. Rather than synthesizing data or comparing technical specifications in a chat format, the tool presented a polling interface designed to filter results.

The latest rumblings from the EU tech scene, a story from our wise ol&#39; founder Boris, and some questionable AI art. It&#39;s free, every week, in your inbox. Sign up now!

The experience is oddly time-sensitive; pause too long to think or drink water, and the screens will skip forward, dumping you back into a list of product cards.
The interface presents products with a binary choice: “More like this” or “Not interested.” It offers brand names and price tags, but virtually no information to help the user actually make a choice.

For a user seeking genuine research, being presented with a list of brands and prices without deep comparative analysis feels like a missed opportunity.
It raises a question: If I wanted to filter products by price and brand, wouldn’t I use a traditional retailer? The value proposition of Gen AI should be synthesis, not just aggregation.

The Tension Between Reasoning and Revenue
This update highlights the inevitable tension facing major AI companies: the balance between user utility and business sustainability.
As OpenAI scales, the pressure to demonstrate revenue models to investors is natural. However, there is a risk in prioritizing transactional features before the core product, reasoning and logic, is fully matured. By introducing a shopping experience that feels closer to a “click-through” engine than a “knowledge” engine, the platform risks blurring its own identity.
Is ChatGPT a research partner that helps me think? Or is it a shopping assistant trying to speed me to checkout?

To be clear, I believe there is a place for shopping within AI. But the execution matters.
A truly Generative AI shopping experience shouldn’t just list products; it should understand the user. It should read between the lines of a prompt to understand that a user asking for a vacuum might actually be solving a problem about pet hair or allergies.

The current iteration feels like a beta test of a business model rather than an evolution of intelligence. As we move forward, the hope is that OpenAI will refine this tool to prioritize the “Chat” over the transaction. We don’t want it to be just another place to see ads. We need a better way to make decisions.

Viviane Mendes is a growth strategist and innovation leader with more than 20 years of experience driving technology-enabled transformation across global markets. She has led initiatives integrating AI-driven strategies, digital transformation, and scalable business innovation for companies such as PSINet, MP3.com, Match.com, UOL and Best Buy Canada, and founded Vitrinepix, one of the first print-on-demand e-commerce platform, later acquired by Spreadshirt. Committed to lifelong learning, Viviane is now focusing on applying emerging technologies to foster digital literacy, responsible AI adoption, and positive human impact.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-64')">
            <div class="source">The Next Web</div>
            <div class="title">Tekpon acquires TNW (The Next Web) brand from The Financial Times</div>
            <div class="meta">2025-12-08</div>
        </div>
        
        <div id="content-64" style="display:none;">
            <h2>Tekpon acquires TNW (The Next Web) brand from The Financial Times</h2>
            <p><strong>The Next Web | 2025-12-08</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/tekpon-acquires-tnw-the-next-web-brand-from-the-financial-times">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Tekpon has acquired 100% of the TNW media and events brands, which cover and convene the European technology ecosystem, from the FT.

The transaction is Tekpon’s largest investment in media and events so far. It broadens the company’s reach across SaaS and AI and strengthens its role in the global innovation landscape.

TNW’s brand and editorial standards will be maintained, while its events and digital platforms will be integrated into Tekpon’s wider strategy.

The FT will continue to own and operate TNW Spaces, Amsterdam’s dynamic tech hub, offering private offices and coworking spaces that support a thriving community of startups, scale-ups, and innovators.

The latest rumblings from the EU tech scene, a story from our wise ol&#39; founder Boris, and some questionable AI art. It&#39;s free, every week, in your inbox. Sign up now!

Alexandru Stan, Founder and CEO of Tekpon, said:

TNW is one of Europe’s most respected technology brands. Its legacy, its community, and its influence have shaped the European tech scene for nearly twenty years. This acquisition accelerates our mission to connect the global SaaS and AI ecosystem and supports Europe’s position in the next decade of innovation.

Tekpon will begin working on TNW branded initiatives immediately. Plans for 2026 include an expanded TNW Conference, new SaaS and AI program tracks curated by Tekpon, cross-regional executive programmes, and specialised gatherings for founders, executives, and investors.

The acquisition is part of Tekpon’s long-term plan to build an international ecosystem connecting software, media, events, advisory, and innovation.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-65')">
            <div class="source">The Next Web</div>
            <div class="title">Ending graciously</div>
            <div class="meta">2025-09-29</div>
        </div>
        
        <div id="content-65" style="display:none;">
            <h2>Ending graciously</h2>
            <p><strong>The Next Web | 2025-09-29</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/tnw-boris-signs-out">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">This article was published on September 29, 2025

A few decades ago, when I was raising funding for a startup, I made a lasting impression on an investor by not only talking about how successful we would be, but also highlighting what would happen if we weren’t. Later, in an informal setting, I asked him what had persuaded him to invest in us. He told me that during the pitch, I had said, “And if all our predictions and expectations are wrong, we will use the last of our funding for a magnificent farewell dinner for all our investors. You’ll have lost your money, but at least you’ll get a great evening for it in return.”

I don’t recall this being part of the original pitch or my strategy. I probably just blurted it out to break the ice, but it impressed the investor. He told me it was refreshing to speak to an entrepreneur who was not blinded by his own pitch. The fact that I had a scenario ready for both success and failure told him that I was honest and realistic.

Now, the startup was not successful, but we still had a nice, opulent dinner with the investors at the end — and we did them one better. As soon as we realised that our predictions and expectations were wrong, we made our investors an offer: we could struggle and pivot and hope for a miracle, or we could return what was left of our funding to our investors. We preferred option two, and so did they, so everybody got some money back (about 40% of what they had invested), as well as a lovely evening with excellent food and drinks. When we raised money for another startup a few years later, almost all of them signed up in our first round.

Obviously, I would have preferred to have made this startup a success instead, but I still regard it as a successful endeavour. I gave it a try and had a plan ready for when my experiment didn’t work out, and in the process, I built relationships that outlasted that one startup.

TNW City Coworking space - Where your best work happens

A workspace designed for growth, collaboration, and endless networking opportunities in the heart of tech.

As you may have read, The Next Web, the company I founded in 2006, is nearing the end of its lifecycle. The events and media business is being wound down, and only TNW Spaces will live on. TNW Programs was sold off a while ago and will continue as well. There won’t be another TNW Conference, and soon there won’t be new articles on the site; people are losing their jobs, including me. It’s a painful process, but I guess I’m taking it well because it also feels natural and logical. When we sold TNW to the FT in 2019, we were very ambitious and optimistic, and surely I would’ve liked for the company and brand to outlive me. However, when the business struggled, I also felt very comfortable with the company ending graciously.

When you’re reading a good book, there’s a moment near the end when you’ll start reading slower because you don’t want it to end. I love those moments, because I’ll know it’s been a good experience. But then you also know that good stories need good endings. So, this is the ending of a great story that I’ve enjoyed participating in.

I’ll keep writing, but this will be my last official TNW story. I’d love it if you would subscribe to my writing over at Substack. It will be less tech-focused, more unpredictable, but just as insightful as before.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-66')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">Eurostar suspends Channel Tunnel services after power supply issue - Reuters</div>
            <div class="meta">2025-12-30</div>
        </div>
        
        <div id="content-66" style="display:none;">
            <h2>Eurostar suspends Channel Tunnel services after power supply issue - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2025-12-30</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiuwFBVV95cUxOUmxJTzJ4Mkp2LW5XcW9KbTk0VXdnd1J0VGh4ZTJnN1dlTkttcGJjRmVwNHVWWkxldkd6eWhob09uSkNNWTZ2cm9mWlJlckZZdmNnbkE0cGd3RjBKb19yVHM0Zm0yV3ZuZnNNUEplN1p5cWY4UUR6a1ZLc0tpRGNvZTRXcVVILWRNcm01SGE3SGxMdDZUVUFXQ2VRZGNzc3FMZzBPSGZ0MUxvbEFkU2NCWWtTR0wwaTZyb1Qw?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-67')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">From brothers to rivals: Key moments in Saudi-UAE relations​ - Reuters</div>
            <div class="meta">2025-12-30</div>
        </div>
        
        <div id="content-67" style="display:none;">
            <h2>From brothers to rivals: Key moments in Saudi-UAE relations​ - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2025-12-30</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiowFBVV95cUxQblVCUDVxNHh5S0xjQS1EcHRuMVVFYm9CQ1pvOFZJVWVoVThhcWNMYmtVNV81QjdVNDJ5blkwdmdSWHlia0RYbEdySnVhWkR1YlhicUd0Rkk2eTR5WWlCUmFTdjRiRVdMalNrWmJERzM3SDJibkJ2YXl0dnJRSlhNdW1ZUUpjQk4xZXZWbDFlN2YweWgtOUdQYkdJQ3FFTEppYjdz?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-68')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">Russia says its negotiating stance on Ukraine will toughen after accusing Kyiv of attack - Reuters</div>
            <div class="meta">2025-12-30</div>
        </div>
        
        <div id="content-68" style="display:none;">
            <h2>Russia says its negotiating stance on Ukraine will toughen after accusing Kyiv of attack - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2025-12-30</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMivAFBVV95cUxNLVpHeHlzXzctZEVlYlNvbUp5dFM4bkJLZkppWXNVdjZYZTJSc1lDdTZNLVhyMFJpVXZfOWdIMVRjaDA1VFE5NDFHd2RBOVJzMlZZZFVMc3Y5R1JkNUU3UERPcDBKTDJMNnZMVVE3aDJsU3RBcTVhVUR0enpybC1yMHBvbGt6cjlXVFJ2VmNtRTFINlJnaFA5Q2ZWWFdiSzdVeG9DTHBoWkNScW92TkU4bHlVSkIwMXRISTVwMg?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-69')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">Russia's pipeline gas exports to Europe fall by 44% to the lowest in decades - Reuters</div>
            <div class="meta">2025-12-30</div>
        </div>
        
        <div id="content-69" style="display:none;">
            <h2>Russia's pipeline gas exports to Europe fall by 44% to the lowest in decades - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2025-12-30</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiswFBVV95cUxQS1dlSEYyLVljUWQ2MVUyWXVkQXVZNVpiY0V1NWNMR0ZwUERMR2VBOFVTVUVZTHFna3pEMlo3eDdHRGhCbWpDZ01ZbHZ4bTVXNlBpcE0wQngwa09DM0pLemJ0WXZZcW9NVklDMDNXNlpjOS1PMWp0S0ctSl81SUFRY1RHTkFBcXk4ZjF3cm9uWmhNN3YyNml0UWF3Q21LMHZtNDd2dFBxbGI3UnRIRHNBRlZSYw?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-70')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">Exclusive: China mandates 50% domestic equipment rule for chipmakers, sources say - Reuters</div>
            <div class="meta">2025-12-30</div>
        </div>
        
        <div id="content-70" style="display:none;">
            <h2>Exclusive: China mandates 50% domestic equipment rule for chipmakers, sources say - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2025-12-30</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMisgFBVV95cUxQSjMySE96WEh2Vl8xdlRrN0xub3FHWktNY196cjFSNnFtSHVEemc2UEVsNnQ2cm8wd2NSWWN2MjlXTm5fbTl3aHI1MWZNSzNxYklFWEd5Q3RBME9iNzRNaXFnMm5mUzhudE5QRE1mWXRhMXJwekpPUjhybE41eUlhZ3M5SXF0LXdrUG16T2twSGhVWWdQeWJncEVWcTN6dDB6enpTcHluYk9KWEVmdURKVmFR?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-71')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">Final Fed minutes of 2025 to shed light on policy divisions - Reuters</div>
            <div class="meta">2025-12-30</div>
        </div>
        
        <div id="content-71" style="display:none;">
            <h2>Final Fed minutes of 2025 to shed light on policy divisions - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2025-12-30</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMimwFBVV95cUxPM1BPWWhCT09oc1ZsNHRiZ1VHT2s5VEJlMHFjRHBCRGRNNkptWkJqX0hRTEstU0pnTlMyby1VVEJqc3RjbjV4eW5qbVRnUXVRU0NNNDdienVJWWZNT3pPR2JlLWpZQ2hpc2xTbnprZXlNTjJ4YnhGam5pRWFzVHhtWXdlVHZXN0RQRXNOX04zM2RNaDA0LWJrenBYYw?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-72')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">Science of Consciousness: The Most Intriguing Discoveries in 2025 Involving Neuroscience and the Mind - The Debrief</div>
            <div class="meta">2025-12-28</div>
        </div>
        
        <div id="content-72" style="display:none;">
            <h2>Science of Consciousness: The Most Intriguing Discoveries in 2025 Involving Neuroscience and the Mind - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2025-12-28</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiwgFBVV95cUxPUGJnOXJuV0VmaDZfU0VTdHJqdm04ZThnTzhaSXJiSzdYT3k5cnRPdHE2ampJSjBfN2VmelhjYXVfWHdmcmJSd0FjNFljWU5xU1I4Y2xKMzlrMWhSWW5wc1QxMjR4LWFxcGg0bHNSclVyaS0zbkl1dzBFZ09CdWtOUWpfdmZ1YmQ2dERQWnBQTGp3NzBVUVFHUmNfRWsweU9uU2VyMXduSThlUmdudk9RWmt6NmdWYjhBYlc5N0YzTnYtUQ?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-73')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">A New Theory Suggests Mass May Emerge From Invisible Dimensions - The Debrief</div>
            <div class="meta">2025-12-23</div>
        </div>
        
        <div id="content-73" style="display:none;">
            <h2>A New Theory Suggests Mass May Emerge From Invisible Dimensions - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2025-12-23</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMikAFBVV95cUxPTFNSQWZDVm5jTkRTaTNMb3p2Y2dGcnZ5bHFnRHhDcGZHT3M0VzZWZzcyNEpiZ284QUowZjhaYkFwTU8zRHdLSUlCY0ZXd2NpRnRDZ2JwOFBQNi1oWHZsZzBoM25iak5rTlhMc0wxSmhXbUh3NmdIQ2FRd2I0blVHamVJckY1V2NCbWVnMjRScXg?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-74')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">“Cosmics” and “Phantoms”: Ukrainian Independent Study Reveals Observations of Unidentified Aerial Phenomena - The Debrief</div>
            <div class="meta">2022-08-26</div>
        </div>
        
        <div id="content-74" style="display:none;">
            <h2>“Cosmics” and “Phantoms”: Ukrainian Independent Study Reveals Observations of Unidentified Aerial Phenomena - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2022-08-26</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMixAFBVV95cUxOWWZHN3JWVE42ZlI4eTRKUnVIX0h0MlAwM25SMFExVlRGVThjNVdicEF3dnNHUXd2VjBGTU5fVE5SUnBTU2hKNUk2MmNjaXVzZnhKTFZDeEp3elV0RGRsVnk3cHdCbDZySld1eFNqOEoyQVh0YU81cXJOeTRSZ3MxZ281RHlTdE1SR2JKOXVMYXFGZm5EX3lVZ2tsaEo1bEYxTU5pWmVYSlJlMjl3S1hxRG1BLW9qRGJSaTItbXl3MDlWVUZT?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-75')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">A Robot Vanished, Then Mysteriously Reappeared Near Antarctica—Now Researchers Reveal What It Discovered While It Was Missing - The Debrief</div>
            <div class="meta">2025-12-23</div>
        </div>
        
        <div id="content-75" style="display:none;">
            <h2>A Robot Vanished, Then Mysteriously Reappeared Near Antarctica—Now Researchers Reveal What It Discovered While It Was Missing - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2025-12-23</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMi4gFBVV95cUxNQmp2ZEdyaGk5elg2aThfWU5NbnVvSnlVYkJkaGNKRzNjLUtmalZoMmk0Z0JIeF9OLVJXUVBNTXhJLTR1TlFpWmRBUTc2U1NSVVJ4YkxSdlg4Y3RBc3hFdzBHelhEaVBISjVOSzlnQ19lYUxrYUVDVTh1NEtCSkY3YWN1VVFGdUdqVV9PZmduWFhoektxUDFPZ0xqNnM3ZEJiSWp1LTQwa0o1UUpiYTczUWwzYWNiZFZ4ZlhYZmFrQ00zZm5nVjJmRVJ6aFFuSjlaUlJXb18td0VFdWVFMEN4NUxR?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-76')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">Archaeology in 2025: Here Are Several of This Year’s Most Fascinating Ancient Discoveries - The Debrief</div>
            <div class="meta">2025-12-27</div>
        </div>
        
        <div id="content-76" style="display:none;">
            <h2>Archaeology in 2025: Here Are Several of This Year’s Most Fascinating Ancient Discoveries - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2025-12-27</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMisAFBVV95cUxPZXh4QUVjMlVqWHB6RUxjWUhhVXRLaXNxbWVJNlkzZldBdE91RWxjUE5abWdQT1VKUkJSQkFRTW5lV3NqQU1uNkNoZmxRcHV6VTR4Wm1udlVDeWZtcmE2RjlMMlhWOG00dkZvV2czRzU3WDRMT3J6NWRaQ2NGTTZ1bmxsMUJKVHdNU1VCdmI4NDZ4YXlPTFAzb2hzcm9zR2Zrb3YyZGFOTnkwb1NnZlhhUg?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-77')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">“This Will Be a New Chapter in Quantum Physics": Odd Quasiparticles May Explain a Pair of Quantum Experiments That Baffled Scientists - The Debrief</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-77" style="display:none;">
            <h2>“This Will Be a New Chapter in Quantum Physics": Odd Quasiparticles May Explain a Pair of Quantum Experiments That Baffled Scientists - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2025-12-26</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMi6gFBVV95cUxPUlYyVWtNWWNWMlNGWmpZb0hOZ2NBdWgwTEZZY1FnV1BURHF6ZW5SUFRDRm9SaU9ZdVVuc3FvZEsydk9SanhaWk4zbWdibGxqcExrRHFvN1lUb2NBclRUV05vczczUzBVbmhPUlRrSTE4bzlHV2NpaFo2Wmc0a2FGdF9nS2ZLMm9WbzFYa2puY2VTdjRvaVVzQ08zNXhnOGlSQUxVOHBEV0xNdG5JYzE5MWhid0dhdlhraXhGRVNTak5zV2hxeFZKdjlGaVZUQjFXMno3TnVyYzNUTnNUcU5oTG1HS0pYZTZBV3c?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-78')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">Meta Acquires Manus AI Agent - The Information</div>
            <div class="meta">2025-12-29</div>
        </div>
        
        <div id="content-78" style="display:none;">
            <h2>Meta Acquires Manus AI Agent - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2025-12-29</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMieEFVX3lxTE53YnUwTmxlVkE0V1NGLUdieW9DSVN4cVNNRWlFZHYwTGxUTnVNQjB6WGVHdTBJQWJwdzRqaUVpWFJRTnBSSjFnckZqVG1CYnZpMmRQUzRBN2pBcVp4NXB2NDkxTDFKSXJPTm1JWGJMWHRyYzg1N19lZQ?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-79')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">The Long Game Behind Waymo’s Potential $100 Billion Valuation - The Information</div>
            <div class="meta">2025-12-29</div>
        </div>
        
        <div id="content-79" style="display:none;">
            <h2>The Long Game Behind Waymo’s Potential $100 Billion Valuation - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2025-12-29</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMimwFBVV95cUxPYlVMeFhNcjRoTzNZMm5sckp6Z3o4b3NpSzZoV0ktNzdzc2E2U2FyMWYwYmNoRUVxREo2U1UxVVptWl9veHZ4cVJQYUxhTmpFVE5xT1k4V1hBb3Y1LWlSb18zYVpoandJNzNMcFlzcktySkxBQkJGUTN0cmZqbXpwVUxuMDZHeFpuVldRXzJYbmNoNGdRdnIzYnJCOA?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-80')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">OpenAI’s Ads Push Starts Taking Shape - The Information</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-80" style="display:none;">
            <h2>OpenAI’s Ads Push Starts Taking Shape - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2025-12-24</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiggFBVV95cUxNUE1HZHAzd1d4ZDhIU1JLdW44Rjg0QUJMN3U4TGdQRzBpckZsV0k3cEpWcnZ6V3B2VzRncG1DY2FPZFVDQXlPSDZXSnNsSk5kenk3Wl9tTDFzODBBSllVMkF1V0RqaS1aMVhmTmI4azVpQzhaSjFQUmlTZ0tRWGhadDlR?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-81')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">Stablecoin Startups Spark Trouble for JPMorgan - The Information</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-81" style="display:none;">
            <h2>Stablecoin Startups Spark Trouble for JPMorgan - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2025-12-26</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiigFBVV95cUxNLTJjWk8xckZBR0NMZ2pzbW9MYWg2aVNLQldSRU53cmFKaWJic2xSMjUzSERkbXZTSXI4eTdLclhCWFRXMzhGNmVtaHl3TW0wN1lQdDdsbllqUnZkdFpYS2luelUxNzRpNlEzRWNtSEFDT3p1V29EazU2Zmg2VlRZVEJ3cndyZ0lKQWc?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-82')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">Salesforce Executives Say Trust in Large Language Models Has Declined - The Information</div>
            <div class="meta">2025-12-19</div>
        </div>
        
        <div id="content-82" style="display:none;">
            <h2>Salesforce Executives Say Trust in Large Language Models Has Declined - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2025-12-19</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMimgFBVV95cUxNOTBxTUdBOUItc3ZrRzZUYWM5TTM0LWpSUmVEVk5SR1d0SVpYbm5ER1RNdVV3Nk45STJ2WVFpems5ZXVVMkxnZEpLVWFoTkRJVzhadGQ1ekVOT0xXeWUxRElhWE1MZm9PLVFHZjAyMTFyVllzTkR0cnJYTFhaaUtiX3A2RFM2SlFoczVVcGNRRWtpV2FKemNTQy1R?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-83')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">OpenAI Is Getting More Efficient at Running Its AI, Internal Financials Show - The Information</div>
            <div class="meta">2025-12-21</div>
        </div>
        
        <div id="content-83" style="display:none;">
            <h2>OpenAI Is Getting More Efficient at Running Its AI, Internal Financials Show - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2025-12-21</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiogFBVV95cUxQdmI2di13dk1valhrLTJ0dE5pemNJYVNEc3h0UENkX0wyMFZidU54cUlsZm1EYmxMaTdTQWphZmI3VzBpa0hDNUYyMUFteU0xZXBScUQ0MmZZYk1DR0lxV3k2X29BRFFhLU11YkoyZ25hNGp3VTRPejdpUWV3MTlpb29XZVk0R3cweGRlWHdxemhYdTdlenZwUC14UkMtUUhteFE?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        </div>

        <div id="reader-modal">
            <div id="close-btn" class="control-btn" onclick="closeModal()">X</div>
            
            <div id="scroll-controls">
                <button class="scroll-btn" onclick="scrollPage(-1)">&#9650;</button> <button class="scroll-btn" onclick="scrollPage(1)">&#9660;</button>  </div>

            <div id="modal-inner"></div>
        </div>

        <script>
            // 1. RANDOMIZE ORDER
            const list = document.getElementById('feed-list');
            const cards = Array.from(document.querySelectorAll('.card'));
            cards.sort(() => Math.random() - 0.5);
            cards.forEach(card => list.appendChild(card));

            // 2. DARK MODE
            const btn = document.getElementById('theme-toggle');
            btn.addEventListener('click', () => document.body.classList.toggle('dark-mode'));

            // 3. MODAL & SCROLL LOGIC
            const modal = document.getElementById('reader-modal');
            const modalInner = document.getElementById('modal-inner');

            function openModal(contentId) {
                const content = document.getElementById(contentId).innerHTML;
                modalInner.innerHTML = content;
                modal.style.display = 'block';
                document.body.style.overflow = 'hidden'; 
            }

            function closeModal() {
                modal.style.display = 'none';
                document.body.style.overflow = 'auto';
            }

            function scrollPage(direction) {
                // Scroll by 80% of the screen height to keep context
                const scrollAmount = window.innerHeight * 0.8;
                modal.scrollBy(0, direction * scrollAmount);
            }
        </script>
    </body>
    </html>
    