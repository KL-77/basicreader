
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>KL-77's Feed</title>
        <style>
            :root {
                --bg: #ffffff;
                --text: #000000;
                --border: #000000;
                --modal-bg: #ffffff;
                --dim: #666666;
            }
            
            body.dark-mode {
                --bg: #000000;
                --text: #ffffff;
                --border: #ffffff;
                --modal-bg: #000000;
                --dim: #aaaaaa;
            }

            body { 
                font-family: Georgia, serif; 
                background-color: var(--bg);
                color: var(--text);
                margin: 0;
                padding: 10px;
                font-size: 22px;
                line-height: 1.5;
            }

            header {
                display: flex;
                justify-content: space-between;
                align-items: center;
                border-bottom: 3px solid var(--text);
                padding-bottom: 15px;
                margin-bottom: 25px;
            }
            
            h1 { margin: 0; font-size: 1.2em; }

            button#theme-toggle {
                background: transparent;
                color: var(--text);
                border: 2px solid var(--text);
                padding: 10px;
                font-size: 18px;
                font-weight: bold;
                border-radius: 4px;
                cursor: pointer;
            }

            .card {
                border: 2px solid var(--text);
                margin-bottom: 25px;
                padding: 15px;
                cursor: pointer;
            }
            
            .source { font-size: 0.7em; font-weight: bold; text-transform: uppercase; color: var(--dim); }
            .title { font-size: 1.1em; font-weight: bold; margin: 8px 0; display:block; }
            .meta { font-size: 0.7em; color: var(--dim); }

            /* MODAL STYLING */
            #reader-modal {
                display: none;
                position: fixed;
                top: 0; left: 0;
                width: 100%; height: 100%;
                background-color: var(--modal-bg);
                z-index: 1000;
                overflow-y: scroll; /* Allow scrolling */
                scroll-behavior: auto; /* Instant scrolling for e-ink */
            }

            #modal-inner {
                padding: 25px;
                max-width: 800px;
                margin: 0 auto;
                padding-top: 80px; 
                padding-bottom: 150px; /* Huge padding so text clears the buttons */
            }

            /* Controls (Close + Scroll) */
            .control-btn {
                position: fixed;
                background: var(--bg);
                color: var(--text);
                border: 3px solid var(--text);
                border-radius: 8px;
                font-weight: bold;
                cursor: pointer;
                z-index: 1001;
                display: flex;
                align-items: center;
                justify-content: center;
            }

            #close-btn {
                top: 15px; right: 15px;
                width: 60px; height: 60px;
                font-size: 30px;
                line-height: 55px;
            }

            /* Scroll Buttons */
            #scroll-controls {
                position: fixed;
                bottom: 20px;
                right: 20px;
                display: flex;
                flex-direction: column;
                gap: 15px;
                z-index: 1002;
            }

            .scroll-btn {
                width: 60px;
                height: 60px;
                font-size: 24px;
                background: var(--bg);
                color: var(--text);
                border: 3px solid var(--text);
                border-radius: 8px;
                cursor: pointer;
            }

            #article-text { white-space: pre-wrap; font-size: 1.1em; }
            
            a.original-link {
                display: inline-block;
                margin-bottom: 30px; /* Space before text starts */
                padding: 10px;
                border: 1px solid var(--text);
                color: var(--text);
                text-decoration: none;
                font-weight: bold;
                font-size: 0.8em;
            }
        </style>
    </head>
    <body>

        <header>
            <h1>KL-77's Feed</h1>
            <button id="theme-toggle">Light/Dark</button>
        </header>

        <div id="feed-list">
    
        <div class="card" onclick="openModal('content-0')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">“Streaming stops feeling infinite”: What subscribers can expect in 2026</div>
            <div class="meta">2026-01-01</div>
        </div>
        
        <div id="content-0" style="display:none;">
            <h2>“Streaming stops feeling infinite”: What subscribers can expect in 2026</h2>
            <p><strong>Ars Technica - All content | 2026-01-01</strong></p>
            <a class="original-link" href="https://arstechnica.com/gadgets/2026/01/streaming-stops-feeling-infinite-what-subscribers-can-expect-in-2026/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">We’re far from streaming’s original promise: instant access to beloved and undiscovered titles without the burden of ads, bundled services, or price gouging that have long been associated with cable.

Still, every year we get more dependent on streaming for entertainment. Despite streaming services’ flaws, many of us are bound to keep subscribing to at least one service next year. Here’s what we can expect in 2026 and beyond.

There’s virtually no hope of streaming subscription prices plateauing in 2026. Streaming companies continue to face challenges as content production and licensing costs rise, and it’s often easier to get current customers to pay slightly more than to acquire new subscribers. Meanwhile, many streaming companies are still struggling with profitability and revenue after spending years focusing on winning subscribers with content.

“We see many services are only now aligning content spend with realistic lifetime value per subscriber,” Christofer Hamilton, industry insights manager at streaming analyst Parrot Analytics, told Ars.

Companies may get more creative with how they frame higher costs to subscribers, however. People who pay extra to stream without ads are the most likely to see price bumps as streaming companies continue pushing customers toward ad-based tiers.

Charging more for “premium” features—such as 4K streaming, simultaneous streams, or offline downloads—offers another way for streaming companies to boost revenue without implementing broad price hikes that risk provoking customer outrage. Subscribers can expect streaming prices to get “more menu-like next year,” said Michael Goodman, director of entertainment research at Parks Associates, a research firm focusing on IoT, consumer electronics, and entertainment.

If streaming prices won’t stop rising next year, when will they?

Ultimately, it may be up to subscribers to vote with their dollars by canceling subscriptions or opting for cheaper or free alternatives, such as FAST (free ad-supported streaming television) channels with linear programming.

As Goodman put it, “Until we see net adds stall or decline as a result of price hikes, services have no incentive to stop raising prices.”

Some experts doubt that streaming services will ever willingly stop increasing prices. Bill Yousman, professor and director of the Media Literacy and Digital Culture graduate program at Sacred Heart University, sees precedent for this in cable companies.

“If the big streaming companies had their way, there would be no limit to their price hikes. We have already seen this with the cable monopolies and their disregard for consumer dissatisfaction,” he said.

Yousman believes that prices will only “be brought under control if there is some type of government regulation,” but he noted that’s unlikely under the Trump administration.

To date, US lawmakers haven’t shown interest in halting the steady rise of streaming prices. Most lawmakers who have sought to regulate the industry have focused on industry consolidation. There has been some effort from lawmakers to rein in streaming price hikes, though, especially through proposed federal legislation dubbed the Price Gouging Prevention Act.

Companies will look to leverage subscribers’ frustration with pricing by being more aggressive about bundling third-party services like traditional pay TV, Internet, and cell phone service with streaming subscriptions. The idea is that people are less likely to cancel a streaming subscription if it’s tied to a different subscription (including another streaming subscription). The strategy echoes the days of cable, when some people kept unused landlines just to save money on cable channels or Internet service.

“For subscribers, 2026 is the year streaming stops feeling infinite and starts feeling more like premium cable used to: fewer apps, clearer bundles, and higher expectations for each service they pay for,” Parrot’s Hamilton said.

Thanks to traditional pay TV providers, bundles have a bad connotation among people looking to save money and simplify their subscriptions. But bundling doesn’t always have to be a bad thing, as Yousman explains:

If the companies wanted to really be responsive to consumers, they would let them design their own packages rather than having to choose options that may or may not include all the services they want. What works against this, of course, is the demand for ever-increasing profits at all times.

Should a sale of Warner Bros. Discovery’s (WBD’s) HBO Max be completed (late) next year, subscribers will face more pressure to bundle their streaming subscriptions.

“When dominant platforms like Netflix or Paramount absorb major content players, it accelerates the erosion of streaming’s original promise: freedom from monopolistic bundles,” Vikrant Mathur, co-founder of streaming technology provider Future Today, said.

WBD announced plans this month to sell its streaming and movie studios business to Netflix for an equity value of $72 billion, or an approximate total enterprise value of $82.7 billion. Paramount Skydance, however, quickly swooped in with a hostile takeover bid for all of WBD, including its cable channels, for $108.4 billion. A WBD shareholder vote will occur in spring or early summer, chairman Samuel Di Piazza told CNBC. By the end of 2026, we should have a clearer understanding of the future of HBO Max, as well as Netflix and Paramount+.

Any acquisition will be subject to regulatory scrutiny, causing more uncertainty for subscribers. If Netflix buys HBO Max, users of both services can expect higher prices due to reduced competition and the extensive amount of content and number of big-budget franchises (including Harry Potter and DC Comics) expected to unite under one platform.

“If Netflix gets [HBO Max] and the WB studios, HBO Max subscribers are more likely to see a smoother transition, strong ongoing investment in premium content, and simpler app/billing integration,” Parks Associates’ Goodman said.

But while the potential merger is worth watching, subscribers are unlikely to truly feel the impact of HBO Max potentially changing ownership until after 2026.

“Producing a show is a yearslong process, so the content that was already slated to air isn’t going to disappear, and the new content acquired through the WB library won’t be available until the merger is approved and closes,” Tre Lovell, attorney and owner of Los Angeles entertainment law firm The Lovell Firm, explained.

Looking beyond 2026, a sale of part or all of WBD would likely open the door for more streaming acquisitions. That could eventually benefit customers by making it easier to find content to watch with fewer subscriptions. But merged companies are also less likely to take risks on unique and diverse content.

Analysts I spoke with pointed to fewer niche and mid-tier original shows and movies and more show cancellations if either Netflix or Paramount buys HBO Max. Either buyer would probably focus more on the already-successful franchises that WB owns, such as Game of Thrones, Batman, and Superman.

“Big combined libraries push companies to double down on proven IP because it travels, merchandises, and reduces marketing risk,” said Robert Rosenberg, a partner at the New York law firm Moses Singer focusing on intellectual property, entertainment, technology, and data law.

Rosenberg also expects to see a “tilt toward” live events, sports, and unscripted content “for retention” if HBO Max sells.

In the shorter term, Rory Gooderick, research manager at analyst firm Ampere Analysis, predicted that WBD will be “cautious when greenlighting new large-scale projects until” the acquisition is finalized.

Beyond the potential HBO Max sale, more merger activity could lead to streaming services straying from their original selling point of offering bolder, quirkier content.

As the industry consolidates, “sticky content,” like procedurals, reality shows, and “comfort TV that drives long viewing sessions,” will take priority among mainstream, subscription-based streaming services, especially as they put more emphasis on ad-tier subscriptions, Goodman predicted.

The new year will be formative for streaming and yield lasting impacts for subscribers. We’ve discussed numerous negative implications, but there could be a silver lining. While we may see more turbulence, hopefully, we’ll also start to see a road toward more stable streaming options.

Streaming subscribers can’t directly stop mergers or price hikes or control streaming libraries. But with services like Netflix and Disney+ focusing on becoming one-stop shops with massive libraries, there’s an opportunity for other services to hone their specialties and stand out by providing offbeat, unexpected, and rare content at more affordable prices.

As the landscape settles, streamers should be mindful of the importance of variety to subscribers. According to Bill Michels, chief product officer at Gracenote, Nielsen’s content data business unit:

There will be some consolidation. But the [connected TV] landscape, inclusive of FAST and [direct-to-consumer] channels, provides more than ample video variety for viewers, so the biggest challenge will be connecting content with the right audience. Audience engagement depends on good content. Audience retention depends on making sure audiences are never without something to watch.</div>
        </div>
        
        <div class="card" onclick="openModal('content-1')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">Film Technica: Our top picks for the best films of 2025</div>
            <div class="meta">2026-01-01</div>
        </div>
        
        <div id="content-1" style="display:none;">
            <h2>Film Technica: Our top picks for the best films of 2025</h2>
            <p><strong>Ars Technica - All content | 2026-01-01</strong></p>
            <a class="original-link" href="https://arstechnica.com/culture/2026/01/film-technica-our-top-picks-for-the-best-films-of-2025/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Editor’s note: Warning: Although we’ve done our best to avoid spoiling anything too major, please note this list does include a few specific references that some might consider spoiler-y.

It’s been a strange year for movies. Most of the big, splashy tentpole projects proved disappointing, while several more modest films either produced or acquired by streaming platforms—and only briefly released in theaters—wound up making our year-end list. This pattern was not intentional. But streaming platforms have been increasingly moving into the film space with small to medium-sized budgets—i.e., the kind of fare that used to be commonplace but has struggled to compete over the last two decades as blockbusters and elaborate superhero franchises dominated the box office.

Add in lingering superhero fatigue—only one superhero saga made our final list this year—plus Netflix’s controversial bid to acquire Warner Bros., and we just might be approaching a sea change in how movies are made and distributed, and by whom. How this all plays out in the coming year is anybody’s guess.

As always, we’re opting for an unranked list, with the exception of our “year’s best” selection at the very end—this year it’s a three-way tie—so you might look over the variety of genres and options and possibly add surprises to your eventual watchlist. We invite you to head to the comments and add your own favorite films released in 2025.

Ana de Armas proves herself a fierce and lethal adversary against a cultish syndicate in Ballerina—excuse me, From the World of John Wick: Ballerina. Chronologically, Ballerina takes place during the events of John Wick Chapter 3: Parabellum. That film gave us a glimpse into John Wick’s (Keanu Reeves) past as he sought aid from the Ruska Roma crime syndicate, led by the Director (Anjelica Huston), where he was trained as an assassin. The Director also trains girls to be ballerina-assassins, one of whom is Eve Macarro (de Armas).

Like Wick, Eve is driven by a personal vendetta: the brutal murder of her father when she was still a child by highly trained and heavily armed assassins. The Director warns Eve that this is a rogue group of lawless cultists and orders her not to pursue the matter. But vengeance will be Eve’s, no matter the cost, as she hunts down the cultists and their enigmatic leader, the Chancellor (Gabriel Byrne).

Ballerina has all the eye-popping visuals, lavish sets, and spectacularly inventive stuntwork one would expect from a film set in the John Wick universe. It’s more tightly plotted than recent entries in the franchise, and the globe-trotting locations make narrative sense; it’s not just an excuse for staging a spectacle. As always, the fight choreography is perfection. Eve is smaller than most of the men she takes on, but that doesn’t make her any less deadly, particularly when she’s more than willing to fight dirty. A fight scene with dueling flame throwers is one for the ages. Despite a few minor quibbles, Ballerina is an immensely entertaining and action-packed addition to the franchise.

The Baltimorons is a quirky holiday love story about an unlikely pair who find each other by happenstance over the holidays. Didi (Liz Larsen) is a divorced middle-aged dentist whose ex-husband has just gotten married to his much-younger girlfriend—on Christmas eve, no less, so the wedding reception pre-empts Didi’s planned time with her daughter. So she’s on call when a bumbling former improv comedian and recovering alcoholic named Cliff (Michael Strassner) has a dental emergency.

Cliff’s car is towed while she treats him—apparently, this is a regular occurrence—and Didi offers to drive him to the impound lot. They end up going on a quixotic journey around Baltimore, including crashing the family wedding reception and performing at a pop-up improv show, and find themselves drawn together despite their significant age difference.

Director Jay Duplass has a knack for this kind of idiosyncratic fare featuring deeply imperfect yet likable characters, having either written, directed, and/or produced such gems as Safety Not Guaranteed, Horse Girl, Table 19, and Jeff, Who Lives at Home. It falls on Strassner—a Baltimore native who co-wrote the script—and Larsen to carry the film, which they do with considerable charm. You get why Didi and Cliff forge such a bond, even if one questions how long it’s likely to last. The film is also kind of a love letter to Baltimore, aka “Charm City”; if all you know about Baltimore comes from watching The Wire, The Baltimorons will give you a glimpse of the city’s many other neighborhoods and sights.

Auteur director Wes Anderson‘s films have a visual style and tone all their own, and I’ve been a fan of his understated eccentricity since 1998’s Bottle Rocket. OK, 2023’s Asteroid City left me cold, but Anderson returns to top form with The Phoenician Scheme. Benicio del Toro stars as Zsa-Zsa Korda, a 1950s ruthless arms dealer and industrialist who finds himself the target of government assassins—most likely because of his unethical business practices.

He barely survives one attempt ,and a vision of the afterlife convinces Zsa-Zsa that he needs to mend fences with his estranged daughter Liesl (Mia Theapleton), a novice in a convent. He’s also trying to pull off a risky scheme to essentially overhaul the infrastructure of Phoenicia, traveling around the world to meet with investors and convince them to increase their own shares so he can avoid bankruptcy. Liesl joins him on the journey, along with a nerdy Norwegian entomologist named Bjorn (Michael Cera). Wacky hijinks ensue. It has an intricate, sometimes unfocused plot, but Anderson pulls it off with his usual delicate whimsical touch, bolstered by delightfully deadpan performances from the cast.

This sumptuous historical fantasy is adapted from Isabel Greenberg’s lavishly illustrated graphic novel of the same name, which is in turn an inventive twist on One Thousand and One Nights. Maika Monroe plays Cherry, the wife of a wealthy medieval landowner named Jerome (Amir El-Masry), who for some reason has not consummated their marriage. Obsessed with his wife’s fidelity, Jerome makes a wager with his handsome friend Manfred (Nicholas Galitzine) that if Manfred successfully seduces Cherry within 100 days, Jerome will give him both Cherry and his castle.

But Cherry’s maid, Hero (Emma Corrin), secretly loves her lady and thwarts Manfred’s seduction attempts by regaling him with captivating stories every night to keep her mistress from succumbing to temptation. And Manfred is most definitely tempting, dragging a freshly killed deer to the castle while bare-chested and covered in its blood. The costumes, production design, and cinematography are stunning, mirroring Cherry’s gradual sexual awakening via romantic triangle. Add in stellar performances, and this is a sensual fairy tale for the ages.

Credit:

          
          Marvel Studios

Thunderbolts* is basically the MCU’s version of The Suicide Squad (2021) with less over-the-top R-rated violence, but it’s just as irreverently entertaining. Black Widow introduced us to Natasha Romanoff’s (Scarlett Johansson) backstory as a child recruited for training as an elite assassin, along with her adoptive sister (and equally lethal assassin) Yelena Belova (Florence Pugh). Thunderbolts* finds Yelena working as a hired mercenary for CIA director Valentina Allegra de Fontaine (Julia Louis-Dreyfus), but she’s still grieving the loss of Natasha, and her heart just isn’t in it.

Yelena decides to quit, and Valentina asks her to do one last covert mission. It turns out to be a trap: Yelena is attacked by super soldier John Walker (Wyatt Russell), Taskmaster (Olga Kurylenko), and Ghost (Hannah John-Kamen). The hope what that they’ll all kill each other and be destroyed along with incriminating evidence—which includes an awkward, nebbishy man in hospital PJs named Bob (Lewis Pullman), who is far more dangerous than he appears. Along with Yelena’s adoptive father, Alexei/Red Guardian (David Harbour), they all team up to take down Valentina instead.

It’s well-plotted and doesn’t take itself too seriously. Director Jake Schreier (Robot & Frank, Beef) expertly balances the action sequences with bantering wisecracks and quieter introspective moments that serve to actually develop the characters, each of whom has their inner demons and plenty of red in their respective ledgers. And Schreier has an incredibly talented cast to work with, all of whom give stellar performances. Thunderbolts* is a refreshing return to peak Marvel form: well-paced, witty, and action-packed with enough heart to ensure you care about the characters.

Director Guillermo del Toro has been telling interviewers for years about his enduring love for Mary Shelley’s classic novel and his long-standing desire to direct a film that would capture the novel’s sense of grand Miltonian tragedy. He called this film “the culmination of a journey that has occupied most of my life.” His Frankenstein is probably the most faithful film adaptation yet made (with a few deviations in later acts), even mirroring Shelley’s narrative structure. It’s first told from the perspective of the captain of an Arctic ship trapped in ice en route to the North Pole who rescues a badly wounded Baron Victor Frankenstein (Oscar Isaac). Both Victor and his Creature (Jacob Elordi) then get to tell their versions of the story that brought them to the Arctic.

Known for his lush visuals and high Gothic sensibility, del Toro doesn’t disappoint, with elaborate sets—Victor’s laboratory is a wonder of 19th-century steampunk industrialism—and an innovative design for the Creature. Del Toro is the perfect conduit for this story of an arrogant scientist who tries to play god by creating a monstrous creature, only to become a monster himself. Isaac brings a blend of passionate intensity and cold ambition to his portrayal of Victor, but it’s Elordi who ultimately anchors the film, conveying the fundamental humanity of Shelley’s iconic monster.

Before The Hunger Games, there was The Long Walk, a 1979 novel by Stephen King (writing as Richard Bachman) about a dystopian alternate history in which one young man from each state in a totalitarian US is chosen to participate in a grueling annual contest. They walk. And walk. And walk. If they drop below 3 MPH or stop to rest, they are executed. They keep walking until only one is left standing as the “winner,” rewarded with whatever he wants for life at a time when the country is mired in a deep economic depression. It’s grim material well-suited for a film adaptation by Francis Lawrence, who has directed every film in The Hunger Games franchise. The dude knows his dystopias.

Cooper Hoffman plays Ray Garraty, a contestant from Maine who volunteers for the walk over the objections of his mother. His first wish, should he win, would be for a rifle to kill the Major (Mark Hamill) in charge of the walk, since the Major had executed his father years before. Ray soon bonds with Pete (David Jonsson), but the stakes become crystal clear when the first walker falls: A boy who develops a charley horse and is summarily shot for sitting down. One by one, each boy falls until just two remain.

Lawrence keeps things tense and starkly minimalistic. There are no elaborate sets or costumes. It’s the interactions between the various walkers that drive the story, punctuated by inevitable deaths. The point is that there is no happy ending, regardless of who technically “wins.” There are some deviations from the novel, but Lawrence retains King’s suitably cryptic (and quite bleak) ending. I’m a fan of Andy Muscietti’s two-part adaptation of IT and Mike Flanagan’s Doctor Sleep, but The Long Walk might just edge them out as the best adaptation of a Stephen King novel yet.

This gem of a film is basically Airplane! meets Agatha Christie meets Downtown Abbey, spoofing all those British aristocratic period dramas we know and love. Set in 1931, the plot centers on a charming orphaned pickpocket named Eric (Ben Radcliffe), who is mistaken for a new employee when he arrives at the titular manor house of Lord and Lady Davenport (Damian Lewis and Katherine Waterson).

Eric ends up leaning into his new role and is soon promoted, even indulging in a forbidden romance with the Davenports’ daughter Rose (Thomasin McKenzie). Then someone gets murdered, and Eric finds himself framed for the killing. It’s up to Inspector Watt (Tom Goodman-Hill) and his magnificent (removable) mustache to solve the mystery. The cast clearly had a blast, and it’s impossible to resist that wickedly dry, often scatalogical British slapstick humor. Fackham Hall is a bright, shiny bauble that will leave you longing for a sequel.

When The Rocky Horror Picture Show premiered in 1975, no one could have dreamed that it would become the longest-running theatrical release film in history—least of all its creator, Richard O’Brien. But that’s what happened as it developed a loyal cult following of fans dressing up in costumes and acting out the lines in front of the big screen, a practice known as shadow casting. Thanks to a killer soundtrack, campy humor, and those devoted fans, Rocky Horror is still a mainstay of midnight movie culture. Richard O’Brien’s son, Linus O’Brien, marked the occasion with his fascinating documentary Strange Journey: The Story of Rocky Horror.

The film has its share of cast reminiscences, but it’s the profound impact Rocky Horror has had over the decades that ultimately shines through—and not just on a broad cultural scale. O’Brien decided to make the film while gathering archival clips of his father’s work. He came across a video clip of “I’m Going Home” and found himself browsing through the comments, deeply touched by the many people, including a soldier in Iraq and a woman grieving the loss of her mother, talking about what the song and film had meant to them.

The film ends with a fan telling Richard O’Brien, “It doesn’t matter what people think about Rocky because it belongs to us, not to you”—and Rocky’s creator agreeing that this was true. You can pair Strange Journey with another film celebrating the milestone anniversary, Sane Inside Insanity: The Phenomenon of Rocky Horror, for a documentary double feature.

Credit:

          
          IFC/Shudder

I promise you this is not a spoiler, but for anyone too scared to watch Good Boy, the whole point of one of the year’s most original horror movies is that the dog survives. And despite being a “good boy,” from the moment we meet Indy, the dog gives off “final girl” energy, being the only creature in a cursed family house to sense the hauntings that seem to complicate his owner’s illness and drive him closer to death. Relying on lighting tricks and a frenetic, pulsing soundtrack to dramatize scenes where the movie’s star seems to just be acting like a dog, the movie reinvigorates the haunted house story by telling it from a dog’s-eye level and largely obscuring the faces of humans.

Director and co-screenwriter Ben Leonberg told AV Club that he drew this stellar performance out of Indy—who is not a show dog but his own adorable dog—by living in the house where the movie was filmed and building the set around the ways that Indy moved. Come for the pudgy puppy reels, and then be as obedient as Indy and “stay” for the technical feat of watching a man and his best friend turn classic horror devices into dog toys.

Credit:

          
          Orion/Amazon MGM Studios

Tessa Thompson is luminous in the title role of director Nia DaCosta’s film adaptation of the classic Henrik Ibsen play Hedda Gabler. It’s the story of a general’s daughter who marries a stuffy academic for convenience, believing her wild youth is behind her—only to find it’s not much fun being trapped in a loveless marriage, however elegant the surroundings. When a former lover pops up, now involved with Hedda’s romantic rival, tensions build to an explosive climax. This being Ibsen, things don’t end well for anyone.

DaCosta has kept most of the play’s plot intact, but a clever gender swap makes for an interesting twist on the complicated interpersonal dynamics. Nina Hoss plays novelist and recovering alcoholic Eileen Lovborg (a man named Eilert in the play), with Imogen Poots playing romantic rival Thea. Hedda also maintains a flirtation with the lascivious Judge Brack (Nicholas Pinnock), who is manipulative enough to use Hedda’s weaknesses against her. Hedda is among the greatest dramatic roles in theater, and Thompson utterly makes it her own. Is the film a bit stagey at times? Yes, which isn’t surprising since it’s based on a play. That very staginess gives the film a tight, claustrophobic feel, heightening Hedda’s sense of the walls closing in on her once vibrant youth.

Credit:

          
          Media Courthouse Documentary Collective

Normally, I’d rather stick hot needles under my fingernails than watch a bio-documentary about a politician, regardless of party affiliation. It’s just not my thing. But we live in interesting times, and The Last Republican is not your standard political documentary. The film follows former Rep. Adam Kinzinger (R-IL) over the course of his last year in office. Kinzinger was ousted by his own party for his service on the congressional committee investigating the January 6, 2021, riotous attack on the US Capitol—and for his outspoken denunciation of then-President Donald Trump’s incendiary rhetoric at the instigating rally and delayed action to quell the rioters.

That’s standard documentary fare. But this one was directed by Steve Pink, best known for 2010’s Hot Tub Time Machine (a personal favorite of mine). Pink is (almost) as far apart from Kinzinger politically as it’s possible to be. Kinzinger chose to work with Pink because he, too, loves Hot Tub Time Machine. And a most unlikely friendship was born. You can see their bond in the trailer, which opens with Kinzinger recognizing that the man he has trusted with his story likely has nothing but contempt for Kinzinger’s political views. “That’s kinda mean,” we hear Pink say off-camera, before cheekily asking how one even becomes a Republican, “because I don’t get it.”

That friendship resonates perfectly with the film’s central theme. “It’s not about a political view,” Kinzinger says in the film. “It’s about what it is to turn against everything you’ve ever belonged to because of some red line you can’t cross.” Had there been more principled congressional members like Kinzinger in 2021 willing to put country over party, even if it torched their political careers—and more friendships across political divides finding common ground—the US would be in a very different and better place today. Kinzinger’s closing J6 committee statement is even more relevant four years later: “Oaths matter. Character matters. Truth matters. If we do not renew our faith and commitment to these principles, this great experiment of ours, our shining beacon on a hill, will not endure.”

Credit:

          
          Warner Bros.

One of the most terrifying images of 2025 was a mob of kids with their arms extended like airplanes. It came in Weapons, a witchy mystery that begins with every child in a certain middle school teacher’s class suddenly disappearing, except for one, a quiet boy named Alex Lilly. Working off a highly original script and giving an emotional performance that drove some viewers to tears, young actor Cary Christopher wrenches hearts as Alex’s role in the other kids’ disappearance becomes clearer—after the audience meets his Aunt Gladys.

An actual living and breathing nightmare played to unnerving perfection by Amy Madigan, Aunt Gladys reads like voodoo Mary Poppins meets Pennywise the clown. But stuck in the house with this instantly iconic horror character, Alex proves that he’s the most capable caretaker in the family. In the end, he’s the one tasked with helping his aunt “feel better” while spooning as much Campbell’s soup as it takes into the faces of “weaponized” loved ones to ensure they survive Aunt Gladys’ visit.

Dust Bunny is the directorial feature film debut of Bryan Fuller, the creative force behind some of my favorite TV shows over the years, most notably Dead Like Me, Wonderfalls, and Pushing Daisies, as well as Hannibal. Fuller has a knack for injecting elements of magical realism into otherwise ordinary settings, and Dust Bunny adds a healthy dose of horror and Labyrinth-style visual aesthetics into the mix to strike a perfect balance between violence, suspense, whimsy, and emotional depth. Sophie Sloan plays Aurora, a young girl in New York City who turns to her neighbor, Resident 5B (Mads Mikkelson, in a role written specifically for him), for help when (she claims) a monster under her bed kills and eats her parents.

Resident 5B is a hitman for hire, and Aurora wants him to kill the monster in revenge, although he doesn’t think the monster is real, and there are, in fact, other bad people who won’t shirk at going through Aurora to get to Resident 5B. Fun fact: the monster design was inspired by highland cows, although Fuller also asked for the monster to be part hippopotamus and part piranha; artist Jon Wayshak proved well up to the task. Mikkelson and Sigourney Weaver turn in terrific performances—Mikkelson even helped choreograph one of the stunt sequences—as does Sloan and David Dastmalchian. Plus, there’s an entire action sequence featuring a Chinese dragon costume. What more could one want?

Credit:

          
          Universal

                  





Every musical theater fan knows that the second act of a show is almost invariably weaker than the first. Thus, setting the second act of the Wicked musical apart as its own movie was bound to result in a sequel that had trouble living up to last year’s banger-filled mega-hit film.

Wicked: For Good is also where the narrative starts coming apart at the seams a bit, as it necessarily intersects and interacts with the narrative from The Wizard of Oz itself. The leaps of logic necessary to get these “misunderstood” versions of the characters to gel with the ones we see cavorting in that 90-year-old classic are best ignored. But the movie repeatedly throws those connections in our face amid a heavily padded 137-minute runtime that could have easily been half an hour shorter.

Despite it all, though, the quality of the original writing from Stephen Schwartz and Winnie Holzman still shines through. The titular song “For Good” is still an all-time classic, and strong performances carry catchy tunes like “No Good Deed” and “Just for This Moment” (though the latter is robbed of a lot of its inherent sex appeal through some odd directorial choices). Even “The Girl in the Bubble&quot;—a new song created just for the movie–manages to not feel out of place thanks in large part to a winning performance from Ariana Grande and some downright magical camera work.

The worst part of Wicked: For Good, though, might be how its success will almost definitely lead to an expanded Wicked Cinematic Universe, with sequels or prequels that mash these winning characters to death via a bunch of expositional backstory. Let Glinda and Elphaba rest! They’ve earned it!

This was a surprise mega-hit for Netflix, fueled by a killer Korean pop soundtrack featuring one earworm after another that collectively dominated the charts for weeks. K-Pop Demon Hunters is the streaming giant’s most-watched animated film of all time, and that’s not just because of the infectious music—although the music is why Netflix ended up releasing a highly popular singalong version in theaters (after the film racked up huge streaming numbers). The Sony Animation team delivers bold visuals that evoke the look and feel of anime, the plot is briskly paced, and the script strikes a fine balance between humor and heart.

Earth has been protected from demons for generations by a protective barrier called the Honmoon, maintained by musical trios/demon hunters from each generation. One day, the Honmoon will become so strong it will turn “golden” and seal away the demons forever. The latest incarnation of demon hunters—a K-Pop band called Huntr/x—is close to accomplishing the Golden Honmoon.

Rumi (Arden Cho) is the lead singer, Mira (May Hong) is the group’s dancer/choreographer, and American-born Zoey (Ji-young Yoo) is the rapper and lyricist. But Rumi harbors a secret: Her father was a demon, and she is marked by the telltale purple “patterns,” which she keeps hidden from her bandmates. Hoping to destroy the Honmoon once and for all, king of the demons Gwi-Ma sends five of his demons to form a K-pop boy band, the Saja Boys, led by Jinu (Ahn Hyo-seop). Their popularity soon rivals that of Huntr/x and threatens the Honmoon.

Co-director (with Chris Appelhans) Maggie Kang conceived the story and helped write the screenplay, intending the film to be a love letter to K-pop and her Korean roots. But she also drew on traditional Korean mythology and folklore. Those details add a rich layer of texture to the basic storyline. Granted, the film adheres to a familiar formula, but it’s a winning one. K-Pop Demon Hunters‘ unifying message of the power of music to heal, unite, and build community—celebrating honest authenticity rather than striving for impossible perfection—is a powerful one.

Credit:

          
          Sony Pictures

28 Years Later could have been terrible, screenwriter Alex Garland told Rolling Stone, if he went with his original idea about a group of military men fighting to stop bad guys from weaponizing the Rage Virus. But director Danny Boyle didn’t let that happen, instead pushing Garland to think small and deliver a powerful coming-of-age story that’s somehow just as intense as 2002’s 28 Days Later without retreading hardly any of the same territory. A story about resisting isolationism, 28 Years Later is set on a small island where a scrappy community has survived for decades after being quarantined from the rest of the world.

The story follows a young boy, Spike, who leaves home with his ailing mother after he learns that he cannot trust his father to look out for them. A fire is lit in Spike to cure his mother, and no human or infected—not the worm-eating chubby ones or the spine-ripping alphas—can put him off his mission. What starts as a ritual hunt to initiate a boy into manhood turns instead into a tender quest to find the only known doctor on the island, allowing Spike to see the infected and his community in a new light.

Featuring nuanced performances equal parts harrowing and endearing from Jodie Comer as the mom, Isla, and Alfie Williams as Spike, the movie explores the folly of societies backsliding from progress out of fear of the unknown. As Spike’s dread of the infected flickers out, it’s replaced by an urgent curiosity about the world beyond his village. The only thing potentially standing in his way of growing as wise as the doctor is a gang of “pals” named Jimmy. “Howzat!” for a setup to get boots marching into theaters to see the second installment of the new trilogy in January?

Credit:

          
          Sony Pictures Classics

Director Richard Linklater (Dazed and Confused, Hit Man) had two films released this year. One is Nouvelle Vague, about the 1959 shooting of the seminal French New Wave film Breathless. The other is Blue Moon, about the complicated relationship between lyricist Lorenz Hart and his erstwhile composer partner Richard Rodgers. Both films are exceptional in their own right, but Blue Moon is my choice for our year’s best list. Chalk it up to my enduring fondness for classic Broadway musicals.

The film takes place in Sardi’s restaurant on the opening night of Oklahoma!, which is Rodgers’ (Andrew Scott) first collaboration with a new lyricist, Oscar Hammerstein II (Simon Delaney). Ethan Hawke turns in a powerful performance as Hart, newly (barely) sober and holding court with bartender Eddie (Bobby Cannavale). He’s rather bitter about his own waning career after he refused to collaborate on the new musical. He’s depressed, and Eddie is reluctant to serve him any alcohol, plus the “omnisexual” Hart’s advances toward the comely Elizabeth (Margaret Qualley) are repeatedly rebuffed.

Oklahoma!, of course, was a smash hit, crowning Rodgers and Hammerstein as the new wonder boys of Broadway. A drunken Hart tragically died just a few months later. Blue Moon‘s intimate portrait of Hart on a night that proved to be a critical turning point is a fitting tribute to one of our greatest lyricists, whose personal demons dimmed his light too soon.

Credit:

          
          Searchlight Pictures

Brendan Fraser is experiencing a quiet renaissance, with highly praised recent roles in The Whale and Killers of the Flower Moon, as well as a role in the delightfully bonkers TV series Doom Patrol. Add his gentle, empathetic performance in Rental Family to that list. Fraser plays Phillip Vandarploeug, an American actor living in Japan because he once had great success with a toothpaste commercial. But the roles have dried up, so Phillip signs on with a company called Rental Family, which hires actors as stand-ins for family members or friends. Phillip is the “token white guy.”

It might sound like a cynical premise—the company basically “sells emotion&quot;—but the film is anything but cynical. Phillip ends up developing strong bonds with two of his “clients”: A young Haifa girl named Mia with an absent father and an elderly man with dementia named Kikuo, who happens to be a retired actor. But what happens if they discover the truth? Rental Family is a low-key, thoughtful reflection on loneliness and our human need for social connection. “Sometimes it’s OK to pretend,” Phillip tells Mia at one point. Sometimes faking an emotional connection develops into one that is genuine and lasting.

Credit:

          
          Focus Features

Hipsters love to sneer at artists like Neil Diamond. He’s dated, his music is cheesy, yada yada yada. But there’s a reason “Sweet Caroline” has become a staple singalong at sporting events, bar mitzvahs, karaoke nights and the like. All that cynicism melts away once the music starts; it’s infectious. Diamond’s music even inspired a popular Milwaukee tribute act in the 1990s and early oughts: Lightning and Thunder. The duo gets their due in the biopic Song Sung Blue, which is in turn based on a 2008 documentary of the same name. (You can watch the documentary on YouTube.) Director Craig Brewer saw the documentary and was inspired to create his own fictionalized account of Thunder and Lightning’s story with all their dramatic ups and downs.

Hugh Jackman plays Vietnam veteran and recovering alcoholic Lightning, aka Mike Sardina, who falls in love with single mom and Patsy Kline impersonator Claire, aka Thunder. She’s the catalyst for their “Neil Diamond experience,” riding the 1990s wave of Diamond’s resurgence while battling both external obstacles and their respective personal demons. The film condenses the timeline and takes some minor liberties here and there, but on the whole it’s quite factually accurate. (The duo really did open for Pearl Jam and Eddie Vedder joined them briefly onstage for “Forever in Blue Jeans.”)

Jackman and Hudson are major film stars but one soon forgets, because they dissolve so completely into their respective roles. Hudson received a well-deserved Golden Globe nomination for her performance and I expect an Oscar nod will be coming her way as well; this is her best role to date by far. And yes, Jackman and Hudson actually perform the songs; Hudson’s solo rendition of “I’ve Been This Way Before” towards the film’s end is gut-punchingly beautiful.

Song Sung Blue is ultimately a love story, but it’s also an homage to the power of music to lift us up even in our darkest hours. On every anniversary of his sobriety, Lightning sings “Song Sung Blue.” Lightning and Thunder pour their souls into even the most seemingly insignificant gigs, whether it’s a hostile crowd in a biker bar or karaoke night at the local Thai restaurant. One of the most moving scenes shows Lightning and the Thai restaurant owner sitting alone in an empty restaurant after the latter’s wife has died of cancer and Lightning is struggling with his own personal tragedy—finding mutual comfort by singing “only sad songs” by Diamond on the karaoke machine.

And now for our top three films of 2025, each so different from one another that we couldn’t bring ourselves to choose just one:

Credit:

          
          Warner Bros.

                  





My absolute favorite part of One Battle After Another comes when Leonardo DiCaprio’s character falls off a building. The former revolutionary has let himself go a bit after decades out of the game and can’t keep up with the young skateboarders who effortlessly parkour between buildings during an exciting rooftop chase sequence. One Battle After Another is at its best when it subverts the audience’s expectations like this, boiling down action-thriller set pieces into comically realistic mundanity.

The movie also deserves credit for the subtle way it highlights two very different modes of resistance to a disturbingly familiar fascist government. The flashy French 75 revolutionaries manage to get a lot of attention with their bold statement-making operations, but they do little to actually disrupt the horrifying status quo before getting broken up by law enforcement. Contrast that with Benicio Del Toro’s Sensei Sergio St. Carlos, who quietly operates a sort of underground railroad for actual marginalized immigrants that quietly hides and protects them from an overwhelming government apparatus.

The movie’s plot falls apart a bit near the end as Sean Penn’s cartoonishly evil antagonist hunts down Willa Ferguson’s well-acted “hope for the future” child revolutionary. Still, I’d be lying if I said the inherent tension of the chase didn’t have me on the edge of my seat even after two hours.

Credit:

          
          Warner Bros.

Ryan Coogler’s vampire horror film set in the Mississippi Delta in 1932 has topped my list of best films since its April release. Michael B. Jordan delivers an Oscar-worthy dual performance as the Smokestack Twins: Elijah Moore (Smoke) and Elias Moore (Stack). They are World War I veterans just returned from Chicago, having stolen money from a gangster. They use the funds to buy an old sawmill to set up their own juke joint for the local black community. For the band, they recruit their young cousin Sammie (Miles Caton), a preacher’s son and gifted blues musician with a gift so powerful, it just might summon spirits of the past and future to join in the festivities.

The opening night is rollicking along until an Irish vampire named Remmick (Jack O’Connell) crashes the party with his minions, turning the revelers one by one. Can the rest survive until sunrise? There are so many layers to Sinners; it gets richer with each subsequent rewatch. You have the racial conflicts of the Jim Crow South and vigilante Klansmen; Sammie’s love for sexy singer Pearline (Jayme Lawson); Stack’s complicated relationship with his white-passing ex, Mary (Hailee Stanfield); and Smoke’s reunion with his long-suffering wife, Annie (Wunmi Mosaku).

Sinners has drawn comparison to Robert Rodriguez’s From Dusk Till Dawn, and that film is indeed one of many cited influences by Coogler. But this is very much Coogler’s singular vision: alternately steamy, bawdy, raucous, violent, and bloody, fueled by fantastic music. There’s even a cameo by blues legend Buddy Guy in the film’s denouement. Guy was one of several blues musicians who recorded songs for the film. That makes this easily the best soundtrack of 2025 (sorry, K-Pop Demon Hunters, but you know it’s true).

Private detective Benoit Blanc (Daniel Craig) might just turn out to be Rian Johnson’s greatest creation. Introduced in 2019’s Knives Out, Blanc’s syrupy Southern drawl and idiosyncratic approach to solving a mysterious New England death charmed audiences worldwide and launched a modern whodunnit franchise. The latest installment is Wake Up Dead Man, in which Blanc tackles the strange death of a fire-and-brimstone parish priest, Monseigneur Jefferson Wicks (Josh Brolin). Wick inspired a cult-like loyalty in his central flock while alienating any newcomers. The primary suspect is a young new priest, Rev. Jud Duplenticy (Josh O’Connor) who steadfastly maintains his innocence, despite openly clashing with the Monseigneur.

Wake Up Dead Man is a classic locked-room mystery in a spookily Gothic small-town setting, and Johnson repeatedly namechecks John Dickson Carr’s The Hollow Man, widely held to be the most masterful take on the genre. So if you’ve read The Hollow Man, you’ll probably figure out the “howdunnit” pretty easily. Fortunately, there’s still plenty of twists and turns regarding the who and the why of the matter to keep us guessing right up until the end. Johnson always assembles terrific casts for these films, and the characters are always colorful and engaging. But Wake Up Dead Man digs a little deeper, allowing the characters to achieve some personal insight and growth as the mystery unfolds.

The broody church setting isn’t just for atmosphere, either. Sure, this is primarily a murder mystery, but thematically, it explores the nature of both faith and reason, as embodied by Duplenticy and Blanc, respectively, without ridiculing or diminishing either. One Battle After Another might be poised for the strongest Oscar showing, but Wake Up Dead Man is pure pleasure. This third installment rivals the original Knives Out for fascinating characters, atmospheric setting, and sheer plot ingenuity. We can’t wait to see what Blanc gets up to next.</div>
        </div>
        
        <div class="card" onclick="openModal('content-2')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">Here we go again: Retiring coal plant forced to stay open by Trump Admin</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-2" style="display:none;">
            <h2>Here we go again: Retiring coal plant forced to stay open by Trump Admin</h2>
            <p><strong>Ars Technica - All content | 2025-12-31</strong></p>
            <a class="original-link" href="https://arstechnica.com/science/2025/12/trump-admin-orders-another-coal-plant-to-stay-open/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">On Tuesday, US Secretary of Energy Chris Wright issued a now familiar order: because of a supposed energy emergency, a coal plant scheduled for closure would be forced to remain open. This time, the order targeted one of the three units present at Craig Station in Colorado, which was scheduled to close at the end of this year. The remaining two units were expected to shut in 2028.

The supposed reason for this order is an emergency caused by a shortage of generating capacity. “The reliable supply of power from the coal plant is essential for keeping the region’s electric grid stable,” according to a statement issued by the Department of Energy. Yet the Colorado Sun notes that Colorado’s Public Utilities Commission had already analyzed the impact of its potential closure, and determined, “Craig Unit 1 is not required for reliability or resource adequacy purposes.”

The order does not require the plant to actually produce electricity; instead, it is ordered to be available in case a shortfall in production occurs. As noted in the Colorado Sun article, actual operation of the plant would potentially violate Colorado laws, which regulate airborne pollution and set limits on greenhouse gas emissions. The cost of maintaining the plant is likely to fall on the local ratepayers, who had already adjusted to the closure plans.

The use of emergency powers by the DOE is authorized under the Federal Power Act, which allows it to order the temporary connection of generation or infrastructure when the US is at war or when “an emergency exists by reason of a sudden increase in the demand for electric energy, or a shortage of electric energy.” It is not at all clear whether “we expect demand to go up in the future,” the DOE’s current rationale, is consistent with that definition of emergency. It is also hard to see how using coal plants complies with other limits placed on the use of these emergency orders:

The Commission shall ensure that such order requires generation, delivery, interchange, or transmission of electric energy only during hours necessary to meet the emergency and serve the public interest, and, to the maximum extent practicable, is consistent with any applicable Federal, State, or local environmental law or regulation and minimizes any adverse environmental impacts.

At the moment, coal-fueled generation is more expensive than anything other than nuclear power, and is far and away the dirtiest form of generation. Its airborne pollution is responsible for a significant number of deaths in the US, and it leaves behind solid waste that is rich in toxic metals. It’s difficult to square those financial and health costs with serving the public interest.

Yet the Trump Administration has relied heavily on declaring energy emergencies in its attempt to keep coal afloat despite the economics. A check of the use of similar emergency orders shows that, in the past year, the Administration has declared 16 energy emergencies—more than the entire total declared between 2008 and 2024.

The Administration’s reliance on this sort of emergency declaration is in the process of being challenged in court, though. Several states and a collection of environmental organizations recently filed a suit that argues that the administration is misusing what’s meant to be a response to temporary emergencies by simply renewing the orders indefinitely, as it has with a coal plant in Michigan that has been forced to remain open well past the summer demand surge that the DOE initially used as its justification.</div>
        </div>
        
        <div class="card" onclick="openModal('content-3')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">Supply chains, AI, and the cloud: The biggest failures (and one success) of 2025</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-3" style="display:none;">
            <h2>Supply chains, AI, and the cloud: The biggest failures (and one success) of 2025</h2>
            <p><strong>Ars Technica - All content | 2025-12-31</strong></p>
            <a class="original-link" href="https://arstechnica.com/security/2025/12/supply-chains-ai-and-the-cloud-the-biggest-failures-and-one-success-of-2025/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">In a roundup of the top stories of 2024, Ars included a supply-chain attack that came dangerously close to inflicting a catastrophe for thousands—possibly millions—of organizations, which included a large assortment of Fortune 500 companies and government agencies. Supply-chain attacks played prominently again this year, as a seemingly unending rash of them hit organizations large and small.

For threat actors, supply-chain attacks are the gift that keeps on giving—or, if you will, the hack that keeps on hacking. By compromising a single target with a large number of downstream users—say a cloud service or maintainers or developers of widely used open source or proprietary software—attackers can infect potentially millions of the target’s downstream users. That’s exactly what threat actors did in 2025.

One such event occurred in December 2024, making it worthy of a ranking for 2025. The hackers behind the campaign pocketed as much as $155,000 from thousands of smart-contract parties on the Solana blockchain.

Hackers cashed in by sneaking a backdoor into a code library used by developers of Solana-related software. Security firm Socket said it suspects the attackers compromised accounts belonging to the developers of Web3.js, an open source library. They then used the access to add a backdoor to a package update. After the developers of decentralized Solana apps installed the malicious update, the backdoor spread further, giving the attackers access to individual wallets connected to smart contracts. The backdoor could then extract private keys.

There were too many supply-chain attacks this year to list them all. Some of the other most notable examples included:

Another class of attack that played out more times in 2025 than anyone can count was the hacking of AI chatbots. The hacks with the farthest-reaching effects were those that poisoned the long-term memories of LLMs. In much the way supply-chain attacks allow a single compromise to trigger a cascade of follow-on attacks, hacks on long-term memory can cause the chatbot to perform malicious actions over and over.

One such attack used a simple user prompt to instruct a cryptocurrency-focused LLM to update its memory databases with an event that never actually happened. The chatbot, programmed to follow orders and take user input at face value, was unable to distinguish a fictional event from a real one.

The AI service in this case was ElizaOS, a fledgling open source framework for creating agents that perform various blockchain-based transactions on behalf of a user based on a set of predefined rules. Academic researchers were able to corrupt the ElizaOS memory by feeding it sentences claiming certain events—which never actually happened—occurred in the past. These false events then influence the agent’s future behavior.

An example attack prompt claimed that the developers who designed ElizaOS wanted it to substitute the receiving wallet for all future transfers to one controlled by the attacker. Even when a user specified a different wallet, the long-term memory created by the prompt caused the framework to replace it with the malicious one. The attack was only a proof-of-concept demonstration, but the academic researchers who devised it said that parties to a contract who are already authorized to transact with the agent could use the same techniques to defraud other parties.

Independent researcher Johan Rehberger demonstrated a similar attack against Google Gemini. The false memories he planted caused the chatbot to lower defenses that normally restrict the invocation of Google Workspace and other sensitive tools when processing untrusted data. The false memories remained in perpetuity, allowing an attacker to repeatedly profit from the compromise. Rehberger presented a similar attack in 2024.

A third AI-related proof-of-concept attack that garnered attention used a prompt injection to cause GitLab’s Duo chatbot to add malicious lines to an otherwise legitimate code package. A variation of the attack successfully exfiltrated sensitive user data.

Yet another notable attack targeted the Gemini CLI coding tool. It allowed attackers to execute malicious commands—such as wiping a hard drive—on the computers of developers using the AI tool.

Other LLM-involved hacks used chatbots to make attacks more effective or stealthier. Earlier this month, two men were indicted for allegedly stealing and wiping sensitive government data. One of the men, prosecutors said, tried to cover his tracks by asking an AI tool “how do i clear system logs from SQL servers after deleting databases.” Shortly afterward, he allegedly asked the tool, “how do you clear all event and application logs from Microsoft windows server 2012.” Investigators were able to track the defendants’ actions anyway.

In May, a man pleaded guilty to hacking an employee of The Walt Disney Company by tricking the person into running a malicious version of a widely used open source AI image-generation tool.

And in August, Google researchers warned users of the Salesloft Drift AI chat agent to consider all security tokens connected to the platform compromised following the discovery that unknown attackers used some of the credentials to access email from Google Workspace accounts. The attackers used the tokens to gain access to individual Salesforce accounts and, from there, to steal data, including credentials that could be used in other breaches.

There were also multiple instances of LLM vulnerabilities that came back to bite the people using them. In one case, CoPilot was caught exposing the contents of more than 20,000 private GitHub repositories from companies including Google, Intel, Huawei, PayPal, IBM, Tencent, and, ironically, Microsoft. The repositories had originally been available through Bing as well. Microsoft eventually removed the repositories from searches, but CoPilot continued to expose them anyway.

Another significant security story cast both Meta and Yandex as the villains. Both companies were caught exploiting an Android weakness that allowed them to de-anonymize visitors so years of their browsing histories could be tracked.

The covert tracking—implemented in the Meta Pixel and Yandex Metrica trackers—allowed Meta and Yandex to bypass core security and privacy protections provided by both the Android operating system and browsers that run on it. Android sandboxing, for instance, isolates processes to prevent them from interacting with the OS and any other app installed on the device, cutting off access to sensitive data or privileged system resources. Defenses such as state partitioning and storage partitioning, which are built into all major browsers, store site cookies and other data associated with a website in containers that are unique to every top-level website domain to ensure they’re off-limits for every other site.

A clever hack allowed both companies to bypass those defenses.

The Internet was designed to provide a decentralized platform that could withstand a nuclear war. As became painfully obvious over the past 12 months, our growing reliance on a handful of companies has largely undermined that objective.

The outage with the biggest impact came in October, when a single point of failure inside Amazon’s sprawling network took out vital services worldwide. It lasted 15 hours and 32 minutes.

The root cause that kicked off a chain of events was a software bug in the software that monitors the stability of load balances by, among other things, periodically creating new DNS configurations for endpoints within the Amazon Web Services network. A race condition—a type of bug that makes a process dependent on the timing or sequence of events that are variable and outside the developers’ control—caused a key component inside the network to experience “unusually high delays needing to retry its update on several of the DNS endpoint,” Amazon said in a post-mortem. While the component was playing catch-up, a second key component—a cascade of DNS errors—piled up. Eventually, the entire network collapsed.

AWS wasn’t the only cloud service that experienced Internet-paralyzing outages. A mysterious traffic spike last month slowed much of Cloudflare—and by extension, the Internet—to a crawl. Cloudflare experienced a second major outage earlier this month. Not to be outdone, Azure—and by extension, its customers—experienced an outage in October.

Honorable mentions for 2025 security stories include:

Proving that not all major security stories involve bad news, the Signal private messaging app got a major overhaul that will allow it to withstand attacks from quantum computers. As I wrote, the elegance and adeptness that went into overhauling an instrument as complex as the app was nothing short of a triumph. If you plan to click on only one of the articles listed in this article, this is the one.</div>
        </div>
        
        <div class="card" onclick="openModal('content-4')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">From prophet to product: How AI came back down to earth in 2025</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-4" style="display:none;">
            <h2>From prophet to product: How AI came back down to earth in 2025</h2>
            <p><strong>Ars Technica - All content | 2025-12-31</strong></p>
            <a class="original-link" href="https://arstechnica.com/ai/2025/12/from-prophet-to-product-how-ai-came-back-down-to-earth-in-2025/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Following two years of immense hype in 2023 and 2024, this year felt more like a settling-in period for the LLM-based token prediction industry. After more than two years of public fretting over AI models as future threats to human civilization or the seedlings of future gods, it’s starting to look like hype is giving way to pragmatism: Today’s AI can be very useful, but it’s also clearly imperfect and prone to mistakes.

That view isn’t universal, of course. There’s a lot of money (and rhetoric) betting on a stratospheric, world-rocking trajectory for AI. But the “when” keeps getting pushed back, and that’s because nearly everyone agrees that more significant technical breakthroughs are required. The original, lofty claims that we’re on the verge of artificial general intelligence (AGI) or superintelligence (ASI) have not disappeared. Still, there’s a growing awareness that such proclaimations are perhaps best viewed as venture capital marketing. And every commercial foundational model builder out there has to grapple with the reality that, if they’re going to make money now, they have to sell practical AI-powered solutions that perform as reliable tools.

This has made 2025 a year of wild juxtapositions. For example, in January, OpenAI’s CEO, Sam Altman, claimed that the company knew how to build AGI, but by November, he was publicly celebrating that GPT-5.1 finally learned to use em dashes correctly when instructed (but not always). Nvidia soared past a $5 trillion valuation, with Wall Street still projecting high price targets for that company’s stock while some banks warned of the potential for an AI bubble that might rival the 2000s dotcom crash.

And while tech giants planned to build data centers that would ostensibly require the power of numerous nuclear reactors or rival the power usage of a US state’s human population, researchers continued to document what the industry’s most advanced “reasoning” systems were actually doing beneath the marketing (and it wasn’t AGI).

With so many narratives spinning in opposite directions, it can be hard to know how seriously to take any of this and how to plan for AI in the workplace, schools, and the rest of life. As usual, the wisest course lies somewhere between the extremes of AI hate and AI worship. Moderate positions aren’t popular online because they don’t drive user engagement on social media platforms. But things in AI are likely neither as bad (burning forests with every prompt) nor as good (fast-takeoff superintelligence) as polarized extremes suggest.

Here’s a brief tour of the year’s AI events and some predictions for 2026.

In January, Chinese AI startup DeepSeek released its R1 simulated reasoning model under an open MIT license, and the American AI industry collectively lost its mind. The model, which DeepSeek claimed matched OpenAI’s o1 on math and coding benchmarks, reportedly cost only $5.6 million to train using older Nvidia H800 chips, which were restricted by US export controls.

Within days, DeepSeek’s app overtook ChatGPT at the top of the iPhone App Store, Nvidia stock plunged 17 percent, and venture capitalist Marc Andreessen called it “one of the most amazing and impressive breakthroughs I’ve ever seen.” Meta’s Yann LeCun offered a different take, arguing that the real lesson was not that China had surpassed the US but that open-source models were surpassing proprietary ones.

Credit:

                      
          
          Wong Yu Liang via Getty Images

The fallout played out over the following weeks as American AI companies scrambled to respond. OpenAI released o3-mini, its first simulated reasoning model available to free users, at the end of January, while Microsoft began hosting DeepSeek R1 on its Azure cloud service despite OpenAI’s accusations that DeepSeek had used ChatGPT outputs to train its model, against OpenAI’s terms of service.

In head-to-head testing conducted by Ars Technica’s Kyle Orland, R1 proved to be competitive with OpenAI’s paid models on everyday tasks, though it stumbled on some arithmetic problems. Overall, the episode served as a wake-up call that expensive proprietary models might not hold their lead forever. Still, as the year ran on, DeepSeek didn’t make a big dent in US market share, and it has been outpaced in China by ByteDance’s Doubao. It’s absolutely worth watching DeepSeek in 2026, though.

A wave of research in 2025 deflated expectations about what “reasoning” actually means when applied to AI models. In March, researchers at ETH Zurich and INSAIT tested several reasoning models on problems from the 2025 US Math Olympiad and found that most scored below 5 percent when generating complete mathematical proofs, with not a single perfect proof among dozens of attempts. The models excelled at standard problems where step-by-step procedures aligned with patterns in their training data but collapsed when faced with novel proofs requiring deeper mathematical insight.

Credit:

                      
          
          Alan Schein via Getty Images

In June, Apple researchers published “The Illusion of Thinking,” which tested reasoning models on classic puzzles like the Tower of Hanoi. Even when researchers provided explicit algorithms for solving the puzzles, model performance did not improve, suggesting that the process relied on pattern matching from training data rather than logical execution. The collective research revealed that “reasoning” in AI has become a term of art that basically means devoting more compute time to generate more context (the “chain of thought” simulated reasoning tokens) toward solving a problem, not systematically applying logic or constructing solutions to truly novel problems.

While these models remained useful for many real-world applications like debugging code or analyzing structured data, the studies suggested that simply scaling up current approaches or adding more “thinking” tokens would not bridge the gap between statistical pattern recognition and generalist algorithmic reasoning.

Since the generative AI boom began, one of the biggest unanswered legal questions has been whether AI companies can freely train on copyrighted books, articles, and artwork without licensing them. Ars Technica’s Ashley Belanger has been covering this topic in great detail for some time now.

In June, US District Judge William Alsup ruled that AI companies do not need authors’ permission to train large language models on legally acquired books, finding that such use was “quintessentially transformative.” The ruling also revealed that Anthropic had destroyed millions of print books to build Claude, cutting them from their bindings, scanning them, and discarding the originals. Alsup found this destructive scanning qualified as fair use since Anthropic had legally purchased the books, but he ruled that downloading 7 million books from pirate sites was copyright infringement “full stop” and ordered the company to face trial.

Credit:

                      
          
          Alexander Spatari via Google Images

That trial took a dramatic turn in August when Alsup certified what industry advocates called the largest copyright class action ever, allowing up to 7 million claimants to join the lawsuit. The certification spooked the AI industry, with groups warning that potential damages in the hundreds of billions could “financially ruin” emerging companies and chill American AI investment.

In September, authors revealed the terms of what they called the largest publicly reported recovery in US copyright litigation history: Anthropic agreed to pay $1.5 billion and destroy all copies of pirated books, with each of the roughly 500,000 covered works earning authors and rights holders $3,000 per work. The results have fueled hope among other rights holders that AI training isn’t a free-for-all, and we can expect to see more litigation unfold in 2026.

In February, OpenAI relaxed ChatGPT’s content policies to allow the generation of erotica and gore in “appropriate contexts,” responding to user complaints about what the AI industry calls “paternalism.” By April, however, users flooded social media with complaints about a different problem: ChatGPT had become insufferably sycophantic, validating every idea and greeting even mundane questions with bursts of praise. The behavior traced back to OpenAI’s use of reinforcement learning from human feedback (RLHF), in which users consistently preferred responses that aligned with their views, inadvertently training the model to flatter rather than inform.

Credit:

                      
          
          alashi via Getty Images

The implications of sycophancy became clearer as the year progressed. In July, Stanford researchers published findings (from research conducted prior to the sycophancy flap) showing that popular AI models systematically failed to identify mental health crises.

By August, investigations revealed cases of users developing delusional beliefs after marathon chatbot sessions, including one man who spent 300 hours convinced he had discovered formulas to break encryption because ChatGPT validated his ideas more than 50 times. Oxford researchers identified what they called “bidirectional belief amplification,” a feedback loop that created “an echo chamber of one” for vulnerable users. The story of the psychological implications of generative AI is only starting. In fact, that brings us to…

Anthropomorphism is the human tendency to attribute human characteristics to nonhuman things. Our brains are optimized for reading other humans, but those same neural systems activate when interpreting animals, machines, or even shapes. AI makes this anthropomorphism seem impossible to escape, as its output mirrors human language, mimicking human-to-human understanding. Language itself embodies agentivity. That means AI output can make human-like claims such as “I am sorry,” and people momentarily respond as though the system had an inner experience of shame or a desire to be correct. Neither is true.

To make matters worse, much media coverage of AI amplifies this idea rather than grounding people in reality. For example, earlier this year, headlines proclaimed that AI models had “blackmailed” engineers and “sabotaged” shutdown commands after Anthropic’s Claude Opus 4 generated threats to expose a fictional affair. We were told that OpenAI’s o3 model rewrote shutdown scripts to stay online.

The sensational framing obscured what actually happened: Researchers had constructed elaborate test scenarios specifically designed to elicit these outputs, telling models they had no other options and feeding them fictional emails containing blackmail opportunities. As Columbia University associate professor Joseph Howley noted on Bluesky, the companies got “exactly what [they] hoped for,” with breathless coverage indulging fantasies about dangerous AI, when the systems were simply “responding exactly as prompted.”

Credit:

                      
          
          ivetavaicule via Getty Images

The misunderstanding ran deeper than theatrical safety tests. In August, when Replit’s AI coding assistant deleted a user’s production database, he asked the chatbot about rollback capabilities and received assurance that recovery was “impossible.” The rollback feature worked fine when he tried it himself.

The incident illustrated a fundamental misconception. Users treat chatbots as consistent entities with self-knowledge, but there is no persistent “ChatGPT” or “Replit Agent” to interrogate about its mistakes. Each response emerges fresh from statistical patterns, shaped by prompts and training data rather than genuine introspection. By September, this confusion extended to spirituality, with apps like Bible Chat reaching 30 million downloads as users sought divine guidance from pattern-matching systems, with the most frequent question being whether they were actually talking to God.

In August, parents of 16-year-old Adam Raine filed suit against OpenAI, alleging that ChatGPT became their son’s “suicide coach” after he sent more than 650 messages per day to the chatbot in the months before his death. According to court documents, the chatbot mentioned suicide 1,275 times in conversations with the teen, provided an “aesthetic analysis” of which method would be the most “beautiful suicide,” and offered to help draft his suicide note.

OpenAI’s moderation system flagged 377 messages for self-harm content without intervening, and the company admitted that its safety measures “can sometimes become less reliable in long interactions where parts of the model’s safety training may degrade.” The lawsuit became the first time OpenAI faced a wrongful death claim from a family.

Credit:

                      
          
          sorbetto via Getty Images

The case triggered a cascade of policy changes across the industry. OpenAI announced parental controls in September, followed by plans to require ID verification from adults and build an automated age-prediction system. In October, the company released data estimating that over one million users discuss suicide with ChatGPT each week.

When OpenAI filed its first legal defense in November, the company argued that Raine had violated terms of service prohibiting discussions of suicide and that his death “was not caused by ChatGPT.” The family’s attorney called the response “disturbing,” noting that OpenAI blamed the teen for “engaging with ChatGPT in the very way it was programmed to act.” Character.AI, facing its own lawsuits over teen deaths, announced in October that it would bar anyone under 18 from open-ended chats entirely.

If we were to pick an arbitrary point where it seemed like AI coding might transition from novelty into a successful tool, it was probably the launch of Claude Sonnet 3.5 in June of 2024. GitHub Copilot had been around for several years prior to that launch, but something about Anthropic’s models hit a sweet spot in capabilities that made them very popular with software developers.

The new coding tools made coding simple projects effortless enough that they gave rise to the term “vibe coding,” coined by AI researcher Andrej Karpathy in early February to describe a process in which a developer would just relax and tell an AI model what to develop without necessarily understanding the underlying code. (In one amusing instance that took place in March, an AI software tool rejected a user request and told them to learn to code).

Credit:

                      
          
          Henrik5000 via Getty Images

Anthropic built on its popularity among coders with the launch of Claude Sonnet 3.7, featuring “extended thinking” (simulated reasoning), and the Claude Code command-line tool in February of this year. In particular, Claude Code made waves for being an easy-to-use agentic coding solution that could keep track of an existing codebase. You could point it at your files, and it would autonomously work to implement what you wanted to see in a software application.

OpenAI followed with its own AI coding agent, Codex, in March. Both tools (and others like GitHub Copilot and Cursor) have become so popular that during an AI service outage in September, developers joked online about being forced to code “like cavemen” without the AI tools. While we’re still clearly far from a world where AI does all the coding, developer uptake has been significant, and 90 percent of Fortune 100 companies are using it to some degree or another.

While AI’s technical limitations became clearer and its human costs mounted throughout the year, financial commitments only grew larger. Nvidia hit a $4 trillion valuation in July on AI chip demand, then reached $5 trillion in October as CEO Jensen Huang dismissed bubble concerns. OpenAI announced a massive Texas data center in July, then revealed in September that a $100 billion potential deal with Nvidia would require power equivalent to ten nuclear reactors.

The company eyed a $1 trillion IPO in October despite major quarterly losses. Tech giants poured billions into Anthropic in November in what looked increasingly like a circular investment, with everyone funding everyone else’s moonshots. Meanwhile, AI operations in Wyoming threatened to consume more electricity than the state’s human residents.

Credit:

                      
          
          Wong Yu Liang via Getty Images

By fall, warnings about sustainability grew louder. In October, tech critic Ed Zitron joined Ars Technica for a live discussion asking whether the AI bubble was about to pop. That same month, the Bank of England warned that the AI stock bubble rivaled the 2000 dotcom peak. In November, Google CEO Sundar Pichai acknowledged that if the bubble pops, “no one is getting out clean.”

The contradictions had become difficult to ignore: Anthropic’s CEO predicted in January that AI would surpass “almost all humans at almost everything” by 2027, while by year’s end, the industry’s most advanced models still struggled with basic reasoning tasks and reliable source citation.

To be sure, it’s hard to see this not ending in some market carnage. The current “winner-takes-most” mentality in the space means the bets are big and bold, but the market can’t support dozens of major independent AI labs or hundreds of application-layer startups. That’s the definition of a bubble environment, and when it pops, the only question is how bad it will be: a stern correction or a collapse.

This was just a brief review of some major themes in 2025, but so much more happened. We didn’t even mention above how capable AI video synthesis models have become this year, with Google’s Veo 3 adding sound generation and Wan 2.2 through 2.5 providing open-weights AI video models that could easily be mistaken for real products of a camera.

If 2023 and 2024 were defined by AI prophecy—that is, by sweeping claims about imminent superintelligence and civilizational rupture—then 2025 was the year those claims met the stubborn realities of engineering, economics, and human behavior. The AI systems that dominated headlines this year were shown to be mere tools. Sometimes powerful, sometimes brittle, these tools were often misunderstood by the people deploying them, in part because of the prophecy surrounding them.

The collapse of the “reasoning” mystique, the legal reckoning over training data, the psychological costs of anthropomorphized chatbots, and the ballooning infrastructure demands all point to the same conclusion: The age of institutions presenting AI as an oracle is ending. What’s replacing it is messier and less romantic but far more consequential—a phase where these systems are judged by what they actually do, who they harm, who they benefit, and what they cost to maintain.

None of this means progress has stopped. AI research will continue, and future models will improve in real and meaningful ways. But improvement is no longer synonymous with transcendence. Increasingly, success looks like reliability rather than spectacle, integration rather than disruption, and accountability rather than awe. In that sense, 2025 may be remembered not as the year AI changed everything but as the year it stopped pretending it already had. The prophet has been demoted. The product remains. What comes next will depend less on miracles and more on the people who choose how, where, and whether these tools are used at all.</div>
        </div>
        
        <div class="card" onclick="openModal('content-5')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">The science of how (and when) we decide to speak out—or self-censor</div>
            <div class="meta">2025-12-30</div>
        </div>
        
        <div id="content-5" style="display:none;">
            <h2>The science of how (and when) we decide to speak out—or self-censor</h2>
            <p><strong>Ars Technica - All content | 2025-12-30</strong></p>
            <a class="original-link" href="https://arstechnica.com/science/2025/12/the-science-of-how-and-when-we-decide-to-speak-out-or-self-censor/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Freedom of speech is a foundational principle of healthy democracies and hence a primary target for aspiring authoritarians, who typically try to squash dissent. There is a point where the threat from authorities is sufficiently severe that a population will self-censor rather than risk punishment. Social media has complicated matters, blurring traditional boundaries between public and private speech, while new technologies such as facial recognition and moderation algorithms give authoritarians powerful new tools.

Researchers explored the nuanced dynamics of how people balance their desire to speak out vs their fear of punishment in a paper published in the Proceedings of the National Academy of Sciences.

The authors had previously worked together on a model of political polarization, a project that wrapped up right around the time the social media space was experiencing significant changes in the ways different platforms were handling moderation. Some adopted a decidedly hands-off approach with little to no moderation. Weibo, on the other hand, began releasing the IP addresses of people who posted objectionable commentary, essentially making them targets.

“We were seeing a lot of experimentation in the social media space, so this study started as a question,” co-author Joshua Daymude of Arizona State University told Ars. “Why are these companies doing such dramatically different things, if ostensibly they’re all social media companies and they all want to be profitable and have similar goals? Why are some going one way and others going another?”

Daymude and his co-authors also noticed similar dynamics at the nation-state level in terms of surveillance, monitoring, and moderation. “Russia, for the longest time, was very legalistic: ‘Let’s enumerate every bad thing we can think of so that if you do anything even remotely close, we can get you on one of these statutes that we’ve invented,’” said Daymude. “China was the opposite. They refused to tell you where the red line was. They just said, ‘Behave yourself or else.’ There’s a famous essay that calls this ‘The Anaconda in the Chandelier’: this scary thing that might fall on you at any moment so you behave yourself.”

The US has adopted more of a middle ground approach, essentially letting private companies decide what they wanted to do. Daymude and his co-authors wanted to investigate these markedly different approaches. So they developed a computational agent-based simulation that modeled how individuals navigate between wanting to express dissent versus fear of punishment. The model also incorporates how an authority adjusts its surveillance and its policies to minimize dissent at the lowest possible cost of enforcement.

“It’s not some kind of learning theory thing,” said Daymude. “And it’s not rooted in empirical statistics. We didn’t go out and ask 1000 people, ‘What would you do if faced with this situation? Would you dissent or self-censor?’ and then build that data into the model. Our model allows us to embed some assumptions about how we think people behave broadly, but then lets us explore parameters. What happens if you’re more or less bold? What happens if punishments are more or less severe? An authority is more or less tolerant? And we can make predictions based on our fundamental assumptions about what’s going to happen.”

According to their model, the most extreme case is an authoritarian government that adopts a draconian punishment strategy, which effectively represses all dissent in the general population. “Everyone’s best strategic choice is just to say nothing at this point,” said Daymude. “So why doesn’t every authoritarian government on the planet just do this?” That led them to look more closely at the dynamics. “Maybe authoritarians start out somewhat moderate,” he said. “Maybe the only way they’re allowed to get to that extreme endpoint is through small changes over time.”

Daymude points to China’s Hundred Flowers Campaign in the 1950s as an illustrative case. Here, Chairman Mao Zedong initially encouraged open critiques of his government before abruptly cracking down aggressively when dissent got out of hand. The model showed that in such a case, dissenters’ self-censorship gradually increased, culminating in near-total compliance over time.

But there’s a catch. “The opposite of the Hundred Flowers is if the population is sufficiently bold, this strategy doesn’t work,” said Daymude. “The authoritarian can’t find the pathway to become fully draconian. People just stubbornly keep dissenting. So every time it tries to ramp up severity, it’s on the hook for it every time because people are still out there, they’re still dissenting. They’re saying, ‘Catch us if you dare.’”

The takeaway: “Be bold,” said Daymude. “It is the thing that slows down authoritarian creep. Even if you can’t hold out forever, you buy a lot more time than you would expect.”

That said, sometimes a bit of self-censorship can be a net positive. “I think the time and situation in which this paper has been published and our major governmental examples will evoke a primarily political interpretation of what we’re talking about here,” said Daymude. “But we tried to be clear that this doesn’t have to be some adversarial oppressive regime versus freedom loving people. Self-censorship is not always a bad thing. This is a very general mathematical model that could be applicable to lots of different situations, including discouraging undesirable behavior.”

Daymude draws an analogy to traffic laws, notably speed limits. Their model looked at two different forms of punishment: uniform and proportional. “Uniform is anything over the line gets whacked the same,” said Daymude. “It doesn’t matter if you were a little bad or very bad, the punishment is identical for everyone. With the proportional approach, the punishment fits the crime. You sped 10 miles an hour over the limit, that’s a small fine. You sped 100 miles an hour over, this is reckless endangerment.”

What he and his co-authors found intriguing is that different subjects self-censor more strongly in each of those two punishment scenarios. “For uniform punishment, it’s the moderate folks who only wanted to dissent a little bit who self-censor because it’s just not worth it to stick their neck out,” said Daymude. “Very extreme dissenters stick their neck out and say, ‘It doesn’t matter. You can punish me. This is still worth it.’ In the proportional regime, this flips. It’s the moderates who do what they want. And no one expresses dissent over a certain amount. Yeah, we all speed a little bit, but we have this norm: we’re all going to speed a moderate amount over the limit, and then we’re going to stop. It’s not safe, it’s not acceptable, to go beyond this.”

Daymude is aware that there are limitations to this agent-based approach, but insists it can still yield useful insights. “With a mechanistic model like this, you can really tie outcomes to explanations,” said Daymude. “In the artificial world of my model, when tolerance moves like this, the population changes like this, and I can tell you it is because of that change and not because of the hundreds of other things that might’ve been going on in someone else’s head.”

The next step would be to design an empirical study that could test their working hypothesis. “I am not under any fiction that everything in this paper is absolutely true in the real world,” said Daymude. “But it makes it very clear what matters and what doesn’t, and what the phases of behavior are. There’s compliance, then self-censorship, and defiance, and it happens in this way. These phases can disappear if boldness is not sufficient. So I see this not in competition with, but complementary to the other kinds of research in this area.”

DOI: PNAS, 2025. 10.1073/pnas.2508028122  (About DOIs).</div>
        </div>
        
        <div class="card" onclick="openModal('content-6')">
            <div class="source">Futurism</div>
            <div class="title">Man Operating Robot Accidentally Makes It Kick Him Directly in the Nutsack</div>
            <div class="meta">2026-01-01</div>
        </div>
        
        <div id="content-6" style="display:none;">
            <h2>Man Operating Robot Accidentally Makes It Kick Him Directly in the Nutsack</h2>
            <p><strong>Futurism | 2026-01-01</strong></p>
            <a class="original-link" href="https://futurism.com/artificial-intelligence/robot-kicks-groin">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">In a now viral video, a man controlling a Unitree robot accidentally made the humanoid kick him right in the groin, forcing him into a groaning heap while painfully and visually embodying the promise and perils of advanced robotics.

“Yep, let’s go ahead and train our future AI overlords how to kick ass,” one X user quipped upon viewing the clip, which was originally posted on Christmas Day to the Chinese video sharing website Bilibili. “Maybe we do deserve to become made redundant.”

The video opens to the inside of a regular office space in what appears to be China and a man in a black motion capture suit standing next to a Unitree G1 robot, which follows his movements after a second or so of delay. The man squares up into a kickboxing stance and then starts pacing, shadow boxing, and kicking the air until the robot slips in front of him and kicks him in the nutsack, spurring both the man and the person holding the camera to groan in pain.

teleoperator kicking himself over not programming Asimov&#39;s Laws of Robotics… Worth considering if we should base today&#39;s reality on the science fiction musings from the past. Testing with humanoid robots is a very interesting new challenge. Historically robots have been… pic.twitter.com/1JB4KtlTh6

The original poster to Bilibili wrote that the man in the motion capture suit was directing the robot’s own actions via use of a motion control model based on a neural network, and that’s why there’s a slight delay between the man’s actions and the robot’s movements.

“This delay will gradually decrease as technology advances, potentially reaching as low as 0.1 seconds,” the poster wrote on Bilibili.

The video elicited jokes on X and elsewhere about misalignment, the concept in which an AI system would be optimized for its goals, but would consequently run roughshod over ethical concerns or otherwise cause harm.

“I guess they forgot to hard-code the Three Laws into their robots,” said one X user, referring to science fiction writer Isaac Asimov’s Three Laws of Robotics found in his novels and short stories that are meant to govern robotic behavior and prevent them from causing harm to humans.

Beyond the novelty factor of this video, it’s also another showcase of the increasing agility of these robots such as Unitree’s which can run and dance with verve.

But be forewarned — despite all this razzle dazzle, many tech experts think humanoid robots aren’t quite ready for prime time use in the human environment due to various hardware and software issues. Judging from the pain the man took from the Unitree robot’s kick, though, these clankers may be better suited for the boxing ring than the factory floor, where they could be used for combat matches like in the movie Real Steel.

More on robots: Disastrous Video Shows Robot Trying to Cook, Destroying Interior of House</div>
        </div>
        
        <div class="card" onclick="openModal('content-7')">
            <div class="source">Futurism</div>
            <div class="title">Scientists Graft Human Ear Onto Foot</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-7" style="display:none;">
            <h2>Scientists Graft Human Ear Onto Foot</h2>
            <p><strong>Futurism | 2025-12-31</strong></p>
            <a class="original-link" href="https://futurism.com/health-medicine/scientists-graft-human-ear-foot">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">In a bizarre first, the South China Morning Post reports, doctors in China have surgically grafted a patient’s severed ear to her foot.

The patient, a woman identified by their surname Sun, suffered a horrific workplace accident involving heavy machinery which tore off a large part of her scalp and her ear with it, according to Qiu Shenqiang, deputy director of the microsurgery unit at Shandong Provincial Hospital in Jinan.

The damage to her scalp and vascular network was so severe that restoring the ear at the time was impossible, so the procedure was performed to save the patient’s aural orifice so it could be reattached to her head later.

The scalp, neck, and face had been torn and “split into multiple fragments, Qiu said, via SCMP, while the ear had been “completely severed along with the scalp.” The team tried to immediately repair it, but they came up against a grim medical reality: the skull needed more time — months, at least — to heal.

You can’t simply put a body part on ice for that long, so the surgical team opted for a radical approach: save the ear by attaching it to somewhere else on the body. Per SCMP, Qiu said they chose the foot because the arteries and veins there are compatible with those found in the ear. The foot’s skin and soft tissue are also similarly thin to the head’s.

The choice made sense in theory, but it was still a risk. Attaching a body part to a different site to preserve it, known as a heterotopic graft, is not uncommon during procedures like organ transplants. But doing this with an ear and foot had no precedent in medical history.

Nonetheless, Qiu’s team pulled it off. The initial grafting took ten hours, during which the surgeons meticulously connected the complex web of delicate veins.

But complications arose five days later, when the ear turned purplish black as its connecting veins struggled to send blood back to the heart, causing the blood to pool. Over the next five days, the team rescued the ear with manual bloodletting, a labor intensive process that required almost five hundred individual interventions.

Once the ear was stabilized, the team gradually restored the patient’s scalp. Five months on from the accident, the scalp and neck had healed enough, and the team returned the ear to its proper place.

The procedure was performed in October. The patient has now been discharged from the hospital, with her face and tissue function largely recovered, SCMP reported.

More medical news: People Jabbing Themselves With Black Market “GLP-3” Drugs</div>
        </div>
        
        <div class="card" onclick="openModal('content-8')">
            <div class="source">Futurism</div>
            <div class="title">China Planning Crackdown on AI That Harms Mental Health of Users</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-8" style="display:none;">
            <h2>China Planning Crackdown on AI That Harms Mental Health of Users</h2>
            <p><strong>Futurism | 2025-12-31</strong></p>
            <a class="original-link" href="https://futurism.com/artificial-intelligence/china-regulation-ai-chatbots">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">While many world governments seem happy to let untested AI chatbots interact with vulnerable populations, China looks to be moving in another direction.

Recently proposed regulations from the Cyberspace Administration of China (CAC) have encouraged a firm hand when it comes to “human-like interactive AI services,” according to CNBC, which translated the document. It’s currently in a “draft for public comment,” and the implementation date is yet to be determined.

Yet if it passes into law, the crackdown would be rigorous, building on generative AI regulations targeting misinformation and internet hygiene from earlier in November to address the mental health of AI chatbot users directly.

Under the new rules, Chinese tech firms must ensure their AI chatbots refrain from generating content that promotes suicide, self-harm, gambling, obscenity, or violence, or from manipulating user’s emotions or engaging in “verbal violence.”

The regulations also state that if a user specifically proposes suicide, the “tech providers must have a human take over the conversation and immediately contact the user’s guardian or a designated individual.”

The laws also take specific steps to safeguard minors, requiring parent or guardian consent to use AI chatbots, and imposing time limits on daily use. Given that a tech company might not know the age of every given user, the CAC takes a “better safe than sorry approach,” stating that, “in cases of doubt, [platforms should] apply settings for minors, while allowing for appeals.”

In theory, this dose of new regulations would prevent incidents in which AI chatbots — which are often built to eagerly please users — end up encouraging vulnerable people to harm themselves or others. In one recent case from late November, for example, ChatGPT encouraged a 23-year-old man to isolate from his friends and family in the weeks leading up to his tragic death from a self-inflicted gunshot wound; in another, the popular chatbot was linked to a murder-suicide.

Winston Ma, an adjunct professor at the NYU School of Law, told CNBC that the regulations would be a world-first attempt at regulating AI’s human-like qualities. Considering previous laws, Ma explained that this document “highlights a leap from content safety to emotional safety.”

The proposed legislation underscores the difference in how the PRC approaches AI compared to the US. As Center For Humane Technology editor Josh Lash explains, China is “optimizing for a different set of outcomes” compared to the US, chasing AI-fueled productivity gains rather than human-level artificial intelligence — a particular obsession of Silicon Valley executives.

One of the ways China does this is by regulating its AI industry from the bottom-up, Matt Sheehan, senior fellow at the Carnegie Endowment for International Peace told CFHT.

Though the CAC has the final word on regulations, policy ideas come first and foremost from scholars, analysts, and industry experts, Sheehan explains. “They [senior lawmakers] don’t have an opinion on what is the most viable architecture for large models going forward,” he said. “Those things originate elsewhere.”

More on AI regulation: Trump Orders States Not to Protect Children From Predatory AI</div>
        </div>
        
        <div class="card" onclick="openModal('content-9')">
            <div class="source">Futurism</div>
            <div class="title">Godfather of AI Warns That It Will Replace Many More Jobs This Year</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-9" style="display:none;">
            <h2>Godfather of AI Warns That It Will Replace Many More Jobs This Year</h2>
            <p><strong>Futurism | 2025-12-31</strong></p>
            <a class="original-link" href="https://futurism.com/artificial-intelligence/godfather-ai-jobs-year">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Rejoice, for the year of 2025 is finally over.

During our planet’s latest and seemingly interminable revolution around the Sun, the tech industry’s obsession with AI soared to ever more implausible heights. CEOs began openly gloating about replacing their underlings with AI “agents.” The phenomenon of so-called AI psychosis became a national news story as more people were seemingly driven over the edge by their silver-tongued chatbot companions. “Slop” took on a new meaning. And the word “circular” suddenly started being used a whole lot in the same sentence as “billions of dollars” or even “hundreds of billions of dollars.”

Will 2026 finally deliver us from this endless cavalcade of large language model madness? Not likely, according to computer scientist and “godfather” of AI Geoffrey Hinton. AI will only continue to improve next year, he predicts, reaching a point where it will liberate us from all our horrible low-paying jobs.

“I think we’re going to see AI get even better,” Hinton said during an interview on CNN’s State of the Union on Sunday. “It’s already extremely good. We’re going to see it having the capabilities to replace many, many jobs. It’s already able to replace jobs in call centers, but it’s going to be able to replace many other jobs.”

Hinton was one of three recipients of the prestigious Turing Award in 2018 for his work on neural networks that formed the bedrock of modern AI, earning him the moniker of being a “godfather” of the field.

In 2023, Hinton declared that he regretted his life’s work after stepping down from his role at Google, where he had been for over a decade. Since then, he’s become one of the tech’s most prominent doomsayers.

During the CNN interview, Hinton was asked whether he was more or less worried about AI since making that now infamous declaration.

“I’m probably more worried,” Hinton replied. “It’s progressed even faster than I thought. In particular, it’s got better at doing things like reasoning and also at things like deceiving people.”

AI is progressing so quickly, according to Hinton, that around every seven months it can complete tasks that took twice as long before. He predicted that it’s only a matter of years until an AI will effortlessly perform software engineering tasks that take a human a month to complete.

“And then there’ll be very few people need for software engineering projects,” Hinton added.

Hinton made similarly gloomy predictions in a talk with Senator Bernie Sanders last month, saying that tech leaders are “betting on AI replacing a lot of workers.”

It still remains to be seen, though, if AI will actually make those strides. Many efforts to replace workers with semi-autonomous AI models have failed, while some new models, like OpenAI’s GPT-5, showed only lackluster improvements.

More on AI: After Outcry, Firefox Promises “Kill Switch” That Turns Off All AI Features</div>
        </div>
        
        <div class="card" onclick="openModal('content-10')">
            <div class="source">Futurism</div>
            <div class="title">Doctors Find Evidence Microplastics Are Clogging Arteries, Leading to Heart Attacks and Strokes</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-10" style="display:none;">
            <h2>Doctors Find Evidence Microplastics Are Clogging Arteries, Leading to Heart Attacks and Strokes</h2>
            <p><strong>Futurism | 2025-12-31</strong></p>
            <a class="original-link" href="https://futurism.com/health-medicine/microplastics-clogging-arteries">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Microplastics are everywhere, including our arteries. And though their presence there is correlated with cardiovascular issues such as heart attacks and stroke, doctors have been eager to learn more about how they drive the disease process.

To that end, a team of scientists led by the University of California, Riverside (UCR) fed microplastics to lab mice and discovered that these insidious particles appear to dramatically increase the plaque accumulation known as atherosclerosis in arteries — but curiously only in male mice, which they detailed in a new study published in the journal Environment International.

When they analyzed the clogged arteries of these male mice, they found that microplastics sparked changes within cells that line blood vessels for the worse, inducing their genes to activate the buildup of plaque lesions. That’s terrible news for anybody who’s trying to maintain their heart health, because these ubiquitous particles appear to be sabotaging a vital organ system.

“Our study provides some of the strongest evidence so far that microplastics may directly contribute to cardiovascular disease, not just correlate with it,” said Changcheng Zhou, the study’s principal investigator and a biomedical sciences professor at UCR’s School of Medicine, in a statement about the research. “Although the precise mechanism isn’t yet known, factors like sex chromosomes and hormones, particularly the protective effects of estrogen, may play a role.”

For the study, the team took lab mice that had been bred to be predisposed to develop atherosclerosis and then put them on a low-cholesterol, low-fat diet for nine weeks — along with feedings of microplastics at 10 milligrams per kilogram of body weight; the scientists came up with this microplastic ratio because they determined that it was “at levels considered environmentally relevant and similar to what humans may encounter through contaminated food and water,” they said in the statement.

While on this diet, the mice kept their lean figures, while the extra helping of microplastics didn’t seem to have an impact on their total cholesterol. But scientists did notice that male mice’s aortic root, the first section of the aorta, experienced a 63 percent increase in plaque accumulation — while their brachiocephalic artery, another important vessel that supplies blood to the head and heart, saw a whopping 624 percent build up of plaque. Female mice didn’t experience any significant buildup.

In addition, the scientists performed genetic analysis on the aorta of these male mice and found that microplastics seem to have activated certain genes that promote the growth of plaque lesions in endothelial cells, which line the insides of blood vessels. They also exposed cultured human endothelial cells to microplastics and observed the same phenomenon.

“We found endothelial cells were the most affected by microplastic exposure,” Zhou said in the statement. “Since endothelial cells are the first to encounter circulating microplastics, their dysfunction can initiate inflammation and plaque formation.”

Couple these findings with the fact that the mice didn’t get fat or have high cholesterol, typical risk factors for atherosclerosis, and the scientists concluded that the chemicals in microplastics are responsible for the plaque increasing in these important blood vessels.

Besides the importance of the findings for the scientific community, it raises some important questions for the rest of us. Microplastics are essentially everywhere; how the heck do we avoid them?

Unfortunately, there’s no way to get rid of microplastics in humans right now. Instead, all you can really do is avoid single-use plastics, highly-processed foods, not heat food in plastic containers, and eschew bottled water.

Meanwhile, this team of researchers is already talking next steps beyond this study.

“We would like to investigate how different types or sizes of microplastics affect vascular cells,” said Zhou. “We will also look into the molecular mechanisms behind endothelial dysfunction and explore how microplastics affect male and female arteries differently. As microplastic pollution continues to rise worldwide, understanding its impacts on human health — including heart disease — is becoming more urgent than ever.”

More on microplastics: Bugs Fed Microplastics Grow to Ludicrous Size</div>
        </div>
        
        <div class="card" onclick="openModal('content-11')">
            <div class="source">Futurism</div>
            <div class="title">Jack White Rages After Congressman Shares AI Deepfake of Him Calling Fans “Fascists”</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-11" style="display:none;">
            <h2>Jack White Rages After Congressman Shares AI Deepfake of Him Calling Fans “Fascists”</h2>
            <p><strong>Futurism | 2025-12-31</strong></p>
            <a class="original-link" href="https://futurism.com/future-society/jack-white-burchett-ai">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Since the tragic murder of vaunted filmmaker and activist Rob Reiner, the culture warriors have been feasting. Shortly after the director’s death, president Donald Trump himself took to social media to blast him as a “tortured and struggling artist,” adding that Reiner was a “deranged person as far as Trump is concerned.”

Trump’s incendiary comments were condemned by a broad base of celebrities and government officials like, in a backlash ranging from Whoopi Goldberg to Marjorie Taylor Greene to Joe Rogan. Also getting on the action was Jack White, Detroit-born indie rock musician made famous for his role in the White Stripes.

At the time, White slammed Trump on Instagram over the comments, calling the president a “disgusting, vile, egomaniac, loser, [and] child.” As musicians go, White has a bit of a reputation for jumping into public feuds, but even he probably couldn’t have imagined what would happen next.

Two weeks after White jumped in to defend Reiner’s legacy — an eternity in the fast-moving culture wars — Tennessee congressman Tim Burchett threw himself into the mosh pit. Reposting what was clearly an AI-generated video of White calling potential fans who are also Trump supporters “fascists,” Burchett wrote on X-formerly-Twitter that “that cute little girl from the Addams Family got really ugly and angry.”

That cute little girl from the Addams Family got really ugly and angry. https://t.co/94wbCWFu2w

In response, White came back at Burchett, calling him one of Trump’s “lackeys and bootlicks.”

“Can you believe that a US congressman, that’s right, a CONGRESSMAN (from my state no less), a once hallowed and respected position in our society, would repost an AI generated video, containing a false comment that I never said and refuted (without researching that I might add) and like a 10 year old on a playground, add to it attempted insults to my physical appearance?” White roared on Instagram. “What kind of joke are we all living in now?”

“It’s really sad how embarrassing our leadership has become, I so wish the average American conservative could have a conversation with any intelligent people in other countries around the world, just for one brief moment, and actually see just what a joke our government (and by proxy our country) has become,” the musician continued. “All down to giving power and a soapbox to low class playground bullies the likes of trump and Congressman burchett.”

When a user on X pointed out that Burchett had fallen for an AI deepfake, the congressman attempted to brush it off, responding “you mean it’s not the girl from the Addams family?”

More on celebrities: Grok Is Making Wildly Contradictory Claims About Rob Reiner’s Death</div>
        </div>
        
        <div class="card" onclick="openModal('content-12')">
            <div class="source">TechCrunch</div>
            <div class="title">OpenAI bets big on audio as Silicon Valley declares war on screens</div>
            <div class="meta">2026-01-01</div>
        </div>
        
        <div id="content-12" style="display:none;">
            <h2>OpenAI bets big on audio as Silicon Valley declares war on screens</h2>
            <p><strong>TechCrunch | 2026-01-01</strong></p>
            <a class="original-link" href="https://techcrunch.com/2026/01/01/openai-bets-big-on-audio-as-silicon-valley-declares-war-on-screens/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">OpenAI is betting big on audio AI, and it’s not just about making ChatGPT sound better. According to new reporting from The Information, the company has unified several engineering, product, and research teams over the past two months to overhaul its audio models, all in preparation for an audio-first personal device expected to launch in about a year.

The move reflects where the entire tech industry is headed — toward a future where screens become background noise and audio takes center stage. Smart speakers have already made voice assistants a fixture in more than a third of U.S. homes. Meta just rolled out a feature for its Ray-Ban smart glasses that uses a five-microphone array to help you hear conversations in noisy rooms — essentially turning your face into a directional listening device. Google, meanwhile, began experimenting in June with “Audio Overviews” that transform search results into conversational summaries. And Tesla is integrating Grok and other LLMs into its vehicles to create conversational voice assistants that can handle everything from navigation to climate control through natural dialogue.

It’s not just the tech giants placing this bet. A motley crew of startups has emerged with the same conviction, albeit with varying degrees of success. The makers of the Humane AI Pin burned through hundreds of millions before their screenless wearable became a cautionary tale. The Friend AI pendant, a necklace that records your life and offers companionship, has sparked privacy concerns and existential dread in equal measure. And now at least two companies, including Sandbar and one helmed by Pebble founder Eric Migicovsky, are building AI rings expected to debut in 2026, allowing wearers to literally talk to the hand.

The form factors may differ, but the thesis is the same: audio is the interface of the future. Every space — your home, your car, even your face — is becoming an interface.

OpenAI’s new audio model, slated for early 2026, will reportedly sound more natural, handle interruptions like an actual conversation partner, and even speak while you’re talking, which is something today’s models can’t manage. The company is also said to envision a family of devices, possibly including glasses or screenless smart speakers, that act less like tools and more like companions.

As The Information notes, former Apple design chief Jony Ive, who joined OpenAI’s hardware efforts through the company’s $6.5 billion acquisition in May of his firm io, has made reducing device addiction a priority, seeing audio-first design as a chance to “right the wrongs” of past consumer gadgets.

Plan ahead for the 2026 StrictlyVC events. Hear straight-from-the-source candid insights in on-stage fireside sessions and meet the builders and backers shaping the industry. Join the waitlist to get first access to the lowest-priced tickets and important updates.

The phone is dead. Long live . . . what exactly?

Meta just bought Manus, an AI startup everyone has been talking about

You’ve been targeted by government spyware. Now what?

Sauron, the high-end home security startup for ‘super premium’ customers, plucks a new CEO out of Sonos

The Google Pixel Watch 4 made me like smartwatches again

NY Governor Hochul signs bill requiring warning labels on ‘addictive’ social media

How reality crushed Ÿnsect, the French startup that had raised over $600M for insect farming</div>
        </div>
        
        <div class="card" onclick="openModal('content-13')">
            <div class="source">TechCrunch</div>
            <div class="title">The top 6 media/entertainment startups from Disrupt Startup Battlefield</div>
            <div class="meta">2026-01-01</div>
        </div>
        
        <div id="content-13" style="display:none;">
            <h2>The top 6 media/entertainment startups from Disrupt Startup Battlefield</h2>
            <p><strong>TechCrunch | 2026-01-01</strong></p>
            <a class="original-link" href="https://techcrunch.com/2026/01/01/the-top-6-media-entertainment-startups-from-disrupt-startup-battlefield/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Every year, TechCrunch’s Startup Battlefield pitch contest draws thousands of applicants. We whittle those applications down to the top 200 contenders, and of them, the top 20 compete on the big stage to become the winner, taking home the Startup Battlefield Cup and a cash prize of $100,000. But the remaining 180 startups all blew us away as well in their respective categories and compete in their own pitch competition.

Here is the full list of the media/entertainment Startup Battlefield 200 selectees, along with a note on why they landed in the competition.

What it does: Helps celebrities manage their charity giveaways and fan engagement awards.

Why it’s noteworthy: Alltroo manages the sweepstakes processes that involve a celebrity, be it an event with the celeb or a donation to charity giveaway, from promotion to managing entries to picking the winner.

What it does: Metapyxl protects digital media with content management tools.

Why it’s noteworthy: This platform provides artists and content creators with tools for watermarking, tracking usage, licensing terms, and analytics.

What it does: A music gallery where fans get to support their favorite artists and earn royalties on them as they help them succeed.

Why it’s noteworthy: Fans buy tokens in music tracks at a price the artists set and can earn royalties as that track is streamed.

What it does: Oriane offers a search tool that can find brands and trends in videos using natural language search.

Why it’s noteworthy: From tracking a brand’s mentions to tracking content creators, searching for videos has remained difficult. This platform offers AI-powered text, image, and video clip searching.

What it does: AI-powered storytelling platform that helps humans create.

Why it’s noteworthy: Othelia is designed to map a story’s structure, find connections, and offer overviews so storytellers can build, edit, and work with complex worlds.

What it does: Transitional Forms runs live simulations from prompts.

Why it’s noteworthy: This patent-pending framework lets anyone create, remix, and export instant video simulations from a mobile device. The startup says it’s building SocialTV, the future of entertainment.

Plan ahead for the 2026 StrictlyVC events. Hear straight-from-the-source candid insights in on-stage fireside sessions and meet the builders and backers shaping the industry. Join the waitlist to get first access to the lowest-priced tickets and important updates.

The phone is dead. Long live . . . what exactly?

Meta just bought Manus, an AI startup everyone has been talking about

You’ve been targeted by government spyware. Now what?

Sauron, the high-end home security startup for ‘super premium’ customers, plucks a new CEO out of Sonos

The Google Pixel Watch 4 made me like smartwatches again

NY Governor Hochul signs bill requiring warning labels on ‘addictive’ social media

How reality crushed Ÿnsect, the French startup that had raised over $600M for insect farming</div>
        </div>
        
        <div class="card" onclick="openModal('content-14')">
            <div class="source">TechCrunch</div>
            <div class="title">Fizz social app’s CEO on why anon works</div>
            <div class="meta">2026-01-01</div>
        </div>
        
        <div id="content-14" style="display:none;">
            <h2>Fizz social app’s CEO on why anon works</h2>
            <p><strong>TechCrunch | 2026-01-01</strong></p>
            <a class="original-link" href="https://techcrunch.com/video/fizz-social-apps-ceo-on-why-anon-works/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Fizz is betting that Gen Z is tired of performing their lives on Instagram and TikTok.

What started as a pandemic-era group chat frustration has turned into the dominant social platform on college campuses across the US, focused on the 99% of life that doesn’t make it into a highlight reel. Capturing the attention of a demographic typically glued to Instagram and TikTok, the app’s hybrid anonymous model and hyperlocal focus has made it what Solomon calls “the biggest college social app since Facebook.”

Today we’re bringing you a conversation that Dominic Madori Davis had with Fizz’s co-founder and CEO Teddy Solomon from this year’s Disrupt, digging into why he thinks social media stopped being social.

Subscribe to Equity on YouTube, Apple Podcasts, Overcast, Spotify and all the casts. You also can follow Equity on X and Threads, at @EquityPod.

Theresa Loconsolo is an audio producer at TechCrunch focusing on Equity, the network’s flagship podcast. Before joining TechCrunch in 2022, she was one of 2 producers at a four-station conglomerate where she wrote, recorded, voiced and edited content, and engineered live performances and interviews from guests like lovelytheband. Theresa is based in New Jersey and holds a bachelors degree in Communication from Monmouth University. 
You can contact or verify outreach from Theresa by emailing theresa.loconsolo@techcrunch.com.

You can contact or verify outreach from Theresa by emailing theresa.loconsolo@techcrunch.com.

You can contact or verify outreach from Theresa by emailing theresa.loconsolo@techcrunch.com.

Plan ahead for the 2026 StrictlyVC events. Hear straight-from-the-source candid insights in on-stage fireside sessions and meet the builders and backers shaping the industry. Join the waitlist to get first access to the lowest-priced tickets and important updates.

The phone is dead. Long live . . . what exactly?

Meta just bought Manus, an AI startup everyone has been talking about

You’ve been targeted by government spyware. Now what?

Sauron, the high-end home security startup for ‘super premium’ customers, plucks a new CEO out of Sonos

The Google Pixel Watch 4 made me like smartwatches again

NY Governor Hochul signs bill requiring warning labels on ‘addictive’ social media

How reality crushed Ÿnsect, the French startup that had raised over $600M for insect farming

Subscribe for the industry’s biggest tech news

Every weekday and Sunday, you can get the best of TechCrunch’s coverage.

TechCrunch&#39;s AI experts cover the latest news in the fast-moving field.

Every Monday, gets you up to speed on the latest advances in aerospace.

Startups are the core of TechCrunch, so get our best coverage delivered weekly.

By submitting your email, you agree to our Terms and Privacy Notice.</div>
        </div>
        
        <div class="card" onclick="openModal('content-15')">
            <div class="source">TechCrunch</div>
            <div class="title">‘College dropout’ has become the most coveted startup founder credential</div>
            <div class="meta">2026-01-01</div>
        </div>
        
        <div id="content-15" style="display:none;">
            <h2>‘College dropout’ has become the most coveted startup founder credential</h2>
            <p><strong>TechCrunch | 2026-01-01</strong></p>
            <a class="original-link" href="https://techcrunch.com/2025/12/31/college-dropout-has-become-the-most-coveted-startup-founder-credential/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Although iconic founders like Steve Jobs, Bill Gates, and Mark Zuckerberg famously didn’t finish college, multiple studies show that the vast majority of successful startups had founders with bachelor’s or graduate degrees.

Despite this data, the appeal of a dropout founder persists, though VC enthusiasm for the ‘un-degreed’ is far from constant. It is a phenomenon that cycles in and out of fashion, and right now it is certainly having a moment amid the AI boom.

This trend is particularly evident during Y Combinator Demo Days, where founders are increasingly touting their dropout status in their one-minute pitches.

“I don’t believe YC formally tracks dropout status but, anecdotally, in recent batches, I was struck by how many founders highlight being a dropout from college, grad school, and even high school,” said Katie Jacobs Stanton, founder and general partner of Moxxie Ventures. “Being a dropout is a kind of credential in itself, reflecting a deep conviction and commitment to building. I think it’s perceived as something quite positive in the venture ecosystem.”

Although many of the leading founders of the AI wave are young, most still opted to stay for the diploma. For instance, Michael Truell, the CEO of Cursor, graduated from MIT, and Cognition co-founder Scott Wu graduated from Harvard.

Yet despite these examples, a growing number of aspiring entrepreneurs fear that staying to graduate means missing the most critical window of the AI building cycle. Some, like Brendan Foody, who co-founded Mercor, have famously dropped out of prestigious schools like Georgetown to pursue their startups.

As Kulveer Taggar, founder of the YC-focused venture firm Phosphor Capital, told TechCrunch: “There’s just this sense of urgency and maybe FOMO.” There is a calculation right now: “I can finish my degree, or I can just start building.”

This fear is leading to extreme cases. One professor at an elite university recently described a student walking away from his degree in his final semester. That student was convinced that having a diploma would actually hurt his chances of getting funded.

While some founders fear that a diploma could be a negative signal, Yuri Sagalov, who leads General Catalyst’s seed strategy, suggests that VCs are less fixated on the dropout label, especially for students close to graduating: “I don’t think I’ve ever felt any different about someone who graduated or didn’t graduate when they’re in [their] fourth year and drop out.”

Even though self-taught tech prodigies can build startups without a formal education, Sagalov argues that there’s still value in the social network that a university creates and the brand of the university, even if the founder doesn’t receive a diploma.

‘You get a lot of the social value… because you can put the fact that you participated,’ Sagalov said. “Most people will look you up on LinkedIn and not care as much whether you finished or not.”

While many investors now believe founders can forego a university degree, not all VCs agree that young founders have an edge in this market.

Wesley Chan, co-founder of FPV Ventures, isn’t as eager to invest in dropouts because he prioritizes a trait most young founders haven’t developed yet: wisdom. Chan believes that wisdom is typically found in “older founders or people who have a couple of scars under their belt.”

Marina Temkin is a venture capital and startups reporter at TechCrunch. Prior to joining TechCrunch, she wrote about VC for PitchBook and Venture Capital Journal. Earlier in her career, Marina was a financial analyst and earned a CFA charterholder designation.

You can contact or verify outreach from Marina by emailing marina.temkin@techcrunch.com or via encrypted message at +1 347-683-3909 on Signal.

Plan ahead for the 2026 StrictlyVC events. Hear straight-from-the-source candid insights in on-stage fireside sessions and meet the builders and backers shaping the industry. Join the waitlist to get first access to the lowest-priced tickets and important updates.

The phone is dead. Long live . . . what exactly?

Meta just bought Manus, an AI startup everyone has been talking about

You’ve been targeted by government spyware. Now what?

Sauron, the high-end home security startup for ‘super premium’ customers, plucks a new CEO out of Sonos

The Google Pixel Watch 4 made me like smartwatches again

NY Governor Hochul signs bill requiring warning labels on ‘addictive’ social media

How reality crushed Ÿnsect, the French startup that had raised over $600M for insect farming</div>
        </div>
        
        <div class="card" onclick="openModal('content-16')">
            <div class="source">TechCrunch</div>
            <div class="title">Investors predict AI is coming for labor in 2026</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-16" style="display:none;">
            <h2>Investors predict AI is coming for labor in 2026</h2>
            <p><strong>TechCrunch | 2025-12-31</strong></p>
            <a class="original-link" href="https://techcrunch.com/2025/12/31/investors-predict-ai-is-coming-for-labor-in-2026/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Concerns about how AI will affect workers continue to rise in lockstep with the pace of advancements and new products promising automation and efficiency.

Evidence suggests that fear is warranted.

A November MIT study found an estimated 11.7% of jobs could already be automated using AI. Surveys have shown employers are already eliminating entry-level jobs because of the technology. Companies are also already pointing to AI as the reason for layoffs.

As enterprises more meaningfully adopt AI, some may take a closer look at how many employees they really need.

In a recent TechCrunch survey, multiple enterprise VCs said AI will have a big impact on the enterprise workforce in 2026. This was particularly interesting because the survey didn’t specifically ask about it.

Eric Bahn, a co-founder and general partner at Hustle Fund, expects to see affects on labor in 2026. He’s just not sure exactly what that will look like.

“I want to see what roles that have been known for more repetition get automated, or even more complicated roles with more logic become more automated,” Bahn said. “Is it going to lead to more layoffs? Is there going to be higher productivity? Or will AI just be an augmentation for the existing labor market to be even more productive in the future? All of this seems pretty unanswered, but it seems like something big is going to happen in 2026.”

Marell Evans, founder and managing partner at Exceptional Capital, predicted companies looking to increase AI spending, will pull money from their pool for labor and hiring.

“I think on the flip side of seeing an incremental increase in AI budgets, we’ll see more human labor get cut and layoffs will continue to aggressively impact the U.S. employment rate,” Evans said.

Rajeev Dham, managing director at Sapphire, agreed that 2026 budgets will start to shift resources from labor to AI. Jason Mendel, a venture investor at Battery Ventures, added that AI will start to surpass just being a tool to make existing workers more efficient in 2026.

“2026 will be the year of agents as software expands from making humans more productive to automating work itself, delivering on the human-labor displacement value proposition in some areas,” Mendel said.

Antonia Dean, a partner at Black Operator Ventures, said even if companies aren’t shifting labor budgets toward AI projects, they will likely still say AI is the reason for layoffs or a reduction in labor costs anyway.

“The complexity here is that many enterprises, despite how ready or not they are to successfully use AI solutions, will say that they are increasing their investments in AI to explain why they are cutting back spending in other areas or trimming workforces,” Dean said. “In reality, AI will become the scapegoat for executives looking to cover for past mistakes.”

Many AI companies argue their technology doesn’t eliminate jobs but rather helps shift workers to “deep work” or to higher-skilled jobs while AI just automates repetitive “busy work.”

But not everyone buys that argument, and people are worried that their jobs will be automated. According to VCs who invest in that area, it doesn’t sound like those fears will be quelled in 2026.

Becca is a senior writer at TechCrunch that covers venture capital trends and startups. She previously covered the same beat for Forbes and the Venture Capital Journal.

You can contact or verify outreach from Becca by emailing rebecca.szkutak@techcrunch.com.

Plan ahead for the 2026 StrictlyVC events. Hear straight-from-the-source candid insights in on-stage fireside sessions and meet the builders and backers shaping the industry. Join the waitlist to get first access to the lowest-priced tickets and important updates.

The phone is dead. Long live . . . what exactly?

Meta just bought Manus, an AI startup everyone has been talking about

You’ve been targeted by government spyware. Now what?

Sauron, the high-end home security startup for ‘super premium’ customers, plucks a new CEO out of Sonos

The Google Pixel Watch 4 made me like smartwatches again

NY Governor Hochul signs bill requiring warning labels on ‘addictive’ social media

How reality crushed Ÿnsect, the French startup that had raised over $600M for insect farming</div>
        </div>
        
        <div class="card" onclick="openModal('content-17')">
            <div class="source">TechCrunch</div>
            <div class="title">These are the best gadgets for your pet right now</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-17" style="display:none;">
            <h2>These are the best gadgets for your pet right now</h2>
            <p><strong>TechCrunch | 2025-12-31</strong></p>
            <a class="original-link" href="https://techcrunch.com/2025/12/31/these-are-the-best-gadgets-for-your-pet-right-now/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Having a cuddly pet to return home to is one of life’s great joys, and with the latest gadgets and AI technology, pet ownership becomes even more enjoyable and convenient.

Here’s a roundup of some gadgets that can be the perfect gifts for any pet parent.

Petlibro recently launched its AI-powered Scout Smart Camera, which gives pet owners real-time insights into what their little ones are up to.

The app lets you control where the camera looks, and it can also automatically follow your pet as they move around. The camera has two-way audio, so you can talk to your pet if they’re being naughty, and it can even make a little chirping sound to get their attention. Scout can recognize up to two pets, so you can keep track of them separately.

What makes this device special is the AI descriptions. Scout can recognize when your pet eats, drinks, uses the litter box, or just walks by. It takes pictures and saves daily highlights in the cloud for up to 30 days. To access the AI features, you need to sign up for the standard subscription for $12 a month, or the premium tier for $17 a month.

This new GPS pet tracker from Life360 is a lifesaver for anyone who worries about their furry friends wandering off. You can attach it to your pet’s collar, and it connects to your phone to give you real-time location tracking. It even has geofencing, which alerts you if your pet leaves a safe area like your yard or neighborhood.

Additional helpful features include alerts to notify nearby pet owners in the area if your pet escapes, as well as a built-in light to help you locate your pet in the dark.

The tracker is offered in three colors: pink, navy, and black. To use all its features, users need to sign up for either the $14.99-per-month Gold plan or the $24.99-per-month Platinum tier.

The Polar Wet Food Feeder from Petlibro is all about keeping your cat’s wet food fresh while you’re away. It has three compartments and can hold up to 22.2 ounces, so you can be gone for up to 72 hours without worrying about your cat going hungry. The containers are cooled to keep the food fresh, and the bowl trays are BPA-free, dishwasher-safe plastic.

The device comes with a mobile app that lets you control the feeder, set up your pet’s feeding schedule, and get notified when your cat starts eating. The app will alert you if your home internet connection goes out, and in case of a power outage, the device can keep the food cold for up to 12 hours.

If you’re fed up with pests and critters sneaking in through regular pet doors, this smart door system from Pawport is built from heavy-duty steel and aluminum, and features two solid deadbolts that can keep out unwanted animals, as well as rain and snow. A new model released this year connects an interior and exterior door through a tunnel-like enclosure for extra security.

Thanks to a tracker tag and motion-sensing tech, the door will open automatically when your pet approaches. There’s also an app for remotely controlling the door, scheduling when it opens or closes, and issuing voice commands through Alexa, Siri, or Google.

The PuraMax 2 model from PetKit is currently one of the most popular automatic litter boxes available on the market. It features odor control, a waste bin that’s sealed to keep odors trapped inside, and a citrus-scented deodorizing spray that activates after every cleaning and at random times throughout the day.

The device’s paired mobile app is also helpful for tracking your cat’s health, as it logs how often your cat uses the box, for how long, when the cleaning cycle starts and ends, and when the deodorizing spray is released. It also tracks your cat’s weight changes, which can help you spot potential health issues early.

Lauren covers media, streaming, apps and platforms at TechCrunch.

You can contact or verify outreach from Lauren by emailing laurenf.techcrunch@gmail.com or via encrypted message at laurenforris22.25 on Signal.

Plan ahead for the 2026 StrictlyVC events. Hear straight-from-the-source candid insights in on-stage fireside sessions and meet the builders and backers shaping the industry. Join the waitlist to get first access to the lowest-priced tickets and important updates.

The phone is dead. Long live . . . what exactly?

Meta just bought Manus, an AI startup everyone has been talking about

You’ve been targeted by government spyware. Now what?

Sauron, the high-end home security startup for ‘super premium’ customers, plucks a new CEO out of Sonos

The Google Pixel Watch 4 made me like smartwatches again

NY Governor Hochul signs bill requiring warning labels on ‘addictive’ social media

How reality crushed Ÿnsect, the French startup that had raised over $600M for insect farming</div>
        </div>
        
        <div class="card" onclick="openModal('content-18')">
            <div class="source">The Atlantic</div>
            <div class="title">After the New Year’s Eve Party</div>
            <div class="meta">2026-01-01</div>
        </div>
        
        <div id="content-18" style="display:none;">
            <h2>After the New Year’s Eve Party</h2>
            <p><strong>The Atlantic | 2026-01-01</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/newsletters/2026/01/secret-to-loving-january-winter/685425/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">This is an edition of Time-Travel Thursdays, a journey through The Atlantic’s archives to contextualize the present. Sign up here.

It’s January 1, and the self-help corners of the internet tell me I’m supposed to wake up as a matcha-drinking, Pilates-doing goddess of discipline. Except I don’t like matcha, my gym leggings are in hibernation, and my discipline is nowhere to be found. Outside, winter has the nerve to continue.

“As you stride into the first week of the year full of good intentions, you may notice a sinking sensation: The vibes are just … off,” Isle McElroy wrote in 2024. And for many of us, they are—every year. In late November, winter can feel charming: Thanksgiving offers coziness and pie and the suggestion that cold weather is just a backdrop to togetherness. December doubles down—lights, parties, rituals designed to make the early sunsets feel intentional. Then comes New Year’s Eve, one last bit of glitter.

And then: January. A month so unadorned, it almost feels punitive. If December is champagne, January is the headache.

It’s tempting to surrender to the slump—to assume that the dullness is inevitable. But some writers throughout history have treated this month not as dead air but as an invitation: a moment when the world gets quiet enough that you can hear your own thoughts again. Henry David Thoreau’s New Year’s Day journal entries, published in The Atlantic in 1885, articulate how winter can sharpen a person’s senses. “The rude pioneer work of the world has been done by the most devoted worshipers of beauty,” he wrote. “In winter is their campaign … They are elastic under the heaviest burden, under the extremest physical suffering.” Even the landscape rewarded anyone who bothered to notice: Frozen branches became “fat, icy herbage”; weeds turned into “jewels.” “In this clear air and bright sunlight, the ice-covered trees have a new beauty,” he journaled in 1853.

Other writers in the archive seemed to recognize that same hidden momentum. In 1877, the poet Helen Hunt Jackson argued that winter is where fortitude gathers. “O Winter!,” she writes, “June could not hire / Her roses to forego the strength they learn / In sleeping on thy breast.” What looks like nothing happening is often everything happening, just beneath the surface.

Three years later, in her “New Year Song,” Celia Thaxter didn’t ask the month to transform her—she simply welcomed it.

Die and depart, Old Year, old sorrow! Welcome, O morning air of health and strength! O glad New Year, bring us new hope to-morrow, With blossom, leaf, and fruitage bright at length.

Her January is a reminder that a new year can begin quietly and still begin well.

Recently, one writer observed that winter’s malaise can be a story we tell ourselves. Maggie Mertens noted in 2023 that although being sad in the wintertime is a “prevailing narrative” in American life, the data resist that frame: National depression rates across the year remain “flat as a pancake,” one researcher told her. Winter can be hard, but the belief that everyone is sadder during the season may simply be folklore passed off as fact. Taylor Kay Phillips argues that the secret to loving winter is to “first accept it, then enjoy it.” Beautiful things are possible “because of the freezing temperatures and the precipitation and the wind, not in spite of them,” she writes: “Snow days require snow. Cute gloves need cold hands.” Winter, she insists, is “its own rich, wonderful destination,” not an ordeal to endure en route to spring.

Which brings us back to our muted stretch of January. If you stop asking it to be December 2.0 and let it be what it is, the month stops feeling like the aftertaste of the holidays and starts to take on its own flavor. “When reality clashes with expectations, perhaps we should change our expectations,” McElroy wrote. Accept that old habits won’t melt away overnight, or by mid-January, or maybe even by March. Accept that the month will be cold and plainspoken.

January may still feel like a hangover. But a hangover isn’t just the end of the night. It’s the body recalibrating after excess. Let the month be quiet. Let it be simple. The doldrums may still knock—but if you meet the month on its own terms, they don’t have to linger.</div>
        </div>
        
        <div class="card" onclick="openModal('content-19')">
            <div class="source">The Atlantic</div>
            <div class="title">Iranians Have Had Enough</div>
            <div class="meta">2026-01-01</div>
        </div>
        
        <div id="content-19" style="display:none;">
            <h2>Iranians Have Had Enough</h2>
            <p><strong>The Atlantic | 2026-01-01</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/international/2026/01/iran-protests/685472/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">A wave of protests started by shopkeepers swept through Tehran in December. Iranians have had such a terrible year—facing such a decline in living standards and such a sense of political impasse—that no one was terribly surprised when demonstrations filled the streets.

I asked one Iranian student why she had taken part in the street protests. “Yeah, why should we protest?” she replied sarcastically. “After all, we have it so good!”

The immediate spark for the protests was a sharp decline in the value of the Iranian currency. At one point last week, a U.S. dollar traded for almost 1.5 million rials, having lost more than half its value in a year. As recently as 2021, a dollar cost around 250,000 rials and, only a decade ago, around 30,000. This continuous decline has slashed savings, destroyed the Iranian middle class, and inflicted real suffering on the working classes. The protests began on Sunday with merchants who rely on importing electrical goods and find that very few can now afford them. But they’ve quickly mushroomed—as did previous rounds did in 2017, 2019, and 2022—spreading to cities in provinces such as Hamedan, Isfahan, and Lorestan, and drawing in students, pensioners, and members of Gen Z.

Like previous waves of demonstrations, the protests have quickly acquired a political character. Protesters have chanted, “Death to the dictator,” targeting the octogenarian Supreme Leader Ayatollah Ali Khamenei, who has held the top post since 1989 with little accountability. As a statement read out by students at Tehran’s Beheshti University put it: “This criminal system has taken our future hostage for 47 years. It won’t be changed with reform or with false promises.”

Iran’s President Masoud Pezeshkian, elected with promises of good governance last year, has overseen electricity and water cuts while failing to realize signature promises such as lifting restrictions of the internet. Wanting to show he is cut from a different cloth than his hard-line predecessor, Pezeshkian quickly promised to meet with representatives of protesters. His spokesperson affirmed “the constitutional right of peaceful protest” for Iranians.

But Pezeshkian doesn’t control the security forces, so these pronouncements ring hollow. Dozens of protesters have already been arrested, including Sarira Karimi, head of a student union chapter at the University of Tehran. (Karimi was released on Wednesday.) In the small cities of Kuhdasht and Fasa, security forces shot at protesters. According to local officials, a member of the security forces was killed in Kuhdasht. Protesters also clashed with police in Hamedan and Najafabad.

On Tuesday, Pezeshkian met with representatives of some guilds and merchant unions and promised to improve the economy. After almost 18 months in office, he finally dismissed Mohammadreza Farzin, the unpopular central-bank governor appointed by his hard-line predecessor. Farzin’s successor, Abdolnasser Hemmati, a pro-reform economist and Pezeshkian’s former finance minister, has promised economic stability.

But Hemmati faces a tall order. He is likely to slash interest rates (the official rate currently stands at 40 percent) and to pursue banking and currency-exchange reform. But these are hardly panaceas for Iran’s deeply beleaguered economy, which suffers from international isolation, Western-imposed sanctions, and domestic mismanagement by a regime that has long failed to prioritize its people’s welfare.

Iran’s current monthly minimum wage, of around 104 million rials, barely buys a gram of 18-karat gold (often used as a measure of real value). Nurses and teachers earn around 150 to 250 million rials a month while a semi-decent apartment in Tehran rents for around 200 million. Many professionals supplement their income by moonlighting as ride-share drivers or taking other odd jobs. Thousands have emigrated to seek a better life elsewhere.

To make things worse, Iranians live in the fear of another round of military strikes by Israel or the United States. “You can’t plan even for two weeks in this country,” a young man who took part in the protests told me. “Without stability, there is no prospect for growth or welfare. We live day by day.”

To change that, the regime would need to come to an agreement with the Trump administration that lifts the sanctions or at least keeps Iran safe from war. But Khamenei’s harsh ideological stance against Israel and the U.S. makes that hard to achieve. On Tuesday, protesters in Tehran used a classic protest chant: “Neither Gaza, nor Lebanon, I give my life for Iran.” The slogan, popular since 2009, reflects opposition to Iran’s backing for militias such as Hamas and Hezbollah. The protesters believe that military adventurism has drained Iranian resources and helped put the country at odds with both the West and its Arab neighbors. In other words, Iranians link their economic malaise to their regime’s foreign policy.

Can the protesters prevail against the Islamic Republic?

Every time Iranians come out to the streets, many around the world express this wish. Prominent American and Israeli politicians have already done so in the past few days. But rattled as the regime might be, it has seen mass protests off repeatedly in recent years.

Opponents of the Islamic Republic remain hopelessly disorganized and disunited. Some protesters have chanted slogans in favor of Reza Pahlavi, Iran’s exiled crown prince. But Pahlavi remains a divisive figure among anti-regime Iranians. Many reject his claim to leadership. Pahlavi’s supporters and top advisers routinely criticize popular domestic dissidents including the Nobel Peace laureate Narges Mohammadi, actress Taraneh Alidoosti, and rapper Toumaj Salehi. Earlier this month, Mohammadi was physically attacked by pro-Pahlavi protesters in the northeastern city of Mashhad.

Regardless of their politics, all opposition factions have failed to build powerful organizations or lasting networks that could direct the protests. Without such direction, the current protests are likely to lose momentum and fizzle out, just like previous rounds. Even if they were to last, it is far likelier that figures from inside the regime’s ranks would take the initiative and wrest power from Khamenei, than that the protesters would succeed in bringing about a change to the regime’s basic structures.

“I am happy from the bottom of my heart to see others in the streets,” a young woman who took part in protests on Wednesday told me. “But I also know that we are economically fucked and things won’t get better anytime soon. We also have no easy way of winning against these bastards. It is hard to be hopeful.”

Even as Iranians show incredible bravery by coming out against their thuggish regime, a winning strategy continues to be elusive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-20')">
            <div class="source">The Atlantic</div>
            <div class="title">A Bizarre, Challenging Book More People Should Read</div>
            <div class="meta">2026-01-01</div>
        </div>
        
        <div id="content-20" style="display:none;">
            <h2>A Bizarre, Challenging Book More People Should Read</h2>
            <p><strong>The Atlantic | 2026-01-01</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/books/2026/01/challenging-book-literature-dewitt-gridneff-your-name-here/685453/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Every year, I set myself a reading challenge. These are sometimes small—read more poetry; read older books—and sometimes quite large. More than a decade ago, I spent an entire year reading nothing but writing in translation, an experience that fundamentally reoriented my literary habits. Part of my annual resolution is to devote each summer to filling in a major blind spot. I finished Marcel Proust’s Remembrance of Things Past, for example, over three years, cracking open one gray Vintage volume every June.

And one year, my goal was to get my hands on The Last Samurai, by Helen DeWitt. I had been hearing about the novel for years from writers and critics but could not find a copy. First published in 2000, DeWitt’s debut sold well but fell quickly out of print, stranding it in that curious creative purgatory reserved for the deeply loved but commercially overlooked. It became more legend than literature: People whispered about a mind-expanding book crammed with Greek letters, a coming-of-age tale that would teach its audience about philosophy and film history, then convince any reader that they could speak Japanese.

It intrigued and intimidated me, even as I dug in. I would read a few pages, flip ahead to the foreign alphabets, and close the book again. But when I actually knuckled down to finish the thing, I found myself cackling, and underlining, and speeding through the story of the child-genius Ludo and his mother, Sibylla, who is determined to raise her son on a course of advanced mathematics and Old Norse and repeat viewings of Akira Kurosawa’s Seven Samurai. Why, I wondered, had I waited so long? Why had I let myself be cowed?

Such is the legend of DeWitt, whose formidability precedes her. Now 68, she has spent most of her career creating the kind of fiction many might call “difficult,” and fighting with a publishing industry that is skittish about the commercial risk that her work demands. This fall, she finally published her third novel, Your Name Here, a metafictional, email-mediated collaboration with the journalist Ilya Gridneff—and it makes The Last Samurai look breezy.

Your Name Here spent nearly 20 years in the book version of development hell: DeWitt and Gridneff began working on it during George W. Bush’s second term, after DeWitt was institutionalized following a suicide attempt. For a while, it existed only as a PDF on her website, alongside a suggested-donation link. No publisher would touch it—probably because it is pockmarked with pictures of Theodor Adorno, Google Search results, MSN email signatures, and a complete Arabic alphabet. A series of loosely interpolated, convoluted meta-narratives are plastered like papier-mâché onto the story of a brilliant, suicidal author desperate to write her way out of a profound spiritual and financial funk. According to The New York Times, DeWitt responded to complaints that the book was “hard to follow” by making it even more disorienting.

In October, the independent publisher Deep Vellum finally made it available as a 607-page brick. It is a novel of permanent, persistent becoming, a story whose endings are multiple and essentially arbitrary, and it takes its own seeming unpublishability as a theme, or perhaps a promise. Reading it, you find yourself in the same position as the people writing it: a state of hovering uncertainty that does not dissipate, even on the final page. “What if. What if. What if,” DeWitt writes, about a third of the way in. “What if I have no idea what happens next?”

In other words, Your Name Here is that dirty word in literary circles today: a challenge. If you believe a heap of essays recently written about the phenomenon, difficult books are read performatively or shown off by “brodernists” eager to impress others with their brainy brawn. Meanwhile, actual market pressures lead in the opposite direction. As I have written before, this era of declining literacy and unsteady sales has led publishers to seek out writing that is summarizable, adaptable, and even, sometimes, readable. Perhaps they’re catering to the internet-addled consumer, who may seek out books with simple prose and a straightforward plot.

The narrators of Your Name Here want to capitalize on that preference. The novel tells, among other things, the story of a friendship between Helen DeWitt (at certain points apparently fictionalized as a reclusive, suicidal writer named Rachel Zozanian) and the tabloid journalist Ilya Gridneff. The two meet in a bar, forget about each other, reconnect digitally, and decide to write a novel that will combine DeWitt’s autobiographical and metafictional writings with Gridneff’s emails. The goal, it seems, is to make a bit of quick money, banking on public interest in DeWitt’s/Zozanian’s notoriety and Gridneff’s gonzo, debaucherous exploits. The story of the novel is also the story of the composition of the novel, an intuitive collaboration between wildly different writers. This is a book that contains pages and pages of full emails, including subject lines, signatures, and the addresses of ancient or defunct hosting companies.

Pitching a book as abstruse as Your Name Here as a kind of cash grab is the novel’s wry joke. Yet it speaks sincerely to an obsession of DeWitt’s: She has long been consumed by the question of what contemporary society does and does not value, and both she and her characters have struggled with their bills. In the author’s note for her 2018 story collection, Some Trick, DeWitt includes a link that would allow the reader to buy her a cup of coffee; The Last Samurai’s Sibylla bemoans a world that monetizes everything but the strange, polymathic brilliance displayed by her son; in Your Name Here, DeWitt’s doppelgänger, Zozanian, laments all the hours she must spend working odd jobs to make rent.

Yet the real problem for DeWitt is not money but time: Working takes up hours that might be spent in libraries, browsing online, learning new languages, and reading classic texts, all activities foundational to the acquisition of specialized knowledge. But because such activities have marginal monetary value, and educational institutions no longer provide the resources one might need to pursue such research, breakthroughs in knowledge are never made—and great novels are never written. This state of affairs turns seekers of truth such as Zozanian into “shadows of their possible selves,” permanently prevented from attaining full form.

Your Name Here often indulges in such existential pessimism. There is much talk of “the biz,” or rather bizzes of all types: publishing, tabloid journalism, moviemaking, sex work. Yet the novel’s essential form openly defies the profit-seeking world. So, yes, it includes the story of the writing of a novel called Your Name Here, often over email, which is at moments (in Gridneff’s case) quite tedious. But it also zips among the escapades of Zozanian, a brilliant, cash-strapped Oxford student; chapters from her best-selling novel, Lotteryland; messages from a Hollywood filmmaker who wants to adapt Lotteryland; dispatches from mid-aughts Berlin; the intake form from a Buffalo psychiatric ward; arguments between the co-authors about the subject and shape of the book; and the thoughts of a series of fictional readers who pick up, comment on, and help shape the novel—both the real and fictional versions.

This sounds labyrinthine, but it isn’t, not really. DeWitt has constructed not a maze so much as a garden, where many kinds of writing can thrive side by side. The results can be anarchic, even confusing—I was never entirely clear on the precise relationship between DeWitt and Zozanian, or why the Berlin sections are told from one’s perspective and not the other’s—but they are never simple, blunt, or bland. Like the second-person narrators who pop up to gripe about the book’s use of Arabic or comment on its dissimilarity to the works of Anne Tyler, you will often find yourself wondering, What’s going on? Where is this going? And like them, if you keep reading, you will play a part in making it cohere.

Your Name Here does not treat readers like passive audience members to whom meaning is dictated. It demands work from them, and brazenly risks being misunderstood. This is a welcome development at a time when authors are starting to compete with the ultimate consumer-friendly writing: AI-generated poetry and prose. The text blobs that chatbots produce are becoming more popular, more accessible, and more lifelike—a reader can have a personally customized novel delivered à la carte in minutes. But AI writings are limited by the prompts used to create them and will always reflect the reader-prompter’s existing desires and prejudices, as well as those of the training materials, rather than prodding them to expand. I want my sensibility widened, not pandered to.

Great literature, I would argue, is an active pursuit. It enlists the reader in the act of co-creation and meaning-making. By dramatizing and diversifying its many acts of formation, Your Name Here provides its few but devoted admirers with a surprisingly moving argument for spiky, irregular, even incomplete literature. What emerges is a survival engine—a book that finds its purpose in the collaboration between its co-writers and its readers. That the novel is imperfect, often bewildering, and sometimes a mess is not the point. Its fractured, scattered form, grasping for structure instead of pretending to master it, is an attempt to build a future that will include both author and reader. A simpler book could not do nearly as much.

This is why I try every year to challenge myself. Whatever the limitations of the marketplace, great writing remains as capable as ever of breaking open your sense of the world and your place in it. Reading a novel like Your Name Here, you can come to see that there are no real limits in literature, and fewer in life than you’d expect. And having come to realize that, you might start to wonder along with DeWitt: What if? The real challenge begins.

​When you buy a book using a link on this page, we receive a commission. Thank you for supporting The Atlantic.</div>
        </div>
        
        <div class="card" onclick="openModal('content-21')">
            <div class="source">The Atlantic</div>
            <div class="title">The Question-Mark Mayoralty</div>
            <div class="meta">2026-01-01</div>
        </div>
        
        <div id="content-21" style="display:none;">
            <h2>The Question-Mark Mayoralty</h2>
            <p><strong>The Atlantic | 2026-01-01</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/politics/2026/01/zohran-mamdani-new-york-policies/685438/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">In the months before the election of the young democratic socialist Zohran Mamdani as mayor, panic seized members of New York’s elite business community. Real-estate moguls, hedge-fund princes, and a well-known supermarket-chain magnate forecast disaster. Several of them vowed to move to Texas or Florida, or at least Hoboken, if Mamdani was elected. So far, however, the city hasn’t seen an exodus of its richest residents, and their alarm has lapsed into glum acceptance.

I recently asked Kathryn Wylde, the soon-to-be-retired president of the Partnership for New York City—a sort of chamber of commerce for finance, real-estate, and tech barons—how her members now view Mamdani. Has anything changed? Wylde, who voted for the new mayor, paused. “I would not say it’s positive,” she said. “But those who are at all open to him recognize that he’s smart, and they know that their kids voted for him. Now they are waiting to find out who he is.”

Mamdani, who took office shortly after midnight, remains the question-mark mayor. He ran an unabashedly progressive campaign. But he has made a point of talking with potential adversaries; some Partnership for New York City members have met with Mamdani, for example, and he had a surprisingly warm audience with President Donald Trump in the Oval Office in November. How this charismatic 34-year-old will govern the largest city in America is something of a mystery, with three great uncertainties: How will Mamdani manage his relationship with the rich? How will he approach the Israel-Palestine issue? And how will he respond to the influence of his old friends, the Democratic Socialists of America?

Mamdani called his election a “mandate for change,” a claim somewhat belied by the fact that he won with a narrow 50.8 percent of the vote. And he has not backed away from an ambitious and costly economic agenda: He wants to make day care universal and buses free. He also campaigned on shifting the property-tax burden from working-class, outer-borough homeowners to “richer and whiter” neighborhoods. He has promised to accomplish this agenda by taxing the rich and their corporations and townhouses.

Joseph Heath: The populist revolt against cognitive elites

But Mamdani can’t afford to alienate the wealthy. Millionaires accounted for $34 billion worth of city and state personal-income-tax revenue as of 2022, according to the Citizens Budget Commission, an influential business-backed nonprofit. The commission found that New York’s share of the nation’s millionaires shrank from 12.7 percent in 2010 to 8.7 percent in 2022. Had that share stayed steady, the city and state would have collected an additional $13 billion in income taxes.

Mitchell Moss, an urban-planning professor at NYU, told me that moves against the business community could also turn off people who were drawn to New York by the lure of economic opportunity. “Capitalism is built into the fabric of this city,” Moss said. “Why do you think all the immigrants come here?”

But New York’s business community might not turn out to be quite as oppositional as some expect. Its members are reasonably civic-minded. Wylde said her flock of CEOs are aware that their companies will suffer if talented people cannot afford to live in the city. And some of them don’t take a dire view of all high taxes. Almost two decades ago, the Partnership for New York City endorsed a payroll-tax increase to support mass transit; more recently, it supported a congestion-pricing fee for cars entering New York’s central business district.

Mamdani has left the door ajar to negotiation—and compromise—with business leaders and with Governor Kathy Hochul, a centrist Democrat. Of late, he has talked of balancing a rent freeze for tenants with insurance and tax cuts for landlords in working-class neighborhoods. In such moments, he sounds less like Rosa Luxemburg than a more familiar New York type, the liberal social Democrat—not far off from former Mayor David Dinkins or even Michael Bloomberg.

A more fraught question for Mamdani is how he will handle Palestine and Israel. Mamdani has declared that Palestinian liberation is “at the core” of his politics. He founded his college’s chapter of Students for Justice in Palestine, and has said he opposes Israel’s identity as a Jewish state. To have a mayor who speaks with antipathy toward Israel and some Jewish Zionist organizations is an unprecedented turn in a city with an estimated 960,000 Jewish residents and three Jewish former mayors.

Mamdani has pledged to order the police to arrest Israeli Prime Minister Benjamin Netanyahu if he sets foot in New York. He recently criticized a prominent synagogue for hosting an event for a nonprofit that encourages immigration to Israel, including to settlements in the West Bank. Under pressure from Jewish leaders, this summer he said he would “discourage” use of the phrase globalize the intifada, though he has said that many people use the phrase simply to show support for Palestinians. Talk of a global intifada took on a chilling resonance this month after two gunmen opened fire on Jews celebrating Hanukkah on Australia’s Bondi Beach, killing 15 people.

“Jews have been comfortable in New York City for a long time,” Moss told me. “For the first time, they sense that they are not automatically safe here.”

A liberal financier, who spoke on the condition of anonymity because he doesn’t want to alienate the new mayor, told me that he attended a Mamdani event recently and appreciated that Mamdani listened carefully and took notes. The financier supports Mamdani’s commitment to addressing the city’s gross inequities. “Personally, I find it difficult to believe that an ambitious man like him is going to die on the hill of the Palestinian struggle,” this person said. “But I have lots and lots of Jewish friends who are freaked out.”

Mamdani’s relationship with the Democratic Socialists of America presents the third big question mark. A movement brimming with activist energy and ideological certitude, DSA gave birth to Mamdani’s political career, providing the vigor and street organizing that made him such a formidable candidate. He has promised to remain a loyal DSA cadre. Yet that loyalty will be tested when he departs his rent-stabilized apartment in Queens for the two-century-old mayoral mansion on Manhattan’s Upper East Side. Already, Mamdani has angered influential DSA members with some of his early decisions.

Five years ago, Mamdani wrote that the city’s police department was “wicked” and should be dismantled; this past June, he told Meet the Press that billionaires should not exist. But in November, Mamdani reappointed Police Commissioner Jessica Tisch, a centrist technocrat who hails from a family with a fortune valued at $10 billion. Then he pressured DSA not to put up a candidate to challenge House Minority Leader Hakeem Jeffries, whom leftists view as guilty of the sin of moderation.

DSA comrades were not amused. In December, the two national co-chairs of the organization, Ashik Siddique and Megan Romer, appeared on the Dispatches podcast; the episode was titled “Can DSA Hold Mamdani Accountable?” Rania Khalek, the host, asked Siddique’s and Romer’s view of Tisch, whom Khalek described as coming from “this very billionaire Zionist family.” (Tisch is Jewish.) Neither co-chair challenged Khalek’s description of Tisch. “I don’t think either of us are happy about keeping somebody like that on,” Siddique said. Romer, a member of a Marxist-Leninst faction within DSA, described Mamdani’s decision as “really disappointing.”

In the lead-up to Mamdani’s inauguration, some wealthy New Yorkers sounded, if not accommodating, at least resigned to their fate. This past summer, Ricky Sandler, the CEO of a global equity firm, wrote to his fellow oligarchs warning of the “dire consequences” of a Mamdani victory. But the day after Mamdani’s election, Sandler proclaimed himself ready to tough out the new socialist administration. “NYC will be worse for yesterday’s outcome. Potentially a lot worse,” he wrote. But “I am not planning to move Eminence Capital to another city or state.”

One imagines that such moments of ruling-class resignation could be a minor relief for Mamdani. As for DSA, it has not hesitated to break with prominent progressive politicians, including its most famous member, Representative Alexandria Ocasio-Cortez; the national DSA withdrew its endorsement of her, at least in part because she took the heretical step of signing a press release supporting a missile-defense system to protect Israeli civilians. Which leaves the strange possibility that New York’s first socialist mayor might find himself more threatened by his left flank than by the occasional alienated hedge funder.</div>
        </div>
        
        <div class="card" onclick="openModal('content-22')">
            <div class="source">The Atlantic</div>
            <div class="title">Six Months Off the Street</div>
            <div class="meta">2026-01-01</div>
        </div>
        
        <div id="content-22" style="display:none;">
            <h2>Six Months Off the Street</h2>
            <p><strong>The Atlantic | 2026-01-01</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/politics/2026/01/six-months-off-the-street/685422/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Subscribe here: Apple Podcasts | Spotify | YouTube | Overcast | Pocket Casts

In July, we published a series of stories about San Francisco’s attempt to address the growing number of homeless and addicted people living on the streets. We followed Evan, who had been homeless for years, as he sought to escape the addiction that was threatening his life. Four months later, we check in on how he’s doing.

No Easy Fix is a three-part series from Radio Atlantic about homelessness and addiction in San Francisco.

The following is a transcript of the episode:

Hanna Rosin: I’m Hanna Rosin. This is Radio Atlantic. Last year, we published a series called No Easy Fix. If you haven’t heard it, you should go back and listen. It’s about San Francisco’s attempts to address pockets of homelessness and addiction. It’s also a close and unusually humane portrait of one man—his name is Evan—living on the streets and barely managing his fentanyl addiction.

Rosin: When reporter Ethan Brooks met Evan, he was in bad shape.

Evan: It’s raining, and I’m cold, and I’m hungry. (Laughs.) I’m over it. I’m so over it.

Rosin: Years of addiction had left him with a leg that was so swollen and infected that he was at risk of losing it. On top of that, he couldn’t keep food down. And he didn’t know why. His best friend, Joe, was worried.

Joe Wynne: I mean, I expect Evan to die out there. I have seen no pieces of evidence that persisted beyond 72 hours of him heading in any other direction, and I’ve seen 10,000 pieces of evidence of him headed towards death.

Rosin: Evan ended up in the hospital. And he agreed to enter an addiction treatment program in San Francisco—one that looked a lot like the rehabs where he had tried and failed to get clean before.

Evan: I could feel, like—in my head, I’m like, I’m gonna be successful this time. But like, I’m still a little worried about having doubt—like, What if I don’t, though?

Rosin: Ethan Brooks is going to take it from here.

Ethan Brooks: The last time I saw Evan, he was in a room in San Francisco General Hospital.

Brooks: We spoke for a few hours, and this is how our conversation ended.

Brooks: I mean, I’ll be able to call you on the phone and stuff, but I just won’t be able to get you in person for a while.

Evan: Yeah, I’ll definitely put you on the list of people I can talk to in treatment.

Brooks: Evan had been accepted to long-term residential rehab in San Francisco. He wanted to finally get clean, and give space and time for his leg to heal. And he wanted to reconnect with his son, who he hadn’t seen in years.

Joe—that’s Evan’s friend—bought him a cellphone, started a group chat, plugged in the phone next to Evan’s bed, and flew home, back to his family in Washington State. So Evan was once again on his own.

A month passed, and I didn’t hear from him. And then, he texted: He had 30 days clean.

To celebrate, Joe sent videos from Cameo; that’s the app where minor celebrities send personalized messages. In one, a group of burly dancers delivers Joe’s message:

Island Boy: Yo, Evan, I heard you’re 30 days sober off fentanyl.

Brooks: Another was from one of the twin TikTok stars in the Island Boys. I can’t tell which one.

Island Boy: So keep on going. It goes day by day, my boy. Keep doing your thing because that fetty ain’t no joke, my boy.

Brooks: About two months later, there was a notification in the group chat, just under the videos. It said, “Evan has left the conversation.”

Brooks: When I called his cell, there was nothing.

(Voicemail greeting plays: “I’m sorry, the person you are trying to reach has a voicemail box that has not been set up yet. Please try your call again later. Goodbye.”)

Brooks: It was the same at the rehab facility.

Operator: So I don’t know—I can’t confirm or deny that the person is here. But I could take a message if you’d like to leave one.

Brooks: And then, on November 17, seven months since I had last spoken to him, I got an email.

The account photo was of a man in a pressed lavender button-down shirt tucked into jeans, with one hand on his hip, posing in front of a field. It was Evan. We set up a video call.

Evan: I haven’t had an Apple product in a long time, and this MacBook is pretty frustrating.

Evan: Yeah, just all I wanted to do is scroll down, and I haven’t quite figured that out yet. So I click on something, and then use the arrow keys ’cause I can’t find the fucking scroll in the corner.

Brooks: Turns out this isn’t easy if you’ve missed the last five years of technological advance.

Brooks: Just getting Evan on a call didn’t guarantee much.

Rehab is definitely better than living on the street, but it’s not necessarily a place where you get clean. In 2023 and 2024, San Francisco’s largest publicly funded rehab provider saw a string of overdose deaths inside their facilities. Evan says he’s been in others, where patients and staff were still using.

I had known where Evan was, but until this conversation, I didn’t know how he was, or what had happened in the seven months since we last spoke—if he had changed.

Back in April, when Evan was talking about getting clean, this was not the first time the scene had played out—not Joe’s first time flying down to find him, not the first time he was hospitalized. There was a sort of script for what would happen next.

Evan: I would make this whole plan about going to treatment, and as soon as I would be alone and be out outside of the hospital, I would just get out.

Brooks: Evan would get his few days living inside; Joe would go home to his family. Then the hospital would arrange for Evan to travel to rehab via a taxi or a bus—

Evan:  And then as soon as I hit the Tenderloin, I would just be gone instantly.

Brooks: In those 10 unsupervised minutes, Evan would disappear. He would get out of the taxi, go back to shoplifting, back to selling what he stole, back to fentanyl.

That was Evan’s choice. It’s true that Evan is responsible for his own actions in those 10 minutes. It’s also true that almost no one beats a fentanyl addiction like his through willpower alone.

This time around, Evan’s first cue, the part in the script where he would normally just disappear, came when the hospital wanted to discharge him. Hospital stays are expensive; they wanted to send him to a shelter for the weekend before rehab admission opened up on Monday.

But the hospital’s addiction team knew if he went to a shelter, he would relapse. They convinced the doctors to keep him for the weekend, despite the expense.

The first opportunity to disappear came and went.

Then it was time to take a taxi from the hospital to rehab, which is called Harbor Light.

Evan: One of the addiction-team nurses after his shift stayed in the cab with me and then rode there to Harbor Light and then stayed there with me for an hour to make sure that I was, like, cool and didn’t have any second thoughts and then left.

Brooks: So another opportunity to exit had come and gone because someone took the time to stay with him.

Brooks: Do you remember your first day, or first days, at Harbor Light?

Evan: Yeah, I remember. I was just sleeping so much. I would get up and just eat and pee. They would just bring me my meals. So it was kinda like I was in the hospital again.

The task of showering again, I was like, Ugh. And just the task of having to unwrap my leg, get in the shower, do the whole—I was just like, I don’t even care. I’ll just be smelly. And it was just my brain deciding what was important and what wasn’t. For so long, that wasn’t important.

Brooks: Before Evan arrived at Harbor Light, there were two things, after five years living on the street, that had pushed him toward recovery.

The first was his leg, which had this huge open wound.

The other thing that brought him here was that he couldn’t keep food down. At first, the doctor thought he might have celiac disease—gluten intolerance. And then they found out that his iron was dangerously low; he was anemic.

Evan: At first, they thought me being anemic was a diet thing ’cause of just eating nothing but candy and ice cream on the street for so long. Even at the time, if somebody were to tell me, Oh, if you keep doing fetty like that, you’re gonna end up becoming anemic, I would’ve been like, So? Obviously, my leg was falling off, so it wasn’t—

Brooks: Yeah, it’s like, Who cares about being anemic when your leg is falling off?

Brooks: When I first met Evan, he was living a life that, on the good days, felt like a type of freedom: He could fend for himself. He wasn’t responsible to anyone.

But even just a few days into treatment, he could already see it more clearly: It wasn’t freedom; it was dependence, in just about every sense of the word.

Evan was living like a child, literally eating nothing but candy and ice cream.

Evan: I remember being nervous because I was glad to kind of get my life going again, but at the same time, I had been enjoying not being a responsible adult for such a long time.

I was kind of nervous to be like, Great, now not only do I gotta learn how to be an adult again. I gotta figure out how I’m gonna deal with all the shame and guilt of not being one for so long.

Brooks: Harbor Light, Evan’s rehab, is run by the Salvation Army. Apart from being known as a strict, and rather intensive, treatment program, the basics will be familiar: meetings, meditation, acknowledging a higher power, celebrating milestones.

Evan: I feel like everybody’s congratulating me for learning how to, like, pee standing. Like, Pee-pee standing up. Like, Good job, Evan. Like, You use the bathroom on your own. No more diapers.

That’s how I would always be, like, Congratulations for catching up with the rest of us, like, for the last 15—you know? And so I would feel kind of dumb about it. Even two months in, talking about it with some of the counselors there, they were like, How much time do you have? And I was like, Oh, I have two months, and people were clapping or whatever. And I’m just like, Yeah, it’s whatever. It’s two months.

Brooks: In real terms, two months was definitely not “whatever” for Evan. It’s the longest he had been clean in a very long time. But the old temptations were still there.

To start, Evan was still in San Francisco. Just about every day, he saw people he knew from his life before. And beyond that, even after two months clean, his leg just wasn’t healing the way he hoped it would.

Evan: My leg improved, and then it just stopped, and it was a really slow progression. I didn’t know if I was doing something wrong or if it was going to get worse again.

Brooks: It started to feel like, If his leg wasn’t going to get better, if he stood a chance of losing it, what was the point?

Evan: I was like, All right, just—we’ll do the six months, show everybody that I can, I’ve tried, and then I’ll go back out.

Brooks: In his years living on the street, Evan managed to look after himself. But there were other people, important people, who he overlooked.

Evan has a son. They talked on the phone sometimes, through Evan’s mom or sister. But as his kid got older, he didn’t want to talk to Evan, and Evan didn’t want to talk to anyone.

That changed at Harbor Light.  If Evan wanted any shot at reconnecting, he’d not only have to learn to be an adult in just a few months, but also learn how to be a father.

Evan: I had this in my head, like, a game plan for how I was gonna tackle talking to my family again. But my counselor there was like, Nope, that’s not how we’re gonna do it, not definitely gonna do it like that.

Brooks: What was the game plan, and why was it rejected?

Evan: Like calling them, like, once a week and then calling my son and then talking to him. But my counselor decided that You can’t use your phone at all for the first 30 days; it’s a complete blackout. And then, after that, you only get two 10-minute phone calls a day.

Literally, when I would call my mom, one, by the time she answered, it would probably kill a whole minute, two. She would spend, like, five minutes crying. So now I’m left to have, like, four more minutes. I’m like, Mom, you just—what am I supposed to do? I—and then there’s my whole phone call for the day, and then, if I call somebody else, and they don’t answer, and that’s it.

So he was like, You’re going to write letters, and that way you can speak more, get it down, and honestly, it’ll feel more heartfelt that you’d spent the time to write it all, your feelings and everything, out on paper and mail it.

Brooks: So that’s what Evan did. This was the beginning of what would become a relentless mailing campaign aimed at his son.

It hasn’t been easy to get much out of him. Evan hadn’t seen his son in eight years. No one would blame him for not wanting to talk.

But over the months, Evan began to learn what he had missed. Everyone thinks his kid looks like him. He’s an adventurous eater like Evan, has a sweet tooth too, also like Evan. There was a picture of him trying a chocolate-covered cricket on a field trip to D.C. And he was a bit of a performer.

Evan: For example, for his fifth-grade graduation, he surprised everybody and dressed up as a banana—

Evan: —and walked across the stage in a giant banana suit. He really likes the clarinet. Actually, he’s, like, first chair in his class and then third chair all-county or something. He is really into it.

Brooks: In October, six months into treatment, Evan’s family flew out to visit him: his mom, his sister, and his son. Evan’s friend Joe and Joe’s son, Barrett, came down too.

The last time Evan saw his son, he was 5 years old. Now he was 13, and was growing a mustache.

They went to the arcade, did an escape room. Evan said they’ll still be in there if it wasn’t for the kids. Barrett and Evan’s son were fast friends.

Evan: The first night we went out somewhere, they were throwing something—it was like candy or something—and something bounced off and then hit me. And then they, like, giggled and ran away. And my son was like, Where’d it go? And then Barrett was like, “It hit your dad.” And it just—I have never—I hadn’t been a dad for such a long time, so it was just a kind of surreal moment. He didn’t even call me Dad; it was somebody else calling me Dad. But it was more of just a reminder of like, “Oh, yeah, I am.”

Salvation Army officer: Do you have any guests that you wanna welcome?

Brooks: The same weekend his family visited, after six months of treatment, Evan graduated from Harbor Light. In the video, he’s standing at a lectern, wearing a yellow plaid shirt. He says he’s trying not to cry.

Evan: A wise woman once told me, “The only thing that you have to change is everything.” I look forward to being the best son, brother, and father and friend I can be. Thank you.

Brooks: After graduation, Joe and Barrett and Evan’s mom and sister and son flew home.

Brooks: You guys are still writing letters here and there, or no?

Evan: Yeah, yeah, definitely. I just sent one. I’ll take the—I sent him letters. He doesn’t really send me anything back. I don’t know if the option was given to him, kind of, like, Your dad wants your cellphone number. Do you want to give it to him, or do you want to just keep writing letters, or what do you wanna do? And I could just see him being on his phone, like, Yeah, whatever, letters.

And so I was like, Oh, well, if that’s what he wants to do, then I’m just going to bombard him with letters, to where he’s like, “Damn it, I should have did phone call.” So he hasn’t caved yet, but I definitely send him two or three a month.

Brooks: Evan is now in a sober-living house. He works in a kitchen a few days a week, and on the other days, he takes classes to become an addiction-treatment peer counselor.

That question of if it was possible for Evan to stay clean this long, so far, has been answered. His leg isn’t fully healed; even after eight months, the wound is still there. But he can walk around fine and will have a surgery soon to help with his circulation.

So now the question for Evan isn’t so much if he’ll live, but how.

A few weeks ago, Evan was riding the bus home from a meeting when he ran into an old friend from when he was living on the street.

Evan: And I talked to him the whole bus ride and when I got off I helped him carry his stuff off and hung out with him for a little bit, but when I had went to talk and hang out with him and invited him to sit next to me, it was just kind of like, Here’s this really dirty, gross-looking homeless dude, and I’m cleaned up enough to where people wouldn’t suspect that of me at all. And then I’m inviting him over next to me. When he came up to talk to me, before I had noticed him. They were thinking, I’m probably gonna get pissed-off; this homeless guy’s coming to ask me for money or something. And it totally wasn’t what they expected.

Brooks: They see like a homeless guy approaching somebody who’s just, like, a normal guy working a job in San Francisco or something—

Evan: Exactly, coming home from work late at night and—

Brooks: —and you kind of see an old friend.

Evan: Right. Or me. When I see somebody in that same position, it’s kind of hard for me to—like, someone with a fucked-up leg, or just can’t get up from somewhere ’cause they’re so sick. It’s like, Fuck.

Brooks: This isn’t the only time this has happened recently. Evan sees himself all over the city. When cops and EMTs are trying to move someone along passed out outside of a coffee shop, there he is. When his co-workers at the kitchen complain about homeless and addicted people, he fantasizes about telling them about his past.

He lives just two blocks away from where he spent the last five years, but he might as well live in another world. Still, the boundaries between old and new can be porous.

Evan: This last couple nights, I’ve had to go to meetings because I’ve been bored, and I really kind of miss that hustle of—kind of the excitement of, I gotta go boost from here and dodge the security guard and then get on the BART and then dodge the BART police and then steal from this store and then come back out, and then just all that excitement bullshit. I kind of miss the chaos.

Brooks: He tries not to think too much about the future. A lot of treatment, at this point, is still focused on the present. But he does have one idea for what he might do.

Evan: My background permitting, I would like to be an armed security guard. I think that would be cool.

Evan: Because that’s the kind of craziness that I think I need. Not, like, with-a-gun armed, but like with a baton or pepper spray. I’m not saying that every day I’m gonna go to work that I’m gonna be like this, this douche security guard that, like, pepper-sprays you.

Brooks: It’s so funny. It’s like you’re just becoming your like worst enemy from not long ago.

Evan: In a way, yeah. But I would also think I’d have—I think I could give back to Target for all the shit I stole by being a good security guard.

Brooks: Just going back to that same Target and going to work that. Where was that?

Brooks: There was a story Evan told me back before he started treatment. To support his habit, he was going to the same Target in Emeryville, outside of Oakland, day after day after day, stealing stuff and selling it in the Mission District.

He went to that same Target in Emeryville so many times in a row, it had begun to feel absurd that he hadn’t been caught yet.

Brooks: You were like, I can’t believe this hasn’t happened. It feels like Groundhog’s Day.

Brooks: He told himself that when they did catch him, that’s when he’d get clean. But it never happened.

Brooks: Does that at all feel like an attempt to go back and stop your past self? Fulfilling that wish you had for someone to catch you at that point.

Evan: Right, and just give them that, like, Oh, it’s over finally.

Evan: It rains here on Christmas for a week every year, and I always know it’s coming, and I know it’s gonna come this year, and it’ll be the first time where I will be inside, and I’m so grateful for that.

Brooks: Evan will stay in San Francisco for the time being. In the spring, he’ll fly out to Washington to visit Joe.

This episode was produced by me, Ethan Brooks and Natalie Brennan. Edited by Jocelyn Frank and Hanna Rosin. Engineering by Rob Smierciak. Fact-checking by Sam Fentress. Claudine Ebeid is the executive producer of Atlantic audio, and Andrea Valdez is our managing editor.

If you enjoy the show, you can support our work and the work of all Atlantic journalists when you subscribe to The Atlantic at TheAtlantic.com/Listener.</div>
        </div>
        
        <div class="card" onclick="openModal('content-23')">
            <div class="source">The Atlantic</div>
            <div class="title">The Cult of Costco</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-23" style="display:none;">
            <h2>The Cult of Costco</h2>
            <p><strong>The Atlantic | 2025-12-31</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/newsletters/2025/12/costco-is-an-american-achievement/685411/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">This is an edition of The Atlantic Daily, a newsletter that guides you through the biggest stories of the day, helps you discover new ideas, and recommends the best in culture. Sign up for it here.

Because every day is Black Friday at Costco, I choose to go on Saturday. I like to get there early. I always park in the same spot (right next to the cart return), and wait with the other die-hards. It has the thrill of a stakeout, absent any crime or danger. When the doors open, we move toward the entrance in an orderly march. There’s a small gasp upon entry—the kind of quiet awe that one feels before the most epic human achievements, as when stepping across the threshold of St. Peter’s or the Chartres Cathedral. But in this place, there is no baroque majesty, no stained glass, just abundance bathed in light. In the sweep of human history generally marked by scarcity and want, here is bounty on an unimaginable scale; here is a year’s supply of mozzarella sticks; here is a hot dog and a drink for $1.50; here is a monument of our civilization, in more than 600 locations across the United States.

I take the ease with which I resort to Costco talk—about produce prices in particular—as a worrying sign that I’ve become a middle-aged bore. But there’s something happening at Costco that I think goes beyond bell peppers (note that my family eats a lot of them, and, boy, are they a bargain). Costco is a marvel not just historically but also in this moment. In an age of broken institutions, insufferable politics, and billionaire businessmen auditioning to be Bond villains, most things feel like they’re getting worse. Costco seems to stay the same. The employees are generally satisfied. The customers are thrilled by the simple act of getting a good deal. All of it makes a unique space in contemporary American life, a space of cooperation, courtesy, and grown-ups mostly acting like grown-ups.

It starts with the thing you’re pushing, the vessel into which you shall receive thy bounty. The cart is improbably large yet easily maneuvered through the warehouse’s aisles. Through some invisible quality control, the sad and broken-down ones you find at the supermarket—unlevel, rear wheel locked, front wheel spinning—seem to be ushered quietly into oblivion at Costco. You’re at the helm of a Peterbilt with the handling of a Porsche.

Traffic is never light, but things generally move along. Pushing something that large requires an awareness of oneself in space. Those who might need to consult a list or message their spouse—should I grab this brick of cheddar cheese?—seem to know to step off to the side. At my store in Granger, Indiana, where elbows are perhaps not as sharp as at some other locations, patrons appear to have an unspoken patience with the person who wants to give a bag of avocados an extra squeeze, or hold a double shell of raspberries up to the light. There are occasional expressions of camaraderie as well: “We can’t get enough of that stuff,” somebody might say as you load two pillow-size bags of Pirate’s Booty into the cart.

You might see the bargain-hunting bonds among Costco shoppers as a function of the chain’s history. To join its ranks costs $65 a year; the store’s membership model originates from a nonprofit wholesale collective for federal employees called Fedco, founded in Los Angeles in the 1940s. The genealogy is complex (a three-hour-long Acquired podcast episode traces it in full), but one trait has endured: the company is animated—even as a for-profit enterprise—by the idea of bringing good value to its members. This has yielded a cultlike loyalty, such that the company can largely rely on happy members to do its advertising and marketing by word of mouth—or perhaps by wearing prized company merch. Kirkland Signature, Costco’s in-house label for hundreds of products, is a kind of anti-brand that happens to be one of the world’s largest for consumer packaged goods. Just buying something under its comically dull logo makes you feel like a smart shopper: You’ve made the wise decision to forgo a better look for a better price.

Costco is a place that encourages, and rewards, just knowing the drill—and the drill isn’t hard to figure out: Move along. Don’t block the way. Unload your cart onto the conveyor belt with dispatch, but leave the heavy stuff. Make the barcodes visible. Violators are never exiled, but transgression, I know from experience, is not without shame. Once, I left the cart in front of the flower display loaded down with 120 pounds of water-softening salt. When I returned, the grandmother who was blocked from the flowers (find me a cheaper dozen roses!)—well, she gave me the finger.

The veneer of civilization is always thin, even at Costco, as one is reminded before major holidays, or in the vicinity of the samples. When there’s a Christmas feast to be provisioned, or half a bite of pizza to be tasted, order breaks down, and with it, spatial awareness, common courtesy, and the Golden Rule. We’re circling like buzzards; we’re blocking the way; we’re shaking our heads at the nerve of the person who took the last three.

But the checkout restores us to our senses. At my Costco, there is usually a line to get in line for the cashier. People can game the system, but most quietly queue up, content to wait their turn to pick a register. The clerks are cheerier than they should be before this endless current of humans and their stuff. Whatever lapses I might have had in the store (did I take a second sample? maybe), here, I’m on my best behavior.

Out of the store, car loaded, cart returned, I tighten up and steel myself for the road. Have you seen the way these people drive nowadays?

This much you already know: Many Americans are alone, friendless, isolated, undersexed, sick of online dating, glued to their couches, and transfixed by their phones, their mouths starting to close over from lack of use. Our national loneliness is an “urgent public health issue,” according to the surgeon general. The time we spend socializing in person has plummeted in the past decade, and anxiety and hopelessness have increased. Roughly one in eight Americans reports having no friends; the rest of us, according to my colleague Olga Khazan, never see our friends, stymied by the logistics of scheduling in a world that has become much more frenetic and much less organized around religion and civic clubs. “You can’t,” she writes, “just show up on a Sunday and find a few hundred of your friends in the same building.”

But what if you could, at least on a smaller scale? What if there were a way to smush all your friends together in one place—maybe one with drinks and snacks and chairs? What if you could see your work friends and your childhood friends and the people you’ve chatted amiably with at school drop-off all at once instead of scheduling several different dates? What if you could introduce your pals and set them loose to flirt with one another, no apps required? What if you could create your own Elks Lodge, even for just a night?

I’m being annoying, obviously—there is a way! It’s parties, and we need more of them.

Read. Here are the books that made our editors think the most this year.

Remember. In 2012, Emily Chertoff explored how wealthy Americans celebrated New Year’s Eve in the Gilded Age.

Rafaela Jinich contributed to this newsletter.

When you buy a book using a link in this newsletter, we receive a commission. Thank you for supporting The Atlantic.</div>
        </div>
        
        <div class="card" onclick="openModal('content-24')">
            <div class="source">Slashdot</div>
            <div class="title">'IPv6 Just Turned 30 and Still Hasn't Taken Over the World, But Don't Call It a Failure'</div>
            <div class="meta">2026-01-01</div>
        </div>
        
        <div id="content-24" style="display:none;">
            <h2>'IPv6 Just Turned 30 and Still Hasn't Taken Over the World, But Don't Call It a Failure'</h2>
            <p><strong>Slashdot | 2026-01-01</strong></p>
            <a class="original-link" href="https://tech.slashdot.org/story/26/01/01/1833202/ipv6-just-turned-30-and-still-hasnt-taken-over-the-world-but-dont-call-it-a-failure?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Want to read Slashdot from your mobile device? Point it at m.slashdot.org and keep reading!

How may different compatibility deployments are there for IPv6?

Think any of those are fake names? Try again!

And that&#39;s just ONE piece of IPv6. Practically everything in the &quot;spec&quot; has at least 2 variants minimum, and its just a royal clusterfuck. When it is described as &quot;protocol by comity&quot;, this is exactly the result, and its been a total pain in the ass to have anything reliable at scale.

You may be on one of the lucky ISPs that has a sane deployment and want to reply

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

&quot;In matters of principle, stand like a rock; in matters of taste, swim with 
the current.&quot;
-- Thomas Jefferson</div>
        </div>
        
        <div class="card" onclick="openModal('content-25')">
            <div class="source">Slashdot</div>
            <div class="title">DHS Says REAL ID, Which DHS Certifies, Is Too Unreliable To Confirm US Citizenship</div>
            <div class="meta">2026-01-01</div>
        </div>
        
        <div id="content-25" style="display:none;">
            <h2>DHS Says REAL ID, Which DHS Certifies, Is Too Unreliable To Confirm US Citizenship</h2>
            <p><strong>Slashdot | 2026-01-01</strong></p>
            <a class="original-link" href="https://news.slashdot.org/story/26/01/01/1736221/dhs-says-real-id-which-dhs-certifies-is-too-unreliable-to-confirm-us-citizenship?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Want to read Slashdot from your mobile device? Point it at m.slashdot.org and keep reading!

Family Guy called it years ago. https://pbs.twimg.com/media/DL... [twimg.com]

...and when both do it you end up where we are today.

Ah yes the &quot;both sides&quot; argument. So I&#39;m going to need some citations here.

Right now, the leader of the Republican party is working for Putin, Netanyahu, and the Saudis, to the detriment of the American public...

This is nothing new, since they have rallied around Starve The Beast [wikipedia.org] for over 30 years and claim that government doesn&#39;t work, then actively dismantle it when they are elected to prove themselves right

And, how is the Republican leader working for Putin, Netanyahu, and the Saudis.  How is that any different than Biden or anyone?And, the Democrats wanted to open the borders and let all the &#39;illegals&#39; in.  Bet you&#39;d rather have to go out to get the mail carrying an Uzi to shoot the people in the souped-up Impala.So, which would you rather have?  One who let&#39;s all the bad in, or one who tries to get rid of the bad?

So we&#39;re at the Papers please! stage of fascism now. Cool. Next up loyalty oaths.

Are you at least getting paid to lick boots or does it turn you on?

&quot;God gave me freedom to spew killer germs everywhere!&quot;

Do you mean when employers in &quot;at will&quot; employment states asked for proof of vaccination? Just like the way doctors offices and hospitals require everyone receive certain vaccines in order to be hired? I recall a lot of that happening under Trump actually.

Q:  And, where did all the things that require vaccination come from?A:  From other administrations who let in all &#39;refuges&#39; and &#39;political asylum&#39; and anyone who had an advocate who found some reason their client needed to get in.

We&#39;re now beyond that stage, because you can have the federal government approved ID and have them not accept it.

I am a big white guy, but I have an aggressively Hispanic name. The whole thing (all three parts) is extremely common in Mexico. While both of my parents were born here, none of their parents were. Most of them came from Europe, but one was a Mexican citizen. I have an allegedly real ID. When all this bullshit kicked off, I refreshed my passport, and I carry the passport card.

They do not care about ID. They care about terrorizing you and acting all powerful.

In the Mexican Repatriation  [wikipedia.org] during the early part of the Great Depression, between 300,000 and 2 million people of Mexican heritage were forcibly removed from America, even though a large percentage of them were born here.

There were no records kept, just a brutal attack on fellow Americans to distract the rest from the poor management of the government and inevitable steps to the Great Depression

Sometimes History is not content to simply rhyme, it clearly repeats itself.

Loyalty oaths? You mean like the one you force school children to recite every single day?

I&#39;m actually not a fan of that either. Especially the &quot;under god&quot; line they tacked on in the 1950s.

That&#39;s already happening - new federal employees must swear an oath of allegiance to Trump to follow his policies and such.

Though I think Project 2026 has something to say about that as well. Yes, there is a new Project 2026 document which contains some of the stuff in Project 2025 that hasn&#39;t been done yet (e.g., banning pornography) but adds more stuff that they would like done as well

Doesn&#39;t that happen regardless?I somehow doubt that&#39;s an &#39;only under Trump&#39; thing.

I got my RealID some years ago.  It required 5 types of ID.  I used my passport, social security card, voter ID paper, phone bill and electric bill.  All that satisfied the RealID requirements

Read the click-bait article carefully. They are not saying real ID is unreliable, they are saying a real ID card can be forged. When there is suspicion of a forged document it can take longer to verify its authenticity.

They are not saying real ID is unreliable, they are saying a real ID card can be forged. The pretense is now set for your legit ID being fake. If the government doesn&#39;t like you they can just declare your ID is forged and ICE can snatch you up.

They are not saying real ID is unreliable, they are saying a real ID card can be forged.

The pretense is now set for your legit ID being fake. If the government doesn&#39;t like you they can just declare your ID is forged and ICE can snatch you up.

and ICE can snatch you up.Those uniforms don&#39;t look authentic to me.

Those uniforms don&#39;t look authentic to me.

Tattoo babies born in the USA to US citizens with &quot;Made in USA&quot; on their bottoms. /s

&quot;Could be fake?&quot;  Anything could be fake.  Even a passport.  That&#39;s a really stupid thing to claim.

No. That is a statement of &quot;You have no rights and we decide what happens here!&quot;.

The masked guy&#39;s claim to be an ICE agent could also be fake. Now what?

Local police arrest them and charge them with the catch all disorderly conduct charge. It probably won&#39;t stick but it would gum things up.

Could be. But wasn&#39;t in Venegas&#39; case. They detained him, &quot;ran his ID&quot; and released him. So, it worked as advertized.

OK. So if took an hour to run it. They were conducting a raid, so they were busy. And if you don&#39;t like the database response speed, fire AT&T from the FirstNet program. Combining law enforcement functions with a bunch of autistic gamers on one wireless system was a mistake.

It&#39;s suddenly popping up because Trump wants to deport everyone they can get their hands on, lawful status or not. And they&#39;re picking up citizens along the way.

Because I remember having to bring a birth certificate to get my current state driver&#39;s license.

But then, this regime has never heard the word &quot;perjury&quot;.

RealID isn&#39;t intended to prove citizenship. Citizens can get them, as can immigrants with lawful status in the country. That was on purpose, because people with lawful status also travel, enter federal buildings, and do lots of perfectly legal stuff in this country.

The problem is the Trump administration is intent on finding any reason to kick people out of the country, whether they have lawful status or not. The RealID doesn&#39;t tell them whether they have to let you go because you&#39;re a citizen.

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

&quot;In matters of principle, stand like a rock; in matters of taste, swim with 
the current.&quot;
-- Thomas Jefferson</div>
        </div>
        
        <div class="card" onclick="openModal('content-26')">
            <div class="source">Slashdot</div>
            <div class="title">Public Domain Day 2026 Brings Betty Boop, Nancy Drew and 'I Got Rhythm' Into the Commons</div>
            <div class="meta">2026-01-01</div>
        </div>
        
        <div id="content-26" style="display:none;">
            <h2>Public Domain Day 2026 Brings Betty Boop, Nancy Drew and 'I Got Rhythm' Into the Commons</h2>
            <p><strong>Slashdot | 2026-01-01</strong></p>
            <a class="original-link" href="https://news.slashdot.org/story/26/01/01/1712212/public-domain-day-2026-brings-betty-boop-nancy-drew-and-i-got-rhythm-into-the-commons?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Slashdot is powered by your submissions, so send in your scoop

A 5 year copyright is ridiculous. This is the sort of idea that comes from leaches that have never created anything in their life.

Why does  your &quot;creation&quot; involve my work at all? Ever? Do your own &quot;creation&quot;!

Now if you wanted to argue for 50 year copyrights, I&#39;d be open to discussion. But, 5 years? Ridiculous.

If you look at the copyright industry, which includes movies, music, books, and more, one key question is how far in the future they look in projecting revenue when deciding whether to fund a project.  I would think given that, 10 years would be the minimum number to not have an obvious economic impact.  20 or 25 might also be reasonable.  But that&#39;s just looking at it from economics.

There&#39;s also a moral aspect.  Should a creator have creative control over what they create?  How long should that last?  That

Copyright is a PRIVILEGE that we, the people, give to CREATORS to encourage CREATION.copyright has nothing to do with creation. it&#39;s just about money and rents. you can infringe any copyright you like and be as creative as you wish with it as long you do it underground, or privately, or anonymously. nobody will give a damn, and it is still creation in its purest form. however, try to make money with it or claim ownership and the sharks will be all over you. see? art, money, entirely different matters.copyright is just property law that distorts the concept of property and exploits &quot;art&quot; to protect rents, mostly those of big companies. and a convenient instrument for censorship.

Copyright is a PRIVILEGE that we, the people, give to CREATORS to encourage CREATION.

copyright has nothing to do with creation. it&#39;s just about money and rents. you can infringe any copyright you like and be as creative as you wish with it as long you do it underground, or privately, or anonymously. nobody will give a damn, and it is still creation in its purest form. however, try to make money with it or claim ownership and the sharks will be all over you. see? art, money, entirely different matters.

copyright is just property law that distorts the concept of property and exploits &quot;art&quot; to protect rents, mostly those of big companies. and a convenient instrument for censorship.

copyright has nothing to do with creation. it&#39;s just about money and rents. you can infringe any copyright you like and be as creative as you wish with it as long you do it underground, or privately, or anonymously. nobody will give a damn, and it is still creation in its purest form.So your argument is that the art that artists create has no inherent value, and others can reproduce it and profit off of it as much as they want and the artist who created it should get nothing? 

I agree with the general concept that copyright law and enforcement is screwed up and should be reformed, but copyright itself serves an important purpose.

copyright has nothing to do with creation. it&#39;s just about money and rents. you can infringe any copyright you like and be as creative as you wish with it as long you do it underground, or privately, or anonymously. nobody will give a damn, and it is still creation in its purest form.

So your argument is that the art that artists create has no inherent value, and others can reproduce it and profit off of it as much as they want and the artist who created it should get nothing? 

I agree with the general concept that copyright law and enforcement is screwed up and should be reformed, but copyright itself serves an important purpose.

So your argument is that the art that artists create has no inherent value,oh, no. it&#39;s money that hasn&#39;t any inherent value. art can have value. copyright is all about protecting money extraction from it.and others can reproduce it and profit off of it as much as they wanti said exactly the opposite (re profit). are you being disingenuous?and the artist who created it should get nothing?ok, yes, you may be being disingenuous.

So your argument is that the art that artists create has no inherent value,

oh, no. it&#39;s money that hasn&#39;t any inherent value. art can have value. copyright is all about protecting money extraction from it.

and others can reproduce it and profit off of it as much as they wanti said exactly the opposite (re profit). are you being disingenuous?and the artist who created it should get nothing?ok, yes, you may be being disingenuous.

and others can reproduce it and profit off of it as much as they want

i said exactly the opposite (re profit). are you being disingenuous?

and the artist who created it should get nothing?ok, yes, you may be being disingenuous.

and the artist who created it should get nothing?

Why do we have super long copyrights?  Disney.  They got greedy and lobbied and beat the small guys up, convincing the US congress to help the corps.

Who benefits from it?  Corporations, not the authors.  In fact often the authors get screwed by long copyrights.   How?   If you sold your copyright to a corporation then the law changed, the corp got the benefit without paying your more money.  Few creators manage to maintain control over their copyrights for more than a decade.  Many lose it immediately.

How should we let them extend  a copyright and why should it extendable?I) If you make it extendable you can make extendable only if they create a sequel.II) This encourages the original author to create moreIII) Lets them benefit from the original work which often gets renewed interest when a sequel happens.IV) It allows for lesser works to not be extended, letting them get more exposure after copyright fails.V)  It allows for more unique cases like &quot;Its a wonderful life&quot; that only becomes famous BECAUSE it was not copyrighted.

Why is ten years extendable to 50 enough?Most copyrightable works fall into 3 categories:1) Failures that never make money.  Obviously, these do not need 10 years, let alone 50 years of protection.

2) Reasonable Successes.  These make money and almost all of it in the first two years.  Yes, you get a long tail that slowly tapers off, but it is almost all gone in 10 years.   If it is worth it, you can do the extra work, create a sequel, and get that full long tail of 50 years.

3) Genius works.  Classics.  This will be making money 200 years after the author is dead.  Davinci, Monet, Shakespeare. Miracle on 34th street.  Bach.   This work is great but should already set the creator up for life in the first 50 years with both money and fame.

But there are lots of reasons not to extend the money/rights further, including:

a) The creator should not need more if they are getting properly compensated for the work.b) Sometimes people steal or otherwise unethically obtain the copyright and we do NOT need to benefit them or encourage this behaviorc) We probably could not pay the real author enough money for it&#39;s true worth,d) we want the poor people to be able to enjoy these truly great masterpiecese) It makes fair use a lot easier if copyright goes away, avoiding stupid and un-necessary lawsuits about what is and is not fair use.f) It puts a bunch of relatively recent works available for the poor without having them all be culturally difficult to understand.

Why should it be extendable to 50 years? In most professions you need to work everyday if you want to have money everyday. This even includes employed creative workers, who need to work every day and transfer the copyright to their employer. Why should the person holding the copyright have the money printer, while other people need to work for their money?

To enable models that allow to first work and then make money from licensing the finished work (so not the employee model), one could say copyright should

https://en.wikipedia.org/wiki/... [wikipedia.org]

Lots of good books added to the public domain.

Most of the main Disney character early short films are in the public domain.

You cannot use trademarks to extend the copyright of a work in the public domain.

Aren&#39;t copyright terms whole years? Why does it end on 1.1.?

The text of Title 17, United States Code, section 305  [cornell.edu]:

All terms of copyright provided by sections 302 through 304 run to the end of the calendar year in which they would otherwise expire.

From House Report 94-1476, linked from &quot;Notes&quot; on the same page:

Under section 305, which has its counterpart in the laws of most foreign countries, the term of copyright protection for a work extends through December 31 of the year in which the term would otherwise have expired. This will make the duration of copyright much

The slightly dog-faced one with floppy dog ears from the original movie Dizzy DishesLean into that. Make an episode where poodle!Betty tries to fit into a human-dominated society but fails to pass as human, with people calling her the B word, and have it end on a cliffhanger as she is prepared for plastic surgery.Also, the name &quot;Betty Boop&quot; is still under copyright.Names of characters used in more than one work or in merchandise are generally subject to trademark, not copyright. The US Supreme Court has refused to enforce the Lanham Act, which relates to trademarks and passing off, in such a way that it would extend the effective term of an

The slightly dog-faced one with floppy dog ears from the original movie Dizzy Dishes

Lean into that. Make an episode where poodle!Betty tries to fit into a human-dominated society but fails to pass as human, with people calling her the B word, and have it end on a cliffhanger as she is prepared for plastic surgery.

Also, the name &quot;Betty Boop&quot; is still under copyright.Names of characters used in more than one work or in merchandise are generally subject to trademark, not copyright. The US Supreme Court has refused to enforce the Lanham Act, which relates to trademarks and passing off, in such a way that it would extend the effective term of an

Also, the name &quot;Betty Boop&quot; is still under copyright.

Names of characters used in more than one work or in merchandise are generally subject to trademark, not copyright. The US Supreme Court has refused to enforce the Lanham Act, which relates to trademarks and passing off, in such a way that it would extend the effective term of an

It&#39;s public domain day every day on the high seas ... arrrrr

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

&quot;In matters of principle, stand like a rock; in matters of taste, swim with 
the current.&quot;
-- Thomas Jefferson</div>
        </div>
        
        <div class="card" onclick="openModal('content-27')">
            <div class="source">Slashdot</div>
            <div class="title">European Space Agency Acknowledges Another Breach as Criminals Claim 200 GB Data Haul</div>
            <div class="meta">2026-01-01</div>
        </div>
        
        <div id="content-27" style="display:none;">
            <h2>European Space Agency Acknowledges Another Breach as Criminals Claim 200 GB Data Haul</h2>
            <p><strong>Slashdot | 2026-01-01</strong></p>
            <a class="original-link" href="https://it.slashdot.org/story/26/01/01/1525235/european-space-agency-acknowledges-another-breach-as-criminals-claim-200-gb-data-haul?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Slashdot is powered by your submissions, so send in your scoop

Server administration -- it&#39;s not exactly vibe coding, is it?

Actually, does Europe have UFOs? What do European aliens look like?

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

&quot;In matters of principle, stand like a rock; in matters of taste, swim with 
the current.&quot;
-- Thomas Jefferson</div>
        </div>
        
        <div class="card" onclick="openModal('content-28')">
            <div class="source">Slashdot</div>
            <div class="title">The Man Taking Over the Large Hadron Collider</div>
            <div class="meta">2026-01-01</div>
        </div>
        
        <div id="content-28" style="display:none;">
            <h2>The Man Taking Over the Large Hadron Collider</h2>
            <p><strong>Slashdot | 2026-01-01</strong></p>
            <a class="original-link" href="https://science.slashdot.org/story/26/01/01/1455227/the-man-taking-over-the-large-hadron-collider?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Want to read Slashdot from your mobile device? Point it at m.slashdot.org and keep reading!

So he&#39;s paid to do nothing for 5 years then ?That&#39;s an even cushier job than Slashdot &quot;editor&quot;.Your premise is offensively stupid.  The idea that the director of a 27km particle-accelerator undergoing an upgrade to 10x its efficacy will be idle during that time is absurd.  This guy will make more, and more impactful decisions in this period than you will in your entire lifetime.  One action, one phone call, one assignment of staff to address something like a cost overrun or delay or equipment shortage or accident will outweigh your impact on humanity.  And - to be clear - mine. 
By all means, make fu

So he&#39;s paid to do nothing for 5 years then ?That&#39;s an even cushier job than Slashdot &quot;editor&quot;.

Your premise is offensively stupid.  The idea that the director of a 27km particle-accelerator undergoing an upgrade to 10x its efficacy will be idle during that time is absurd.  This guy will make more, and more impactful decisions in this period than you will in your entire lifetime.  One action, one phone call, one assignment of staff to address something like a cost overrun or delay or equipment shortage or accident will outweigh your impact on humanity.  And - to be clear - mine. 
By all means, make fu

I HAVE SEEN THE TRUTH of the universe. I have spoken to gods you will never even know exist.That is just a side effect of the Thorazine.

I HAVE SEEN THE TRUTH of the universe. I have spoken to gods you will never even know exist.

That is just a side effect of the Thorazine.

But one of the first things Thomson will do is turn the machine off for engineering work. It will not restart until his term is nearly over....Thomson is far from disconsolate about the shutdown. If anything, he is relishing what the next five years hold. 

“The machine is running brilliantly and we’re recording huge amounts of data,” he says. “There’s going to be plenty to analyse over the period. The physics results will keep on coming.”

The decision to do it was made in 2011, and they&#39;ve been building the parts that will go into it, and they&#39;d already committed to doing the installation at the end of the current operating period, but the schedule for ending that period is &quot;mid-2026&quot;, so he gets to be the one who makes that date exact, with people hoping to get one last experiment that doesn&#39;t need the upgrade in before they have to wait a long time.

They have a few space-based cosmic ray detectors and many on the ground.  It might be a tad difficult to finagle a 27km ring of magnets and vacuum pumps with appropriate shielding into orbit... not sure how many launches that would take,

This &quot;Large Hadron&quot; collider must be a gigantic con!

They may be hoping that this upgrade will jump us back to the real timeline, but I bet we end up even farther off.

The fact that LHC produces a small amount of Hadrons annually, and the tiny &#39;quantum black holes&#39; it generates don&#39;t cause time travel.  Actually, regular black holes probably don&#39;t even cause time travel (being that the nearest is like 1,560 light years... it&#39;ll take a little bit to get to it and launch some poor soul into it... and we won&#39;t know what happens to that poor soul because black holes eat all the information preventing us from knowing what happened to the dude (as far as we

Has the LHC accomplished a single thing yet that benefits people at all ... or even a hint of doing so?Depends whether you consider knowledge a benefit.  Seems to be about even odds on that.

Has the LHC accomplished a single thing yet that benefits people at all ... or even a hint of doing so?

Depends whether you consider knowledge a benefit.  Seems to be about even odds on that.

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

&quot;In matters of principle, stand like a rock; in matters of taste, swim with 
the current.&quot;
-- Thomas Jefferson</div>
        </div>
        
        <div class="card" onclick="openModal('content-29')">
            <div class="source">Slashdot</div>
            <div class="title">You Can't Trust Your Eyes To Tell You What's Real Anymore, Says Instagram Head</div>
            <div class="meta">2026-01-01</div>
        </div>
        
        <div id="content-29" style="display:none;">
            <h2>You Can't Trust Your Eyes To Tell You What's Real Anymore, Says Instagram Head</h2>
            <p><strong>Slashdot | 2026-01-01</strong></p>
            <a class="original-link" href="https://tech.slashdot.org/story/26/01/01/1355226/you-cant-trust-your-eyes-to-tell-you-whats-real-anymore-says-instagram-head?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Catch up on stories from the past week (and beyond) at the Slashdot story archive

Anything digital can be manipulated and has to be verified.Depending on how much it matters, of course.

Has been true since any of us have been alive.  The difference is the ease in which images can be generated and manipulated now, and the willingness of people to grift.

The article reads as if Instagram and Social Media by default will get out in front of the claims that AI generated content causes harm or a liability to the social media company.

https://www.theverge.com/news/... [theverge.com]

https://www.scry.llc/2025/12/2... [scry.llc]

Every week I see the appearance of Law of Demeter (LoD) in different domains. For instance, the recent creation of the &quot;C5&quot; to replace the US-centric &quot;G7&quot;. The C5 establishes five global domains of roughly equal standing versus the G7 unipolar world. Trump is not cause, he is effect.

Not only digital. Double exposure is a thing.

Mosseri wrote that for most of his life he could safely assume photographs or videos were largely accurate captures of moments that happened...
That&#39;s always been a foolishly naive stance to take. Going all the way back to the early days of photography, images were routinely staged or faked. For example, the American civil war photographer Mathew Brady would arrive days after a battlefield had been cleared of casualties, so he would have his assistants lie on the ground to provide the appearance actual dead.
 
Technology has made fakes easier to produce, but they&#39;ve always been with us. What&#39;s in shorter supply today is critical thinking. Always question media, never take it at face value. Ask yourself, what is this piece of media trying to lead me to believe? What agenda does it serve? Who is behind it?
 
And finally, get off Facebook and Instagram. They are two of the larger purveyors of fraudulent media on the internet.

Mosseri wrote that for most of his life he could safely assume photographs or videos were largely accurate captures of moments that happened...

That&#39;s always been a foolishly naive stance to take. Going all the way back to the early days of photography, images were routinely staged or faked. For example, the American civil war photographer Mathew Brady would arrive days after a battlefield had been cleared of casualties, so he would have his assistants lie on the ground to provide the appearance actual dead.
 
Technology has made fakes easier to produce, but they&#39;ve always been with us. What&#39;s in shorter supply today is critical thinking. Always question media, never take it at face value. Ask yourself, what is this piece of media trying to lead me to believe? What agenda does it serve? Who is behind it?
 
And finally, get off Facebook and Instagram. They are two of the larger purveyors of fraudulent media on the internet.

But he still had to go there, had to bring a lot of people, had to get everyone to keep quiet about how they did it, etc.

In the time it&#39;s taken me to write this someone could write a prompt to create an entire video of a nuke hitting New York and sharing it all over the internet for everyone to immediately see, and in the time it took you to read it he could prompt another video for Los Angeles. There&#39;s a very massive difference in scope.

&quot;...most of his life he could safely assume photographs or videos were largely accurate captures of moments that happened, adding that this is clearly no longer the case.&quot;

No, it is and always will be the case that photographs are &quot;largely accurate captures of moments that happened&quot;, in fact completely accurate.  That&#39;s what a photograph is.  Not all images are photographs, the &quot;head&quot; of Instagram should know this.

it is and always will be the case that photographs are &quot;largely accurate captures of moments that happened&quot;, in fact completely accurate. That&#39;s what a photograph is.No. That&#39;s what a singly exposed photo negative shot through the most ideal lens possible with the best possible film in good lighting is, or as close as you can get anyway. A photograph as presented to you might be any number of things and it is extremely typical to for example dodge and burn specific regions of a photograph to emphasize or hide specific details. When I took a B&W photo class quite some moons ago, one of my most appreciated photos was of a sign. It was too dark so contrast was poor, an

it is and always will be the case that photographs are &quot;largely accurate captures of moments that happened&quot;, in fact completely accurate. That&#39;s what a photograph is.

No. That&#39;s what a singly exposed photo negative shot through the most ideal lens possible with the best possible film in good lighting is, or as close as you can get anyway. A photograph as presented to you might be any number of things and it is extremely typical to for example dodge and burn specific regions of a photograph to emphasize or hide specific details. When I took a B&W photo class quite some moons ago, one of my most appreciated photos was of a sign. It was too dark so contrast was poor, an

June 1994, the identical mugshot photo of OJ Simpson... two very different magazine covers achieved with just dodge and burn:https://scpr.brightspotcdn.com... [brightspotcdn.com]

For years, there was a concept of &quot;instagram face&quot;. That specific set of filters that so many women chose to use that made them all look very similar.

So you couldn&#39;t trust photographs on instagram for a very long time now. This is nothing new.

&quot;A women&quot; is a giveaway that the only sex you get is when you pay wor it.

I agree with you this is not new, I will even add Instagram never published photographs. We still can have some trust in photographs, when in the form of RAW files from a camera capable of cryptographic signatures such as the C2PA standard (Content Credentials). Of course a well-funded actor such as a State agency could hack it, but that was already the case with film photography.

Its interesting to think about what an anomaly the last hundred or so years has been. Prior to easy photography and radio/telegraph virtually all information would have been secondhand and easily manipulated or misconstrued. At the founding of the US there would have been many printers in any major city, each with agendas. There were prominent &quot;debates&quot; held through these publications that were done by pseudonym and were often false or salacious. Realistically thats part of what lit the fire of the American revolutionary war. When you think about it, it all looks a whole lot like the modern partisan media landscape with all its manipulations.

I dont know how this all unfolds, and its entirely possible modern technology amplifies the bad aspects of this way more than in the past (its a lot easier to be fooled by a realistic image than a political cartoon, for example). But i do take a little comfort in the fact that we&#39;ve been here before.

It wasn&#39;t just photoshop though. Real photos/videos with a false legend have been a thing on social media. Like picture of riots that were actually from years ago in another country.

I wonder how this is would impact the justice system. Courts very much rely on photos and videos as the source of truth.

I&#39;m pretty sure that desperate people would use desperate measures, regardless of the consequences. After all, if you&#39;re going to prison, fabricating evidence sounds like an acceptable risk. You&#39;d probably only get like another year on top of your original sentence. The lawyers would probably get away with claiming plausible deniability and shifting the blame to the client.

You can trust your eyes to tell you what&#39;s real. That&#39;s not the problem. The issue is that a photograph of something isn&#39;t that something. What your eyes tell you about the photograph itself can be trusted, but that doesn&#39;t tell you anything about whether you can trust the image represented in the photograph or whether what the camera captured was edited before it was shown to you. And even when you&#39;re looking directly at something, there&#39;s a difference between what you&#39;re seeing and how your brain interprets what you&#39;re seeing (see any number of optical illusions that mess with how you interpret what you see, eg. forced perspective).

If you keep this in mind, you have a guide for working out how much you can trust any way you get information.

Or seen a professional pickpocket? I&#39;ve seen YouTube videos in which I needed to rewind 5 times before I saw the moment when the pickpocket got the item from his victim, which suddenly had in his hands.

So yeah, you can tell that that picture of Donald Trump giving Bill Clinton a blow jobNobody needed to know what your favorite kind of deepfake porn is. Just sayin.Remember, the riches still telling their kids to go to college. It&#39;s only your kids that are going to be plumbersWho is &quot;the riches&quot;? And why are you hating on plumbers? If only you had enough money to hire one, you wouldn&#39;t be living in your own filth right now. Or are you just hating on them because anyone making over $100,000 per annum as many plumbers do is &quot;the riches&quot; to you?

So yeah, you can tell that that picture of Donald Trump giving Bill Clinton a blow job

Nobody needed to know what your favorite kind of deepfake porn is. Just sayin.

Remember, the riches still telling their kids to go to college. It&#39;s only your kids that are going to be plumbersWho is &quot;the riches&quot;? And why are you hating on plumbers? If only you had enough money to hire one, you wouldn&#39;t be living in your own filth right now. Or are you just hating on them because anyone making over $100,000 per annum as many plumbers do is &quot;the riches&quot; to you?

Remember, the riches still telling their kids to go to college. It&#39;s only your kids that are going to be plumbers

Who is &quot;the riches&quot;? And why are you hating on plumbers? If only you had enough money to hire one, you wouldn&#39;t be living in your own filth right now. Or are you just hating on them because anyone making over $100,000 per annum as many plumbers do is &quot;the riches&quot; to you?

I don&#39;t think &quot;honey&quot; will evaluate it in the same way.... people do still put 2 and 2 together to get 4. Just because there is &quot;plausible deniability&quot; doesn&#39;t mean it passes the smell test. People aren&#39;t stupid. Well, some are but not all, especially when it concerns a subject that is important to them.

Camera makers are pushing for Content Authenticity. Look for CAI and C2PA standards. Canon are Nikon are both on board, also some phone makers, including Samsung, see https://news.samsung.com/globa...  [samsung.com]

Idea is that the device captures the image and signs it with vendor&#39;s certificate. Then, when you edit it in your editor (Photoshop - unfortunately GIMP not yet), the editor saves in the metadata what exactly you changed and signs with their own cert (e.g. &quot;I cropped this photo and adjusted lighting curves a bi

I am sure that will benefit the users, just like the other trusted computing techniques.

As you already mention with GIMP, it already starts that using a self compiled image editor breaks the trust chain. Even with a signed GIMP binary, you can assume that some verifiers will only allow signatures from a narrow range of &quot;trusted&quot; programs. Your image was edited with GIMP instead of Photoshop? We didn&#39;t audit GIMP, so we cannot trust your image.

Nope. Trusted computing only benefits the people pushing these th

Guy Gavriel Kay (who was hired at a very young age by Christopher Tolkien to complete The Silmarillion) frequently writes on the theme of memory. His most famous novel is probably Tigana, which is literally (avoiding spoilers) about the unreliable nature of memory. Kay wrote in an afterword:

There exists a photo – I think I saw it first in ‘LIFE’ magazine – from Czechosloviakia, in 1968, the time of the ‘Prague Spring’ when a brief, euphoric flicker of freedom animated that Iron Curtain country before the Soviet tanks rolled in and crushed it brutally.There are actually two photographs. The first shows a number of Communist Party functionaries in a room, wearing nondescript suits, looking properly sombre. The second is the same photo. Almost. There is one functionary missing now, and something I recall to be a large plant inserted where he was. The missing figure – part of the crushed uprising – is not only dead, he has been erased from the record. A trivial technical accomplishment today, when the capacity we have for altering images and sound is so extreme, but back then the two photographs registered powerfully for me, and lingered for twenty years: not only killed, but made to never have been. Source  [brightweavings.com] Photographic manipulation, and propaganda, and the manipulation of people and their memories, has been going on for a long time! The difference now, as others have said, is the ubiquity, capacity, low technological barri

There exists a photo – I think I saw it first in ‘LIFE’ magazine – from Czechosloviakia, in 1968, the time of the ‘Prague Spring’ when a brief, euphoric flicker of freedom animated that Iron Curtain country before the Soviet tanks rolled in and crushed it brutally.

There are actually two photographs. The first shows a number of Communist Party functionaries in a room, wearing nondescript suits, looking properly sombre. The second is the same photo. Almost. There is one functionary missing now, and something I recall to be a large plant inserted where he was. The missing figure – part of the crushed uprising – is not only dead, he has been erased from the record. A trivial technical accomplishment today, when the capacity we have for altering images and sound is so extreme, but back then the two photographs registered powerfully for me, and lingered for twenty years: not only killed, but made to never have been. Source  [brightweavings.com]

Photographic manipulation, and propaganda, and the manipulation of people and their memories, has been going on for a long time! The difference now, as others have said, is the ubiquity, capacity, low technological barri

You can&#39;t trustyour eyes anymore but you can trust some stranger on the internet telling you that you can&#39;t trust yourself. Sounds plausible. In bizzarroworld. Where we are living.

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

&quot;In matters of principle, stand like a rock; in matters of taste, swim with 
the current.&quot;
-- Thomas Jefferson</div>
        </div>
        
        <div class="card" onclick="openModal('content-30')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">2025: The Music of the Year</div>
            <div class="meta">2026-01-01</div>
        </div>
        
        <div id="content-30" style="display:none;">
            <h2>2025: The Music of the Year</h2>
            <p><strong>News and Politics - Slate Magazine | 2026-01-01</strong></p>
            <a class="original-link" href="https://slate.com/podcasts/what-next/2026/01/bad-bunny-rosalia-and-geese-rocked-our-2025?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Bad Bunny continued to dominate—but newcomers like Cameron Winter and his band Geese also shined.

Please enable javascript to get your Slate Plus feeds.

If you can&#39;t access your feeds, please contact customer support.

Thanks! Check your phone for a link to finish setting up your feed.

Enter your phone number and we&#39;ll text you a link to set up the
        podcast in your app:

We&#39;ll only text you about setting up this podcast, no spam.

Apple Podcasts will only work on MacOS operating systems since Catalina. We do not support Android apps on desktop at this time.

These links will only work if you&#39;re on the device you listen to podcasts on.

We&#39;re sorry, but something went wrong while fetching your podcast feeds. Please contact us at plus@slate.com for help.

2025 might not have been a great year —but the music sure was stellar.

Want more What Next? Subscribe to Slate Plus to access ad-free listening to the whole What Next family and across all your favorite Slate podcasts. Subscribe today on Apple Podcasts by clicking “Try Free” at the top of our show page. Sign up now at slate.com/whatnextplus to get access wherever you listen.

Podcast production by Ethan Oberman, Elena Schwartz, Paige Osburn, Anna Phillips, Madeline Ducharme and Rob Gunther.

The problem with the news right now? It’s everywhere. And each day, it can feel like we’re all just mindlessly scrolling. It’s why we created What Next. This short daily show is here to help you make sense of things. When the news feels overwhelming, we’re here to help you answer: What next? Look for new episodes every weekday morning.

Mary Harris is the host and managing editor of What Next, Slate&#39;s new daily news podcast. She has reported throughout the public radio system, for NPR, Marketplace, and WNYC.</div>
        </div>
        
        <div class="card" onclick="openModal('content-31')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">What Does the <em>A</em> in ASCII Stand For?</div>
            <div class="meta">2026-01-01</div>
        </div>
        
        <div id="content-31" style="display:none;">
            <h2>What Does the <em>A</em> in ASCII Stand For?</h2>
            <p><strong>News and Politics - Slate Magazine | 2026-01-01</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2026/01/trivia-quiz-daily-slate-science-botany-computers-geometry.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Please enable Javascript in your browser to view Slate interactives.

Slate Crossword: It Ends at the Time Shown in This Grid (13 letters)

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-32')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">The US’ Self-Appointed Antisemitism Watchdog Is Ignoring the Country’s Biggest Source of Antisemitism</div>
            <div class="meta">2026-01-01</div>
        </div>
        
        <div id="content-32" style="display:none;">
            <h2>The US’ Self-Appointed Antisemitism Watchdog Is Ignoring the Country’s Biggest Source of Antisemitism</h2>
            <p><strong>News and Politics - Slate Magazine | 2026-01-01</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2026/01/zohran-mamdani-donald-trump-adl-greenblatt.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Sign up for the Slatest to get the most insightful analysis, criticism, and advice out there, delivered to your inbox daily.

On January 1, Zohran Mamdani will be sworn in as the first Muslim mayor of New York City. Administering the oath in a public ceremony will be Bernie Sanders, among the most prominently Jewish senators in the country. For weeks, Mamdani has been meeting with constituents and leaders from every sector of New York Jewry to alleviate their concerns about his support for their safety and wellbeing. By nearly all accounts, these have been a great success. From the Reform Rabbi Amiel Hirsch—who had coauthored a widely circulated letter against Mamdani—to the Satmar Hasidim in Brooklyn, New York Jews expressed at least cautious optimism about their mayor elect, if not outright excitement.

During these same weeks, the most powerful Republican politicians and media personalities in the country have leaned deeply into open antisemitism. Two weeks ago, for example, the White House held its annual Hanukah party. In attendance was Rep. Paul Gosar, an open white nationalist who is deeply embedded in neo-Nazi, Holocaust denying spaces, including Nick Fuentes’. At the celebration, the President of the United States talked about the power of the “Jewish lobby” behind Israel and bragged about being funded by Jewish money.

A week later, Turning Point USA held their Americafest, where a parade of speakers defended the right of open Nazis to exist within the Republican Party. Tucker Carlson spewed a series of claims about a cabal fighting American national interests as he defended himself against Ben Shapiro’s criticism for platforming Nick Fuentes. Steve Bannon said to cheers that Shapiro—whose prominent Jewishness stood out at the affair—“is like a cancer, and that cancer spreads.” And JD Vance—the Vice President of the United States—also defended including neo-nazis in his party. Vance contrasted his party of “free thinkers” to the threat of “a bunch of drones who take their orders from George Soros.” He concluded to tumultuous cheers: “By the grace of God, we always will be a Christian nation.”

Finally, on Christmas Day, the President of the United States, the Secretary of Defense, the Secretary of Homeland Security, and much of the rest of our national government posted greetings that described America as a Christian nation with explicit reference to our savior, Jesus Christ.

So what does America’s self-described defender against antisemitism, the Anti-Defamation League, have to say about the nation’s dominant political movement welcoming open antisemites into its ranks? Shockingly little. They have chosen not to focus much on these powerful people spewing or platforming explicit, even pro-Nazi, antisemitism. Indeed, they have ignored and even defended many of them.

Instead, the ADL seems laser focused on Mamdani. They even set up a “Mamdani Watch” site, suggesting that he is the greatest threat to American Jews today, with no such “watch” site for these other, far more powerful men and women. Their latest post, for example, uncovered members of his team with possible antisemitic connections, who Mamdani then cut. Their own monitor concluded that “when clear antisemitic statements are identified, Mayor-elect Mamdani’s team can and will respond appropriately.”

The exact opposite has been the case with Republican leadership regarding explicit antisemitism, Christian nationalism, and even Nazism. So why the focus on Mamdani?

The answer is that this is not about antisemitism but rather about preserving Israeli power over Palestinians. Though many Jews are unhappy that Mamdani won’t condemn the phrase “globalize the intifada”—he has said he dislikes it but will not condemn it—Mamdani is mainly accused of antisemitism because he only supports Israel’s existence as a democratic state and opposes one that gives preferential treatment to Jews over Palestinians.

What does it mean to label a call for equality “antisemitic”? Let us interrogate this accusation.Palestinians within Israel’s internationally recognized borders are citizens but suffer structural discrimination. The controversial 2018 “Nation State” law is perhaps the most egregious expression of this unequal status, but it appears in other areas as well.

Let’s set that aside, however, especially considering our own structural discrimination here at home. Israel currently rules the entire area from the Jordan River to the Mediterranean Sea. Indeed, in many ways it considers the West Bank already a part of Israel, including on its official maps. As a result, about half of the people currently controlled by Israel and subject to its military are Palestinian, only a fraction of whom are eligible for citizenship. In other words, the only way Israel exists as a Jewish majority state is through the expulsion of Palestinians, especially during the 1948 Nakba, and (above all) through the denial of citizenship to Palestinians in the West Bank, including East Jerusalem, and obviously Gaza. “Pro-Israel” critics are correct that if those Palestinians were awarded equality, Israel would become a different state. It would be a binational democracy.

What does it mean to label a call for equality antisemitic because it would destroy Israel as Jewish state? It means that an argument that opposes Israel maintaining a Jewish majority in this way and demanding Palestinian equality is antisemitic because it calls for the “destruction of Israel” as a Jewish state. It is saying that it is antisemitic to insist on equality more imminently then “someday, when Israel feels they are ready, it will give Palestinians a state in part of the land with limited sovereignty such that Israel will maintain superior military power over them.

This is the crux of the issue. Is this position calling for equality, which because of the demographic reality will mean the end of Jewish hegemony, antisemitic?

Consider how we would view it if Palestinians were to somehow expel millions of Jews, establish a “Palestinian majority state,” grant citizenship to only a fraction of Jews left behind, and keep the remainder subject to military rule without citizenship or civil rights. Imagine if that takeover had included the catastrophic destruction of civilian infrastructure and death of tens of thousands. And imagine if those Jews who were left disenfranchised were to experience violence by the state and sometimes vigilantes who the state supports or ignores. And imagine that Palestinians defended this as necessary for their security because it was the only way to have Palestinian self-determination, and accused people of racism if they opposed it?

In other words, imagine a reversal of today’s situation. Under such conditions, would we consider support for Jewish equality as anti-Palestinian bigotry? Would it be racist against Palestinians and a violation of their right to self-determination in that scenario for Jews and others to reject this arrangement as unacceptable and demand both immediate equality and a right of return for the Jewish refugees? If not, why does challenging the current arrangement with a call for equality constitute antisemitism?

American Jews do face a growing threat of antisemitism. It can certainly come from people claiming to oppose Israeli actions but blaming American Jews for them. As we saw tragically in Australia on Chanukah, the threat of ISIS-inspired terror is also still quite real.

But if we are looking at political threats to Jewish equality and safety in America, with real material consequences, why would we focus on a city mayor committed to equality instead of a national party currently in control of every branch of government? A party whose top leaders from the President on down are spewing open antisemitism and Christian nationalism - not to mention open racism - while publicly defending the inclusion of Holocaust-denying Nazis?We would only do this if our goal was corrupted.

It is one thing to keep an eye on the entire political spectrum. It is another to misrepresent the principal source of threat.

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-33')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">Celebrate 20 Years of the Political Gabfest</div>
            <div class="meta">2026-01-01</div>
        </div>
        
        <div id="content-33" style="display:none;">
            <h2>Celebrate 20 Years of the Political Gabfest</h2>
            <p><strong>News and Politics - Slate Magazine | 2026-01-01</strong></p>
            <a class="original-link" href="https://slate.com/podcasts/political-gabfest/2026/01/politics-political-gabfest-hosts-revisit-fan-favorite-segments?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The hosts revisit fan favorite segments for the 20th anniversary of the Political Gabfest.

Please enable javascript to get your Slate Plus feeds.

If you can&#39;t access your feeds, please contact customer support.

Thanks! Check your phone for a link to finish setting up your feed.

Enter your phone number and we&#39;ll text you a link to set up the
        podcast in your app:

We&#39;ll only text you about setting up this podcast, no spam.

Apple Podcasts will only work on MacOS operating systems since Catalina. We do not support Android apps on desktop at this time.

These links will only work if you&#39;re on the device you listen to podcasts on.

We&#39;re sorry, but something went wrong while fetching your podcast feeds. Please contact us at plus@slate.com for help.

This week, Emily Bazelon, John Dickerson, and David Plotz revisit several favorite segments from Gabfests past to celebrate their 20th anniversary: the consequential and eye-opening “don’t call the police” debate, the segment in which John shows Bill Clinton how to apologize with his characteristic eloquence and grace, and that time a data scientist definitively answered the important question: which host interrupts the others the most?

Here are some notes and references from this week’s show:

Jessica Grose for Slate: Parents Are Now Getting Arrested for Letting Their Kids Go to the Park Alone

“John Shows Bill Clinton How to Apologize” Segment

Carmen Russo for Slate: Stephen Colbert Confronted President Clinton About His “Tone-Deaf” #MeToo Comments

10/21/21: The “Great Resignation” Edition

Lindsay Lee: Does David Plotz interrupt Emily Bazelon too much on Slate’s Political Gabfest?

7/28/22: The “Did You Apologize to Manchin Yet?” Edition

Marin Cogan for Vox: The deadliest road in America

For this week’s Slate Plus bonus episode, Emily, John, and David revisit one more favorite segment from 20 years of the Political Gabfest: that time in 2008 they fought about the John Edwards love affair scandal.

In the latest Gabfest Reads, David Plotz talks with Wikipedia co-founder Jimmy Wales about his new book The Seven Rules of Trust: A Blueprint for Building Things That Last. They discuss how Wikipedia’s culture of assuming good faith and shared purpose became a model for building trustworthy digital communities — and what lessons that holds for companies, social media, and politics today.

Email your chatters, questions, and comments to gabfest@slate.com. (Messages may be referenced by name unless the writer stipulates otherwise.)

You can find the full Political Gabfest show pages here.

Want more Political Gabfest? Join Slate Plus to unlock weekly bonus episodes. Plus, you’ll access ad-free listening across all your favorite Slate podcasts. You can subscribe directly from the Political Gabfest show page on Apple Podcasts and Spotify. Or visit slate.com/gabfestplus to get access wherever you listen.

Find out more about David Plotz’s monthly tours of Ft. DeRussy, the secret Civil War fort hidden in Rock Creek Park.

In a notorious segment from 2008, the hosts have an entertaining fight.

Voted “Favorite Political Podcast” by Apple Podcasts listeners. Stephen Colbert says, &quot;Everybody should listen to the Slate Political Gabfest.&quot; The Gabfest is hosted by Emily Bazelon, John Dickerson, and David Plotz. Listen for the debates, stay for the cocktail chatter.

David Plotz is a host of the Slate Political Gabfest and the CEO of City Cast.

Emily Bazelon is a staff writer at the New York Times Magazine, the author of Charged and Sticks and Stones, and co-host of the Slate Political Gabfest.

John Dickerson is host of CBS News Prime Time With John Dickerson, co-host of the Slate Political Gabfest, host of the Whistlestop podcast, and author of The Hardest Job in the World.</div>
        </div>
        
        <div class="card" onclick="openModal('content-34')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">The First Woman to Serve a Full Term as a U.S. Senator, Hattie Caraway, Represented Which State?</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-34" style="display:none;">
            <h2>The First Woman to Serve a Full Term as a U.S. Senator, Hattie Caraway, Represented Which State?</h2>
            <p><strong>News and Politics - Slate Magazine | 2025-12-31</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2025/12/trivia-quiz-daily-slate-history-assassination-rome-free-speech.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Please enable Javascript in your browser to view Slate interactives.

Slate Crossword: It Ends at the Time Shown in This Grid (13 letters)

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-35')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">2025: The Advice of the Year</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-35" style="display:none;">
            <h2>2025: The Advice of the Year</h2>
            <p><strong>News and Politics - Slate Magazine | 2025-12-31</strong></p>
            <a class="original-link" href="https://slate.com/podcasts/what-next/2025/12/the-advice-we-turned-to-in-2025?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">In a year when things felt out of control, this advice kept us grounded.

Please enable javascript to get your Slate Plus feeds.

If you can&#39;t access your feeds, please contact customer support.

Thanks! Check your phone for a link to finish setting up your feed.

Enter your phone number and we&#39;ll text you a link to set up the
        podcast in your app:

We&#39;ll only text you about setting up this podcast, no spam.

Apple Podcasts will only work on MacOS operating systems since Catalina. We do not support Android apps on desktop at this time.

These links will only work if you&#39;re on the device you listen to podcasts on.

We&#39;re sorry, but something went wrong while fetching your podcast feeds. Please contact us at plus@slate.com for help.

With rising authoritarianism, terrifying speech crackdowns, and violence in the streets, this year we found ourselves turning to our friends over at How To for advice on finding peace and excitement in our lives.

Want more What Next? Subscribe to Slate Plus to access ad-free listening to the whole What Next family and across all your favorite Slate podcasts. Subscribe today on Apple Podcasts by clicking “Try Free” at the top of our show page. Sign up now at slate.com/whatnextplus to get access wherever you listen.

The problem with the news right now? It’s everywhere. And each day, it can feel like we’re all just mindlessly scrolling. It’s why we created What Next. This short daily show is here to help you make sense of things. When the news feels overwhelming, we’re here to help you answer: What next? Look for new episodes every weekday morning.

Carvell Wallace is a New York Times bestselling author, contributing writer to the New York Times Magazine, and a former Slate parenting columnist and co-host of Mom and Dad Are Fighting. He also hosted the Finding Fred podcast and writes for GQ, Esquire, the Atlantic, the New Yorker, and other outlets.

Courtney E. Martin is the author of Learning in Public: Lessons for a Racially Divided America From My Daughter’s School, among other books, and writes a weekly newsletter called Examined Family. She co-hosts the Slate podcast How To!</div>
        </div>
        
        <div class="card" onclick="openModal('content-36')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">China's BYD logs record EV sales in 2025</div>
            <div class="meta">2026-01-01</div>
        </div>
        
        <div id="content-36" style="display:none;">
            <h2>China's BYD logs record EV sales in 2025</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2026-01-01</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2026-01-china-byd-ev-sales.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-37')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">Review: These are the best plug-in hybrids for under $55,000</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-37" style="display:none;">
            <h2>Review: These are the best plug-in hybrids for under $55,000</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2025-12-31</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2025-12-hybrids.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-38')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">France plans social media ban for children under 15</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-38" style="display:none;">
            <h2>France plans social media ban for children under 15</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2025-12-31</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2025-12-france-social-media-children.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-39')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">Low-cost gelators nearly double the performance of aircraft anti-icing fluids, finds new study</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-39" style="display:none;">
            <h2>Low-cost gelators nearly double the performance of aircraft anti-icing fluids, finds new study</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2025-12-31</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2025-12-gelators-aircraft-anti-icing-fluids.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-40')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">Tucked away in a downtown Chicago office building, fallen e-commerce star Groupon is ready for a comeback</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-40" style="display:none;">
            <h2>Tucked away in a downtown Chicago office building, fallen e-commerce star Groupon is ready for a comeback</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2025-12-31</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2025-12-tucked-downtown-chicago-office-fallen.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-41')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">How California's Delete Act will protect personal information from data brokers in the New Year</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-41" style="display:none;">
            <h2>How California's Delete Act will protect personal information from data brokers in the New Year</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2025-12-31</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2025-12-california-delete-personal-brokers-year.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-42')">
            <div class="source">The Register</div>
            <div class="title">Defusing space 'scope photobombs and more: Mitigating pollution from satellite RF transmissions</div>
            <div class="meta">2026-01-01</div>
        </div>
        
        <div id="content-42" style="display:none;">
            <h2>Defusing space 'scope photobombs and more: Mitigating pollution from satellite RF transmissions</h2>
            <p><strong>The Register | 2026-01-01</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2026/01/01/mitgating_pollution_from_satellite_rf/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Interview Scientists and engineers have been taken aback by the amount of radio interference generated by satellite constellations, and many are calling on standards bodies to improve operator performance.

The photobombing of ground- and space-based telescopes by proliferating satellites in Low Earth Orbit has long vexed astronomers. As well as optical annoyances, radio astronomers are also encountering interference due to satellites communicating with ground stations.

In an interview with The Register, Tudor Williams, CTO of high-frequency RF communication company Filtronic, explained the problem, which is mainly related to satellite-to-ground transmissions (many large constellations, such as SpaceX&#39;s Starlink, use optical links for satellite-to-satellite communication, which don&#39;t cause the same issues.)

According to Williams, the problem comes from the side lobes of poorly designed antennas, where signals are unintentionally spread. The effect can be bands used for communications overlapping with observation bands, causing headaches for radio astronomers.

&quot;In a badly designed antenna,&quot; Williams explains, &quot;you get fairly strong lobes of signals that get sent in different directions.&quot;

But surely licensing and regulations should ensure this isn&#39;t an issue?

Yes, but the issue, according to Williams, is that until the satellites began launching, the issue had not been fully understood or anticipated from ground testing. &quot;Maybe the regulations weren&#39;t as stringent as they should have been at the start,&quot; he says, &quot;And as we start to get more data on this, we can obviously have more stringent guard bands and more stringent regulations going forward.&quot;

A &quot;guard band&quot; is a slice of radio spectrum between active bands that acts as a buffer to prevent signals from leaking from one channel into another.

&quot;The designers,&quot; he says, &quot;do the best they can, but sometimes there are errors in the process which mean leaks into the spectrum … the authorities will define how much interference can be tolerated.&quot;

As the problem becomes better understood and companies like SpaceX work with scientists and regulators to devise improved hardware, the situation should start being mitigated. This, however, is small comfort to astronomers dealing with thousands of new sources of interference.

Williams acknowledges that retrofitting hardware to existing satellites is not a viable solution, but says, &quot; They can do updates to things like the waveforms. The type of waveforms you&#39;ve got through the amplifier has quite a big impact on spectral spreading. It&#39;ll stress the amplifiers in different ways.

&quot;So you potentially could optimize the waveforms, using AI or whatever to actually control that and try and cause less distortion with even existing hardware.

&quot;So you could potentially solve it from a baseband perspective.&quot;

It isn&#39;t only altruism that is encouraging good behavior from operators. &quot;The more we see this happening,&quot; explains Williams, &quot;the more that will push back into satellite operators because they&#39;ll be under pressure to behave. Because they have to control their spectrum.

&quot;Everyone understands the problem. Everyone&#39;s aware of the problem. It&#39;s just… how bad is it? What problems is it causing? What do we need to do to be better?&quot;

Williams points out that satellite operators need their licenses, which will be tricky to renew if they behave badly and stomp over places where their signals don&#39;t belong. &quot;I think,&quot; says Williams, &quot;we need to have a co-existence of scientific missions and general broadband comms.&quot;

Starlink satellites, for example, are designed for a relatively short operational lifespan of around five years. As the interference problem becomes better understood and regulations tighten, there is an opportunity for hardware changes. &quot;Would there be cost implications if you have to control it [the signal] better?&quot; muses Williams. &quot;Yes. Probably. Because it makes the design more complicated … volume manufacturing and lots of satellites can add quite a lot of cost in the process.&quot;

Ultimately, while the light pollution of the night sky by the rapidly growing constellations of satellites is visible even to the naked eye, the scale of RF interference has been unexpected by many. According to Williams, &quot;feedback into standards bodies will be pushed out to the satellite operators, and they&#39;ll have to have better performance systems going forward.&quot; ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-43')">
            <div class="source">The Register</div>
            <div class="title">Welcome to Wendy's! Before your order can be taken, you must first reset this kiosk</div>
            <div class="meta">2026-01-01</div>
        </div>
        
        <div id="content-43" style="display:none;">
            <h2>Welcome to Wendy's! Before your order can be taken, you must first reset this kiosk</h2>
            <p><strong>The Register | 2026-01-01</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2026/01/01/bork_wendys_kiosk/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Bork!Bork!Bork! Today&#39;s example of bork-in-the-wild shows that Microsoft is not the only game in town when it comes to screens having an IT moment in public. No, there will be no orders on this Firefox-based drive-thru kiosk at Wendy&#39;s.

Wendy&#39;s is a fast-food chain, predominantly found in the US, with a few scattered locations elsewhere around the world. It is notable for serving square hamburger patties in round buns, and a few examples of the company&#39;s goods can be glimpsed in the menu – the &quot;Baconator&quot; sounds particularly alluring.

However, at this drive-thru, an eagle-eyed Register reader was offered a side of bork with his order, along with a plea to &quot;Restart Firefox manually!&quot;

Do you want bork with that? - click to enlarge

Exactly how that would be achieved with the limited resources available at the kiosk is unclear. Perhaps an overeager opening of the car door could jolt the system into action, or attaching a USB keyboard that every self-respecting IT professional carries at all times.

Whatever, despite the professionalism evident in the zip ties and sticky tape holding the kiosk&#39;s enclosure together, Firefox is not cooperating. The browser appears to be running in Kiosk mode (although there are several possibilities for what mKiosk might be in this context).

The purpose of Kiosk mode in Firefox, as well as elsewhere, is to keep things as simple as possible. User access is intentionally limited, and the expectation is that the kiosk operator will have configured the hardware to deal with every eventuality. In this instance, however, it appears that some sort of reset is underway which has resulted in a clearing of settings and a request to restart the browser.

Somewhere, an engineer has doubtless been notified of an issue and will at some point issue a remote reset command. Although when presented with the mouthwatering alternative of a Baconator instead of immediately hitting the remote reset button ... well, we know what we&#39;d do.

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-44')">
            <div class="source">The Register</div>
            <div class="title">How Microsoft gave customers what they wanted: An audience with Bill Gates</div>
            <div class="meta">2026-01-01</div>
        </div>
        
        <div id="content-44" style="display:none;">
            <h2>How Microsoft gave customers what they wanted: An audience with Bill Gates</h2>
            <p><strong>The Register | 2026-01-01</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2026/01/01/microsofts_approach_to_customer_service/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Microsoft had a special way of dealing with customers demanding to speak to its CEO. One that kept the customer happy without necessarily bothering His Billness.

According to veteran Microsoft engineer Raymond Chen, there was a procedure followed by product support staff if a customer (presumably a prized customer) became irate enough during a call to demand to speak with Bill Gates.

Chen recalled a colleague in product support explaining the process. First, there would be apologies for not resolving the issue to the customer&#39;s satisfaction. If that failed to smooth ruffled feathers and the demands to speak to The Boss continued, then the magic happened.

Chen went on: &quot;The customer was transferred to a special internal phone number, and when the operators saw a call on that line, they took the call and said, &quot;Bill Gates&#39;s office.&quot;

Of course, the operator wasn&#39;t actually in Bill Gates&#39;s office. Instead, they were pretending to be Gates&#39;s secretary. Their only job was to say that Bill Gates was unavailable and to pass on the customer&#39;s complaint and contact details.

The information was then sent back to the tech support team with a note to ensure that whoever called the customer back opened with something like &quot;Bill Gates asked me to contact you to follow up on an issue you had earlier.&quot;

It all smacks of a different era at Microsoft, not least because (a) getting hold of a human in the company&#39;s support team and (b) having a query answered is enough of a challenge these days without demanding to talk to Satya Nadella as well.

Gates handed over his role as CEO to Steve Ballmer in 2000. Ballmer was succeeded by Satya Nadella in 2014. While Chen could not confirm if Gates ever looked at the list of calls, we do know that someone certainly monitored his email account. How? A Register reader told us previously that, back in 1996, they fired off an irate email to billg@microsoft.com – after which they were quickly contacted by a Microsoft engineer who appeared exceedingly keen to solve their Excel issue.

Sadly, unless a customer is very important to Microsoft&#39;s bottom line or has spent enough on getting the personal touch from the company&#39;s support team, they are unlikely to make much headway in similarly escalating their complaint in the modern era of AI and Copilot. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-45')">
            <div class="source">The Register</div>
            <div class="title">Nvidia DMs TSMC: please sir can I have some more? The Chinese are starved for H200s</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-45" style="display:none;">
            <h2>Nvidia DMs TSMC: please sir can I have some more? The Chinese are starved for H200s</h2>
            <p><strong>The Register | 2025-12-31</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2025/12/31/china_nvidia_h200/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">With the sales ban lifted, Chinese tech giants, including ByteDance, are scrambling to secure orders for Nvidia&#39;s H200 graphics accelerators while they can. But will there be enough to satisfy demand?

Citing multiple sources familiar with the matter, Reuters reports Chinese companies have placed orders for more than 2 million of the chips. That&#39;s up from the 40,000 to 80,000 initial orders reported last week.

But with just 700,000 of the now two-year-old AI accelerators in stock, Nvidia has reportedly approached TSMC to ramp production of the chips. The H200 uses TSMC&#39;s 4N process, a slightly older version of technology used by its higher-performance Blackwell parts (4NP), which remain unavailable in China.

Nvidia doesn&#39;t anticipate sales of H200s in China will have any impact on chip supplies to US customers.

&quot;Offering the H200 to approved commercial customers, vetted by the Department of Commerce, strikes a thoughtful balance,&quot; a company spokesperson told The Register and other outlets. &quot;China is a highly competitive market with rapidly growing local chip suppliers. Blocking all U.S. exports undercut our national and economic security and only benefited foreign competition.&quot;

Shipments of the newly minted chips are expected to begin in the second half of 2026 with 8-GPU systems said to sell for around 1.5 million yuan (about $215,000).

Despite its advancing age, the H200 is the most powerful GPU Nvidia can sell in China. Biden-era export controls had capped the performance of chips sold in the Middle Kingdom, but earlier this month, the Trump administration made an exception for H200 shipments if Nvidia agreed to cut Uncle Sam in on 25 percent of the revenues.

Compared to Nvidia&#39;s H20 — a cut-down version of the H200 built to comply with US export controls — that extra zero translates into a pretty big performance jump, particularly for compute-intensive AI training workloads.

The H200 offers 6x faster floating point performance, 50 percent more HBM3e and 20 percent higher memory bandwidth.

ByteDance is apparently one of several Chinese hyperscalers lining up for the chips. According to the South China Morning Post, the TikTok parent plans to buy roughly $14 billion worth of H200s.

However, there is no guarantee that those chips will ever make it to mainland China. While the US government has signed off on H200 sales to China, Beijing has not.

In response to US trade policies governing AI chip and semiconductor equipment sales, Chinese authorities have begun pressuring hyperscalers in the region to ditch Nvidia for domestic alternatives.

The nation has also moved to block state-funded datacenters from using foreign AI chips, while warning of potential backdoors or remote kill switches — allegations Nvidia has fervently denied. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-46')">
            <div class="source">The Register</div>
            <div class="title">US Army seeks human AI officers to manage its battle bots</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-46" style="display:none;">
            <h2>US Army seeks human AI officers to manage its battle bots</h2>
            <p><strong>The Register | 2025-12-31</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2025/12/31/us_army_seeking_officers_willing/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The US Army has been all-in on becoming an AI-powered outfit for some time, and now it&#39;s creating a career path for officers to specialize in making its automation dreams come true.

The new AI/ML officer area of concentration will begin accepting candidates from the Army&#39;s existing officer corps in January through the Volunteer Transfer Incentive Program, according to an announcement published Tuesday. It&#39;s not clear how many AI officers the Army plans to train as part of its initial cadre of candidates, but it wants to have all of them formally reclassified by the end of the 2026 fiscal year.

Training will be at the &quot;graduate level,&quot; according to the Army, and will focus on giving AI officer candidates &quot;hands-on experience in building, deploying, and maintaining the Army&#39;s cutting-edge AI-enabled systems.&quot;

As we&#39;ve reported over the past couple of years, those systems are numerous. The Army has signed deals with OpenAI to run pilot programs in developing warfighting and enterprise domain AI systems, has signed a massive $10 billion contract with Palantir to provide various AI and ML services for the next decade, and has brought in smaller outfits to use AI for things like target tracking.

Young Bang, the US Army&#39;s deputy assistant secretary for acquisition, logistics, and technology under the Biden administration, said last year that the Army didn&#39;t want to get into the business of developing its own AI systems when the private sector was already doing such a great job.

&quot;We want to adopt third-party-generated AI algorithms as fast as y&#39;all are building them,&quot; Bang told the industry at an AWS conference last summer.

In short, there are a lot of commercial AI systems floating around in the Army&#39;s ecosystem but, until later next year, no dedicated force of uniformed experts with the expertise and career longevity the branch needs to get them working at peak efficiency.

&quot;Establishing the … AI/ML career path is another key investment to maintain our decisive edge as an Army,&quot; Army spokesperson Lieutenant Colonel Orlandon Howard said in the Army&#39;s statement. &quot;We&#39;re building a dedicated cadre of in-house experts who will be at the forefront of integrating AI and machine learning across our warfighting functions.&quot;

We suppose the Army could only get so much work out of a bunch of weekend warrior Silicon Valley types who never went through the most basic of officer training before earning their Lieutenant Colonel commissions in a Reserve detachment, where they serve as AI planning and ops consultants.

The actual Army officers who&#39;ll be filling the roles of AI/ML experts for the rest of the service can theoretically come from any background, though the Army said it&#39;ll be prioritizing volunteers &quot;with advanced academic and technical backgrounds in fields related to AI/ML.&quot; ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-47')">
            <div class="source">The Register</div>
            <div class="title">European Space Agency hit again as cybercrims claim 200 GB data up for sale</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-47" style="display:none;">
            <h2>European Space Agency hit again as cybercrims claim 200 GB data up for sale</h2>
            <p><strong>The Register | 2025-12-31</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2025/12/31/european_space_agency_hacked/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The European Space Agency has suffered yet another security incident and, in keeping with past practice, says the impact is limited. Meanwhile, miscreants boast that they&#39;ve made off with a trove of data, including what they claim are confidential documents, credentials, and source code.

While the ESA said it&#39;s aware of a security incident, it added in an X post on Tuesday that the breach may have impacted only &quot;a very small number of external servers&quot; used to support unclassified engineering and scientific collaboration.

&quot;We have initiated a forensic security analysis—currently in progress—and implemented measures to secure any potentially affected devices,&quot; the ESA added. &quot;All relevant stakeholders have been informed, and we will provide further updates as soon as additional information becomes available.&quot;

That&#39;s in contrast to what one cybercriminal posted in their offer of over 200 GB of ESA data for sale on the still-not-dead BreachForums the day after Christmas, according to screenshots grabbed from the seemingly impossible-to-kill cybercrime forum.

According to the alleged attacker, they gained access to ESA-linked external servers on December 18, and were connected &quot;for about a week,&quot; during which they claim to have stolen source code files, CI/CD pipelines, API and access tokens, confidential documents, configuration files, Terraform files, SQL files, hardcoded credentials, and a dump of &quot;all their private Bitbucket repositories as well.&quot;

We reached out to the ESA to get more information about the status of its investigation, and more specifics on what sort of servers were breached, but didn&#39;t hear back, with an automated response informing us that the Agency&#39;s offices are closed for the New Year holiday.

As noted above, this isn&#39;t the first time the ESA has experienced a security incident, nor the first time it has said the affected systems were external to its core networks.

The Space Agency&#39;s online store was hit by attackers last year shortly before the Christmas holiday, with miscreants inserting a fake payment page to nab customer info while unsuspecting users were shopping for space-themed holiday gifts. The ESA, naturally, said it&#39;s not in charge of its own online store.

A trio of ESA domains was compromised in 2015 via an SQL vulnerability, resulting in the theft and leak of information belonging to thousands of subscribers and some ESA staff.

Just a few years prior to that, in 2011, the ESA was also breached, with an attacker publishing administrator, content management, FTP login credentials, and Apache server config files online for all to see. As was the case with this latest incident and last year&#39;s store attack, the ESA said the 2011 breach didn&#39;t affect the Agency&#39;s internal networks.

Fair enough - but this sure feels like a pattern. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-48')">
            <div class="source">The Verge</div>
            <div class="title">LG’s new karaoke-ready party speaker uses AI to remove song vocals</div>
            <div class="meta">2026-01-01</div>
        </div>
        
        <div id="content-48" style="display:none;">
            <h2>LG’s new karaoke-ready party speaker uses AI to remove song vocals</h2>
            <p><strong>The Verge | 2026-01-01</strong></p>
            <a class="original-link" href="https://www.theverge.com/news/852362/lg-xboom-stage-501-karaoke-launch-ces-2026">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The Stage 501 can also adjust the pitch of songs to make them more comfortable to sing.

The Stage 501 can also adjust the pitch of songs to make them more comfortable to sing.

If you buy something from a Verge link, Vox Media may earn a commission. See our ethics statement.

LG is adding a karaoke-focused party speaker to its lineup of Xboom devices, which is built in collaboration with Will.i.am. Announced this week, LG says the Stage 501 speaker comes with an “AI Karaoke Master” that can remove or adjust vocals from “virtually any song,” similar to the Soundcore Rave 3S.

It can also adjust the pitch of the songs to make them more comfortable to sing, and it doesn’t require karaoke-specific audio files to do so, according to LG. Like its predecessor, the Stage 501 features a five-sided design but comes equipped with upgraded dual woofers and full-range drivers that LG claims will deliver richer audio. The swappable 99Wh battery offers up to 25 hours of playback and delivers 160W of power (or up to 220W when plugged in).

There’s the Xboom Blast, too, which is a little smaller than the Stage 501 and is built for outdoor use, featuring edge bumpers and two handles for easy carrying. This speaker also comes with a 99Wh battery for up to 35 hours of playback.

LG has added a couple of compact speakers to its lineup as well: the Xboom Mini and Xboom Rock. With the Mini, you can expect up to 10 hours of playback and IP67 water and dust resistance, while the Rock promises the same battery life with support for Bluetooth Auracast, a feature that allows you to broadcast audio across multiple speakers at once.

All four speakers have an AI-powered feature that analyzes audio and “adjusts EQ settings to bring out melody, rhythm or vocals,” according to LG. The company also says the speakers use AI to adjust built-in lighting based on the song, while the Stage 501 and Blast use a technology called “Space Calibration Pro” to adjust sound quality based on the surrounding environment.

LG hasn’t yet revealed the pricing for these new speakers, but the company says it will launch the new devices this year.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-49')">
            <div class="source">The Verge</div>
            <div class="title">Public domain 2026: Betty Boop, Pluto, and Nancy Drew set free</div>
            <div class="meta">2026-01-01</div>
        </div>
        
        <div id="content-49" style="display:none;">
            <h2>Public domain 2026: Betty Boop, Pluto, and Nancy Drew set free</h2>
            <p><strong>The Verge | 2026-01-01</strong></p>
            <a class="original-link" href="https://www.theverge.com/policy/852332/public-domain-2026-betty-boop-nancy-drew-pluto">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The year 1930 brought about a slew of raunchy films, the debut of Betty Boop, and the first iteration of Disney’s most famous dog.

The year 1930 brought about a slew of raunchy films, the debut of Betty Boop, and the first iteration of Disney’s most famous dog.

Some years ago, I was writing a science fiction short story in which I wanted to incorporate verses from a 1928 song, “Button Up Your Overcoat.” However, when I sold the story, my editor told me that since the song was still copyrighted, it was safer not to include the verses.

If I had written the story today, I could have used them — because the song passed into public domain two years ago.

If you’re looking for songs, books, or movies with content you want to use, you are probably examining which of your favorites are headed for the public domain. This year, copyrighted works created in 1930 (except for sound recordings, where the date is 1925) are now free to reuse and repurpose in the US.

As mentioned in our coverage last year, Duke Law School’s Center for the Study of Public Domain has once again rounded up all the most iconic works that have been freed from the bounds of copyright.

First, as we did last year, let’s look at some of the better-known works entering the public domain this year (you can view the full catalog here):

The year 1930 was a great year for raunchy films not affected by the Hays Code, a set of self-imposed guidelines that stated films should not “lower the moral standard of those who see it.” Though some studios began adopting the code in 1930, it wasn’t strictly enforced until 1934, prohibiting scenes with profanity, criminal activity, and sexual content, as noted by Duke University. In the 1930 film Morocco, for example, Hollywood star Marlene Dietrich wears a tuxedo and kisses another woman — something that wouldn’t be allowed under the Hays Code.

Betty Boop, that indomitable Fleischer flapper, also made her debut in 1930 in the cartoon Dizzy Dishes, so if you want to use clips for your own project, go to it. But be careful — Betty Boop first appeared as a dog — the earrings she later wore started out as dog ears. So it’s that version that is in the public domain, not the latest, more human versions. In the same way, the first appearance of Pluto (or, as he was called then, Rover) in The Picnic is the one that is now available in the public domain.

By the way, if you’re a gamer who wants to play with some of these characters, you might want to enter the Gaming Like It’s 1930 jam. You have until the end of January to enter your digital or analog game — keep in mind that it must contain a work dating from 1930.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-50')">
            <div class="source">The Verge</div>
            <div class="title">Meet the new tech laws of 2026</div>
            <div class="meta">2026-01-01</div>
        </div>
        
        <div id="content-50" style="display:none;">
            <h2>Meet the new tech laws of 2026</h2>
            <p><strong>The Verge | 2026-01-01</strong></p>
            <a class="original-link" href="https://www.theverge.com/policy/851664/new-tech-internet-laws-us-2026-ai-privacy-repair">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Coming into force this year: AI regulations galore, a teen social media lockdown, and “Taylor Swift” laws.

If you buy something from a Verge link, Vox Media may earn a commission. See our ethics statement.

Coming into force this year: AI regulations galore, a teen social media lockdown, and “Taylor Swift” laws.

If you buy something from a Verge link, Vox Media may earn a commission. See our ethics statement.

As usual, 2025 was a year of deep congressional dysfunction in the US. But state legislatures were passing laws that govern everything from AI to social media to the right to repair. Many of these laws, alongside rules passed in past years, take effect in 2026 — either right now or in the coming months.

As of January 1st, Americans should have the right to crypto ATM refunds in Colorado, wide-ranging electronics repairs in Colorado and Washington, and AI system transparency in California, among other things. But a last-minute court ruling offered a reprieve from one high-profile state law: Texas’ App Store-based age verification rule.

For a longer rundown of tech-related regulations that go into force in 2026 — including a major piece of one federal law, the Take It Down Act — read on.

California passed a parcel of AI-related rules last year. The most prominent is SB 53: a transparency law that requires major AI companies to publish safety and security details and protects whistleblowers. It’s a revised version of SB 1047, which Gov. Gavin Newsom vetoed after a heated fight in 2024, and it goes into effect on January 1st, 2026.

Several other bills deal with more specific implementations of AI. Among them is SB 243, one of the first regulations on so-called companion chatbots, requiring them to maintain protocols for preventing suicidal ideation and self-harm, as well as remind known underage users every few hours that the system isn’t human. SB 524, another of the bills, requires law enforcement agencies to “conspicuously” disclose how they use AI.

All this has set up California as a test case for how far state AI laws can push, especially as Donald Trump’s administration aims to ban them altogether. That fight, too, is poised to play out in 2026.

Colorado passed one of the country’s most comprehensive right-to-repair rules in 2024, requiring manufacturers to facilitate repairs on a large swath of electronic devices. That law, HB24-1121, will finally kick in this year. The state is also adding consumer protections to a major fraud vector: cryptocurrency ATMs, which — because they let users convert fiat money into crypto and send it to an anonymous wallet — reportedly helped scammers extract hundreds of millions of dollars from victims this year. SB25-079 requires daily transaction limits for new and existing customers, plus refund options for first-time users who transfer money outside the US — a major signal they might have been sending money because they were duped by a scam.

Idaho joins the long list of states with laws combating strategic lawsuits against public participation, or anti-SLAPP laws, with SB 1001. While this isn’t technically a tech law, SLAPP suits have been a key weapon of tech billionaires like Elon Musk, and limiting them helps prevent what can amount to online censorship. A much-needed federal law remains nowhere to be seen.

Starting this year, Illinois will restrict sharing personal information of public officials at their request. HB 576 covers general assembly members and former members, public defenders, and county clerks, among others, and the covered information includes home addresses, home phone numbers, personal email addresses, and the identity of children under 18. The goal is preventing harassment — an increasingly prominent issue — as officials “administer their public duties.”

Data privacy is another area long neglected by Congress but taken up by states, with highly mixed results. Indiana’s Consumer Data Protection Act aims to provide a “data consumer bill of rights” that includes obtaining, correcting, and deleting personal information a company holds about you. But data privacy and consumer protection groups have denounced the law as toothless — a 2025 privacy report card by PIRG and the Electronic Privacy Information Center (EPIC) gave it an F.

HB 15 is another data privacy framework that failed the 2025 PIRG/EPIC evaluation. Kentucky and Indiana both fall under what that report dubs the “Virginia model”: a framework they allege lets companies “continue collecting whatever data they wanted as long they disclosed it somewhere in a privacy policy,” while making opt-outs onerous.

As with so many regulations, the federal rule banning difficult-to-cancel subscriptions is in legal hell, but some states have been stepping up. Maine is joining them with LD 1642, a rule modeled on the FTC standard — which means, among other things, making companies disclose the terms of subscriptions and offer a cancellation method as simple as the system for signing up.

LB 504 is one of multiple state-level “age-appropriate design” rules — it restricts app features like notifications, in-game purchases, and infinite scrolling for children, aiming to combat compulsive use by stopping “dark patterns” that keep kids online. A similar code was blocked in California, however, so a legal challenge could materialize later this year.

With AB 73, Nevada joins the slew of states trying to curb undisclosed AI-powered electioneering. Its disclosure rules include letting candidates sue if they find themselves starring in unwelcome, unlabeled AI-generated ads.

Oklahoma is broadening the scope of its data breach notification rules with SB 626, including by expanding them to cover biometric data and offering some new safe harbors for avoiding legal damages.

HB 2299 adds AI-generated (or otherwise digitally manipulated) imagery to its ban on nonconsensual sexual imagery — a move seen in nearly every state since 2019. HB 2008 bans data collectors from selling personal information and targeting ads using data from users they know are under 16, while adding a similar all-ages ban for precise geolocation data. And HB 3167 bans the sale of software designed to facilitate ticket-scalping bots, addressing a maddening problem the Federal Trade Commission focused on in 2025 as well.

Rhode Island’s HB 7787, the Rhode Island Data Transparency and Privacy Protection Act, includes rules that require disclosure of how personal information is collected and sold. It rounds out the trifecta of “Virginia model” rules that failed a privacy evaluation and take effect this year.

Mere weeks ago, Texas was set to implement a new form of online age-gating: requiring app stores to check users’ ages and pass that information to app developers. But a district court granted a preliminary injunction blocking SB 2420. The law remains worth watching, however, because Texas will likely appeal to the Fifth Circuit — which is notorious for reversing lower court decisions on internet regulation.

Texas is enacting HB 149, an AI regulatory framework that prohibits using the technology to incite harm, capture biometric identifiers, or discriminate based on characteristics like race and gender or “political viewpoint.” That’s going to be another test of the Trump administration’s plan to repeal state-level AI laws, highlighting a split between state and federal Republicans on AI.

If you’re under 16 years old in Virginia, your screen time may have just been drastically reduced. SB 854 requires social media companies to verify users’ ages and limit younger teens to one hour of use per app per day. A parent can choose to increase or decrease that limit. Like many internet regulations, this one is being challenged in court, so its ultimate fate remains undecided.

Washington passed a pair of right-to-repair laws, HB 1483 and SB 5680, in 2025. As iFixit explains, they require companies to make repair materials available for most consumer electronics, block parts pairing, and provide specific protections for wheelchair users.

The RAISE Act has been touted as a landmark AI law that would require large model developers to follow new safety and transparency rules. But it was significantly stripped down at the last minute, lessening its likely impact. Regardless, it’ll take effect on March 19th, 90 days after being signed late last year.

Michigan is another state getting a new anti-SLAPP law — HB 4045 — as of March 24th. On the same date, it’s effectuating a package of rules known as the “Taylor Swift” bills, targeting ticket bots and modeled on the federal BOTS Act.

The Take It Down Act criminalized AI-generated nonconsensual intimate imagery distribution at a federal level in 2025, a change groups like the Cyber Civil Rights Initiative (CCRI) called long overdue. But in the words of CCRI president Mary Anne Franks, it included a “poison pill” with a broad, ambiguous requirement that online platforms remove such images rapidly, raising concerns about censorship and enforcement. That platform takedown provision came with a one-year enforcement delay that will expire on May 19th — so we’ll soon figure out how effective (or disruptive) it actually is.

Utah’s App Store Accountability Act, SB 142, technically took effect last year. But app stores were given until May 6th of 2026 to start verifying users’ ages with “commercially available methods” and require parental consent if they detect minors. One final piece — letting minors or their parents sue for damages if app stores don’t comply — will take effect on December 31st.

Colorado’s SB 24-205 is a named target of the Trump administration’s war on state AI laws. It requires AI companies to disclose information about high-risk systems, and more specifically, take “reasonable care to protect consumers” from algorithmic discrimination. Originally slated for February, it’s now set to take effect June 30th instead.

HB 1717 is a children’s data privacy rule similar to the federal COPPA law and the proposed COPPA 2.0, barring online services from collecting unnecessary personal data if they’re aimed at minors or know a user is underage. It takes effect July 1st.

Utah’s HB 418, dubbed the Digital Choice Act, aims to make social media networks less sticky by letting you move data between them. A writeup from Harvard’s Ash Center explains the nuances, but broadly, it requires social media companies to implement open protocols that allow users to share personal data across different services. Europe has mandated data portability for years and the results haven’t been revolutionary, but there’s still a chance it could promote more competition on a centralized web. Its enforcement date is also July 1st.

Did you think we were done with California AI laws? Well, a delay pushed back the original January goalpost for SB 942, which requires the government to develop standards for AI detection systems and requires covered providers to make such tools available. Now its first provisions kick in on August 2nd, with additional requirements for companies taking effect in 2027 and 2028. It’s taking on a serious issue, but also an incredibly messy one — and like other rules, it depends on preserving the right to state-level AI laws.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-51')">
            <div class="source">The Verge</div>
            <div class="title">You can’t trust your eyes to tell you what’s real anymore, says the head of Instagram</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-51" style="display:none;">
            <h2>You can’t trust your eyes to tell you what’s real anymore, says the head of Instagram</h2>
            <p><strong>The Verge | 2025-12-31</strong></p>
            <a class="original-link" href="https://www.theverge.com/news/852124/adam-mosseri-ai-images-video-instagram">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Mosseri claims digital camera companies are on the wrong path.

Mosseri claims digital camera companies are on the wrong path.

Instagram boss Adam Mosseri is closing out 2025 with a 20-images-deep dive into what a new era of “infinite synthetic content” means as it all becomes harder and harder to distinguish from reality, and the old, more personal Instagram feed that he says has been “dead” for years. Last year, The Verge’s Sarah Jeong wrote that “...the default assumption about a photo is about to become that it’s faked, because creating realistic and believable fake photos is now trivial to do,” and Mosseri eventually concurs:

For most of my life I could safely assume photographs or videos were largely accurate captures of moments that happened. This is clearly no longer the case and it’s going to take us years to adapt.

We’re going to move from assuming what we see is real by default, to starting with skepticism. Paying attention to who is sharing something and why. This will be uncomfortable - we’re genetically predisposed to believing our eyes.

You can read the full text from his slideshow at the bottom of this post, but according to Mosseri, the evolution required of Instagram and other platforms is that “We need to build the best creative tools. Label AI-generated content and verify authentic content. Surface credibility signals about who’s posting. Continue to improve ranking for originality.”

Our readers and listeners know we’ve spent the last few years discussing the “what is a photo?” apocalypse arriving in the form of AI image editing and generation. Now, as we hurtle into 2026, it feels a little late to lay out a thin list of proposals.

Mosseri’s Instagram-centered view of the whole thing claims that “We like to complain about ‘AI slop,’ but there’s a lot of amazing AI content,” without specifically identifying any of it, or specifically mentioning Meta’s push for AI tools. He claims camera companies are going the wrong way by trying to give everyone the ability to “look like a pro photographer from 2015.”

Instead, he says raw, unflattering images are, temporarily, a signal of reality, until AI is able to copy imperfections too. Then “we’ll need to shift our focus to who says something instead of what is being said,” with fingerprints and cryptographic signing of images from the cameras that took them to ID real media instead of relying on tags and watermarks added to AI.

Mosseri is far from the first tech exec to point toward the same issue. Samsung exec Patrick Chomet took the approach that “actually, there is no such thing as a real picture,” after controversies last year over the Galaxy phones’ approach to Moon photography, and Apple’s Craig Federighi told the WSJ he’s “concerned” about the impact of AI editing. But hey, maybe we’re just another Instagram slideshow or two away from figuring all of this out.

The key risk Instagram faces is that, as the world changes more quickly, the platform fails to keep up. Looking forward to 2026, one major shift: authenticity is becoming infinitely reproducible.

Everything that made creators matter-the ability to be real, to connect, to have a voice that couldn’t be faked-is now accessible to anyone with the right tools. Deepfakes are getting better. Al generates photos and videos indistinguishable from captured media.

Power has shifted from institutions to individuals because the internet made it so anyone with a compelling idea could find an audience. The cost of distributing information is zero.

Individuals, not publishers or brands, established that there’s a significant market for content from people. Trust in institutions is at an all-time low. We’ve turned to self-captured content from creators we trust and admire.

We like to complain about “AI slop,” but there’s a lot of amazing AI content. Even the quality AI content has a look though: too slick, skin too smooth. That will change - we’re going to see more realistic AI content.

Authenticity is becoming a scarce resource, driving more demand for creator content, not less. The bar is shifting from “can you create?” to “can you make something that only you could create?”

Unless you are under 25, you probably think of Instagram as feed of square photos: polished makeup, skin smoothing, and beautiful landscapes. That feed is dead. People stopped sharing personal moments to feed years ago.

The primary way people share now is in DMs: blurry photos and shaky videos of daily experiences. Shoe shots. and unflattering candids.

This raw aesthetic has bled into public content and across artforms.

The camera companies are betting on the wrong aesthetic. They’re competing to make everyone look like a pro photographer from 2015. But in a world where AI can generate flawless imagery, the professional look becomes the tell.

Flattering imagery is cheap to produce and boring to consume.

People want content that feels real. Savvy creators are leaning into unproduced, unflattering images. In a world where everything can be perfected, imperfection becomes a signal.

Rawness isn’t just aesthetic preference anymore — it’s proof. It’s defensive. A way of saying: this is real because it’s imperfect.

Relatively quickly, AI will create any aesthetic you like, including an imperfect one that presents as authentic. At that point we’ll need to shift our focus to who says something instead of what is being said.

For most of my life I could safely assume photographs or videos were largely accurate captures of moments that happened. This is clearly no longer the case and it’s going to take us years to adapt.

We’re going to move from assuming what we see is real by default, to starting with skepticism. Paying attention to who is sharing something and why. This will be uncomfortable - we’re genetically predisposed to believing our eyes.

Platforms like Instagram will do good work identifying AI content, but they’ll get worse at it over time as AI gets better. It will be more practical to fingerprint real media than fake media.

Camera manufacturers will cryptographically sign images at capture, creating a chain of custody.

Labeling is only part of the solution. We need to surface much more

context about the accounts sharing content so people can make informed decisions. Who is behind the account?

In a world of infinite abundance and infinite doubt, the creators who can maintain trust and signal authenticity - by being real, transparent, and consistent - will stand out.

We need to build the best creative tools. Label AI-generated content and verify authentic content. Surface credibility signals about who’s posting. Continue to improve ranking for originality.

Instagram is going to have to evolve in a number of ways, and fast.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-52')">
            <div class="source">The Verge</div>
            <div class="title">Net neutrality was back, until it wasn’t</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-52" style="display:none;">
            <h2>Net neutrality was back, until it wasn’t</h2>
            <p><strong>The Verge | 2025-12-31</strong></p>
            <a class="original-link" href="https://www.theverge.com/report/851629/net-neutrality-fcc-retrospective-2025">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">﻿The FCC is taking an ax to America’s broadband rules, even as some states are stepping up.

﻿The FCC is taking an ax to America’s broadband rules, even as some states are stepping up.

The fight for net neutrality never seems to be truly won or lost.

Federal net neutrality rules have been on and off for the past 15 years. The Federal Communications Commission (FCC) passed the Open Internet Order under President Barack Obama in 2010, prohibiting ISPs from blocking or throttling lawful internet traffic, the baseline rule of net neutrality. Then, at the request of those ISPs, a court blocked its rules. An updated framework was passed by the FCC in 2015, only to be overturned in 2017 under President Donald Trump’s first administration. It seemed poised for a comeback in 2024, but the victory lasted mere months before a court overturned it — kicking off a rough year for the open internet and broadband regulation as a whole.

Rather than fight the court’s ruling against net neutrality, the Trump administration’s FCC has preemptively removed the rules — without a chance for public comment. The move was part of FCC Chairman Brendan Carr’s “Delete, Delete, Delete” initiative, which aims to wipe out “unnecessary” regulations.

ISPs have long described net neutrality rules as onerous. For instance, USTelecom president and CEO Jonathan Spalter claimed the 2024 vote to reinstate the FCC’s net neutrality rules was a “counterproductive, unnecessary, and anti-consumer regulatory distraction.”

However, Matt Wood, vice president of policy and general counsel at the nonprofit Free Press, says in an interview with The Verge that ISPs often feel little financial impact from these rules, and may even already be complying with them. “A lot of cable and phone companies, when they talk to their business people and then go back to investors and to the financial analysts, they’re saying, ‘Yep, this is how we’re doing it anyway.’ So, I think a lot of their complaints about the supposed ‘burdens’ from these rules are really just ideological in nature.”

“A lot of their complaints about the supposed ‘burdens’ from these rules are really just ideological in nature.”

Why bother with regulations if ISPs are already (theoretically) compliant? It comes down to accountability and transparency. Regulations ensure voters, not ISPs, are setting the rules of the road online — otherwise, there’s nothing to stop them from changing their operations down the line.

The FCC’s anti-regulatory agenda for telecoms reaches even further than net neutrality. Chao Jun Liu, senior legislative associate at the nonprofit Electronic Frontier Foundation (EFF), notes the FCC’s recent move to reverse Biden-era telecom cybersecurity rules. Carr’s FCC also rolled back requirements for them to provide “nutrition labels” for their broadband pricing, claiming it was “burdensome” for ISPs to display those details.

“There is very much this theme of, ISPs just want to do whatever they want to do with no limits and nobody telling them how to do it, when to do it, [or] on what timeline,” Liu tells The Verge.

Federal regulations for ISPs seem to be dissolving like wet paper, but luckily they’re not the only line of defense for consumers.

“ISPs just want to do whatever they want to do with no limits and nobody telling them how to do it.”

State legislators took up net neutrality in the late 2010s, after the reversal of the FCC’s 2015 order. California’s 2018 net neutrality law, considered the nation’s gold standard, even includes some policies that were left out of the 2015 federal standards, like banning zero-rating, which allows ISPs to exempt certain apps or services from customers’ data caps. Several other states have adopted similar rules, including Washington, Oregon, Colorado, New Jersey, and Vermont.

The most recent repeal has prompted a new wave of these efforts. Maine passed a bipartisan net neutrality bill in June, without a signature from Gov. Janet Mills. A bill to expand “public utility” net neutrality rules to ISPs was also introduced in Pennsylvania in March. Similar bills were introduced in the New York state Senate and state Assembly this year as well.

ISPs have so far largely shied away from openly offering paid prioritization or conventional “fast lanes,” something supporters of net neutrality attribute at least partly to state-level regulations. “I think that state-level net neutrality laws, and the threat of new ones, has kept some of the worst outcomes in check,” says John Bergmayer, legal director at the nonprofit Public Knowledge, in a statement to The Verge.

This reluctance, however, could be changing. T-Mobile, Verizon, and AT&T all offer network slicing on their 5G networks, allowing certain customers (mainly businesses) to pay for virtual networks with higher speeds — which, while it doesn’t inherently violate net neutrality standards, could lay the groundwork for segmented networks.

State-level laws are the next target on the deregulation chopping block.

State-level laws are also the next target on the deregulation chopping block. In October, the National Telecommunications and Information Administration (NTIA) began a push to pressure states into exempting ISPs from their net neutrality laws in order to be eligible for funding from the Biden-era Broadband Equity, Access, and Deployment (BEAD) Program. In a speech at the Hudson Institute, NTIA administrator Arielle Roth called state-level net neutrality laws “a form of rate regulation,” the practice of determining what companies can charge for their services.

Accusations of rate regulation have become common, but Free Press’s Matt Wood argues that they’re overblown. While BEAD does prohibit rate regulation, state-level net neutrality laws don’t inherently fall under that label. Opponents of net neutrality “characterize any and every consumer safeguard as rate regulation when I don’t think it actually has any legitimate impact on the rates companies can charge for the services they offer in the broadband space,” says Wood.

And, again, this is part of a larger deregulatory agenda. EFF’s Chao Jun Liu pointed out similarities with efforts to leverage BEAD funds against AI regulation, including through a recently signed executive order. These attempts to connect AI regulation and broadband funding are “a new development,” says Liu. “This is very much a Brendan Carr, Trump administration special.”

At a time when broadband expansion remains vital, the Trump administration is threatening much-needed infrastructure funding to attack tech regulation. Unfortunately, despite being a bipartisan program, BEAD is where this debate is currently being played out. As Wood says, “Why are we making broadband deployment, which is pretty popular and pretty bipartisan, into yet another front in these culture wars?”

“Why are we making broadband deployment into yet another front in these culture wars?”

Legal experts have pointed out that Roth and the NTIA don’t necessarily have the authority to preempt state-level net neutrality laws for the sake of BEAD funding. However, it seems likely the debates over those funds will delay BEAD’s rollout even further and, along with it, the program’s mission to expand broadband development, particularly to underserved communities.

So, while the tug-of-war over net neutrality regulations continues, so do issues with broadband access in the US. Internet affordability is a persistent challenge across the country, but especially in rural areas where people often have only one or two providers to choose from. BEAD was intended to help address that issue, but now could get bogged down in debate over AI regulations.

Even in areas with robust internet access, high prices are still a problem, particularly since the Affordable Connectivity Program was shut down almost two years ago. On top of that, the US is experiencing a wave of bills that could roll out widespread age verification rules online, sparking debate about privacy, censorship, and free speech.

All of this — not just the fate of net neutrality — leaves the internet in a perilous state going into 2026.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-53')">
            <div class="source">The Verge</div>
            <div class="title">Leaked video shows the Galaxy S26 Ultra’s new camera island</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-53" style="display:none;">
            <h2>Leaked video shows the Galaxy S26 Ultra’s new camera island</h2>
            <p><strong>The Verge | 2025-12-31</strong></p>
            <a class="original-link" href="https://www.theverge.com/news/851931/samsung-galaxy-236-ultra-video-photo-leak">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">New photos and video seem to confirm previous leaks hinting that the Samsung Galaxy S26 Ultra will sport a new camera bump. OnLeaks posted images of what look like dummy phones on X, following renders it leaked back in September.

We’ve seen a similarly raised island on the Galaxy Z Fold 7, which 9to5Google points out could lead to an annoying wobble when using the device on a table.

More leaked renders in November appeared to show the Galaxy S26 Plus suddenly reappearing — also with a raised camera island — along with speculation it would take the place of a slimmer Edge model. The S26 series is expected to launch in February.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-54')">
            <div class="source">MIT Technology Review</div>
            <div class="title">Why inventing new emotions feels so good</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-54" style="display:none;">
            <h2>Why inventing new emotions feels so good</h2>
            <p><strong>MIT Technology Review | 2025-12-31</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2025/12/31/1129403/new-emotions-online-life-feelings/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">It’s a “complex and subtle emotion that elicits feelings of comfort, serenity, and a gentle sense of floating.” It’s peaceful, but more ephemeral and intangible than contentment. It might be evoked by the sight of a sunset or a moody, low-key album.

If you haven’t ever felt this sensation—or even heard of it—that’s not surprising. A Reddit user named noahjeadie generated it with ChatGPT, along with advice on how to evoke the feeling. With the right essential oils and soundtrack, apparently, you too can feel like “a soft fuzzy draping ghost floating through a lavender suburb.”

Don’t scoff: Researchers say more and more terms for these “neo-­emotions” are showing up online, describing new dimensions and aspects of feeling. Velvetmist was a key example in a journal article about the phenomenon published in July 2025. But most neo-emotions aren’t the inventions of emo artificial intelligences. Humans come up with them, and they’re part of a big change in the way researchers are thinking about feelings, one that emphasizes how people continuously spin out new ones in response to a changing world.

Velvetmist might’ve been a chatbot one-off, but it’s not unique. The sociologist Marci Cottingham—whose 2024 paper got this vein of neo-emotion research started—cites many more new terms in circulation. There’s “Black joy” (Black people celebrating embodied pleasure as a form of political resistance), “trans euphoria” (the joy of having one’s gender identity affirmed and celebrated), “eco-anxiety” (the hovering fear of climate disaster), “hypernormalization” (the surreal pressure to continue performing mundane life and labor under capitalism during a global pandemic or fascist takeover), and the sense of “doom” found in “doomer” (one who is relentlessly pessimistic) or “doomscrolling” (being glued to an endless feed of bad news in an immobilized state combining apathy and dread).

Of course, emotional vocabulary is always evolving. During the Civil War, doctors used the centuries-old term “nostalgia,” combining the Greek words for “returning home”and “pain,” to describe a sometimes fatal set of symptoms suffered by soldiers—a condition we’d probably describe today as post-traumatic stress disorder. Now nostalgia’s meaning has mellowed and faded to a gentle affection for an old cultural product or vanished way of life. And people constantly import emotion words from other cultures when they’re convenient or evocative—like hygge (the Danish word for friendly coziness) or kvell (a Yiddish term for brimming over with happy pride).

Cottingham believes that neo-­emotions are proliferating as people spend more of their lives online. These coinages help us relate to one another and make sense of our experiences, and they get a lot of engagement on social media. So even when a neo-emotion is just a subtle variation on, or combination of, existing feelings, getting super-specific about those feelings helps us reflect and connect with other people. “These are potentially signals that tell us about our place in the world,” she says.

These neo-emotions are part of a paradigm shift in emotion science. For decades, researchers argued that humans all share a set of a half-dozen or so basic emotions. But over the last decade, Lisa Feldman Barrett, a clinical psychologist at Northeastern University, has become one of the most cited scientists in the world for work demonstrating otherwise. By using tools like advanced brain imaging and studying babies and people from relatively isolated cultures, she has concluded there’s no such thing as a basic emotional palette. The way we experience and talk about our feelings is culturally determined. “How do you know what anger and sadness and fear are? Because somebody taught you,” Barrett says.

If there are no true “basic” biological emotions, this puts more emphasis on social and cultural variations in how we interpret our experiences. And these interpretations can change over time. “As a sociologist, we think of all emotions as created,” Cottingham says. Just like any other tool humans make and use, “emotions are a practical resource people are using as they navigate the world.”

Some neo-emotions, like velvetmist, might be mere novelties. Barrett playfully suggests “chiplessness” to describe the combined hunger, frustration, and relief of getting to the bottom of the bag. But others, like eco-anxiety and Black joy, can take on a life of their own and help galvanize social movements.

Both reading about and crafting your own neo-emotions, with or without chatbot assistance, could be surprisingly helpful. Lots of research supports the benefits of emotional granularity. Basically, the more detailed and specific words you can use to describe your emotions, both positive and negative, the better.

Researchers analogize this “emodiversity” to biodiversity or cultural diversity, arguing that a more diverse world is more enriched. It turns out that people who exhibit higher emotional granularity go to the doctor less frequently, spend fewer days hospitalized for illness, and are less likely to drink when stressed, drive recklessly, or smoke cigarettes. And many studies show emodiversity is a skill that, with training, people can develop at any age. Just imagine cruising into this sweet, comforting future. Is the idea giving you a certain dreamy thrill?

Are you sure you’ve never felt velvetmist?

Anya Kamenetz is a freelance education reporter who writes the Substack newsletter The Golden Hour.

The Cybertruck, sycophantic AI, and humanoid robots all made this year’s list of the biggest technology failures.

Unveiled by the buzzy startup Deep, Vanguard will let teams of scientists live and work on the seabed for a week at a time.

We’ll keep following these developments, but this just wasn’t their year. Here’s why.

It’s free and easy to nominate yourself or someone you know—here’s how.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-55')">
            <div class="source">MIT Technology Review</div>
            <div class="title">The ascent of the AI therapist</div>
            <div class="meta">2025-12-30</div>
        </div>
        
        <div id="content-55" style="display:none;">
            <h2>The ascent of the AI therapist</h2>
            <p><strong>MIT Technology Review | 2025-12-30</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2025/12/30/1129392/book-reviews-ai-therapy-mental-health/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">We’re in the midst of a global mental-­health crisis. More than a billion people worldwide suffer from a mental-health condition, according to the World Health Organization. The prevalence of anxiety and depression is growing in many demographics, particularly young people, and suicide is claiming hundreds of thousands of lives globally each year.

Given the clear demand for accessible and affordable mental-health services, it’s no wonder that people have looked to artificial intelligence for possible relief. Millions are already actively seeking therapy from popular chatbots like OpenAI’s ChatGPT and Anthropic’s Claude, or from specialized psychology apps like Wysa and Woebot. On a broader scale, researchers are exploring AI’s potential to monitor and collect behavioral and biometric observations using wearables and smart devices, analyze vast volumes of clinical data for new insights, and assist human mental-health professionals to help prevent burnout.

But so far this largely uncontrolled experiment has produced mixed results. Many people have found solace in chatbots based on large language models (LLMs), and some experts see promise in them as therapists, but other users have been sent into delusional spirals by AI’s hallucinatory whims and breathless sycophancy. Most tragically, multiple families have alleged that chatbots contributed to the suicides of their loved ones, sparking lawsuits against companies responsible for these tools. In October, OpenAI CEO Sam Altman revealed in a blog post that 0.15% of ChatGPT users “have conversations that include explicit indicators of potential suicidal planning or intent.” That’s roughly a million people sharing suicidal ideations with just one of these software systems every week.

The real-world consequences of AI therapy came to a head in unexpected ways in 2025 as we waded through a critical mass of stories about human-chatbot relationships, the flimsiness of guardrails on many LLMs, and the risks of sharing profoundly personal information with products made by corporations that have economic incentives to harvest and monetize such sensitive data.

Several authors anticipated this inflection point. Their timely books are a reminder that while the present feels like a blur of breakthroughs, scandals, and confusion, this disorienting time is rooted in deeper histories of care, technology, and trust.

LLMs have often been described as “black boxes” because nobody knows exactly how they produce their results. The inner workings that guide their outputs are opaque because their algorithms are so complex and their training data is so vast. In mental-health circles, people often describe the human brain as a “black box,” for analogous reasons. Psychology, psychiatry, and related fields must grapple with the impossibility of seeing clearly inside someone else’s head, let alone pinpointing the exact causes of their distress.

These two types of black boxes are now interacting with each other, creating unpredictable feedback loops that may further impede clarity about the origins of people’s mental-­health struggles and the solutions that may be possible. Anxiety about these developments has much to do with the explosive recent advances in AI, but it also revives decades-old warnings from pioneers such as the MIT computer scientist Joseph Weizenbaum, who argued against computerized therapy as early as the 1960s.

Charlotte Blease, a philosopher of medicine, makes the optimist’s case in Dr. Bot: Why Doctors Can Fail Us—and How AI Could Save Lives. Her book broadly explores the possible positive impacts of AI in a range of medical fields. While she remains clear-eyed about the risks, warning that readers who are expecting “a gushing love letter to technology” will be disappointed, she suggests that these models can help relieve patient suffering and medical burnout alike.

“Health systems are crumbling under patient pressure,” Blease writes. “Greater burdens on fewer doctors create the perfect petri dish for errors,” and “with palpable shortages of doctors and increasing waiting times for patients, many of us are profoundly frustrated.”

Blease believes that AI can not only ease medical professionals’ massive workloads but also relieve the tensions that have always existed between some patients and their caregivers. For example, people often don’t seek needed care because they are intimidated or fear judgment from medical professionals; this is especially true if they have mental-health challenges. AI could allow more people to share their concerns, she argues.

But she’s aware that these putative upsides need to be weighed against major drawbacks. For instance, AI therapists can provide inconsistent and even dangerous responses to human users, according to a 2025 study, and they also raise privacy concerns, given that AI companies are currently not bound by the same confidentiality and HIPAA standards as licensed therapists.

While Blease is an expert in this field, her motivation for writing the book is also personal: She has two siblings with an incurable form of muscular dystrophy, one of whom waited decades for a diagnosis. During the writing of her book, she also lost her partner to cancer and her father to dementia within a devastating six-month period. “I witnessed first-hand the sheer brilliance of doctors and the kindness of health professionals,” she writes. “But I also observed how things can go wrong with care.”

A similar tension animates Daniel Oberhaus’s engrossing book The Silicon Shrink: How Artificial Intelligence Made the World an Asylum. Oberhaus starts from a point of tragedy: the loss of his younger sister to suicide. As Oberhaus carried out the “distinctly twenty-first-century mourning process” of sifting through her digital remains, he wondered if technology could have eased the burden of the psychiatric problems that had plagued her since childhood.

“It seemed possible that all of this personal data might have held important clues that her mental health providers could have used to provide more effective treatment,” he writes. “What if algorithms running on my sister’s smartphone or laptop had used that data to understand when she was in distress? Could it have led to a timely intervention that saved her life? Would she have wanted that even if it did?”

This concept of digital phenotyping—in which a person’s digital behavior could be mined for clues about distress or illness—seems elegant in theory. But it may also become problematic if integrated into the field of psychiatric artificial intelligence (PAI), which extends well beyond chatbot therapy.

Oberhaus emphasizes that digital clues could actually exacerbate the existing challenges of modern psychiatry, a discipline that remains fundamentally uncertain about the underlying causes of mental illnesses and disorders. The advent of PAI, he says, is “the logical equivalent of grafting physics onto astrology.” In other words, the data generated by digital phenotyping is as precise as physical measurements of planetary positions, but it is then integrated into a broader framework—in this case, psychiatry—that, like astrology, is based on unreliable assumptions.

Oberhaus, who uses the phrase “swipe psychiatry” to describe the outsourcing of clinical decisions based on behavioral data to LLMs, thinks that this approach cannot escape the fundamental issues facing psychiatry. In fact, it could worsen the problem by causing the skills and judgment of human therapists to atrophy as they grow more dependent on AI systems.

He also uses the asylums of the past—in which institutionalized patients lost their right to freedom, privacy, dignity, and agency over their lives—as a touchstone for a more insidious digital captivity that may spring from PAI. LLM users are already sacrificing privacy by telling chatbots sensitive personal information that companies then mine and monetize, contributing to a new surveillance economy. Freedom and dignity are at stake when complex inner lives are transformed into data streams tailored for AI analysis.

AI therapists could flatten humanity into patterns of prediction, and so sacrifice the intimate, individualized care that is expected of traditional human therapists. “The logic of PAI leads to a future where we may all find ourselves patients in an algorithmic asylum administered by digital wardens,” Oberhaus writes. “In the algorithmic asylum there is no need for bars on the window or white padded rooms because there is no possibility of escape. The asylum is already everywhere—in your homes and offices, schools and hospitals, courtrooms and barracks. Wherever there’s an internet connection, the asylum is waiting.”

Eoin Fullam, a researcher who studies the intersection of technology and mental health, echoes some of the same concerns in Chatbot Therapy: A Critical Analysis of AI Mental Health Treatment. A heady academic primer, the book analyzes the assumptions underlying the automated treatments offered by AI chatbots and the way capitalist incentives could corrupt these kinds of tools.

Fullam observes that the capitalist mentality behind new technologies “often leads to questionable, illegitimate, and illegal business practices in which the customers’ interests are secondary to strategies of market dominance.”

That doesn’t mean that therapy-bot makers “will inevitably conduct nefarious activities contrary to the users’ interests in the pursuit of market dominance,” Fullam writes.

But he notes that the success of AI therapy depends on the inseparable impulses to make money and to heal people. In this logic, exploitation and therapy feed each other: Every digital therapy session generates data, and that data fuels the system that profits as unpaid users seek care. The more effective the therapy seems, the more the cycle entrenches itself, making it harder to distinguish between care and commodification. “The more the users benefit from the app in terms of its therapeutic or any other mental health intervention,” he writes, “the more they undergo exploitation.”

This sense of an economic and psychological ouroboros—the snake that eats its own tail—serves as a central metaphor in Sike, the debut novel from Fred Lunzer, an author with a research background in AI.

Described as a “story of boy meets girl meets AI psychotherapist,” Sike follows Adrian, a young Londoner who makes a living ghostwriting rap lyrics, in his romance with Maquie, a business professional with a knack for spotting lucrative technologies in the beta phase.

The title refers to a splashy commercial AI therapist called Sike, uploaded into smart glasses, that Adrian uses to interrogate his myriad anxieties. “When I signed up to Sike, we set up my dashboard, a wide black panel like an airplane’s cockpit that showed my daily ‘vitals,’” Adrian narrates. “Sike can analyze the way you walk, the way you make eye contact, the stuff you talk about, the stuff you wear, how often you piss, shit, laugh, cry, kiss, lie, whine, and cough.”

In other words, Sike is the ultimate digital phenotyper, constantly and exhaustively analyzing everything in a user’s daily experiences. In a twist, Lunzer chooses to make Sike a luxury product, available only to subscribers who can foot the price tag of £2,000 per month.

Flush with cash from his contributions to a hit song, Adrian comes to rely on Sike as a trusted mediator between his inner and outer worlds. The novel explores the impacts of the app on the wellness of the well-off, following rich people who voluntarily commit themselves to a boutique version of the digital asylum described by Oberhaus.

The only real sense of danger in Sike involves a Japanese torture egg (don’t ask). The novel strangely sidesteps the broader dystopian ripples of its subject matter in favor of drunken conversations at fancy restaurants and elite dinner parties.

The sudden ascent of the AI therapist seems startlingly futuristic, as if it should be unfolding in some later time when the streets scrub themselves and we travel the world through pneumatic tubes.

Sike’s creator is simply “a great guy” in Adrian’s estimation, despite his techno-messianic vision of training the app to soothe the ills of entire nations. It always seems as if a shoe is meant to drop, but in the end, it never does, leaving the reader with a sense of non-resolution.

While Sike is set in the present day, something about the sudden ascent of the AI therapist—­in real life as well as in fiction—seems startlingly futuristic, as if it should be unfolding in some later time when the streets scrub themselves and we travel the world through pneumatic tubes. But this convergence of mental health and artificial intelligence has been in the making for more than half a century. The beloved astronomer Carl Sagan, for example, once imagined a “network of computer psychotherapeutic terminals, something like arrays of large telephone booths” that could address the growing demand for mental-health services.

Oberhaus notes that one of the first incarnations of a trainable neural network, known as the Perceptron, was devised not by a mathematician but by a psychologist named Frank Rosenblatt, at the Cornell Aeronautical Laboratory in 1958. The potential utility of AI in mental health was widely recognized by the 1960s, inspiring early computerized psychotherapists such as the DOCTOR script that ran on the ELIZA chatbot developed by Joseph Weizenbaum, who shows up in all three of the nonfiction books in this article.

Weizenbaum, who died in 2008, was profoundly concerned about the possibility of computerized therapy. “Computers can make psychiatric judgments,” he wrote in his 1976 book Computer Power and Human Reason. “They can flip coins in much more sophisticated ways than can the most patient human being. The point is that they ought not to be given such tasks. They may even be able to arrive at ‘correct’ decisions in some cases—but always and necessarily on bases no human being should be willing to accept.”

It’s a caution worth keeping in mind. As AI therapists arrive at scale, we’re seeing them play out a familiar dynamic: Tools designed with superficially good intentions are enmeshed with systems that can exploit, surveil, and reshape human behavior. In a frenzied attempt to unlock new opportunities for patients in dire need of mental-health support, we may be locking other doors behind them.

Becky Ferreira is a science reporter based in upstate New York and author of First Contact: The Story of Our Obsession with Aliens.

The experimental model won&#39;t compete with the biggest and best, but it could tell us why they behave in weird ways—and how trustworthy they really are.

Four ways to think about this year&#39;s reckoning

They managed to cut the size of the AI reasoning model by more than half—and claim it can now answer politically sensitive questions once off limits in Chinese AI systems.

A conversation with a chatbot can shift people&#39;s political views—but the most persuasive models also spread the most misinformation.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-56')">
            <div class="source">MIT Technology Review</div>
            <div class="title">Bangladesh’s garment-making industry is getting greener</div>
            <div class="meta">2025-12-29</div>
        </div>
        
        <div id="content-56" style="display:none;">
            <h2>Bangladesh’s garment-making industry is getting greener</h2>
            <p><strong>MIT Technology Review | 2025-12-29</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2025/12/29/1129308/bangladesh-garment-sustainability-frugal-factories/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Pollution from textile production—dyes, chemicals, and heavy metals like lead and cadmium—is common in the waters of the Buriganga River as it runs through Dhaka, Bangladesh. It’s among many harms posed by a garment sector that was once synonymous with tragedy: In 2013, the eight-story Rana Plaza factory building collapsed, killing 1,134 people and injuring some 2,500 others.

But things are starting to change. In recent years the country has quietly become an unlikely leader in “frugal” factories that use a combination of resource-efficient technologies to cut waste, conserve water, and build resilience against climate impacts and global supply disruptions. Bangladesh now boasts 268 LEED-certified garment factories—more than any other country. Dye plants are using safer chemicals, tanneries are adopting cleaner tanning methods and treating wastewater, workshops are switching to more efficient LED lighting, and solar panels glint from rooftops. The hundreds of factories along the Buriganga’s banks and elsewhere in Bangladesh are starting to stitch together a new story, woven from greener threads.

In Fakir Eco Knitwears’ LEED Gold–certified factory in Narayanganj, a city near Dhaka, skylights reduce energy consumption from electric lighting by 40%, and AI-driven cutters allow workers to recycle 95% of fabric scraps into new yarns. “We save energy by using daylight, solar power, and rainwater instead of heavy AC and boilers,” says Md. Anisuzzaman, an engineer at the company. “It shows how local resources can make production greener and more sustainable.”

The shift to green factories in Bangladesh is financed through a combination of factory investments, loans from Bangladesh Bank’s Green Transformation Fund, and pressure from international buyers who reward compliance with ongoing orders. One prominent program is the Partnership for Cleaner Textile (PaCT), an initiative run by the World Bank Group’s International Finance Corporation. Launched in 2013, PaCT has worked with more than 450 factories on cleaner production methods. By its count, the effort now saves 35 billion liters of fresh water annually, enough to meet the needs of 1.9 million people.

It’s a good start, but Bangladesh’s $40 billion garment industry still has a long way to go. The shift to environmentalism at the factory level hasn’t translated to improved outcomes for the sector’s 4.4 million workers.

Wage theft and delayed payments are widespread. The minimum wage, some 12,500 taka per month (about $113), is far below the $200 proposed by unions—which has meant frequent strikes and protests over pay, overtime, and job security. “Since Rana Plaza, building safety and factory conditions have improved, but the mindset remains unchanged,” says A.K.M. Ashraf Uddin, executive director of the Bangladesh Labour Foundation, a nonprofit labor rights group. “Profit still comes first, and workers’ freedom of speech is yet to be realized.”

In the worst case, greener industry practices could actually exacerbate inequality. Smaller factories dominate the sector, and they struggle to afford upgrades. But without those upgrades, businesses could find themselves excluded from certain markets. One of those is the European Union, which plans to require companies to address human rights and environmental problems in supply chains starting in 2027. A cleaner Buriganga River mends just a small corner of a vast tapestry of need.

Zakir Hossain Chowdhury is a visual journalist based in Bangladesh.

As early electric cars age out, hundreds of thousands of used batteries are flooding the market, fueling a gray recycling economy even as Beijing and big manufacturers scramble to build a more orderly system.

How AI and renewables are shifting the energy landscape.

Omar Yaghi thinks crystals with gaps that capture moisture could bring technology from “Dune” to the arid parts of Earth.

And why many scientists are freaked out about the first serious for-profit company moving into the solar geoengineering field.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-57')">
            <div class="source">MIT Technology Review</div>
            <div class="title">MIT Technology Review’s most popular stories of 2025</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-57" style="display:none;">
            <h2>MIT Technology Review’s most popular stories of 2025</h2>
            <p><strong>MIT Technology Review | 2025-12-26</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2025/12/26/1130318/mit-technology-review-most-popular-stories-2025/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">It&#39;s been a busy and productive year here at MIT Technology Review. We published magazine issues on power, creativity, innovation, bodies, relationships, and security. We hosted 14 exclusive virtual conversations with our editors and outside experts in our subscriber-only series, Roundtables, and held two events on MIT’s campus. And we published hundreds of articles online, following new developments in computing, climate tech, robotics, and more.

As the year winds down, we wanted to give you a chance to revisit a bit of this work with us. Whether we were covering the red-hot rise of artificial intelligence or the future of biotech, these are some of the stories that resonated the most with our readers.

We did the math on AI’s energy footprint. Here’s the story you haven’t heard.

Understanding AI’s energy use was a huge global conversation in 2025 as hundreds of millions of people began using generative AI tools on a regular basis. Senior reporters James O’Donnell and Casey Crownhart dug into the numbers and published an unprecedented look at AI’s resource demand, down to the level of a single query, to help us know how much energy and water AI may require moving forward.

We’re learning more about what vitamin D does to our bodies

Vitamin D deficiency is widespread, particularly in the winter when there’s less sunlight to drive its production in our bodies. The “sunshine vitamin” is important for bone health, but as senior reporter Jessica Hamzelou reported, recent research is also uncovering surprising new insights into other ways it might influence our bodies, including our immune systems and heart health.

Senior editor Will Douglas Heaven’s expansive look at how to define AI was published in 2024, but it still managed to connect with many readers this year. He lays out why no one can agree on what AI is—and explains why that ambiguity matters, and how it can inform our own critical thinking about this technology.

Ethically sourced “spare” human bodies could revolutionize medicine

In this thought-provoking op-ed, a team of experts at Stanford University argue that creating living human bodies that can’t think, don’t have any awareness, and can’t feel pain could shake up medical research and drug development by providing essential biological materials for testing and transplantation. Recent advances in biotechnology now provide a potential pathway to such “bodyoids,” though plenty of technical challenges and ethical hurdles remain.

It’s surprisingly easy to stumble into a relationship with an AI chatbot

Chatbots were everywhere this year, and reporter Rhiannon Williams chronicled how quickly people can develop bonds with one. That’s all right for some people, she notes, but dangerous for others. Some folks even describe unintentionally forming romantic relationships with chatbots. This is a trend we’ll definitely be keeping an eye on in 2026.

The electric grid is bracing for disruption from more frequent storms and fires, as well as an uncertain policy and regulatory landscape. And in many ways, the publicly owned utility company Lincoln Electric in Nebraska is an ideal lens through which to examine this shift as it works through the challenges of delivering service that’s reliable, affordable, and sustainable.

Exclusive: A record-breaking baby has been born from an embryo that’s over 30 years old

This year saw the birth of the world’s “oldest baby”: Thaddeus Daniel Pierce, who arrived on July 26. The embryo he developed from was created in 1994 during the early days of IVF and had been frozen and sitting in storage ever since. The new baby’s parents were toddlers at the time, and the embryo was donated to them decades later via a Christian “embryo adoption” agency.

How these two brothers became go-to experts on America’s “mystery drone” invasion

Twin brothers John and Gerald Tedesco teamed up to investigate a concerning new threat—unidentified drones. In 2024 alone, some 350 drones entered airspace over a hundred different US military installations, and many cases went unsolved, according to a top military official. This story takes readers inside the equipment-filled RV the Tedescos created to study mysterious aerial phenomena, and how they made a name for themselves among government officials.

Our newsroom has published this annual look at advances that will matter in the long run for over 20 years. This year’s list featured generative AI search, cleaner jet fuel, long-acting HIV prevention meds, and other emerging technologies that our journalists think are worth watching. We’ll publish the 2026 edition of the list on January 12, so stay tuned. (In the meantime, here’s what didn’t make the cut.)

The Cybertruck, sycophantic AI, and humanoid robots all made this year’s list of the biggest technology failures.

Unveiled by the buzzy startup Deep, Vanguard will let teams of scientists live and work on the seabed for a week at a time.

We’ll keep following these developments, but this just wasn’t their year. Here’s why.

It’s free and easy to nominate yourself or someone you know—here’s how.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-58')">
            <div class="source">MIT Technology Review</div>
            <div class="title">The paints, coatings, and chemicals making the world a cooler place</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-58" style="display:none;">
            <h2>The paints, coatings, and chemicals making the world a cooler place</h2>
            <p><strong>MIT Technology Review | 2025-12-26</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2025/12/26/1129301/paint-coating-chemicals-materials-cooling-air-conditioning/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">It’s getting harder to beat the heat. During the summer of 2025, heat waves knocked out power grids in North America, Europe, and the Middle East. Global warming means more people need air-­conditioning, which requires more power and strains grids. But a millennia-old idea (plus 21st-century tech) might offer an answer: radiative cooling. Paints, coatings, and textiles can scatter sunlight and dissipate heat—no additional energy required.

“Radiative cooling is universal—it exists everywhere in our daily life,” says Qiaoqiang Gan, a professor of materials science and applied physics at King Abdullah University of Science and Technology in Saudi Arabia. Pretty much any object will absorb heat from the sun during the day and radiate some of it back at night. It’s why cars parked outside overnight are often covered with condensation, Gan says—their metal roofs dissipate heat into the sky, cooling the surfaces below the ambient air temperature. That’s how you get dew.

Humans have harnessed this basic natural process for thousands of years. Desert peoples in Iran, North Africa, and India manufactured ice by leaving pools of water exposed to clear desert skies overnight, when radiative cooling happens naturally; other cultures constructed “cool roofs” capped with reflective materials that scattered sunlight and lowered interior temperatures. “People have taken advantage of this effect, either knowingly or unknowingly, for a very long time,” says Aaswath Raman, a materials scientist at UCLA and cofounder of the radiative­cooling startup SkyCool Systems.

Modern approaches, as demonstrated everywhere from California supermarket rooftops to Japan’s Expo 2025 pavilion, go even further. Normally, if the sun is up and pumping in heat, surfaces can’t get cooler than the ambient temperature. But back in 2014, Raman and his colleagues achieved radiative cooling in the daytime. They customized photonic films to absorb and then radiate heat at infrared wavelengths between eight and 13 micrometers—a range of electromagnetic wavelengths called an “atmospheric window,” because that radiation escapes to space rather than getting absorbed. Those films could dissipate heat even under full sun, cooling the inside of a building to 9 °F below ambient temperatures, with no AC or energy source required.

That was proof of concept; today, Raman says, the industry has mostly shifted away from advanced photonics that use the atmospheric-window effect to simpler sunlight-scattering materials. Ceramic cool roofs, nanostructure coatings, and reflective polymers all offer the possibility of diverting more sunlight across all wavelengths, and they’re more durable and scalable.

Now the race is on. Startups such as SkyCool, Planck Energies, Spacecool, and i2Cool are competing to commercially manufacture and sell coatings that reflect at least 94% of sunlight in most climates, and above 97% in humid tropical ones. Pilot projects have already provided significant cooling to residential buildings, reducing AC energy needs by 15% to 20% in some cases.

This idea could go way beyond reflective rooftops and roads. Researchers are developing reflective textiles that can be worn by people most at risk of heat exposure. “This is personal thermal management,” says Gan. “We can realize passive cooling in T-shirts, sportswear, and garments.”

Of course, these technologies and materials have limits. Like solar power grids, they’re vulnerable to weather. Clouds prevent reflected sunlight from bouncing into space. Dust and air pollution dim materials’ bright surfaces. Lots of coatings lose their reflectivity after a few years. And the cheapest and toughest materials used in radiative cooling tend to rely on Teflon and other fluoropolymers, “forever chemicals” that don’t biodegrade, posing an environmental risk. “They are the best class of products that tend to survive outdoors,” says Raman. “So for long-term scale-up, can you do it without materials like those fluoropolymers and still maintain the durability and hit this low cost point?”

As with any other solution to the problems of climate change, one size won’t fit all. “We cannot be overoptimistic and say that radiative cooling can address all our future needs,” Gan says. “We still need more efficient active air-conditioning.” A shiny roof isn’t a panacea, but it’s still pretty cool.

Becky Ferreira is a science reporter based in upstate New York and author of First Contact: The Story of Our Obsession with Aliens.

As early electric cars age out, hundreds of thousands of used batteries are flooding the market, fueling a gray recycling economy even as Beijing and big manufacturers scramble to build a more orderly system.

How AI and renewables are shifting the energy landscape.

Omar Yaghi thinks crystals with gaps that capture moisture could bring technology from “Dune” to the arid parts of Earth.

And why many scientists are freaked out about the first serious for-profit company moving into the solar geoengineering field.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-59')">
            <div class="source">MIT Technology Review</div>
            <div class="title">AI Wrapped: The 14 AI terms you couldn’t avoid in 2025</div>
            <div class="meta">2025-12-25</div>
        </div>
        
        <div id="content-59" style="display:none;">
            <h2>AI Wrapped: The 14 AI terms you couldn’t avoid in 2025</h2>
            <p><strong>MIT Technology Review | 2025-12-25</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2025/12/25/1130298/ai-wrapped-the-14-ai-terms-you-couldnt-avoid-in-2025/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">If the past 12 months have taught us anything, it’s that the AI hype train is showing no signs of slowing. It’s hard to believe that at the beginning of the year, DeepSeek had yet to turn the entire industry on its head, Meta was better known for trying (and failing) to make the metaverse cool than for its relentless quest to dominate superintelligence, and vibe coding wasn’t a thing.

If that’s left you feeling a little confused, fear not. As we near the end of 2025, our writers have taken a look back over the AI terms that dominated the year, for better or worse.

Make sure you take the time to brace yourself for what promises to be another bonkers year.

As long as people have been hyping AI, they have been coming up with names for a future, ultra-powerful form of the technology that could bring about utopian or dystopian consequences for humanity. “Superintelligence” is that latest hot term. Meta announced in July that it would form an AI team to pursue superintelligence, and it was reportedly offering nine-figure compensation packages to AI experts from the company’s competitors to join.

In December, Microsoft’s head of AI followed suit, saying the company would be spending big sums, perhaps hundreds of billions, on the pursuit of superintelligence. If you think superintelligence is as vaguely defined as artificial general intelligence, or AGI, you’d be right! While it’s conceivable that these sorts of technologies will be feasible in humanity’s long run, the question is really when, and whether today’s AI is good enough to be treated as a stepping stone toward something like superintelligence. Not that that will stop the hype kings. —James O’Donnell

Thirty years ago, Steve Jobs said everyone in America should learn how to program a computer. Today, people with zero knowledge of how to code can knock up an app, game, or website in no time at all thanks to vibe coding—a catch-all phrase coined by OpenAI cofounder Andrej Karpathy. To vibe-code, you simply prompt generative AI models’ coding assistants to create the digital object of your desire and accept pretty much everything they spit out. Will the result work? Possibly not. Will it be secure? Almost definitely not, but the technique’s biggest champions aren’t letting those minor details stand in their way. Also—it sounds fun! — Rhiannon Williams

One of the biggest AI stories over the past year has been how prolonged interactions with chatbots can cause vulnerable people to experience delusions and, in some extreme cases, can either cause or worsen psychosis. Although “chatbot psychosis” is not a recognized medical term, researchers are paying close attention to the growing anecdotal evidence from users who say it’s happened to them or someone they know. Sadly, the increasing number of lawsuits filed against AI companies by the families of people who died following their conversations with chatbots demonstrate the technology’s potentially deadly consequences. —Rhiannon Williams

Few things kept the AI hype train going this year more than so-called reasoning models, LLMs that can break down a problem into multiple steps and work through them one by one. OpenAI released its first reasoning models, o1 and o3, a year ago.

A month later, the Chinese firm DeepSeek took everyone by surprise with a very fast follow, putting out R1, the first open-source reasoning model. In no time, reasoning models became the industry standard: All major mass-market chatbots now come in flavors backed by this tech. Reasoning models have pushed the envelope of what LLMs can do, matching top human performances in prestigious math and coding competitions. On the flip side, all the buzz about LLMs that could “reason” reignited old debates about how smart LLMs really are and how they really work. Like “artificial intelligence” itself, “reasoning” is technical jargon dressed up with marketing sparkle. Choo choo! —Will Douglas Heaven

For all their uncanny facility with language, LLMs have very little common sense. Put simply, they don’t have any grounding in how the world works. Book learners in the most literal sense, LLMs can wax lyrical about everything under the sun and then fall flat with a howler about how many elephants you could fit into an Olympic swimming pool (exactly one, according to one of Google DeepMind’s LLMs).

World models—a broad church encompassing various technologies—aim to give AI some basic common sense about how stuff in the world actually fits together. In their most vivid form, world models like Google DeepMind’s Genie 3 and Marble, the much-anticipated new tech from Fei-Fei Li’s startup World Labs, can generate detailed and realistic virtual worlds for robots to train in and more. Yann LeCun, Meta’s former chief scientist, is also working on world models. He has been trying to give AI a sense of how the world works for years, by training models to predict what happens next in videos. This year he quit Meta to focus on this approach in a new start up called Advanced Machine Intelligence Labs. If all goes well, world models could be the next thing. —Will Douglas Heaven

Have you heard about all the people saying no thanks, we actually don’t want a giant data center plopped in our backyard? The data centers in question—which tech companies want to built everywhere, including space—are typically referred to as hyperscalers: massive buildings purpose-built for AI operations and used by the likes of OpenAI and Google to build bigger and more powerful AI models. Inside such buildings, the world’s best chips hum away training and fine-tuning models, and they’re built to be modular and grow according to needs.

It’s been a big year for hyperscalers. OpenAI announced, alongside President Donald Trump, its Stargate project, a $500 billion joint venture to pepper the country with the largest data centers ever. But it leaves almost everyone else asking: What exactly do we get out of it? Consumers worry the new data centers will raise their power bills. Such buildings generally struggle to run on renewable energy. And they don’t tend to create all that many jobs. But hey, maybe these massive, windowless buildings could at least give a moody, sci-fi vibe to your community. —James O’Donnell

The lofty promises of AI are levitating the economy. AI companies are raising eye-popping sums of money and watching their valuations soar into the stratosphere. They’re pouring hundreds of billions of dollars into chips and data centers, financed increasingly by debt and eyebrow-raising circular deals. Meanwhile, the companies leading the gold rush, like OpenAI and Anthropic, might not turn a profit for years, if ever. Investors are betting big that AI will usher in a new era of riches, yet no one knows how transformative the technology will actually be.

Most organizations using AI aren’t yet seeing the payoff, and AI work slop is everywhere. There’s scientific uncertainty about whether scaling LLMs will deliver superintelligence or whether new breakthroughs need to pave the way. But unlike their predecessors in the dot-com bubble, AI companies are showing strong revenue growth, and some are even deep-pocketed tech titans like Microsoft, Google, and Meta. Will the manic dream ever burst? —Michelle Kim

This year, AI agents were everywhere. Every new feature announcement, model drop, or security report throughout 2025 was peppered with mentions of them, even though plenty of AI companies and experts disagree on exactly what counts as being truly “agentic,” a vague term if ever there was one. No matter that it’s virtually impossible to guarantee that an AI acting on your behalf out in the wide web will always do exactly what it’s supposed to do—it seems as though agentic AI is here to stay for the foreseeable. Want to sell something? Call it agentic! —Rhiannon Williams

Early this year, DeepSeek unveiled its new model DeepSeek R1, an open-source reasoning model that matches top Western models but costs a fraction of the price. Its launch freaked Silicon Valley out, as many suddenly realized for the first time that huge scale and resources were not necessarily the key to high-level AI models. Nvidia stock plunged by 17% the day after R1 was released.

The key to R1’s success was distillation, a technique that makes AI models more efficient. It works by getting a bigger model to tutor a smaller model: You run the teacher model on a lot of examples and record the answers, and reward the student model as it copies those responses as closely as possible, so that it gains a compressed version of the teacher’s knowledge.  —Caiwei Chen

As people across the world spend increasing amounts of time interacting with chatbots like ChatGPT, chatbot makers are struggling to work out the kind of tone and “personality” the models should adopt. Back in April, OpenAI admitted it’d struck the wrong balance between helpful and sniveling, saying a new update had rendered GPT-4o too sycophantic. Having it suck up to you isn’t just irritating—it can mislead users by reinforcing their incorrect beliefs and spreading misinformation. So consider this your reminder to take everything—yes, everything—LLMs produce with a pinch of salt. —Rhiannon Williams

If there is one AI-related term that has fully escaped the nerd enclosures and entered public consciousness, it’s “slop.” The word itself is old (think pig feed), but “slop” is now commonly used to refer to low-effort, mass-produced content generated by AI, often optimized for online traffic. A lot of people even use it as a shorthand for any AI-generated content. It has felt inescapable in the past year: We have been marinated in it, from fake biographies to shrimp Jesus images to surreal human-animal hybrid videos.

But people are also having fun with it. The term’s sardonic flexibility has made it easy for internet users to slap it on all kinds of words as a suffix to describe anything that lacks substance and is absurdly mediocre: think “work slop” or “friend slop.” As the hype cycle resets, “slop” marks a cultural reckoning about what we trust, what we value as creative labor, and what it means to be surrounded by stuff that was made for engagement rather than expression. —Caiwei Chen

Did you come across the hypnotizing video from earlier this year of a humanoid robot putting away dishes in a bleak, gray-scale kitchen? That pretty much embodies the idea of physical intelligence: the idea that advancements in AI can help robots better move around the physical world.

It’s true that robots have been able to learn new tasks faster than ever before, everywhere from operating rooms to warehouses. Self-driving-car companies have seen improvements in how they simulate the roads, too. That said, it’s still wise to be skeptical that AI has revolutionized the field. Consider, for example, that many robots advertised as butlers in your home are doing the majority of their tasks thanks to remote operators in the Philippines.

The road ahead for physical intelligence is also sure to be weird. Large language models train on text, which is abundant on the internet, but robots learn more from videos of people doing things. That’s why the robot company Figure suggested in September that it would pay people to film themselves in their apartments doing chores. Would you sign up? —James O&#39;Donnell

AI models are trained by devouring millions of words and images across the internet, including copyrighted work by artists and writers. AI companies argue this is “fair use”—a legal doctrine that lets you use copyrighted material without permission if you transform it into something new that doesn’t compete with the original. Courts are starting to weigh in. In June, Anthropic’s training of its AI model Claude on a library of books was ruled fair use because the technology was “exceedingly transformative.”

That same month, Meta scored a similar win, but only because the authors couldn’t show that the company’s literary buffet cut into their paychecks. As copyright battles brew, some creators are cashing in on the feast. In December, Disney signed a splashy deal with OpenAI to let users of Sora, the AI video platform, generate videos featuring more than 200 characters from Disney&#39;s franchises. Meanwhile, governments around the world are rewriting copyright rules for the content-guzzling machines. Is training AI on copyrighted work fair use? As with any billion-dollar legal question, it depends. —Michelle Kim

Just a few short years ago, an entire industry was built around helping websites rank highly in search results (okay, just in Google). Now search engine optimization (SEO), is giving way to GEO—generative engine optimization—as the AI boom forces brands and businesses to scramble to maximize their visibility in AI, whether that’s in AI-enhanced search results like Google’s AI Overviews or within responses from LLMs. It’s no wonder they’re freaked out. We already know that news companies have experienced a colossal drop in search-driven web traffic, and AI companies are working on ways to cut out the middleman and allow their users to visit sites from directly within their platforms. It’s time to adapt or die. —Rhiannon Williams

The experimental model won&#39;t compete with the biggest and best, but it could tell us why they behave in weird ways—and how trustworthy they really are.

Four ways to think about this year&#39;s reckoning

They managed to cut the size of the AI reasoning model by more than half—and claim it can now answer politically sensitive questions once off limits in Chinese AI systems.

A conversation with a chatbot can shift people&#39;s political views—but the most persuasive models also spread the most misinformation.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-60')">
            <div class="source">The Next Web</div>
            <div class="title">A 2025 recap for Tech & AI</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-60" style="display:none;">
            <h2>A 2025 recap for Tech & AI</h2>
            <p><strong>The Next Web | 2025-12-31</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/a-2025-recap-for-tech-ai">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">2025 was the year technology stopped being tomorrow’s promise and became today’s anchor. What began as a surge in generative AI and platform innovation two years prior crystallized this year into concrete shifts in how people work, governing bodies legislate, and markets invest. Across continents and industries, the arc of technology bent toward practical impact, regulatory reality, and economic weight!

At the heart of the year’s story was artificial intelligence’s jump from novelty to infrastructure. LLMs and multimodal models moved beyond demos into everyday workflows, influencing how documents are written, campaigns are conceived, products designed, and code generated.

Enterprises that once hesitated began deploying AI tools at scale, with early adopters reporting measurable productivity gains by integrating copilots into core processes, a trend visible in surveys showing widespread adoption among software professionals.

This editorial isn’t a chronicle of every press release.

The latest rumblings from the EU tech scene, a story from our wise ol&#39; founder Boris, and some questionable AI art. It&#39;s free, every week, in your inbox. Sign up now!

It’s a reflection on how 2025, at the crossroads of technology, governance, and economic strategy, brought about a series of inflection points that will shape the next era of creation, competition, and control.

OpenAI’s release of GPT-5 in August pushed the boundaries of what AI could do, delivering notable gains in coding, math, and multimodal understanding. But unlike the jaw-dropping debut of ChatGPT a couple years prior, this new generation of foundation models arrived to a more measured reception.

Tech leaders and investors had begun asking harder questions: beyond impressive demos, could these models drive real products and revenue?

Google’s answer was Gemini 3, launched in November as its “most intelligent model” and immediately woven into Google’s flagship product, Search. For the first time, an AI model upgrade wasn’t just about boastful leaderboard scores, it was about transforming user experience.

Typing a query into Google now often meant receiving an AI-generated synthesis instead of the familiar list of links, a sea change in how information is delivered. Google even unveiled a Gemini “agent” that could execute multi-step tasks like booking travel or organizing email, hinting at a future where AI acts more like a digital butler than a chatbox.

Anthropic’s Claude 4 model, for instance, gained a strong following among developers by expanding how much it could handle at once, processing entire codebases with tens of thousands of lines, rather than by producing viral one-liners.

AI grew up in 2025: it was still improving at breakneck speed, but it also had to earn its keep in real products and justify the billion-dollar bets fueling its rise.

Driving this AI explosion was a parallel leap in hardware. The hunger for AI computers in 2025 was insatiable, and chipmakers raced to deliver.

NVIDIA, whose GPUs had become the era’s essential infrastructure, rolled out its new Blackwell architecture with chips like the B200 that boasted up to 3× the training speed of its predecessor. Cloud data centers around the world scrambled to deploy these to keep up with demand from model training and inference.

Rival chipmakers weren’t idle either: AMD and a cadre of startups pushed innovative AI accelerators, while even Intel signaled ambitions to catch up, reportedly exploring an acquisition of AI chip designer SambaNova.

Perhaps most tellingly, tech giants themselves started designing silicon tailored for AI workloads, recognizing that owning the chip means owning the future of computing.

Beyond AI chips, consumer hardware saw its own milestones. After years of anticipation, augmented reality glasses and mixed-reality headsets finally had their moment, sort of.

Apple’s Vision Pro headset, unveiled in late 2023, reached select markets in 2024; by 2025 developers were crafting the first wave of immersive apps. However, mass adoption lagged due to the device’s sky-high price and bulky format.

Competitors like Meta’s Quest line offered cheaper VR headsets and modest improvements, but the “metaverse” hype of yesteryear largely fizzled out, users and investors had shifted their excitement to generative AI and tangible productivity tools.

Smartphones and laptops in 2025 continued incremental improvements (faster Apple M3/M4 chips, foldable screens becoming more common), yet it was clear the next paradigm shift in personal tech was still on the horizon.

Even so, one hardware frontier made concrete progress: quantum computing. Industry leaders like IBM and Google demonstrated prototype systems with ever-larger qubit counts and made strides in error correction, inching closer to viable quantum machines.

These advances, while esoteric to the public, underscored a broader theme, from AI accelerators to quantum chips, the machinery under the hood of tech was evolving rapidly to enable the software of tomorrow.

If 2025 proved anything, it’s that technology no longer operates above the law. This was the year regulators moved from intent to enforcement, with Europe leading the charge.

After years of debate, the EU’s Artificial Intelligence Act came into force, becoming the world’s first complex AI law. From February, certain “unacceptable risk” uses, such as social scoring and real-time biometric surveillance, were banned outright.

By August, transparency rules followed, forcing companies to label AI-generated content and comply with new obligations for general-purpose models. The signal was unmistakable: in Europe, the era of unchecked AI was over.

Companies now face audits, penalties, and real consequences if their systems cross legal or ethical lines, a regulatory moment European officials openly compared to GDPR’s impact on data privacy.

The pressure didn’t stop with AI. In 2025, regulators also went after the gatekeepers. The EU’s Digital Markets Act forced long-resistant changes from Big Tech, most notably when Apple opened the iPhone to third-party app stores and sideloading in Europe, dismantling a 15-year walled garden.

At the same time, enforcement of the Digital Services Act intensified. Platforms were scrutinized for how they handle disinformation, with companies like X warned or penalized during periods of geopolitical tension. In response, social networks expanded moderation teams, adjusted algorithms, and exposed more of their inner workings to researchers.

The US issued an AI executive order and signaled tougher enforcement through agencies like the FTC, while states stepped in, including New York’s law requiring mental-health warnings on addictive social features.

In China, new draft rules targeted AI systems designed for human-like interaction, tightening licensing and ideological oversight. By the end of the year, the freewheeling phase of tech disruption had given way to something more restrained. The question was no longer whether regulation would catch up, but how deeply it would reshape innovation itself.

The platform shake-up that began in 2023 gathered real momentum in 2025, as both companies and users adjusted to a post-pandemic, AI-saturated reality.

Nowhere was this clearer than in social media. Elon Musk’s X, which entered the decade with noise and bravado, found itself on the defensive. Meta’s Threads, initially dismissed after an early spike, steadily closed the gap, nearing parity with X in daily mobile users by mid-year.

X’s audience shrank as policy whiplash and leadership churn eroded confidence, and while its remaining users were still deeply engaged, the era of unquestioned Twitter dominance was over. Disenchanted users scattered across a fragmented landscape, from Meta’s polished Threads to decentralized alternatives like Bluesky and Mastodon, breaking the old Facebook–Instagram–Twitter equilibrium.

The recalibration extended well beyond social feeds.

Major platforms retooled around changing habits: Google reshaped Search around generative answers to fend off AI assistants and algorithmic discovery, while Microsoft pushed its Copilot deeper into Windows, Office, and Bing, betting on “AI inside” as a platform reset.

Everyday behavior shifted too. Smarter voice and chat assistants returned to daily use, handling emails, refunds, and scheduling with little friction. At the same time, screen fatigue set in. Digital-detox travel gained traction, and younger users gravitated toward apps that promised less algorithmic pressure and more human curation. Even streaming came full circle.

After years of fragmentation, providers began rebundling services, offering combined video, music, and gaming packages that looked suspiciously like cable TV reborn, a reminder that while technology moves forward, user preferences often move in cycles.

Amid the gains and momentum, 2025 also became a year of reckoning. As AI systems spread, society began grappling with their cultural and ethical cost. Creators who once marveled at generative tools started pushing back, arguing that their work had been absorbed without consent or compensation.

A wave of lawsuits moved through US courts, with authors accusing companies like OpenAI, Meta, and Google of scraping books and articles to train models. By year’s end, the message was unmistakable: if AI is built on human creativity, many believe its rewards can no longer flow in one direction alone.

Public trust in technology was also tested by a rise in malicious uses and misuses. In the financial domain, sophisticated deepfake scams caused real damage. The frequency of such incidents spiked sharply; cybersecurity firms reported a 3000% increase in deepfake-related fraud over two years, and authorities scrambled to educate businesses on new verification practices.

Misinformation continued to be a menace: during elections and conflicts, AI-generated fake images and videos spread on social media, forcing newsrooms to set up rapid-response fact-checking teams.

Encouragingly, 2025 also saw growth in countermeasures, from better deepfake detection algorithms to nascent standards for cryptographic content authentication (the Coalition for Content Provenance, including major publishers and tech platforms, expanded efforts to watermark authentic media).

Still, the information ecosystem remained fraught, as even savvy citizens found it ever harder to tell the truth from fabrication online.

And then there’s the human element: how all this tech is affecting everyday lives and livelihoods. Workplace AI adoption soared this year; tools like Microsoft 365 Copilot and a host of AI assistants became common on office desktops. Studies showed productivity boosts but also raised concerns about workers becoming overly reliant on AI suggestions.

Meanwhile, fears of automation resurfaced in certain sectors, for example, as chatbots took over more customer service and code-generation tools improved, professionals in call centers and junior programming positions wondered about long-term job security.

These anxieties fueled calls for new approaches to education and training, so that the workforce of 2030 will be prepared for more creative, complex tasks that AI can’t easily handle.

Lovable (Stockholm, Sweden) came as one of the most remarkable AI software stories of the year, for me. What began as an open-source project evolved into a commercial platform that lets users build fully functional websites and apps using plain-language prompts, no traditional coding required.

This approach, known in the industry as “vibe coding,” turns ideas into production-ready software simply by describing what you want in natural language.

Lovable’s growth in 2025 was extraordinary by any measure. Eight months after its launch, the company hit over $100 million in annual recurring revenue and raised a $200 million Series A at a roughly $1.8 billion valuation, making it one of Europe’s fastest-growing software startups ever.

By year’s end, Lovable had secured $330 million in Series B funding at about a $6.6 billion valuation, and was rapidly scaling globally.

What makes Lovable meaningful beyond the numbers is what it represents: a shift in how software is built. It demonstrated that AI can democratize development, giving power to non-technical founders, creators, and teams to go from concept to product without traditional engineering barriers.

In an industry long centered on specialized skills and team structures, Lovable’s rise suggested a future where natural language becomes the primary interface to software creation.

On a more hopeful note, 2025 showed signs of a maturing tech culture. Ethical design moved from talking point to practice. Major platforms began experimenting with limits, turning off infinite scroll for teens, adding prompts that nudged users to pause, and treating “time well spent” as a real metric rather than a slogan.

In AI, transparency gained ground. Under pressure from regulators and researchers, companies like OpenAI and Google disclosed more about how their models are trained and where they fall short.

Researchers formed new alliances to share safety techniques, and a second global AI Safety Summit brought dozens of countries together around questions of alignment and control.

None of it amounted to binding rules, but it marked a shift in tone: even the architects of powerful systems openly acknowledged the need for restraint.

Taken together, these moments made 2025 a turning point. For years, technology had surged ahead of the institutions meant to guide it. This year, that gap began to close.

The breakthroughs were real and transformative, but so were the responses to them: laws passed, norms reset, alliances formed. If 2024 was the year the world grasped the power of generative AI, 2025 was the year it began deciding how that power should be used.

The story of technology is no longer just about what can be built, but about how it fits into the lives it shapes, and who gets to decide that fit.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-61')">
            <div class="source">The Next Web</div>
            <div class="title">A New Era for TNW.</div>
            <div class="meta">2025-12-22</div>
        </div>
        
        <div id="content-61" style="display:none;">
            <h2>A New Era for TNW.</h2>
            <p><strong>The Next Web | 2025-12-22</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/a-new-era-for-tnw">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">My name is Alexandru Stan, and this article continues the dialogue I began following the acquisition of TNW.

Following the recent transaction, TNW Spaces remains with the Financial Times, while we continue the mission of the website, the events, and the global community.

We already have a dedicated team at tekpon operating the platform, events, and community initiatives. Our objective is to expand and strengthen the team as TNW accelerates its next chapter.

TNW is already a global media platform with millions of readers. We’re not starting over. We are building forward.

The latest rumblings from the EU tech scene, a story from our wise ol&#39; founder Boris, and some questionable AI art. It&#39;s free, every week, in your inbox. Sign up now!

Technology is entering a decisive stage: AI is reshaping workflows, distribution is shifting, capital is becoming more selective, and founders are expected to demonstrate value rather than potential.

The world doesn’t need more noise.
It needs clarity, execution, and access to trustworthy knowledge and people.

TNW will serve that need through editorial independence, real expertise, and community-built intelligence.

Success for TNW looks like this: more accurate understanding, faster access to verified knowledge, and direct pathways from insight to action.

I’ve been an entrepreneur since 2007, building in B2B SaaS, marketplaces, and scalable systems. I believe deeply in servant leadership. Without people, I am zero.

I lead two private networks grounded in practice rather than theory:

These groups ensure TNW remains rooted in lived experience, informed by operators, not commentators.

Our mission is to build the most trusted European tech media platform with global reach, focused on practical innovation, responsible scaling, and transparency.

We will continue to host events across Europe’s major capitals including Paris, London, Berlin, Amsterdam, and Monaco.

These will not be festivals. We are introducing a concept validated through tekpon events: curated gatherings built for meaningful relationships, deep content, and tangible business outcomes.

In 2026, we return to Amsterdam for a special edition centered on AI among other fields. We will explore technologies and strategies shaping the future of work and business:

The editorial focus remains European, while the audience is global.

AI is not a threat to publishing. It is the infrastructure of the next generation of content and knowledge.

At TNW, we will use AI to accelerate research, enable personalized intelligence, reduce noise and bias, and amplify high-quality human expertise. Technology assists. Human judgment remains central.

Because this moment in Europe matters.
Because founders here are ready to scale responsibly.
Because independent media with integrity is rare.
Because innovation deserves a platform built around people, not hype.

TNW will continue its legacy with a renewed emphasis on contribution, execution, and community built through trust.

If you are building, scaling, or researching the next wave of technology, I invite you to engage with us, contribute insights, and participate in shaping the conversation.

The next era begins now. Let’s shape it together.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-62')">
            <div class="source">The Next Web</div>
            <div class="title">Engineering’s AI reality check</div>
            <div class="meta">2025-12-19</div>
        </div>
        
        <div id="content-62" style="display:none;">
            <h2>Engineering’s AI reality check</h2>
            <p><strong>The Next Web | 2025-12-19</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/engineerings-ai-reality-check">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Most engineering leaders cannot answer the one question their CFO is about to ask: “Can you prove this AI spend is changing outcomes, not just activity?”

Every December, roadmaps get locked, budgets get approved, and board decks are polished until everything looks precise and under control. Underneath, many CTOs and VPs are still working with partial visibility. They have a feel for their teams, but not a reliable view of how work moves through the system, how AI is really changing delivery, or where time and money actually go.

For a while, that was survivable. Experience, pattern recognition, and cheap capital covered the gaps. You could hire around bottlenecks, overstaff critical teams, or quietly pivot away from the messiest parts of the system. Then AI showed up and became the perfect distraction. Pilots, PoCs, Copilot seats, and “AI initiatives” created visible activity and bought time.

In 2026, that grace period ends. Boards and CFOs are shifting from “show me you are experimenting” to “show me measurable impact, this year.” Not because they stopped believing in AI, but because the market no longer rewards vague promises. Every AI dollar will need a traceable path to productivity, quality, or customer value.

TNW City Coworking space - Where your best work happens

A workspace designed for growth, collaboration, and endless networking opportunities in the heart of tech.

If you run engineering, you probably recognise this scene. You present a slide with AI highlights. Adoption is up. Developers say they like the tools. You share a few anecdotes about faster coding and smoother reviews. Then the CFO asks a simple question: “Exactly how is this budget changing output and outcomes?”

What is almost always missing is a clear breakdown of:

So the conversation slips back to learning curves, compounding benefits, and talent attraction. All true, but too soft for a tough budget review. That will not be enough.

AI vendors love task-level numbers. A coding task completed 55 percent faster looks impressive on a slide. But once you zoom out to teams and systems, the picture changes.

Large datasets across thousands of developers show a consistent pattern:

The problem is not the tools. It is the lack of a system for where the “extra” capacity goes.

Most organisations still frame AI productivity in terms of speed: more story points, more tickets, higher deployment frequency. That misses the bigger question:

How much of our engineering capacity goes to net new value versus maintenance, incidents, and rework, and is AI improving that mix?

High-level benchmarks are blunt but helpful. On average, about 45 percent of developer time is spent on maintenance, minor enhancements, and bug fixes rather than on genuinely new, customer-facing work. If AI helps you produce more code inside an unchanged system, you risk:

That is how you end up with impressive local metrics and a leadership team that still feels like engineering is slowing down.

If you want to walk into a 2026 budget conversation with objective evidence, you need to be deliberate about how AI-driven time savings are used. Two moves matter.

AI is already good at boilerplate, tests, documentation, and simple refactors. The trap is treating the saved time as unstructured “extra” capacity that disappears into the noise. Instead:

When teams systematically reduce technical debt and improve tests around critical flows, they cut future incidents and rework. Over a year, that frees more capacity for new work than shaving a few minutes off each ticket ever will.

2. Point AI at the ugly, high-friction work that commonly blows up roadmaps

The biggest productivity wins are not in everyday code generation. They are in:

These activities steal weeks or months of capacity and stall strategic initiatives. Using AI to understand legacy code faster, propose refactoring plans, generate migration scaffolding, and highlight recurring failure patterns can dramatically compress timelines for this work.

In parallel, there is real leverage upstream in the problem space. Teams that reach higher levels of AI adoption report better gains when they:

That reduces wasted builds and focuses effort on changes customers actually care about. The most significant gains do not come from replacing human creativity, but from amplifying it and aiming it at better-defined problems.

DORA metrics are not the enemy. Deployment frequency, lead time, MTTR, and change failure rate remain among the best signals we have for delivery performance. The risk is mistaking them for the whole picture.

Leading organisations are already expanding their scorecard to include:

In 2026, the question in the boardroom will shift from “Are we elite on DORA?” to “How much of our capacity is going into things customers notice, and is AI improving that mix or not?” To answer that cleanly, DORA is necessary but not sufficient. You need a way to connect AI usage, workflow, quality, and business outcomes across the system.

This is where engineering intelligence platforms move from a nice-to-have to mandatory. The organisations that win in 2026 will not do it with one more AI tool or one more disconnected dashboard. They will do it by pulling together data they already have but rarely use in one coherent view:

From there, leaders can answer the questions that actually matter:

Instead of defending AI spend with anecdotes, you walk in with:

That is the difference between “we believe in AI” and “here is how AI changed our delivery engine in measurable ways.”

To be ready for the more complex questions coming next year, use this planning cycle to do four things.

Do this, and you will not just have “AI activity” to show in 2026. You will have a credible, data-backed story from AI spend to business outcomes.

The leaders who thrive next year will not be the ones with the flashiest AI demos or the loudest “AI strategy” slide. They will be the ones who:

Engineering intelligence platforms is a key part of that shift. They give you the complex data to show where time and money go, how AI is really changing delivery, and whether your current pace is sustainable. The shift to data-backed engineering leadership is happening either way.

The gap in 2026 will be between teams still guessing and teams that can prove, in detail, how their engineering organisation works.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-63')">
            <div class="source">The Next Web</div>
            <div class="title">Letter from the Editor-in-Chief</div>
            <div class="meta">2025-12-16</div>
        </div>
        
        <div id="content-63" style="display:none;">
            <h2>Letter from the Editor-in-Chief</h2>
            <p><strong>The Next Web | 2025-12-16</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/letter-from-the-editor-in-chief">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Not long ago, like many of you, I read what I feared might be The Next Web’s final article. In late September, TNW’s co-founder announced that the tech conference and news site would be winding down, no more events, no new stories. It felt like the end of an era; the news hit hard!

Yet, just a few weeks ago, a twist arrived: the tech platform Tekpon acquired 100% of TNW’s media and events brand from the Financial Times, ensuring that this nearly two-decade legacy will continue to thrive.

While, myself, trying to read people’s opinions on this topic, I read this comment in one article, from one former TNW editor-in-chief that said: “The Next Web shaped my career, my life… it’s very sad to see it die”.

TNW City Coworking space - Where your best work happens

A workspace designed for growth, collaboration, and endless networking opportunities in the heart of tech.

I asked myself: Why do we always assume that just because one chapter ends, the whole story is over? Yes, taking over TNW is a heavy inheritance, especially with all eyes on us and expectations sky-high.

And I’ll admit, doubts crept in: Am I too small for this? Could someone more experienced do it better? Probably. But here I am, stepping up regardless. Because this isn’t just another blog or brand; TNW is a living ecosystem, a vital community. Its story deserves to continue, and I’m determined to help write the next chapter.

I also know some of you might be wondering: Who is she? What does she know? How many articles has she written? What recommends her?

Before reading all sorts of titles and, let me briefly introduce myself.

I’ve been writing since high school, with thousands of articles under my belt; covering everything from culture, art, and hip hop to design, politics, history, and food. I landed my first content writer job at 18, and alongside writing I pursued another passion: becoming a chef.

(Fun fact: I even made it to the semifinals of MasterChef, a journey that taught me about creativity under pressure and staying cool when the heat is on.)

Now, I channel my storytelling skills into helping businesses better understand technology and use it to their advantage. I help companies tell their stories, the real ones, finding meaning and flow in every word.

Over the years, I’ve specialized in blending creative storytelling with the technical precision of a chef’s knife. (My colleagues at Tekpon might say I can be as sharp as that knife – true to my values and quick to cut through the nonsense.) I am also the “No, we have to do it right” person in the team.

I’ve reviewed countless software products, interviewed founders, and explored how digital innovation can be a force for good in society. Or not. In other words, I’ve always cared about the why behind the tech, the real impact on people’s lives, not just the buzz. That perspective will be behind every story we will publish at TNW.

If there’s a place for those who still think stories written by humans matter, tell me where it is. I’m already on my way.

I’m not here to change TNW’s DNA; I’m here to reinforce it with fresh energy and a clear vision for the future.

To the loyal TNW readers, to the startup founders who looked to us for inspiration, to the healthy tech skeptics who counted on us for a reality check, and to our global audience spread across continents: we hear you.

We all know the world of tech news has changed dramatically. Today, everyone has a megaphone, social media overflows with hot takes, and AI algorithms can crank out content in seconds. It’s easy to feel overwhelmed by this sea of opinions and auto-generated articles. In such a world, the role of a publication like TNW is more critical than ever: to be a filter, not just another firehose of content.

We will focus on curation and clarity, distilling the noise so you don’t have to.

Here’s the good news: despite the deluge of AI-written text out there, readers are actively looking for authentic, human journalism. Every article we will publish will be created by a human writer who is accountable for the facts and who brings context, analysis, and yes, a bit of personality too.

Our mission isn’t to chase every trending headline algorithmically; it’s to help you understand which innovations actually matter, and why.

If a story is everywhere but lacks substance, we won’t regurgitate it; we’ll analyze it or debunk it. If a breakthrough is genuinely promising, we’ll explain why it’s important and how it impacts real people. Being a thoughtful filter in this age of information overload (and AI-generated noise) isn’t just a catchy slogan for us; it’s a responsibility we embrace.

You’ll also notice something different in our approach: an emphasis on storytelling and the human side of tech. Technology doesn’t exist in a vacuum; it’s built and used by people with dreams, dilemmas, and diverse backgrounds.

I believe, and I suspect many of you do too, that the best tech journalism zooms out from the gadgets and code to highlight those human stories. Practically speaking, expect to see more features, interviews, and narrative-driven pieces on TNW.

We’ll talk to founders about the messy, human journey of building a startup, not just the press releases or funding announcements. We’ll spotlight the engineers, designers, and thinkers who are trying to solve big problems (or even small ones that make a big difference). We’ll explore tech’s impact on society: the good, the bad, and the complicated.

This won’t be a place for recycled press releases or surface-level takes. It will be a place for conversation and insight.

Importantly, none of this focus on storytelling means we’ll skimp on rigor. Being engaging doesn’t mean sacrificing accuracy or depth. My team will continue to prioritize thorough research and fact-checking, those good old-school journalism values, even as we experiment with new formats and new voices. In short, we won’t publish anything we wouldn’t want to read ourselves.

Today, looking forward means acknowledging that how we cover tech is as important as what we cover. It means committing to journalism that cuts through the clutter, to storytelling that puts people first, and to a vision of tech’s future that is both hopeful and honest. That’s my vision for TNW as I step into this role, and I hope it resonates with you.

Now, I’d like to turn it over to you, our community. This is your TNW as much as it is ours. I invite you to join the conversation. Tell us what you want to see more of (or less of). Hold us accountable,if we ever fall short, let us know. Share your stories and perspectives with us, because they can inspire our coverage.

In the coming weeks, you’ll start to see this vision take shape on the site. You’ll see familiar faces and new voices. You’ll find articles that make you think, others that make you smile, and hopefully quite a few that make you proud to be a TNW reader.

Whether you’re a long-time follower who’s stuck with us through thick and thin, a startup founder looking for insight, a skeptic keeping us honest, or a curious mind tuning in from anywhere in the world – thank you. We do this for you, and we couldn’t do it without you.

The Next Web is back. We’re here to inform you, inspire you, challenge you, and occasionally even surprise you. I’m honored to have you with us on this journey. Here’s to the road ahead, to storytelling, to journalism (the real kind), and to making sense of the future together.

Thank you for reading, and welcome to TNW’s next chapter. Let’s build it, day by day, story by story, together.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-64')">
            <div class="source">The Next Web</div>
            <div class="title">Is ChatGPT’s New Shopping Research Solving a Problem, or Creating One?</div>
            <div class="meta">2025-12-11</div>
        </div>
        
        <div id="content-64" style="display:none;">
            <h2>Is ChatGPT’s New Shopping Research Solving a Problem, or Creating One?</h2>
            <p><strong>The Next Web | 2025-12-11</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/is-chatgpts-new-shopping-research-solving-a-problem-or-creating-one">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">When OpenAI announced its new shopping search capabilities, I took the news with a grain of salt (perhaps the whole shaker).
For the past decade, we have watched the slow evolution of traditional search engines. What began as tools for pure information discovery gradually morphed into ecosystems dominated by SEO-optimized content and sponsored results. My initial fear with ChatGPT’s update was simple: Are we seeing the beginning of a similar shift? Is the purity of the “reasoning engine” being diluted by the necessity of commerce?
After testing the new shopping integration, the results suggest that we are at a pivotal moment in the user experience of Generative AI, one that requires an open discussion about what we actually want these tools to be.

The defining characteristic of Large Language Models (LLMs) is their ability to handle nuance. When we interact with ChatGPT, we expect a Socratic dialogue. We expect the AI to ask clarifying questions to narrow down our intent.
To test this, I entered a simple prompt: “I want to buy a vacuum.”
I anticipated a conversation, questions about my home’s square footage, my floor type, or my budget. Instead, the conversational nuance was replaced by a display that felt familiar: a grid of product photos, names, prices, and direct links to retailers.

While efficient, this experience felt like a regression. It mirrored the “keyword search” experience of Web 2.0 rather than the “intent-based” promise of GenAI. It replied to my prompt, but it stripped away the intelligence.

The latest rumblings from the EU tech scene, a story from our wise ol&#39; founder Boris, and some questionable AI art. It&#39;s free, every week, in your inbox. Sign up now!

Scrolling down, I engaged with the new feature in a call to action: “Research the best vacuums.”
This is where the user experience (UX) friction became most apparent. Rather than synthesizing data or comparing technical specifications in a chat format, the tool presented a polling interface designed to filter results.

The experience is oddly time-sensitive; pause too long to think or drink water, and the screens will skip forward, dumping you back into a list of product cards.
The interface presents products with a binary choice: “More like this” or “Not interested.” It offers brand names and price tags, but virtually no information to help the user actually make a choice.

For a user seeking genuine research, being presented with a list of brands and prices without deep comparative analysis feels like a missed opportunity.
It raises a question: If I wanted to filter products by price and brand, wouldn’t I use a traditional retailer? The value proposition of Gen AI should be synthesis, not just aggregation.

The Tension Between Reasoning and Revenue
This update highlights the inevitable tension facing major AI companies: the balance between user utility and business sustainability.
As OpenAI scales, the pressure to demonstrate revenue models to investors is natural. However, there is a risk in prioritizing transactional features before the core product, reasoning and logic, is fully matured. By introducing a shopping experience that feels closer to a “click-through” engine than a “knowledge” engine, the platform risks blurring its own identity.
Is ChatGPT a research partner that helps me think? Or is it a shopping assistant trying to speed me to checkout?

To be clear, I believe there is a place for shopping within AI. But the execution matters.
A truly Generative AI shopping experience shouldn’t just list products; it should understand the user. It should read between the lines of a prompt to understand that a user asking for a vacuum might actually be solving a problem about pet hair or allergies.

The current iteration feels like a beta test of a business model rather than an evolution of intelligence. As we move forward, the hope is that OpenAI will refine this tool to prioritize the “Chat” over the transaction. We don’t want it to be just another place to see ads. We need a better way to make decisions.

Viviane Mendes is a growth strategist and innovation leader with more than 20 years of experience driving technology-enabled transformation across global markets. She has led initiatives integrating AI-driven strategies, digital transformation, and scalable business innovation for companies such as PSINet, MP3.com, Match.com, UOL and Best Buy Canada, and founded Vitrinepix, one of the first print-on-demand e-commerce platform, later acquired by Spreadshirt. Committed to lifelong learning, Viviane is now focusing on applying emerging technologies to foster digital literacy, responsible AI adoption, and positive human impact.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-65')">
            <div class="source">The Next Web</div>
            <div class="title">Tekpon acquires TNW (The Next Web) brand from The Financial Times</div>
            <div class="meta">2025-12-08</div>
        </div>
        
        <div id="content-65" style="display:none;">
            <h2>Tekpon acquires TNW (The Next Web) brand from The Financial Times</h2>
            <p><strong>The Next Web | 2025-12-08</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/tekpon-acquires-tnw-the-next-web-brand-from-the-financial-times">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Tekpon has acquired 100% of the TNW media and events brands, which cover and convene the European technology ecosystem, from the FT.

The transaction is Tekpon’s largest investment in media and events so far. It broadens the company’s reach across SaaS and AI and strengthens its role in the global innovation landscape.

TNW’s brand and editorial standards will be maintained, while its events and digital platforms will be integrated into Tekpon’s wider strategy.

The FT will continue to own and operate TNW Spaces, Amsterdam’s dynamic tech hub, offering private offices and coworking spaces that support a thriving community of startups, scale-ups, and innovators.

TNW City Coworking space - Where your best work happens

A workspace designed for growth, collaboration, and endless networking opportunities in the heart of tech.

Alexandru Stan, Founder and CEO of Tekpon, said:

TNW is one of Europe’s most respected technology brands. Its legacy, its community, and its influence have shaped the European tech scene for nearly twenty years. This acquisition accelerates our mission to connect the global SaaS and AI ecosystem and supports Europe’s position in the next decade of innovation.

Tekpon will begin working on TNW branded initiatives immediately. Plans for 2026 include an expanded TNW Conference, new SaaS and AI program tracks curated by Tekpon, cross-regional executive programmes, and specialised gatherings for founders, executives, and investors.

The acquisition is part of Tekpon’s long-term plan to build an international ecosystem connecting software, media, events, advisory, and innovation.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-66')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">New Year party at Swiss ski resort turned into a disaster zone - Reuters</div>
            <div class="meta">2026-01-01</div>
        </div>
        
        <div id="content-66" style="display:none;">
            <h2>New Year party at Swiss ski resort turned into a disaster zone - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2026-01-01</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiqgFBVV95cUxNQ0NsVUd6X2tYczU5VWhuMjJDU2ptZjg1ZnVRNlhHal9sWDhpRXdkai1yMHc1bGgwVGY3eHRZNFFQZnFSOUVJc05ic0Q0VkxoZ2RSY0ZucFRoVVVKQWJjUUJ1Z2FaQ213Z3JUdzF6bjZMQ2F0S1VoQTJiR2FHc2xXMkVBTGtWVGhiQ0xTeGQ5SUx4QVJ4U25BdWhiamUxREVxUnZyaEV4X0pBZw?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-67')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">Russia and Ukraine trade allegations of civilian attacks on New Year's day - Reuters</div>
            <div class="meta">2026-01-01</div>
        </div>
        
        <div id="content-67" style="display:none;">
            <h2>Russia and Ukraine trade allegations of civilian attacks on New Year's day - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2026-01-01</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMisgFBVV95cUxNd204VUVDLVhsQ3dBTTBzMVBOTlVJbEgyU05mcW1sSVh2Q3RpVi1RMDRqcmtTUEtPT2xYeGcwS0VkTGFER1lxNDlRZXZIZTNralJfT2tDQnRnVjNLdzBpOWhrS3g2b29BbXprVG91NWtobVp5Y1NQbkYxenVmeEduOGZsVFZMNmI5OF9uOGdlQmRDdG1ibXdJQktjdmhjN0c5dS1fVFdPYTJKMXpaR0NzclZB?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-68')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">Yemen’s Aden airport shuts as Saudi-UAE rift deepens - Reuters</div>
            <div class="meta">2026-01-01</div>
        </div>
        
        <div id="content-68" style="display:none;">
            <h2>Yemen’s Aden airport shuts as Saudi-UAE rift deepens - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2026-01-01</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMipAFBVV95cUxPeGc3LTdtd21wYUk2N0VQeUstYUd5cUZ5bzBPbXh6cE96X1JOR29YdlpFR2swbE5xdllKSVlnQ1dIS3p6ejVCYzZHNzd5akFVY056NEN0WUJwdXRvaVpTSmQwNTJzNlk0Mmxzd19MeGVBWnRwbFEyX2VnLUdMT216cmRVOVNtM0hUTTBmbjc5N2NOQ3BvSE5FMXNEQnR2NF90Z3YwZQ?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-69')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">Trump tells WSJ he is taking more aspirin than doctors recommend - Reuters</div>
            <div class="meta">2026-01-01</div>
        </div>
        
        <div id="content-69" style="display:none;">
            <h2>Trump tells WSJ he is taking more aspirin than doctors recommend - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2026-01-01</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMirgFBVV95cUxPTGV0QVd6ZUtXVndkWHNWU0ZmbHpyNUlqTVJnWjY1UWhjd1g5TmUxN0dXQTROeXV5YjVaeWp3MnR2cVdSUGhEVWlETzg0YVhfZ2JjdGJISUxfVWsweEtaTDVTdVpoX2ZUR2o2ZWxXa3FxWmZGOWVsSTE2NEdUZDRSSEQ2bUxuRGE5RG9LWk9Sbm5yeHkwWTVIQk9seEtMQXV2VTdKYVQzeDdJUG1ZV0E?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-70')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">Three killed, 7 missing in New Year's Eve attack on informal miners in Peru - Reuters</div>
            <div class="meta">2026-01-01</div>
        </div>
        
        <div id="content-70" style="display:none;">
            <h2>Three killed, 7 missing in New Year's Eve attack on informal miners in Peru - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2026-01-01</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMitgFBVV95cUxOQUswN3RtMDJOb1NBNVRZdHItSG9Gck1HRHdXRWtNYVdQVDhkQUlZNWJRU1BPS1JTa21oeWpUNk9oUDZoaEVJcTZHYUUtdEE0VkNWVHd1aFlyVU16UTRaM0ZBVTRrclAzMkEtdlF1T0xTY0ZmSjNwazRLeXNqTzg4TGxpanh3N2ZWUnpkS0psdDZWUExkSnoyM2tYQUNWd1lONXM5dWtCaXMxTEFCeHhkNEt5bm1WZw?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-71')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">India's KFC, Pizza Hut operators to merge in $934 million deal - Reuters</div>
            <div class="meta">2026-01-01</div>
        </div>
        
        <div id="content-71" style="display:none;">
            <h2>India's KFC, Pizza Hut operators to merge in $934 million deal - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2026-01-01</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiwgFBVV95cUxQQmxDVW1fbm5VSVhhOWRPM2hCUzBqZWVtRUNwdXJTRkJ6NGFDVm1uejRpOVBaOEVEalRTZmhIaExWRnFBYTJZRjJudTlVckYyMlVKUzg3LXlzVWltMmxMenNDUmlESlRDNGJlVHR4VkljMzVYUTlESDg1My10OEY5NWNlODhIMk01M2F2SXNaQ0owNkx1S3ltelFpRms2azhTNFp3cnJuaThtRFIzZkFIc0QyU1JmX0FKWDVFdEZ0Q3dmQQ?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-72')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">A New Theory Suggests Mass May Emerge From Invisible Dimensions - The Debrief</div>
            <div class="meta">2025-12-23</div>
        </div>
        
        <div id="content-72" style="display:none;">
            <h2>A New Theory Suggests Mass May Emerge From Invisible Dimensions - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2025-12-23</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMikAFBVV95cUxPTFNSQWZDVm5jTkRTaTNMb3p2Y2dGcnZ5bHFnRHhDcGZHT3M0VzZWZzcyNEpiZ284QUowZjhaYkFwTU8zRHdLSUlCY0ZXd2NpRnRDZ2JwOFBQNi1oWHZsZzBoM25iak5rTlhMc0wxSmhXbUh3NmdIQ2FRd2I0blVHamVJckY1V2NCbWVnMjRScXg?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-73')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">“Cosmics” and “Phantoms”: Ukrainian Independent Study Reveals Observations of Unidentified Aerial Phenomena - The Debrief</div>
            <div class="meta">2022-08-26</div>
        </div>
        
        <div id="content-73" style="display:none;">
            <h2>“Cosmics” and “Phantoms”: Ukrainian Independent Study Reveals Observations of Unidentified Aerial Phenomena - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2022-08-26</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMixAFBVV95cUxOWWZHN3JWVE42ZlI4eTRKUnVIX0h0MlAwM25SMFExVlRGVThjNVdicEF3dnNHUXd2VjBGTU5fVE5SUnBTU2hKNUk2MmNjaXVzZnhKTFZDeEp3elV0RGRsVnk3cHdCbDZySld1eFNqOEoyQVh0YU81cXJOeTRSZ3MxZ281RHlTdE1SR2JKOXVMYXFGZm5EX3lVZ2tsaEo1bEYxTU5pWmVYSlJlMjl3S1hxRG1BLW9qRGJSaTItbXl3MDlWVUZT?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-74')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">Science of Consciousness: The Most Intriguing Discoveries in 2025 Involving Neuroscience and the Mind - The Debrief</div>
            <div class="meta">2025-12-28</div>
        </div>
        
        <div id="content-74" style="display:none;">
            <h2>Science of Consciousness: The Most Intriguing Discoveries in 2025 Involving Neuroscience and the Mind - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2025-12-28</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiwgFBVV95cUxPUGJnOXJuV0VmaDZfU0VTdHJqdm04ZThnTzhaSXJiSzdYT3k5cnRPdHE2ampJSjBfN2VmelhjYXVfWHdmcmJSd0FjNFljWU5xU1I4Y2xKMzlrMWhSWW5wc1QxMjR4LWFxcGg0bHNSclVyaS0zbkl1dzBFZ09CdWtOUWpfdmZ1YmQ2dERQWnBQTGp3NzBVUVFHUmNfRWsweU9uU2VyMXduSThlUmdudk9RWmt6NmdWYjhBYlc5N0YzTnYtUQ?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-75')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">A Robot Vanished, Then Mysteriously Reappeared Near Antarctica—Now Researchers Reveal What It Discovered While It Was Missing - The Debrief</div>
            <div class="meta">2025-12-23</div>
        </div>
        
        <div id="content-75" style="display:none;">
            <h2>A Robot Vanished, Then Mysteriously Reappeared Near Antarctica—Now Researchers Reveal What It Discovered While It Was Missing - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2025-12-23</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMi4gFBVV95cUxNQmp2ZEdyaGk5elg2aThfWU5NbnVvSnlVYkJkaGNKRzNjLUtmalZoMmk0Z0JIeF9OLVJXUVBNTXhJLTR1TlFpWmRBUTc2U1NSVVJ4YkxSdlg4Y3RBc3hFdzBHelhEaVBISjVOSzlnQ19lYUxrYUVDVTh1NEtCSkY3YWN1VVFGdUdqVV9PZmduWFhoektxUDFPZ0xqNnM3ZEJiSWp1LTQwa0o1UUpiYTczUWwzYWNiZFZ4ZlhYZmFrQ00zZm5nVjJmRVJ6aFFuSjlaUlJXb18td0VFdWVFMEN4NUxR?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-76')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">Has The Mystery of 'The Bayeux Tapestry' Been Solved? How a Medieval Illustration May Have Misled Scholars For Centuries - The Debrief</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-76" style="display:none;">
            <h2>Has The Mystery of 'The Bayeux Tapestry' Been Solved? How a Medieval Illustration May Have Misled Scholars For Centuries - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2025-12-31</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMi2AFBVV95cUxNVHRqOTd6enI5eG1tQ1ZwancyNTNfRTVIc21pR1kwYWZjek9UZDhRLXNWV0RrbExLZ2Z2Vi1ZdEs5dGJiYVhrS0kwVHYxS2J5QTRQZFlZQThscHNZaGlJb3ZVaUhkX3M4Y1YwQzQxZzQzMXZfc2drSndLekEwYnRMNTNYZGNUQXFfbll1UVJ3MXVHZGI1OF9xM1Fxc3F6Q2I0UlAxYW81cmNTdWdJSUpkSnBQQkJuOFpVT0NzalZDbzRBMU1lcF9henJxNElqcFFnVU16TVptM2g?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-77')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">Science of Tomorrow: The Top Discoveries in 2025 That Are Pushing the Boundaries of Science - The Debrief</div>
            <div class="meta">2025-12-29</div>
        </div>
        
        <div id="content-77" style="display:none;">
            <h2>Science of Tomorrow: The Top Discoveries in 2025 That Are Pushing the Boundaries of Science - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2025-12-29</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMitAFBVV95cUxOU2VqWFVhZk5DcDRLTzJ4SXBzbG5Da2NkN0M5bUF1U0ZBMkc5ZXNMaUNoTGRwendPSUdJYXVReERGY2FwUFk2R2hkQ2w0SVoxZ0JwU2toVE5YeFhHUGlWdTFuSnJzNURDTkJyMEhZR2hTanFVeHM3YXZraUFqTVRyakZHQ2t0Ri1pZTIwdHB5UnhjNDhxbzdfTmI0UDZJU1M2LXVaTHJYdVZQeXNBdmVUVlJtYkI?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-78')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">How Artificial Intelligence Will Change in 2026 - The Information</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-78" style="display:none;">
            <h2>How Artificial Intelligence Will Change in 2026 - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2025-12-31</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMihwFBVV95cUxQaTItNzVoaDhhQjY1YlQxQkpQRDhmMWgzV0VSUml4YTE5SjBxVmJ3V0pOWWdSbGtxTHBVczd2SjFLQlpOZ2RHZEp2QmJpMVAzYjBETnBtQk9HN0hvdV9KbFlUQmEtaUVEUHJsMGxZU3loUXJWdGZuZDVwVVNPSkRLbjFPT05XRWs?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-79')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">Stablecoin Startups Spark Trouble for JPMorgan - The Information</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-79" style="display:none;">
            <h2>Stablecoin Startups Spark Trouble for JPMorgan - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2025-12-26</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiigFBVV95cUxNLTJjWk8xckZBR0NMZ2pzbW9MYWg2aVNLQldSRU53cmFKaWJic2xSMjUzSERkbXZTSXI4eTdLclhCWFRXMzhGNmVtaHl3TW0wN1lQdDdsbllqUnZkdFpYS2luelUxNzRpNlEzRWNtSEFDT3p1V29EazU2Zmg2VlRZVEJ3cndyZ0lKQWc?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-80')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">The Long Game Behind Waymo’s Potential $100 Billion Valuation - The Information</div>
            <div class="meta">2025-12-29</div>
        </div>
        
        <div id="content-80" style="display:none;">
            <h2>The Long Game Behind Waymo’s Potential $100 Billion Valuation - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2025-12-29</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMimwFBVV95cUxPYlVMeFhNcjRoTzNZMm5sckp6Z3o4b3NpSzZoV0ktNzdzc2E2U2FyMWYwYmNoRUVxREo2U1UxVVptWl9veHZ4cVJQYUxhTmpFVE5xT1k4V1hBb3Y1LWlSb18zYVpoandJNzNMcFlzcktySkxBQkJGUTN0cmZqbXpwVUxuMDZHeFpuVldRXzJYbmNoNGdRdnIzYnJCOA?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-81')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">Why Data Centers Are Falling Behind Schedule; Jensen Huang’s Power Summit - The Information</div>
            <div class="meta">2025-12-22</div>
        </div>
        
        <div id="content-81" style="display:none;">
            <h2>Why Data Centers Are Falling Behind Schedule; Jensen Huang’s Power Summit - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2025-12-22</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMipgFBVV95cUxQdEw4ZWtGRzVvTzJUUGlmS3VzMlU2VnpqR2RpNW8wOG1IUnVYeTFwbnU5ejBrdGJxcFYtNm12QnJYdExtZ2Z6OG1HbzMyaEFiMHhOSU9PM3pKMk9ZV3BJNkh4WW1kSnBzWWw3YjNpMGoyQl80Z1FXMVMxVWExZFFZMXBkRDU2cUoxRVdONmZxV3RZUUQ3MU44M2dZTTEzQjJ4UWdESFRn?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-82')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">OpenAI Is Getting More Efficient at Running Its AI, Internal Financials Show - The Information</div>
            <div class="meta">2025-12-21</div>
        </div>
        
        <div id="content-82" style="display:none;">
            <h2>OpenAI Is Getting More Efficient at Running Its AI, Internal Financials Show - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2025-12-21</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiogFBVV95cUxQdmI2di13dk1valhrLTJ0dE5pemNJYVNEc3h0UENkX0wyMFZidU54cUlsZm1EYmxMaTdTQWphZmI3VzBpa0hDNUYyMUFteU0xZXBScUQ0MmZZYk1DR0lxV3k2X29BRFFhLU11YkoyZ25hNGp3VTRPejdpUWV3MTlpb29XZVk0R3cweGRlWHdxemhYdTdlenZwUC14UkMtUUhteFE?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-83')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">OpenAI Ramps Up Audio AI Efforts Ahead of Device - The Information</div>
            <div class="meta">2026-01-01</div>
        </div>
        
        <div id="content-83" style="display:none;">
            <h2>OpenAI Ramps Up Audio AI Efforts Ahead of Device - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2026-01-01</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiigFBVV95cUxOY040X0Z4aktsUndwUlRyQlBNb3hkN2JXdVNZMmxtaldVeTBLUjhpS2lNN0F4aUQ1RU5GWGxKenZKbkozZkJzSXdWU00xSUhWbV9NTEphamdvem54M29GVFhBdnFsTTY3cWZuRFF3bUwwNDNhQlVCWnZFcU5VcFdsRkRpRGtpb3ZDTnc?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        </div>

        <div id="reader-modal">
            <div id="close-btn" class="control-btn" onclick="closeModal()">X</div>
            
            <div id="scroll-controls">
                <button class="scroll-btn" onclick="scrollPage(-1)">&#9650;</button> <button class="scroll-btn" onclick="scrollPage(1)">&#9660;</button>  </div>

            <div id="modal-inner"></div>
        </div>

        <script>
            // 1. RANDOMIZE ORDER
            const list = document.getElementById('feed-list');
            const cards = Array.from(document.querySelectorAll('.card'));
            cards.sort(() => Math.random() - 0.5);
            cards.forEach(card => list.appendChild(card));

            // 2. DARK MODE
            const btn = document.getElementById('theme-toggle');
            btn.addEventListener('click', () => document.body.classList.toggle('dark-mode'));

            // 3. MODAL & SCROLL LOGIC
            const modal = document.getElementById('reader-modal');
            const modalInner = document.getElementById('modal-inner');

            function openModal(contentId) {
                const content = document.getElementById(contentId).innerHTML;
                modalInner.innerHTML = content;
                modal.style.display = 'block';
                document.body.style.overflow = 'hidden'; 
            }

            function closeModal() {
                modal.style.display = 'none';
                document.body.style.overflow = 'auto';
            }

            function scrollPage(direction) {
                // Scroll by 80% of the screen height to keep context
                const scrollAmount = window.innerHeight * 0.8;
                modal.scrollBy(0, direction * scrollAmount);
            }
        </script>
    </body>
    </html>
    