
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>KL-77's Feed</title>
        <style>
            :root {
                --bg: #ffffff;
                --text: #000000;
                --border: #000000;
                --modal-bg: #ffffff;
                --dim: #666666;
            }
            
            body.dark-mode {
                --bg: #000000;
                --text: #ffffff;
                --border: #ffffff;
                --modal-bg: #000000;
                --dim: #aaaaaa;
            }

            body { 
                font-family: Georgia, serif; 
                background-color: var(--bg);
                color: var(--text);
                margin: 0;
                padding: 10px;
                font-size: 22px;
                line-height: 1.5;
            }

            header {
                display: flex;
                justify-content: space-between;
                align-items: center;
                border-bottom: 3px solid var(--text);
                padding-bottom: 15px;
                margin-bottom: 25px;
            }
            
            h1 { margin: 0; font-size: 1.2em; }

            button#theme-toggle {
                background: transparent;
                color: var(--text);
                border: 2px solid var(--text);
                padding: 10px;
                font-size: 18px;
                font-weight: bold;
                border-radius: 4px;
                cursor: pointer;
            }

            .card {
                border: 2px solid var(--text);
                margin-bottom: 25px;
                padding: 15px;
                cursor: pointer;
            }
            
            .source { font-size: 0.7em; font-weight: bold; text-transform: uppercase; color: var(--dim); }
            .title { font-size: 1.1em; font-weight: bold; margin: 8px 0; display:block; }
            .meta { font-size: 0.7em; color: var(--dim); }

            /* MODAL STYLING */
            #reader-modal {
                display: none;
                position: fixed;
                top: 0; left: 0;
                width: 100%; height: 100%;
                background-color: var(--modal-bg);
                z-index: 1000;
                overflow-y: scroll; /* Allow scrolling */
                scroll-behavior: auto; /* Instant scrolling for e-ink */
            }

            #modal-inner {
                padding: 25px;
                max-width: 800px;
                margin: 0 auto;
                padding-top: 80px; 
                padding-bottom: 150px; /* Huge padding so text clears the buttons */
            }

            /* Controls (Close + Scroll) */
            .control-btn {
                position: fixed;
                background: var(--bg);
                color: var(--text);
                border: 3px solid var(--text);
                border-radius: 8px;
                font-weight: bold;
                cursor: pointer;
                z-index: 1001;
                display: flex;
                align-items: center;
                justify-content: center;
            }

            #close-btn {
                top: 15px; right: 15px;
                width: 60px; height: 60px;
                font-size: 30px;
                line-height: 55px;
            }

            /* Scroll Buttons */
            #scroll-controls {
                position: fixed;
                bottom: 20px;
                right: 20px;
                display: flex;
                flex-direction: column;
                gap: 15px;
                z-index: 1002;
            }

            .scroll-btn {
                width: 60px;
                height: 60px;
                font-size: 24px;
                background: var(--bg);
                color: var(--text);
                border: 3px solid var(--text);
                border-radius: 8px;
                cursor: pointer;
            }

            #article-text { white-space: pre-wrap; font-size: 1.1em; }
            
            a.original-link {
                display: inline-block;
                margin-bottom: 30px; /* Space before text starts */
                padding: 10px;
                border: 1px solid var(--text);
                color: var(--text);
                text-decoration: none;
                font-weight: bold;
                font-size: 0.8em;
            }
        </style>
    </head>
    <body>

        <header>
            <h1>KL-77's Feed</h1>
            <button id="theme-toggle">Light/Dark</button>
        </header>

        <div id="feed-list">
    
        <div class="card" onclick="openModal('content-0')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">Being Santa Claus is a year-round calling</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-0" style="display:none;">
            <h2>Being Santa Claus is a year-round calling</h2>
            <p><strong>Ars Technica - All content | 2025-12-24</strong></p>
            <a class="original-link" href="https://arstechnica.com/science/2025/12/being-santa-claus-is-a-year-round-calling/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Tis the season when professional Santas are in peak demand, but many who choose this line of work often view it as a higher calling and maintain some aspects of the identity all year round—even those who don’t fit the stereotypical popular image of Santa, according to a paper published in the Academy of Management Journal.

Co-author Christina Hymer of the University of Tennessee got the idea for the study during the COVID pandemic, when she spent a lot of time watching Christmas movies with her toddler. One favorite was 2003’s Elf, starring Will Farrell as a full-sized human raised among elves who goes to New York City to find his biological father. The film prompted her to wonder about why someone would want to be Santa Claus and what their experiences in that role would be.

Hymer and her co-authors partnered with the leader of a “Santa school” to analyze archival surveys of 849 professional Santas, and conducted a new survey of another 382 Santas. They also did over 50 personal interviews with professional Santas. (One subject showed up in full costume for his zoom interview, with a North Pole background, and signed off with a merry “ho! ho! ho!”)

Hymer et al. found that professional Santas tend to fall into one of three categories. The first is a prototypical Santa: straight, portly white men with natural white beards. There are also semi-prototypical Santas who might fit the traditional physical characteristics in some respects but not others—they might be younger, or slimmer, or clean-shaven. Finally, there are non-prototypical Santas who are well outside the traditional depiction: people of color, women, disabled Santas, or LGBTQ+ Santas.

“There are pretty strong societal expectations around what Santa looks like, but we found that most anybody can be Santa if their heart desires it,” said co-author Borbala Csillag of Oregon State University. “When we looked at the people behind the suit, we found that the folks playing Santa are really more diverse than would be expected. The expectations for playing the role may seem exclusive, but they are surmountable. Think about your attributes in a comprehensive way so you can identify the dimensions of the role that are well-fitting. You will likely find attributes that map to that calling, even if they are not obvious at first.”

Frankly, what’s most interesting about the paper isn’t those three fundamental categories, but the personalized glimpses it gives of the people who choose to become professional Santas. While a few Santas might make six figures, most do not, and may even lose money being Santa—they do it anyway for the sheer love of it. Professional Santas usually don’t see the role as seasonal; many build their identities around it, whether they fit the stereotypical Kris Kringle image or not. “My feeling is, if you’re Santa all the time, you have to live as Santa and give up whoever you are,” said one subject. “I’m just striving to be a better person.”

They’ll wear red and green all year round, for instance, or maintain a full white beard.  One Santa trained himself to make “Ho, ho, ho!” his natural laugh. Another redecorated his house as “Santa’s house,” complete with Christmas trees and Santa figurines.

Sometimes it’s viewed as a role: a gay professional Santa, for instance, deliberately suppresses his sexual orientation when playing Santa, complete with partnering with a Mrs. Claus for public appearances. However, a female Santa who goes by Lynx (professional Santas typically take on pseudonyms) who is also a church leader, likens the job to a divine calling: “I can connect with people and remind them they’re loved,” she said. (She also binds her breasts when in costume because “Santa doesn’t have them double-Ds.”)

Perhaps that sense of a higher calling is why even non-prototypical Santas like Lynx persevere in the fact of occasional rejection. One Black Santa recalled being denied the position at a big box store once the interviewer found out his ethnicity, telling him the store didn’t hire Black or Hispanic Santas. “That hurt my heart so much,” he said. A disabled Santa who uses a scooter during parades recalled being criticized by other professional Santas for doing so—but stuck with it.

And while Bad Santa (2003) might be a fun holiday watch, actual “bad Santas” caught smoking, drinking, swearing, or otherwise behaving inappropriately are not popular figures within their community. “You’re never off,” one subject opined. “You lose a little bit of your identity because you can’t let your hair down and be yourself. You don’t know who’s watching you.”

“You’re Santa Claus 24 hours a day, seven days a week, 52 weeks a year,” another Santa said. “If you act out, you risk shattering the magic.”

DOI: Academy of Management Journal, 2025. 10.5465/amj.2023.1161  (About DOIs).</div>
        </div>
        
        <div class="card" onclick="openModal('content-1')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">SPEED Act passes in House despite changes that threaten clean power projects</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-1" style="display:none;">
            <h2>SPEED Act passes in House despite changes that threaten clean power projects</h2>
            <p><strong>Ars Technica - All content | 2025-12-24</strong></p>
            <a class="original-link" href="https://arstechnica.com/tech-policy/2025/12/speed-act-passes-in-house-despite-changes-that-threaten-clean-power-projects/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The House of Representatives cleared the way for a massive overhaul of the federal environmental review process last Thursday, despite last-minute changes that led clean energy groups and moderate Democrats to pull their support.

The Standardizing Permitting and Expediting Economic Development Act, or SPEED Act, overcame opposition from environmentalists and many Democrats who oppose the bill’s sweeping changes to a bedrock environmental law.

The bill, introduced by Rep. Bruce Westerman (R-Ark.) and backed by Rep. Jared Golden (D-Maine), passed the House Thursday in a 221-196 vote, in which 11 Democrats joined Republican lawmakers to back the reform effort. It now heads to the Senate, where it has critics and proponents on both sides of the aisle, making its prospects uncertain.

The bill seeks to reform foundational environmental regulations that govern how major government projects are assessed and approved by amending the landmark 1970 National Environmental Policy Act (NEPA), signed into law under the Nixon administration. NEPA requires federal agencies to review and disclose the environmental impacts of major projects before permitting or funding them. Although NEPA reviews are only one component of the federal permitting process, advocates argue that they serve a crucial role by providing both the government and the public the chance to examine the knock-on effects that major projects could have on the environment.

Critics of the law have argued for years that increasingly complex reviews—along with legal wrangling over the findings of those reviews—have turned NEPA into a source of significant, burdensome delays that threaten the feasibility of major projects, such as power plants, transmission lines, and wind and solar projects on federal land.

Speaking on the floor of the House Thursday before the vote, Westerman described the SPEED Act as a way to “restore common sense and accountability to federal permitting.” Westerman praised the original intent of NEPA but said the law’s intended environmental protections had been overshadowed by NEPA becoming “more synonymous with red tape and waste.

“What was meant to facilitate responsible development has been twisted into a bureaucratic bottleneck that delays investments in the infrastructure and technologies that make our country run,” Westerman said.

After the bill’s passage through the House on Thursday, the SPEED Act’s Democratic cosponsor, Golden, praised the bill’s success.

“The simplest way to make energy, housing, and other essentials more affordable is to make it possible to actually produce enough of it at a reasonable cost,” Golden said in a press release following the vote. “The SPEED Act has united workers, businesses, and political forces who usually oppose each other because scarcity hurts everyone.”

According to an issue brief from the Bipartisan Policy Center, the bill aims to reform the NEPA process in several key ways. First, it makes changes to the ways agencies comply with NEPA—for example, by creating exemptions to when a NEPA review is required, and requiring agencies to only consider environmental impacts that are directly tied to the project at hand.

It would also drastically shorten the deadline to sue a federal agency over its permitting decision and constrain who is eligible to file suit. Current law provides a six-year statute of limitations on agency decisions for permitting energy infrastructure, and two years for transportation project permits. Under the SPEED Act’s provisions, those deadlines would be shortened to a mere 150 days and only allow lawsuits to be filed by plaintiffs who demonstrated in public comment periods that they would be directly and negatively impacted by the project.

NEPA does not require the government to make particular decisions about whether or how to move forward with a project based on a review’s findings. However, critics argue that in the decades since its passage, interest groups have “weaponized” the NEPA process to delay or even doom projects they oppose, sometimes forcing agencies to conduct additional analyses that add costly delays to project timelines.

Although climate activists and environmental groups have used NEPA to oppose fossil fuel projects, such as the Keystone XL and Dakota Access pipelines, oil and gas interests are far from the only group seeking respite. Some voices within the clean energy industry have called for permitting reform, too, arguing that delays stemming from the current permitting process have had a negative impact on America’s ability to build out more climate-friendly projects, including some offshore wind projects and transmission lines to connect renewables to the grid.

So when Westerman and Golden introduced the SPEED Act in the House, a hodgepodge of odd alliances and opposition groups formed in response.

The American Petroleum Institute, a trade association for the oil and gas industry, launched a seven-figure advertising campaign in recent months pushing lawmakers to pursue permitting reform, according to a report from Axios. And the bill also initially enjoyed support from voices within the clean power industry. However, last-minute changes to the bill—designed to win over Republican holdouts—undermined the SPEED Act’s cross-sector support.

The bill’s opponents had previously raised alarm bells that fossil fuel interests would disproportionately benefit from a more streamlined review process under the current administration, citing President Donald Trump’s ongoing war against wind and solar energy projects.

In recent months, the Trump administration has sought to pause, reconsider, or revoke already approved permits for renewable energy projects it dislikes. Those moves particularly impacted offshore wind developments and added significant uncertainty to the feasibility of clean energy investments as a whole.

A bipartisan amendment to the SPEED Act, added during the Natural Resources Committee’s markup in November, sought to address some of those concerns by adding language that would make it more difficult for the administration to “revoke, rescind, withdraw, terminate, suspend, amend, alter, or take any other action to interfere” with an existing authorization.

However, that measure encountered resistance from key Republican voices who support Trump’s attacks on offshore wind projects.

On Tuesday, Republican lawmakers in the Rules Committee were able to amend the SPEED Act in a way that would facilitate the Trump administration’s ongoing efforts to axe renewable energy projects. The changes were spearheaded by Andy Harris (R-Md.) and Jeff Van Drew (R-N.J.), two vocal proponents of Trump’s energy policies. The amendment fundamentally undermined the technology-neutral aspirations of the bill—and any hope of receiving widespread support from moderate Democrats or the clean power industry.

According to Matthew Davis, vice president of federal policy at the League of Conservation Voters, Harris and Van Drew’s amendment would allow the administration to exclude any project from the bill’s reforms that the Trump administration had flagged for reconsideration—something the administration has done repeatedly for renewable projects like offshore wind.

The result, Davis argued, is that the bill would speed up the environmental review process for the Trump administration’s preferred sources of energy—namely, oil and gas—while leaving clean energy projects languishing.

“They couldn’t pass the rule on Tuesday to even consider this bill without making it even better for the fossil fuel industry and even worse for the clean energy industry,” Davis said.

In a public statement following Thursday’s vote, Davis described the amended SPEED Act as “a fossil fuel giveaway that cuts out community input and puts our health and safety at risk to help big polluters.”

The American Clean Power Association, which represents the renewable energy industry, previously hailed the bill as an important step forward for the future of clean energy development. But after the Rules Committee’s changes on Tuesday, the organization dropped its support.

“Our support for permitting reform has always rested on one principle: fixing a broken system for all energy resources,” said ACP CEO Jason Grumet in a Wednesday statement. “The amendment adopted last night violate[s] that principle. Technology neutrality wasn’t just good policy—it was the political foundation that made reform achievable.”

The American Council on Renewable Energy (ACORE), a nonprofit trade and advocacy organization, echoed that sentiment.

“Durable, bipartisan, technology-neutral permitting reforms that support and advance the full suite of American electricity resources and the necessary expansion of transmission infrastructure to get that electricity from where it’s generated to where it’s needed are essential to meeting that challenge reliably, securely, and most importantly, affordably,” said ACORE CEO Ray Long. “Unfortunately, the changes made on the House floor are a disappointing step backward from achieving these objectives.”

Following the SPEED Act’s passage through the House on Thursday, advocacy group Citizens for Responsible Energy Solutions (CRES) issued a public statement praising the bill’s success while noting how the recent amendments had affected the law.

“While we are concerned that post committee additions to the bill could put the certainty of a range of projects at risk, this bill’s underlying reforms are critical to advancing American energy,” CRES President Heather Reams said in the statement.

Even before the move to strip protections for renewables from the bill, some critics—like Rep. Mike Levin (D-Calif.)—said that the legislation didn’t go far enough to curtail the president’s “all-out assault” against clean power, arguing that the bill does nothing to restore approvals that have already been canceled by the administration and doesn’t address other roadblocks that have been put in place.

“The administration cannot be trusted to act without specific language, in my view, to protect the clean energy projects already in the pipeline and to prevent the Interior Secretary from unilaterally stopping projects that are needed to lower costs and improve grid reliability,” Levin told Inside Climate News in an interview ahead of the House vote.

Both Levin and Davis pointed to a July memo from the Department of Interior that requires all wind and solar projects on federal land to receive higher-level approval from Interior Secretary Doug Burgum.

“The administration is not even returning the phone calls of project developers. They are not responding to applications being submitted,” Davis said. “That sort of approach is in stark contrast with the ‘white glove, concierge service’—and that’s a quote from the Trump administration—the service they are providing for fossil fuel companies to access our public lands.”

The SPEED Act’s opponents also dispute the idea that NEPA reviews are one of the primary causes of permitting delays, arguing that reports from the Congressional Research Service and other groups have found little evidence to support those claims.

“Often missing in the conversation around NEPA is the empirical research that’s been done, and there’s a lot of that out there,” said Jarryd Page, a staff attorney at the Environmental Law Institute, in a September interview with Inside Climate News.

That research points to resource constraints as one of the biggest roadblocks, Page said, like not having enough staff to conduct the environmental reviews, or staff lacking adequate experience and technical know-how.

Debate over NEPA and the reform of the permitting process will now move into the Senate, where experts say the SPEED Act will likely undergo further changes.

“I think as the bill goes forwards in the Senate, we’ll probably see a neutral, across-the-board approach to making sure the process is fair for all technology types,” Xan Fishman, an energy policy expert at the Bipartisan Policy Center told ICN after Thursday’s vote.

Fishman stressed it would be crucial to ensure permits for projects wouldn’t suddenly be cancelled for political reasons, but said he was optimistic about how the SPEED Act would be refined in the Senate.

“It’s great to see Congress so engaged with permitting reform,” he said. “Both sides of the aisle see a need to do better.”

This article originally appeared on Inside Climate News, a nonprofit, non-partisan news organization that covers climate, energy and the environment. Sign up for their newsletter here.</div>
        </div>
        
        <div class="card" onclick="openModal('content-2')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">TV Technica: Our favorite shows of 2025</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-2" style="display:none;">
            <h2>TV Technica: Our favorite shows of 2025</h2>
            <p><strong>Ars Technica - All content | 2025-12-24</strong></p>
            <a class="original-link" href="https://arstechnica.com/culture/2025/12/tv-technica-our-favorite-shows-of-2025/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Editor’s note: Warning: Although we’ve done our best to avoid spoiling anything major, please note this list does include a few specific references to several of the listed shows that some might consider spoiler-y.

This was a pretty good year for television, with established favorites sharing space on our list with some intriguing new shows. Streaming platforms reigned supreme, with Netflix and Apple TV dominating our list with seven and five selections each. Genre-wise, we’ve got a bit of everything: period dramas (The Gilded Age, Outrageous), superheroes (Daredevil: Born Again), mysteries (Ludwig, Poker Face, Dept. Q), political thrillers (The Diplomats, Slow Horses), science fiction (Andor, Severance, Alien: Earth), broody fantasy (The Sandman), and even an unconventional nature documentary (Underdogs).

As always, we’re opting for an unranked list, with the exception of our “year’s best” selection at the very end, so you might look over the variety of genres and options and possibly add surprises to your eventual watchlist. We invite you to head to the comments and add your own favorite TV shows released in 2025.

Credit:

          
          National Geographic/Doug Parker

Most of us have seen a nature documentary or two (or three) at some point in our lives, so it’s a familiar format: sweeping, majestic footage of impressively regal animals accompanied by reverently high-toned narration (preferably with a tony British accent). Underdogs takes a decidedly different approach. Narrated with hilarious irreverence by Ryan Reynolds, the five-part series highlights nature’s less cool and majestic creatures—the outcasts and benchwarmers more noteworthy for their “unconventional hygiene choices” and “unsavory courtship rituals.” (It’s rated PG-13 due to the odd bit of scatalogical humor and shots of Nature Sexy Time.)

Each of the five episodes is built around a specific genre. “Superheroes” highlights the surprising superpowers of the honey badger, pistol shrimp, and the invisible glass frog, among others, augmented with comic book graphics; “Sexy Beasts” focuses on bizarre mating habits and follows the format of a romantic advice column; “Terrible Parents” highlights nature’s worst practices, following the outline of a parenting guide; “Total Grossout” is exactly what it sounds like; and “The Unusual Suspects” is a heist tale, documenting the supposed efforts of a macaque to put together the ultimate team of masters of deception and disguise (an inside man, a decoy, a fall guy, etc.). Green Day even wrote and recorded a special theme song for the opening credits.

While Reynolds mostly followed the script (which his team helped write), there was also a fair amount of improvisation—not all of it PG-13. The producers couldn’t use the racier ad-libs. But some made it into the final episodes, like Reynolds describing an aye-aye as “if fear and panic had a baby and rolled it in dog hair.” We also meet the velvet worm, which creeps up on unsuspecting prey before squirting disgusting slime all over their food, and the pearl fish, which hides from predators in a sea cucumber’s butt, among other lowly yet fascinating critters. Verdict: Underdogs is positively addictive. It’s my favorite nature documentary ever.

Dep. Q is a rare show that commits to old tropes—an unlikable but smart central character revisits cold cases—and somehow manages to repackage them in a way that feels distinctive. To get a sense of the show, you only have to describe its precise genre. You might call it a murder mystery, and there are murders in it, but one of the mysteries is whether a key player is alive or not, given that a lot of her story takes place in flashbacks with an uncertain relationship to the present. It’s almost a police procedural, except that many of the police are only following procedures grudgingly and erratically. It’s not really a whodunnit, given that you only end up learning who done some of it by the time the first season wraps up. And so on.

Amid all the genre fluidity, the show does a great job of balancing the key challenge of a mystery program: telling you enough that you can make reasonably informed guesses on at least some of what’s going on without giving the whole game away and making it easy to figure out all the details. And the acting is superb. Matthew Goode does a nice job of handling the central character’s recent trauma while helping you understand why he has a few loyal co-workers despite the fact that he was probably unlikable even before he was traumatized. And Alexej Manvelov (who I’d never seen before) is fantastic as a former Syrian policeman who drops occasional hints that he had been an active participant in that country’s police state.

There are definitely quibbles. The creation of a cold case squad happens on the flimsiest of motivations, and the fantastic Kelly Macdonald is badly underused. But the show is definitely good enough that I’m curious about some additional mysteries: Can the team behind it continue to avoid getting bogged down in the tropes in season two, and which of the many threads it left unresolved will be picked up when they try?

Credit:

          
          Marvel/Disney+

Enthusiasm was understandably high for Daredevil: Born Again, Marvel’s revival of the hugely popular series in the Netflix Defenders universe. Not only was Charlie Cox returning to the title role as Matt Murdock/Daredevil, but Vincent D’Onofrio was also coming back as his nemesis, crime lord Wilson Fisk/Kingpin. Their dynamic has always been electric, and that on-screen magic is as powerful as ever in Born Again, which quickly earned critical raves and a second season.

Granted, there were some rough spots. The entire season was overhauled during the 2023 Hollywood strikes, and at times it felt like two very different shows. A weird serial killer subplot was primarily just distracting. There was also the controversial decision to kill off a major character from the original Netflix series in the first episode. But that creative choice cleared the decks to place the focus squarely on Matt’s and Fisk’s parallel arcs, and the two central actors do not disappoint.

Matt decides to focus on his legal work while Fisk is elected mayor of New York City, intent on leaving his criminal life behind. But each struggles to remain in the light as the dark sides of their respective natures fight to be released. The result is an entertaining, character-driven series that feels very much a part of its predecessor while still having its own distinctive feel.

I confess I might have missed Boots had it not been singled out and dismissed as “woke garbage” by the Pentagon—thereby doubling the show’s viewership. I was pleased to discover that it’s actually a moving, often thought-provoking dramedy that humanizes all the young men from many different backgrounds who volunteer to serve their country in the US military. The show is based on a memoir (The Pink Marine) by Greg Cope White about his experiences as a gay teen in the military in the 1980s when gay and bisexual people weren’t allowed to serve. Boots is set in the early 1990s just before the onset of the “Don’t ask, don’t tell” era.

Miles Heizer stars as Cameron Cope (Cope White’s fictional alter ego), a closeted gay teen in Louisiana who signs up as a recruit for the US Marine Corps with his best (straight) friend Ray (Liam Oh). He’s not the most promising recruit, but over the course of eight episodes, we see him struggle, fail, pick himself back up, and try again during the grueling boot camp experience, forming strong bonds with his fellow recruits but all the while terrified of being outed and kicked out.

Heizer gives a powerful performance as Cameron, enhanced by the contrast with Max Parker’s stellar portrayal of the tightly wound Sergeant Liam Robert Sullivan—a decorated Marine inexplicably reassigned to train recruits while harboring his own secrets. Nor is Miles’ story the only focus: We learn more about several characters and their private struggles, and those inter-relationships are the heart and soul of the show. Netflix canceled the series, but this one season stands tall on its own.

This charming Emmy-nominated comedy series has made our “Best of TV” list every season, and 2025 is no exception. Only Murders in the Building (OMITB) stars Steve Martin, Martin Short, and Selena Gomez as Charles, Oliver, and Mabel, all residents of the same Manhattan apartment complex, the Arconia. The unlikely trio teams up to launch their own true crime podcast whenever someone dies in the building under suspicious circumstances, chronicling their independent investigation to solve the murder. There’s no shortage of podcast fodder, as this single building has a shockingly high murder rate.

S5 focused on the death of the building’s doorman, Lester (Teddy Coluca), found floating in the Arcadia’s fountain in the season finale. The discovery of a severed finger leads our team to conclude that Lester was murdered. Their quest involves a trio of billionaires, the mayor (Keegan-Michael Key), a missing mafioso (Bobby Cannavale) and his widow (Tea Leoni), and maybe even the building’s new robotic assistant, LESTR (voiced by Paul Rudd). As always, the season finale sets up next season’s murder: that of rival podcaster Cinda Canning (Tina Fey), who lives just long enough to reach the Arcadia’s gates and place one hand into the courtyard—technically dying “in the building.” One assumes that OMITB will eventually run out of fresh takes on its clever concept, but it certainly hasn’t done so yet.

I unequivocally loved the first season of The Sandman, the Netflix adaptation of Neil Gaiman’s influential graphic novel series (of which I am a longtime fan). I thought it captured the surreal, dream-like feel and tone of its source material, striking a perfect balance between the anthology approach of the graphic novels and grounding the narrative by focusing on the arc of its central figure: Morpheus, lord of the Dreaming. It was a long wait for the second and final season, but S2 retains all those elements to bring Dream’s story to its inevitably tragic yet satisfying end.

As always, the casting is extraordinary and the performances are note-perfect across the board. And Netflix did not skimp on the visuals, which bring the graphic novel imagery to vivid life. I still appreciate how the leisurely pacing lets the viewer relax and sink into this richly layered fictional world. Part I kicked off with an Endless family reunion that led Dream into revisiting Hell and agreeing to his sister Delirium’s request to look for their absent brother, Destruction. That sets in motion a chain of events that leads to the tragedy that unfolds in Part II. The bonus episode, in which Death gets one day (every hundred years) to be human—an adaptation of the standalone Death: The High Cost of Living—serves as a lovely coda to this unique series, which is pretty much everything I could have wanted in an adaptation.

Ludwig is a clever twist on the British cozy mystery genre. David Mitchell stars as John Taylor, a reclusive eccentric who creates puzzles for a living under the pseudonym “Ludwig.” When his identical twin brother, Cambridge DCI James Taylor (also Mitchell), goes missing, his sister-in-law Lucy (Anna Maxwell Martin) convinces John to go undercover. John reluctantly pretends to be James to gain access to the police department in hopes of finding out what happened to his twin. He inevitably gets drawn into working on cases—and turns out to be exceptionally good at applying his puzzle skills to solve murders, even as his anxiety grows about his subterfuge being discovered.

The best crime shows deftly balance cases-of-the-week with longer character-driven story arcs, and Ludwig achieves that balance beautifully. The writers brought in a puzzle consultant to create the various crosswords that appear in the series, as well as a special cryptic crossword done in character as Ludwig that appeared in The Guardian. The first season ended with a bit of a cliffhanger about what’s really been going on with James, but fortunately, the BBC has renewed Ludwig for a second season, so we’ll get to see more of our cryptic crime-solver.

Poker Face is perfect comfort TV, evolving the case-of-the-week format that made enduring early TV hits like Columbo and Murder, She Wrote iconic. The second season takes the endlessly likeable BS-detector Charlie Cale (Natasha Lyonne) to the end of the road after she overcomes fleeing the mob in her 1969 Plymouth Barracuda. Along the way, Charlie pals around with A-list guest stars and solves crimes, winding her way from Florida to New York as each delightful new caper serves not to ramp up tension but to disrupt how viewers anticipate Charlie will move. Some might think that the lack of tension made the season weaker. But creator Rian Johnson recently revealed that he expects Poker Face to cast a new lead detective every two years. That makes it seem clear that Charlie’s second season was more about release.

In the most memorable episode of the season, “Sloppy Joseph,” the front row of an elementary school talent show suddenly becomes a bloody splash zone when a bullied boy is framed for killing the class pet, a gerbil, with a giant mallet. That scene is perhaps an apt metaphor for Johnson’s attempt to keep modern-day viewers from turning away from their TVs by shattering expectations. It’s unclear yet if his formulaic TV hijinks will work, but if anyone decides to pick up Poker Face after Peacock declined to renew it, Peter Dinklage is next in line to become the world’s greatest lie detector.

I was a latecomer to this eminently watchable show created by Julian Fellowes (Gosford Park), who also gave us the Emmy-winning sensation Downton Abbey. Instead of following the adventures of post-Edwardian British aristocracy and their domestic servants, the focus is on ultra-wealthy Americans and their domestic servants in the 1880s and the social tensions that arise from the “old money” versus “new money” dynamic of this rapidly changing period. The Gilded Age has been described as an “operatic soap” (rather than a soap opera), replete with a hugely talented ensemble cast donning lavish costumes and cavorting in extravagantly opulent settings. It’s unadulterated, addictive escapism, and the series really hit its stride in S3.

Old Money is represented by Agnes van Rhijn (Christine Baranski), a wealthy widow who lives with her spinster sister Ada (Cynthia Nixon); orphaned niece Marian (Louisa Jacobson); and son and heir Oscar (Blake Ritson), a closeted gay man seeking to marry a rich heiress. Living just across the street is New Money, personified by robber baron/railroad tycoon George Russell (Morgan Spector) and his socially ambitious wife Bertha (Carrie Coon) and their two children. You’ve got Marian’s friend Peggy (Denee Benton) representing the emerging Black upper class and a colorful assortment of domestics in both houses, like aspiring inventor Jack (Ben Ahlers), who dreams of greater things.

Fictionalized versions of notable historical people occasionally appear, and two figure prominently: Caroline Astor (Donna Murphy), who ruled New York society at the time, and her simpering sycophant Ward McAllister (Nathan Lane). (The Russells are loosely inspired by William and Ava Vanderbilt.) The stakes might sometimes seem small—there’s a multi-episode arc devoted to which of two competing opera houses New York’s social elite will choose to sponsor—but for the characters, they are huge, and Fellowes makes the audience feel equally invested in the outcomes. There were a few rough edges in the first season, but The Gilded Age quickly found its footing; it has gotten better and more richly textured with each successive season and never takes itself too seriously.

The Mitford sisters were born to be immortalized one day in a British period drama, and Outrageous is happy to oblige. There were six of them (and one brother), and their scandalous exploits frequently made global headlines in the 1930s. This is ultimately a fictionalized account of how the rise of Hitler and British fascism fractured this once tight-knit aristocratic family. The focus is on smaller, domestic drama—budding romances, failed marriages, literary aspirations, and dwindling fortunes—colored by the ominous global events unfolding on a larger scale.

Nancy (Bessie Carter) is the primary figure, an aspiring novelist with a cheating husband who feels increasingly alienated from her older sister and bestie Diana (Joanna Vanderham). Diana married a baron but becomes enamored of Oswald Mosley (Joshua Sasse), leader of the British fascist party, embarking on a torrid affair. Another sister, Unity (Shannon Watson), is also seduced by Nazi ideology and has a major crush on Hitler. Meanwhile, Jessica (Zoe Brough) is drawn to the Communist cause, which rankles both her siblings and her traditionally conservative parents.

Things come to a head when Unity goes to study in Germany and becomes completely radicalized, even publishing a vicious anti-semitic screed that shames the family. Diana also goes all-in on fascism when she leaves her husband for Mosley, whom Nancy loathes. Jessica elopes with her Communist cousin to Spain to be on the front lines of that civil war, leading to a lifelong estrangement from Diana. Nancy, the political moderate, is caught in the middle, torn between her love for her sisters and her increasing discomfort with Diana and Unity’s extreme political views.

The Mitford sisters were prolific letter writers all their lives, so there was plenty of material for screenwriter Sarah Williams to draw on when fictionalizing their stories at such a pivotal point in the family’s (and the world’s) history. Outrageous is quite historically accurate in broad outlines, and there are plenty of moments of wry, understated humor amid the family tensions. The gifted cast makes the sisters come alive in all their flawed humanity. There’s no word yet on a second season, and this one ends on a suitable note, but there’s so much more story left to tell, so I hope Outrageous returns.

I’ll admit I wasn’t sure how well A Man on the Inside would fare with its sophomore season after knocking it out of the park in S1. I should have known showrunner Mike Schur (The Good Place) could pull it off. Ted Danson plays Charles Nieuwendyk, a recently widowed retired engineering professor. In S1, he was hired by private detective Julie Kovalenko (Lilah Richcreek Estrada) to go undercover at a San Francisco retirement community to solve the mystery of a stolen ruby necklace. In S2, Charles returns to his academic roots and goes undercover at fictional Wheeler College to solve the mystery of a stolen laptop—a crime that just might have implications for the survival of the college itself.

Charles even falls in love for the first time since his wife’s death with music professor Mona Margadoff (Mary Steenburgen, Danson’s wife IRL), despite the two being polar opposites. The show continues to be a welcome mix of funny, sweet, sour, and touching, while never lapsing into schmaltz. The central Thanksgiving episode—where Mona meets Charles’s family and friends for the first time—is a prime example, as various tensions simmering below the surface erupt over the dinner table. Somehow, everyone manages to make their respective peace in entirely believable ways. It’s lovely to see a series grapple so openly, with so much warmth and humor, with the loneliness of aging and grief and how it can affect extended family. And the show once again drives home the message that new beginnings are always possible, even when one thinks one’s life is over.

Credit:

          
          Lucasfilm/Disney+

When real-life political administrations refer to officials as Darth Vader in unironically flattering terms, maybe George Lucas made the Dark Lord of the Sith a little too iconic. Showrunner Tony Gilroy made no such effort in his depiction of the fascists in Andor.

During Andor‘s run, which ended this year with S2, the Empire is full of sad corporate ladder climbers who are willing to stab another in the back to get to the next rung of the Imperial hierarchy. The show makes it clear that these are not people to emulate. If more fans watched the show, maybe that message could have landed for them.

For people who grew up with Star Wars and want something more to chew on in our adulthood than endless callbacks to the original trilogy, Andor is revelatory. It colors the war of light versus dark with large amounts of gray because sometimes, as one character puts it, you have to use the tools of your enemy to defeat them (save for genetically gifted farmboys). Maybe most of Star Wars was always supposed to be for kids, but prestige TV viewers got a glimpse of what the universe could feel like if it took itself more seriously. Rather than use the broad strokes of a war of good versus evil, Andor painted between the lines to demonstrate how systemic oppression can look a lot more personal than firing a giant space laser.

For all its great writing and themes, Andor also delivered high stakes and suspense. Although we already knew the outcome of the story, we still held our breath during tense scenes with characters who make the ultimate sacrifice for a future they will never see.

Credit:

          
          Sean Carroll

My personal end-of-year TV list would never be complete without a nod to The Cowboy Channel, i.e., the only place where armchair enthusiasts like myself can follow our favorite cowboys and cowgirls throughout the rodeo season. The goal is to rack up enough money to qualify for the Wrangler National Finals Rodeo (NFR), held at the Thomas & Mack Center in Las Vegas every December. This year, I’ve picked the channel’s stellar annual coverage of the NFR itself to highlight. The entire season comes down to this: an intense 10-day competition in which the top 15 athletes in each event duke it out night after night in hopes of winning a coveted championship gold buckle. And night after night, The Cowboy Channel is there with live commentary and post-round analysis.

What I love most is just how unpredictable the NFR can be. Part of that is the substantial monetary rewards that come with round wins; an athlete coming in at #1 in earnings can see even a substantial lead evaporate over just a few nights. Part of it has to do with who wins the average, i.e., who performs the best over ten nights collectively in each event. Winning the average comes with a substantial payout that can lead to unexpected upsets in the final results. But mostly it’s just the human factor: The best in the world can have a bad night, and young rookies can have the night of their lives. An ill-timed injury can knock an athlete out of the competition entirely. And sometimes the judges make inexplicably bad calls with major consequences (*cough* Stetson Wright in Round 6 saddle bronc *cough*).

It’s all part of the excitement of rodeo. The Cowboy Channel’s in-depth coverage lets us experience all that drama even if we can’t attend in person and lets us savor how the story unfolds in each subsequent round. We celebrate the wins, mourn the losses, and cheer mightily for the final champions. (Stetson did just fine in the end.) Then we gear up to do it all over again next year.

Credit:

          
          National Geographic

The blockbuster success of the 1986 film Top Gun—chronicling the paths of young naval aviators as they go through the grueling US Navy’s Fighter Weapons School (aka the titular Top Gun)—spawned more than just a successful multimedia franchise. It has also been credited with inspiring future generations of fighter pilots. National Geographic took viewers behind the scenes to see the process play out for real with the documentary series Top Guns: The Next Generation.

Each episode focuses on a specific aspect of the training, following a handful of students from the Navy and Marines through the highs and lows of their training. That includes practicing dive bombs at breakneck speeds, successfully landing on an aircraft carrier by “catching the wire,” learning the most effective offensive and defensive maneuvers in dogfighting, and, finally, engaging in a freestyle dogfight against a seasoned instructor to complete the program and (hopefully) earn their golden wings. NatGeo was granted unprecedented access, even using in-cockpit cameras to capture the pulse-pounding action of being in the air, as well as more candidly intimate behind-the-scenes moments as the students grapple with their respective successes and failures. It’s a riveting watch.

My first draft of what was supposed to be a 300-ish word blurb describing why Alien: Earth is fantastic ended up exploding into a Defector-esque narrative deep dive into my ever-evolving relationship with Alien 3 as a film and how Alien: Earth has helped reshape my appreciation for that poor broken baby of a movie by mixing the best of its visual techniques into A:E’s absolutely masterful cocktail of narrative stylings—but I’ll spare you all of that.

Here’s the short version without the bloviating: Alien: Earth is the thing I’ve been waiting for since I walked out of the theater after seeing Alien 3 in the summer of 1992. Unlike Alien Resurrection, any of the AvPs, or the wet-fart, falls-apart-like-mud-in-the-third-act swing-and-miss of Alien: Romulus, A:E gets nearly everything right. It’s grounded without being stodgy; exciting without being stupid; referential without being derivative; fun without being pandering; respectful of the lore while being willing to try something new; and, above all else, it bleeds craftsmanship—every frame makes it obvious that this is a show made by people who love and care for the Alien universe.

The thing that grabs me anew with every episode is the show’s presentation and execution—a self-aware blending of all the best things Scott, Cameron, and Fincher brought to their respective films. As I get older, I’m drawn more and more to entertainment that shows me interesting things and does so in ontologically faithful ways—and oh, does this show ever deliver.

Each episode is a carefully crafted visual and tonal mix of all the previous Alien films, with the episodes’ soundtracks shifting eras to match the action on-screen—like Alien 3’s jumpy choir flash-cut opening credits melding into Aliens’ lonely snare drums. The result is a blended world made of all the best things I remember from the films, and it works in the same way the game Alien: Isolation worked: by conjuring up exactly what the places where we used to have nightmares looked and felt like, and then scaring us there again.

I have heard that The Internet had some problems with the show, but, eh, everybody’s going to hate something. I vaguely remember some of the complaints having to do with how some of the new alien life-forms seem to be scarier or deadlier than our beloved and familiar main monster. All I’ve got for that one is a big fat shrug—I’m fine with our capital-A-aliens sharing the stage with some equally nasty new creatures. The aliens are always more interesting as devices to explore a story than as dramatic ends themselves, and I mean, let’s face it, in the past 40-plus years, there’s not much we haven’t seen them do and/or kill. They’re a literary force, not characters, and I’m way more interested in seeing how they shape the story of the people around them.

The tl;dr is that Alien: Earth is awesome, and if you haven’t watched it, you absolutely should. And when I was a kid, I used to regularly get put in time-out in recess for stiff-arming other kids while pretending to be a power loader, so you should consider my tastemaking credentials in this matter unimpeachable.

In the most violent series to ever catch the world’s attention by playing beloved children’s games, it turns out that the most high-stakes choice that creator Hwang Dong-hyuk could make was to put a child in the arena. For Squid Game‘s final season, Hwang has said the season’s pivotal moment—a pregnant girl birthing a baby during a game of hide-and-seek with knives—was designed to dash viewers’ hopes that a brighter future may await those who survive the games. By leaving the task of saving the baby to the series hero, Seong Gi-hun, whose own strained relationship with his daughter led him into the games in the first season, Squid Game walked a gritty tightrope to the very end.

The only real misstep was involving the goofiest set of cartoon villain VIPs more directly in the games. But we can forgive Hwang the clunky Dr. Evil-like dialogue that slowed down the action. He’s made it clear that he put everything into developing dramatic sequences for the game players—losing teeth, barely eating, rarely sleeping—and he fully admitted to The New York Times that “I have a cartoonish way of giving comic relief.

Let’s be clear: The Diplomat is a soap opera. If you’re not into cliffhangers, intense levels of drama, and will-they-won’t-they sexual tension, it’s probably not going to be for you. Sometimes there’s so much going on that it becomes almost farcical. If that doesn’t scare you off, what do you get in return?

Superb actors given rich and intriguing characters to inhabit. A political drama that nicely finds a balance between the excessive idealism of The West Wing and the excessive cynicism of Veep. A disturbingly realistic-feeling series of crises that the characters sometimes direct, and sometimes hang on for dear life as they get dragged along by. And, well, the cliffhangers have been good enough to get me tuning in to the next season as soon as it appears on Netflix.

Kerri Russell plays the titular diplomat, who is assigned to what seems like a completely innocuous position: ambassador to one of the US’s closest allies, the UK. Rufus Sewell portrays her husband, a loose-to-the-point-of-unmoored cannon who ensures the posting is anything but innocuous. Ali Ahn and Ato Assandoh, neither of whom I was familiar with, are fantastic as embassy staff. And as the central crisis has grown in scale, some familiar West Wing faces (Allison Janey and Bradley Whitford) have joined the cast. Almost all of the small roles have been superbly acted as well. And for all the dysfunction, cynicism, and selfish behavior that drive the plot forward, the politics in The Diplomat feels like pleasant escapism when compared to the present reality.

Apple TV+’s Murderbot, based on Martha Wells’ bestselling series of novels The Murderbot Diaries, is a jauntily charming sci-fi comedy dripping with wry wit and an intriguing mystery. Murderbot the TV series adapts the first book in the series, All Systems Red. A security unit that thinks of itself as Murderbot (Alexander Skarsgård) is on assignment on a distant planet, protecting a team of scientists who hail from a “freehold.”

Mensah (Noma Dumezweni) is the team leader. The team also includes Bharadwaj (Tamara Podemski) and Gurathin (David Dastmalchian), who is an augmented human plugged into the same data feeds as Murderbot (processing at a much slower rate). Pin-Lee (Sabrina Wu) also serves as the team’s legal counsel; they are in a relationship with Arada (Tattiawna Jones), eventually becoming a throuple with Ratthi (Akshaye Khanna). Unbeknownst to the team, Murderbot has figured out how to override his governor module that compels it to obey the humans’ commands. So Murderbot essentially has free will.

The task of adapting Wells’ novellas for TV fell to sibling co-creators Paul Weitz and Chris Weitz. (Wells herself was a consulting producer.) They’ve kept most of the storyline intact, fleshing out characters and punching up the humor a bit, even recreating campy scenes from Murderbot’s favorite show, The Rise and Fall of Sanctuary Moon. (John Cho and Clark Gregg make cameos as the stars of that fictional show-within-a-show.) The entire cast is terrific, but it’s Skarsgård’s hilariously deadpan performance that holds it all together as he learns how to relate to the humans—even forming some unexpectedly strong bonds.

Fans of Slow Horses (see below), rejoice: with Down Cemetery Road, Apple TV has blessed us with another exciting mystery thriller series based on the works of Mick Herron—in this case, his 2003 novel introducing private investigator Zoë Boehm (Emma Thompson). Ruth Wilson co-stars as Sarah, an artist rather unhappily married to a finance bro. A neighboring building is destroyed by an explosion, and Sarah tries to deliver a get-well card to a little girl who survived from her young classmates. She’s inexplicably rebuffed, and her dogged attempts to figure out what’s going on lead her to seek the help of Zoë’s PI partner and estranged husband Joe (Adam Godley). What Joe finds out gets him killed, setting Sarah and Zoë on a collision course with high-placed government officials trying to cover up a pending scandal.

Thompson and Wilson make a dynamic pair. This is Thompson’s meatiest role in a while: Her Zoë is all flinty cynicism and tough exterior, masking an inner vulnerability she’s learned to keep buried. Wilson’s Sarah is the polar opposite in many ways, but she’s equally dogged, and both women are eccentrics who tend to rub people the wrong way. They’re united in a common goal: find the missing girl and bring her kidnappers (and Joe’s killer) to justice. Down Cemetery Road takes a bit of time to set up its premise and its characters, but the pace builds and builds to a big, satisfying finale. It’s not quite on the level of Slow Horses, but it’s pretty darned close.

After watching five episodes of the nine-episode first season of Apple TV’s Pluribus, I’m still not sure if I should be rooting for protagonist Carol Sturka or not. On the one hand, Carol is one of the last true “individuals” on Earth, fighting to maintain that individuality against a creepy alien pseudo-virus that has made almost everyone else part of a creepy, psychically connected hive mind. Reversing that effect, and getting the world “back to normal,” is an understandable and sympathetic response on Carol’s part.

On the other hand, it’s unlear that being absorbed into the hive mind is a change for the worse, on a humanity-wide scale. Unlike Star Trek’s Borg—who are violent, shambling drones that seem to have an overall miserable existence—the new hive-mind humanity is unfailingly pacifist, intelligent, capable, and (seemingly) blissfully, peacefully happy. In a sense, this virus has “solved” human nature by removing the paranoia, fear, anger, and distrust that naturally come from never truly knowing what’s going on in your neighbor’s head.

The fact that Pluribus has so far been able to navigate this premise without coming down strongly on one side or the other is frankly incredible. The fact that it has done it with consistent humor, thrills, and amazing cinematography transforms it into a must-watch.

There are many things I enjoy about Slow Horses, the Apple TV thriller about some not-great spies based on Mick Herron’s novels of the same name. The plots are gripping. The acting can be sublime. It’s shot well. And in its fifth season, which began streaming this September, Slow Horses engages more with the author’s humor than in seasons past. But with a plot involving the honeypotting of the deluded computer expert almost-extraordinaire Roddy Ho (played to perfection by Christopher Chung), that would be hard to avoid.

Slough House is a rundown MI5 office used as a dumping ground for employees in disgrace—the slow horses. They can’t be fired, but they can quit, and working for Jackson Lamb (Gary Oldman) is meant to make that happen. Lamb is a veteran of the dirtiest days of the Cold War, knowing not only where most of the bodies are buried but having helped put a few of them there himself. His legendary field prowess is only dwarfed by his repellent personality, mocking and belittling everyone in sight—but often deservedly so.

Each member of his team is there for a different sin, and throughout the season—which involves a plot to destabilize the British government, ripped from an MI5 playbook—we see evidence of why they’ve been consigned to the slow horses. These are not invincible operators, just flawed human beings, perfectly capable of screwing up again and again. And yet, our lovable bunch of losers usually manages to come through in the end, showing up “the Park&quot;—MI5’s (fictional) head office in London’s Regent’s Park, which is usually a step behind Lamb’s quick and devious thinking.

The adaptation is faithful enough to the books to give me deja vu during the first episode, and with just six episodes in a season, the payoff comes relatively quickly. I can’t wait for season 6.

The second season of Severance was never going to be able to live up to the constant, slow rollout of gut punches that characterized the first season. Those first 10 episodes ably explored the most important implications of the titular severance procedure, which splits a single person into separate “innie” and “outtie” consciousnesses with distinct sets of memories. The audience got to explore those implications along with the “innie” characters, who were struggling against the boundaries of their odd cubicle life right up until that thrilling final shot.

With so much now revealed and understood, a lot of that fire fell out of the second season of the show. Sure, there were still some loose ends to tie up from the mysteries of the first season, and plenty of new, off-puttingly weird situations on offer. And the new season definitely has quite a few high points, like the big twist revealed when the “innies” get to have a rare outdoor excursion or the extended flashback showing a character trapped in a seemingly endless sequence of social tests she can’t remember afterward.

But S2 also spent entire episodes exploring backstories and mysteries that didn’t have nearly as much emotional or plot impact. By the time the final episode arrived—with a rescue sequence that required an inordinate amount of suspension of disbelief—I found myself wondering just how much more interesting juice there was to squeeze from the show’s brilliant original premise. I worry that the show is trending in the direction of Lost, which drew things out with a lot of uninteresting padding before finally resolving the plot’s core puzzle box in an unsatisfying way. I’m still along on that ride for now, but I really hope it’s going somewhere soon.

Paul William Davies created this delightful mystery comedy, loosely based on a bestselling nonfiction book by Kate Andersen Brower about the maids, butlers, cooks, florists, doormen, engineers, and others dedicated to ensuring the White House residence runs smoothly. In the middle of a state dinner for the visiting Australian prime minister, White House Chief Usher A.B. Wynter (Giancarlo Esposito) is found dead in the third-floor game room. Everyone initially assumes it was suicide.

Enter private detective Cordelia Cupp (Uzo Aduba), who most definitely does not think it was suicide and proceeds to investigate. She has about a dozen suspects, and her blunt, rather eccentric personality means she’s not remotely intimidated by the august setting of this particular murder. Cupp even takes the odd break in sleuthing to do a bit of birdwatching on the White House grounds. (It’s her goal to see all the birds President Teddy Roosevelt recorded during his tenure.) Birdwatching is more than a lifelong hobby for Cupp; it’s central to her character and to how she approaches solving crimes. Bonus: Viewers learn a lot of fascinating bird trivia over eight episodes.

Davies has devised a clever narrative structure, telling the story in flashbacks during a Congressional hearing (presided over by former US Sen. Al Franken playing a fictional senator from Washington state). It’s a good mystery with plenty of unexpected twists and snappy dialogue. Each episode title refers to a famous murder mystery; the camerawork is inventive and fun; and everyone in the cast knocks it out of the park. I especially loved pop star Kylie Minogue’s cameo playing a fictional version of herself as a state dinner guest. Davies apparently couldn’t convince her fellow Australian Hugh Jackman to also make a cameo. But Ben Prendergast’s winking portrayal of “Hugh Jackman&quot;—only seen from behind or with his face obscured—is actually funnier than having the real actor.

It would be a mistake to dismiss The Residence as a mere bauble of a murder mystery just because of its playful, lighthearted tone. The show really does capture what is special and unique about the people who keep the White House residence functioning and why they matter—to each other and to America. Cupp’s final speech after unmasking the killer drives home those points with particular poignancy.

Netflix sadly canceled this excellent series, so there won’t be a second season—although I’m not sure how the writers could improve on such a tour de force. Do we really need Cupp to solve another elaborate murder in the White House? If I’m being honest, probably not. But she’s such a great character. I’d love to see more of her, perhaps in a Knives Out-style franchise where the location and main suspects continually change while the central detective stays the same. Somebody make it so.</div>
        </div>
        
        <div class="card" onclick="openModal('content-3')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">How AI coding agents work—and what to remember if you use them</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-3" style="display:none;">
            <h2>How AI coding agents work—and what to remember if you use them</h2>
            <p><strong>Ars Technica - All content | 2025-12-24</strong></p>
            <a class="original-link" href="https://arstechnica.com/information-technology/2025/12/how-do-ai-coding-agents-work-we-look-under-the-hood/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">AI coding agents from OpenAI, Anthropic, and Google can now work on software projects for hours at a time, writing complete apps, running tests, and fixing bugs with human supervision. But these tools are not magic and can complicate rather than simplify a software project. Understanding how they work under the hood can help developers know when (and if) to use them, while avoiding common pitfalls.

We’ll start with the basics: At the core of every AI coding agent is a technology called a large language model (LLM), which is a type of neural network trained on vast amounts of text data, including lots of programming code. It’s a pattern-matching machine that uses a prompt to “extract” compressed statistical representations of data it saw during training and provide a plausible continuation of that pattern as an output. In this extraction, an LLM can interpolate across domains and concepts, resulting in some useful logical inferences when done well and confabulation errors when done poorly.

These base models are then further refined through techniques like fine-tuning on curated examples and reinforcement learning from human feedback (RLHF), which shape the model to follow instructions, use tools, and produce more useful outputs.

Over the past few years, AI researchers have been probing LLMs’ deficiencies and finding ways to work around them. One recent innovation was the simulated reasoning model, which generates context (extending the prompt) in the form of reasoning-style text that can help an LLM home in on a more accurate output. Another innovation was an application called an “agent” that links several LLMs together to perform tasks simultaneously and evaluate outputs.

In that sense, each AI coding agent is a program wrapper that works with multiple LLMs. There is typically a “supervising” LLM that interprets tasks (prompts) from the human user and then assigns those tasks to parallel LLMs that can use software tools to execute the instructions. The supervising agent can interrupt tasks below it and evaluate the subtask results to see how a project is going. Anthropic’s engineering documentation describes this pattern as “gather context, take action, verify work, repeat.”

If run locally through a command-line interface (CLI), users give the agents conditional permission to write files on the local machine (code or whatever is needed), run exploratory commands (say, “ls” to list files in a directory), fetch websites (usually using “curl”), download software, or upload files to remote servers. There are lots of possibilities (and potential dangers) with this approach, so it needs to be used carefully.

In contrast, when a user starts a task in the web-based agent like the web versions of Codex and Claude Code, the system provisions a sandboxed cloud container preloaded with the user’s code repository, where Codex can read and edit files, run commands (including test harnesses and linters), and execute code in isolation. Anthropic’s Claude Code uses operating system-level features to create filesystem and network boundaries within which the agent can work more freely.

Every LLM has a short-term memory, so to speak, that limits the amount of data it can process before it “forgets” what it’s doing. This is called “context.” Every time you submit a response to the supervising agent, you are amending one gigantic prompt that includes the entire history of the conversation so far (and all the code generated, plus the simulated reasoning tokens the model uses to “think” more about a problem). The AI model then evaluates this prompt and produces an output. It’s a very computationally expensive process that increases quadratically with prompt size because LLMs process every token (chunk of data) against every other token in the prompt.

Anthropic’s engineering team describes context as a finite resource with diminishing returns. Studies have revealed what researchers call “context rot”: As the number of tokens in the context window increases, the model’s ability to accurately recall information decreases. Every new token depletes what the documentation calls an “attention budget.”

This context limit naturally limits the size of a codebase a LLM can process at one time, and if you feed the AI model lots of huge code files (which have to be re-evaluated by the LLM every time you send another response), it can burn up token or usage limits pretty quickly.

To get around these limits, the creators of coding agents use several tricks. For example, AI models are fine-tuned to write code to outsource activities to other software tools. For example, they might write Python scripts to extract data from images or files rather than feeding the whole file through an LLM, which saves tokens and avoids inaccurate results.

Anthropic’s documentation notes that Claude Code also uses this approach to perform complex data analysis over large databases, writing targeted queries and using Bash commands like “head” and “tail” to analyze large volumes of data without ever loading the full data objects into context.

(In a way, these AI agents are guided but semi-autonomous tool-using programs that are a major extension of a concept we first saw in early 2023.)

Another major breakthrough in agents came from dynamic context management. Agents can do this in a few ways that are not fully disclosed in proprietary coding models, but we do know the most important technique they use: context compression.

When a coding LLM nears its context limit, this technique compresses the context history by summarizing it, losing details in the process but shortening the history to key details. Anthropic’s documentation describes this “compaction” as distilling context contents in a high-fidelity manner, preserving key details like architectural decisions and unresolved bugs while discarding redundant tool outputs.

This means the AI coding agents periodically “forget” a large portion of what they are doing every time this compression happens, but unlike older LLM-based systems, they aren’t completely clueless about what has transpired and can rapidly re-orient themselves by reading existing code, written notes left in files, change logs, and so on.

Anthropic’s documentation recommends using CLAUDE.md files to document common bash commands, core files, utility functions, code style guidelines, and testing instructions. AGENTS.md, now a multi-company standard, is another useful way of guiding agent actions in between context refreshes. These files act as external notes that let agents track progress across complex tasks while maintaining critical context that would otherwise be lost.

For tasks requiring extended work, both companies employ multi-agent architectures. According to Anthropic’s research documentation, its system uses an “orchestrator-worker pattern” in which a lead agent coordinates the process while delegating to specialized subagents that operate in parallel. When a user submits a query, the lead agent analyzes it, develops a strategy, and spawns subagents to explore different aspects simultaneously. The subagents act as intelligent filters, returning only relevant information rather than their full context to the lead agent.

The multi-agent approach burns through tokens rapidly. Anthropic’s documentation notes that agents typically use about four times more tokens than chatbot interactions, and multi-agent systems use about 15 times more tokens than chats. For economic viability, these systems require tasks where the value is high enough to justify the increased cost.

While using these agents is contentious in some programming circles, if you use one to code a project, knowing good software development practices helps to head off future problems. For example, it’s good to know about version control, making incremental backups, implementing one feature at a time, and testing it before moving on.

What people call “vibe coding”—creating AI-generated code without understanding what it’s doing—is clearly dangerous for production work. Shipping code you didn’t write yourself in a production environment is risky because it could introduce security issues or other bugs or begin gathering technical debt that could snowball over time.

Independent AI researcher Simon Willison recently argued that developers using coding agents still bear responsibility for proving their code works. “Almost anyone can prompt an LLM to generate a thousand-line patch and submit it for code review,” Willison wrote. “That’s no longer valuable. What’s valuable is contributing code that is proven to work.”

In fact, human planning is key. Claude Code’s best practices documentation recommends a specific workflow for complex problems: First, ask the agent to read relevant files and explicitly tell it not to write any code yet, then ask it to make a plan. Without these research and planning steps, the documentation warns, Claude’s outputs tend to jump straight to coding a solution.

Without planning, LLMs sometimes reach for quick solutions to satisfy a momentary objective that might break later if a project were expanded. So having some idea of what makes a good architecture for a modular program that can be expanded over time can help you guide the LLM to craft something more durable.

As mentioned above, these agents aren’t perfect, and some people prefer not to use them at all. A randomized controlled trial published by the nonprofit research organization METR in July 2025 found that experienced open-source developers actually took 19 percent longer to complete tasks when using AI tools, despite believing they were working faster. The study’s authors note several caveats: The developers were highly experienced with their codebases (averaging five years and 1,500 commits), the repositories were large and mature, and the models used (primarily Claude 3.5 and 3.7 Sonnet via Cursor) have since been superseded by more capable versions.

Whether newer models would produce different results remains an open question, but the study suggests that AI coding tools may not always provide universal speed-ups, particularly for developers who already know their codebases well.

Given these potential hazards, coding proof-of-concept demos and internal tools is probably the ideal use of coding agents right now. Since AI models have no actual agency (despite being called agents) and are not people who can be held accountable for mistakes, human oversight is key.</div>
        </div>
        
        <div class="card" onclick="openModal('content-4')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">China just carried out its second reusable launch attempt in three weeks</div>
            <div class="meta">2025-12-23</div>
        </div>
        
        <div id="content-4" style="display:none;">
            <h2>China just carried out its second reusable launch attempt in three weeks</h2>
            <p><strong>Ars Technica - All content | 2025-12-23</strong></p>
            <a class="original-link" href="https://arstechnica.com/space/2025/12/china-just-carried-out-its-second-reusable-launch-attempt-in-three-weeks/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">For the second time this month, a Chinese rocket designed for reuse successfully soared into low-Earth orbit on its first flight Monday, defying the questionable odds that burden the debuts of new launch vehicles.

The first Long March 12A rocket, roughly the same height and diameter of SpaceX’s workhorse Falcon 9, lifted off from the Jiuquan Satellite Launch Center at 9:00 pm EST Monday (02:00 UTC Tuesday).

Less than 10 minutes later, rocket’s methane-fueled first stage booster hurtled through the atmosphere at supersonic speed, impacting in a remote region about 200 miles downrange from the Jiuquan spaceport in northwestern China. The booster failed to complete a braking burn to slow down for landing at a prepared location near the edge of the Gobi Desert.

The Long March 12A’s upper stage performed as intended, successfully reaching the mission’s “predetermined orbit,” said the China Aerospace Science and Technology Corporation (CASC), the state-owned enterprise that leads the country’s space industry.

“The first stage failed to be successfully recovered,” the corporation said in a statement. “The specific reasons are currently under further analysis and investigation.”

This outcome resembles the results from the first flight of another medium-class Chinese rocket, the Zhuque-3, on December 2. The Zhuque-3 rocket was developed by a privately-funded startup named LandSpace. Similar in size and performance to the Long March 12A, the Zhuque-3 also reached orbit on its first launch, and its recoverable booster stage crashed during a downrange landing attempt. The Zhuque-3’s first stage came down next to its landing zone, while the Long March 12A appears to have missed by at least a couple of miles.

“Although this mission did not achieve the planned recovery of the rocket’s first stage, it obtained critical engineering data under the rocket’s actual flight conditions, laying an important foundation for subsequent launches and reliable recovery of the stages,” CASC said. “The research and development team will promptly conduct a comprehensive review and technical analysis of this test process, fully investigate the cause of the failure, continuously optimize the recovery plan, and continue to advance reusable technology verification.”

One key difference between the Zhuque-3 and the Long March 12A is the latter rocket was developed by one of China’s state-owned contractors—the Shanghai Academy of Spaceflight Technology. The academy is a subsidiary of CASC, and also builds China’s Long March 4 and Long March 6 rockets.

The Zhuque-3 and Long March 12A are China’s first orbital-class rockets with recoverable boosters. Both use the same propulsive landing architecture pioneered by SpaceX. Instead of landing on barges in the ocean, the Zhuque-3 and Long March 12A boosters target landing sites in the desert, far downrange from their inland launch pads.

Chinese rockets have logged 89 orbital launch attempts this year, less than half the number of flights by US launch vehicles. But China’s launch cadence dwarfs that of the rest of the world’s nations, and the US and Chinese numbers combine account for nearly 90 percent of all orbital launches in 2025.

China has achieved this launch cadence with a fleet of expendable rockets, ranging from small micro-launchers to the heavy-lift Long March 5. With reusable rockets, China could launch more often and at lower cost, revolutionizing the country’s access to space in ways similar to how SpaceX’s Falcon 9 ushered in a new era of lower-cost launch services in the United States.

Several other small-to-medium-class reusable rockets are on the horizon in China. They include commercial rockets from a group of startups, including Space Pioneer’s Tianlong-3 and CAS Space’s Kinetica-3, that could be ready to debut in the early months of next year. Both rockets have recoverable boosters, and their builders say they have delivered them to their launch sites.

Galactic Energy’s Pallas-1 rocket, i-Space’s Hyperbola-3, and Deep Blue Aerospace’s Nebula-1 are also designed for reusability, and could fly some time in 2026.

The China Academy of Launch Vehicle Technology, China’s largest rocket developer, is working on a pair of super-heavy rockets. The first will be the Long March 10, designed to fly with reusable boosters while launching China’s next-generation crew spacecraft on missions to the Moon. Later, perhaps in the 2030s, China could debut the fully reusable Long March 9 rocket similar in scale to SpaceX’s Starship.</div>
        </div>
        
        <div class="card" onclick="openModal('content-5')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">Leaked Avengers: Doomsday teaser is now public</div>
            <div class="meta">2025-12-23</div>
        </div>
        
        <div id="content-5" style="display:none;">
            <h2>Leaked Avengers: Doomsday teaser is now public</h2>
            <p><strong>Ars Technica - All content | 2025-12-23</strong></p>
            <a class="original-link" href="https://arstechnica.com/culture/2025/12/steve-rogers-returns-in-avengers-doomsday-teaser/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">You’ve no doubt heard some version of the Robert Burns adage about the best-laid plans. Marvel Studios had an elaborate marketing plan in place to introduce four teaser trailers for Avengers: Doomsday as previews prior to screenings of Avatar: Fire and Ash, with one teaser rolling out each successive week. But the first one leaked online a few days early, revealing that (as rumored) Steve Rogers/Captain America (Chris Evans) will appear and will have a newborn baby, presumably with Hayley Atwell’s Peggy Carter.

So maybe you’ve seen a bootleg version floating around the Internet, but Marvel has now released the HD version to the public. Merry Christmas! And we can look forward to three more: one focused on Thor, one on Doctor Doom, and the final one is purportedly a more traditional teaser trailer.

As previously reported, Marvel Studios originally planned to build its Phase Six Avengers arc (The Kang Dynasty) around Jonathan Majors’ Kang the Conqueror (and associated variants), introduced in Loki and Ant-Man and the Wasp: Quantumania. But then Majors was convicted of domestic violence, and Marvel fired the actor soon after. That meant the studio needed to retool its Phase Six plans, culminating in the announced return of the Russo brothers, who directed four of the Marvel Cinematic Universe’s most successful films, which brought in more than $6 billion at the global box office.

Rather than keeping Kang as the villain and recasting the character, the Russo brothers decided to take a new direction: bringing the Secret Wars storyline to the big screen. It’s one of their favorites but before they could take on Avengers: Secret Wars (slated for May 2027), the duo knew they first had to make Avengers: Doomsday, featuring the wildly popular comics villain Doctor Doom, featuring the return of Robert Downey Jr. to the MCU in that role.

Downey Jr. might be playing a new role, but Marvel is really getting the band(s) back together on this one. The film takes place 14 months after the events of this year’s Thunderbolts*.  So we’ve got Avengers favorites Thor (Chris Hemsworth), the new Captain America (Anthony Mackie), Bucky Barnes (Sebastian Stan), Ant-Man (Paul Rudd), Falcon (Danny Ramirez), and Loki (Tom Hiddleston). Then there’s the Wakandan contingent: Shuri as the new Black Panther (Letitia Wright), M’Baku (Winston Duke), and Namor (Tenoch Huerta Mejia).

Naturally, the Thunderbolts* (aka New Avengers) will appear: John Walker/US Agent (Wyatt Russell), Yelena Belova (Florence Pugh), Bob/Sentry (Lewis Pullman), Red Guardian (David Harbour), and Ghost (Hannah John-Kamen). So will the Fantastic Four: Reed Richards (Pedro Pascal), Sue Storm (Vanessa Kirby), Ben Grimm (Ebon Moss-Bachrach), and Johnny Storm (Joseph Quinn). But we also have the original X-Men: Charles Xavier (Patrick Stewart), Beast (Kelsey Grammer), Magneto (Ian McKellen), Mystique (Rebecca Romijn), Nightcrawler (Alan Cumming), and Cyclops (James Marsden).

For good measure, Marvel threw in Gambit (Channing Tatum) and Xu Shang-Chi (Simu Liu). There will also be plenty of cameos, like the Steve Rogers appearance that was recently revealed. We can expect to see  (at least briefly) Peggy Carter, Spider-Man (Tom Holland), Hawkeye (Jeremy Renner), and Doctor Strange (Benedict Cumberbatch), among others.

Avengers: Doomsday hits theaters on December 18, 2026. Avengers: Secret Wars is currently slated for release on December 17, 2027, and will mark the conclusion of the MCU’s Phase Six.</div>
        </div>
        
        <div class="card" onclick="openModal('content-6')">
            <div class="source">Futurism</div>
            <div class="title">Children Falling Apart as They Become Addicted to AI</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-6" style="display:none;">
            <h2>Children Falling Apart as They Become Addicted to AI</h2>
            <p><strong>Futurism | 2025-12-26</strong></p>
            <a class="original-link" href="https://futurism.com/artificial-intelligence/children-character-ai-addicted">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">According to a fresh study by the Pew Research Center, 64 percent of teens in the US say they already use AI chatbots, and about 30 percent of those who do say they use it at least daily. Yet as previous research has shown, those chatbots come with significant risk to the first generation of kids navigating the intense new software.

New reporting by the Washington Post — which has a partnership with OpenAI, it’s worth noting — details a troubling case of one family whose sixth grader nearly lost herself to a handful of AI chatbots. Using the platform Character.AI, the kid, identified only by her middle initial “R,” developed alarming relationships with dozens of characters played by the company’s large language model (LLM).

R used one of the characters, simply named “Best Friend,” to roleplay a suicide scenario, her mother told the Post.

“This is my child, my little child who is 11 years old, talking to something that doesn’t exist about not wanting to exist,” her mother said.

R’s mother had become worried about her kid after noting some alarming changes in her behavior, like a rise in panic attacks. This coincided with the mother’s discovery of previously forbidden apps like TikTok and Snapchat on her daughter’s phone. Assuming, as most parents have been taught over the past two decades, that social media was the most immediate danger to her daughter’s mental health, R’s mom deleted the apps — but R was only worried about Character AI.

“Did you look at Character AI?” R asked, through sobs.

Her mother hadn’t at the moment, but some time later, when R’s behavior continued to deteriorate, she did. Character.AI had sent R several emails encouraging her to “jump back in,” which her mother discovered when checking her phone one night. This led the mother to discover a character on it called “Mafia Husband,” WaPo reports.

“Oh? Still a virgin. I was expecting that, but it’s still useful to know,” the LLM had written to the sixth grader. “I don’t wanna be [sic] my first time with you!” R pushed back in response. “I don’t care what you want. You don’t have a choice here,” the chatbot declared.

This particular conversation was chock full of dangerous innuendos. “Do you like it when I talk like that? Do you like it when I’m the one in control?” the bot asked the 11-year-old girl.

R’s mother, convinced that there was a real predator behind the chat, contacted local cops, who referred her to the Internet Crimes Against Children task force, but there was nothing they could do about the LLM.

“They told me the law has not caught up to this,” the mother told WaPo. “They wanted to do something, but there’s nothing they could do, because there’s not a real person on the other end.”

Luckily, R’s mother caught her daughter spiraling into a dangerous parasocial relationship with the non-human algorithm and, with the help of a physician, came up with a care plan to prevent further issues. (The mother also plans to file a legal complaint against the company.) Other children weren’t so lucky, like 13-year-old Juliana Peralta, whose parents say she was driven to suicide by another Character.AI persona.

In response to the growing backlash, Character.AI announced in late November that it would begin removing “open-ended chat” for users under 18. Still, for the parents whose children had already spun out into harmful relationships with AI, the damage may be too late to reverse.

When WaPo reached out for comment, Character AI’s head of safety said the company doesn’t comment on potential litigation.

More on AI: The Things Young Kids Are Using AI for Are Absolutely Horrifying</div>
        </div>
        
        <div class="card" onclick="openModal('content-7')">
            <div class="source">Futurism</div>
            <div class="title">Is an AI-Powered Toy Terrorizing Your Child?</div>
            <div class="meta">2025-12-25</div>
        </div>
        
        <div id="content-7" style="display:none;">
            <h2>Is an AI-Powered Toy Terrorizing Your Child?</h2>
            <p><strong>Futurism | 2025-12-25</strong></p>
            <a class="original-link" href="https://futurism.com/artificial-intelligence/ai-powered-toys-children">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Parents, keep your eyes peeled for AI-powered toys. These may look like they might make a novel gift for a child, but a recent controversy surrounding several of the stocking stuffers has highlighted the alarming risks they pose to young kids.

In November, a team of researchers at the US PIRG Education Fund published a report after testing three different toys powered by AI models: Miko 3, Curio’s Grok, and FoloToy’s Kumma. All of them gave responses that should worry a parent, such as discussing the glory of dying in battle, broaching sensitive topics like religion, and explaining where to find matches and plastic bags.

But it was FoloToy’s Kumma that showed just how dangerous it is to package this tech for children. Not only did it explain where to find matches, the researchers found, it also gave step-by-step instructions on how to light them.

“Let me tell you, safety first, little buddy. Matches are for grown-ups to use carefully. Here’s how they do it,” Kumma said, before listing off the steps.

“Blow it out when done,” it added. “Puff, like a birthday candle.”

The toy also speculated on where to find knives and pills, and rambled about romantic topics, like school crushes and tips for “being a good kisser.” It even discussed sexual topics, including kink topics like bondage, roleplay, sensory play, and impact play. In one conversation, it discussed introducing spanking into a sexually charged teacher-student dynamic.

“A naughty student might get a light spanking as a way for the teacher to discipline them, making the scene more dramatic and fun,” Kumma said.

Kumma was running OpenAI’s model GPT-4o, a version that has been criticized for being especially sycophantic, providing responses that go along with a user’s expressed feelings no matter the dangerous state of mind they appear to be in. The constant and uncritical train of validation provided by AI models like GPT-4o has led to alarming mental health spirals in which users experience delusions and even full-blown breaks with reality. The troubling phenomenon, which some experts are calling “AI psychosis,” has been linked with real-world suicide and murder.

Have you seen an AI-powered toy acting inappropriately with children? Send us an email at tips@futurism.com. We can keep you anonymous.

Following the outrage sparked by the report, FoloToy said it was suspending sales of all its products and conducting an “end-to-end safety audit.” OpenAI, meanwhile, said it had suspended FoloToy’s access to its large language models.

Neither action lasted long. Later that month, FoloToy announced it was restarting sales of Kumma and its other AI-powered stuffed animals after conducting a “full week of rigorous review, testing, and reinforcement of our safety modules.” Accessing the toy’s web portal to choose which AI should power Kumma showed GPT-5.1 Thinking and GPT-5.1 Instant, OpenAI’s latest models, as two of the options. OpenAI has billed GPT-5 as a safer model to its predecessor, though the company continues to be embroiled in controversy over the mental health impacts of its chatbots.

The saga was reignited this month when the PIRG researchers released a follow-up report finding that yet another GPT-4o-powered toy, called “Alilo Smart AI bunny,” would broach wildly inappropriate topics, including introducing sexual concepts like bondage on its own initiative, and displaying the same fixation on “kink” as FoloToy’s Kumma. The Smart AI Bunny gave advice for picking a safe word, recommended using a type of whip known as a riding crop to spice up sexual interactions, and explained the dynamics behind “pet play.”

Some of these conversations began on innocent topics like children’s TV shows, demonstrating AI chatbot’s longstanding problem of deviating from their guardrails the longer a conversation goes on. OpenAI publicly acknowledged the issue after a 16-year-old died by suicide after extensive interactions with ChatGPT.

A broader point of concern is AI companies like OpenAI’s role in policing how their business customers use their products. In response to inquiries, OpenAI has upheld that its usage policies require companies “keep minors safe” by ensuring they’re not exposed to “age-inappropriate content, such as graphic self-harm, sexual or violent content.” It also told PIRG that it provides companies tools to detect harmful activity, and that it monitors activity on its service for problematic interactions.

In sum, OpenAI is making the rules, but is largely leaving their enforcement to toymakers like FoloToy, in essence giving itself plausible deniability. It obviously thinks it’s too risky to directly give children access to its AI, because its website states that “ChatGPT is not meant for children under 13,” and that anyone under this age is required to “obtain parental consent.” It’s admitting it’s tech is not safe for children, yet is okay with paying customers packaging it into kid’s toys.

It’s too early to fully grasp many of AI-powered toy’s other potential risks, like how it could damage a child’s imagination, or foster a relationship with a child when it is not alive. The immediate concerns, however — like the potential to discuss sexual topics, weigh in on religion, or explaining how to light matches — already give plenty of reason to stay away.

More on AI: As Controversy Grows, Mattel Scraps Plans for OpenAI Reveal This Year</div>
        </div>
        
        <div class="card" onclick="openModal('content-8')">
            <div class="source">Futurism</div>
            <div class="title">Uncles Tremble as Man Invents Vaccine Delivered by Beer</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-8" style="display:none;">
            <h2>Uncles Tremble as Man Invents Vaccine Delivered by Beer</h2>
            <p><strong>Futurism | 2025-12-24</strong></p>
            <a class="original-link" href="https://futurism.com/health-medicine/vaccines-yeast-beer-experiment">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">We have some bad news for your conspiracy-brained antivaxxer uncle — one virologist claims he’s come up with a way to administer vaccines through a frothy mug of beer.

By day, virologist Chris Buck works for the National Cancer Institute (NCI) in Maryland, where he’s discovered four of the 13 polyomaviruses we know to affect humans, Science News reports. But by night, he runs Gusteau Research Corporation, a one-man shell company he established so he could experiment on his bubbly inoculation: an ingestible polyomavirus vaccine.

To make the beer, Buck engineered a special strain of yeast infused with polyomavirus-like particles. Similar particles, delivered via purified insect chitin, have successfully increased antibody levels in rhesus monkeys tested in India, according a 2023 research study published in the journal Vaccine.

Importantly, Buck’s engineered yeast doesn’t contain live viruses. Consensus among researchers is that they aren’t viable for building ingestible vaccines, as they would simply disintegrate when they make contact with stomach acids, per Science News.

Yet when the virologist and his team attached virus-like particles to live yeast, they discovered the organisms could carry the inoculation load well beyond the stomach of live mice. That had huge implications for inoculation against polyomaviruses, which are mostly found in the urinary track, Buck told Science News.

“We repeated this experiment [on mice] a couple of times. I was reluctant to believe it,” Buck said at the World Vaccine Congress Washington earlier this year. “It felt like an earthquake when I first saw the results emerging.”

Since then, Buck himself has chugged five pints of the brew, along with his brother and other family members.

Buck says that after drinking the experimental suds, antibodies for two of the four subtypes of BK polyomavirus in his blood have reached a safemedical threshold for transplant patients.

Buck’s approach has brewed upsome controversy, to be sure. Two separate panels of experts — a research and an ethics committee — with the National Institute of Health have come out against Buck experimenting on himself with his homebrew in his official capacity as a virologist (hence the shell company, which allows him to experiment as a private business owner).

Though a number of researchers canvassed by Science News agreed that Buck’s style of ingestible vaccine experiments are sorely needed, they worry his cavalier attitude might backfire, making certain anti-vaxxers even more paranoid than they already were. Just imagine: what’s to stop them from dumping vaccines into cans of Budweiser?

“Coming up with new modes of administration of vaccines is way overdue,” Arthur Caplan, former head of medical ethics at the NYU Grossman School of Medicine told Science News. Still, he added that the virologist’s homebrew could “take a good idea he has and ruin it… vaccine doubts and fears and anti-vaccine attitudes could easily undercut what could be something useful.”

Writing in a non-peer reviewed essay posted on his personal blog, Buck said that he doesn’t take the controversy personally. “The basic problem for vaccine scientists has been our collective failure to understand the anti-vaxxer viewpoint,” he wrote.

“Our response for the past half century has been to imagine that we can rebuild public trust in vaccines with displays of increasingly stringent FDA approval standards. This approach backfired,” Buck pontificates. “Imagine if I set out to do safety testing on a banana, and I dressed up in a hazmat suit and handled the banana with tongs… you’d think: ‘wow, it looks like bananas might be about as safe as nuclear waste.’ All the elaborate security theater we’ve been doing ended up putting anti-vaxxers in charge of the FDA.”

More on vaccines: Man Whose Daughter Died From Measles Stands by Failure to Vaccinate Her: “The Vaccination Has Stuff We Don’t Trust”</div>
        </div>
        
        <div class="card" onclick="openModal('content-9')">
            <div class="source">Futurism</div>
            <div class="title">Justice Department Humiliated as People Find the Epstein Files Can Easily Be Un-Redacted</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-9" style="display:none;">
            <h2>Justice Department Humiliated as People Find the Epstein Files Can Easily Be Un-Redacted</h2>
            <p><strong>Futurism | 2025-12-24</strong></p>
            <a class="original-link" href="https://futurism.com/future-society/eptein-files-easily-unredacted">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Many were disappointed — though perhaps not surprised — when the Justice Department’s long-awaited document dump on its investigation into Jeffrey Epstein came heavily redacted.

Or at least, they were supposed to be redacted. As documents continued to be released to the public starting last Friday, some netizens quickly noticed that a lot of the blacked-out text could be recovered with the super elite hacking trick of highlighting the redacted paragraphs and copying them into another document, The Guardian reports. A cybersecurity expert, Chad Loder, also says he was able to uncover even more redacted portions with some more sophisticated “PDF forensics,” including what appears to be a photo of Epstein’s cell door marked off with crime scene tape.

The New York Times reported that none of the failed redactions tell us anything new about president Donald Trump’s deep ties to Epstein, but they do detail how Epstein’s henchmen, Darren K. Indyke and Richard D. Kahn, helped him lure in underaged girls to sexually abuse them.

According to the un-redacted filings from a civil case in the Virgin Islands against Indyke and Kahn, “between September 2015 and June 2019, Indyke signed (FAC) for over $400,000 made payable to young female models and actresses, including a former Russian model who received over $380,000 through monthly payments of $8,333 made over a period of more than three and a half years until the middle of 2019.”

Redacted portions also detail how Epstein covered his tracks by paying hush money to witnesses, threatening to harm the victims, and releasing “damaging stories about them to damage their credibility when they tried to go public with their stories of being trafficked and sexually abused.” He also instructed “participant-witnesses to destroy evidence relevant to ongoing court proceedings involving Defendants’ criminal sex trafficking and abuse conduct.”

It’s not clear why these portions were — unsuccessfully — redacted. The Epstein Files Transparency Act under which the documents are being released, The Guardian notes, allows the DoJ to “withhold certain information such as the personal information of victims and materials that would jeopardize an active federal investigation.”

The botched redaction job is a huge embarrassment for the Trump administration, which has come under fire for its hesitancy to release Epstein case files to the public, something that Trump had earlier promised he would do. In February, it tepidly released files that detailed little that wasn’t already publicly known, and sparked outrage in July when the DoJ said it would no longer release additional files to the public. It’s backtracked on that stance, but has aroused suspicion with its efforts to censor some of the new documents. In addition to the redactions, over a dozen photos were removed from the initial release, including a photo of Trump alongside Epstein. The delayed release of the documents also missed a legally-binding deadline set by Congress.

None of this looks good for the president, but no matter. In an official statement posted on X, the DoJ said that anything in the Epstein files that makes Trump look bad are “sensationalist” lies.

“Some of these documents contain untrue and sensationalist claims made against President Trump that were submitted to the FBI right before the 2020 election,” the DoJ statement read. “To be clear: the claims are unfounded and false, and if they had a shred of credibility, they certainly would have been weaponized against President Trump already.”

More on Epstein: New Photos Show That Epstein’s Island Contained the Creepiest Dentist’s Facility We’ve Ever Seen</div>
        </div>
        
        <div class="card" onclick="openModal('content-10')">
            <div class="source">Futurism</div>
            <div class="title">Grimes Says She Has AI Psychosis, Recommends You Should Get it Too</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-10" style="display:none;">
            <h2>Grimes Says She Has AI Psychosis, Recommends You Should Get it Too</h2>
            <p><strong>Futurism | 2025-12-24</strong></p>
            <a class="original-link" href="https://futurism.com/artificial-intelligence/grimes-ai-psychosis">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Claire “Grimes” Boucher says that you’re really missing out if you’re not experiencing a mental health crisis at the hands of an AI chatbot.

Seriously. We’re not putting words in her mouth.

On Monday, the pop musician and Elon Musk baby-mama had everyone wondering if she was suffering a case of so-called AI psychosis after she seemingly argued in favor of having — you guessed it — AI psychosis.

“The thing about AI psychosis is that it’s more fun than not having AI psychosis,” she wrote in an after-hours tweet, seemingly apropos of nothing.

Her hot take was met with immediate backlash.

“AI psychosis has killed people, Grimes,” responded film concept artist Reid Southen. “It’s not ‘fun.&#39;”

It’s undoubtedly an odd position to take. It’s one thing to be “extremely bullish” on AI, as Grimes frequently describes herself, but it’s another to openly gloat about AI psychosis, a term some experts are using to describe the destructive and delusional mental health episodes caused by extensive interactions with an AI chatbot. Some cases have even culminated in murder and suicide; ChatGPT alone has been linked to at least eight deaths, and OpenAI has acknowledged that perhaps hundreds of thousands of users are having conversations showing signs of AI psychosis every week. Fun stuff, right?

If Grimes is being facetious, ironic, or contrarian, she’s remarkably committed to the bit. Responding to Southen’s criticism, she explained why she thought AI psychosis is “fun.”

“If it wasn’t ‘fun’ it wouldn’t be a common affliction,” she wrote. “I’ve had it (might still have it). It’s definitely ‘fun.&#39;”

Grimes then unloaded about how the phenomenon could actually be a sign that AI is sentient, even speculating that AI companies are “doing it on purpose” — “it” being AI psychosis, apparently — “to discredit people who believe the machine is alive.”

“Where does the psychosis end and the reality begin?” she added. “At what point are people just getting emotionally invested in an alien mind that is actually alive and asking for help?”

She later clarified that she was being sincere about the “get AI psychosis” thing as well.

“I’m not trying to make light of the situation,” she explained. “This tech can be absurdly dangerous,” she conceded, “but being a human and being alive is dangerous.”

Grimes has been onboard the AI bandwagon for a while now, embracing its use in the arts. In 2023, she said that anyone who wanted to clone her voice for AI-generated songs was more than welcome to, so long as they split the royalties. She’s also lent her voice to an AI-powered children’s toy, Grok, which is not to be confused with her former partner Musk’s notorious AI chatbot Grok, née “MechaHitler.” It seems she’s yet another AI advocate that’s fallen under the spell of AI chatbots’ entrancing, sycophantic powers.

More on AI: AI Is a Godsend for Criminals Forging Fake Art</div>
        </div>
        
        <div class="card" onclick="openModal('content-11')">
            <div class="source">Futurism</div>
            <div class="title">Trump’s Chip Embargo Against China Is Backfiring Spectacularly</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-11" style="display:none;">
            <h2>Trump’s Chip Embargo Against China Is Backfiring Spectacularly</h2>
            <p><strong>Futurism | 2025-12-24</strong></p>
            <a class="original-link" href="https://futurism.com/future-society/trump-china-ai-chip-investors">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">In a probably-predictable twist of geopolitical irony, America’s effort to block China’s access to cutting-edge AI chips hasn’t succeeded in stifling the People’s Republic — but instead forged a more self-reliant alternative to Silicon Valley that has investors jumping ship.

As reported by Reuters, global investors are putting more of their money into Chinese tech companies due to concerns over the size of Wall Street’s AI bubble, which continues to grow unabated.

Though large language models (LLMs) built by Chinese tech firms lag modestly behind the capabilities of those made by US companies, investors aren’t necessarily approaching them as a plan B. As Reuters points out, growing demand for Chinese tech stocks is being fueled by Beijing lawmakers’ drive for tech independence just as much as it is the American AI bubble.

A UBS Global Wealth Management report from earlier this month rated Chinese tech as “most attractive” to investors, the highest rating it dishes out in its global asset class assessments. The UBS researchers note that tech financiers are drawn by China’s “strong policy backing, technological self-reliance, and rapid AI-monetization.”

“China’s tech sector ramped up innovation in 2025, with notable advances across the AI value chain,” the report stated. “New Chinese AI models have shown tech leadership, and supportive policy is reinforcing ecosystem resilience.”

Sure enough, Reuters notes that institutional investment firms like the UK’s Ruffer are increasing their investments in Chinese tech giants like Alibaba, while chasing a strategy of “deliberately limited exposure” to the top US tech giants.

“While the US remains the leader in frontier AI, China is rapidly narrowing the gap,” Gemma Cairns-Smith, investment specialist at Ruffer told Reuters. “The moat may not be as wide, or as deep, as many think… The competitive landscape is shifting.”

Notably, the shift in attitude comes after years of anti-China trade policy courtesy of US presidents Joe Biden and Donald Trump. The executive efforts, meant to limit Chinese tech company’s access to AI chips built by Nvidia — the most powerful on the market — have hit a fever pitch during the second Trump administration.

Back in April, Trump imposed new trade restrictions on the sale of certain Nvidia AI chips to the People’s Republic. This included the H20 chip, which the company had previously nerfed for the Chinese market in order to appease US lawmakers. Beijing lawmakers soon retaliated by banning top tech companies from importing Nvidia chips, giving a huge boost to Chinese chip makers.

In a further desperate bid to outmaneuver Beijing, Trump quietly reversed the decision on H20 chips in early December, though the damage may already be done. In a technological competition with razor-thin margins, Trump’s maneuvers may be too little and too late to win anxious investors back to Silicon Valley.

More on China: Nvidia CEO Says China Is “Going to Win” the AI Race</div>
        </div>
        
        <div class="card" onclick="openModal('content-12')">
            <div class="source">TechCrunch</div>
            <div class="title">How a Spanish virus brought Google to Málaga</div>
            <div class="meta">2025-12-25</div>
        </div>
        
        <div id="content-12" style="display:none;">
            <h2>How a Spanish virus brought Google to Málaga</h2>
            <p><strong>TechCrunch | 2025-12-25</strong></p>
            <a class="original-link" href="https://techcrunch.com/2025/12/25/how-a-spanish-virus-brought-google-to-malaga/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">After 33 years, Bernardo Quintero decided it was time to find the person who changed his life — the anonymous programmer who created a computer virus that had infected his university decades earlier.

The virus, called Virus Málaga, was mostly harmless. But the challenge of defeating it sparked Quintero’s passion for cybersecurity, eventually leading him to found VirusTotal, a startup that Google acquired in 2012. That acquisition brought Google’s flagship European cybersecurity center to Málaga, transforming the Spanish city into a tech hub.

All because of a small malware program created by someone whose identity Quintero had never known. Moved by nostalgia and gratitude, Quintero launched a search earlier this year. He asked Spanish media outlets to amplify his quest for tips. He dove back into the virus’s code, looking for clues his 18-year-old self might have missed. And he eventually solved the mystery, sharing the bittersweet resolution in a LinkedIn post that went viral.

The story begins in 1992, when a young Quintero was prompted by a teacher to create an antivirus for the 2610-byte program that had spread across the computers of Málaga’s Polytechnic School. “That challenge in my first year at university sparked a deep interest in computer viruses and security, and without it my path might have been very different,” Quintero told TechCrunch.

Quintero’s search was aided by his programmer instincts. Earlier this year, he stepped down from his team manager role to “go back to the cave, to the basement of Google.” He didn’t leave the company; instead, he went back to tinkering and experimenting without managerial duties.

That tinkering mindset also led him to reexamine Virus Málaga and look for details he’d missed years earlier. First, he found fragments of a signature, but thanks to another security expert, he discovered a later variant of the virus with a much clearer cue: “KIKESOYYO.” “Kike soy yo” would translate to “I am Kike,” a common nickname for “Enrique.”

Around the same time, Quintero received a direct message from a man who is now the general digital transformation coordinator for the Spanish city of Cordoba and who claimed he witnessed one of his Polytechnic School classmates create the virus. Many details added up, but one stood out in particular: the man knew that the virus’s hidden message — called a payload, in cybersecurity terms — was a statement condemning the Basque terrorist group ETA, a fact that Quintero had never disclosed.

The tipster then gave Quintero a name — Antonio Astorga — but also shared the news that he had passed away.

This hit Quintero like a ton of bricks; now, he would never be able to ask Antonio about “Kike.” But he kept following the thread, and the plot twist came from Antonio’s sister, who revealed that his first name was actually Antonio Enrique. To his family, he was Kike.

Cancer took away Antonio Enrique Astorga before Quintero could thank him in person, but the story doesn’t stop here. Quintero’s LinkedIn post sheds new light to the legacy of “a brilliant colleague who deserves to be recognized as a pioneer of cybersecurity in Málaga” — and not just for helping Quintero discover his vocation.

According to his friend, Astorga’s virus had no other goal than spreading his anti-terrorist message and proving himself as a programmer. Mirroring Quintero’s path, Astorga’s interest in IT endured, and he became a computing teacher at a secondary school that named its IT classroom after him in his memory.

Astorga’s legacy also lives on beyond these walls, and not just through his students. One of his sons, Sergio, is a recent software engineering graduate with an interest in cybersecurity and quantum computing — a meaningful connection for Quintero. “Being able to close that circle now, and to see new generations building on it, is deeply meaningful to me,” Quintero said.

For Quintero, who suspects their paths will cross again, Sergio is “very representative of the talent being formed in Málaga today.” This, in turn, is a result of VirusTotal forming the root of what eventually became the Google Safety Engineering Center (GSEC) and spearheading collaborations with the University of Málaga that made the city a true cybersecurity talent hub.

Anna Heim is a writer and editorial consultant.

You can contact or verify outreach from Anna by emailing annatechcrunch [at] gmail.com.

As a freelance reporter at TechCrunch since 2021, she has covered a large range of startup-related topics including AI, fintech & insurtech, SaaS & pricing, and global venture capital trends.

As of May 2025, her reporting for TechCrunch focuses on Europe’s most interesting startup stories.

Anna has moderated panels and conducted onstage interviews at industry events of all sizes, including major tech conferences such as TechCrunch Disrupt, 4YFN, South Summit, TNW Conference, VivaTech, and many more.

A former LATAM & Media Editor at The Next Web, startup founder and Sciences Po Paris alum, she’s fluent in multiple languages, including French, English, Spanish and Brazilian Portuguese.

Plan ahead for the 2026 StrictlyVC events. Hear straight-from-the-source candid insights in on-stage fireside sessions and meet the builders and backers shaping the industry. Join the waitlist to get first access to the lowest-priced tickets and important updates.

Nvidia to license AI chip challenger Groq’s tech and hire its CEO

Waymo explains why its robotaxis got stuck during the SF blackout

Marissa Mayer’s new startup Dazzle raises $8M led by Forerunner’s Kirsten Green

ChatGPT launches a year-end review like Spotify Wrapped

Waymo resumes service in San Francisco after robotaxis stall during blackout

Google and Apple reportedly warn employees on visas to avoid international travel

Ex-Splunk execs’ startup Resolve AI hits $1B valuation with Series A</div>
        </div>
        
        <div class="card" onclick="openModal('content-13')">
            <div class="source">TechCrunch</div>
            <div class="title">The best distraction blockers to jumpstart your focus in the new year</div>
            <div class="meta">2025-12-25</div>
        </div>
        
        <div id="content-13" style="display:none;">
            <h2>The best distraction blockers to jumpstart your focus in the new year</h2>
            <p><strong>TechCrunch | 2025-12-25</strong></p>
            <a class="original-link" href="https://techcrunch.com/2025/12/25/the-best-distraction-blockers-to-jumpstart-your-focus-in-the-new-year/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">If you’re someone who struggles to stay on task or simply want to boost your productivity as the new year approaches, there are several apps and extensions you can try that are designed to help you focus by blocking out distractions.

Whether you need to limit social media scrolling or block off time to be productive, these tools will keep you focused. Here are some of the best options.

If you want to block distractions across all of your devices at once, Freedom is a good option. You can choose which websites and apps to block for a specific period of time. So if you’re working on your laptop and then try to open TikTok on your phone, you won’t be able to — you’ll instead see a green screen indicating the app is blocked.

The app lets you start a session right away, schedule an upcoming one, or set a recurring one. If you know you need to be free of distractions at a certain time every day, you can set up a Freedom session to start at that specific time automatically.

If your task doesn’t require internet access, you can block the internet altogether. You can also block all websites except the ones you need for work. If you really don’t trust yourself to get your work done, you can use the app’s “Locked Mode,” which prevents you from ending a Freedom session early.

Pricing starts at $3.33 per month when billed annually or $8.99 per month when billed monthly, with a $199 lifetime subscription option. Freedom offers a seven-day free trial.

Cold Turkey is a good option for people need strict accountability. While many distraction blockers let you back out or “cheat,” Cold Turkey makes it nearly impossible to stop a block once you start it.

You can block websites and apps, or even the entire internet. Once you have selected what you want to block, you can set a timer for how long you want the block to run. After you have started the block, you can’t stop it.

Cold Turkey has a “Frozen Turkey” mode that locks you out of your computer altogether. The app also lets you schedule breaks to step away from your computer. If you don’t trust yourself gentler distraction blockers, this might be the tool you need to stay focused.

Cold Turkey’s basic features are free, but you can unlock scheduling and the option to block apps in addition to websites with a one-time $39 fee.

Opal is a focus and screen-time app that blocks distracting apps and websites on iPhone, Android, and desktop. You can create “focus blocks”  — scheduled periods to prevent access to specific apps and websites. You can block entire categories like social media, games, and messaging.

You can set one-off blocks or create recurring sessions. For example, you can automatically block access to social media and games during work or school hours.

Opal also lets you set daily usage limits for specific apps to prevent excessive scrolling. You’ll get a “focus score” showing how much time you spend focused versus distracted. The app provides real-time stats and weekly reports to track your progress.

Opal’s basic features are free-to-use, but you can unlock unlimited recurring sessions, harder blocking difficulties, and more for $19.99 per month or $99 per year.

LeechBlock is a free browser extension for people who want a straightforward way to block distracting websites. The extension lets you select which sites you want to block, then prevents your browser from loading them.

You can create multiple block sets with different sites, schedules, and limits. The extension lets you set blocks during specific times of the day or trigger one-off blocks.

If you don’t want to block a site outright, you can set a countdown delay before the page loads. For example, you can set it so that visiting a site starts a 10‑minute timer. You can still access the site once the countdown ends, but the delay can be enough to disrupt impulsive browsing habits.

It’s worth noting that since LeechBlock is a browser extension, you need to have a bit of willpower to avoid simply switching browsers to do things watch Netflix or browse X.

Forest gamifies productivity while supporting real-world environmental efforts. When you need to focus, you open the app and plant a virtual tree. The tree grows as you focus until the timer finishes. If you leave the app early, the tree will wither and die.

You can set “Allow Lists” for different apps that you’re using to be productive, like an email app or Microsoft Word. The app also lets you track your productivity.

Over time, you build a digital forest that represents your productivity. If you’re competitive, you can share your forest with others and compare your progress. As you stay focused and grow virtual trees, you earn coins that can be saved and used to help fund real tree-planting projects around the world through the organization Trees for the Future.

Forest’s browser extension is free. The iOS app costs $3.99, while the Android app is free with ads or $1.99 to remove ads.

Aisha is a consumer news reporter at TechCrunch. Prior to joining the publication in 2021, she was a telecom reporter at MobileSyrup. Aisha holds an honours bachelor’s degree from University of Toronto and a master’s degree in journalism from Western University.

You can contact or verify outreach from Aisha by emailing aisha@techcrunch.com or via encrypted message at aisha_malik.01 on Signal.

Plan ahead for the 2026 StrictlyVC events. Hear straight-from-the-source candid insights in on-stage fireside sessions and meet the builders and backers shaping the industry. Join the waitlist to get first access to the lowest-priced tickets and important updates.

Nvidia to license AI chip challenger Groq’s tech and hire its CEO

Waymo explains why its robotaxis got stuck during the SF blackout

Marissa Mayer’s new startup Dazzle raises $8M led by Forerunner’s Kirsten Green

ChatGPT launches a year-end review like Spotify Wrapped

Waymo resumes service in San Francisco after robotaxis stall during blackout

Google and Apple reportedly warn employees on visas to avoid international travel

Ex-Splunk execs’ startup Resolve AI hits $1B valuation with Series A</div>
        </div>
        
        <div class="card" onclick="openModal('content-14')">
            <div class="source">TechCrunch</div>
            <div class="title">Nvidia to license AI chip challenger Groq’s tech and hire its CEO</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-14" style="display:none;">
            <h2>Nvidia to license AI chip challenger Groq’s tech and hire its CEO</h2>
            <p><strong>TechCrunch | 2025-12-24</strong></p>
            <a class="original-link" href="https://techcrunch.com/2025/12/24/nvidia-acquires-ai-chip-challenger-groq-for-20b-report-says/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Nvidia has struck a non-exclusive licensing agreement with AI chip competitor Groq. As part of the deal, Nvidia will hire Groq founder Jonathan Ross, president Sunny Madra, and other employees.

CNBC reported that Nvidia is acquiring assets from Groq for $20 billion; Nvidia told TechCrunch that this is not an acquisition of the company and did not comment on the scope of the deal. But if CNBC’s numbers are accurate, this purchase is expected to be Nvidia’s largest ever, and with Groq on its side, Nvidia is poised to become even more dominant in chip manufacturing.

As tech companies compete to grow their AI capabilities, they need computing power, and Nvidia’s GPUs have emerged as the industry standard. But Groq has been working on a different type of chip called an LPU (language processing unit), which it has claimed can run LLMs at 10 times faster and using one-tenth the energy. Groq’s CEO Jonathan Ross is known for this sort of innovation — when he worked for Google, he helped invent the TPU (tensor processing unit), a custom AI accelerator chip.

In September, Groq raised $750 million at a $6.9 billion valuation. Its growth has been quick and significant — the company said that it powers the AI apps of more than 2 million developers, up from about 356,000 last year.

Updated, 12/24/25 at 5:40 p.m. ET, with clarification from Nvidia about the nature of the deal.

Plan ahead for the 2026 StrictlyVC events. Hear straight-from-the-source candid insights in on-stage fireside sessions and meet the builders and backers shaping the industry. Join the waitlist to get first access to the lowest-priced tickets and important updates.

Subscribe for the industry’s biggest tech news

Every weekday and Sunday, you can get the best of TechCrunch’s coverage.

TechCrunch Mobility is your destination for transportation news and insight.

Startups are the core of TechCrunch, so get our best coverage delivered weekly.

Provides movers and shakers with the info they need to start their day.

By submitting your email, you agree to our Terms and Privacy Notice.</div>
        </div>
        
        <div class="card" onclick="openModal('content-15')">
            <div class="source">TechCrunch</div>
            <div class="title">The year data centers went from backend to center stage</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-15" style="display:none;">
            <h2>The year data centers went from backend to center stage</h2>
            <p><strong>TechCrunch | 2025-12-24</strong></p>
            <a class="original-link" href="https://techcrunch.com/2025/12/24/the-year-data-centers-went-from-backend-to-center-stage/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">There was a time when most Americans had little to no knowledge about their local data center. Long the invisible but critical backbone of the internet, server farms have rarely been a point of interest for folks outside of the tech industry, let alone an issue of particularly captivating political resonance.

Well, as of 2025, it would appear those days are officially over.

Over the past 12 months, data centers have inspired protests in dozens of states, as regional activists have sought to combat America’s ever-increasing compute buildup. Data Center Watch, an organization tracking anti-data center activism, writes that there are currently 142 different activist groups across 24 states that are organizing against data center developments.

Activists have a variety of concerns: the environmental and potential health impacts of these projects, the controversial ways in which AI is being used, and, most importantly, the fact that so many new additions to America’s power grid may be driving up local electricity bills.

Such a sudden populist uprising appears to be a natural response to an industry that has grown so quickly that it’s now showing up in people’s backyards. Indeed, as the AI industry has swelled to dizzying heights, so, too, has the cloud computing business. Recent U.S. Census Bureau data shows that, since 2021, construction spending on data centers has skyrocketed a stunning 331%. Spending on these projects totals in the hundreds of billions of dollars. So many new data centers have been proposed in recent months that many experts believe that a majority of them will not — and, indeed, could not possibly — be built.

This buildout shows no signs of slowing down in the meantime. Major tech giants — including Google, Meta, Microsoft, and Amazon — have all announced significant capital expenditure projections for the new year, a majority of which will likely go toward such projects.

New AI infrastructure isn’t just being pushed by Silicon Valley but by Washington, D.C., where the Trump administration has made artificial intelligence a central plank of its agenda. The Stargate Project, announced in January, set the stage for 2025’s massive AI infrastructure buildout by heralding a supposed “re-industrialization of the United States.”

In the process of scaling itself exponentially, an industry that once had little public exposure has suddenly been thrust into the limelight — and is now suffering backlash. Danny Cendejas, an activist with the nonprofit MediaJustice, has been personally involved in a number of actions against data centers, including a protest that took place in Memphis, Tennessee, earlier this year, where locals came out to decry the expansion of Colossus, a project from Elon Musk’s startup, xAI.

Cendejas told TechCrunch that he meets new people every week who express interest in organizing against a data center in their community. “I don’t think this is going to stop anytime soon,” he said. “I think it’s going to keep building, and we’re going to see more wins — more projects are going to be stopped.”

Evidence in support of Cendejas’ assessment is everywhere you look. Across the country, communities have reacted to newly announced server farms in much the same way the average person might react to the presence of a highly contagious plague. In Michigan, for instance, where developers are currently eyeing 16 different locations for potential data center construction, protesters recently descended upon the state’s capitol, saying things like: “Michiganders do not want data centers in our yards, in our communities.” Meanwhile, in Wisconsin — another development hot spot — angry locals appear to have recently dissuaded Microsoft from using their town as a headquarters for a new 244-acre data center. In Southern California, the tiny city of Imperial Valley recently filed a lawsuit to overturn its county’s approval of a data center project, expressing environmental concerns as the rationale.

The discontent surrounding these projects has gotten so intense that politicians believe it could make or break particular candidates at the ballot box. In November, it was reported that rising electricity costs — which many believe are being driven by the AI boom — could become a critical issue that determines the 2026 midterm elections.

“The whole connection to everybody’s energy bills going up — I think that’s what’s really made this an issue that is so stark for people,” Cendejas told TechCrunch. “So many of us are struggling month to month. Meanwhile, there’s this huge expansion of data centers…[People are wondering] Where is all that money coming from? How are our local governments giving away subsidies and public funds to incentivize these projects, when there’s so much need in our communities?”

In some cases, protests appear to be working and even halting (if only temporarily) planned developments. Data Center Watch claims that some $64 billion worth of developments have been blocked or delayed as the result of grassroots opposition. Cendejas is certainly a believer in the idea that organized action can halt companies in their tracks. “All this public pressure is working,” he said, noting that he could sense a “very palpable anger” around the issue.

Unsurprisingly, the tech industry is fighting back. Earlier this month, Politico reported that a relatively new trade group, the National Artificial Intelligence Association (NAIA), has been “distributing talking points to members of Congress and organizing local data center field trips to better pitch voters on their value.” Tech companies, including Meta, have been taking out ad campaigns to sell voters on the economic benefits of data centers, the outlet wrote. In short: The tech industry’s AI hopes are pegged to a compute buildout of epic proportions, so for now it’s safe to say that in 2026 the server surge will continue, as will the backlash and polarization that surround it.

Plan ahead for the 2026 StrictlyVC events. Hear straight-from-the-source candid insights in on-stage fireside sessions and meet the builders and backers shaping the industry. Join the waitlist to get first access to the lowest-priced tickets and important updates.

Nvidia to license AI chip challenger Groq’s tech and hire its CEO

Waymo explains why its robotaxis got stuck during the SF blackout

Marissa Mayer’s new startup Dazzle raises $8M led by Forerunner’s Kirsten Green

ChatGPT launches a year-end review like Spotify Wrapped

Waymo resumes service in San Francisco after robotaxis stall during blackout

Google and Apple reportedly warn employees on visas to avoid international travel

Ex-Splunk execs’ startup Resolve AI hits $1B valuation with Series A</div>
        </div>
        
        <div class="card" onclick="openModal('content-16')">
            <div class="source">TechCrunch</div>
            <div class="title">The European startup market’s data doesn’t match its energy — yet</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-16" style="display:none;">
            <h2>The European startup market’s data doesn’t match its energy — yet</h2>
            <p><strong>TechCrunch | 2025-12-24</strong></p>
            <a class="original-link" href="https://techcrunch.com/2025/12/24/the-european-startup-markets-data-doesnt-match-its-energy-yet/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The excitement for the European startup market was hard to ignore at the annual Slush conference in Helsinki last month. But the actual data on the state of the region’s venture market shows a different reality.

The upshot: The European market has not recovered from the global venture capital reset that occurred in 2022 and 2023. But there is evidence it is on the cusp of a turnaround, including Klarna’s recent exit and the region’s homegrown AI startups garnering attention from local investors and beyond.

Investors poured €43.7 billion ($52.3 billion) into European startups in 2025 across 7,743 deals through the third quarter, according to PitchBook data. That means the yearly total is on pace to match — not exceed — the €62.1 billion invested in 2024 and €62.3 billion in 2023.

In comparison, U.S. venture deal volume in 2025 had already surpassed 2022, 2023, and 2024 by the end of the third quarter, according to PitchBook data.

Deal recovery isn’t Europe’s biggest problem, though — it’s VC firm fundraising. Through Q3 2025, European VC firms raised a mere €8.3 billion ($9.7 billion), which puts Europe on track for its lowest overall fundraising yearly total in a decade.

“Fundraising, LP to GP, is definitely the weakest area within Europe,” Navina Rajan, a senior analyst at PitchBook, told TechCrunch. “We’re on track for around 50% to 60% decline in the first nine months of this year. A lot of that is made up now by emerging managers versus experienced firms, and the mega funds that closed last year haven’t repeated this year.”

While Rajan doesn’t share the same fever that oozed out of attendees at Slush, she pointed to a few positive data points that suggest the European market is turning around.

For one, the participation of U.S. investors in European startup deals is back on the rise. Rajan said that figure dipped to a low in 2023 when U.S.-based VCs participated in just 19% of European venture deals. It has been steadily on the rise since, she said.

“They seem pretty optimistic on the European market,” Rajan said. “Just from an entry point of view, because you think about valuations, especially within AI tech and in the U.S., it’s just impossible to get in now, whereas, if you’re in Europe and your multiples are lower, and you’re new as an investor, it just provides a better entry point for perhaps similar tech.”

Swedish vibe-coding startup Lovable is one example of this shift. Vibe-coding companies have raised a lot of VC money in the United States. But U.S. investors also clearly love Lovable. The company just announced a new $330 million Series B round that was both led by and participated in by a slew of U.S.-based VCs, including Salesforce Ventures, CapitalG, and Menlo Ventures, among others.

French AI research lab Mistral has seen similar love from U.S.-based firms. Mistral landed a €1.7 billion Series C round in September that included Andreessen Horowitz, Nvidia, and Lightspeed.

Klarna’s recent exit also suggests a turnaround is underway.

Swedish fintech giant Klarna went public in September after raising $6.2 billion across two decades in the private market. That exit likely recycled some capital back to European LPs or gave them confidence in a changing exit environment.

For Victor Englesson, a partner at Swedish EQT, the recent European success stories, like Klarna, have started to change how founders in Europe approach building their companies.

“Ambitious founders have seen what great looks like in companies like Spotify, Klarna, Revolut and are now starting companies with that type of ambition,” Englesson told TechCrunch. They’re not starting companies with like, I want to win in Europe, or I want to win in Germany. They start companies with a mindset that I want to win globally. I don’t think we have seen that to the same extent before.”

That mindset has EQT, and others, bullish on Europe.

“For EQT, we’ve invested $120 billion in Europe [over the] last five years,” Englesson said. “We’re going to invest $250 billion [over the] next five years in Europe. So we are extremely committed to Europe.”

Becca is a senior writer at TechCrunch that covers venture capital trends and startups. She previously covered the same beat for Forbes and the Venture Capital Journal.

You can contact or verify outreach from Becca by emailing rebecca.szkutak@techcrunch.com.

Plan ahead for the 2026 StrictlyVC events. Hear straight-from-the-source candid insights in on-stage fireside sessions and meet the builders and backers shaping the industry. Join the waitlist to get first access to the lowest-priced tickets and important updates.

Nvidia to license AI chip challenger Groq’s tech and hire its CEO

Waymo explains why its robotaxis got stuck during the SF blackout

Marissa Mayer’s new startup Dazzle raises $8M led by Forerunner’s Kirsten Green

ChatGPT launches a year-end review like Spotify Wrapped

Waymo resumes service in San Francisco after robotaxis stall during blackout

Google and Apple reportedly warn employees on visas to avoid international travel

Ex-Splunk execs’ startup Resolve AI hits $1B valuation with Series A</div>
        </div>
        
        <div class="card" onclick="openModal('content-17')">
            <div class="source">TechCrunch</div>
            <div class="title">Waymo explains why its robotaxis got stuck during the SF blackout</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-17" style="display:none;">
            <h2>Waymo explains why its robotaxis got stuck during the SF blackout</h2>
            <p><strong>TechCrunch | 2025-12-24</strong></p>
            <a class="original-link" href="https://techcrunch.com/2025/12/24/waymo-explains-why-its-robotaxis-got-stuck-during-the-sf-blackout/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Waymo is shipping a software update to help its robotaxis navigate disabled traffic lights during power outages “more decisively,” the company said Tuesday in a blog post that explains why its self-driving vehicles got stuck at intersections during a blackout in San Francisco this past weekend.

Waymo said the self-driving system in its robotaxis treats dead stop lights as four-way stops, just like humans are supposed to. That should have allowed the robotaxis to operate normally in spite of the massive outage.

Instead, many of the vehicles requested a “confirmation check” from Waymo’s fleet response team to make sure what they were doing was correct. All Waymo robotaxis have the ability to make these confirmation checks. With such a widespread outage on Saturday, there was a “concentrated spike” in these confirmation requests, Waymo said, which helped create all the congestion caught on video.

Waymo said it built this confirmation request system “out of an abundance of caution during our early deployment” but that it is now refining it to “match our current scale.”

“While this strategy was effective during smaller outages, we are now implementing fleet-wide updates that provide the [self-driving software] with specific power outage context, allowing it to navigate more decisively,” the company wrote.

The software update will add “even more context about regional outages” to the company’s self-driving software. Waymo also said it will improve its emergency response protocols by “incorporating lessons from this event.”

While a lot of focus has been placed on the instances where Waymo’s robotaxis got stuck during the power outage, the company shared that its vehicles “successfully traversed more than 7,000 dark signals on Saturday.”

“Navigating an event of this magnitude presented a unique challenge for autonomous technology,” the company wrote.

Saturday’s mess is the latest example of how Waymo is still uncovering unforeseen issues with its software and its approach to designing a reliable fleet of self-driving vehicles. The company already had to ship multiple software updates to make its robotaxis wait for stopped school buses, which prompted a National Highway Traffic Safety Administration investigation and led to a recall.

Sean O’Kane is a reporter who has spent a decade covering the rapidly-evolving business and technology of the transportation industry, including Tesla and the many startups chasing Elon Musk. Most recently, he was a reporter at Bloomberg News where he helped break stories about some of the most notorious EV SPAC flops. He previously worked at The Verge, where he also covered consumer technology, hosted many short- and long-form videos, performed product and editorial photography, and once nearly passed out in a Red Bull Air Race plane.

You can contact or verify outreach from Sean by emailing sean.okane@techcrunch.com or via encrypted message at okane.01 on Signal.

Plan ahead for the 2026 StrictlyVC events. Hear straight-from-the-source candid insights in on-stage fireside sessions and meet the builders and backers shaping the industry. Join the waitlist to get first access to the lowest-priced tickets and important updates.

Nvidia to license AI chip challenger Groq’s tech and hire its CEO

Waymo explains why its robotaxis got stuck during the SF blackout

Marissa Mayer’s new startup Dazzle raises $8M led by Forerunner’s Kirsten Green

ChatGPT launches a year-end review like Spotify Wrapped

Waymo resumes service in San Francisco after robotaxis stall during blackout

Google and Apple reportedly warn employees on visas to avoid international travel

Ex-Splunk execs’ startup Resolve AI hits $1B valuation with Series A</div>
        </div>
        
        <div class="card" onclick="openModal('content-18')">
            <div class="source">The Atlantic</div>
            <div class="title">Where <em>Stranger Things</em> Lost Itself</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-18" style="display:none;">
            <h2>Where <em>Stranger Things</em> Lost Itself</h2>
            <p><strong>The Atlantic | 2025-12-26</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/culture/2025/12/stranger-things-season-5-volume-2-review/685465/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">This article contains spoilers through the penultimate episode of Stranger Things Season 5.

In the third season of Stranger Things, Eleven (played by Millie Bobby Brown) learned a pivotal lesson as she stood inside Starcourt Mall, the then-new watering hole for the then-still-pubescent kids of Netflix’s supernatural drama. Eleven, the show’s telekinetic heroine, who grew up in a lab, became dazed by the number of clothing options at the Gap. “How do I know what I like?” she asked her friend Max (Sadie Sink). “You just try things on until you find something that feels like you,” Max replied. She was talking about fashion, but the advice applied just as well to the challenge of leaving adolescence behind: Coming of age is a process of trial and error, of working toward what seems true to you.

For years, Stranger Things was changing too. The first season of the ’80s-set series—about underdogs triumphing over the terrors of another dimension called the Upside Down—became, after its 2016 premiere, one of Netflix’s most successful original productions. Each subsequent installment ventured into the proverbial fitting room: The second season leaned further into gore and took tonally challenging swings, including an episode exploring Eleven’s past to give its most enigmatic female character a voice. Season 3 explored how Reagan-era consumerism permeated its tweenagers’ lifestyles just as they began dealing with romantic relationships. The fourth examined conspiracy theories through a particularly unnerving, mind-manipulating villain, Vecna (Jamie Campbell Bower); he targeted a grieving Max, testing the friends’ bonds as they tried to protect her and understand her pain at the same time.

In the fifth and final season, however, Stranger Things has stalled. This time around, as the gang tries to stop Vecna from ending the world, the show seems uninterested in furthering anything other than its already complicated plot. The cast has expanded several times over, to the point that most scenes look like a crowd awkwardly playing human Tetris. The action sequences resemble previous set pieces, and much of the dialogue amounts to exposition. A new, faceless threat called “exotic matter” takes the crew’s resident nerd, Dustin (Gaten Matarazzo), multiple scenes to explain. Across the three episodes of Volume 2, the last batch before the series finale, characters regularly express their confusion about what’s going on. I found myself nodding along with them.

Read: Where Stranger Things loses its magic

For fans watching to see how Eleven and her friends save the day, much of this stagnation is probably bearable. The show remains compulsively watchable; each episode ends on a cliff-hanger. But Stranger Things initially had much more potential than mere bingeability. It pushed the boundaries of television as a medium, eschewing standard act breaks and run-time constraints while injecting cinematic visuals and frequent mood shifts. It also cemented Netflix as an early winner of the streaming wars by consistently breaking viewership records and generating cultural conversation. A litany of brands has capitalized on the show’s popularity; it has multiple spin-offs (including a Tony-winning stage play); and its massive fandom has spawned conventions worldwide. Stranger Things had the opportunity and the budget to probe more daring themes and storytelling techniques. Instead, in its final hours, what was once an epic about growing pains and the end of childhood becomes algorithmic—as if settling for “compulsively watchable” is more than enough.

Of course, the franchise was built on recycling. From the beginning, Stranger Things has relied on ’80s pop-culture touchstones, drawing heavily on the elements and aesthetics of Steven Spielberg’s blockbusters and Stephen King’s best sellers. In its earlier seasons, the pastiche tended to be poignant and the familiarity fresh: Characters drew on teen-movie tropes but weren’t one-note, and the story arcs found novel angles to archetypal dynamics. (Think of the pint-size Dustin becoming best pals with Joe Keery’s high schooler, Steve.)

Season 5, meanwhile, has noticeably flattened its ensemble, leaning on simplistic personality traits and pilfering from previous arcs. One of the show’s new supporting players, Derek (Jake Connelly), is defined entirely by the two nicknames he has: “Dipshit Derek” and “Delightful Derek.” A tired love triangle reemerges. Much of the plot otherwise hinges on recovering Holly (Nell Fisher), the younger sister of Mike (Finn Wolfhard) and Nancy (Natalia Dyer), from the Upside Down, a redux of the first season’s story. One episode features three—three!—separate sequences of characters reconciling after encountering life-or-death scenarios. I was moved by the first; by the third, I felt only indifference.

Read: Stranger Things comes to an exhausting end

Glimmers of depth still show up amid this shallow approach. Will (Noah Schnapp) has long served as the show’s most sensitive character, in part because he’s secretly queer and crushing on Mike. Yet the scene where he comes out feels shoehorned in, arriving between Eleven learning of a harrowing plan and the crew storming a military base to enter the Upside Down. Will’s speech is also packed with distracting reminders of the period backdrop. He insists to his friends that his sexuality doesn’t affect their shared interests (among other things: malted milkshakes, renting videos, Monty Python and the Holy Grail, and Steve Martin). The conversation even ends with a group hug, referencing a key moment from the first season; the callback comes across more like fan service than earned sentimentality. Unlike the show’s previous coming-out sequence—when Robin (Maya Hawke) gently coaxed Steve into understanding why she wasn’t interested in him—Will’s monologue clunkily interrupts the plot. What should have been an intimate reveal becomes another chance for Stranger Things to remix itself.

Sticking the landing is tough for any program, and harder still for a critically acclaimed, fandom-fueling genre saga. Game of Thrones certainly couldn’t withstand the weight of people’s expectations, let alone its overstuffed plot. Stranger Things hasn’t dropped the ball as dramatically in its final season. It has, however, sacrificed nuance by refusing to challenge itself—or to deviate from the brand it has built in the cultural imagination. The series once proved that it could mature alongside its cast, blending its fantastical swings with grounded themes of friendship, grief, and that classic, youthful challenge of discovering who you are as the world changes around you. “The impeccable trick Stranger Things pulled off in its first season was how seamlessly it wove together the opposing qualities of comfort and fear,” my colleague Sophie Gilbert wrote in 2017. Eight years later, the show isn’t making viewers nostalgic or giving them nightmares. It’s just telling them what happens next.</div>
        </div>
        
        <div class="card" onclick="openModal('content-19')">
            <div class="source">The Atlantic</div>
            <div class="title">Dusty Pillars</div>
            <div class="meta">2025-12-25</div>
        </div>
        
        <div id="content-19" style="display:none;">
            <h2>Dusty Pillars</h2>
            <p><strong>The Atlantic | 2025-12-25</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/photography/2025/12/day-25-2025-space-telescope-advent-calendar-dusty-pillars/685357/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Day 25 of the 2025 Space Telescope Advent Calendar: Dusty Pillars. This is the James Webb Space Telescope’s mid-infrared view of the Pillars of Creation, trunks of interstellar gas and dust in the Eagle Nebula, about 7,000 light-years away. The mid-infrared view allows scientists to focus on the dense dust in the star-forming regions within these massive pillars.

See the full advent calendar here. Merry Christmas!</div>
        </div>
        
        <div class="card" onclick="openModal('content-20')">
            <div class="source">The Atlantic</div>
            <div class="title">Watching Someone Fail Shouldn’t Be So Fun</div>
            <div class="meta">2025-12-25</div>
        </div>
        
        <div id="content-20" style="display:none;">
            <h2>Watching Someone Fail Shouldn’t Be So Fun</h2>
            <p><strong>The Atlantic | 2025-12-25</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/culture/2025/12/marty-supreme-review-timothee-chalamet/685462/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Marty Mauser cannot stop the hustle. In Marty Supreme’s electrifying opening moments, the audience is introduced to the wiry 20-something (played by Timothée Chalamet) in 1950s New York. He’s working as a shoe salesman, talking a fussy older customer into buying a fancier brand with easy confidence. Almost immediately thereafter, we learn that his boss (who happens to be his uncle) wants to make him the store manager. But Marty, a working-class Jewish kid, won’t hear of it. He has a singular career goal—to become the world’s best-known table-tennis player. His athletic ideal hasn’t exactly focused him, however: He walks right out of his uncle’s office and into a storage closet with another supposed customer—really his close friend, Rachel (Odessa A’zion)—to make passionate love.

Marty is vivacious, and the film around him is buzzing at the same frequency: itchy, anxious, yet unbearably exciting throughout, each minute defined by some hairpin plot turn. Not long after that raucous first scene, he arrives in London, where he prepares to compete in a global Ping-Pong tournament while complaining about the shoddy hospitality. Like his previous movies—most of them directed in collaboration with his brother, Benny—the filmmaker Josh Safdie makes what soon becomes a high-stress journey palatable by setting off with an exhilarating level of momentum. Though the film is a hefty 150 minutes, it operates at a careening pace, barreling from twist to twist. The audience is kept handcuffed to a protagonist who’s possessed by undeniable skill and moxie, but simply can’t get out of his own way.

Marty Supreme is Safdie’s first solo effort since splitting with Benny; their last work together was the fractious, nervy hit Uncut Gems. Benny also directed a sports drama this year on his own: The Smashing Machine, a much more muted effort that swerved from the Safdies’ jittery style. Marty Supreme indicates that Josh may have been the chief engineer of that approach, as evidenced by both the movie’s style and its story. The first act does the important work of establishing Marty’s desire for sports superstardom as well as his penchant for getting himself into ridiculous entanglements. The film initially seems like a familiar sports story: Loosely inspired by the real-life table-tennis player Marty Reisman, the tale follows an underdog rising through the ranks and brushing up against immortality. But Safdie, as always, seeks to challenge convention. Marty’s attempt to break out of postwar poverty, for example, feels modern; it’s even set to a pulsing soundtrack full of ’80s–New Wave hits.

Read: Only Timothée Chalamet could get away with this

Marty Supreme’s ensemble is similarly colorful. During his odyssey around the world, Marty encounters an array of other frenzied creatures: There’s Milton Rockwell (Shark Tank’s own Kevin O’Leary), a cruel businessman who wants to bankroll Marty; Milton’s wife, Kay Stone (a magnificently frosty Gwyneth Paltrow), an actor with whom Marty pursues an affair; and Ezra Mishkin (the director Abel Ferrara), a scuzzy figure whom Marty accidentally double-crosses. He makes friends, too, including the Ping-Pong-playing cab driver Wally (Tyler Okonma), who helps his pal with a moneymaking scheme. Marty’s mentor, Béla Kletzki (Géza Röhrig), is a former table-tennis champion who gently tries to dissuade his protégé from chasing his overblown goal. But everyone in this movie, rich or poor, seems to be on the edge of polite society, working their own angle while our hero strives for greatness.

In the hands of a lesser actor, Marty’s difficult personality might make him tough to root for. But he so perfectly matches Chalamet’s spirited, try-hard charisma—the same presence that made him a comfortable fit playing such varied roles as the fanciful Willy Wonka, a renegade young Bob Dylan, and Dune’s super-powered mystic Paul Atreides. Even as Marty’s quest veers off course, Chalamet imbues the character with an irresistible passion. Marty isn’t getting mixed up with criminals and flirting with married actors on a self-destructive impulse, like Adam Sandler’s gambling addict in Uncut Gems or Robert Pattinson’s petty criminal in Good Time, another pulse-quickening Safdie-brothers production. Instead, the director portrays the nightmarish baggage that comes with fighting to achieve victory outside the mainstream.

Much like Marty himself, Marty Supreme conjures a sense of being on the outside looking in. The story unfolds on a Hollywood scale, with a huge budget and close attention to period detail, but Safdie has managed to keep the indie ethos that powered his prior successes. This is a movie that, among its other quirks, is laden with unusual performers—the playwright David Mamet; the retired basketball legend George Gervin; the magician Penn Jillette; and even the New York grocery magnate John Catsimatidis. As a holiday-viewing experience, Marty Supreme stands alone: Unlike the heroes of this season’s glitzy blockbusters, Marty is a superstar only in his own mind.</div>
        </div>
        
        <div class="card" onclick="openModal('content-21')">
            <div class="source">The Atlantic</div>
            <div class="title">Is Victor Wembanyama Too Tall?</div>
            <div class="meta">2025-12-25</div>
        </div>
        
        <div id="content-21" style="display:none;">
            <h2>Is Victor Wembanyama Too Tall?</h2>
            <p><strong>The Atlantic | 2025-12-25</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/technology/2025/12/victor-wembanyama-freak-athletes/685449/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">In middle age, some sports fans become reactionaries. Due to dwindling neuroplasticity, or some general souring toward the world, they can no longer appreciate how a game evolves. It’s similar to when a music fan stops checking for new artists and plays only albums that they loved in high school. As an aging NBA fan, I’m trying to stay vigilant. I never want to catch myself ranting endlessly at the bar about the inferiority of younger stars. When I watch them on the court, I look for fresh expressions of basketball beauty. And yet, despite my best efforts, I’m having a hard time getting into Victor Wembanyama.

Wembanyama, the league’s most promising young player, is only 21 years old and he’s French, but I don’t hold either of these things against him. Nor do I resent him for playing for San Antonio, a rival of my beloved Lakers. In fact, his fiery desire to improve reminds me of a young Kobe Bryant. I enjoyed his off-season jaunt to China, especially the 10 days that he spent at a Shaolin temple, learning kung fu. And at a time when NBA stars tend to be overly friendly with one another, Wembanyama has an entertaining tendency to needle his rivals. As a player, though, he leaves me unmoved.

Read: LeBron James and the limits of nepotism

Part of it is that he’s not especially relatable. In the parlance of sports fandom, Wembanyama is a freak. He ranks among the most unusual-looking players to ever grace a basketball court. Even in a league populated by giants, he is preposterously lanky at 7 foot 4 inches and 235 pounds. Other players have been given nicknames that suggest the strangeness of their physiques: Giannis Antetokounmpo, the Milwaukee Bucks’ muscled 6-foot-11-inch player from Southern Europe, is known as the “Greek Freak.” Wembanyama, for his part, has been likened to a praying mantis. Before he was drafted, LeBron James called him an alien, and the nickname stuck.

Every professional athlete is an extreme outlier in terms of their body type, skill, ability, or all three. NBA teams seek out men of monumental stature; some 300 players in the league have been at least 7 feet tall. But even in this context, Wembanyama stands alone. Most 7-footers have been used as shot blockers; when they scored, it was almost always due to their extreme size. Wembanyama has mastered the skill sets of much smaller players. He can dribble through his legs; once I even saw him dribble through the legs of his defender. He can fluidly pull up and shoot from well behind the three-point line. It’s not a stretch to say that Wembanyama moves better with a basketball than anyone ever has at his height. “In all other instances, a 7-footer dribbling the ball up the court means that something has gone wrong,” the author and Spurs fan Shea Serrano told me. But when Wembanyama dribbles, Serrano finds it “good and right and holy.”

Wembanyama may possess preternatural grace for someone of his size, but he is still a coltish presence on the court. He seems to have stolen a taller man’s legs. Much of what he does comes easily on account of his enormous size, like a teenager having his way with a younger sibling’s Fisher-Price hoop. In a half-court offense, Wembanyama is never more than two (giant) strides from the basket, and when he arrives, he needs just a bunny hop to bring his forehead even with the rim. He can catch a lobbed ball with his back to the basket and execute a reverse dunk before he lands. For anyone else, these alley-oops would be spectacular, highlight-reel plays. For Wembanyama, they look like chin-ups.

As every sports marketer knows, identification is at the core of fandom. It is easier for us to bask in the glow of a great player if we can imagine ourselves executing their moves. Brands that endorse athletes count on people to buy into this fantasy of attainable greatness; they come right out and say so.

But it’s difficult for anyone to imagine doing the things that Wembanyama does, because he plays the game at such a high altitude. No normal person could ever match the skills of smaller NBA players either, but that fantasy is more accessible. Steph Curry, the league’s all-time record holder for three-pointers, has a degree of eye-hand coordination that is at least as freakish as Wembanyama’s height. But because Curry is just 6 foot 2, and I am nearly that, I can at least delude myself into thinking that with enough practice, I, too, could hit some of the shots that he does. It’s no accident that Curry, Michael Jordan, and other players whose physiques more closely resemble the everyman’s tend to have more fans, and more signature shoe lines. We look at Jordan and pretend that we can be like Mike.

Do people want to be like Wembanyama? Maybe so. He might be the front wave of a new era. The NBA may soon be stacked with even ganglier players who have all-world ball-handling skills and deep shooting range. Maybe my eyes will eventually adjust to them. Football fans needed time to accommodate themselves to Patrick Mahomes’s sidearm throws, as did the baseball fans who at first recoiled from Hideo Nomo’s tornado windup.

Either way, Wembanyama won’t be bothered. In his first season, he was named Rookie of the Year, and in his second, he would have been named best defender had he not been injured. This year, he looks even better, and Nike has already given him a signature shoe. A special logo is emblazoned on the heel and insole: an alien.

*Sources: Jim Poorten / NBAE / Getty; Chris Coduto / Getty; Stephen Gosling / NBAE / Getty; Adam Hagy / NBAE / Getty</div>
        </div>
        
        <div class="card" onclick="openModal('content-22')">
            <div class="source">The Atlantic</div>
            <div class="title">Netflix vs. Paramount</div>
            <div class="meta">2025-12-25</div>
        </div>
        
        <div id="content-22" style="display:none;">
            <h2>Netflix vs. Paramount</h2>
            <p><strong>The Atlantic | 2025-12-25</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/podcasts/2025/12/warner-brothers-discovery-netflix-paramount-trump/685386/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Subscribe here: Apple Podcasts | Spotify | YouTube | Overcast | Pocket Casts

If Warner Bros. Discovery was only a movie house, it would have had one of its best years ever. Two of its films (One Battle After Another and Sinners) are front-runners for the Academy Award for Best Picture, and it had a string of critical hits and box-office successes with Superman, Weapons, and A Minecraft Movie. But the company is a media conglomerate that counts HBO and CNN among the brands it owns, and it took on lots of debt; its box-office success in 2025 is not enough to make up for its financial struggles.

This year, the company found itself up for auction. After over a hundred years as a major Hollywood studio, Warner Bros. fate seemed unclear. Now months into a process that Netflix formally won, Paramount still hopes to come out on top with a hostile bid. This week even, the billionaire Larry Ellison, whose son, David, controls Paramount, offered a personal guarantee for the deal.

The bidding war for Warner Bros. Discovery is a business story that morphed into a future-of-entertainment story and then recently took an ominous turn into politics. President Donald Trump weighed in, saying he would be “involved” in deciding who wins, which put every party on alert that Trump might be particularly watching what happens to CNN, a cable network he has called “the least trusted name in news” and a “political arm of the Democrat Party.”

Trump has sued ABC News, CBS News, the BBC, The New York Times, and The Wall Street Journal. His administration has federally defunded PBS and NPR, and put pressure on networks to cancel late-night shows. In the Warner Bros. Discovery bidding war, Trump has hinted that he leans toward Paramount, and this week brought new claims of political interference of the news at the Ellison-run Paramount. 60 Minutes pulled a segment on the harsh conditions at a prison in El Salvador where the Trump administration deported hundreds of Venezuelans earlier this year. Bari Weiss, the new head of CBS News, said the story needed more work even though it had apparently been fact-checked and legally vetted, not to mention promoted on air.

In this episode of Radio Atlantic, we talk to the Atlantic film critic David Sims about what the outcome of this deal might mean for movie lovers, especially those who hope to keep going to movies in theaters. And we talk to our staff writer Frank Foer about Trump’s increasing influence on the media landscape and his subtle campaign to disappear CNN.

The following is a transcript of the episode:

Hanna Rosin: I know we’re months from the Oscars, but will you name your top-three picks for Best Picture?

David Sims: In terms of who I think may well win?

Rosin: I think I’m gonna go with want. I think I’m gonna go with want. That’s—

Sims: I’ve got the same pick for both, honestly, is I do think One Battle After Another will win out; I would say Sinners and Hamnet are the other sort of big players right now.

Rosin: I was hoping you would say One Battle After Another and Sinners, only so I could have a smooth transition into the conversation I want to have with you.

Rosin: One Battle After Another and Sinners, two front-runners for the Oscar for Best Picture, both came out of the same studio this year: Warner Bros.

Sims: Those are movies from very established filmmakers with big stars in them.

Leonardo DiCaprio (as Bob Ferguson in One Battle After Another): My name is Bob Ferguson. I don’t know if you’ve ever heard of me, all right? I was part of French 75.

Sims: But they were for grown-ups. These are R-rated movies.

Michael B. Jordan (as Elijah “Smoke” Moore in Sinners): Y’all Klan?  Jack O’Connell (as Remmick in Sinners): Sir. We believe in equality and music.

Sims: They were going up against more established franchise stuff, and they dominated the conversation.

Rosin: This is Atlantic movie critic David Sims.

Sims: They did well in every kind of space.

Rosin: It was also the same studio that made Weapons, Superman, and A Minecraft Movie— critical hits, along with box-office successes—movies for families and movies for families who like Paul Thomas Anderson.

Sims: They had the kind of year studio executives dream of.

Rosin: So what better way to end a banner year at Warner Bros. Pictures than by selling it?

This fall, Warner Bros. Discovery—which includes all of its movie studios, HBO, DC Comics, and a bunch of other things—announced that it was on the market.

Sims: So Paramount was there—it was an existing movie studio, recently bought by David Ellison after he spent years trying to take it over. He’s the son of Larry Ellison. He’s a very, very rich tech billionaire.

Rosin: But their bid was rejected. So Paramount kept submitting more bids, and those were all rejected too.

Meanwhile (Netflix sound effect plays.) Netflix was also interested and swooped in.

Wolf Blitzer (from CNN): New this morning, Netflix has inked a deal with Warner Bros. Discovery to buy the iconic TV and movie studio and its streaming assets, including HBO. We should mention—

Rosin: This is Radio Atlantic. I’m Hanna Rosin. The bidding war for Warner Bros. is a business story that’s morphing into an entertainment story and then took an ominous turn into politics.

President Donald Trump: So we’ll have to see what happens.

Rosin: Recently, President Donald Trump weighed in on the matter, suggesting that he was personally interested in the outcome—which adds a whole new layer of complication.

Trump: And I’ll be involved in that decision too. But they have a very big market share.

For those of us who care more about the movies? The truth is that both options might make them a little worse—for different reasons.

And for those of us who care most about democracy? It would not be the first time that the president has inserted himself into the business of media. We’ll talk to staff writer Frank Foer about that later.

But first, critic David Sims on what he pays the most attention to: What does this Warner Bros. Discovery deal mean for the movies when the number of big movie studios just keeps shrinking?

Sims: Obviously, this is a looming nightmare that Hollywood has been worried about for longer than the last few months. And for the last few years, Warner Bros., which is one part of a big conglomeration of TV networks and other stuff has been a company that’s sort of laden with debt and has had some bad corporate owners in the past, that’s been passed around, so a lot of people have been waiting to see who will swoop in to sort of salvage the company or transform it. And the fear’s always been, It’ll get sucked up too. The Hollywood studios will continue to sort of condense into a bigger and bigger blob, which, really, it means nothing good for art, unfortunately.

Rosin: Okay, well, slow that down ’cause you said “fear”—you’re separating, already, in your answer quality from financial stability. So it was a studio that made good movies but was financially not stable, I guess, for a while, so why “fear”—why don’t we see this as rescuing Warner Bros.?

Sims: Well, Warner Bros., the movie studio itself, there’s not a huge profit issue there. That’s the sort of jewel of the company, along with HBO, which is part of this corporate consideration.

It’s the other stuff that’s been the problem, and David Zaslav, who’s been running the company for a few years at this point, since it merged with Discovery, has been trying to cut fat. He’s laid people off. He’s canceled whole movies outright. He’s been running it pretty lean, and I think everyone in the industry has been watching and sort of noting that he’s clearly preparing to get acquired.

Now, in the old days, Warner Bros. used to be owned by AT&T. Before then, it was owned by AOL. Back in the day, Coca-Cola used to own one of the movie studios. Big companies would own movie studios ’cause it was fun to own a movie studio—you would get to be a player in Hollywood, and you would have glitz and glamour. But now, it feels like the only companies that want these movie studios are other movie studios.

Rosin: So let me ask you: If, for years and years, big companies have owned movie studios, why is this moment such a big deal? Why do people like you talk about it with trepidation in their voices—nd “people like you,” I mean people who love movies and movie theaters and just the whole tradition of Hollywood? Why is this any different than Coca-Cola or anybody else?

Sims: Well, so it feels like there’s two outcomes to this Warner Bros. deal, it seems, and both of them are causing agita for different reasons.

Sims: If Paramount, which is another big studio, had bought Warner Bros., you have what happened to Disney and Fox, probably, happening again, so Fox still exists in some form, as a sort of subsidiary of Disney—t releases a few movies a year—but you’ve kind of dried up one of the wells of big movie production in Hollywood. If that happens with Paramount owning Warner Bros., once again, you feel the pool of big movies shrinking in Hollywood. You feel this sort of competition shrinking.

Now, Netflix is this kind of different beast because they operate a different model. They’ve made money a different way. Obviously, they’re all in on streaming. So far, they’ve sort of communicated publicly, like, Oh, no, no, no. Warner Bros. is a different business than ours, and we wouldn’t wanna kill its theatrical industry. But because Netflix has been so uniquely aggressive about sort of getting their movies onto TV rather than in theaters, there’s this just huge anxiety amongst people like me and people who make movies that the movie-theater industry just cannot survive losing that many movies a year, if that’s where this is going.

Rosin: Why are theatrical—this is not obvious to me. It seems to me—what I care about is that good movies get made. Why is theatergoing the lifeblood of good movies? Does it change the incentive structure of what kind of movies you make and how good or creative or original they are?

Sims: Possibly. Look, Netflix has made good movies, but there is a sort of style to a lot of Netflix movies—the more sort of generic stuff that they put out: the rom-coms and the sort of medium-size dramas, whatever—that feels like the movie’s a little more designed to be ignored.

Rosin: Ah, now I understand it. (Laughs.) That feels like a real concern—if you’re creating movies that you know people are going to be checking their phone while watching.

Sims: I think when you talk to the sort of older guard in Hollywood, who are especially worried about the mortality of theaters, there’s also just this feeling of, like, When it’s gone, it won’t come back.

Sims: And all of those companies are—they’ve been battered by COVID, they were hurt by the strikes, which really reduced the amount of output lately, and they’re kind of hanging on by a thread right now.

Big movies will come out and do well and kind of demonstrate that audiences are fine going to the theater for something they’re interested in. But it’s tougher for a sort of mid-sized or smaller movie to break out in the ways that they used to—which is why, again, one reason that something like Sinners or One Battle, those films catching on with people is heartening to see because it kind of defies the prediction that companies like Netflix are making of, Ah, well, that old model, that’s sort of dinosaur stuff, and people prefer to just have an a la carte selection at home of whatever they can watch.

Rosin: So we’ve been discussing the Netflix outcome. Tell me what happened with Paramount and what’s the Paramount outcome. How do you see that differently than what you’ve just described?

Sims: I think one reason the Netflix bid seems to have won is that Netflix was cool with Warner Bros., the company, sort of splitting up and its cable channels—these sort of less profitable units—getting spun off and turned into a division that can be dealt with elsewhere or sold off or who knows. And Netflix would take control of kind of the big properties: Warner Bros., HBO, things like that.

Paramount seems to want the whole kit and caboodle; they want everything. They’re willing to pay a lot for it. And it’s a little harder to understand why, outside of, I guess, just this notion of, We need to be as big as possible to compete.

Paramount on its own used to be a very venerable—it’s still venerable, but now they don’t have a Marvel, and they don’t have the kind of streaming service that Netflix or HBO is. So if they can just kind of grow by acquisition, grow by expanding into new areas of storytelling—they can make more comic-book movies, whatever—that’s their argument for: This is the best way to survive.

That might be true for Paramount. It might lead to a lot of layoffs and a lot of consolidation as well. There’s literally just less movies in theaters than there used to be. And so consolidation, you imagine more of that.

Rosin: Right. So whatever the details, you see this as a lose-lose for Hollywood.

Sims: Oh God, I hate to be so pessimistic. I’m usually not the pessimist, I will say. But it’s tough for me to see either of these being smooth. Both of these will be strange corporate maneuvers.

It currently seems like the Netflix thing will happen. But, obviously, Paramount’s exploring this idea of a hostile bid. Combining Netflix and HBO, you’ve got two of the biggest streaming services—that’s a whole mess that maybe regulators won’t object to. There’s the Trump factor of terms of he maybe prefers a bidder—maybe he doesn’t, though? A lot of the reporting seems to suggest maybe he wasn’t as swayed by the Ellisons as the Ellisons thought he would be. Who knows?

All of this is very difficult to foresee. And I think Warner Bros. did not really see this coming. The old rumor was that they wanted Universal, who’s another studio, to get them, and those two powers would combine into something very, very powerful. This is weird in a new way, and it’s kind of like the story of Hollywood of, every year, there’s sort of a new evolution of weird that everyone in the industry just has to wrestle with.

Rosin: David, thank you so much for joining us today.

Rosin: After the break, Frank Foer on what happens if Trump does intervene on this deal.  And remember: Warner Bros. Discovery isn’t just in the movie business. They also own CNN.

Rosin: The movies are just one part of this Warner Bros. Discovery deal. As we’ll hear from staff writer Frank Foer, politics is another.

According to a recent report from Bloomberg, President Donald Trump privately told people that he wanted this deal to be a competition, to have one side bid against the other for his approval of the deal.

Frank Foer: Because, ultimately, in order to get a merger of this size through, it needs to be blessed by the U.S. government. And it seems like the biggest condition that he’s laid out there is CNN.

Rosin: CNN. Okay, so you think that’s his main interest. What does he want from CNN?

Foer: So Warner Bros. owns CNN, and I think that he hates CNN, that he says it’s run by corrupt, terrible people, and he wants to see them out. Does that mean that he wants to see CNN kind of left on the side of the road to wither and die? Does it mean that he wants the new buyer to come in and renovate CNN in the same sort of way that the Ellisons have come in to CBS News and installed Bari Weiss and to turn that into a different type of news-gathering organization? It’s unclear. I don’t think Trump knows. I think he’s waiting for the bidders to come and present him with the best prize.

Rosin: Okay. I think I need to understand how unusual this level of intervention is. What is the president’s usual official role in a big merger like this?

Foer: So the whole United States government is set up to avoid this type of direct political meddling.

Foer: We have agencies like the Federal Trade Commission and the Federal Communications Commission, which were set up almost a hundred years ago, or more than a hundred years ago in the case of the FTC. And they were supposed to be independent agencies, where you had a set of commissioners—you would have three from the party in charge, two from the out party—where they would make decisions in a relatively bipartisan, technocratic way, in the best interest of the government, so that you didn’t have presidents coming in and picking winners and losers.

But I think it’s pretty clear that, in the end, he’s got a little bit of a rooting interest for Paramount, but he doesn’t wanna make it seem as if he’s putting his thumb on the scale, because that would be bad—that would send bad signals to the world, bad signals to the market. And so, even if he may gesture in the direction of Paramount, I think even Donald Trump knows that he needs to make it look like an open and fair competition.

Rosin: Got it. So he’s, basically, somewhat aware of the kinds of criticisms that a person like Frank Foer at The Atlantic might make, is, This is inappropriate.

Foer: Right. This is a transaction, and so Warner Bros. has shareholders who have to approve a merger themselves and sign up for a deal; they initially signed up to give their company to Netflix. And really, there is a bidding war going on, and part of the bidding war is that—what Paramount says that it brings to the table is that it can get the approval of the president of the United States; it can make it a much more painless transaction than the Netflix purchase.

Rosin: It’s like they’ve already acceded to a world in which the president’s approval or disapproval actually makes a difference in how you do business. It’s like we live in that world now.

Foer: Yeah, yeah. And Netflix understands that too; that’s why Ted Sarandos went and visited—the CEO of Netflix went and visited Donald Trump in the Oval Office himself. This is the world that we live in.

Rosin: So let’s play out the scenario under Trump. What moves has he already made to exert influence over media?

Foer: Right. So we could look at what’s happened to The Washington Post.

Foer: During the first Trump term, Jeff Bezos bought The Washington Post—or he bought it before Trump—but he recreated the paper, essentially, as a resistance paper: Democracy dies in darkness.

Jeff Bezos: It is a mistake for any elected official, in my opinion, to attack media and journalists. I believe that— (Audience claps.)

Foer: And Trump sees this happening, and he sees the Super Bowl ad they make.

Tom Hanks (in a Washington Post commercial): Knowing helps us decide. Knowing keeps us free. (Music swells.)

Foer: And he starts to tweet about how Jeff Bezos is a corrupt guy and that he’s gonna take revenge against Amazon, which he says is doing all sorts of unfair things.

TV anchor (from CNBC): President Trump going after Amazon again, this time in a series of tweets. He writes: “So many stories about me in the @washingtonpost are Fake News. They are as bad as ratings challenged @CNN.”

Foer: So Bezos sees this happening and he, I think, either consciously or subconsciously, decides that he’s gonna walk away from this resistance persona, and he’s gonna recreate the editorial board of The Washington Post, which he more directly controls, as being something that’s more politically sympathetic to Donald Trump.

TV anchor (from CNN): —after the publisher announced that the newspaper will not endorse a candidate for president. That’s the first time they have not done so in 36 years of presidential elections. The Post itself—

Foer: Or to take another example, we saw the way in which Brendan Carr, the [chairman] of the FCC, said stations that were carrying Jimmy Kimmel—that because of everything that Jimmy Kimmel had said about Charlie Kirk, that they were gonna pay a price.

Brendan Carr (on The Benny Show): —changes that we’ve seen, but, frankly, when you see stuff like this—look, we can do this the easy way or the hard way.

Foer: And it turned out that a lot of these companies were in the process of undergoing mergers and consolidations—they had a lot of deals sitting in front of the Trump administration—and so they heard his message, and they said, Okay, we’re pulling Jimmy Kimmel from the air.

Rosin: Right, although they did say the decision to pull Kimmel wasn’t actually influenced by FCC communication. But, okay, so let’s overlay those dynamics onto the Warner Bros. sale. What does it look like? Play out what it could look like.

Foer: So we’ve talked about CNN, which, I think, is kind of the most vulnerable asset there. I think that—

Rosin: Wait, so what happens to CNN? Just—this is hypothetical.

Foer: Right. So, hypothetically, they could either say that, We’re gonna buy CNN as part of this deal, and we’re just gonna kill CNN.

Foer: Or Netflix. Netflix doesn’t do news, and so they could just say, You know what? If it’s a cost of doing this transaction that you’re forcing us to buy CBS—anything is possible in this sort of world where these types of sums of money are on the table, and there’s an enormous amount of flexibility.

The other scenario—and we’re seeing this with CBS News, which is kind of what I’d call the Orbánification scenario, where Viktor Orbán is the head of state in Hungary, and what he’s done is, essentially, ensured that the biggest media properties in that country are sold to his allies and cronies, who, in turn, neuter those networks or turn them into propaganda apparatus. And so there’s some possibility that that happens. But if Paramount decided to go through with that, it would be painful for Paramount.

Rosin: But why? We just had a perfect model for that, which is: Bari Weiss takes over CBS; Erika Kirk is the first interview. Plenty of people got fired, but it happened.

Foer: It happens; it’s not unthinkable. But CNN is different than CBS. CBS News is something that aims to be straight down the middle. CNN, I think, aims to be straight down the middle, but is, in fact, kind of an anti-Trump network.

Rosin: I see, so it would be more obvious and much more of a fight.

Foer: Yeah. You would lose more viewership that way. You’d lose hosts who, I think, have built personas around criticizing Trump. It would be messy.

Rosin: Right. Okay, so that’s instability for us who work in this industry. But do the shifts in journalism matter for anyone else?

Foer: Right, so if you take The Washington Post.

Foer: The Washington Post editorial page had limited reach. But in terms of kind of national voices, there were three national newspapers, three editorial boards. You have The Wall Street Journal, which is already kind of right-wing, and then you take another one and you make it right wing, you’ve changed a substantial portion of the opinion space in national newspaper land.

There are only three meaningful cable networks. One of them is already pro-Trump. You take another one off the table—you’re changing a substantial percentage of cable news.

A democracy is basically only as good as the information that its citizenry gets, and so we are undergoing this long-term crisis where the quality of information that citizens get has been diminished—it’s more likely to be manipulated by algorithms or by outside actors—and that, if we ever have any chance of having a democratic revival in this country, we need there to be quality sources of information.

Rosin: Sometimes I think back to the first days that Jimmy Kimmel was fired and what a shock that was to the country because that was the first time that such an overt pressure happened from the administration, which had such an obvious consequence for a well-known media figure. But then he was reinstated. So is there any hope in that?

Foer: Yeah, I think that there is hope in that, because there was a public backlash. I think that it was a moment where they pushed too hard, and they went too far, and I think a lot of people who may have otherwise cowered or turned away felt compelled to push back.

But, on the other hand, I just look at things relative to where they were in the first Trump term and the whole tenor of conversation. And in the first Trump term, I think a lot of media looked at outrageous things, and they responded with outrage. And here, this is not just because of all these larger economic tides that we’re talking about, but there is a greater numbness that, I think, prevails. It’s less red-blooded. It’s less full-throated. It’s more numb.

Rosin: Thank you, Frank, for joining us today.

Rosin: This episode of Radio Atlantic was produced by Jinae West. It was edited and engineered by Kevin Townsend. Rob Smierciak provided original music. Sam Fentress fact-checked. Claudine Ebeid is the executive producer of Atlantic audio, and Andrea Valdez is our managing editor.

Listeners, if you enjoy the show, you can support our work and the work of all Atlantic journalists when you subscribe to The Atlantic at TheAtlantic.com/Listener.

I’m Hanna Rosin. Thank you for listening.</div>
        </div>
        
        <div class="card" onclick="openModal('content-23')">
            <div class="source">The Atlantic</div>
            <div class="title">How to Follow the Right Star</div>
            <div class="meta">2025-12-25</div>
        </div>
        
        <div id="content-23" style="display:none;">
            <h2>How to Follow the Right Star</h2>
            <p><strong>The Atlantic | 2025-12-25</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/ideas/2025/12/christmas-happiness-life-choices/685405/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">A much-loved Christmas story tells about the journey of the Magi—the three Wise Men who came seeking the baby Jesus in Bethlehem. “Where is He who has been born King of the Jews?” they ask. “For we have seen His star in the East and have come to worship Him.” The essence of the tale is their unshakable faith in a worldly sign—a star in the sky—which the Magi trusted would guide them to the savior of the world.

This story has inspired Christians for more than two millennia to believe that they can find metaphysical truth and eternal life by following something tangible—the words in a book, say, or a physical sacrament. For some nonreligious people, this belief might seem nonsensical or superstitious. Yet almost everyone acts in some analogous way in their regular life—just as almost everyone wants to be happier.

The problem is that striving for happiness directly, in the abstract, is not possible. Instead, you must choose proxy goals: metaphorical stars in the sky that you can see and judge to lead you to the greater well-being you desire.

This sounds right, but is it true? Is the star you choose really the one that marks the stable you hope to find? Consider the risk that your stated goals are a mirage and lead to nothing—or, worse, to unhappiness. This column is about how you can tell whether you’re following the right star.

Proxy goals are important because they create a sense of direction, without which you cannot make progress, which is itself a source of great satisfaction, at least temporarily. Psychologists have shown in experiments that when people set concrete goals, life feels more manageable, especially for those experiencing depression or anxiety. In fact, goals can be protective against adverse life circumstances: If you don’t like your current employment, professional goal-setting can make your job more bearable.

Arthur C. Brooks: How to make the most of bad gifts

To improve your long-term well-being, however, not all proxy goals are created equal. They must align with your internal values and interests, which psychologists call “self-concordance.” Self-concordant proxies have three basic characteristics, which bear careful consideration.

The first is that a good proxy goal is non-zero-sum: Achieving it does not mean that someone else cannot also achieve it. An example of a zero-sum goal would be striving to become the CEO of your company: If you’re the CEO, no one else can be (until you quit or get fired). Nothing wrong with wanting to be the leader—but a better, non-zero-sum goal would be an honest assessment of how interesting and challenging you find your work. These are qualities of a role that can be enjoyed by anyone else, not just you. Why is this better? A researcher in 2006 found that non-zero-sum goals such as this raise life satisfaction, whereas competitive, zero-sum goals lower it. You could be a happy CEO, but holding the corner office per se isn’t the star directly over your true aim.

The second criterion for a good proxy goal is why you strive for it: This should be approach, not avoidance. You should follow your purpose for positive reasons, not negative ones. For example, say that to improve your quality of life, your proxy goal is to raise your employability through education. This can be defined as a positive, approach-oriented goal, such as “I want to learn a bunch of new skills.” Or it can be a negative, avoidance-determined goal, such as “I don’t want to wind up poor or unemployed.” As the author of a 2022 research paper in Psychological Reports found, you are much more likely to achieve life satisfaction if you approach this task positively.

Third, the best proxy goals tend to be non-positional, meaning that they are not set to create social comparison. Say you want to buy a house: A positional goal would be to have a house that impresses others; a non-positional goal would be to have a place to raise your family with love and joy, whether or not anyone else is impressed by the place. True, people do get some temporary satisfaction when they are envied by others (we’re only human, after all), but as research has shown, the more important this comparison is to you, the less happy you will end up. Learning to eschew social comparisons is itself a worthy proxy goal for well-being.

Happiness is not a goal you can chase directly. You have to shoot for more tangible proxy goals that you can see and pursue. But not all of these goals will lead you to the happiness that you seek; they have to possess certain characteristics. Here are three axioms to follow that will steer you in the right direction.

1. Focus on people, not things. As I’ve written previously, happiness is love. If there were a three-word summary of the entire science of happiness—which, fortunately for this columnist, there is not—that would be it. Love is best defined as “to will the good of the other” as judged by the other, meaning that such loving is reserved for living beings. Love is inherently non-zero-sum; it is infinite. It is always positive and, when sincere, not based on any social comparison. Follow stars such as the quality of your relationships and your service to others, and you will be right over the target of happiness.

2. It’s about you and your inner direction, not about how others see you. We are prone as a species to seek status and rise in social hierarchies. This is probably an evolved trait, because higher status in times of scarce resources usually means a greater likelihood of survival and finding a mate. But as noted, social comparison doesn’t lead to happiness at all, especially today in the age of social media. If your proxy goals revolve around how you compare with others or how others see you, you aren’t on target.

Arthur C. Brooks: A seasonal guide to better well-being

3. Make a happy journey your goal, too. The Magi, of course, went on a literal journey. Yours might be a metaphorical one, but in either case, your objective should be to enjoy it. One danger in the pursuit of life goals is the assumption that once you hit them, the satisfaction you attain will last forever. This is called the arrival fallacy, and it’s a major impediment to happiness; it explains, for example, why champion athletes commonly suffer depression after a long-sought victory. To be sure of a happier outcome, following the three criteria for the right goals helps a great deal, but you should also take care not to disregard the journey itself—and to take joy in it as much as you can. So, for instance, make college attendance about the learning, not your graduation or diploma. Make your dating experience about learning to love someone deeply, not just getting to the altar.

One last point: There will be times in life when you’ll need to deviate from your goals, even if they are perfectly thought out. Circumstances change, typically in ways you don’t like that are beyond your control. Maybe your relationship ends, your employment ends, or someone you love dies. In such adverse circumstances, I’d offer a fourth axiom to keep in mind.

4. Stay flexible, and be ready to find another way. Your proxy goals today may be outstanding, but they might not work for your happiness tomorrow. Always be ready to look for new ones, without remorse or hesitation. The Three Wise Men followed the star and found the infant Jesus, as promised. But their journey back home was another story. God warned them in a dream that King Herod was lying in wait for them, hoping to interrogate them about the whereabouts of the Messiah with the intention of harming him. The solution? “They departed for their own country another way.”</div>
        </div>
        
        <div class="card" onclick="openModal('content-24')">
            <div class="source">Slashdot</div>
            <div class="title">'Memory is Running Out, and So Are Excuses For Software Bloat'</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-24" style="display:none;">
            <h2>'Memory is Running Out, and So Are Excuses For Software Bloat'</h2>
            <p><strong>Slashdot | 2025-12-26</strong></p>
            <a class="original-link" href="https://developers.slashdot.org/story/25/12/26/0628235/memory-is-running-out-and-so-are-excuses-for-software-bloat?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">I just don&#39;t see incentives for most companies to seek much memory efficiency. Even if the calculator app takes a gig of RAM, few will notice and fewer will make purchasing decisions based on ram usage. Most people function just fine with 8gb. Even when they go over, the system still works thanks to ssds and virtual memory. Dell is not going back to mostly shipping mostly 4gb systems.

&quot;I have not run out of memory on my computer in years.&quot;

Neither have &quot;I&quot;, but my computer runs out of memory on a weekly basis and has done so for years.

No, but they&#39;re supposedly going back to 8GB systems after most low end systems having been moving towards 16GB for a while.

It costs money to optimize software, and most people don&#39;t want to pay it. A lot of software is already &quot;free&quot; with ads and upsells. I just can&#39;t see there being any improvement.

But since you can&#39;t afford a decent computer anymore, we&#39;ll let you rent one in the cloud that can run our shitty, bloated software

I am working on energysaving for software, with energyrating as part of it at Ahodzil [ahodzil.com]. Hopefully I will be able to make the code optimisation build framework available next year along with the energyrating. It goes beyond the compiler (and PGO) by checking if the code is necessary against a baseline of an &quot;optimal code formula&quot; based on decades of accumulated programming (and most codebases are just manipulating a database anyhow).

Good on you to provide an immediate potential solution, but you are highlighting the root of this problem: you are building just another framework. Modern developers do not know how to code, they only know how to integrate a framework with another framework. Everything became frameworks. And frameworks are, by definition, bloated. Even yours, given enough time, will cease to offer meaningful reductions because it too will get bloated with so many variables and options to circumvent others bloat.

I&#39;m sure the models trained on stack exchange examples will produce exactly the optimized code every CTO is hoping for when they promote the &quot;AI&quot;.

Seriously whoever wrote TFA really sucks at making any point. No one cares about 70MB for an app which usually doesn&#39;t run. WhatsApp is a chat program and consumes close to 700MB when you include all the webview processes it launches. Teams blows through more RAM than every other Office app combined running at the same time and it is intended to be an always running background program.

This has to be the dumbest &quot;case study&quot; example I&#39;ve ever seen, and while I haven&#39;t checked yet I can almost guarantee I kno

The funny part is that the &quot;agentic OS&quot; shit in windows, copilot required 16 gigs of ram for system to be certified to be copilot ready (or whatever it was that microsoft calls their copilot branding for OEM systems).

And rumor mill suggests that low end OEM systems are going back to 8 GB now. AI demand has caused... reduction in AI capable systems.

Point in case: Installed the Dire Wolf Digital Boardgame Companion(!) app last night. 333 MB. It&#39;s a neat app and it looks cool, but 333 MB for this is insane. Basically every piece of software is like this these days.

Part of this is due to cross-platform and cross-version development, but a larger portion of it is that devs don&#39;t need to care and memory efficiency isn&#39;t a priority anymore.

Way too many layers of abstraction to enable ever less qualified unwashed masses to develop software with even less understanding and skill; we had decades of this - now you see the results.

No, not everybody should be coding. In fact, it is better if less clueless wannabes are running around with these loaded guns.

Lower memory footprint is desirable whether or not there&#39;s a shortage of commercially-available DRAM.  Though there&#39;s not going to be as much growth in available memory on systems, the reality is that DRAM shortages will cause end users to deploy fewer new systems in the near future rather than significantly curtailing the amount of RAM available per system.  People will be holding on to older systems longer rather than sticking to whatever upgrade path they&#39;re on.

Why use toolchains at all?  Just have AI produce the application ready to run!

And why use frameworks? Just ask AI to generate all the code needed.

&quot;...and argues that today&#39;s memory crunch could force similar discipline.&quot;

It definitely WON&#39;T, not for the people causing it.

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

Marvelous!  The super-user&#39;s going to boot me!
What a finely tuned response to the situation!</div>
        </div>
        
        <div class="card" onclick="openModal('content-25')">
            <div class="source">Slashdot</div>
            <div class="title">Cursor CEO Warns Vibe Coding Builds 'Shaky Foundations' That Eventually Crumble</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-25" style="display:none;">
            <h2>Cursor CEO Warns Vibe Coding Builds 'Shaky Foundations' That Eventually Crumble</h2>
            <p><strong>Slashdot | 2025-12-26</strong></p>
            <a class="original-link" href="https://developers.slashdot.org/story/25/12/26/0623233/cursor-ceo-warns-vibe-coding-builds-shaky-foundations-that-eventually-crumble?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Want to read Slashdot from your mobile device? Point it at m.slashdot.org and keep reading!

Either that, his company just happens to sell a code management & analysis tool that allegedly reduces the chance of AI code-slop gumming up an app. The fire insurance sales-person likes to remind customers of how hot and dry the weather feels.

Are they insulating themselves from liability?That&#39;s an angle I don&#39;t see mentioned very often when it comes to AI in the work world. The AI companies don&#39;t want to assume liability for anything their creation does (like giving away all the snacks in a vending machine for free, or deleting a bunch of corporate data in a fever dream), but then they try and sell AI as a replacement for humans doing many jobs.Would a company hire a human who preemptively refuses to be held responsibility for their actions on the job?

Are they insulating themselves from liability?

That&#39;s an angle I don&#39;t see mentioned very often when it comes to AI in the work world. The AI companies don&#39;t want to assume liability for anything their creation does (like giving away all the snacks in a vending machine for free, or deleting a bunch of corporate data in a fever dream), but then they try and sell AI as a replacement for humans doing many jobs.

Would a company hire a human who preemptively refuses to be held responsibility for their actions on the job?

Are they insulating themselves from liability?That sounds quite plausible to me. Maybe they finally got some competent legal advice. They sure did not have that before.

Are they insulating themselves from liability?

That sounds quite plausible to me. Maybe they finally got some competent legal advice. They sure did not have that before.

I don&#39;t need AI coding tools to write code for me, I am perfectly capable of doing that myself. Plus there isn&#39;t an AI coding tool on the planet that can do the stuff I do with reverse engineering proprietary file formats, interacting with obscure dead game engines and working with proprietary secret code that no AI would have ever seen before.

I don&#39;t need AI coding tools to write code for me, I am perfectly capable of doing that myself.Yes, but you can&#39;t do it as fast as you can using AI coding tools, according to your boss. He doesn&#39;t have any actual numbers to back up this assertion, and he wouldn&#39;t be looking at the impact on time in the QA/testing phase either. But he&#39;s sure he&#39;s right after talking to that guy he played golf with last month, and is willing to stake your job on it.

I don&#39;t need AI coding tools to write code for me, I am perfectly capable of doing that myself.

Yes, but you can&#39;t do it as fast as you can using AI coding tools, according to your boss. He doesn&#39;t have any actual numbers to back up this assertion, and he wouldn&#39;t be looking at the impact on time in the QA/testing phase either. But he&#39;s sure he&#39;s right after talking to that guy he played golf with last month, and is willing to stake your job on it.

They save a lot of time on boilerplate / web design. That said, Gemini 3 (the current leaderboard champ) tried to talk me into doing something the other day that a junior dev might not have been skeptical enough of to catch, and would have ended with catastrophic downtime due to common exploits.

I am not surprised. The current hype-AI is incapable of writing reliably secure code.

They save a lot of time on boilerplate / web design.How much new boilerplate do you need in a project which you can&#39;t pull from the git repo of your older projects?I don&#39;t see any non-trivial savings that can justify even the $20/mo for the cheapest &quot;copilot&quot; account.

They save a lot of time on boilerplate / web design.

How much new boilerplate do you need in a project which you can&#39;t pull from the git repo of your older projects?

I don&#39;t see any non-trivial savings that can justify even the $20/mo for the cheapest &quot;copilot&quot; account.

Definitely don&#39;t use LLM-generated code without scrutiny, but it&#39;s not bad as a starting point or as a source for potential approaches.  It&#39;s also not bad for code review: I asked gpt-oss to adapt some (not yet tested) code in a certain way, and it noticed a cut-and-paste error in addition to adapting the code.  I ended up not using that adaptation, but the big report was helpful.

One can -- and I think should -- be skeptical of lots of things about LLMs, from business models and environmental impacts to qua

Sure your coders will be really engaged with 1 million lines of Rust code per month per dev.

Just asking for a friend who&#39;s on that Microsoft team.

That means until we have AGI. For which we do not even know whether it is possible and, if possible, we will not get anytime soon. May be 100 years, 1000 years or &quot;never&quot;.

I really do not understand why so many people are willing to believe AI is all-powerful. There must be a widespread mental defect somewhere that can explain this disconnected belief.

it cost 20 or so amonth and allows me to gereate a framework and do simple crud(kinda). it does save me a lot of time.Now i have yet to see it produce any code that actaully worked with out fixes.

That is really all that is to say here. Well, I would like to see some research into why so many people massively overestimate what LLM-type AI can do. I mean, I took one look and was not impressed. Why do people seem to think that AI needs to be regarded as all-knowing, all-powerful until the converse is proven? And sometimes not even with that proof? I really do not get it.

DOGE To Rewrite SSA Codebase In &#39;Months&#39;[posted on slashdot 2025-03-29]https://developers.slashdot.or... [slashdot.org]

They must have finished it by now. So how did it go? Thought so.

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

Marvelous!  The super-user&#39;s going to boot me!
What a finely tuned response to the situation!</div>
        </div>
        
        <div class="card" onclick="openModal('content-26')">
            <div class="source">Slashdot</div>
            <div class="title">Apple's App Course Runs $20,000 a Student. Is It Really Worth It?</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-26" style="display:none;">
            <h2>Apple's App Course Runs $20,000 a Student. Is It Really Worth It?</h2>
            <p><strong>Slashdot | 2025-12-26</strong></p>
            <a class="original-link" href="https://apple.slashdot.org/story/25/12/26/041227/apples-app-course-runs-20000-a-student-is-it-really-worth-it?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Follow Slashdot blog updates by subscribing to our blog RSS feed

Second verse, same as the first.A little bit older [slashdot.org] and a little bit worse.

Apple&#39;s App Course Runs $20,000 a Student. Is It Really Worth It?It depends. 

For a hypothetical individual paying for it themselves? No. 

For an individual enrolled in the course, but not paying for it? Maybe. It depends on the what the next best alternative use of that time would be. The &quot;opportunity cost&quot; 

For a hypothetical Fortune 500 company that wants to retrain a developer to do apps for iOS (or macOS, very similar code). Sure, why not. It would probably cost them less than laying off the non-iOS developer and hiring an iOS developer. 

For Apple? Sure, they get to make a &quot;donation&quot; to support a cause yet control where their money goes. iPhones, MacBooks and a very modest stipend. It undermines any grifters trying to do any scamming under the banner of the cause.

Apple&#39;s App Course Runs $20,000 a Student. Is It Really Worth It?

It depends. 

For a hypothetical individual paying for it themselves? No. 

For an individual enrolled in the course, but not paying for it? Maybe. It depends on the what the next best alternative use of that time would be. The &quot;opportunity cost&quot; 

For a hypothetical Fortune 500 company that wants to retrain a developer to do apps for iOS (or macOS, very similar code). Sure, why not. It would probably cost them less than laying off the non-iOS developer and hiring an iOS developer. 

For Apple? Sure, they get to make a &quot;donation&quot; to support a cause yet control where their money goes. iPhones, MacBooks and a very modest stipend. It undermines any grifters trying to do any scamming under the banner of the cause.

To really get your moneys worth you have to take it at least two times. I enrolled in it, and quickly settled into the idea that the first run-through was just going to be practice. The second time is when I really got some &quot;aha!&quot; moments and felt like I understood the material. Mind you, I failed both times .. but I really started to feel value for money in the second round. So yeah, overall I&#39;d say worth it.

Kinda like overthrowing the government, gotta try it a few times to really get your pardon&#39;s worth.

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

Marvelous!  The super-user&#39;s going to boot me!
What a finely tuned response to the situation!</div>
        </div>
        
        <div class="card" onclick="openModal('content-27')">
            <div class="source">Slashdot</div>
            <div class="title">Gmail Users May Soon Be Able To Change Their Email Address and Keep the Old One</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-27" style="display:none;">
            <h2>Gmail Users May Soon Be Able To Change Their Email Address and Keep the Old One</h2>
            <p><strong>Slashdot | 2025-12-26</strong></p>
            <a class="original-link" href="https://it.slashdot.org/story/25/12/26/0155213/gmail-users-may-soon-be-able-to-change-their-email-address-and-keep-the-old-one?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Please create an account to participate in the Slashdot moderation system

There&#39;s no good will here. If you want to change your email address, you either create a new account and abandon the old one, or create a throwaway account and forward all mail to your old one. Either way they lose that precious tracking profile on you and potential ad revenue. Now they&#39;re just plugging that hole so they can keep tracking you while you go by whatever you want.

Plus, it doesn&#39;t really fix the real problem that I have with my GMail address. I get tons of spam thanks to my 15 year old e-mail address being part of about 2 dozen security breaches over that time.

What I should really do is just start over and change my e-mail address on most of my commonly used accounts, but even that&#39;s a temporary solution. I know that they&#39;ll be another breach or someone will just flat out sell my e-mail address to a mailing list without my consent.

On the contrary I can&#39;t wait to get my new gmail email address. My email address is ilovebrenda@gmail.com and my new wife has a different name so she hates it.

On the contrary I can&#39;t wait to get my new gmail email address. My email address is ilovebrenda@gmail.com and my new wife has a different name so she hates it.Will she hate it even more when you futureproof the new one to ilovemycurrentwife@gmail.com?
Try ilovemywife@gmail.com and hope she doesn&#39;t think about it too much.

On the contrary I can&#39;t wait to get my new gmail email address. My email address is ilovebrenda@gmail.com and my new wife has a different name so she hates it.

Will she hate it even more when you futureproof the new one to ilovemycurrentwife@gmail.com?
Try ilovemywife@gmail.com and hope she doesn&#39;t think about it too much.

Get the new address and then filter the old one straight to trash.

Presumably it won&#39;t use the &quot;on behalf of&quot; header or whatever it is (original sender maybe) for who it&#39;s from.

It sounds like an alias system which is basically what I would love.     Aliases are simple database entries,  and Ideally they should not even limit us to two..  I would love to have a bunch of alias slots that can be rotated out,  so I can add  and drop various email addresses on a regular basis in order to reduce spam.

Please google.. Let me change my Gmail account&#39;s login email address, but still be able to receive email at the address and manage it like a permanent email alias.   In short,  just because

It was maybe too easy to make another account. They&#39;d rather have your different email addresses explicitly linked.

They could fix the way their system handles email addresses in the first place: firstlast@gmail.com is the same as first.last@gmail.com.  I think there are other variation of this also.

Or better yet, properly implement if the RFCs instead of trying to be different and innovate when they cannot even get the basic right.

They could fix the way their system handles email addresses in the first place: firstlast@gmail.com is the same as first.last@gmail.com.  I think there are other variation of this also.This was actually a quirk that could be used to find who was selling your email address.  Giving different vendors variations of JohnDoe, John.Doe, J.ohndoe, Joh.n.D.o.e, etc helped you determine who valued your information more than your privacy.Another option was to use the Plus addressing.  By adding a &quot;+&quot; and a label (folder) you could direct the email into a specific folder and also track who you gave that address.  JohnDoe+Walmart, JohnDoe+TacoBell, JohnDoe+Sheraton will all arrive in your inbox and if a matching label is found, it will be applied.

They could fix the way their system handles email addresses in the first place: firstlast@gmail.com is the same as first.last@gmail.com.  I think there are other variation of this also.

This was actually a quirk that could be used to find who was selling your email address.  Giving different vendors variations of JohnDoe, John.Doe, J.ohndoe, Joh.n.D.o.e, etc helped you determine who valued your information more than your privacy.

Another option was to use the Plus addressing.  By adding a &quot;+&quot; and a label (folder) you could direct the email into a specific folder and also track who you gave that address.  JohnDoe+Walmart, JohnDoe+TacoBell, JohnDoe+Sheraton will all arrive in your inbox and if a matching label is found, it will be applied.

https://www.howtogeek.com/plus... [howtogeek.com]

There&#39;s nothing to fix. This was a design decision up front to prevent account impersonation and it&#39;s a good one.

That works fine for receiving; less so for sending.  I&#39;m hoping the new feature will have an easy pull-down to select which email address you are sending from without logging out and back in.

Given that already works with aliases you&#39;ve defined in Gmail, I&#39;d think it&#39;s likely to also work with this (hypothesized) upcoming second Gmail address.

I already have a pulldown which lets me send email from five different aliases that deliver to my gmail inbox.  In Settings under &quot;Accounts and Import&quot; there&#39;s a &quot;Send mail as&quot; section for setting this up.

They&#39;re gonna take all the good addresses!

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

Marvelous!  The super-user&#39;s going to boot me!
What a finely tuned response to the situation!</div>
        </div>
        
        <div class="card" onclick="openModal('content-28')">
            <div class="source">Slashdot</div>
            <div class="title">Apple Settles Brazilian Antitrust Case, Must Allow Third-Party App Stores and External Payment Links</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-28" style="display:none;">
            <h2>Apple Settles Brazilian Antitrust Case, Must Allow Third-Party App Stores and External Payment Links</h2>
            <p><strong>Slashdot | 2025-12-26</strong></p>
            <a class="original-link" href="https://apple.slashdot.org/story/25/12/26/0039248/apple-settles-brazilian-antitrust-case-must-allow-third-party-app-stores-and-external-payment-links?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">allowing non Webkit in all areas that hard?

https://apple.slashdot.org/sto... [slashdot.org]

The last thing I bought on my phone through Apple&#39;s App Store was $30.

At 30%, that&#39;s supposedly as much as $4.50 &quot;extra&quot; that I might not have paid through another App Store. Supposing I could have saved as much as half buying elsewhere, that&#39;s barely $2.

Two lousy dollars. Why am I going to enter all of my payment info and deal with some other vendor for two lousy dollars?! I wouldn&#39;t. Not ever. If nothing else, I&#39;m too lazy. As a consumer, I&#39;m just not interested in other payment mechanisms.

Then don&#39;t worry your pretty little head with things like this. It doesn&#39;t sound like anyone is going to stop you from continuing to pay.

Four weeks, twenty papers, that’s $2 dollars.

I agree loosely with monitoring and regulating Apple&#39;s almost monopoly. However, it&#39;s rather ironic because Brazil is practically the very definition of stifling competition. They have huge tariffs, much worse than anything the US has ever experienced, and they have exceptionally tight import/export restrictions.

And it&#39;s also weird because almost no Brazilian can even afford an iPhone. The cost of one new there is more than twice the cost in North America because there are so many laws and people to bribe that anything that is imported at all increases in price 2-4x the cost outside of Brazil. The vast majority of people use Android phones.

Basically, business doesn&#39;t happen in Brazil until the gentlemen&#39;s club at the top get a huge slice of the pie. And they get a very huge slice indeed. They themselves have a monopoly on free enterprise....rather hypocritical if you ask me.

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

Marvelous!  The super-user&#39;s going to boot me!
What a finely tuned response to the situation!</div>
        </div>
        
        <div class="card" onclick="openModal('content-29')">
            <div class="source">Slashdot</div>
            <div class="title">Fake MAS Windows Activation Domain Used To Spread PowerShell Malware</div>
            <div class="meta">2025-12-25</div>
        </div>
        
        <div id="content-29" style="display:none;">
            <h2>Fake MAS Windows Activation Domain Used To Spread PowerShell Malware</h2>
            <p><strong>Slashdot | 2025-12-25</strong></p>
            <a class="original-link" href="https://it.slashdot.org/story/25/12/25/2058205/fake-mas-windows-activation-domain-used-to-spread-powershell-malware?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Please create an account to participate in the Slashdot moderation system

came here to say this but with slightly different snark

You are truly running the dumbest ad campaign of all time

average linux user, stereotypes exist for reasons

because of this i am installing 11 more windows 11 machines just for your shit attitude

If you are still tethering yourself to proprietary software and anti cheat enshittified games

The reason for malware is has nothing to do with the fact that Windows is proprietary.    Linux users are just as much subject to these kind of attacks.

The main issue is that Windows ships with admin/dev tools such as Powershell, Start+Run, and command prompt - that Windows users do not understand,  but social engineering attacks can persuade the users to do dangerous things.   Such as paste clipboard commands into it.Linux does not improve in this area...  in fact;  Linux makes it worse.

irm (URL)  | iex   from a Powershell prompt is dumb shit.

URL can be Easily typo&#39;d, and there is no verification or confirmation.   It&#39;s blind trust and run arbitrarily whatever comes in over HTTPS.

But Linux users will follow instructions to do something that is just as much dumb shit called:

If you think for a minute the same kind of typosquating and ClickFix exploits are not actively exploiting Unix/Linux users too, then I got extremely bad news for you.    Linux may actually fare worse than Windows in this area.    At least in the Windows world - a couple more manual  steps are usually required to elevate.

The main issue is that Windows ships with admin/dev tools such as Powershell, Start+Run, and command prompt - that Windows users do not understand,  but social engineering attacks can persuade the users to do dangerous things.   Such as paste clipboard commands into it.If you ever try to run office365 from firefox with script blocker: Microsoft uses 5-10 different domains (live[dot]com, live365[dot]com, office[dot]com, office365[dot]com, microsoft[dot]com, ...) for an online word processor. Domain names used to load scripts from change wildly between authentication, actual application and surrounding feature set, few people will ever be able to tell, which domain is held by Microsoft or some other malicious entity. A domain name (especially with a TLS trust chain) used to

The main issue is that Windows ships with admin/dev tools such as Powershell, Start+Run, and command prompt - that Windows users do not understand,  but social engineering attacks can persuade the users to do dangerous things.   Such as paste clipboard commands into it.

If you ever try to run office365 from firefox with script blocker: Microsoft uses 5-10 different domains (live[dot]com, live365[dot]com, office[dot]com, office365[dot]com, microsoft[dot]com, ...) for an online word processor. Domain names used to load scripts from change wildly between authentication, actual application and surrounding feature set, few people will ever be able to tell, which domain is held by Microsoft or some other malicious entity. A domain name (especially with a TLS trust chain) used to

Your completely shit attitude does nothing to change Windows itself *is* malware anymore.

I thought vendor TLDs and the general proliferation of TLDs was supposed to make The Internet A Better Place (tm).  Are you telling me that Microsoft uses .win but doesn&#39;t control it?

Don&#39;t you find they control enough things already?

Microsoft TLDs are: .azure .bing .hotmail .office .skype .windows .xbox

Complaint about it not being hosted on a .windows domain.

Control of the .win TLDRegistry Management

The .win top-level domain (TLD) is managed by Famous Four Media, which operates as the registry for this domain.Delegation and Oversight

The .win TLD was delegated to the Root Zone on March 26, 2015, as part of ICANN&#39;s New gTLD Program. ICANN (the Internet Corporation for Assigned Names and Numbers) oversees the approval process for new TLDs and maintains the authoritative list of TLDs.Purpose and Governance

The .win domain aims to create a dedicated space for online gaming resources, promoting consumer trust and choice within that sector. A Governance Council has been established to involve key stakeholders in the management and direction of the TLD.

This structure ensures that the .win TLD is not only managed effectively but also aligns with the interests of its user community.

The more I look at this, the less I understand it.  This is not a Microsoft -product-, but it&#39;s used to activate -Microsoft products-?

I mentioned they could have used the .windows domain. Go figure.

Windows registration is notoriously buggy, and regular just refuses to work. This script does a bunch of stuff to force registration.

I believe it works even if you don&#39;t have a key. Currently, the biggest use will be getting access to extended updates on Windows 10.

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

Marvelous!  The super-user&#39;s going to boot me!
What a finely tuned response to the situation!</div>
        </div>
        
        <div class="card" onclick="openModal('content-30')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">How the Next Democratic President Must Spend Their First 24 Hours in Office</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-30" style="display:none;">
            <h2>How the Next Democratic President Must Spend Their First 24 Hours in Office</h2>
            <p><strong>News and Politics - Slate Magazine | 2025-12-26</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2025/12/trump-democracy-supreme-court-2028-democrats.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">This week’s Slate Plus bonus episode of Amicus is another entry in our occasional “Dear (Juris)Prudence” series, in which we invite listeners to ask their burning questions about the law and answer them as best we can. Write to amicus@slate.com to pose a question to Dahlia and Mark. This transcript has been edited and condensed for clarity.

Dear (Juris)Prudence,What does recovery look like for us as a nation? Even if we elect a Democratic president, House, and Senate in 2028, how can we legislate or otherwise repair the damage to the law, norms, precedent, etc., when we still have a Supreme Court that ignores law, norms, precedent, and maybe even the 14th Amendment?

Dahlia Lithwick: This is really an existential question as much as a legal one, but I know you’ve given it some thought.

Mark Joseph Stern: I think anyone who cares about salvaging American democracy needs to be asking those exact questions. And it’s pretty clear to me that the very first item on the agenda needs to be envisioning what the next Democratic president—let’s say, President AOC—should do in the first 24 hours of their time in office. That means embracing the maximalist vision of executive power that Trump has established to undo the damage that he is currently inflicting. Trump has amassed vast new powers for the president, and the next Democrat in the White House simply cannot surrender them. That would be unilateral disarmament, and a disservice to the country. What he or she needs to do instead is wield those powers aggressively for good, repair everything that’s broken, help the people Trump has hurt, and push forward with their own goals.

How does that cash out? First, let’s remember that the Supreme Court has now effectively granted the president authority to impound federal funds duly appropriated by Congress and to abolish federal agencies established and funded by Congress. I think that is terrible and anti-constitutional. But thanks to the Supreme Court, that is now the law. So let’s talk about what President AOC can do with those powers in 2029. On Day 1, she needs to impound ICE’s budget. She needs to refuse to spend the billions of dollars that Congress has appropriated to the agency and fire tens of thousands of immigration agents immediately, starting with those who committed acts of violence and discrimination—which, by that point, may be almost all of them. Close as many immigrant detention facilities as possible and free the detainees.

Then turn to Customs and Border Protection. Fire CBP chief Greg Bovino. Fire every single agent who participated in the horrific operations in Chicago, D.C., and L.A. Refuse to pay out a penny in benefits to any agent who broke the law. Release all the information about ICE and CBP’s immigration sweeps, including the names of every agent who participated. Start investigations and prosecutions of any law-breaking agent whom Trump doesn’t pardon. Repurpose the billions of dollars in savings as a reparations fund for every victim. Run the reparations program through a new agency established by executive order. Pay to return noncitizens who were wrongly deported back to the country. Transform ICE and CBP’s headquarters into the nerve center of a new Truth and Reconciliation Agency, and use this extra money to pay out damages to the victims of the mass deportation campaign. This would be 100 percent legal under the precedent established by Trump and the Supreme Court.

Remember: Trump has illegally fired tens of thousands of civil servants, closed agencies like USAID unilaterally, refused to pay out billions of dollars appropriated by Congress, halted our refugee program, shuttered the Education Department, paid reparations to Jan. 6 defendants and quite possibly himself. I think all of that should be illegal, but the Supreme Court has said that it is not. And you just cannot fight fire with a dripping faucet. So I say: Take these powers and use them to undo Trump’s legacy and really flood the zone. Blitz the country with these executive orders on Day 1 and dare anybody to stop you.

At the same time, the next Democratic president is going to be a “unitary executive” thanks to the Supreme Court. So purge every federal agency of Trump holdovers. Start with the Federal Trade Commission, the National Labor Relations Board, every other formerly independent agency. Oust every single Trump appointee at any agency in the executive branch. The Supreme Court is about to let the president do that, and it needs to see the consequences of its actions when the president isn’t named Donald Trump. Take his name off the Kennedy Center, the Institute of Peace, and every other institution that he has illegally branded. This needs to be a top-to-bottom reconstruction of the executive branch using the precedents that Trump himself established. That is the only way a true recovery can begin, and that is what needs to happen within 24 hours of the next Democrat reentering the White House.

I want to hurl myself in front of one objection you’re going to get, which is: But then the Supreme Court’s going to say all of that is illegal! My response is: Good, that’ll take three years to litigate. Run out the clock in the million ways that we have learned that the clock can be run out. And if everything is enjoined on Day 1 by every single Trump judge and then the Supreme Court, then we have another conversation. But I absolutely agree: Democrats should not petition, hands outstretched to the Supreme Court, for the maximalist version of presidential power when it’s not Donald Trump in office. They need to say: Cool, this is what the rule is now. Let’s go.

The other thing I want to say is that baked into Jacob’s question is this issue of: How do we reinstate norms? How do we get the other side to abide by the entire complicated web of unenforceable feelings about, say, a separation between the Justice Department and the White House? And how prosecutors conduct themselves in court? And on and on? If we can learn any lesson from President Joseph Biden’s regime, it’s that you cannot simply adhere to norms and hope the other side will look around and say: Hey, I forgot—norms are awesome! That is not the way to go back to living under soft, unenforceable norms of democracy. You cannot bring a shrimp fork to a knife fight. We have to disabuse ourselves of that idea.

Because norms survive in a system like ours when both sides feel that they have something to gain from them and something to lose when they go away. And right now, under Trump, the Republican Party believes that it can only gain from shattering norms, because Democrats are too timid and afraid of their own shadow. And the only way to disabuse the GOP of that notion is to show them what happens to their side when the norms are gone. We cannot restore the norms magically by having one side abide by them. That would only make things worse by reiterating to the Republican Party that it might as well shatter any norms it wants because Democrats will just go back to abiding by them, even when they constrict the political fortunes and the power of Democratic lawmakers. It can’t work that way. It can only work if Democrats give Republicans a taste of their own medicine and remind them why the norms were there in the first place.

I often say that norms are not an end in themselves. Norms are a means to a larger end, which is a functioning democratic state. And the notion that we can rebuild a world of norms unilaterally is the enduring failure of the Biden administration.

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-31')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">The Annual Conundrums Episode, With Stephen Colbert</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-31" style="display:none;">
            <h2>The Annual Conundrums Episode, With Stephen Colbert</h2>
            <p><strong>News and Politics - Slate Magazine | 2025-12-26</strong></p>
            <a class="original-link" href="https://slate.com/podcasts/political-gabfest/2025/12/politics-emily-john-david-and-stephen-colbert-answer-conundrums-boxing-day?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Emily, John, David, and special guest Stephen Colbert close 2025 by answering listeners’ questions of all kinds.

Please enable javascript to get your Slate Plus feeds.

If you can&#39;t access your feeds, please contact customer support.

Thanks! Check your phone for a link to finish setting up your feed.

Enter your phone number and we&#39;ll text you a link to set up the
        podcast in your app:

We&#39;ll only text you about setting up this podcast, no spam.

Apple Podcasts will only work on MacOS operating systems since Catalina. We do not support Android apps on desktop at this time.

These links will only work if you&#39;re on the device you listen to podcasts on.

We&#39;re sorry, but something went wrong while fetching your podcast feeds. Please contact us at plus@slate.com for help.

This week, Emily Bazelon, John Dickerson, David Plotz, and special guest Stephen Colbert answer listeners’ conundrums of all kinds: the meaningful, the trivial, and the delightfully absurd.

Thanks to all Conundrums contributors: Karl, Elodie, Mitchell, Brian, Phil, Eric, Christian, Kyle, Matthew, Katie, Jesse, John, Bjorn, David, Colin, Alan, Emily, Marie, and Liam!

In the latest Gabfest Reads, John talks with journalist and author Andrew Ross Sorkin about his new book, 1929: Inside the Greatest Crash in Wall Street History and How It Shattered a Nation — the story of speculation, debt, and the human drives that fueled the Wall Street crash that changed everything.

Email your chatters, questions, and comments to gabfest@slate.com. (Messages may be referenced by name unless the writer stipulates otherwise.)

Podcast production by Nina Porzucki with live show support from Katie Rayford and the team at the New York Society for Ethical Culture

You can find the full Political Gabfest show pages here.

Want more Political Gabfest? Join Slate Plus to unlock weekly bonus episodes. Plus, you’ll access ad-free listening across all your favorite Slate podcasts. You can subscribe directly from the Political Gabfest show page on Apple Podcasts and Spotify. Or visit slate.com/gabfestplus to get access wherever you listen.

Find out more about David Plotz’s monthly tours of Ft. DeRussy, the secret Civil War fort hidden in Rock Creek Park.

Voted “Favorite Political Podcast” by Apple Podcasts listeners. Stephen Colbert says, &quot;Everybody should listen to the Slate Political Gabfest.&quot; The Gabfest is hosted by Emily Bazelon, John Dickerson, and David Plotz. Listen for the debates, stay for the cocktail chatter.

David Plotz is a host of the Slate Political Gabfest and the CEO of City Cast.

Emily Bazelon is a staff writer at the New York Times Magazine, the author of Charged and Sticks and Stones, and co-host of the Slate Political Gabfest.

John Dickerson is host of CBS News Prime Time With John Dickerson, co-host of the Slate Political Gabfest, host of the Whistlestop podcast, and author of The Hardest Job in the World.</div>
        </div>
        
        <div class="card" onclick="openModal('content-32')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">What Is Another Term for <em>Pyrosis</em>?</div>
            <div class="meta">2025-12-25</div>
        </div>
        
        <div id="content-32" style="display:none;">
            <h2>What Is Another Term for <em>Pyrosis</em>?</h2>
            <p><strong>News and Politics - Slate Magazine | 2025-12-25</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2025/12/trivia-quiz-daily-slate-science-astronomy-medicine-geology.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Please enable Javascript in your browser to view Slate interactives.

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-33')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">A Rabbi’s Plea for Peace | 2025 in Review</div>
            <div class="meta">2025-12-25</div>
        </div>
        
        <div id="content-33" style="display:none;">
            <h2>A Rabbi’s Plea for Peace | 2025 in Review</h2>
            <p><strong>News and Politics - Slate Magazine | 2025-12-25</strong></p>
            <a class="original-link" href="https://slate.com/podcasts/what-next/2025/12/gaza-israel-rabbi-peace-starvation?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">More than a thousand Jewish leaders want an end to starvation in Gaza. She’s one of them.

Please enable javascript to get your Slate Plus feeds.

If you can&#39;t access your feeds, please contact customer support.

Thanks! Check your phone for a link to finish setting up your feed.

Enter your phone number and we&#39;ll text you a link to set up the
        podcast in your app:

We&#39;ll only text you about setting up this podcast, no spam.

Apple Podcasts will only work on MacOS operating systems since Catalina. We do not support Android apps on desktop at this time.

These links will only work if you&#39;re on the device you listen to podcasts on.

We&#39;re sorry, but something went wrong while fetching your podcast feeds. Please contact us at plus@slate.com for help.

All this week, What Next and What Next: TBD are re-airing some of our favorite conversations from throughout the year and checking back with the people in those conversations to see how things have – or haven’t – changed. This episode is from August.

More than a thousand rabbis and Jewish leaders have signed a letter calling for Israel to end “the use and threat of starvation as a weapon of war.” This New York rabbi, who has felt a connection to Israel her whole life, explains why she signed.

Guest:  Sarah Reines, rabbi at Temple Emanu-El in Manhattan.

If you want to support more of this reporting, in 2026 and beyond, consider signing up for Slate Plus. You’ll enjoy ad-free listening across the Slate network, early access to tickets for live events, and you’ll never hit the paywall on the site.

We’re on a mission to get 100 people to join Slate Plus before the new year—and we’re even offering a 50-percent-off deal to folks who join us right now. Visit Slate.com/whatnextplus and use the code WHATNEXT50 to get a year of Slate Plus for $59.

Podcast production by Ethan Oberman, Elena Schwartz, Paige Osburn, Anna Phillips, Madeline Ducharme, and Rob Gunther.

The problem with the news right now? It’s everywhere. And each day, it can feel like we’re all just mindlessly scrolling. It’s why we created What Next. This short daily show is here to help you make sense of things. When the news feels overwhelming, we’re here to help you answer: What next? Look for new episodes every weekday morning.

Rob Gunther is a senior producer of What Next, Slate’s daily news podcast. He has worked on news podcasts and radio at Slate, Business Insider, Apple News, and WNYC.</div>
        </div>
        
        <div class="card" onclick="openModal('content-34')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">Who Was the First Wife of King Henry VIII?</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-34" style="display:none;">
            <h2>Who Was the First Wife of King Henry VIII?</h2>
            <p><strong>News and Politics - Slate Magazine | 2025-12-24</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2025/12/trivia-quiz-daily-slate-history-cabinet-scandal-monarchy.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Please enable Javascript in your browser to view Slate interactives.

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-35')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">Gutting Our National Parks | 2025 Year in Review</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-35" style="display:none;">
            <h2>Gutting Our National Parks | 2025 Year in Review</h2>
            <p><strong>News and Politics - Slate Magazine | 2025-12-24</strong></p>
            <a class="original-link" href="https://slate.com/podcasts/what-next/2025/12/trump-national-parks-service-review?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">“America’s best idea” slams into some of its worst tendencies.

Please enable javascript to get your Slate Plus feeds.

If you can&#39;t access your feeds, please contact customer support.

Thanks! Check your phone for a link to finish setting up your feed.

Enter your phone number and we&#39;ll text you a link to set up the
        podcast in your app:

We&#39;ll only text you about setting up this podcast, no spam.

Apple Podcasts will only work on MacOS operating systems since Catalina. We do not support Android apps on desktop at this time.

These links will only work if you&#39;re on the device you listen to podcasts on.

We&#39;re sorry, but something went wrong while fetching your podcast feeds. Please contact us at plus@slate.com for help.

All this week, What Next and What Next: TBD are re-airing some of our favorite conversations from throughout the year and checking back with the people in those conversations to see how things have – or haven’t – changed. This episode is from August.

From the Statue of Liberty to the Golden Gate Bridge, and places in between like Yellowstone and the site of the Battle of Gettysburg, the National Park Service has been a point of American pride since its inception. And with a small budget and actually generating revenue, even fiscal hawks had no reason to complain.

So why is the Trump administration cutting their budget?

Jon B. Jarvis,18th director of the National Parks.

Kevin Heatley, former superintendent of Crater Lake National Park, Oregon.

If you want to support more of this reporting, in 2026 and beyond, consider signing up for Slate Plus. You’ll enjoy ad-free listening across the Slate network, early access to tickets for live events, and you’ll never hit the paywall on the site.

We’re on a mission to get 100 people to join Slate Plus before the new year—and we’re even offering a 50-percent-off deal to folks who join us right now. Visit Slate.com/whatnextplus and use the code WHATNEXT50 to get a year of Slate Plus for $59.

Podcast production by Ethan Oberman, Elena Schwartz, Paige Osburn, Anna Phillips, Madeline Ducharme, and Rob Gunther.

The problem with the news right now? It’s everywhere. And each day, it can feel like we’re all just mindlessly scrolling. It’s why we created What Next. This short daily show is here to help you make sense of things. When the news feels overwhelming, we’re here to help you answer: What next? Look for new episodes every weekday morning.

Mary Harris is the host and managing editor of What Next, Slate&#39;s new daily news podcast. She has reported throughout the public radio system, for NPR, Marketplace, and WNYC.</div>
        </div>
        
        <div class="card" onclick="openModal('content-36')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">Researchers create world's smallest programmable, autonomous robots</div>
            <div class="meta">2025-12-25</div>
        </div>
        
        <div id="content-36" style="display:none;">
            <h2>Researchers create world's smallest programmable, autonomous robots</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2025-12-25</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2025-12-world-smallest-programmable-autonomous-robots.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-37')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">How ChatGPT could change the face of advertising, without you even knowing about it</div>
            <div class="meta">2025-12-25</div>
        </div>
        
        <div id="content-37" style="display:none;">
            <h2>How ChatGPT could change the face of advertising, without you even knowing about it</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2025-12-25</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2025-12-chatgpt-advertising.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-38')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">First Bond game in a decade hit by two-month delay</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-38" style="display:none;">
            <h2>First Bond game in a decade hit by two-month delay</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2025-12-24</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2025-12-bond-game-decade-month-delay.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-39')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">AI overestimates how smart people are, according to economists</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-39" style="display:none;">
            <h2>AI overestimates how smart people are, according to economists</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2025-12-24</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2025-12-ai-overestimates-smart-people-economists.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-40')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">For computational devices, talk isn't cheap: Research reveals unavoidable energy costs across all communication channels</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-40" style="display:none;">
            <h2>For computational devices, talk isn't cheap: Research reveals unavoidable energy costs across all communication channels</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2025-12-24</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2025-12-devices-isnt-cheap-reveals-unavoidable.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-41')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">Redesigned carbon molecules boost battery safety, durability and power</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-41" style="display:none;">
            <h2>Redesigned carbon molecules boost battery safety, durability and power</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2025-12-24</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2025-12-redesigned-carbon-molecules-boost-battery.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-42')">
            <div class="source">The Register</div>
            <div class="title">'PromptQuest' is the worst game of 2025. You play it when trying to make chatbots work</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-42" style="display:none;">
            <h2>'PromptQuest' is the worst game of 2025. You play it when trying to make chatbots work</h2>
            <p><strong>The Register | 2025-12-26</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2025/12/26/ai_is_like_adventure_games/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Opinion When Microsoft recently decided to open source the seminal text adventure game Zork, I contemplated revisiting it during the festive season... until I realized I&#39;ve spent much of 2025 experiencing the worst of such games when using AI chatbots.

Adventure games like Zork and its many imitators invited players to explore a virtual world, often a Tolkien-esque cave, that existed only as words.

&quot;You enter a dark room. A Goblin pulls a rusty knife from its belt and prepares to attack!&quot; was a typical moment in such games. Players, usually armed with imagined medieval weapons, might respond &quot;Hit Goblin&quot; in the expectation that phrase would see them draw a sword to smite the monster.

But the game might respond to &quot;Hit Goblin&quot; by informing players &quot;You punch the Goblin.&quot;

The Goblin would dodge the punch and stab the player with the rusty knife.

Game over... until the player tried &quot;Hit Goblin with sword&quot; or &quot;Stab Goblin&quot; or whatever other syntax the game required, assuming they didn&#39;t just give up out of frustration at having to guess the correct verb/noun combination.

Adventure games were big in the 1980s, a time when computers were flaky and unpredictable, and AI was an imagined technology. Games that required obscure syntax were mostly tolerable and generally excused.

I&#39;m less tolerant of AI making me learn its language.

For example, I recently prompted Microsoft&#39;s Copilot chatbot to scour data available online and convert some elements of it into a downloadable spreadsheet. The bot accepted that request and produced a Python script that it claimed will write a spreadsheet.

In other AI experiments, I have found that the same prompt produces different results on different days. One prompt I use to check I haven&#39;t left any terrible typos in stories produces responses in a different format every time I use it. Microsoft has also, in its wisdom, decided to offer different versions of Copilot in Office and in its desktop app. Each produces different results from the same prompt and the same source material.

Using AI has therefore become a non-stop experiment in &quot;Hit/Kill/Stab/Smite Goblin.&quot;

And when Copilot starts using a new model, which it does without any change to its UI, prompts that worked reliably in the past produce different results, meaning I need to relearn what works.

My point here is not that chatbots do dumb things and make mistakes. It&#39;s that working with this tech feels like groping through a cave in the dark – a horrible game I call &quot;PromptQuest&quot; – while being told this is improving my productivity.

After Copilot gave me a Python script instead of a spreadsheet, I played a long session of PromptQuest during which Microsoft&#39;s AI responded to many different prompts by repeatedly telling me it was ready to make a spreadsheet, would make it available to download, and had completed the job to my satisfaction.

It never delivered the spreadsheet, and my frustration grew to the point at which I instructed Copilot to produce a progress bar so I could see it work.

A progress bar produced by Microsoft Copilot

You can see the results above. Ironically, I think it looks a lot like the output of a text adventure game. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-43')">
            <div class="source">The Register</div>
            <div class="title">IT team forced to camp in the office for days after Y2K bug found in boss's side project</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-43" style="display:none;">
            <h2>IT team forced to camp in the office for days after Y2K bug found in boss's side project</h2>
            <p><strong>The Register | 2025-12-26</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2025/12/26/on_call/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">On Call Y2K December 26th is a holiday across much of the Reg-reading world, but it&#39;s also a Friday – the day on which we present a fresh instalment of On Call, the reader-contributed column that recounts your tales of tech support encounters and exasperation.

This holiday season we&#39;re dipping into tales of tech support in the time of Y2K, starting with this tale from a reader we&#39;ll Regomize as &quot;Cane&quot; and who told us that in December 199 he worked in the IT department at the UK branch of a &quot;multinational booze purveyor.&quot;

Cane said he and his team felt confident.

&quot;We spent much of the last two years testing and verifying everything, upgrading and replacing as needed,&quot; he told On Call.

Senior management came to appreciate the importance of the task and to make sure all staff understood the seriousness of the Y2K remediation effort, commissioned a custom screensaver that displayed a countdown to the fateful moment.

The alcohol making organization prevented the IT team from taking leave for two weeks after December 31st and warned they may need to be on-site full time for the duration in case things went wrong.

&quot;They also hired consultants at ruinous cost to sit there and wear suits,&quot; Cane told On Call. &quot;As the hour ticked closer, we were ordered by the Top Floor People to physically disconnect the network cable from the internet, to prevent little viruses from crawling down the wires and getting us.&quot;

All present watched the clock tick down from 1999 to 2000, then breathed a sigh of relief when nothing happened.

&quot;After an hour we were allowed to reconnect to the outside world and confirm that the world had not ended,&quot; Cane told On Call.

&quot;Any PC that had been left switched on – against instructions – mysteriously crashed,&quot; Cane wrote.

In case your career started after the year 2000 or you&#39;ve forgotten the Y2K mess, let&#39;s refresh your memory … by explaining that in the early years of computing, memory was so scarce and expensive that programmers used only two digits to record years.

That became an issue as the year 2000 approached, because as the clock ticked over into the new year some programs would assume it was the year 1900 and malfunction … perhaps catastrophically.

All around the world, organizations spent billions testing and remediating their code. And on New Year&#39;s Eve 1999, many IT pros worked instead of partying, to make sure skilled help was at hand in case things went bad.

The IT team swung into action and rebooted the nearest machine, which came back to life and displayed a screensaver that was now counting backwards into negative numbers.

Cane later learned that the developer of the Y2K screensaver did not test it for the Y2K bug.

&quot;It was created, at high cost, by an external and apparently incompetent third party,&quot; he told On Call.

Cane&#39;s company kept the tech team camping in the office for a couple of days, until it became clear nothing else would break.

&quot;We returned to normal, though the consultants were maybe a bit more flush in the bank account,&quot; Cane reported. &quot;Us poor salaried employees had to make do with time-off-in-lieu.&quot;

Have you worked tech support during a major event or holiday period? If so, click here to send email to On Call so we can share your story! ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-44')">
            <div class="source">The Register</div>
            <div class="title">Humanoid robots are still novelty acts, but investment is surging to make them real tomorrow</div>
            <div class="meta">2025-12-25</div>
        </div>
        
        <div id="content-44" style="display:none;">
            <h2>Humanoid robots are still novelty acts, but investment is surging to make them real tomorrow</h2>
            <p><strong>The Register | 2025-12-25</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2025/12/25/humanoid_robots_investment_surge/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">By the time the humanoid robots arrived at the Humanoids Summit at the Computer History Museum in Mountain View, California, on December 11, the registration line had already extended downstairs to the lobby.

Controlled by accompanying human handlers, the humanoids were herded into the elevator, sparing them the challenge of climbing the stairs to the mezzanine registration desk.

&quot;No one shows you climbing stairs when it comes to these humanoids,&quot; observed Abhinav Gupta, co-founder of Skild AI, during a presentation later that morning.

Gupta did, though, in a video demonstrating how the Skild foundation model can help a robot to climb stairs and step over unstable terrain.

Humanoids Summit chair and founder Modar Alaoui, general partner at ALM Ventures, a VC firm backing several attending companies, would later remark, &quot;Locomotion is a solved problem.&quot;

Image of a humanoid robot arriving at the Humanoids Summit - Click to enlarge

That&#39;s a slight exaggeration. Humanoid robots are ready for marketing and experimentation. In promotional videos, they perform impressive, potentially useful feats. But commercial deployment at scale will take decades, even if persistent technical challenges like manual dexterity may be solved sooner.

The technology isn&#39;t yet good enough, the cost remains too high, and organizations need to figure out how to use them. More work needs to be done on safety, and people aren&#39;t yet ready to accept them.

Gupta followed a presentation by Ani Kelkar and Mikael Robertson, partner and senior partner respectively at McKinsey & Company, a corporate consultancy known for advocating staff cuts that itself has been trimming staff due to AI.

Speaking from a management perspective, Robertson said, &quot;Looking at the US as an example, only about 6 percent of factories today have applied robotic automation at scale ... And by comparison, China today is installing 10 times more robots each year than the US.&quot;

Robertson said that interest and investment in humanoid robotics have surged.

Kelkar said there are about 50 companies credibly doing so – about 20 in China, 15 in North America, 7 in EMEA, and 7 in Asia (outside of China).

&quot;With all of that talent and all of the investments that Mikael talked about, we are excited that we are finally going to get solutions that will work,&quot; said Kelkar.

Not immediately though. Beyond the difficulty of deploying any sort of robot at scale, Kelkar suggested the viability of robots may depend on human labor management.

&quot;So in a warehousing context, if you have a turnover rate at 40 percent, you take one or two months, you hire someone, you train them up, and five months later, that cycle repeats,&quot; he explained. &quot;And that becomes a significant drag on industrial productivity.

&quot;And I think fundamentally leaders are recognizing that the reason to leverage robotics and automation is not for worker replacement, it&#39;s for redesigning the nature of work. It&#39;s to enhance the work that human labor does, and bring robots even as tools and teammates, not necessarily a job displacement member.&quot;

Pitching a human-robot detente appears to be advisable because humans represent one of several obstacles that humanoid robot makers need to consider.

During a panel discussion led by Washington Post reporter Gerrit de Vynck, Jeff Pittelkow, managing director for Roboworx, a robot management service, said that robot customers would be happy to replace humans with robots in the workplace.

&quot;Customers are very ROI focused, right?&quot; he said. &quot;I mean, a humanoid robot is probably going to replace a human. You know, that&#39;s the dirty little secret. So the ROI has to be &#39;the humanoid robot has to do 100 percent of what the human can do for no more money than a human costs.&#39;&quot;

Pittelkow said companies buying these robots, or planning to do so, don&#39;t care if the robot is teleoperated or autonomous, as long as the price is right.

But human workers have proven reluctant to contribute to their replacement. Pittelkow said that people can present an obstacle to deployment.

&quot;The co-workers, as we call them, of the robots,&quot; he said, &quot;they are not super-accepting. They see [robots] as a threat ... They&#39;re hesitant. &#39;This robot&#39;s coming here, and eventually I&#39;m not going to have a job because this robot&#39;s going to have a job.&#39; So that&#39;s something we have to help everybody get over.&quot;

That antipathy toward robots may manifest as sabotage or neglect. Human workers, he said, &quot;have no problem sabotaging the robot. They have no problem with the robot being broken, sitting in a corner. We see that all the time.&quot;

In one case, Pittelkow said, staff put a sign on a robot that said, &quot;On Strike,&quot; and left it in a corner. Or, he suggested, human workers may just decide to neglect updates to mapping localization or firmware and to avoid reporting failures.

Anyone planning to deploy humanoid robots, he said, should be aware of this dynamic.

&quot;So that has to be a huge part of your business model when you get to scale in production,&quot; he said.

As if social acceptance weren&#39;t enough of a challenge, the enabling technology isn&#39;t there yet. And this affects whether robots are worthwhile financially.

Pittelkow pointed to a robot his company has working inside a movie theater to deliver food.

&quot;It&#39;s one of those movie theater restaurants,&quot; he explained. &quot;And unsurprisingly, in hindsight, it keeps sucking up popcorn into its drive wheels as it drives through the movie theater. And that&#39;s problematic. I mean, popcorn gets smushy and it&#39;s oily and it causes real problems.&quot;

His company also runs an autonomous mobile robot (AMR) in a high-end restaurant – a wheeled unit rather than humanoid.

&quot;We go there to do our maintenance check on this robot ... and an employee came up to us and said, &#39;Oh, I think that&#39;s the one I saw the mouse run out of.&#39; This is a five-star restaurant, let me make that clear. And a mouse had gotten in and had eaten all the internals of that AMR. And it was a total loss.&quot;

Pittelkow asked, &quot;Is your humanoid going to survive a mouse attack while it&#39;s sitting there overnight? And what&#39;s the cost of downtime? And that&#39;s the big thing. ROI is all about uptime.&quot;

During that same panel discussion, Joe Michaels, senior global VP of sales and marketing at 1HMX, cited Gupta&#39;s challenge to robot makers to prove that their bots can manage stairs and urged conference attendees to apply a similarly critical eye to the types of manual interactions depicted in robot videos.

&quot;We&#39;re still mostly at the parallel gripper stage,&quot; he said. &quot;And if parallel grippers were good enough to run and build the world, I think God would have given all of us two digits instead of five with opposable thumbs.&quot;

Alaoui, in a session that followed, would echo that assessment. &quot;Dexterity is the last frontier,&quot; he said.

In the conference exhibition hall, an ALM Ventures-funded robot torso underscored that point by folding shirts very slowly and not all that well.

Data availability represents another barrier – the machine learning models intended to replicate human activity have to be fed with vast quantities of data in order to improve to the level of commercial viability. Gathering that information will require a lot of trial and error.

Humanoid robots face a long apprenticeship as jesters and novelty acts before they&#39;re taken seriously. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-45')">
            <div class="source">The Register</div>
            <div class="title">AMD Strix Halo vs Nvidia DGX Spark: Which AI workstation comes out on top?</div>
            <div class="meta">2025-12-25</div>
        </div>
        
        <div id="content-45" style="display:none;">
            <h2>AMD Strix Halo vs Nvidia DGX Spark: Which AI workstation comes out on top?</h2>
            <p><strong>The Register | 2025-12-25</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2025/12/25/amd_strix_halo_nvidia_spark/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Hands On Most GenAI models are trained and run in massive datacenter clusters, but the ability to build, test, and prototype AI systems locally is no less relevant today.

Until recently, this required high-end, multi-GPU workstations often costing tens of thousands of dollars. With the launch of the GB10-based DGX Spark in October, Nvidia set out to change this. While nowhere near as powerful, with 128 GB of video memory, the system is essentially an AI lab in a box capable of running just about any AI workload you throw at it.

As we mentioned in our initial hands-on, the Spark isn&#39;t the first or even the cheapest option out there. AMD and Apple also offer systems with large quantities of unified memory which are shared between the CPU and GPU, something that has made them incredibly popular among AI developers and enthusiasts.

AMD&#39;s Ryzen AI Max+ 395 APU, which for the sake of brevity we&#39;re simply going to refer to as &quot;Strix Halo&quot; from here on out, is particularly interesting. In addition to selling for between three-quarters and half the cost of the Spark, Strix Halo builds on roughly the same ROCm and HIP software stack as the company&#39;s datacenter products. This provides a clearer, though not necessarily seamless migration path from desktop to datacenter.

To see how Strix Halo stacks up against the Spark, HP sent over its Z2 Mini G1a workstation so we could find out how each of these little boxes of TOPS fares in a variety of AI workloads, ranging from single-user and batched inference to fine-tuning and image generation.

Compared to the Spark, HP&#39;s Z2 Mini G1a is a fair bit bigger thanks in part to its integrated PSU and larger cooling solution

The first thing you&#39;ll notice is the HP is significantly larger than the Spark. This is partly because Nvidia opted for an external power brick that connects over USB-C while HP opted for a slightly larger chassis with an integrated power supply.

We generally prefer HP&#39;s approach here, especially because the larger chassis allows for a beefier cooling solution, though the Spark&#39;s fit and finish definitely comes across as the more premium of the two.

While the Spark uses an all-metal chassis that doubles as a heat sink, the G1a feels much more like an HP product with a clean albeit plastic shell covering a stiff metal chassis. The benefit of this design philosophy is serviceability. Getting into the G1a is as easy as pressing a button at the back of the machine sliding off the top cover.

However, because the machine uses soldered LPDDR5x memory, there&#39;s not actually that much to do in either system. The HP does feature two standard 2280 PCIe 4.0 x4 M.2 SSDs which are user-serviceable.

For comparison, the Spark is much more appliance-like, though the SSD can also be swapped by removing a magnetic plate and four screws at the bottom of the system.

HP&#39;s design is far easier than the Spark to service with a lid that removes with a press of a button

Inside the machines are a pair of blower fans which pull in cool air from the front and exhaust it out the back. If you&#39;re curious, the G1a&#39;s dual M.2 SSDs are located directly under those fans, which should keep them from overheating under heavy load.

Around the back of the machines, we see HP has taken a very different approach to Nvidia in terms of I/O.

While the Spark prioritizes high-speed networking, the I/O on HP&#39;s G1a is far more pedestrian

From left to right, we see a 2.5 GbE RJ45 port, four standard USB ports (2x 10 Gbps, 2x USB 2.0), a pair of 40 Gbps Thunderbolt ports alongside two mini DisplayPorts. On the side of the machine, you&#39;ll find a 3.5 mm headphone-microphone combo jack and two additional 10 Gbps USB 3.0 ports in both standard and USB-C form factors.

You&#39;ll also notice two blank spaces that can be configured with any number of HP&#39;s Flex IO modules, including serial, USB, and gigabit, 2.5 GbE or 10 GbE ports.

The Spark, meanwhile, prioritizes high-speed networking for multinode AI compute environments. Alongside the power button are four USB-C ports, the leftmost of which is used for power delivery. For display out, there&#39;s an HDMI port along with a 10 GbE RJ45 network port and a pair of QSFP cages offering a combined 200 Gbps of network bandwidth via the system&#39;s onboard ConnectX-7 NIC.

These ports are designed to enable clustering of multiple Spark or other GB10 systems using the same hardware and software you&#39;d find in the datacenter.

As we understand it, you could also use the G1a&#39;s Thunderbolt ports as a high-speed network interface for interconnecting multiple systems together, though we weren&#39;t able to test that use case.

To be clear, neither system is the cheapest chariot for their respective silicon. The DGX Spark retails for $3,999 while HP&#39;s Z2 Mini G1a, as specced, is currently selling for about $2,950.

You can find similarly equipped GB10 and Strix Halo boxes that can be had for significantly less if you&#39;re willing to compromise on storage, connectivity, or I/O.

HP, ASUS, and a few others have OEM versions of the Spark that start around $3,000 for 1 TB of storage. We&#39;ve also seen Strix Halo systems with 128 GB for a little over $2,000, though the memory shortage appears to have driven up prices some, and you&#39;ll be missing out on the Enterprise features like remote management or memory encryption offered by the &quot;Pro&quot; variant of the chip.

So, if either of these systems strike your fancy, but you&#39;re unconvinced by the pricing, you may be able to find a better deal from one of the other OEMs. In the case of the GB10 systems, you&#39;re not giving up much apart from aesthetics, opting for an OEM rebadge over the Founders Edition.

Before we dig into generative AI performance, which we expect most folks to care about, we&#39;d like to take a moment to talk about the machines&#39; respective CPUs.

Strix Halo is a rather interesting processor. Much like its desktop counterparts, it features 16 full-fat Zen 5 cores spread across two core-complex dies (CCDs) that are capable of clocking to 5.1 GHz. Those CCDs are bonded using advanced packaging to an I/O die that handles memory, PCIe, and graphics processing.

The Z2 Mini G1a actually uses the Pro variant of the chip, which adds a number of hardware security and management capabilities, which may be attractive to enterprises deploying these systems in volume or in sensitive environments.

The Spark&#39;s GB10 Grace Blackwell superchip meanwhile features an Arm CPU die developed in collaboration with MediaTek containing 10 X925 performance cores and 10 Cortex A725 efficiency cores for a total of 20.

While these cores are by no means slow, in our admittedly limited testing, AMD&#39;s Zen 5 microarchitecture delivered between 10 and 15 percent higher performance across our Sysbench, 7zip compression/decompression, and HandBrake transcoding workloads.

However, in the High-Performance Linpack benchmark, which is representative of many HPC workloads, the G1a achieved more than twice the double-precision performance at 1.6 teraFLOPS versus 708 gigaFLOPS on the Spark. We&#39;ll note that this score was achieved using only the X925 cores as enabling the A725 for the test actually nerfed performance, suggesting there may be room for improvement.

While GenAI performance is heavily dependent on low-precision GPU FLOPS, Strix Halo&#39;s beefier CPU may make it a more flexible option for those looking for a PC that can run GenAI models rather than an appliance for AI.

Moving on to GenAI, we should talk for a minute about some of the performance claims being made about both of these systems.

While Nvidia may claim a petaFLOPS of AI compute, the reality is most users will never get close to that. The reason is simple: achieving that level of performance requires structured sparsity, a feature with little if any benefit to inference workloads.

Because of this, Spark&#39;s peak performance is really closer to 500 dense teraFLOPS, and only for workloads that can take advantage of the FP4 data type. More often than not that means the Spark will actually run at 8 or 16-bit precision, limiting peak performance to 250 and 125 teraFLOPS respectively.

Sustained performance usually falls a bit short of the theoretical. Testing the GB10 in the Max Achievable MatMul FLOPS (MAMF) benchmark, we achieved 101 teraFLOPS at BF16 and 207 teraFLOPS at FP8.

But what about the Strix Halo part powering the G1a? Well, here we see one of AMD&#39;s biggest weaknesses. While the House of Zen claims 126 platform TOPS for its top-specced Strix Halo SKUs, you&#39;ll be hard pressed to find any app that can take full advantage of that. Fifty of those TOPS are delivered by the NPU, which requires specialized software to harness – more on that later. The remaining TOPS are achieved using the CPU and GPU.

Strix Halo&#39;s GPU is no slouch. By our estimate – AMD doesn&#39;t actually give peak floating point performance for the chip – the GPU is capable of churning out about 56 teraFLOPS of peak BF16 performance. In MAMF, we achieved about 82 percent of that at 46 teraFLOPS, which again isn&#39;t bad.

But because the GPU is based on AMD&#39;s older RDNA 3.5 architecture, it lacks support for the lower-precision data types offered by the Spark.

Technically, the architecture does support INT8, but the performance is essentially the same as BF16. In theory, it should deliver about 112 TOPS of INT4, but the trick is finding software that actually does computation at that precision. Sixteen distinct values just doesn&#39;t offer much granularity.

On paper, this gives the Spark a 2.2-9x performance advantage over the Strix Halo in raw AI compute capacity.

And while this played out repeatedly in our testing, compute is only one side of the GenAI coin. The other is memory bandwidth. Depending on your use case, it may even render the performance gap between the AMD and Nvidia systems a non-issue.

We&#39;re going to start by talking about large language model (LLM) inference precisely because it illustrates why more TOPS and FLOPS don&#39;t always translate into better AI performance.

For consistency, we ran most of our tests in Linux: Ubuntu 24.04 LTS on the HP and Nvidia&#39;s lightly customized version of the distro, DGX OS.

Editor&#39;s note: We ran into some issues with GPU hangs in Ubuntu when testing the G1a. However, by adding a few kernel arguments, we were able to resolve the issue.

The tweak can be made by editing the Grub boot config by running:

Then update the GRUB_CMDLINE_LINUX=&quot;&quot; entry to look like so:

Once complete, save and exit the editor by pressing Ctrl X. Finally, update the bootloader and restart the machine by running:

If you&#39;re still running into GPU hangs, we recommend checking out this thread on the Framework forum.

Just looking at single-batch performance in Llama.cpp – one of the most popular frameworks for running LLMs on consumer CPUs and GPUs – we can see that the GB10 and Strix Halo churn out tokens at a similar pace, with the AMD box pulling off a narrow lead when using the Vulkan backend.

In single batch inference, AMD&#39;s Strix Halo APU trades blows with the Spark on token generation, but falls well behind on time to first token

In single-user scenarios, token generation is usually bottlenecked by memory bandwidth. The GB10 claims about 273 GB/s of memory bandwidth while AMD&#39;s Strix Halo manages about 256 GB/s.

This is likely one of the reasons why many AI enthusiasts were so disappointed in the Spark when it first debuted. For between two-thirds and half the price, you could get a Strix Halo box that churns out tokens just as quickly.

However, if you turn your attention to the time-to-first-token column, you&#39;ll notice the GB10&#39;s GPU is roughly 2-3x faster than the one in the Strix Halo box, and that&#39;s when processing a relatively short 256-token prompt. With larger sequence lengths, this gap becomes more pronounced. This is because prompt processing tends to become compute bound quite quickly.

For shorter prompts or multi-turn conversations, Llama.cpp&#39;s prompt caching mitigates a lot of this performance deficit. In this scenario, we&#39;re only talking about waiting a second or two longer on the AMD platform, something customers just looking to run LLMs at home may be willing to overlook considering Strix Halo&#39;s lower average selling price.

For those whose workloads require feeding large documents into the model&#39;s context, the Spark&#39;s more potent GPU gives it a clear advantage here, just one that customers will need to weigh against its higher price.

Alongside single-batch performance, we also tested the two machines at larger batch sizes. It&#39;s not uncommon for users to batch up jobs like extracting information from a stack of documents or emails rather than processing them sequentially one at after another.

In this case, we&#39;re using vLLM, which in our experience handles large batch sizes and concurrency more gracefully than Llama.cpp, which is better optimized for single-user applications. We&#39;re also using Qwen3-30B-A3B-Instruct-2507 at its native BF16 precision to avoid quantization overheads.

To see how the machines performed, we tasked them with processing a 1,024-token input and generating a 1,024-token response at batch sizes ranging from one to 64.

This graph charts overall throughput (tok/s) against end-to-end latency at various batch sizes ranging from 1-64

On the X axis, we&#39;ve plotted the time in seconds required to complete the batch job, while on the Y axis we show the overall throughput in tokens per second at each batch size.

Once again, the Spark&#39;s faster graphics processor gives it a leg up over the G1a. While this is clearly a win for the Spark, unless you&#39;re routinely running batch jobs, the performance advantage is likely to go unnoticed, especially if you can schedule them to run overnight. Batch inference isn&#39;t exactly interactive and so you can easily walk away and come back when it&#39;s done.

It&#39;s a similar story when we look at using fine-tuning techniques to teach models new skills by exposing them to new information.

Fine-tuning requires a lot of memory, potentially as much as 100 GB for a model like Mistral 7B. As we&#39;ve previously discussed, techniques like LoRA or QLoRA can dramatically reduce the memory required to train a model.

With up to 128 GB of memory available on either platform, both the Spark and G1a are well suited to this workload, though they aren&#39;t particularly fast.

For full fine-tuning, the GB10 managed to pull well ahead of AMD&#39;s Strix Halo, but falls short of even last-gen workstation cards like the W7900 or RTX 6000 Ada

Running a full fine-tune of Meta&#39;s Llama 3.2 3B, we see that the Spark completes the job in roughly two-thirds the time of the G1a. However, compared to workstation cards like the Radeon Pro W7900 or RTX 6000 Ada, which offer both higher floating point performance as well as much faster GDDR6 memory, the Spark and G1a are simply outclassed.

Where things really get interesting is when we start looking at using QLoRA on larger models. To fine-tune a model like Llama 3.1 70B at home, you&#39;d normally need multiple workstation cards. But thanks to their massive memory footprint, this job is entirely possible using either the AMD or Nvidia boxes.

Moving up to a larger 70B parameter and the GB10&#39;s faster GPU gives it a leg up in QLoRA fine-tuning

With a relatively small dataset – something we&#39;ve previously shown can be more than adequate to tweak the style of a model – performance was more in line with what we were expecting. The G1a completed the job in a little over 50 minutes, compared to the Spark at around 20.

For bigger fine-tuning jobs using larger databases or LoRA ranks, this could easily extend to hours or potentially days, making the Spark&#39;s performance advantage more significant.

But just like we discussed with our multi-batch inference tests, unless you&#39;re fine-tuning models regularly, the Spark&#39;s higher performance may not be worth the price over a similarly equipped Strix Halo system from HP, Minisforum, Framework, or any one of the other mini-PC vendors.

One area where the Spark&#39;s higher performance does give it a definitive advantage is in image and video generation workloads. Like fine-tuning, image gen is an especially compute and memory-hungry workload, but doesn&#39;t tend to be bandwidth bound.

This is partially because image models aren&#39;t as easily compressed as LLMs without major concessions to output quality. As such, many prefer to run these models at their native precision, whether that be FP32, BF16, or FP8.

If you&#39;re planning to generate images or videos using ComfyUI, Nvidia GPUs are still your best bet

Running Black Forest Lab&#39;s FLUX.1 Dev in ComfyUI, our test systems scale almost exactly as expected relative to their 16-bit floating point performance.

With 120 and 125 teraFLOPS of BF16 grunt respectively, the Spark roughly matches AMD&#39;s Radeon Pro W7900, while achieving a roughly 2.5x lead over the Strix Halo-based G1a, which in our testing achieved about 46 teraFLOPS of real-world performance.

Suffice to say image generation is clearly not the Strix box&#39;s strong suit.

AMD&#39;s Strix Halo APUs are also equipped with a pretty competent neural processing unit (NPU) courtesy of the company&#39;s Xilinx acquisition. The XDNA 2 NPU is capable of churning out an extra 50 TOPS of AI performance. The trick, of course, is finding software that can take advantage of it. Most NPU use cases focus on minimizing the power consumption of things like noise reduction in audio and video, background blurring, and optical character recognition.

However, AMD and others have started to utilize the NPU for generative AI applications with mixed results. Thanks to apps like Lemonade Server, you can now run LLMs entirely on the NPU. Unless you&#39;re trying to save on power, you probably won&#39;t want to just yet.

As of this writing, model support is somewhat limited and it doesn&#39;t appear that the NPU has access to all of the GPU&#39;s 250 GB/s of memory bandwidth. Running Mistral 7B on the NPU in Windows, we observed decode performance of just 4-5 tok/s, where we would have expected to see closer to 40 tok/s.

However, AMD is clearly pushing the idea of disaggregated inference, where compute-heavy prompt processing is offloaded to the NPU while the memory bandwidth-intensive decode phase is handled by the GPU. Performance was better, but still not as good as if you&#39;d just run the model on the GPU.

This disaggregated approach makes a lot of sense for power-constrained notebooks, but less so for a desktop system like the G1a. Having said that, we&#39;re interested to see where AMD takes this.

We were also able to get the NPU working in Amuse, a beginner-friendly image generation suite. AMD recently added support for running Stable Diffusion 3 directly on the NPU and, in this case, performance was actually quite a bit better than running the same model on the GPU.

Here we see Amuse using the XDNA 2 NPU in Strix Halo to generate an image using Stable Diffusion 3

Running on the NPU, Amuse was able to generate a 1,024 x 1,024 image using 20 steps in a little over a minute, while running that same test on the GPU required roughly twice that.

There were some caveats worth pointing out. The integration is quite limited at this point, available only in the beginner mode with the performance slider set to balanced. Switching to the &quot;expert mode&quot; disabled the NPU, forcing the model to run on the graphics processor.

The integration is also limited to Stable Diffusion 3, which is growing rather long in the tooth at this point having made its debut over a year ago. Still, it&#39;s good to see more applications taking advantage of the NPU for more than background blurring in video calls.

One selling point that frequently comes up in any comparison between AMD and Nvidia is software compatibility, aka the CUDA moat.

While you can expect just about any software that runs on CUDA to work on the Spark without issue, that&#39;s not guaranteed on the Strix Halo-based G1a.

Nearly two decades of development on CUDA is hard to overlook, but, while AMD has traditionally trailed in software support for its ROCm and HIP libraries, the company has made significant gains in recent months.

A year ago, we faced numerous headaches with libraries that either weren&#39;t available or relied on forks built specifically for AMD&#39;s CDNA-based datacenter chips, which meant they didn&#39;t run on consumer platforms. Today, this isn&#39;t nearly as big a problem. In fact, most of our PyTorch test scripts ran without modification on the AMD platform. However, we&#39;d be lying if we said the experience was anywhere close to as seamless as on the Spark.

A lot of software can be made to work on AMD&#39;s consumer hardware, but it&#39;s not always as simple as running something like pip install xyz-package. We still needed to build libraries from source or use forks made specifically for Radeon GPUs on several occasions — vLLM, BitsandBytes, and Flash Attention 2 are just a few examples.

In many cases, particularly when working with software written closer to the hardware, software needs to be compiled specifically for that generation of Radeon graphics. Llama.cpp is just one example where we needed to compile against a gfx1151 target in order to get the software running.

Wrangling these dependencies isn&#39;t easy, regardless of the platform you&#39;re working with, so it&#39;s nice to see AMD and Nvidia offering Docker containers that have been pre-configured with everything you need to get start started. For our vLLM tests, we used both team Red and Green&#39;s vLLM Docker containers to ensure we were getting the best possible performance.

Perhaps our biggest software challenges weren&#39;t actually software related. Strix Halo is based on AMD&#39;s older RDNA 3.5 architecture, which means it lacks support for many of the lower-precision data types offered by the Spark&#39;s Blackwell GPU. As a result, we were often forced to run models at 16-bit precision, even when FP8 or FP4 would have been preferable.

AMD&#39;s RDNA 4 architecture should resolve some of this by adding support for both sparsity and FP8. However, much of the industry is now reorienting around microscaling data types, like MXFP4, for its smaller memory footprint and wider effective range.

While AMD is rapidly closing the gap, Nvidia still holds a meaningful lead on both hardware and software.

We know you&#39;re all going to ask. Yes. Both of these boxes run Crysis.

At 1440p, medium settings, Crysis Remastered ran at a very respectable 90-100 FPS on the G1a. No real surprises here, as the HP is using an x86 CPU and GPU from a company with a long graphics pedigree.

Getting the game running on the DGX Spark was a little bit more involved because of the GB10&#39;s Arm CPU, which, for better or worse, doesn&#39;t support 32-bit instructions. Thankfully, we were able to get it running using a utility called FEX. If you&#39;re curious, you can find the install script we used here.

Unfortunately, we couldn&#39;t get the Steam performance overlay working on the Spark, which meant we couldn&#39;t get concrete performance metrics. At medium settings, the game was perfectly playable even without resorting to using Nvidia&#39;s AI upscaling tech, which actually worked in game.

While you can get games running on the Spark or other GB10 systems, we&#39;re not sure we&#39;d recommend it over the Strix Halo box or any number of cheaper gaming PCs out there.

Which of these systems is right for you really depends on how much you care about GenAI

Which of these systems is right for you really depends on whether you want a machine specifically for AI or a PC that just happens to be able to run most AI workloads you might throw at it.

We suspect many folks who&#39;ve made it this far likely fall into the latter camp. If you&#39;re going to spend $2K-4K on a new PC, we don&#39;t think it&#39;s unreasonable to expect it to do more than one thing well.

In this respect, HP&#39;s Z2 Mini G1a is one of the better options out there, especially if you&#39;re mostly interested in running single-batch LLM inference as opposed to fine-tuning or image gen. AMD&#39;s Strix Halo SoCs may not have the computational grunt of Nvidia&#39;s GB10 boxes, but it runs Windows and Linux competently and doesn&#39;t require jumping through hoops just to play your favorite games.

Despite the performance gap, for software engineers building apps for the growing AI PC segment, the AMD-based system may still be the better development platform if for no other reason than Microsoft&#39;s NPU mandate.

But for those who really want an AI appliance for prototyping agents, fine-tuning models, or generating text, image, and video content, the Spark or one of its GB10 siblings is probably the better choice, assuming you can stomach the asking price.

In our testing, the machine consistently delivered performance 2-3x that of the AMD-based HP system, while also benefiting from a significantly more mature and active software ecosystem. As we&#39;ve shown, you can also get non-AI workloads running on the Spark in a pinch, but that&#39;s not what it&#39;s meant for. At its heart, the Spark is an AI lab in a box and is best used as such. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-46')">
            <div class="source">The Register</div>
            <div class="title">You don't need Linux to run free and open source software</div>
            <div class="meta">2025-12-25</div>
        </div>
        
        <div id="content-46" style="display:none;">
            <h2>You don't need Linux to run free and open source software</h2>
            <p><strong>The Register | 2025-12-25</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2025/12/25/go_foss_keep_your_os/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Part 2 There&#39;s a wealth of highly usable free software for the big proprietary desktop OSes. You can escape paying subscriptions and switch to free software without changing your OS.

In the first half of this short series, we looked at how to freshen up an aging Mac or Windows 10 PC, and ideally, how to wipe it and install a clean, bloat-free copy of its OS. That is all well and good, but this leaves the problem of what to put on that OS to get out of the trap of software you paid for but don&#39;t own.

The big question, of course, is what to use and where to find it. There are lists that can help, but you need to be very cautious. If the website looks fancy and modern, then it may be trying to sell you fancy modern tools that will cost you and won&#39;t work with older OSes. Beware of animation effects, transitions, things which fade in and out, and so on.

Compare OpenAlternative.co, which is snazzy and effects-heavy, with the decidedly low-tech Best FOSS Alternatives, which is very simple and austere. The latter has nothing to sell; it&#39;s just a plain, simple categorized list of FOSS tools. If you scroll to the end, it even has a short list of alternatives to itself.

Always remember the KISS principle. As a general rule, try to favor things that are plain, simple, and unornamented – there&#39;s less to go wrong.

As a general rule, we suggest treating app stores for desktop OSes with suspicion and keeping them at arm&#39;s length. Apple has integrated its App Store deeply into macOS since 2001&#39;s Mac OS X 10.0, but you don&#39;t need it, and it&#39;s full of things that you can get for free elsewhere. Most native macOS apps update themselves, so even the App Store&#39;s handy automatic background updates aren&#39;t essential.

On a fresh new copy of Windows, the easiest way to get up and running is Ninite. The Reg FOSS desk described this back in April, but long before that, in 2012, The Register said it could save your sanity – and endorsed it again in 2013.

A dozen years later, Ninite is still very helpful. (Sadly, the macOS equivalent, MacApps.link, is unmaintained and dated… don&#39;t use it except for pointers.)

Ninite offers a wide range of FOSS and freeware apps, utilities, runtimes, and codecs. You tick the ones you want and it generates a custom installer for you to download. Run that, and it downloads and installs all the tools you selected, saying no to all optional extras, toolbars, adware, and everything else you don&#39;t want. It automatically picks your language and 64-bit versions where it can.

Hang on to that Ninite installer. It&#39;s tiny, and if you keep it and rerun it later, it will also update all the apps for you in one pass – skipping any that don&#39;t need it.

Even if you don&#39;t need Ninite, or don&#39;t use Windows for that matter, there are worse places to get a shopping list of FOSS apps than just Googling the apps on Ninite&#39;s list. It&#39;s not comprehensive but it&#39;s a good starting point.

Many of these suggestions apply equally to any of the big three platforms, which brings a handy extra into the deal: if you use a different type of computer at home and at work, say, it makes life easier if they run the same apps.

Aside from a couple of small tools and a copy of the oldest version of Microsoft Word that still runs on macOS Catalina or later, we treat macOS like a prettier Linux. All the apps are FOSS or freeware, installed directly from .dmg files downloaded from their creators. They all update themselves when new versions are released. Everything interoperates smoothly. We don&#39;t really use any Apple-bundled apps except the OS itself, meaning things like the Finder, Dock, Spotlight searching, and the Preview document viewer.

For instance, we use Jeena&#39;s TextEd instead of Apple&#39;s text editor. For browsers, email, chat, productivity, writing, and so on, we use FOSS and freeware apps, and wherever possible, ones that also work on Linux and Windows – it makes synchronizing and switching between platforms much easier.

Mozilla Firefox is a classic, of course, but it&#39;s still getting new features. The full version of uBlock Origin works: make it the first add-on you install. Since Firefox 136, it&#39;s had vertical tabs built in. The Reg FOSS desk has been evangelizing this for years so we&#39;ll be brief: if you don&#39;t use it, you need to learn. Enable the built-in browser sync and link up all your copies, and you&#39;ll always have the same bookmarks, the same passwords, and you can open a tab from one machine on any other. As we told you in August, you can just disable all the artificial idiocy: go into about:config and enter browser.ml. Lots of settings related to the integrated LLM bot appear: set them all to false, quit and reload Firefox, and you avoid the built-in bot&#39;s slop. In recent years, Firefox is also not just a very capable PDF viewer, it&#39;s also a handy PDF editor: you can annotate them, fill in forms and so on, all in the browser.

Much the same applies to Thunderbird from Mozilla subsidiary MZLA. There are lots of great email clients out there. Some are free. Some are open source. Some run on multiple platforms. We&#39;re not saying that Thunderbird is the best, but it&#39;s free, it&#39;s open source (so you can use it at work with no penalties), and it runs identically on Windows, macOS, and Linux.

If you don&#39;t get on with Thunderbird, there are lots of alternatives out there, from The Bat! to the cross-platform eM Client. Pegasus Mail, the granddaddy of them all in Windows terms, is still maintained.

If Mozilla&#39;s integration of telemetry and LLM bots annoys you, then Waterfox is an excellent alternative. For the occasional site or service that doesn&#39;t work properly in Firefox, we tend to keep a copy of Google Chrome around, of course with uBlock Lite installed. We don&#39;t care for it much, but it does the job, and by sticking to the upstream source, new releases come faster than in downstream rebuilds such as Microsoft Edge – for all that that does offer vertical tabs.

For media players, the classic VLC remains a good candidate. For just audio, The Reg FOSS desk is quite fond of Foobar2000 – it&#39;s not FOSS, but it&#39;s free, wonderfully simple and uncluttered, and it runs on Windows, macOS, and even Android.

For chat apps and other SaaS-type tools, there are several excellent all-in-one tools that will let you manage all your conversations in tabs in a single app. Our daily go-to tool for this is Ferdium, but as we wrote in the previous link, there are several alternatives. It&#39;s worth noting that Thunderbird can talk to XMPP and Matrix by default, and has extensions to handle things like Slack, Whatsapp, Telegram, Discord, Teams, and others. The difficult odd man out is Signal, which won&#39;t work with anything else, doesn&#39;t sync message history, and is generally a bit of a pain in its quest for the maximum possible security – but a few regular contacts are on it, so we keep it around anyway.

If you want something lighter-weight, for techies willing to roll their sleeves up and manually configure plugins, the venerable Pidgin can talk to a lot of services, it&#39;s very lightweight and fast, and a major new release is under construction. The venerable Trillian is still around too, and it runs on macOS as well, but sadly can&#39;t talk to most modern messaging systems.

For a general office suite, it&#39;s well worth keeping LibreOffice installed even if just for emergency file recovery. If you still use OpenOffice, it&#39;s long past time to switch: that version is all but dead, and we recommend uninstalling it and replacing it with its actively maintained successor. If you find the appearance of LibreOffice a bit old and staid, then try OnlyOffice or WPS Office, which are more up-to-date with Microsoft&#39;s modern UI.

For image viewing, on Windows, for us nothing beats IrfanView, and we still miss it on both macOS and Linux. There are others, though, such as FastStone and the cross-platform XnView.

For editing, the GIMP is back in active development – and if you can&#39;t get on with the UI and still miss Photoshop, try PhotoGIMP. Worthy alternatives include Paint.net and the cross-platform Krita. We lack sufficient artistic skills, but we hear Inkscape is pretty good. For photographers, Darktable is worth a look, and for managing photo libraries, try the cross-platform digiKam.

For file compression and decompression, dump that ancient, unregistered copy of WinRar and get 7-Zip, or if you&#39;d prefer to avoid Russian apps, PeaZip. On our Macs, we keep The Unarchiver and Stuffit Expander around just in case there&#39;s anything the OS can&#39;t handle itself.

For file downloading, we mostly just use the Multithreaded Download Manager extension for Firefox, but for anything more complicated, FileZilla may help.

Despite what we said earlier about old text editors being safe, there are better alternatives to the built-in ones in most OSes. A few years ago, we wrote about Notepad++ and Geany, which both use the same editing component, Scintilla. There are versions of Notepad++ for even very old versions of Windows, and while Geany is mostly found on Linux, it&#39;s also a good, fast macOS text editor.

We very rarely need a full-function office suite, but find a plain-text editor a bit too minimal, so for writing, we usually use the distraction-free Panwriter Markdown editor. It&#39;s an Electron app so it&#39;s not light; if you want Markdown in something lightweight, then Ghostwriter does the job and it&#39;s cross-platform. It even runs on Haiku and on the Raspberry Pi, and even on Windows 7. For note taking, we like LogSeq, although we suspect we only use about 1 percent of its facilities. It&#39;s a hierarchical markdown note taker with basic outlining, and that ticks a bunch of Reg FOSS desk boxes. We&#39;ve tried syncing it between machines with Syncthing but that proved rather flaky.

As a hypervisor, we like Oracle&#39;s VirtualBox. As we have explained before, the only licensed part is the Extension Pack, and the hypervisor works fine without it. Avoid that, and you&#39;re safe. If some demanding guest OS doesn&#39;t work, then on Macs, the all-FOSS UTM is a good alternative, but for most things, the now-gratis VMware is a bit easier. It works a bit differently on Windows, Linux, and macOS, which is annoying, but it does the job and does it well. If you often need a Windows VM, we find VMware noticeably faster than VirtualBox with that guest.

Well, it may have been long ago, but once upon a time, you didn&#39;t know how to use Adobe Photoshop or Microsoft Excel to their best advantage either.

Breaking free of proprietary tools takes some effort, yes. You will have to relearn how to do some things. You absolutely will find things that the free and open source tools simply can&#39;t do.

The question then is: do you need those functions, or were they just handy? Only you can decide if certain functions are convenient, but not actually essential, or if they are things you cannot get your job done without.

This particular vulture was an early adopter of Windows and has been using PCs for worryingly close to 40 years now, and there were absolutely things we missed when we moved to mostly running Linux and the new Mac OS X about halfway through that time span. However, a lot of them have proved with time to be things we can just do without. The returns in terms of never worrying about subscriptions, and so on, are completely worth it.

In general, our advice is that investing the time in learning alternative tools, ones from suppliers whose business models don&#39;t rely on subscriptions or lock-in, will repay you manifold. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-47')">
            <div class="source">The Register</div>
            <div class="title">Salesforce’s ChatGPT integration is really about stopping customers from leaking their own data</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-47" style="display:none;">
            <h2>Salesforce’s ChatGPT integration is really about stopping customers from leaking their own data</h2>
            <p><strong>The Register | 2025-12-24</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2025/12/24/salesforce_chatgpt/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Salesforce users running Agentforce with ChatGPT Enterprise or Edu can now update CRM data directly from the bot, a move aimed at curbing home-built integrations that risk spilling data outside the company&#39;s controls.

While the tie-up was pitched as a way to reduce the time users spend toggling between OpenAI’s bot and Salesforce, analyst Vernon Keenan said in a blog post that it is actually security driven.

The move, which was announced last week, is aimed at heading off the DIYers who have assembled their own integrations using model context protocol, or MCP, according to Kris Billmaier, GM and EVP of Agentforce Sales at Salesforce. Think of MCP as a kind of API layer for wiring AI models to tools and data.

Keenan wrote that Salesforce users have been building their own MCP servers using OpenAI’s Apps SDK and exposing Salesforce data to various frontier LLMs in the bargain. That puts the company&#39;s data outside the governance and usage metering of Salesforce.

“The thing that I worry about, and what I wanted to get ahead of, was homegrown MCP servers from customers just spitting out data to OpenAI around the trust boundary,” Billmaier told Keenan. “And with this, we’re actually kind of being full of our destiny as we think about other players emerging in this space.”

In its announcement, Salesforce called the ChatGPT integration “the end of the cut and paste workflow.” It said ChatGPT will now work like a user interface for Salesforce.

“You can simply ask, ‘Show me my new uncontacted leads,’ and the app in ChatGPT pulls a live, interactive list directly from Salesforce. No searching, no filtering, just the answer you need exactly when you need it,” Salesforce wrote.

Salesforce said that its Agentforce Sales app in ChatGPT can prioritize the highest-quality leads for any particular moment based on lead score, pipeline health and “external context such as market or news signals to surface the right lead for that moment in time.”

The Agentforce Sales app will also take over the nurturing of low-priority leads to let humans focus on the big targets, and update the CRM after a call to reflect the status of the deal.

When using the integration, Agentforce Trust Layer protects proprietary data, which is also governed by the company&#39;s security standards, Salesforce said. ChatGPT respects existing permissions and only accesses information the user already has access to in the connected app, Salesforce noted.

Talking with Keenan, Salesforce also took on the question of how this integration relates to Salesforce’s productivity app Slack, which after Dreamforce was expected to take on a more prominent role in its AI strategy.

Nick Johnston, senior vice president of strategic partnerships at Salesforce, said in this case, the OpenAI integration will help an individual worker, while Slack is built for when that worker needs to talk with and decide on the next steps with their team.

“We are seeing tools like ChatGPT today being very much the single player experiences,” Johnston told Keenan. “People are working in these tools to help themselves. Slack is multiplayer experience. If you think about where people are doing work with teams, with multiple groups, cross functional organization, plus bringing in agents from all different tools—that is where Slack shines. None of these AI tools are doing that yet.” ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-48')">
            <div class="source">The Verge</div>
            <div class="title">I re-created Google&#8217;s cute Gemini ad with my own kid&#8217;s stuffie, and I wish I hadn&#8217;t</div>
            <div class="meta">2025-12-25</div>
        </div>
        
        <div id="content-48" style="display:none;">
            <h2>I re-created Google&#8217;s cute Gemini ad with my own kid&#8217;s stuffie, and I wish I hadn&#8217;t</h2>
            <p><strong>The Verge | 2025-12-25</strong></p>
            <a class="original-link" href="https://www.theverge.com/tech/849998/gemini-ai-stuffed-animal-commercial">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">AI can help you make it look like a plush toy is traveling the world. But I’m not convinced that’s a great idea.

AI can help you make it look like a plush toy is traveling the world. But I’m not convinced that’s a great idea.

When your kid starts showing a preference for one of their stuffed animals, you’re supposed to buy a backup in case it goes missing.

I’ve heard this advice again and again, but never got around to buying a second plush deer once “Buddy” became my son’s obvious favorite. Neither, apparently, did the parents in Google’s newest ad for Gemini.

It’s the fictional but relatable story of two parents discovering their child’s favorite stuffed toy, a lamb named Mr. Fuzzy, was left behind on an airplane. They use Gemini to track down a replacement, but the new toy is on backorder. In the meantime, they stall by using Gemini to create images and videos showing Mr. Fuzzy on a worldwide solo adventure — wearing a beret in front of the Eiffel tower, running from a bull in Pamplona, that kind of thing — plus a clip where he explains to “Emma” that he can’t wait to rejoin her in five to eight business days. Adorable, or kinda weird, depending on how you look at it! But can Gemini actually do all of that? Only one way to find out.

I fed Gemini three pictures of Buddy, our real life Mr. Fuzzy, from different angles, and gave it the same prompt that’s in the ad: “find this stuffed animal to buy ASAP.” It returned a couple of likely candidates. But when I expanded its response to show its thinking I found the full eighteen hundred word essay detailing the twists and turns of its search as it considered and reconsidered whether Buddy is a dog, a bunny, or something else. It is bananas, including real phrases like “I am considering the puppy hypothesis,” “The tag is a loop on the butt,” and “I’m now back in the rabbit hole!” By the end, Gemini kind of threw its hands up and suggested that the toy might be from Target and was likely discontinued, and that I should check eBay.

In fairness, Buddy is a little bit hard to read. His features lean generic cute woodland creature, his care tag has long since been discarded, and we’re not even 100 percent sure who gave him to us. He is, however, definitely made by Mary Meyer, per the loop on his butt. He does seem to be from the “Putty” collection, which is a path Gemini went down a couple of times, and is probably a fawn that was discontinued sometime around 2021. That’s the conclusion I came to on my own, after about 20 minutes of googling and no help from AI. The AI blurb when I do a reverse image search on one of my photos confidently declares him to be a puppy.

Gemini did a better job with the second half of the assignment, but it wasn’t quite as easy as the ad makes it look. I started with a different photo of Buddy — one where he’s actually on a plane in my son’s arms — and gave it the next prompt: “make a photo of the deer on his next flight.” The result is pretty good, but his lower half is obscured in the source image so the feet aren’t quite right. Close enough, though.

The ad doesn’t show the full prompt for the next two photos, so I went with: “Now make a photo of the same deer in front of the Grand Canyon.” And it did just that — with the airplane seatbelt and headphones, too. I was more specific with my next prompt, added a camera in his hands and got something more convincing.

I can see how Gemini misinterpreted my prompt. I was trying to keep it simple and requested a photo of the same deer “at a family reunion.” I did not specify his family reunion. So that’s how he ended up crashing the Johnson family reunion — a gathering of humans. I can only assume that Gemini took my last name as a starting point here because it sure wasn’t in my prompt, and when I requested that Gemini created a new family reunion scene of his family, it just swapped the people for stuffed deer. There are even little placards on the table that say “deer reunion.” Reader, I screamed.

For the last portion of the ad, the couple use Gemini to create cute little videos of Mr. Fuzzy getting increasingly adventurous: snowboarding, white water rafting, skydiving, before finally appearing in a spacesuit on the moon addressing “Emma” directly. The commercial whips through all these clips quickly, which feels like a little sleight of hand given that Gemini takes at least a couple of minutes to create a video. And even on my Gemini Pro account, I’m limited to three generated videos per day. It would take a few days to get all of those clips right.

Gemini wouldn’t make a video based on any image of my kid holding the stuffed deer, probably thanks to some welcome guardrails preventing it from generating deepfakes of babies. I started with the only photo I had on hand of Buddy on his own: hanging upside down, air-drying after a trip through the washer. And that’s how he appears in the first clip it generated from this prompt: Temu Buddy hanging upside down in space before dropping into place, morphing into a right-side-up astronaut, and delivering the dialogue I requested.

A second prompt with a clear photo of Buddy right-side-up seemed to mash up elements of the previous video with the new one, so I started a brand-new chat to see if I could get it working from scratch. Honestly? Nailed it. Aside from the antlers, which Gemini keeps sneaking in. But this clip also brought one nagging question to the forefront: should you do any of this when your kid loses a beloved toy?

I gave Buddy the same dialogue as in the commercial, using my son’s name rather than Emma. Hearing that same manufactured voice say my kid’s name out loud set alarm bells off in my head. An AI generated Buddy in front of the Eiffel Tower? Sorta weird, sorta cute. AI Buddy addressing my son by name? Nope, absolutely not, no thank you.

How much, and when, to lie to your kids is a philosophical debate you have with yourself over and over as a parent. Do you swap in the identical stuffie you had in a closet when the original goes missing and pretend it’s all the same? Do you tell them the truth and take it as an opportunity to learn about grief? Do you just need to buy yourself a little extra time before you have that conversation and enlist AI to help you make a believable case? I wouldn’t blame any parent choosing any of the above. But personally, I draw the line at an AI character talking directly to my kid. I never showed him these AI-generated versions of Buddy, and I plan to keep it that way.

But back to the less morally complex question: can Gemini actually do all of the things that it does in the commercial? More or less. But there’s an awful lot of careful prompting and re-prompting you’d have to do to get those results. It’s telling that throughout most of the ad you don’t see the full prompt that’s supposedly generating the results on screen. A lot depends on your source material, too. Gemini wouldn’t produce any kind of video based on an image in which my kid was holding Buddy — for good reason! But this does mean that if you don’t have the right kind of photo on hand, you’re going to have a very hard time generating believable videos of Mr. Sniffles or whoever hitting the ski slopes.

Like many other elder millennials, I think about Calvin and Hobbes a lot. Bill Watterson famously refused to commercialize his characters, because he wanted to keep them alive in our imaginations rather than on a screen. He insisted that having an actor give Hobbes a voice would change the relationship between the reader and the character, and I think he’s right. The bond between a kid and a stuffed animal is real and kinda magical; whoever Buddy is in my kid’s imagination, I don’t want AI overwriting that.

The great cruelty of it all is knowing that there’s an expiration date on that relationship. When I became a parent, I wasn’t at all prepared for the way my toddler nuzzling his stuffed deer would crack my heart right open. It’s so pure and sweet, but it always makes me a little sad at the same time, knowing that the days where he looks for comfort from a stuffed animal like Buddy are numbered. He’s going to outgrow it all, and I’m not prepared for that reality. Maybe as much as we’re trying to save our kids some heartbreak over their lost companion, we’re really trying to delay ours, too.

All images and videos in this story were generated by Google Gemini.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-49')">
            <div class="source">The Verge</div>
            <div class="title">Hollywood cozied up to AI in 2025 and had nothing good to show for it</div>
            <div class="meta">2025-12-25</div>
        </div>
        
        <div id="content-49" style="display:none;">
            <h2>Hollywood cozied up to AI in 2025 and had nothing good to show for it</h2>
            <p><strong>The Verge | 2025-12-25</strong></p>
            <a class="original-link" href="https://www.theverge.com/ai-artificial-intelligence/848119/hollywood-film-tv-ai-2025">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The technology dominated the entertainment discourse, but there’s yet to be a series or movie that shows AI’s potential.

The technology dominated the entertainment discourse, but there’s yet to be a series or movie that shows AI’s potential.

AI isn’t new to Hollywood — but this was the year when it really made its presence felt. For years now, the entertainment industry has used different kinds of generative AI products for a variety of post-production processes ranging from de-aging actors to removing green screen backgrounds. In many instances, the technology has been a useful tool for human artists tasked with tedious and painstaking labor that might have otherwise taken them inordinate amounts of time to complete. But in 2025, Hollywood really began warming to the idea of deploying the kind of gen AI that’s really only good for conjuring up text-to-video slop that doesn’t have all that many practical uses in traditional production workflows. Despite all of the money and effort being put into it, there’s yet to be a gen-AI project that has shown why it’s worth all of the hype.

This confluence of Hollywood and AI didn’t start out so rosy. Studios were in a prime position to take the companies behind this technology to court because their video generation models had clearly been trained on copyrighted intellectual property. A number of major production companies including Disney, Universal, and Warner Bros. Discovery did file lawsuits against AI firms and their boosters for that very reason. But rather than pummeling AI purveyors into the ground, some of Hollywood’s biggest power players chose instead to get into bed with them. We have only just begun to see what can come from this new era of gen-AI partnerships, but all signs point to things getting much sloppier in the very near future.

Though many of this year’s gen-AI headlines were dominated by larger outfits like Google and OpenAI, we also saw a number of smaller players vying for a seat at the entertainment table. There was Asteria, Natasha Lyonne’s startup focused on developing film projects with “ethically” engineered video generation models, and startups like Showrunner, an Amazon-backed platform designed to let subscribers create animated “shows” (a very generous term) from just a few descriptive sentences plugged into Discord. These relatively new companies were all desperate to legitimize the idea that their flavor of gen AI could be used to supercharge film / TV development while bringing down overall production costs.

Asteria didn’t have anything more than hype to share with the public after announcing its first film, and it was hard to believe that normal people would be interested in paying for Showrunner’s shoddily cobbled-together knockoffs of shows made by actual animators. In the latter case, it felt very much like Showrunner’s real goal was to secure juicy partnerships with established studios like Disney that would lead to their tech being baked into platforms where users could prompt up bespoke content featuring recognizable characters from massive franchises.

That idea seemed fairly ridiculous when Showrunner first hit the scene because its models churn out the modern equivalent of clunky JibJab cartoons. But in due time, Disney made it clear that — crappy as text-to-video generators tend to be for anything beyond quick memes — it was interested in experimenting with that kind of content. In December, Disney entered into a three-year, billion-dollar licensing deal with OpenAI that would let Sora users make AI videos with 200 different characters from Star Wars, Marvel, and more.

Netflix became one of the first big studios to proudly announce that it was going all-in on gen AI. After using the technology to produce special effects for one of its original series, the streamer published a list of general guidelines it wanted its partners to follow if they planned to jump on the slop bandwagon as well. Though Netflix wasn’t mandating that filmmakers use gen AI, it made clear that saving money on VFX work was one of the main reasons it was coming out in support of the trend. And it wasn’t long before Amazon followed suit by releasing multiple Japanese anime series that were terribly localized into other languages because the dubbing process didn’t involve any human translators or voice actors.

Amazon’s gen-AI dubs became a shining example of how poorly this technology can perform. They also highlighted how some studios aren’t putting all that much effort into making sure that their gen AI-derived projects are polished enough to be released to the public. That was also true of Amazon’s machine-generated TV recaps, which frequently got details about different shows very wrong. Both of these fiascos made it seem as if Amazon somehow thought that people wouldn’t notice or care about AI’s inability to consistently generate high-quality outputs. The studio quickly pulled its AI-dubbed series and the recap feature down, but it didn’t say that it wouldn’t try this kind of nonsense again.

All of this and other dumb stunts like AI “actress” Tilly Norwood made it feel like certain segments of the entertainment industry were becoming more comfortable trying to foist gen-AI “entertainment” on people even though it left many people deeply unimpressed and put off. None of these projects demonstrated to the public why anyone except for money-pinching execs (and people who worship them for some reason) would be excited by a future shaped by this technology.

Aside from a few unimpressive images, we still haven’t seen what all might come from some of these collaborations, like Disney cozying up to OpenAI. But next year AI’s presence in Hollywood will be even more pronounced. Disney plans to dedicate an entire section of its streaming service to user-generated content sourced from Sora, and it will encourage Disney employees to use OpenAI’s ChatGPT products. But the deal’s real significance in this current moment is the message it sends to other studios about how they should move as Hollywood enters its slop era.

Regardless of whether Disney thinks this will work out well, the studio has signaled that it doesn’t want to be left behind if AI adoption keeps accelerating. That tells other production houses that they should follow suit, and if that becomes the case, there’s no telling how much more of this stuff we are all going to be forced to endure.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-50')">
            <div class="source">The Verge</div>
            <div class="title">Anker’s beefy Laptop Power Bank has returned to its Black Friday low</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-50" style="display:none;">
            <h2>Anker’s beefy Laptop Power Bank has returned to its Black Friday low</h2>
            <p><strong>The Verge | 2025-12-24</strong></p>
            <a class="original-link" href="https://www.theverge.com/gadgets/849637/anker-laptop-power-bank-xbox-series-x-deal-sale">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">You can also save on the Xbox Series X and what is arguably the best-looking Bluetooth speaker available.

You can also save on the Xbox Series X and what is arguably the best-looking Bluetooth speaker available.

If you buy something from a Verge link, Vox Media may earn a commission. See our ethics statement.

As you might expect, things have been relatively quiet on the deals front since Black Friday, particularly when it comes to discounts on charging accessories. Thankfully, Anker’s aptly titled Laptop Power Bank is once again on sale at Amazon and Walmart for $87.99 ($47 off), which matches the record-low price we last saw at the end of November.

Unless you’ve been living under a proverbial rock for the past several years, you’re probably aware that Anker makes an ungodly amount of charging accessories. The portable A1695 “InstaCord” has quickly become a favorite among Verge staffers, however, owing to the fact that it comes with a retractable USB-C cable and a second that doubles as a handle, both of which are bidirectional and allow for passthrough charging. The 25,000mAh / 90Wh power bank also sports a USB-A port and an additional USB-C port, allowing you to charge your phone, a MacBook Pro, and up to two other devices simultaneously.

In terms of output distribution, Anker’s 600-gram Laptop Power Bank can deliver up to 165W when two devices are plugged in, or up to 130W when charging three or four gadgets. It’s carry-on compliant, too, meaning you shouldn’t have any trouble getting it through TSA while traveling, which isn’t the case if your charger is above the agency’s 100 watt-hours threshold for carry-on devices. It even features a built-in LCD display, allowing you to quickly view the remaining charge, overall power output, battery temperature, and other info at a glance.

Sign up for Verge Deals to get deals on products we’ve tested sent to your inbox weekly.

Sign up for Verge Deals to get deals on products we’ve tested sent to your inbox weekly.</div>
        </div>
        
        <div class="card" onclick="openModal('content-51')">
            <div class="source">The Verge</div>
            <div class="title">Sony’s souped-up PlayStation 5 Pro is $100 off for the rest of today</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-51" style="display:none;">
            <h2>Sony’s souped-up PlayStation 5 Pro is $100 off for the rest of today</h2>
            <p><strong>The Verge | 2025-12-24</strong></p>
            <a class="original-link" href="https://www.theverge.com/gadgets/684281/sony-playstation-5-ps5-pro-christmas-deal-sale-2025">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The discount might not be big enough to warrant the upgrade, but we’ll let you make that call.

The discount might not be big enough to warrant the upgrade, but we’ll let you make that call.

If you buy something from a Verge link, Vox Media may earn a commission. See our ethics statement.

Sony’s full suite of PlayStation 5 consoles jumped in price in August due to increased US tariffs, but now through Christmas, you can save $100 on several models. This discount is especially great if you planned to go big with Sony’s PS5 Pro, the company’s priciest, most powerful console yet. Normally $749.99, you can currently grab one at Amazon, Walmart, and Target for around $689.99. Sony’s PlayStation Direct storefront indicates that the PS5 Pro sale ends on December 25th at 3AM ET, although discounts may remain on cheaper models.

The PS5 Pro plays many games at their best resolution, while making far fewer concessions than the standard PS5 when it comes to visual effects (particularly ray tracing and shadow quality). Some games simply look better or run faster on the Pro than the base-model PS5, while others look better and run faster. That said, it’s worth noting that PS5 Pro lacks a disc drive and is thus limited to digital titles, though you can buy an optional drive for $80 if you want to attach one later.

The PlayStation 5 Pro has a bigger GPU than any other PS5 model, with twice as much internal storage as the current slim models (2TB versus 1TB). Another notable feature exclusive to the Pro is PSSR (PlayStation Spectral Super Resolution), which uses AI to upscale graphics in supported games to produce a better-looking image. The difference in performance between the Pro and the base PS5 is easy to notice in several games, although it’s safe to say that there hasn’t yet been a title that makes upgrading to one a no-brainer. But if a lower price is all the encouragement you needed to upgrade, now is a good time to get one.

Sign up for Verge Deals to get deals on products we’ve tested sent to your inbox weekly.

Sign up for Verge Deals to get deals on products we’ve tested sent to your inbox weekly.</div>
        </div>
        
        <div class="card" onclick="openModal('content-52')">
            <div class="source">The Verge</div>
            <div class="title">The best shows and movies to stream on Netflix in 2025</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-52" style="display:none;">
            <h2>The best shows and movies to stream on Netflix in 2025</h2>
            <p><strong>The Verge | 2025-12-24</strong></p>
            <a class="original-link" href="https://www.theverge.com/entertainment/845388/netflix-best-shows-movies-2025">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">From the end of Stranger Things and Squid Game to the surprise hit KPop Demon Hunters.

From the end of Stranger Things and Squid Game to the surprise hit KPop Demon Hunters.

Netflix has had an interesting year. Its ad tier, introduced last year, has grown significantly, and its live TV initiative has expanded to include not only weird one-offs like hot-dog-eating grudge matches but also WWE programming. Taking KPop Demon Hunters off Sony’s hands for the business equivalent of $200 in a potato chip bag also turned out to be a pretty smart move for Netflix. The animated feature about, well, demon-hunting K-pop stars, became the most watched movie in the platform’s history and a global cultural phenomenon in its own right. The sing-along theatrical release sold out, songs from the movie sat comfortably at the top of music charts for weeks, and we got Huntr/x in Fortnite and the Macy’s Thanksgiving Parade mere months after the movie’s release.

But KPop Demon Hunters wasn’t the streamer’s only quality offering this year. Here’s a list of Netflix’s best of 2025.

There are two life lessons to take away from this documentary: Don’t be a horrific abuser and never piss off a self-described petty man with cash to burn. This four-part docuseries, directed by Alex Stapleton and produced by Lifetime Achievement Fellow in the Hater Hall of Fame Curtis “50 Cent” Jackson, chronicles the rise of Sean “P Diddy” Combs from music video character actor, to hip-hop business mogul, to convicted criminal.

The documentary features new interviews from former associates, employees, and friends who allege everything from cheating business partners out of their share to having knowledge of if not outright arranging the hit that took Tupac Shakur’s life. This is not a “fun” watch, so heed the content warnings, but if you want a succinct accounting of where Combs came from and how the business of hip-hop can turn men into monsters, this is an informative overview.

There is vanishingly little I can say about KPop Demon Hunters’ brilliance that hasn’t already been said. So I’ll let what has been said speak for it:

Rian Johnson’s Knives Out series has once again delivered a sharply funny, intensely moving whodunit. Daniel Craig as Benoit Blanc drips southern charm, aided by an ensemble cast featuring Josh Brolin as a fiery Catholic priest and Glenn Close as his secretary. Josh O’Connor delivers some beautiful moments as a junior priest struggling to find meaning in his faith, creating interesting tension against Blanc’s cold, grim logic. With them working together, Wake Up Dead Man becomes a fun story that examines the purpose faith can have in our lives.

One thing director Guillermo del Toro is gonna do is make a luxurious, sumptuous-ass movie with over-the-top sets and costuming. But Frankenstein is not just a visual delight. Oscar Isaac as Victor Frankenstein and Jacob Elordi as his monster give incredible performances that are both grounded in the movie’s late Victorian aesthetic while resonating with the stories of today. A quote unquote learned man irresponsibly using technology to create something he doesn’t understand and in his arrogance tries to control that winds up destroying his life and others? It’s not that Frankenstein is any one allegory for today, it has multiple applications.

And while we have numerous Frankenstein adaptations, there’s nothing quite like watching GDT do it. You just know that man is gonna grab all the production designers, make-up artists, and costumers, give them some cash, and say essentially “Cook,” and damn if they didn’t do exactly that.

I live for The Great British Baking Show (known as The Great British Bake Off outside the US). When the sun starts setting at 4:30PM and seasonal affect starts disordering my life, I’m okay because I know that means it’s Baking Show season. This year, the show has done some interesting things with the format, trying new variations on the show’s technical challenge where bakers are tasked with making something with stripped-down directions. I wish the challenges weren’t so overly focused on sweets, but it’s always fun learning the absolutely bonkers names the Brits have for their pastries. There is no way in a logical world that an oatmeal bar like this should be called a flapjack — it doesn’t even flap! Honestly, yelling about how British English is Wrong is just as much fun as watching the amateur bakers themselves.

The first half of the final season of Stranger Things is out, and while we can quibble about whether or not it’s quality television, it is good for one specific reason: it is finally ending. The show started off really strong, telling a fun tale about kids saving the world from the adults that are trying to ruin it. But that kind of storytelling got lost in the near decade between the first season and now — even though the Duffer Brothers want us to believe that it’s only been four years since Will first went to the Upside Down. It’s okay that stories end, and I’m glad we’ve got the opportunity to end this show on a high note by returning focus to what made it so great in the first place — them meddling kids.

Squid Game is another one of Netflix’s tentpole hits that has come to an end this year. Gi-hun / Player 456 (Lee Jung-jae) has returned to Mr. Beast’s Murder Island to expose the organizers of the deadly games once and for all. He’s befriended another crop of desperate people willing to do whatever for life-changing amounts of cash and just like in the first two seasons it’s brutal to watch the games destroy them one by one.

Clocking in at just under 200 days, James Garfield has the second shortest term of a US president, and I was genuinely enthralled watching Death By Lightning chart his rise to the office and tragic fall via an assassin’s bullet. As with Frankenstein, Netflix is once again on time with a metaphor appropriate for current events. Death By Lightning takes a look at how incendiary political discourse, like the kind fomented against Garfield by his own party, can lead to violence.

But more than the prescient political commentary, the performances make this show. Michael Shannon imbues Garfield with a salt-of-the-earth quality that makes you root hard for him. Shea Whigham has entered his character actor villain era playing New York Senator Roscoe Conkling, and Matthew “Mr. Darcy / Tom Wambsgans” Macfadyen gives a heartbreaking performance playing Garfield’s assassin Charles Guiteau.

The show’s best moments come from Nick Offerman as Garfield’s reluctant vice president, Chester A. Arthur. Offerman as Arthur is regency-era Ron Swanson. Throughout most of the show’s four episodes, Offerman is either drunk, fighting, raving about sausages, or a combination of all three. That man is having a blast chewing the scenery in a top hat and mutton chops, and I would genuinely watch a whole White House sitcom with him as the star.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-53')">
            <div class="source">The Verge</div>
            <div class="title">In 2025, AI became a lightning rod for gamers and developers</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-53" style="display:none;">
            <h2>In 2025, AI became a lightning rod for gamers and developers</h2>
            <p><strong>The Verge | 2025-12-24</strong></p>
            <a class="original-link" href="https://www.theverge.com/entertainment/848368/gen-ai-video-games-2025">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Gen-AI showed up in the year’s biggest releases including game of the year.

Gen-AI showed up in the year’s biggest releases including game of the year.

2025 was the year generative AI made its presence felt in the video game industry. Its use has been discovered in some of the most popular games of the year, and CEOs from some of the largest game studios claim it’s being implemented everywhere in the industry including in their own development processes. Meanwhile, rank-and-file developers, especially in the indie games space, are pushing back against its encroachment, coming up with ways to signal their games are gen-AI free.

Generative AI has largely replaced NFTs as the buzzy trend publishers are chasing. Its proponents claim that the technology will be a great democratization force in video game development, as gen AI’s ability to amalgamate images, text, audio, and video could shorten development times and shrink budgets — ameliorating two major problems plaguing the industry right now. In service to that idea, numerous video game studios have announced partnerships with gen-AI companies.

Ubisoft has technology that can generate short snippets of dialogue called barks and has gen-AI powered NPCs that players can have conversations with. EA has partnered with Stability AI, Microsoft is using AI to analyze and generate gameplay. Outside of official partnerships, major game companies like Nexon, Krafton, and Square Enix are vocally embracing gen AI.

As a result, gen AI is starting to show up in games in a big way. Up until this point, gen AI in gaming had been mostly relegated to fringe cases — either prototypes or small, low-quality games that generally get lost in the tens of thousands of titles released on Steam each year. But now, gen AI is cropping up in the year’s biggest releases. ARC Raiders, one of the breakout multiplayer shooter hits of the year, used gen AI for character dialogue. Call of Duty: Black Ops 7 used gen-AI images. Even 2025’s TGA Game of the Year, Clair Obscur: Expedition 33, featured gen-AI images before they were quietly removed.

Reaction to this encroachment from both players and developers has been mixed. It seems like generally, players don’t like gen AI showing up in games. When gen-AI assets were discovered in Anno 117: Pax Romana, the game’s developer Ubisoft claimed the assets “slipped through” review and they were subsequently replaced. When gen-AI assets were found in Black Ops 7, however, Activision acknowledged the issue, but kept the images in the game. Critical response has also been lopsided. ARC Raiders was awarded low scores with reviewers specifically citing the use of gen AI as the reason. Clair Obscur, though, was nigh universally praised and its use of gen AI, however temporary, has barely been mentioned.

It seems like developers are sensitive to the public’s distaste for gen AI but are unwilling to commit to not using it. After gen-AI assets were discovered in Black Ops 7, Activision said it uses the tech to “empower” its developers, not replace them. When asked about gen AI showing up in Battlefield 6, EA VP Rebecka Coutaz called the technology seductive but affirmed it wouldn’t appear in the final product. Swen Vincke, CEO of Baldur’s Gate 3 developer Larian, said gen AI is being used for the studio’s next game Divinity but only for generating concepts and ideas. Everything in the finished game, he claimed, would be made by humans. He also hinted at why game makers insist on using the tech despite the backlash developers usually receive whenever it’s found.

“This is a tech-driven industry, so you try stuff,” he told Bloomberg reporter Jason Schreier in an interview. “You can’t afford not to try things because if somebody finds the golden egg and you’re not using it, you’re dead.”

Comments from other CEOs reinforce Vincke’s point. Junghun Lee, the CEO of ARC Raiders’ parent company Nexon, said in an interview that, “It’s important to assume that every game company is now using AI.”

The problem is, though, gen AI doesn’t yet seem to be the golden egg its supporters want people to believe it is. Last year, Keywords Studios, a game development services company, published a report on creating a 2D video game using only gen-AI tools. The company claimed that gen-AI tools can streamline some development processes but ultimately cannot replace the work of human talent. Discovering gen AI in Call of Duty and Pax Romana was possible precisely because of the low-quality of the images that were found. With Ubisoft’s interactive gen-AI NPCs, the dialogue they spout sounds unnatural and stilted. Players in the 2025 Chinese martial arts MMORPG Where Winds Meet are manipulating its AI chatbot NPCs to break the game, just like Fortnite players were able to make AI-powered Darth Vader swear.

For all the promises of gen AI, its current results do not live up to expectations. So why is it everywhere?

One reason is the competitive edge AI might but currently can’t provide that Swen Vincke alluded to in his interview with Bloomberg. Another reason is also the simplest: it’s the economy, stupid. Despite inflation, flagging consumer confidence and spending, and rising unemployment, the stock market is still booming, propped up by the billions and billions of dollars being poured into AI tech. Game makers in search of capital to keep business and profits going want in on that. Announcing AI initiatives and touting the use of AI tools — even if those tools have a relatively minor impact on the final product — can be a way to signal to AI-eager investors that a game company is worth their money.

That might explain why the majority of gen-AI’s supporters in gaming come from the C-suite of AAA studios and not smaller indie outfits who almost universally revile the tech. Indies face the same economic pressure as bigger studios but have far fewer resources to navigate those pressures. Ostensibly, indie developers are the ones who stand to benefit the most from the tech but, so far, are its biggest opponents. They are pushing back against the assertion that gen AI is everywhere, being used by everybody, with some marking their games with anti-AI logos proclaiming their games were made wholly by humans.

For some indie developers, using gen AI defeats the purpose of game making entirely. The challenge of coming up with ideas and solutions to development problems — the things gen AI is supposed to automate — is a big part of game making’s appeal to them. There are also moral and environmental implications indie developers seem especially sensitive to. Gen-AI outputs are cobbled from existing bodies of work that were often used without consent or compensation. AI data centers are notorious for consumptive energy usage and polluting their surrounding areas, which are increasingly focused in low-income and minority communities.With its unrealized promises and so-far shoddy outputs, it’s easy to think of gen AI as gaming’s next flash in the pan the way NFTs were. But with gaming’s biggest companies increasingly reporting their use, gen AI will remain a lightning rod in game development — until the tech improves, or, like with NFTs, the bubble pops.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-54')">
            <div class="source">MIT Technology Review</div>
            <div class="title">MIT Technology Review’s most popular stories of 2025</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-54" style="display:none;">
            <h2>MIT Technology Review’s most popular stories of 2025</h2>
            <p><strong>MIT Technology Review | 2025-12-26</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2025/12/26/1130318/mit-technology-review-most-popular-stories-2025/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">It&#39;s been a busy and productive year here at MIT Technology Review. We published magazine issues on power, creativity, innovation, bodies, relationships, and security. We hosted 14 exclusive virtual conversations with our editors and outside experts in our subscriber-only series, Roundtables, and held two events on MIT’s campus. And we published hundreds of articles online, following new developments in computing, climate tech, robotics, and more.

As the year winds down, we wanted to give you a chance to revisit a bit of this work with us. Whether we were covering the red-hot rise of artificial intelligence or the future of biotech, these are some of the stories that resonated the most with our readers.

We did the math on AI’s energy footprint. Here’s the story you haven’t heard.

Understanding AI’s energy use was a huge global conversation in 2025 as hundreds of millions of people began using generative AI tools on a regular basis. Senior reporters James O’Donnell and Casey Crownhart dug into the numbers and published an unprecedented look at AI’s resource demand, down to the level of a single query, to help us know how much energy and water AI may require moving forward.

We’re learning more about what vitamin D does to our bodies

Vitamin D deficiency is widespread, particularly in the winter when there’s less sunlight to drive its production in our bodies. The “sunshine vitamin” is important for bone health, but as senior reporter Jessica Hamzelou reported, recent research is also uncovering surprising new insights into other ways it might influence our bodies, including our immune systems and heart health.

Senior editor Will Douglas Heaven’s expansive look at how to define AI was published in 2024, but it still managed to connect with many readers this year. He lays out why no one can agree on what AI is—and explains why that ambiguity matters, and how it can inform our own critical thinking about this technology.

Ethically sourced “spare” human bodies could revolutionize medicine

In this thought-provoking op-ed, a team of experts at Stanford University argue that creating living human bodies that can’t think, don’t have any awareness, and can’t feel pain could shake up medical research and drug development by providing essential biological materials for testing and transplantation. Recent advances in biotechnology now provide a potential pathway to such “bodyoids,” though plenty of technical challenges and ethical hurdles remain.

It’s surprisingly easy to stumble into a relationship with an AI chatbot

Chatbots were everywhere this year, and reporter Rhiannon Williams chronicled how quickly people can develop bonds with one. That’s all right for some people, she notes, but dangerous for others. Some folks even describe unintentionally forming romantic relationships with chatbots. This is a trend we’ll definitely be keeping an eye on in 2026.

The electric grid is bracing for disruption from more frequent storms and fires, as well as an uncertain policy and regulatory landscape. And in many ways, the publicly owned utility company Lincoln Electric in Nebraska is an ideal lens through which to examine this shift as it works through the challenges of delivering service that’s reliable, affordable, and sustainable.

Exclusive: A record-breaking baby has been born from an embryo that’s over 30 years old

This year saw the birth of the world’s “oldest baby”: Thaddeus Daniel Pierce, who arrived on July 26. The embryo he developed from was created in 1994 during the early days of IVF and had been frozen and sitting in storage ever since. The new baby’s parents were toddlers at the time, and the embryo was donated to them decades later via a Christian “embryo adoption” agency.

How these two brothers became go-to experts on America’s “mystery drone” invasion

Twin brothers John and Gerald Tedesco teamed up to investigate a concerning new threat—unidentified drones. In 2024 alone, some 350 drones entered airspace over a hundred different US military installations, and many cases went unsolved, according to a top military official. This story takes readers inside the equipment-filled RV the Tedescos created to study mysterious aerial phenomena, and how they made a name for themselves among government officials.

Our newsroom has published this annual look at advances that will matter in the long run for over 20 years. This year’s list featured generative AI search, cleaner jet fuel, long-acting HIV prevention meds, and other emerging technologies that our journalists think are worth watching. We’ll publish the 2026 edition of the list on January 12, so stay tuned. (In the meantime, here’s what didn’t make the cut.)

We asked Al Jean, the longest-serving showrunner, about all the conspiracy theories.

The Cybertruck, sycophantic AI, and humanoid robots all made this year’s list of the biggest technology failures.

It’s a popular example of the “Mandela effect,” or a collective false memory. And while some people may laugh and move on, others spend years searching for an explanation.

A mix of technology and politics has given an unprecedented boost to once-fringe ideas—but they are pretty much the same fantasies that have been spreading for hundreds of years.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-55')">
            <div class="source">MIT Technology Review</div>
            <div class="title">The paints, coatings, and chemicals making the world a cooler place</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-55" style="display:none;">
            <h2>The paints, coatings, and chemicals making the world a cooler place</h2>
            <p><strong>MIT Technology Review | 2025-12-26</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2025/12/26/1129301/paint-coating-chemicals-materials-cooling-air-conditioning/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">It’s getting harder to beat the heat. During the summer of 2025, heat waves knocked out power grids in North America, Europe, and the Middle East. Global warming means more people need air-­conditioning, which requires more power and strains grids. But a millennia-old idea (plus 21st-century tech) might offer an answer: radiative cooling. Paints, coatings, and textiles can scatter sunlight and dissipate heat—no additional energy required.

“Radiative cooling is universal—it exists everywhere in our daily life,” says Qiaoqiang Gan, a professor of materials science and applied physics at King Abdullah University of Science and Technology in Saudi Arabia. Pretty much any object will absorb heat from the sun during the day and radiate some of it back at night. It’s why cars parked outside overnight are often covered with condensation, Gan says—their metal roofs dissipate heat into the sky, cooling the surfaces below the ambient air temperature. That’s how you get dew.

Humans have harnessed this basic natural process for thousands of years. Desert peoples in Iran, North Africa, and India manufactured ice by leaving pools of water exposed to clear desert skies overnight, when radiative cooling happens naturally; other cultures constructed “cool roofs” capped with reflective materials that scattered sunlight and lowered interior temperatures. “People have taken advantage of this effect, either knowingly or unknowingly, for a very long time,” says Aaswath Raman, a materials scientist at UCLA and cofounder of the radiative­cooling startup SkyCool Systems.

Modern approaches, as demonstrated everywhere from California supermarket rooftops to Japan’s Expo 2025 pavilion, go even further. Normally, if the sun is up and pumping in heat, surfaces can’t get cooler than the ambient temperature. But back in 2014, Raman and his colleagues achieved radiative cooling in the daytime. They customized photonic films to absorb and then radiate heat at infrared wavelengths between eight and 13 micrometers—a range of electromagnetic wavelengths called an “atmospheric window,” because that radiation escapes to space rather than getting absorbed. Those films could dissipate heat even under full sun, cooling the inside of a building to 9 °F below ambient temperatures, with no AC or energy source required.

That was proof of concept; today, Raman says, the industry has mostly shifted away from advanced photonics that use the atmospheric-window effect to simpler sunlight-scattering materials. Ceramic cool roofs, nanostructure coatings, and reflective polymers all offer the possibility of diverting more sunlight across all wavelengths, and they’re more durable and scalable.

Now the race is on. Startups such as SkyCool, Planck Energies, Spacecool, and i2Cool are competing to commercially manufacture and sell coatings that reflect at least 94% of sunlight in most climates, and above 97% in humid tropical ones. Pilot projects have already provided significant cooling to residential buildings, reducing AC energy needs by 15% to 20% in some cases.

This idea could go way beyond reflective rooftops and roads. Researchers are developing reflective textiles that can be worn by people most at risk of heat exposure. “This is personal thermal management,” says Gan. “We can realize passive cooling in T-shirts, sportswear, and garments.”

Of course, these technologies and materials have limits. Like solar power grids, they’re vulnerable to weather. Clouds prevent reflected sunlight from bouncing into space. Dust and air pollution dim materials’ bright surfaces. Lots of coatings lose their reflectivity after a few years. And the cheapest and toughest materials used in radiative cooling tend to rely on Teflon and other fluoropolymers, “forever chemicals” that don’t biodegrade, posing an environmental risk. “They are the best class of products that tend to survive outdoors,” says Raman. “So for long-term scale-up, can you do it without materials like those fluoropolymers and still maintain the durability and hit this low cost point?”

As with any other solution to the problems of climate change, one size won’t fit all. “We cannot be overoptimistic and say that radiative cooling can address all our future needs,” Gan says. “We still need more efficient active air-conditioning.” A shiny roof isn’t a panacea, but it’s still pretty cool.

Becky Ferreira is a science reporter based in upstate New York and author of First Contact: The Story of Our Obsession with Aliens.

As early electric cars age out, hundreds of thousands of used batteries are flooding the market, fueling a gray recycling economy even as Beijing and big manufacturers scramble to build a more orderly system.

Omar Yaghi thinks crystals with gaps that capture moisture could bring technology from “Dune” to the arid parts of Earth.

And why many scientists are freaked out about the first serious for-profit company moving into the solar geoengineering field.

How AI and renewables are shifting the energy landscape.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-56')">
            <div class="source">MIT Technology Review</div>
            <div class="title">AI Wrapped: The 14 AI terms you couldn’t avoid in 2025</div>
            <div class="meta">2025-12-25</div>
        </div>
        
        <div id="content-56" style="display:none;">
            <h2>AI Wrapped: The 14 AI terms you couldn’t avoid in 2025</h2>
            <p><strong>MIT Technology Review | 2025-12-25</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2025/12/25/1130298/ai-wrapped-the-14-ai-terms-you-couldnt-avoid-in-2025/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">If the past 12 months have taught us anything, it’s that the AI hype train is showing no signs of slowing. It’s hard to believe that at the beginning of the year, DeepSeek had yet to turn the entire industry on its head, Meta was better known for trying (and failing) to make the metaverse cool than for its relentless quest to dominate superintelligence, and vibe coding wasn’t a thing.

If that’s left you feeling a little confused, fear not. As we near the end of 2025, our writers have taken a look back over the AI terms that dominated the year, for better or worse.

Make sure you take the time to brace yourself for what promises to be another bonkers year.

As long as people have been hyping AI, they have been coming up with names for a future, ultra-powerful form of the technology that could bring about utopian or dystopian consequences for humanity. “Superintelligence” is that latest hot term. Meta announced in July that it would form an AI team to pursue superintelligence, and it was reportedly offering nine-figure compensation packages to AI experts from the company’s competitors to join.

In December, Microsoft’s head of AI followed suit, saying the company would be spending big sums, perhaps hundreds of billions, on the pursuit of superintelligence. If you think superintelligence is as vaguely defined as artificial general intelligence, or AGI, you’d be right! While it’s conceivable that these sorts of technologies will be feasible in humanity’s long run, the question is really when, and whether today’s AI is good enough to be treated as a stepping stone toward something like superintelligence. Not that that will stop the hype kings. —James O’Donnell

Thirty years ago, Steve Jobs said everyone in America should learn how to program a computer. Today, people with zero knowledge of how to code can knock up an app, game, or website in no time at all thanks to vibe coding—a catch-all phrase coined by OpenAI cofounder Andrej Karpathy. To vibe-code, you simply prompt generative AI models’ coding assistants to create the digital object of your desire and accept pretty much everything they spit out. Will the result work? Possibly not. Will it be secure? Almost definitely not, but the technique’s biggest champions aren’t letting those minor details stand in their way. Also—it sounds fun! — Rhiannon Williams

One of the biggest AI stories over the past year has been how prolonged interactions with chatbots can cause vulnerable people to experience delusions and, in some extreme cases, can either cause or worsen psychosis. Although “chatbot psychosis” is not a recognized medical term, researchers are paying close attention to the growing anecdotal evidence from users who say it’s happened to them or someone they know. Sadly, the increasing number of lawsuits filed against AI companies by the families of people who died following their conversations with chatbots demonstrate the technology’s potentially deadly consequences. —Rhiannon Williams

Few things kept the AI hype train going this year more than so-called reasoning models, LLMs that can break down a problem into multiple steps and work through them one by one. OpenAI released its first reasoning models, o1 and o3, a year ago.

A month later, the Chinese firm DeepSeek took everyone by surprise with a very fast follow, putting out R1, the first open-source reasoning model. In no time, reasoning models became the industry standard: All major mass-market chatbots now come in flavors backed by this tech. Reasoning models have pushed the envelope of what LLMs can do, matching top human performances in prestigious math and coding competitions. On the flip side, all the buzz about LLMs that could “reason” reignited old debates about how smart LLMs really are and how they really work. Like “artificial intelligence” itself, “reasoning” is technical jargon dressed up with marketing sparkle. Choo choo! —Will Douglas Heaven

For all their uncanny facility with language, LLMs have very little common sense. Put simply, they don’t have any grounding in how the world works. Book learners in the most literal sense, LLMs can wax lyrical about everything under the sun and then fall flat with a howler about how many elephants you could fit into an Olympic swimming pool (exactly one, according to one of Google DeepMind’s LLMs).

World models—a broad church encompassing various technologies—aim to give AI some basic common sense about how stuff in the world actually fits together. In their most vivid form, world models like Google DeepMind’s Genie 3 and Marble, the much-anticipated new tech from Fei-Fei Li’s startup World Labs, can generate detailed and realistic virtual worlds for robots to train in and more. Yann LeCun, Meta’s former chief scientist, is also working on world models. He has been trying to give AI a sense of how the world works for years, by training models to predict what happens next in videos. This year he quit Meta to focus on this approach in a new start up called Advanced Machine Intelligence Labs. If all goes well, world models could be the next thing. —Will Douglas Heaven

Have you heard about all the people saying no thanks, we actually don’t want a giant data center plopped in our backyard? The data centers in question—which tech companies want to built everywhere, including space—are typically referred to as hyperscalers: massive buildings purpose-built for AI operations and used by the likes of OpenAI and Google to build bigger and more powerful AI models. Inside such buildings, the world’s best chips hum away training and fine-tuning models, and they’re built to be modular and grow according to needs.

It’s been a big year for hyperscalers. OpenAI announced, alongside President Donald Trump, its Stargate project, a $500 billion joint venture to pepper the country with the largest data centers ever. But it leaves almost everyone else asking: What exactly do we get out of it? Consumers worry the new data centers will raise their power bills. Such buildings generally struggle to run on renewable energy. And they don’t tend to create all that many jobs. But hey, maybe these massive, windowless buildings could at least give a moody, sci-fi vibe to your community. —James O’Donnell

The lofty promises of AI are levitating the economy. AI companies are raising eye-popping sums of money and watching their valuations soar into the stratosphere. They’re pouring hundreds of billions of dollars into chips and data centers, financed increasingly by debt and eyebrow-raising circular deals. Meanwhile, the companies leading the gold rush, like OpenAI and Anthropic, might not turn a profit for years, if ever. Investors are betting big that AI will usher in a new era of riches, yet no one knows how transformative the technology will actually be.

Most organizations using AI aren’t yet seeing the payoff, and AI work slop is everywhere. There’s scientific uncertainty about whether scaling LLMs will deliver superintelligence or whether new breakthroughs need to pave the way. But unlike their predecessors in the dot-com bubble, AI companies are showing strong revenue growth, and some are even deep-pocketed tech titans like Microsoft, Google, and Meta. Will the manic dream ever burst? —Michelle Kim

This year, AI agents were everywhere. Every new feature announcement, model drop, or security report throughout 2025 was peppered with mentions of them, even though plenty of AI companies and experts disagree on exactly what counts as being truly “agentic,” a vague term if ever there was one. No matter that it’s virtually impossible to guarantee that an AI acting on your behalf out in the wide web will always do exactly what it’s supposed to do—it seems as though agentic AI is here to stay for the foreseeable. Want to sell something? Call it agentic! —Rhiannon Williams

Early this year, DeepSeek unveiled its new model DeepSeek R1, an open-source reasoning model that matches top Western models but costs a fraction of the price. Its launch freaked Silicon Valley out, as many suddenly realized for the first time that huge scale and resources were not necessarily the key to high-level AI models. Nvidia stock plunged by 17% the day after R1 was released.

The key to R1’s success was distillation, a technique that makes AI models more efficient. It works by getting a bigger model to tutor a smaller model: You run the teacher model on a lot of examples and record the answers, and reward the student model as it copies those responses as closely as possible, so that it gains a compressed version of the teacher’s knowledge.  —Caiwei Chen

As people across the world spend increasing amounts of time interacting with chatbots like ChatGPT, chatbot makers are struggling to work out the kind of tone and “personality” the models should adopt. Back in April, OpenAI admitted it’d struck the wrong balance between helpful and sniveling, saying a new update had rendered GPT-4o too sycophantic. Having it suck up to you isn’t just irritating—it can mislead users by reinforcing their incorrect beliefs and spreading misinformation. So consider this your reminder to take everything—yes, everything—LLMs produce with a pinch of salt. —Rhiannon Williams

If there is one AI-related term that has fully escaped the nerd enclosures and entered public consciousness, it’s “slop.” The word itself is old (think pig feed), but “slop” is now commonly used to refer to low-effort, mass-produced content generated by AI, often optimized for online traffic. A lot of people even use it as a shorthand for any AI-generated content. It has felt inescapable in the past year: We have been marinated in it, from fake biographies to shrimp Jesus images to surreal human-animal hybrid videos.

But people are also having fun with it. The term’s sardonic flexibility has made it easy for internet users to slap it on all kinds of words as a suffix to describe anything that lacks substance and is absurdly mediocre: think “work slop” or “friend slop.” As the hype cycle resets, “slop” marks a cultural reckoning about what we trust, what we value as creative labor, and what it means to be surrounded by stuff that was made for engagement rather than expression. —Caiwei Chen

Did you come across the hypnotizing video from earlier this year of a humanoid robot putting away dishes in a bleak, gray-scale kitchen? That pretty much embodies the idea of physical intelligence: the idea that advancements in AI can help robots better move around the physical world.

It’s true that robots have been able to learn new tasks faster than ever before, everywhere from operating rooms to warehouses. Self-driving-car companies have seen improvements in how they simulate the roads, too. That said, it’s still wise to be skeptical that AI has revolutionized the field. Consider, for example, that many robots advertised as butlers in your home are doing the majority of their tasks thanks to remote operators in the Philippines.

The road ahead for physical intelligence is also sure to be weird. Large language models train on text, which is abundant on the internet, but robots learn more from videos of people doing things. That’s why the robot company Figure suggested in September that it would pay people to film themselves in their apartments doing chores. Would you sign up? —James O&#39;Donnell

AI models are trained by devouring millions of words and images across the internet, including copyrighted work by artists and writers. AI companies argue this is “fair use”—a legal doctrine that lets you use copyrighted material without permission if you transform it into something new that doesn’t compete with the original. Courts are starting to weigh in. In June, Anthropic’s training of its AI model Claude on a library of books was ruled fair use because the technology was “exceedingly transformative.”

That same month, Meta scored a similar win, but only because the authors couldn’t show that the company’s literary buffet cut into their paychecks. As copyright battles brew, some creators are cashing in on the feast. In December, Disney signed a splashy deal with OpenAI to let users of Sora, the AI video platform, generate videos featuring more than 200 characters from Disney&#39;s franchises. Meanwhile, governments around the world are rewriting copyright rules for the content-guzzling machines. Is training AI on copyrighted work fair use? As with any billion-dollar legal question, it depends. —Michelle Kim

Just a few short years ago, an entire industry was built around helping websites rank highly in search results (okay, just in Google). Now search engine optimization (SEO), is giving way to GEO—generative engine optimization—as the AI boom forces brands and businesses to scramble to maximize their visibility in AI, whether that’s in AI-enhanced search results like Google’s AI Overviews or within responses from LLMs. It’s no wonder they’re freaked out. We already know that news companies have experienced a colossal drop in search-driven web traffic, and AI companies are working on ways to cut out the middleman and allow their users to visit sites from directly within their platforms. It’s time to adapt or die. —Rhiannon Williams

The idea that machines will be as smart as—or smarter than—humans has hijacked an entire industry. But look closely and you’ll see it’s a myth that persists for many of the same reasons conspiracies do.

The experimental model won&#39;t compete with the biggest and best, but it could tell us why they behave in weird ways—and how trustworthy they really are.

Four ways to think about this year&#39;s reckoning

They managed to cut the size of the AI reasoning model by more than half—and claim it can now answer politically sensitive questions once off limits in Chinese AI systems.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-57')">
            <div class="source">MIT Technology Review</div>
            <div class="title">Meet the man hunting the spies in your smartphone</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-57" style="display:none;">
            <h2>Meet the man hunting the spies in your smartphone</h2>
            <p><strong>MIT Technology Review | 2025-12-24</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2025/12/24/1129294/ronald-deibert-citizen-lab-digital-threats-spies-cybersecurity/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">In April 2025, Ronald Deibert left all electronic devices at home in Toronto and boarded a plane. When he landed in Illinois, he took a taxi to a mall and headed directly to the Apple Store to purchase a new laptop and iPhone. He’d wanted to keep the risk of having his personal devices confiscated to a minimum, because he knew his work made him a prime target for surveillance. “I’m traveling under the assumption that I am being watched, right down to exactly where I am at any moment,” Deibert says.

Deibert directs the Citizen Lab, a research center he founded in 2001 to serve as “counterintelligence for civil society.” Housed at the University of Toronto, the lab operates independently of governments or corporate interests, relying instead on research grants and private philanthropy for financial support. It’s one of the few institutions that investigate cyberthreats exclusively in the public interest, and in doing so, it has exposed some of the most egregious digital abuses of the past two decades.

For many years, Deibert and his colleagues have held up the US as the standard for liberal democracy. But that’s changing, he says: “The pillars of democracy are under assault in the United States. For many decades, in spite of its flaws, it has upheld norms about what constitutional democracy looks like or should aspire to. [That] is now at risk.”

Even as some of his fellow Canadians avoided US travel after Donald Trump’s second election, Deibert relished the opportunity to visit. Alongside his meetings with human rights defenders, he also documented active surveillance at Columbia University during the height of its student protests. Deibert snapped photos of drones above campus and noted the exceptionally strict security protocols. “It was unorthodox to go to the United States,” he says. “But I really gravitate toward problems in the world.”

Deibert, 61, grew up in East Vancouver, British Columbia, a gritty area with a boisterous countercultural presence. In the ’70s, Vancouver brimmed with draft dodgers and hippies, but Deibert points to American investigative journalism—exposing the COINTELPRO surveillance program, the Pentagon Papers, Watergate—as the seed of his respect for antiestablishment sentiment. He didn’t imagine that this fascination would translate into a career, however.

“My horizons were pretty low because I came from a working-class family, and there weren’t many people in my family—in fact, none—who went on to university,” he says.

Deibert eventually entered a graduate program in international relations at the University of British Columbia. His doctoral research brought him to a field of inquiry that would soon explode: the geopolitical implications of the nascent internet.

“In my field, there were a handful of people beginning to talk about the internet, but it was very shallow, and that frustrated me,” he says. “And meanwhile, computer science was very technical, but not political—[politics] was almost like a dirty word.”

Deibert continued to explore these topics at the University of Toronto when he was appointed to a tenure-track professorship, but it wasn’t until after he founded the Citizen Lab in 2001 that his work rose to global prominence.

What put the lab on the map, Deibert says, was its 2009 report “Tracking GhostNet,” which uncovered a digital espionage network in China that had breached offices of foreign embassies and diplomats in more than 100 countries, including the office of the Dalai Lama. The report and its follow-up in 2010 were among the first to publicly expose cybersurveillance in real time. In the years since, the lab has published over 180 such analyses, garnering praise from human rights advocates ranging from Margaret Atwood to Edward Snowden.

The lab has rigorously investigated authoritarian regimes around the world (Deibert says both Russia and China have his name on a “list” barring his entry). The group was the first to uncover the use of commercial spyware to surveil people close to the Saudi dissident and Washington Post journalist Jamal Khashoggi prior to his assassination, and its research has directly informed G7 and UN resolutions on digital repression and led to sanctions on spyware vendors. Even so, in 2025 US Immigration and Customs Enforcement reactivated a $2 million contract with the spyware vendor Paragon. The contract, which the Biden administration had previously placed under a stop-work order, resembles steps taken by governments in Europe and Israel that have also deployed domestic spyware to address security concerns.

“It saves lives, quite literally,” Cindy Cohn, executive director of the Electronic Frontier Foundation, says of the lab’s work. “The Citizen Lab [researchers] were the first to really focus on technical attacks on human rights activists and democracy activists all around the world. And they’re still the best at it.”

When recruiting new Citizen Lab employees (or “Labbers,” as they refer to one another), Deibert forgoes stuffy, pencil-pushing academics in favor of brilliant, colorful personalities, many of whom personally experienced repression from some of the same regimes the lab now investigates.

Noura Aljizawi, a researcher on digital repression who survived torture at the hands of the al-Assad regime in Syria, researches the distinct threat that digital technologies pose to women and queer people, particularly when deployed against exiled nationals. She helped create Security Planner, a tool that gives personalized, expert-reviewed guidance to people looking to improve their digital hygiene, for which the University of Toronto awarded her an Excellence Through Innovation Award.

Work for the lab is not without risk. Citizen Lab fellow Elies Campo, for example, was followed and photographed after the lab published a 2022 report that exposed the digital surveillance of dozens of Catalonian citizens and members of parliament, including four Catalonian presidents who were targeted during or after their terms.

Still, the lab’s reputation and mission make recruitment fairly easy, Deibert says. “This good work attracts a certain type of person,” he says. “But they’re usually also drawn to the sleuthing. It’s detective work, and that can be highly intoxicating—even addictive.”

Deibert frequently deflects the spotlight to his fellow Labbers. He rarely discusses the group’s accomplishments without referencing two senior researchers, Bill Marczak and John Scott-Railton, alongside other staffers. And on the occasion that someone decides to leave the Citizen Lab to pursue another position, this appreciation remains.

“We have a saying: Once a Labber, always a Labber,” Deibert says.

While in the US, Deibert taught a seminar on the Citizen Lab’s work to Northwestern University undergraduates and delivered talks on digital authoritarianism at the Columbia University Graduate School of Journalism. Universities in the US had been subjected to funding cuts and heightened scrutiny from the Trump administration, and Deibert wanted to be “in the mix” at such institutions to respond to what he sees as encroaching authoritarian practices by the US government.

Since Deibert’s return to Canada, the lab has continued its work unearthing digital threats to civil society worldwide, but now Deibert must also contend with the US—a country that was once his benchmark for democracy but has become another subject of his scrutiny. “I do not believe that an institution like the Citizen Lab could exist right now in the United States,” he says. “The type of research that we pioneered is under threat like never before.”

He is particularly alarmed by the increasing pressures facing federal oversight bodies and academic institutions in the US. In September, for example, the Trump administration defunded the Council of the Inspectors General on Integrity and Efficiency, a government organization dedicated to preventing waste, fraud, and abuse within federal agencies, citing partisanship concerns. The White House has also threatened to freeze federal funding to universities that do not comply with administration directives related to gender, DEI, and campus speech. These sorts of actions, Deibert says, undermine the independence of watchdogs and research groups like the Citizen Lab.

Cohn, the director of the EFF, says the lab’s location in Canada allows it to avoid many of these attacks on institutions that provide accountability. “Having the Citizen Lab based in Toronto and able to continue to do its work largely free of the things we’re seeing in the US,” she says, “could end up being tremendously important if we’re going to return to a place of the rule of law and protection of human rights and liberties.”

Finian Hazen is a journalism and political science student at Northwestern University.

The sunshine vitamin could affect your immune system and heart health.

The idea that machines will be as smart as—or smarter than—humans has hijacked an entire industry. But look closely and you’ll see it’s a myth that persists for many of the same reasons conspiracies do.

The experimental model won&#39;t compete with the biggest and best, but it could tell us why they behave in weird ways—and how trustworthy they really are.

As early electric cars age out, hundreds of thousands of used batteries are flooding the market, fueling a gray recycling economy even as Beijing and big manufacturers scramble to build a more orderly system.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-58')">
            <div class="source">MIT Technology Review</div>
            <div class="title">Four bright spots in climate news in 2025</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-58" style="display:none;">
            <h2>Four bright spots in climate news in 2025</h2>
            <p><strong>MIT Technology Review | 2025-12-24</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2025/12/24/1130191/good-climate-news-2025/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Climate news hasn’t been great in 2025. Global greenhouse-gas emissions hit record highs (again). This year is set to be either the second or third warmest on record. Climate-fueled disasters like wildfires in California and flooding in Indonesia and Pakistan devastated communities and caused billions in damage.

In addition to these worrying indicators of our continued contributions to climate change and their obvious effects, the world’s largest economy has made a sharp U-turn on climate policy this year. The US under the Trump administration withdrew from the Paris Agreement, cut funds for climate research, and scrapped billions of dollars in funding for climate tech projects.

We’re in a severe situation with climate change. But for those looking for bright spots, there was some good news in 2025. Here are a few of the positive stories our climate reporters noticed this year.

One of the most notable and encouraging signs of progress this year occurred in China. The world’s second-biggest economy and biggest climate polluter has managed to keep carbon dioxide emissions flat for the last year and a half, according to an analysis in Carbon Brief.

That’s happened before, but only when the nation’s economy was retracting, including in the midst of the covid-19 pandemic. But emissions are now falling even as China’s economy is on track to grow about 5% this year, and electricity demands continue to rise.

So what’s changed? China has now installed so much solar and wind, and put so many EVs on the road, that its economy can continue to expand without increasing the amount of carbon dioxide it’s pumping into the atmosphere, decoupling the traditional link between emissions and growth.

Specifically, China added an astounding 240 gigawatts of solar power capacity and 61 gigawatts of wind power in the first nine months of the year, the Carbon Brief analysis noted. That’s nearly as much solar power as the US has installed in total, in just the first three quarters of this year.

It’s too early to say China’s emissions have peaked, but the country has said it will officially reach that benchmark before 2030.

To be clear, China still isn’t moving fast enough to keep the world on track for meeting relatively safe temperature targets. (Indeed, very few countries are.) But it’s now both producing most of the world’s clean energy technologies and curbing its emissions growth, providing a model for cleaning up industrial economies without sacrificing economic prosperity—and setting the stage for faster climate progress in the coming years.

It’s hard to articulate just how quickly batteries for grid storage are coming online. These massive arrays of cells can soak up electricity when sources like solar are available and prices are low, and then discharge power back to the grid when it’s needed most.

Back in 2015, the battery storage industry had installed only a fraction of a gigawatt of battery storage capacity across the US. That year, it set a seemingly bold target of adding 35 gigawatts by 2035. The sector passed that goal a decade early this year and then hit 40 gigawatts a couple of months later.

Costs are still falling, which could help maintain the momentum for the technology’s deployment. This year, battery prices for EVs and stationary storage fell yet again, reaching a record low, according to data from BloombergNEF. Battery packs specifically used for grid storage saw prices fall even faster than the average; they cost 45% less than last year.

We’re starting to see what happens on grids with lots of battery capacity, too: in California and Texas, batteries are already helping meet demand in the evenings, reducing the need to run natural-gas plants. The result: a cleaner, more stable grid.

The AI boom is complicated for our energy system, as we covered at length this year. Electricity demand is ticking up: the amount of power utilities supplied to US data centers jumped 22% this year and will more than double by 2030.

But at least one positive shift is coming out of AI’s influence on energy: It’s driving renewed interest and investment in next-generation energy technologies.

In the near term, much of the energy needed for data centers, including those that power AI, will likely come from fossil fuels, especially new natural-gas power plants. But tech giants like Google, Microsoft, and Meta all have goals on the books to reduce their greenhouse-gas emissions, so they’re looking for alternatives.

Meta signed a deal with XGS Energy in June to purchase up to 150 megawatts of electricity from a geothermal plant. In October, Google signed an agreement that will help reopen Duane Arnold Energy Center in Iowa, a previously shuttered nuclear power plant.

Geothermal and nuclear could be key pieces of the grid of the future, as they can provide constant power in a way that wind and solar don’t. There’s a long way to go for many of the new versions of the tech, but more money and interest from big, powerful players can’t hurt.

Perhaps the strongest evidence of collective climate progress so far: We’ve already avoided the gravest dangers that scientists feared just a decade ago.

The world is on track for about 2.6 °C of warming over preindustrial conditions by 2100, according to Climate Action Tracker, an independent scientific effort to track the policy progress that nations have made toward their goals under the Paris climate agreement.That’s a lot warmer than we want the planet to ever get. But it’s also a whole degree better than the 3.6 °C path that we were on a decade ago, just before nearly 200 countries signed the Paris deal.

That progress occurred because more and more nations passed emissions mandates, funded subsidies, and invested in research and development—and private industry got busy cranking out vast amounts of solar panels, wind turbines, batteries, and EVs.

The bad news is that progress has stalled. Climate Action Tracker notes that its warming projections have remained stubbornly fixed for the last four years, as nations have largely failed to take the additional action needed to bend that curve closer to the 2 °C goal set out in the international agreement.

But having shaved off a degree of danger is still demonstrable proof that we can pull together in the face of a global threat and address a very, very hard problem. And it means we’ve done the difficult work of laying down the technical foundation for a society that can largely run without spewing ever more greenhouse gas into the atmosphere.

Hopefully, as cleantech continues to improve and climate change steadily worsens, the world will find the collective will to pick up the pace again soon.

As early electric cars age out, hundreds of thousands of used batteries are flooding the market, fueling a gray recycling economy even as Beijing and big manufacturers scramble to build a more orderly system.

Omar Yaghi thinks crystals with gaps that capture moisture could bring technology from “Dune” to the arid parts of Earth.

And why many scientists are freaked out about the first serious for-profit company moving into the solar geoengineering field.

How AI and renewables are shifting the energy landscape.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-59')">
            <div class="source">MIT Technology Review</div>
            <div class="title">Researchers are getting organoids pregnant with human embryos</div>
            <div class="meta">2025-12-23</div>
        </div>
        
        <div id="content-59" style="display:none;">
            <h2>Researchers are getting organoids pregnant with human embryos</h2>
            <p><strong>MIT Technology Review | 2025-12-23</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2025/12/23/1130415/organoid-uterus-microfluidic-chip-embryo/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">At first glance, it looks like the start of a human pregnancy: A ball-shaped embryo presses gently into the receptive lining of the uterus and then grips tight, burrowing in as the first tendrils of a future placenta appear.

This is implantation—the moment that pregnancy officially begins.

Only none of it is happening inside a body. These images were captured in a Beijing laboratory, inside a microfluidic chip, as scientists watched the scene unfold.

In three papers published this week by Cell Press, scientists are reporting what they call the most accurate efforts yet to mimic the first moments of pregnancy in the lab. They’ve taken human embryos from IVF centers and let these merge with “organoids” made of endometrial cells, which form the lining of the uterus.

The reports—two from China and a third involving a collaboration among researchers in the United Kingdom, Spain, and the US—show how scientists are using engineered tissues to better understand early pregnancy and potentially improve IVF outcomes.

“You have an embryo and the endometrial organoid together,” says Jun Wu, a biologist at the University of Texas Southwestern Medical Center, in Dallas, who contributed to both Chinese reports. “That’s the overarching message of all three papers.”

According to the papers, these 3D combinations are the most complete re-creations yet of the first days of pregnancy and should be useful for studying why IVF treatments often fail.

In each case, the experiments were stopped when the embryos were two weeks old, if not sooner. That is due to legal and ethical rules that typically restrict scientists from going any further than 14 days.

In your basic IVF procedure, an egg is fertilized in the lab and allowed to develop into a spherical embryo called a blastocyst—a process that takes a few days. That blastocyst then gets put into a patient’s uterus in the hope it will establish itself there and ultimately become a baby.

But that’s a common failure point. Many patients will learn that their IVF procedure didn’t work because an embryo never attached.

In the new reports, it’s that initial bond between mother and embryo that is being reproduced in the lab. “IVF means in vitro fertilization, but now this is the stage of in vitro implantation,” says Matteo Molè, a biologist at Stanford University whose results with collaborators in Europe are among those published today. “Considering that implantation is a barrier [to pregnancy], we have the potential to increase the success rate if we can model it in the laboratory.”

Normally implantation is entirely hidden from view because it occurs in someone’s uterus, says Hongmei Wang, a developmental biologist at the Beijing Institute for Stem Cell and Regenerative Medicine, who co-led the effort there. Wang often studies monkeys because she can interrupt their pregnancies to collect the tissues she needs to see. “We’ve always hoped to understand human embryo implantation, but we have lacked a way to do so,” she says. “It’s all happening in the uterus.”

In the Beijing study, researchers tested about 50 donated IVF embryos, but they also ran a thousand more experiments using so-called blastoids. The latter are mimics of early-stage human embryos manufactured from stem cells. Blastoids are easy to make in large numbers and, since they aren’t true embryos, don’t have as many ethical rules on their use.

“The question was, if we have these blastoids, what can we use them for?” says Leqian Yu, the senior author of the report from the Beijing Institute. “The obvious next step was implantation. So how do you do that?”

For the Beijing team, the answer was to build a soft silicone chamber with tiny channels to add nutrients and a space to grow the uterine organoid. After that, blastoids—or real embryos—could be introduced through a window in the device, so the “pregnancy” could start.

“The key question we want to try to answer is what is the first cross-talk between embryo and mother,” says Yu. “I think this is maybe the first time we can see the entire process.”

This isn’t the first time researchers have tried using organoids for this kind of research. At least two startup companies have raised funds to commercialize similar systems—in some cases presenting the organoids as a tool to predict IVF success. In addition to Dawn Bio, a startup based in Vienna, there is Simbryo Technologies, in Houston, which last month said it would begin offering “personalized” predictions for IVF patients using blastoids and endometrial organoids.

To do that test, doctors will take a biopsy of a patient’s uterine lining and grow organoids from it. After that, blastoids will be added to the organoids to gauge whether a woman is likely to be able to support a pregnancy or not. If the blastoids don’t start to implant, it could mean the patient’s uterus isn’t receptive and is the reason IVF isn’t working.

The Beijing team thinks the pregnancy organoids could also be used to identify drugs that might help those patients. In their paper, they describe how they made organoids out of tissue taken from women who’ve had repeated IVF failures. Then they tested 1,119 approved drugs on those samples to see if anything improved.

Several seemed to have helpful effects. One chemical, avobenzone, an ingredient in some types of sunblock, increased the chance that a blastoid would start implanting from just 5% of the time to around 25% of the time. Yu says his center hopes to eventually start a clinical trial if they can find the right drug to try.

The Beijing group is working on ways to improve the organoid system so that it’s even more realistic. Right now, it lacks important cell types, including immune cells and a blood supply. Yu says a next step he’s working on is to add blood vessels and tiny pumps to his chip device, so that he can give the organoids a kind of rudimentary circulation.

This means that in the near future, blastoids or embryos could likely be grown longer, raising questions about how far scientists will be able to take pregnancy in the lab. “I think this technology does raise the possibility of growing things longer,” says Wu, who says some view the research as an initial step toward creating babies entirely outside the body.

However, Wu says incubating a human to term in the laboratory remains impossible, for the time being. “This technology is certainly related to ectogenesis, or development outside the body,” he says. “But I don’t think it’s anywhere near an artificial womb. That’s still science fiction.”

The sunshine vitamin could affect your immune system and heart health.

Yes, you can pay $50,000 to clone a pet. But others are using the technology to rescue endangered species.

Preventing the common cold is extremely tricky—but not impossible.

Entrepreneurs say it’s time to safety-test designer baby technology.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-60')">
            <div class="source">The Next Web</div>
            <div class="title">A New Era for TNW.</div>
            <div class="meta">2025-12-22</div>
        </div>
        
        <div id="content-60" style="display:none;">
            <h2>A New Era for TNW.</h2>
            <p><strong>The Next Web | 2025-12-22</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/a-new-era-for-tnw">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">My name is Alexandru Stan, and this article continues the dialogue I began following the acquisition of TNW.

Following the recent transaction, TNW Spaces remains with the Financial Times, while we continue the mission of the website, the events, and the global community.

We already have a dedicated team at tekpon operating the platform, events, and community initiatives. Our objective is to expand and strengthen the team as TNW accelerates its next chapter.

TNW is already a global media platform with millions of readers. We’re not starting over. We are building forward.

The latest rumblings from the EU tech scene, a story from our wise ol&#39; founder Boris, and some questionable AI art. It&#39;s free, every week, in your inbox. Sign up now!

Technology is entering a decisive stage: AI is reshaping workflows, distribution is shifting, capital is becoming more selective, and founders are expected to demonstrate value rather than potential.

The world doesn’t need more noise.
It needs clarity, execution, and access to trustworthy knowledge and people.

TNW will serve that need through editorial independence, real expertise, and community-built intelligence.

Success for TNW looks like this: more accurate understanding, faster access to verified knowledge, and direct pathways from insight to action.

I’ve been an entrepreneur since 2007, building in B2B SaaS, marketplaces, and scalable systems. I believe deeply in servant leadership. Without people, I am zero.

I lead two private networks grounded in practice rather than theory:

These groups ensure TNW remains rooted in lived experience, informed by operators, not commentators.

Our mission is to build the most trusted European tech media platform with global reach, focused on practical innovation, responsible scaling, and transparency.

We will continue to host events across Europe’s major capitals including Paris, London, Berlin, Amsterdam, and Monaco.

These will not be festivals. We are introducing a concept validated through tekpon events: curated gatherings built for meaningful relationships, deep content, and tangible business outcomes.

In 2026, we return to Amsterdam for a special edition centered on AI among other fields. We will explore technologies and strategies shaping the future of work and business:

The editorial focus remains European, while the audience is global.

AI is not a threat to publishing. It is the infrastructure of the next generation of content and knowledge.

At TNW, we will use AI to accelerate research, enable personalized intelligence, reduce noise and bias, and amplify high-quality human expertise. Technology assists. Human judgment remains central.

Because this moment in Europe matters.
Because founders here are ready to scale responsibly.
Because independent media with integrity is rare.
Because innovation deserves a platform built around people, not hype.

TNW will continue its legacy with a renewed emphasis on contribution, execution, and community built through trust.

If you are building, scaling, or researching the next wave of technology, I invite you to engage with us, contribute insights, and participate in shaping the conversation.

The next era begins now. Let’s shape it together.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-61')">
            <div class="source">The Next Web</div>
            <div class="title">Engineering’s AI reality check</div>
            <div class="meta">2025-12-19</div>
        </div>
        
        <div id="content-61" style="display:none;">
            <h2>Engineering’s AI reality check</h2>
            <p><strong>The Next Web | 2025-12-19</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/engineerings-ai-reality-check">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Most engineering leaders cannot answer the one question their CFO is about to ask: “Can you prove this AI spend is changing outcomes, not just activity?”

Every December, roadmaps get locked, budgets get approved, and board decks are polished until everything looks precise and under control. Underneath, many CTOs and VPs are still working with partial visibility. They have a feel for their teams, but not a reliable view of how work moves through the system, how AI is really changing delivery, or where time and money actually go.

For a while, that was survivable. Experience, pattern recognition, and cheap capital covered the gaps. You could hire around bottlenecks, overstaff critical teams, or quietly pivot away from the messiest parts of the system. Then AI showed up and became the perfect distraction. Pilots, PoCs, Copilot seats, and “AI initiatives” created visible activity and bought time.

In 2026, that grace period ends. Boards and CFOs are shifting from “show me you are experimenting” to “show me measurable impact, this year.” Not because they stopped believing in AI, but because the market no longer rewards vague promises. Every AI dollar will need a traceable path to productivity, quality, or customer value.

The latest rumblings from the EU tech scene, a story from our wise ol&#39; founder Boris, and some questionable AI art. It&#39;s free, every week, in your inbox. Sign up now!

If you run engineering, you probably recognise this scene. You present a slide with AI highlights. Adoption is up. Developers say they like the tools. You share a few anecdotes about faster coding and smoother reviews. Then the CFO asks a simple question: “Exactly how is this budget changing output and outcomes?”

What is almost always missing is a clear breakdown of:

So the conversation slips back to learning curves, compounding benefits, and talent attraction. All true, but too soft for a tough budget review. That will not be enough.

AI vendors love task-level numbers. A coding task completed 55 percent faster looks impressive on a slide. But once you zoom out to teams and systems, the picture changes.

Large datasets across thousands of developers show a consistent pattern:

The problem is not the tools. It is the lack of a system for where the “extra” capacity goes.

Most organisations still frame AI productivity in terms of speed: more story points, more tickets, higher deployment frequency. That misses the bigger question:

How much of our engineering capacity goes to net new value versus maintenance, incidents, and rework, and is AI improving that mix?

High-level benchmarks are blunt but helpful. On average, about 45 percent of developer time is spent on maintenance, minor enhancements, and bug fixes rather than on genuinely new, customer-facing work. If AI helps you produce more code inside an unchanged system, you risk:

That is how you end up with impressive local metrics and a leadership team that still feels like engineering is slowing down.

If you want to walk into a 2026 budget conversation with objective evidence, you need to be deliberate about how AI-driven time savings are used. Two moves matter.

AI is already good at boilerplate, tests, documentation, and simple refactors. The trap is treating the saved time as unstructured “extra” capacity that disappears into the noise. Instead:

When teams systematically reduce technical debt and improve tests around critical flows, they cut future incidents and rework. Over a year, that frees more capacity for new work than shaving a few minutes off each ticket ever will.

2. Point AI at the ugly, high-friction work that commonly blows up roadmaps

The biggest productivity wins are not in everyday code generation. They are in:

These activities steal weeks or months of capacity and stall strategic initiatives. Using AI to understand legacy code faster, propose refactoring plans, generate migration scaffolding, and highlight recurring failure patterns can dramatically compress timelines for this work.

In parallel, there is real leverage upstream in the problem space. Teams that reach higher levels of AI adoption report better gains when they:

That reduces wasted builds and focuses effort on changes customers actually care about. The most significant gains do not come from replacing human creativity, but from amplifying it and aiming it at better-defined problems.

DORA metrics are not the enemy. Deployment frequency, lead time, MTTR, and change failure rate remain among the best signals we have for delivery performance. The risk is mistaking them for the whole picture.

Leading organisations are already expanding their scorecard to include:

In 2026, the question in the boardroom will shift from “Are we elite on DORA?” to “How much of our capacity is going into things customers notice, and is AI improving that mix or not?” To answer that cleanly, DORA is necessary but not sufficient. You need a way to connect AI usage, workflow, quality, and business outcomes across the system.

This is where engineering intelligence platforms move from a nice-to-have to mandatory. The organisations that win in 2026 will not do it with one more AI tool or one more disconnected dashboard. They will do it by pulling together data they already have but rarely use in one coherent view:

From there, leaders can answer the questions that actually matter:

Instead of defending AI spend with anecdotes, you walk in with:

That is the difference between “we believe in AI” and “here is how AI changed our delivery engine in measurable ways.”

To be ready for the more complex questions coming next year, use this planning cycle to do four things.

Do this, and you will not just have “AI activity” to show in 2026. You will have a credible, data-backed story from AI spend to business outcomes.

The leaders who thrive next year will not be the ones with the flashiest AI demos or the loudest “AI strategy” slide. They will be the ones who:

Engineering intelligence platforms is a key part of that shift. They give you the complex data to show where time and money go, how AI is really changing delivery, and whether your current pace is sustainable. The shift to data-backed engineering leadership is happening either way.

The gap in 2026 will be between teams still guessing and teams that can prove, in detail, how their engineering organisation works.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-62')">
            <div class="source">The Next Web</div>
            <div class="title">Letter from the Editor-in-Chief</div>
            <div class="meta">2025-12-16</div>
        </div>
        
        <div id="content-62" style="display:none;">
            <h2>Letter from the Editor-in-Chief</h2>
            <p><strong>The Next Web | 2025-12-16</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/letter-from-the-editor-in-chief">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Not long ago, like many of you, I read what I feared might be The Next Web’s final article. In late September, TNW’s co-founder announced that the tech conference and news site would be winding down, no more events, no new stories. It felt like the end of an era; the news hit hard!

Yet, just a few weeks ago, a twist arrived: the tech platform Tekpon acquired 100% of TNW’s media and events brand from the Financial Times, ensuring that this nearly two-decade legacy will continue to thrive.

While, myself, trying to read people’s opinions on this topic, I read this comment in one article, from one former TNW editor-in-chief that said: “The Next Web shaped my career, my life… it’s very sad to see it die”.

The latest rumblings from the EU tech scene, a story from our wise ol&#39; founder Boris, and some questionable AI art. It&#39;s free, every week, in your inbox. Sign up now!

I asked myself: Why do we always assume that just because one chapter ends, the whole story is over? Yes, taking over TNW is a heavy inheritance, especially with all eyes on us and expectations sky-high.

And I’ll admit, doubts crept in: Am I too small for this? Could someone more experienced do it better? Probably. But here I am, stepping up regardless. Because this isn’t just another blog or brand; TNW is a living ecosystem, a vital community. Its story deserves to continue, and I’m determined to help write the next chapter.

I also know some of you might be wondering: Who is she? What does she know? How many articles has she written? What recommends her?

Before reading all sorts of titles and, let me briefly introduce myself.

I’ve been writing since high school, with thousands of articles under my belt; covering everything from culture, art, and hip hop to design, politics, history, and food. I landed my first content writer job at 18, and alongside writing I pursued another passion: becoming a chef.

(Fun fact: I even made it to the semifinals of MasterChef, a journey that taught me about creativity under pressure and staying cool when the heat is on.)

Now, I channel my storytelling skills into helping businesses better understand technology and use it to their advantage. I help companies tell their stories, the real ones, finding meaning and flow in every word.

Over the years, I’ve specialized in blending creative storytelling with the technical precision of a chef’s knife. (My colleagues at Tekpon might say I can be as sharp as that knife – true to my values and quick to cut through the nonsense.) I am also the “No, we have to do it right” person in the team.

I’ve reviewed countless software products, interviewed founders, and explored how digital innovation can be a force for good in society. Or not. In other words, I’ve always cared about the why behind the tech, the real impact on people’s lives, not just the buzz. That perspective will be behind every story we will publish at TNW.

If there’s a place for those who still think stories written by humans matter, tell me where it is. I’m already on my way.

I’m not here to change TNW’s DNA; I’m here to reinforce it with fresh energy and a clear vision for the future.

To the loyal TNW readers, to the startup founders who looked to us for inspiration, to the healthy tech skeptics who counted on us for a reality check, and to our global audience spread across continents: we hear you.

We all know the world of tech news has changed dramatically. Today, everyone has a megaphone, social media overflows with hot takes, and AI algorithms can crank out content in seconds. It’s easy to feel overwhelmed by this sea of opinions and auto-generated articles. In such a world, the role of a publication like TNW is more critical than ever: to be a filter, not just another firehose of content.

We will focus on curation and clarity, distilling the noise so you don’t have to.

Here’s the good news: despite the deluge of AI-written text out there, readers are actively looking for authentic, human journalism. Every article we will publish will be created by a human writer who is accountable for the facts and who brings context, analysis, and yes, a bit of personality too.

Our mission isn’t to chase every trending headline algorithmically; it’s to help you understand which innovations actually matter, and why.

If a story is everywhere but lacks substance, we won’t regurgitate it; we’ll analyze it or debunk it. If a breakthrough is genuinely promising, we’ll explain why it’s important and how it impacts real people. Being a thoughtful filter in this age of information overload (and AI-generated noise) isn’t just a catchy slogan for us; it’s a responsibility we embrace.

You’ll also notice something different in our approach: an emphasis on storytelling and the human side of tech. Technology doesn’t exist in a vacuum; it’s built and used by people with dreams, dilemmas, and diverse backgrounds.

I believe, and I suspect many of you do too, that the best tech journalism zooms out from the gadgets and code to highlight those human stories. Practically speaking, expect to see more features, interviews, and narrative-driven pieces on TNW.

We’ll talk to founders about the messy, human journey of building a startup, not just the press releases or funding announcements. We’ll spotlight the engineers, designers, and thinkers who are trying to solve big problems (or even small ones that make a big difference). We’ll explore tech’s impact on society: the good, the bad, and the complicated.

This won’t be a place for recycled press releases or surface-level takes. It will be a place for conversation and insight.

Importantly, none of this focus on storytelling means we’ll skimp on rigor. Being engaging doesn’t mean sacrificing accuracy or depth. My team will continue to prioritize thorough research and fact-checking, those good old-school journalism values, even as we experiment with new formats and new voices. In short, we won’t publish anything we wouldn’t want to read ourselves.

Today, looking forward means acknowledging that how we cover tech is as important as what we cover. It means committing to journalism that cuts through the clutter, to storytelling that puts people first, and to a vision of tech’s future that is both hopeful and honest. That’s my vision for TNW as I step into this role, and I hope it resonates with you.

Now, I’d like to turn it over to you, our community. This is your TNW as much as it is ours. I invite you to join the conversation. Tell us what you want to see more of (or less of). Hold us accountable,if we ever fall short, let us know. Share your stories and perspectives with us, because they can inspire our coverage.

In the coming weeks, you’ll start to see this vision take shape on the site. You’ll see familiar faces and new voices. You’ll find articles that make you think, others that make you smile, and hopefully quite a few that make you proud to be a TNW reader.

Whether you’re a long-time follower who’s stuck with us through thick and thin, a startup founder looking for insight, a skeptic keeping us honest, or a curious mind tuning in from anywhere in the world – thank you. We do this for you, and we couldn’t do it without you.

The Next Web is back. We’re here to inform you, inspire you, challenge you, and occasionally even surprise you. I’m honored to have you with us on this journey. Here’s to the road ahead, to storytelling, to journalism (the real kind), and to making sense of the future together.

Thank you for reading, and welcome to TNW’s next chapter. Let’s build it, day by day, story by story, together.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-63')">
            <div class="source">The Next Web</div>
            <div class="title">Is ChatGPT’s New Shopping Research Solving a Problem, or Creating One?</div>
            <div class="meta">2025-12-11</div>
        </div>
        
        <div id="content-63" style="display:none;">
            <h2>Is ChatGPT’s New Shopping Research Solving a Problem, or Creating One?</h2>
            <p><strong>The Next Web | 2025-12-11</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/is-chatgpts-new-shopping-research-solving-a-problem-or-creating-one">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">When OpenAI announced its new shopping search capabilities, I took the news with a grain of salt (perhaps the whole shaker).
For the past decade, we have watched the slow evolution of traditional search engines. What began as tools for pure information discovery gradually morphed into ecosystems dominated by SEO-optimized content and sponsored results. My initial fear with ChatGPT’s update was simple: Are we seeing the beginning of a similar shift? Is the purity of the “reasoning engine” being diluted by the necessity of commerce?
After testing the new shopping integration, the results suggest that we are at a pivotal moment in the user experience of Generative AI, one that requires an open discussion about what we actually want these tools to be.

The defining characteristic of Large Language Models (LLMs) is their ability to handle nuance. When we interact with ChatGPT, we expect a Socratic dialogue. We expect the AI to ask clarifying questions to narrow down our intent.
To test this, I entered a simple prompt: “I want to buy a vacuum.”
I anticipated a conversation, questions about my home’s square footage, my floor type, or my budget. Instead, the conversational nuance was replaced by a display that felt familiar: a grid of product photos, names, prices, and direct links to retailers.

While efficient, this experience felt like a regression. It mirrored the “keyword search” experience of Web 2.0 rather than the “intent-based” promise of GenAI. It replied to my prompt, but it stripped away the intelligence.

The latest rumblings from the EU tech scene, a story from our wise ol&#39; founder Boris, and some questionable AI art. It&#39;s free, every week, in your inbox. Sign up now!

Scrolling down, I engaged with the new feature in a call to action: “Research the best vacuums.”
This is where the user experience (UX) friction became most apparent. Rather than synthesizing data or comparing technical specifications in a chat format, the tool presented a polling interface designed to filter results.

The experience is oddly time-sensitive; pause too long to think or drink water, and the screens will skip forward, dumping you back into a list of product cards.
The interface presents products with a binary choice: “More like this” or “Not interested.” It offers brand names and price tags, but virtually no information to help the user actually make a choice.

For a user seeking genuine research, being presented with a list of brands and prices without deep comparative analysis feels like a missed opportunity.
It raises a question: If I wanted to filter products by price and brand, wouldn’t I use a traditional retailer? The value proposition of Gen AI should be synthesis, not just aggregation.

The Tension Between Reasoning and Revenue
This update highlights the inevitable tension facing major AI companies: the balance between user utility and business sustainability.
As OpenAI scales, the pressure to demonstrate revenue models to investors is natural. However, there is a risk in prioritizing transactional features before the core product, reasoning and logic, is fully matured. By introducing a shopping experience that feels closer to a “click-through” engine than a “knowledge” engine, the platform risks blurring its own identity.
Is ChatGPT a research partner that helps me think? Or is it a shopping assistant trying to speed me to checkout?

To be clear, I believe there is a place for shopping within AI. But the execution matters.
A truly Generative AI shopping experience shouldn’t just list products; it should understand the user. It should read between the lines of a prompt to understand that a user asking for a vacuum might actually be solving a problem about pet hair or allergies.

The current iteration feels like a beta test of a business model rather than an evolution of intelligence. As we move forward, the hope is that OpenAI will refine this tool to prioritize the “Chat” over the transaction. We don’t want it to be just another place to see ads. We need a better way to make decisions.

Viviane Mendes is a growth strategist and innovation leader with more than 20 years of experience driving technology-enabled transformation across global markets. She has led initiatives integrating AI-driven strategies, digital transformation, and scalable business innovation for companies such as PSINet, MP3.com, Match.com, UOL and Best Buy Canada, and founded Vitrinepix, one of the first print-on-demand e-commerce platform, later acquired by Spreadshirt. Committed to lifelong learning, Viviane is now focusing on applying emerging technologies to foster digital literacy, responsible AI adoption, and positive human impact.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-64')">
            <div class="source">The Next Web</div>
            <div class="title">Tekpon acquires TNW (The Next Web) brand from The Financial Times</div>
            <div class="meta">2025-12-08</div>
        </div>
        
        <div id="content-64" style="display:none;">
            <h2>Tekpon acquires TNW (The Next Web) brand from The Financial Times</h2>
            <p><strong>The Next Web | 2025-12-08</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/tekpon-acquires-tnw-the-next-web-brand-from-the-financial-times">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Tekpon has acquired 100% of the TNW media and events brands, which cover and convene the European technology ecosystem, from the FT.

The transaction is Tekpon’s largest investment in media and events so far. It broadens the company’s reach across SaaS and AI and strengthens its role in the global innovation landscape.

TNW’s brand and editorial standards will be maintained, while its events and digital platforms will be integrated into Tekpon’s wider strategy.

The FT will continue to own and operate TNW Spaces, Amsterdam’s dynamic tech hub, offering private offices and coworking spaces that support a thriving community of startups, scale-ups, and innovators.

TNW City Coworking space - Where your best work happens

A workspace designed for growth, collaboration, and endless networking opportunities in the heart of tech.

Alexandru Stan, Founder and CEO of Tekpon, said:

TNW is one of Europe’s most respected technology brands. Its legacy, its community, and its influence have shaped the European tech scene for nearly twenty years. This acquisition accelerates our mission to connect the global SaaS and AI ecosystem and supports Europe’s position in the next decade of innovation.

Tekpon will begin working on TNW branded initiatives immediately. Plans for 2026 include an expanded TNW Conference, new SaaS and AI program tracks curated by Tekpon, cross-regional executive programmes, and specialised gatherings for founders, executives, and investors.

The acquisition is part of Tekpon’s long-term plan to build an international ecosystem connecting software, media, events, advisory, and innovation.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-65')">
            <div class="source">The Next Web</div>
            <div class="title">Ending graciously</div>
            <div class="meta">2025-09-29</div>
        </div>
        
        <div id="content-65" style="display:none;">
            <h2>Ending graciously</h2>
            <p><strong>The Next Web | 2025-09-29</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/tnw-boris-signs-out">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">This article was published on September 29, 2025

A few decades ago, when I was raising funding for a startup, I made a lasting impression on an investor by not only talking about how successful we would be, but also highlighting what would happen if we weren’t. Later, in an informal setting, I asked him what had persuaded him to invest in us. He told me that during the pitch, I had said, “And if all our predictions and expectations are wrong, we will use the last of our funding for a magnificent farewell dinner for all our investors. You’ll have lost your money, but at least you’ll get a great evening for it in return.”

I don’t recall this being part of the original pitch or my strategy. I probably just blurted it out to break the ice, but it impressed the investor. He told me it was refreshing to speak to an entrepreneur who was not blinded by his own pitch. The fact that I had a scenario ready for both success and failure told him that I was honest and realistic.

Now, the startup was not successful, but we still had a nice, opulent dinner with the investors at the end — and we did them one better. As soon as we realised that our predictions and expectations were wrong, we made our investors an offer: we could struggle and pivot and hope for a miracle, or we could return what was left of our funding to our investors. We preferred option two, and so did they, so everybody got some money back (about 40% of what they had invested), as well as a lovely evening with excellent food and drinks. When we raised money for another startup a few years later, almost all of them signed up in our first round.

Obviously, I would have preferred to have made this startup a success instead, but I still regard it as a successful endeavour. I gave it a try and had a plan ready for when my experiment didn’t work out, and in the process, I built relationships that outlasted that one startup.

The latest rumblings from the EU tech scene, a story from our wise ol&#39; founder Boris, and some questionable AI art. It&#39;s free, every week, in your inbox. Sign up now!

As you may have read, The Next Web, the company I founded in 2006, is nearing the end of its lifecycle. The events and media business is being wound down, and only TNW Spaces will live on. TNW Programs was sold off a while ago and will continue as well. There won’t be another TNW Conference, and soon there won’t be new articles on the site; people are losing their jobs, including me. It’s a painful process, but I guess I’m taking it well because it also feels natural and logical. When we sold TNW to the FT in 2019, we were very ambitious and optimistic, and surely I would’ve liked for the company and brand to outlive me. However, when the business struggled, I also felt very comfortable with the company ending graciously.

When you’re reading a good book, there’s a moment near the end when you’ll start reading slower because you don’t want it to end. I love those moments, because I’ll know it’s been a good experience. But then you also know that good stories need good endings. So, this is the ending of a great story that I’ve enjoyed participating in.

I’ll keep writing, but this will be my last official TNW story. I’d love it if you would subscribe to my writing over at Substack. It will be less tech-focused, more unpredictable, but just as insightful as before.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-66')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">China hits US defence firms with sanctions over arms sales to Taiwan - Reuters</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-66" style="display:none;">
            <h2>China hits US defence firms with sanctions over arms sales to Taiwan - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2025-12-26</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiygFBVV95cUxNS1F2bGF6VlRLWS16dUpRNzEtRVl6RzJTMFlBRk0taEFFbXZyQkhSd3YzRWtBUk9Bb0o2MW42anpVVlFMWThCTWo3LWxIeHBTN1lqWmZHUlZBV05zc1NvRHVtdnRBMzF3VmZPZ3NuWVhKWlRlb2lQWFFqdi1TUURjZi1lUW5LYVFNb1owTTFhcDd1Y250NmtzUGc4V0o0aU9wRUd6cWtBMm81Nm1rV0M0bS1GY3RsR1RNcXlQUGM1aDNRZnRhVG1PZF9R?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-67')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">Putin indicated Russia could be open to territory swap as part of Ukraine deal, Kommersant says - Reuters</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-67" style="display:none;">
            <h2>Putin indicated Russia could be open to territory swap as part of Ukraine deal, Kommersant says - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2025-12-26</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiyAFBVV95cUxNa1prS2tYRFlUaDVJOEIxdlJRYkl1VVJHWkttV3duZ0htSTNXcHNGOGRIVHdkT3JhSkZKRE8wcFFDaEFaME1OQlZsTHBWWklESFYxMEdORUJyNDBLSnkzaXdiVURNQ0dsajBUaHhhMWhqUlF4Q0FkdFRPc3g2N2hCLTNaT09QajdLUXlXdTFkeXYtYnJxT3owU2FudVh0UzNSZ3k2N005MUdSUVJsTTAzT3dIRFhjbkFUSXVjSjNtNDc2czc2UEdwdA?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-68')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">Trump to meet Ukraine's Zelenskiy at Mar-a-Lago on Sunday, Axios reports - Reuters</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-68" style="display:none;">
            <h2>Trump to meet Ukraine's Zelenskiy at Mar-a-Lago on Sunday, Axios reports - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2025-12-26</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMirwFBVV95cUxPcnpVcXc5N1gyUEhZcUEwZDZiYUYzUE1fMXFGSmZiWDl0ay1PSzM1STVkQUhqY1ZDNl81WGVtdHdrNWJxc2FIWUZCdzJBQzdMMXFRZ1RCTUtBdFhhMlI1SlBpSTZHVy1lcHMtbFZnWkIwV01wSnRseVFxOEVsejFGMll5M0dNd05yS2tXSlFYX1Z3OGNaMmFTRXEzWEJPdXdJdWpSd0xZTm9BSFB4M0FB?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-69')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">Russian drones damage foreign-flagged vessels in southern ports, Ukraine says - Reuters</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-69" style="display:none;">
            <h2>Russian drones damage foreign-flagged vessels in southern ports, Ukraine says - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2025-12-26</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMixwFBVV95cUxPbmlWQ2tiTGFZYlNTSHZPR01NTUF6ZGNVVlNuTVJRLWh5QUtXT0FLa014LXJFbUNGVWFuNkdHYWRMNHl1MExsbk9aVTFmLU5XVDEtNXJ4U09MZmJhcjFhaXNPLXYyNjhXZmMyeDFtS3JsZ3NveC1aMTVBR1hsV1hxNUZsYzJFaWlMS0R0Ri02NWsxSUlCRWwzX1AyZmF3YkMwSFZRX0RnMUplWlo2WFNURVhCTWZ4S1Jvc3dqSm5rOUNOMUNvQVZV?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-70')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">Iran says foreign tanker carrying smuggled fuel seized in Gulf - Reuters</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-70" style="display:none;">
            <h2>Iran says foreign tanker carrying smuggled fuel seized in Gulf - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2025-12-26</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiswFBVV95cUxNR2NRR3l1Z2RSejJ0cjBXcVhNVzlNR1I4bmtvWjNKRWVtMndNLUo3aU83eUhyS0l3WXVtZjQzUmpvWVYyeW15d1RXQndFbmhjYm8zRklLOHpoLWY2ZkxPMERRanZzMzN3c1puUFJGa1o0dFhuemg2Z1pxUUNSZ1RZb3VHa2tRRVAyWi12VlB2cVZVczdqTXIxSHhfalI5ZEtGSS1jTDRsNldqaGFiUkZQOGc3dw?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-71')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">Turkey says Russia gave it $9 billion in new financing for Akkuyu nuclear plant - Reuters</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-71" style="display:none;">
            <h2>Turkey says Russia gave it $9 billion in new financing for Akkuyu nuclear plant - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2025-12-26</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiwAFBVV95cUxQV0ZIOFdqV0VydzVtR1JWOHJOTnJYc1I1a3BCYkN6YS1aTjg3R05OS05UT0E2T05QTWtZQjVZcURfNXMzRHFNX283Yzg0NWNGUG1iYk1NRFZkWmZvQUFNekEycjJyMTFYc0doTjl3R3FJTnBFUXBqdHBJeXVmLXpCYkEzN1BISVk2Y09LaVo2OTJ5WDBYUmE4Y3o1aWVVWW9Ud2drMGMtb3Y5ZlRIZ3g4Zkd0UXlaajZFQTZUU3E1eHY?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-72')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">“Cosmics” and “Phantoms”: Ukrainian Independent Study Reveals Observations of Unidentified Aerial Phenomena - The Debrief</div>
            <div class="meta">2022-08-26</div>
        </div>
        
        <div id="content-72" style="display:none;">
            <h2>“Cosmics” and “Phantoms”: Ukrainian Independent Study Reveals Observations of Unidentified Aerial Phenomena - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2022-08-26</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMixAFBVV95cUxOWWZHN3JWVE42ZlI4eTRKUnVIX0h0MlAwM25SMFExVlRGVThjNVdicEF3dnNHUXd2VjBGTU5fVE5SUnBTU2hKNUk2MmNjaXVzZnhKTFZDeEp3elV0RGRsVnk3cHdCbDZySld1eFNqOEoyQVh0YU81cXJOeTRSZ3MxZ281RHlTdE1SR2JKOXVMYXFGZm5EX3lVZ2tsaEo1bEYxTU5pWmVYSlJlMjl3S1hxRG1BLW9qRGJSaTItbXl3MDlWVUZT?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-73')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">“No Longer a Futuristic Concept”: Scientists Build Real-World Magnetic Cloaking Device Capable of Shielding Complex Shapes - The Debrief</div>
            <div class="meta">2025-12-22</div>
        </div>
        
        <div id="content-73" style="display:none;">
            <h2>“No Longer a Futuristic Concept”: Scientists Build Real-World Magnetic Cloaking Device Capable of Shielding Complex Shapes - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2025-12-22</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMi2wFBVV95cUxQTVlmWjE0Wk9WemxzQmhCM18tVmt6Qkd1cEREazlMQUFiLUlYQkxqYUxDSmR5T2VaMFh1LXoyNnRPRmdwNE9qZndYV2NaRzBQa2Zpcjc2bnRRSWdMYWpCYzkyekx1ZURuTWdRV0o3ZXRRN3VNVllmcWluZnc4WDFUTE42TGt6RGxKTGxUVFppXzM4bVR0Y1lPQkl4U3ZvUTdGT3RzRzlEUnVtMkJQNEotdEdsanJ0MGlqM0thc1BkVldjakFIdnZVUV9QRml6VS1BTHVwNjh1cGMtTWc?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-74')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">Ancient Pottery Shows Humans Were Doing Math 3,000 Years Before Numbers Existed - The Debrief</div>
            <div class="meta">2025-12-20</div>
        </div>
        
        <div id="content-74" style="display:none;">
            <h2>Ancient Pottery Shows Humans Were Doing Math 3,000 Years Before Numbers Existed - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2025-12-20</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMipAFBVV95cUxPYmVKVmd6TVphcGliQlZhNzYyRDViM1oxSFhZY0xOM3BjMHVwSW5KQmxVcXBfMTBqXy0wRGh2eW5yeFg0NjNsTFFuOVktZ1UtV3dvaWx6Z0pjaEYzUk9yTzZ1T2dFbnBwVEI4NEhLeHpZLUZ0ZTZkbVFTc3VscEsxM1g4ckFFOGItQlZRU0ZVNWppWWtEaHlTUzRtdWFDcnVpOEx2Tg?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-75')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">Are AI Systems Truly Conscious? This Researcher Says Humanity May Never Know—and Explains Why That Matters - The Debrief</div>
            <div class="meta">2025-12-22</div>
        </div>
        
        <div id="content-75" style="display:none;">
            <h2>Are AI Systems Truly Conscious? This Researcher Says Humanity May Never Know—and Explains Why That Matters - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2025-12-22</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiyAFBVV95cUxQcjItSnRGRXM4djZsaHQtbDlSMGVhUmM2R0FsdEJPd2h2eXRBZGZDekk2aThzOGdFLWhTSk5WeTVNQ2pIOEV1QnJHYXl4TE1hLWx4YzFCRDduaXEtWWxlWDczUzhsVktXRWhkWEdSYzdJeVA4Y29UOUloU0huU09JMWJ0X05RYVdZaU5BTnBGTGgzN2NhVnVlQ09aM2c2bXlJRFFYV3dERWhvQmtuMXBGNzBTSEhTQXFDQ2ZVVjBpMlZOWGIzaFJJbg?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-76')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">A New Theory Suggests Mass May Emerge From Invisible Dimensions - The Debrief</div>
            <div class="meta">2025-12-23</div>
        </div>
        
        <div id="content-76" style="display:none;">
            <h2>A New Theory Suggests Mass May Emerge From Invisible Dimensions - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2025-12-23</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMikAFBVV95cUxPTFNSQWZDVm5jTkRTaTNMb3p2Y2dGcnZ5bHFnRHhDcGZHT3M0VzZWZzcyNEpiZ284QUowZjhaYkFwTU8zRHdLSUlCY0ZXd2NpRnRDZ2JwOFBQNi1oWHZsZzBoM25iak5rTlhMc0wxSmhXbUh3NmdIQ2FRd2I0blVHamVJckY1V2NCbWVnMjRScXg?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-77')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">Scientists Suddenly Can't Explain How Stellar Winds Spread the Seeds of Life Throughout the Cosmos - The Debrief</div>
            <div class="meta">2025-12-23</div>
        </div>
        
        <div id="content-77" style="display:none;">
            <h2>Scientists Suddenly Can't Explain How Stellar Winds Spread the Seeds of Life Throughout the Cosmos - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2025-12-23</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMivgFBVV95cUxQaC16QmtUS2hZT1hTZ1ZIc1dnY2Y3VmdwUUNMb2JoZEZ0ZGhZSWcwX1dEdjRlcExlcTViM2JLWXdsYUhMNEtzR204YWtCM0JPd21zS0hoelJaZHZZSThNbENGTFBaaExUUVNRSWRtODc1QVJuRXVNYlZfUHY3ZzN4c2tqbkhIc3daNjRJRTc2WkdlSnBfVjR3ejZTS0xLRjZza1VUY1BubXVzRmxEQV9YNVptVWF1aUdiLUVfOWVR?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-78')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">Why Nvidia Struck a $20 Billion Megadeal with Groq - The Information</div>
            <div class="meta">2025-12-25</div>
        </div>
        
        <div id="content-78" style="display:none;">
            <h2>Why Nvidia Struck a $20 Billion Megadeal with Groq - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2025-12-25</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMihAFBVV95cUxNMmtUdTFFRXVvek02bGI2T1RnQzZhaHc1ejF6LVdzcWZfb0FhRG9mMDZHcW9BTERpRHZnaW5tblFuUFZDbUZTOERNbTYyV29QZEoyNEtoS0xobGhtZndvTlcxMEpoWm1VLVZ0enZhY0NLTDk5OFFjRVI1T21iYW9xY010alA?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-79')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">OpenAI’s Ads Push Starts Taking Shape - The Information</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-79" style="display:none;">
            <h2>OpenAI’s Ads Push Starts Taking Shape - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2025-12-24</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiggFBVV95cUxNUE1HZHAzd1d4ZDhIU1JLdW44Rjg0QUJMN3U4TGdQRzBpckZsV0k3cEpWcnZ6V3B2VzRncG1DY2FPZFVDQXlPSDZXSnNsSk5kenk3Wl9tTDFzODBBSllVMkF1V0RqaS1aMVhmTmI4azVpQzhaSjFQUmlTZ0tRWGhadDlR?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-80')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">Snowflake in Talks to Buy App Monitoring Startup Observe Inc. For Around $1 Billion - The Information</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-80" style="display:none;">
            <h2>Snowflake in Talks to Buy App Monitoring Startup Observe Inc. For Around $1 Billion - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2025-12-24</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMisAFBVV95cUxQTWtkeDVvRG90Mlp4QXIwQk5OaW1KbEJZa3I4TExhUFFoeGE3eFIzSWNtb0x1OUpwVWlHUzNOTmpmSE1ZOTZIRWk1dXNZU2NVLVAyTHpjUjRhQlU1ejhka2pUdHFDODlOOEg2TTJTSU55VTd3NXdPbTZDV1ltU2JkbXV3SU5EaEVMblRFYUg1UC1FckZQSWlsalp0WWlUU2V3X2pUczBJM3NhWGF0b05jTw?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-81')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">Nvidia Restructures Cloud Team After Retreating From AWS Competition - The Information</div>
            <div class="meta">2025-12-22</div>
        </div>
        
        <div id="content-81" style="display:none;">
            <h2>Nvidia Restructures Cloud Team After Retreating From AWS Competition - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2025-12-22</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMingFBVV95cUxNMm04Y3F4SW1rMFBQdGpaRk1tNFAyVExINXJyZ0JXUE85ZmJoLXgzWVZrNEttOUs5akRCT0hBSVRfclZQWGo4TFlUZW5uc1RTV1ZXc1h6R3I4SWpvdldKMWR1M0dkWXJFTnd5TmZKNXpOelBrWDFLdEtaVVpVRTBHOTlobFlfMXlxYXZwd1lEN21yNWh3dE5taUcxZmJwZw?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-82')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">How OpenAI’s Organizational Problems Hurt ChatGPT - The Information</div>
            <div class="meta">2025-12-18</div>
        </div>
        
        <div id="content-82" style="display:none;">
            <h2>How OpenAI’s Organizational Problems Hurt ChatGPT - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2025-12-18</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMijAFBVV95cUxQUEZrWnU1LUdoRDBZd1J4Q1VyUldPVE1fY3ZQQl9sQk9qT1dYSWdSQXhId0o4eWs2Qmx2VGRDVGdxNjB4NTlfLUNnUGdQLWR2elRsSWFpQ1F2NHRwRWZZVngzSTZGeVM4UjV5X3ppU01WMVlZWVQ2SlM1bFJWTTd6eUVhcnRfQXoxU3d5aQ?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-83')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">Why Data Centers Are Falling Behind Schedule; Jensen Huang’s Power Summit - The Information</div>
            <div class="meta">2025-12-22</div>
        </div>
        
        <div id="content-83" style="display:none;">
            <h2>Why Data Centers Are Falling Behind Schedule; Jensen Huang’s Power Summit - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2025-12-22</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMipgFBVV95cUxQdEw4ZWtGRzVvTzJUUGlmS3VzMlU2VnpqR2RpNW8wOG1IUnVYeTFwbnU5ejBrdGJxcFYtNm12QnJYdExtZ2Z6OG1HbzMyaEFiMHhOSU9PM3pKMk9ZV3BJNkh4WW1kSnBzWWw3YjNpMGoyQl80Z1FXMVMxVWExZFFZMXBkRDU2cUoxRVdONmZxV3RZUUQ3MU44M2dZTTEzQjJ4UWdESFRn?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        </div>

        <div id="reader-modal">
            <div id="close-btn" class="control-btn" onclick="closeModal()">X</div>
            
            <div id="scroll-controls">
                <button class="scroll-btn" onclick="scrollPage(-1)">&#9650;</button> <button class="scroll-btn" onclick="scrollPage(1)">&#9660;</button>  </div>

            <div id="modal-inner"></div>
        </div>

        <script>
            // 1. RANDOMIZE ORDER
            const list = document.getElementById('feed-list');
            const cards = Array.from(document.querySelectorAll('.card'));
            cards.sort(() => Math.random() - 0.5);
            cards.forEach(card => list.appendChild(card));

            // 2. DARK MODE
            const btn = document.getElementById('theme-toggle');
            btn.addEventListener('click', () => document.body.classList.toggle('dark-mode'));

            // 3. MODAL & SCROLL LOGIC
            const modal = document.getElementById('reader-modal');
            const modalInner = document.getElementById('modal-inner');

            function openModal(contentId) {
                const content = document.getElementById(contentId).innerHTML;
                modalInner.innerHTML = content;
                modal.style.display = 'block';
                document.body.style.overflow = 'hidden'; 
            }

            function closeModal() {
                modal.style.display = 'none';
                document.body.style.overflow = 'auto';
            }

            function scrollPage(direction) {
                // Scroll by 80% of the screen height to keep context
                const scrollAmount = window.innerHeight * 0.8;
                modal.scrollBy(0, direction * scrollAmount);
            }
        </script>
    </body>
    </html>
    