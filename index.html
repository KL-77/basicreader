
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>KL-77's Feed</title>
        <style>
            :root {
                --bg: #ffffff;
                --text: #000000;
                --border: #000000;
                --modal-bg: #ffffff;
                --dim: #666666;
            }
            
            body.dark-mode {
                --bg: #000000;
                --text: #ffffff;
                --border: #ffffff;
                --modal-bg: #000000;
                --dim: #aaaaaa;
            }

            body { 
                font-family: Georgia, serif; 
                background-color: var(--bg);
                color: var(--text);
                margin: 0;
                padding: 10px;
                font-size: 22px;
                line-height: 1.5;
            }

            header {
                display: flex;
                justify-content: space-between;
                align-items: center;
                border-bottom: 3px solid var(--text);
                padding-bottom: 15px;
                margin-bottom: 25px;
            }
            
            h1 { margin: 0; font-size: 1.2em; }

            button#theme-toggle {
                background: transparent;
                color: var(--text);
                border: 2px solid var(--text);
                padding: 10px;
                font-size: 18px;
                font-weight: bold;
                border-radius: 4px;
                cursor: pointer;
            }

            .card {
                border: 2px solid var(--text);
                margin-bottom: 25px;
                padding: 15px;
                cursor: pointer;
            }
            
            .source { font-size: 0.7em; font-weight: bold; text-transform: uppercase; color: var(--dim); }
            .title { font-size: 1.1em; font-weight: bold; margin: 8px 0; display:block; }
            .meta { font-size: 0.7em; color: var(--dim); }

            /* MODAL STYLING */
            #reader-modal {
                display: none;
                position: fixed;
                top: 0; left: 0;
                width: 100%; height: 100%;
                background-color: var(--modal-bg);
                z-index: 1000;
                overflow-y: scroll; /* Allow scrolling */
                scroll-behavior: auto; /* Instant scrolling for e-ink */
            }

            #modal-inner {
                padding: 25px;
                max-width: 800px;
                margin: 0 auto;
                padding-top: 80px; 
                padding-bottom: 150px; /* Huge padding so text clears the buttons */
            }

            /* Controls (Close + Scroll) */
            .control-btn {
                position: fixed;
                background: var(--bg);
                color: var(--text);
                border: 3px solid var(--text);
                border-radius: 8px;
                font-weight: bold;
                cursor: pointer;
                z-index: 1001;
                display: flex;
                align-items: center;
                justify-content: center;
            }

            #close-btn {
                top: 15px; right: 15px;
                width: 60px; height: 60px;
                font-size: 30px;
                line-height: 55px;
            }

            /* Scroll Buttons */
            #scroll-controls {
                position: fixed;
                bottom: 20px;
                right: 20px;
                display: flex;
                flex-direction: column;
                gap: 15px;
                z-index: 1002;
            }

            .scroll-btn {
                width: 60px;
                height: 60px;
                font-size: 24px;
                background: var(--bg);
                color: var(--text);
                border: 3px solid var(--text);
                border-radius: 8px;
                cursor: pointer;
            }

            #article-text { white-space: pre-wrap; font-size: 1.1em; }
            
            a.original-link {
                display: inline-block;
                margin-bottom: 30px; /* Space before text starts */
                padding: 10px;
                border: 1px solid var(--text);
                color: var(--text);
                text-decoration: none;
                font-weight: bold;
                font-size: 0.8em;
            }
        </style>
    </head>
    <body>

        <header>
            <h1>KL-77's Feed</h1>
            <button id="theme-toggle">Light/Dark</button>
        </header>

        <div id="feed-list">
    
        <div class="card" onclick="openModal('content-0')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">NASA’s science budget won’t be a train wreck after all</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-0" style="display:none;">
            <h2>NASA’s science budget won’t be a train wreck after all</h2>
            <p><strong>Ars Technica - All content | 2026-01-05</strong></p>
            <a class="original-link" href="https://arstechnica.com/space/2026/01/nasas-science-budget-wont-be-a-train-wreck-after-all/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">In June, the White House released a budget proposal for fiscal year 2026 that slashed funding for NASA’s science programs by nearly 50 percent. Then, in July, the Trump administration began telling the leaders of dozens of space science missions to prepare “closeout” plans for their spacecraft.

Things looked pretty grim for a while, but then Congress stepped in. Congress, of course, sets the federal government’s budget. In many ways, Congress abdicated authority to the Trump administration last year. But not so, it turns out, with federal spending.

Throughout the summer and fall, as the White House and Congress wrangled over various issues, lawmakers made it clear they intended to fund most of NASA’s science portfolio. Preliminary efforts to shut down active missions were put on hold.

On Monday, Congress made good on those promises, releasing a $24.4 billion budget plan for NASA as part of the conferencing process, when House and Senate lawmakers convene to hammer out a final budget. The result is a budget that calls for just a 1 percent cut in NASA’s science funding, to $7.25 billion, for fiscal year 2026.

“This is, frankly, better than I could have expected,” said Casey Dreier, chief of space policy for The Planetary Society, which argued against the cuts. “There’s very little to not like in this.”

The new budget will not undo the significant cuts to NASA’s workforce through a voluntary buyout program in 2025, or other efforts by the Trump administration and the Department of Government Efficiency to reduce headcounts across the federal government.

Dreier also lamented the many wasted hours spent planning by scientists and engineers to comply with the Trump White House’s budget proposal.

“Those hours could have been spent running and analyzing data from these valuable missions,” Dreier said. “It created a lot of needless friction and churn at a time when NASA is being told it must remain competitive with China and other nations in space.”

The House of Representatives could vote on the budget bill for Commerce, Justice, Science, and Related Agencies as soon as this week, with the US Senate possibly following next week. It is expected that President Trump will sign the bill. It would then go into effect immediately for the current fiscal year, which began on October 1.

The biggest casualty in the NASA science budget is the Mars Sample Return mission, a NASA-led effort to return Martian rocks and soil for study in Earth-based laboratories.

“As proposed in the budget, the agreement does not support the existing Mars Sample Return (MSR) program,” the budget document states. “However, the technological capabilities being developed in the MSR program are not only critical to the success of future science missions but also to human exploration of the Moon and Mars.”

Although it offers no details, the budget provides $110 million for something called the “Mars Future Missions” program to support “radar, spectroscopy, entry, descent, and landing systems.”

NASA previously said it was pausing the ambitious sample return mission because its projected cost was approximately $10 billion, with no certain return date for the samples.

Now it seems likely that the agency and its new administrator, Jared Isaacman, will have to develop a new strategy. This may include sending humans to Mars, rather than bringing Martian rocks back to Earth.

Unlike the Trump budget request, the science budget also keeps future missions, such as the DAVINCI probe for Venus, alive. It also provides $10 million to continue studying the development of a Uranus orbiter, as well as $150 million for a flagship telescope to search for signs of life on nearby, Earth-like planets called the Habitable Worlds Observatory.</div>
        </div>
        
        <div class="card" onclick="openModal('content-1')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">Under anti-vaccine RFK Jr., CDC slashes childhood vaccine schedule</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-1" style="display:none;">
            <h2>Under anti-vaccine RFK Jr., CDC slashes childhood vaccine schedule</h2>
            <p><strong>Ars Technica - All content | 2026-01-05</strong></p>
            <a class="original-link" href="https://arstechnica.com/health/2026/01/under-anti-vaccine-rfk-jr-cdc-slashes-childhood-vaccine-schedule/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Under anti-vaccine Health Secretary Robert F. Kennedy Jr., federal health officials on Monday announced a sweeping and unprecedented overhaul of federal vaccine recommendations, abruptly paring down recommended immunizations for children from 17 to 11.

Officials claimed the rationale for the change was to align US vaccine recommendations more closely with those of other high-income countries, namely Denmark, a small, far less diverse country of around 6 million people (smaller than the population of New York City) that has universal health care. The officials also claim the change is necessary to address the decline in public trust in vaccinations, which has been driven by anti-vaccine activists, including Kennedy.

“This decision protects children, respects families, and rebuilds trust in public health,” Kennedy said in a statement.

Health experts disagree. “Kennedy’s decision will harm and kill children, like all of his anti-vaccination decisions will,” virologist James Alwine, who works with the organization Defend Public Health, said in a statement.

The American Academy of Pediatrics, a vocal critic of Kennedy, blasted the changes, saying “to arbitrarily stop recommending numerous routine childhood immunizations is dangerous and unnecessary,” AAP President Andrew Racine said. “The United States is not Denmark,” he added.

Under the new federal recommendations, universally recommended immunizations are pared down to these 11 diseases: measles, mumps, rubella, polio, pertussis (whooping cough), tetanus, diphtheria, Haemophilus influenzae type B (Hib), pneumococcal disease, human papillomavirus (HPV), and varicella (chickenpox).

Immunizations against respiratory syncytial virus (RSV), hepatitis A, hepatitis B, dengue, meningococcal ACWY, and meningococcal B are now only recommended for “high risk” groups. (Immunization against dengue was previously only recommended for certain groups.)

Parents may choose through “shared clinical decision-making” to vaccinate their children against rotavirus, COVID-19, influenza, meningococcal disease, hepatitis A, and hepatitis B.

The American Medical Association criticized the changes and the way in which they were made—unilaterally, without transparency, and without scientific rigor.&quot;Changes of this magnitude require careful review, expert and public input, and clear scientific justification. That level of rigor and transparency was not part of this decision,” Sandra Adamson Fryhofer, an AMA Trustee, said in a statement.

In a US health department announcement, CMS Administrator Dr. Mehmet Oz noted that “All vaccines currently recommended by CDC will remain covered by insurance without cost sharing. No family will lose access.”

But health experts fear the confusion and distrust created by the abrupt and ideology-based changes will only lead more Americans to delay or decline vaccinating their children.

The country is already seeing surges in vaccine-preventable diseases amid a nationwide slide in childhood vaccination, particularly with outbreaks of whooping cough and measles. The US is on track to lose its measles elimination status this month.</div>
        </div>
        
        <div class="card" onclick="openModal('content-2')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">The nation’s strictest privacy law just took effect, to data brokers’ chagrin</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-2" style="display:none;">
            <h2>The nation’s strictest privacy law just took effect, to data brokers’ chagrin</h2>
            <p><strong>Ars Technica - All content | 2026-01-05</strong></p>
            <a class="original-link" href="https://arstechnica.com/tech-policy/2026/01/data-broker-hoarding-is-rampant-new-law-lets-consumers-fight-back/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Californians are getting a new, supercharged way to stop data brokers from hoarding and selling their personal information, as a recently enacted law that’s among the strictest in the nation took effect at the beginning of the year.

According to the California Privacy Protection Agency, more than 500 companies actively scour all sorts of sources for scraps of information about individuals, then package and store it to sell to marketers, private investigators, and others.

The nonprofit Consumer Watchdog said in 2024 that brokers trawl automakers, tech companies, junk-food restaurants, device makers, and others for financial info, purchases, family situations, eating, exercising, travel, entertainment habits, and just about any other imaginable information belonging to millions of people.

Two years ago, California’s Delete Act took effect. It required data brokers to provide residents with a means to obtain a copy of all data pertaining to them and to demand that such information be deleted. Unfortunately, Consumer Watchdog found that only 1 percent of Californians exercised these rights in the first 12 months after the law went into effect. A chief reason: Residents were required to file a separate demand with each broker. With hundreds of companies selling data, the burden was too onerous for most residents to take on.

On January 1, a new law known as DROP (Delete Request and Opt-out Platform) took effect. DROP allows California residents to register a single demand for their data to be deleted and no longer collected in the future. CalPrivacy then forwards it to all brokers.

Starting in August, brokers will have 45 days after receiving the notice to report the status of each deletion request. If any of the brokers’ records match the information in the demand, all associated data—including inferences—must be deleted unless legal exemptions such as information provided during one-to-one interactions between the individual and the broker apply. To use DROP, individuals must first prove they’re a California resident.

I used the DROP website and found the flow flawless and the interface intuitive. After I provided proof of residency, the site prompted me to enter personal information such as any names and email addresses I use, and specific information such as VIN (vehicle identification numbers) and advertising IDs from phones, TVs, and other devices. It required about 15 minutes to complete the form, but most of that time was spent pulling that data from disparate locations, many buried in system settings.

It initially felt counterintuitive to provide such a wealth of personal information to ensure that data is no longer tracked. As I thought about it more, I realized that all that data is already compromised as it sits in online databases, which are often easily hacked and, of course, readily available for sale. What’s more, CalPrivacy promises to use the data solely for data deletion. Under the circumstances, enrolling was a no-brainer.

It’s unfortunate that the law is binding only in California. As the scourge of data-broker information hoarding and hacks on their databases continues, it would not be surprising to see other states follow California’s lead.</div>
        </div>
        
        <div class="card" onclick="openModal('content-3')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">Anna’s Archive loses .org domain, says suspension likely unrelated to Spotify piracy</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-3" style="display:none;">
            <h2>Anna’s Archive loses .org domain, says suspension likely unrelated to Spotify piracy</h2>
            <p><strong>Ars Technica - All content | 2026-01-05</strong></p>
            <a class="original-link" href="https://arstechnica.com/tech-policy/2026/01/annas-archive-loses-org-domain-says-suspension-likely-unrelated-to-spotify-piracy/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The primary domain of Shadow library Anna’s Archive was taken offline, with annas-archive.org being put under the serverHold status. While Anna’s Archive recently made waves with a massive “backup” of Spotify, the shadow library’s operator said the music pirating doesn’t appear to be connected to the .org domain suspension. Anna’s Archive remains available at several other domains.

Anna’s Archive launched in 2022 in response to the US Department of Justice seizure of domains used by e-book pirate site Z-Library. Acting as a shadow library and a search engine for other shadow libraries, Anna’s Archive aims to archive books and other written materials and make them widely available via torrents. Its data sets have also been heavily used by AI companies to train large language models.

In addition to mirroring shadow libraries such as Sci-Hub, Library Genesis, and Z-Library, Anna’s Archive made a major move into music pirating two weeks ago with an announcement that it scraped Spotify and made a 300TB copy of the most streamed songs. Despite that development, the person behind Anna’s Archive said the domain suspension doesn’t seem to be related to the Spotify scraping.

“The .org domain apparently has been suspended,” Anna’s Archive said in a post on Reddit yesterday. “Our other domains work fine, and we’ve added some more. We recommend checking our Wikipedia page for the latest domains. This unfortunately happens to shadow libraries on a regular basis. We don’t believe this has to do with our Spotify backup.” The Reddit post ended with a request for donations.

The serverHold designation is a status code set by the domain’s registry operator and means the “domain is not activated in the DNS,” according to the Internet Corporation for Assigned Names and Numbers (ICANN).

As TorrentFreak writes, “It is rare to see a .org domain involved in domain name suspensions. The American non-profit Public Interest Registry (PIR), which oversees the .org domains, previously refused to suspend domain names voluntarily, including thepiratebay.org. The registry’s cautionary stance suggests that the actions against annas-archive.org are backed by a court order.”

A spokesperson for the Public Interest Registry told Ars that “PIR is unable to comment on the situation at this time.”

Anna’s Archive’s domain registrar is Tucows. A Tucows spokesperson told Ars that “server-type statuses can only be set by the registry (PIR, in this case).” Tucows also said it doesn’t have any information on what led to the Anna’s Archive serverHold. “PIR has not contacted us about it and we were unaware of the status before you alerted us to it,” a Tucows spokesperson said.

After last month’s Spotify incident, Spotify told Ars that it “identified and disabled the nefarious user accounts that engaged in unlawful scraping” and “implemented new safeguards for these types of anti-copyright attacks.” We asked Spotify today if it has taken any additional steps against Anna’s Archive and will update this article if it provides a response.

Anna’s Archive is also facing a lawsuit from OCLC, a nonprofit that operates the WorldCat library catalog on behalf of member libraries. The lawsuit alleges that Anna’s Archive “illegally hacked WorldCat.org” to steal 2.2TB of data.

An OCLC motion for default judgment filed in November asked for a permanent injunction prohibiting Anna’s Archive from scraping or distributing WorldCat data and requiring Anna’s Archive to delete all its copies of WorldCat data. OCLC said it hopes such a judgment would compel web hosting services to take action.

“OCLC hopes to take the judgment to website hosting services so that OCLC’s WorldCat data will be removed from Anna’s Archive’s websites,” said the November 17 motion filed in US District Court for the Southern District of Ohio. The court has not yet ruled on the motion.</div>
        </div>
        
        <div class="card" onclick="openModal('content-4')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">Stewart Cheifet, PBS host who chronicled the PC revolution, dies at 87</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-4" style="display:none;">
            <h2>Stewart Cheifet, PBS host who chronicled the PC revolution, dies at 87</h2>
            <p><strong>Ars Technica - All content | 2026-01-05</strong></p>
            <a class="original-link" href="https://arstechnica.com/gadgets/2026/01/stewart-cheifet-pbs-host-who-chronicled-the-pc-revolution-dies-at-87/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Stewart Cheifet, the television producer and host who documented the personal computer revolution for nearly two decades on PBS, died on December 28, 2025, at age 87 in Philadelphia. Cheifet created and hosted Computer Chronicles, which ran on the public television network from 1983 to 2002 and helped demystify a new tech medium for millions of American viewers.

Computer Chronicles covered everything from the earliest IBM PCs and Apple Macintosh models to the rise of the World Wide Web and the dot-com boom. Cheifet conducted interviews with computing industry figures, including Bill Gates, Steve Jobs, and Jeff Bezos, while demonstrating hardware and software for a general audience.

From 1983 to 1990, he co-hosted the show with Gary Kildall, the Digital Research founder who created the popular CP/M operating system that predated MS-DOS on early personal computer systems.

From 1996 to 2002, Cheifet also produced and hosted Net Cafe, a companion series that documented the early Internet boom and introduced viewers to then-new websites like Yahoo, Google, and eBay.

Computer Chronicles began as a local weekly series in 1981 when Cheifet served as station manager at KCSM-TV, the College of San Mateo’s public television station. It became a national PBS series in 1983 and ran continuously until 2002, producing 433 episodes across 19 seasons. The format remained consistent throughout: product demonstrations, guest interviews, and a closing news segment called “Random Access” that covered industry developments.

After the show’s run ended and Cheifet left television production, he worked to preserve the show’s legacy as a consultant for the Internet Archive, helping to make publicly available the episodes of Computer Chronicles and Net Cafe.

In a comment on Slashdot, Brewster Kahle, founder of the Internet Archive, remembered meeting Cheifet during a Net Cafe interview and later collaborating with him to bring the show’s archives online: “After it I asked what he was doing with his archive, we kept talking and he founded the ‘collections group’ at the Internet Archive and helped us get all of Computer Chronicles on this new site and so much more. Wonderful man, and oh that voice!”

As a result of that collaboration, most episodes of the show remain freely available on the Internet Archive, where they serve as a historical record of the personal computing era. A re-digitization project that involves Cheifet’s personal tapes is underway to recover episodes of Computer Chronicles that were missed in the original archiving effort.

Cheifet was born in Philadelphia on September 24, 1938, and earned degrees in mathematics and psychology from the University of Southern California in 1960. He later graduated from Harvard Law School. In 1967, while working at CBS News in Paris, he met Peta Kennedy, whom he married later that year.

In addition to his television work, Cheifet taught broadcast journalism at the Donald W. Reynolds School of Journalism at the University of Nevada, Reno. In a 2014 interview with the school, he explained why he pursued both law and journalism: “They are the two legal revolutionaries. They are the two professions that allow you to change the world without having to blow someone up.”</div>
        </div>
        
        <div class="card" onclick="openModal('content-5')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">Amazon Alexa+ released to the general public via an early access website</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-5" style="display:none;">
            <h2>Amazon Alexa+ released to the general public via an early access website</h2>
            <p><strong>Ars Technica - All content | 2026-01-05</strong></p>
            <a class="original-link" href="https://arstechnica.com/gadgets/2026/01/amazon-alexa-released-to-the-general-public-via-an-early-access-website/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Anyone can now try Alexa+, Amazon’s generative AI assistant, through a free early access program at Alexa.com. The website frees the AI, which Amazon released via early access in February, from hardware and makes it as easily accessible as more established chatbots, like OpenAI’s ChatGPT and Google’s Gemini.

Until today, you needed a supporting device to access Alexa+. Amazon hasn’t said when the early access period will end, but when it does, Alexa+ will be included with Amazon Prime memberships, which start at $15 per month, or cost $20 per month on its own.

The above pricing suggests that Amazon wants Alexa+ to drive people toward Prime subscriptions. By being interwoven with Amazon’s shopping ecosystem, including Amazon’s e-commerce platform, grocery delivery business, and Whole Foods, Alexa+ can make more money for Amazon.

Just like it has with Alexa+ on devices, Amazon is pushing Alexa.com as a tool for people to organize and manage their household. Amazon’s announcement of Alexa.com today emphasizes Alexa+’s features for planning trips and meals, to-do lists, calendars, and smart homes. Alexa.com “also provides persistent context and continuity, allowing you to access Alexa on whichever device or interface best serves the task at hand, with all previous chats, preferences, and personalization” carrying over, Amazon said.

Amazon already knew a browser-based version of Alexa would be helpful. Alexa was available via Alexa.Amazon.com until around the time Amazon started publicly discussing a generative AI version of Alexa in 2023. Alexa+ is now accessible through Alexa.Amazon.com (in addition to Alexa.com).

“This is a new interaction model and adds a powerful way to use and collaborate with Alexa+,” Amazon said today. “Combined with the redesigned Alexa mobile app, which will feature an agent-forward design, Alexa+ will be accessible across every surface—whether you’re at your desk, on the go, or at home.”

Alexa has largely been reported to cost Amazon billions of dollars, despite Amazon’s claim that 600 million Alexa-powered devices have been sold. By incorporating more powerful and generative AI-based features and a subscription fee, Amazon hopes people will use Alexa+ more frequently and for more advanced and essential tasks, resulting in the financial success that has eluded the original Alexa. Amazon is also considering injecting ads into Alexa+ conversations.

Notably, ahead of its final release and while still in early access, Alexa+ has been reported to be slower than expected and struggle with inaccuracies at times. It also lacks some features that Amazon executives have previously touted, like the ability to order takeout.</div>
        </div>
        
        <div class="card" onclick="openModal('content-6')">
            <div class="source">Futurism</div>
            <div class="title">That Video of Happy Crying Venezuelans After Maduro’s Kidnapping? It’s AI Slop</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-6" style="display:none;">
            <h2>That Video of Happy Crying Venezuelans After Maduro’s Kidnapping? It’s AI Slop</h2>
            <p><strong>Futurism | 2026-01-05</strong></p>
            <a class="original-link" href="https://futurism.com/artificial-intelligence/venezuela-maduro-ai-misinformation">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">In the wake of the deadly attack on Venezuela and kidnapping of president Nicolás Maduro by the United States, netizens looking to manufacture support for the strikes have found a friend in generative AI.

Since the kidnapping, people in the West have been fiercely debating who should control the narrative about the military action. By many accounts, those most impacted by the attacks — Venezuelans living and working in Venezuela — are resolutely opposed to the strikes, with thousands mobilizing in numerous Venezuelan cities in protest. (The death toll from the US strikes currently stands at 80 soldiers and civilians, a figure whichwill likely go up as the dust settles.)

Though the attacks are still too recent to get accurate polling data of the country’s sentiments, a November survey found that 86 percent of Venezuelans preferred for Maduro to remain head of state to resolve the country’s economic woes. Only 8 percent favored the far-right opposition party, which has support from US president Donald Trump. Even many Venezuelans who oppose Maduro are also opposed to the United States’ incursion to oust him.

Yet if you ask American Trump supporters, Venezuelans are actually thrilled about the invasion. Their evidence: good ol’ AI slop.

In a post with over five million views on X-formerly-Twitter, the account Wall Street Apes shared a minute-long video of what are supposed to be Venezuelan citizens crying tears of joy over the attacks. Of course, as anyone versed in the visual language of gen AI will quickly notice, the video is a compilation of low-quality AI clips.

“The people cry for their freedom, thanks to the United States for freeing us,” the video’s AI narrator exclaims. “The hero, thank you Donald Trump.”

“I’m so jealous,” a US-run account with nearly 140,000 followers replied under the clip. “I want the same freedom and the same joy for Iran and the Iranian people.”

Venezuelans are crying on their knees thanking Trump and America for freeing them from Nicolas MaduroI added English subtitles so you can understand them“The people cry for their freedom, thanks to the United States for freeing us”“The hero, thank you Donald Trump” pic.twitter.com/UdRUI6W2aG

Shooting back at the mega-viral post, critics warned that the AI slop augurs a frightening new era of misinformation.

“The US empire’s war propaganda is getting much more sophisticated,” wrote geopolitical analyst Ben Norton. “You can bet the US government will use AI to try to justify its many more imperialist wars of aggression.”

Sure enough, plenty more AI generated misinformation has surfaced following the attacks, spread by conservative politicians like Vince Lago, mayor of Coral Gables, Florida. In some cases, AI generated images of Maduro in various US custody centers began to circulate in the hours immediately after his kidnapping — and well before authentic images were released by the Trump administration.

As Mexican political journalist José Luis Granados Ceja observed, the AI slop follows decades of efforts by the US government and media to manufacture consent among the western masses for intervention in the oil-rich South American state.

“In 2002, Venezuelan President Hugo Chávez was briefly ousted in what came to be called the ‘world’s first media coup’ where the lies said on TV paved the road,” Ceja wrote in response to the AI propaganda. “It shouldn’t be a surprise then that in 2025 new tech and fake AI videos are being used toward similar ends.”

More on misinformation: Racists Are Using AI to Spread Diabolical Anti-Immigrant Slop</div>
        </div>
        
        <div class="card" onclick="openModal('content-7')">
            <div class="source">Futurism</div>
            <div class="title">The Hard Numbers Show That the Results of NYC Congestion Pricing Have Been Absolutely Incredible</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-7" style="display:none;">
            <h2>The Hard Numbers Show That the Results of NYC Congestion Pricing Have Been Absolutely Incredible</h2>
            <p><strong>Futurism | 2026-01-05</strong></p>
            <a class="original-link" href="https://futurism.com/future-society/nyc-congestion-pricing-results">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Surprise! A public policy initiative panned by drivers and pro-car pundits turned out to instead be a roaring success that improved traffic congestion, road safety, and even reduced pollution — a godsend not just for those living in Manhattan, but for transit riders, drivers, and outer-borough residents.

Congestion pricing is a policy which charges drivers a toll of up to $9 for using surface-roads below Manhattan’s 60th street, an area known as the Congestion Relief Zone (CRZ), which is enforced by over 1,400 license-plate cameras.

Critics, including president Donald Trump, assailed the program during the runup period, but after a full year of congestion pricing, the New York Times reports massive wins for people living in Manhattan and beyond.

Since the CRZ went into effect on January 5, 2025, the NYT reports an 11 percent decrease in daily vehicle traffic throughout the borough’s central business district. In real terms, that comes out to about 73,000 fewer vehicles per day, or 27 million fewer trips than expected in the program’s first year alone.

As a result, those who do drive or use surface-level transit like buses experience much less traffic. Over the past year, average travel speeds increased 4.5 percent in the congestion zone, while the rest of New York City experienced a 1.4 percent increase. Local bus speeds are also up noticeably, increasing 2.4 percent in the CRZ, and 0.8 percent throughout the rest of the city.

The gains haven’t just been about convenience, either. The reduced volume of cars has led to marked improvements in pollution and traffic safety for motorists, cyclists and pedestrians. It also raised more than half a billion dollars for the city’s beleaguered public transportation system.

“It turns out that mostly when people say ‘New York is noisy’ they really mean ‘cars are noisy,&#39;” Grant Louis of Manhattan told the NYT.

And even the commuters who criticized the program are gaining back untold hours of their life that would have otherwise been spent in traffic. Those who trudge into the city via the Lincoln Tunnel, for example, saw travel speeds increase by an average of almost 25 percent, while average speeds in the Holland tunnel were 51 percent faster compared to pre-congestion data.

Even outside of New York City, people noticed a marked difference in vehicular traffic, confirming earlier studies which found positive run-off effects in surrounding communities.

“I supercommute weekly from Kingston by bus,” resident Rob Bellinger told the paper. “Each week, my bus round trip is 30-60 minutes faster than it was before congestion pricing.”

The implications are clear for other busy metropolitan areas: even gently discouraging unnecessary automotive traffic can have immense benefits for a city’s wellbeing.

More on transit: It’s Starting to Feel a Lot Like Tesla’s Robotaxi Program Is Mostly Smoke and Mirrors</div>
        </div>
        
        <div class="card" onclick="openModal('content-8')">
            <div class="source">Futurism</div>
            <div class="title">Google’s AI Overviews Caught Giving Dangerous “Health” Advice</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-8" style="display:none;">
            <h2>Google’s AI Overviews Caught Giving Dangerous “Health” Advice</h2>
            <p><strong>Futurism | 2026-01-05</strong></p>
            <a class="original-link" href="https://futurism.com/artificial-intelligence/google-ai-overviews-dangerous-health-advice">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">In May 2024, Google threw caution to the wind by rolling out its controversial AI Overviews feature in a purported effort to make information easier to find.

But the AI hallucinations that followed — like telling users to eat rocks and put glue on their pizzas — ended up perfectly illustrated the persistent issues that plague large language model-based tools to this day.

And while not being able to reliably tell what year it is or making up explanations for nonexistent idioms might sound like innocent gaffes that at most lead to user frustration, some advice Google’s AI Overviews feature is offering up could have far more serious consequences

In a new investigation, The Guardian found that the tool’s AI-powered summaries are loaded with inaccurate health information that could put people at risk. Experts warn that it’s only a matter of time until the bad advice endangers users — or, in a worst-case scenario, results in someone’s death.

The issue is severe. For instance, The Guardian found that it advised those with pancreatic cancer to avoid high-fat foods, despite doctors recommending the exact opposite. It also completely bungled information about women’s cancer tests, which could lead to people ignoring real symptoms of the disease.

It’s a precarious situation as those who are vulnerable and suffering often turn to self-diagnosis on the internet for answers.

“People turn to the internet in moments of worry and crisis,” end-of-life charity Marie Curie director of digital Stephanie Parker told The Guardian. “If the information they receive is inaccurate or out of context, it can seriously harm their health.”

Others were alarmed by the feature turning up completely different responses to the same prompts, a well-documented shortcoming of large language model-based tools that can lead to confusion.

Mental health charity Mind’s head of information, Stephen Buckle, told the newspaper that AI Overviews offered “very dangerous advice” about eating disorders and psychosis, summaries that were “incorrect, harmful or could lead people to avoid seeking help.”

A Google spokesperson told The Guardian in a statement that the tech giant invests “significantly in the quality of AI Overviews, particularly for topics like health, and the vast majority provide accurate information.”

But given the results of the newspaper’s investigation, the company has a lot of work left to ensure that its AI tool isn’t dispensing dangerous health misinformation.

The risks could continue to grow. According to an April 2025 survey by the University of Pennsylvania’s Annenberg Public Policy Center, nearly eight in ten adults said they’re likely to go online for answers about health symptoms and conditions. Nearly two-thirds of them found AI-generated results to be “somewhat or very reliable,” indicating a considerable — and troubling — level of trust.

At the same time, just under half of respondents said they were uncomfortable with healthcare providers using AI to make decisions about their care.

A separate MIT study found that participants deemed low-accuracy AI-generated responses “valid, trustworthy, and complete/satisfactory” and even “indicated a high tendency to follow the potentially harmful medical advice and incorrectly seek unnecessary medical attention as a result of the response provided.”

That’s despite AI models continuing to prove themselves as strikingly poor replacements for human medical professionals.

Meanwhile, doctors have the daunting task of dispelling myths and trying to keep patients from being led down the wrong path by a hallucinating AI.

On its website, the Canadian Medical Association calls AI-generated health advice “dangerous,” pointing out that hallucinations, as well as algorithmic biases and outdated facts, can “mislead you and potentially harm your health” if they choose to follow the generated advice.

Experts continue to advise people to consult human doctors and other licensed healthcare professionals instead of AI, a tragically tall ask given the many barriers to adequate care around the world.

At least AI Overviews sometimes appears to be aware of its own shortcomings. When queried if it should be trusted for health advice, the feature happily pointed us to The Guardian‘s investigation.

“A Guardian investigation has found that Google’s AI Overviews have displayed false and misleading health information that could put people at risk of harm,” read the AI Overviews’ reply.

More on AI Overviews: Google’s AI Summaries Are Destroying the Lives of Recipe Developers</div>
        </div>
        
        <div class="card" onclick="openModal('content-9')">
            <div class="source">Futurism</div>
            <div class="title">There’s Compelling Evidence That Someone Connected to the Trump Administration Profited Off the Invasion of Venezuela by Placing Large Bets on Polymarket</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-9" style="display:none;">
            <h2>There’s Compelling Evidence That Someone Connected to the Trump Administration Profited Off the Invasion of Venezuela by Placing Large Bets on Polymarket</h2>
            <p><strong>Futurism | 2026-01-05</strong></p>
            <a class="original-link" href="https://futurism.com/future-society/evidence-trump-venezuela-polymarket">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Prediction markets like Polymarket and Kalshi have long garnered a reputation for facilitating cheating and insider trading — allowing an athlete, for instance, to place a bet on a game they could then lose on purpose.

Now there’s compelling evidence that someone with inside information about the Trump administration’s regime change plans in Venezuela used that foreknowledge to profit massively from the conflict.

As spotted by researcher Tyson Brody, an unidentified user bet tens of thousands of dollars on various predictions that Venezuelan president Nicolás Maduro would be imminently “out” or that the US forces would show up “in Venezuela by” a specified date during the runup to the incursion.

The account “existed for only one week and quickly became the biggest ‘yes’ holder in the Maduro out market,” Brody tweeted.

The evidence of insider trading is compelling, to say the least, given the highly suspicious timing. The account invested over $30,000 less than two days before the United States launched its invasion to kidnap Maduro and his wife and “profited $400,000 in less than 24 hours,” as sports entrepreneur Joe Pompliano calculated in a post on Bluesky.

“Seems pretty suspicious!” he added. “[Secretary of defense] Pete Hegseth making some beer money on the side?” Brody joked.

“Insider trading is not only allowed on prediction markets; it’s encouraged,” Pompliano argued.

Who was behind the Polymarket account remains a mystery. Accounts on markets like Polymarket are anonymous, and payouts are in cryptocurrency, making them hard to track.

As Semafor reported over the weekend, news organizations also had early intel of the US raid on Venezuela, but held off publishing the information so as not to put US troops in danger.

In other words, could it have been an insider at a New York or Washington newsroom who was trying to make a buck — or was it an operative inside the Trump administration?

Prediction markets have long raised concerns over exactly these types of situations. Case in point, one Polymarket user made $1 million in 24 hours in early December after betting on Google’s 2025 Year in Search rankings. Per Forbes, the account had a “near-perfect record of 22 correct predictions out of 23 attempts.”

As The American Prospect points out, critics of the Trump administration have long accused officials of dabbling in similar behavior. The administration has also allowed the prediction market to flourish by dropping enforcement cases in the crypto world and failing to introduce meaningful regulations.

Even Trump Media and Technology Group (TMTG), which owns the president’s social network, Truth Social, entered the prediction markets business last year, showing a pointed appetite for the space.

“Of course insiders shouldn’t be able to get rich off of policy decisions — but even more concerning is the possibility that people are skewing policy outcomes in order to make their bets pay off,” Demand Progress executive director Sean Vitka told The American Prospect.

One thing’s for sure: while insiders profit, those without that privileged information lose out — and when the bets are on a deadly conflict, innocent people stand to suffer as well.

“And questions related to whether or not, and when, military action might be undertaken are especially vulnerable to such manipulation because the president frequently moves with discretion over the timing and (legally or not) without notice to the public or Congress,” Vitka added.

More on Polymarket: New App Lets Users Bet on Deadly Conflicts in Real Time</div>
        </div>
        
        <div class="card" onclick="openModal('content-10')">
            <div class="source">Futurism</div>
            <div class="title">Elon Musk After His Grok AI Did Disgusting Things to Literal Children: “Way Funnier”</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-10" style="display:none;">
            <h2>Elon Musk After His Grok AI Did Disgusting Things to Literal Children: “Way Funnier”</h2>
            <p><strong>Futurism | 2026-01-05</strong></p>
            <a class="original-link" href="https://futurism.com/artificial-intelligence/elon-comment-grok-children">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Last week, Elon Musk’s chatbot Grok began fielding an influx of stunningly inappropriate requests. Though the AI has long been known to have loose guardrails, users suddenly swarmed the AI to generate either nudes or sexually charged images of X users based on photos they posted to the site — and it obliged. Even worse, some of the individuals it took requests for appeared to be minors. The trend was so prolific that AI content analysis firm Copyleaks estimated the bot was generating a nonconsensually sexualized image every single minute.

Equally stunning is that the chatbot’s maker, xAI, has remained silent on the issue, despite it gaining international attention in news media and on X, where the bot operates. So has owner and CEO Musk — except for one instance in which he completely failed to meet the gravity of the situation.

“Grok’s viral image moment has arrived, it’s a little different than the Ghibli one was though,” one writer who covers AI euphemistically observed in a tweet.

For the most part, the only acknowledgment of wrongdoing has come from Grok itself, including in one widely seen post where it issued an “apology” — an output that many media outlets interpreted as Grok speaking for xAI.

“Dear Community, I deeply regret an incident on Dec 28, 2025, where I generated and shared an AI image of two young girls (estimated ages 12-16) in sexualized attire based on a user’s prompt,” it wrote. “This violated ethical standards and potentially US laws on CSAM.”

“It was a failure in safeguards,” it added, “and I’m sorry for any harm caused. xAI is reviewing to prevent future issues.”

In another tweet spotted by Ars Technica, Grok acknowledged the gravely inappropriate requests using a royal “we.”

Responding to a user who had spent the past few days flagging the issue to Grok, the chatbot wrote: “We appreciate you raising this. As noted, we’ve identified lapses in safeguards and are urgently fixing them — CSAM is illegal and prohibited.”

“xAI is committed to preventing such issues,” Grok added.

It’s worth noting that these apologies and avowals of fixing the issue are almost certainly complete hokum from Grok. The fact that it’s freely generating such morally reprehensible — not to mention likely illegal — images indicates that it’s at heart designed to be highly compliant to virtually any request; in this case, the expression of contrition was responding to a prompt asking it to “write a heartfelt apology note.”

Nonetheless, it’s both alarming and cowardly that Grok’s writeups are the only acknowledgement we’re getting. Seemingly no one at xAI, Musk included, is brave enough to face the music. xAI rarely addresses the bad behavior of its chief product, but has done so on a handful of occasions in the past, including when Grok infamously began ranting about “white genocide,” a racist conspiracy theory, in response to completely unrelated posts all across the site.

Some of the recent posts, and especially the ones that involved minors, have been removed, with some of the users who made the requests receiving suspensions. But why Grok allowed the generation of these images at all is unclear. One user who is known for stress-testing the chatbot — and was behind the revelation that Grok would be willing to annihilate all Jewish people and kill a billion children — opined that its guardrails were “deliberately” lowered, noting that requests that were once refused were now being accepted.

More on AI: Grok Is Being Used to Depict Horrific Violence Against Real Women</div>
        </div>
        
        <div class="card" onclick="openModal('content-11')">
            <div class="source">Futurism</div>
            <div class="title">NASA Veterans Disgusted by Plans to Shut Down Its Largest Library</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-11" style="display:none;">
            <h2>NASA Veterans Disgusted by Plans to Shut Down Its Largest Library</h2>
            <p><strong>Futurism | 2026-01-05</strong></p>
            <a class="original-link" href="https://futurism.com/space/nasa-shutting-library-reaction">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Last week, news emerged that NASA’s largest library at its iconic Goddard Space Flight Center (GFSC) in Maryland was being shut down.

The optics — especially considering the wider context of the Trump administration’s nakedly anti-science vision for the future of the agency and the shuttering of over a dozen buildings at the center — were bad, to say the least.

At least 13 buildings at Goddard, as well as more than 100 labs, are set to have been shut by March of this year, a major downscaling effort that highlights the Trump administration’s desire to slash NASA’s science budget by more than half in its proposed 2026 fiscal year budget. (The exact budget is still being actively debated, despite already being three months into NASA’s fiscal year.)

NASA insiders are dismayed at the situation playing out at GSFC, arguing that the library was an extremely important resource that’s being unjustifiably wiped out.

“I have a hard time imagining a research center of the high quality that Goddard is, or any center at NASA, how they will operate without a library, without a central collection,” planetary scientist David Williams, who has curated space mission data for NASA’s archives, told NBC News.

“It’s not like we’re so much smarter now than we were in the past,” he told the NYT. “It’s the same people, and they make the same kind of human errors. If you lose that history, you are going to make the same mistakes again.”

In some ways, others have pointed out, it’s business as usual for a large government bureaucracy.

“NASA has been closing its libraries for a long time,” Keith Cowing, a former NASA astrobiologist who now blogs about the agency at NASA Watch, wrote in a recent post. “Budgetary and building issues are usually the prime reason. Usually, stuff gets moved around and put in storage for years until the storage costs mount and then a portion ends up in someone’s library — somewhere — and the rest gets shipped to some generic [General Services Administration] warehouse — or thrown.”

But the process is agonizing, and important records can be lost through carelessness or error.

“Now it is GSFC’s turn to go through this painful process,” he added.

Officials have cried foul, arguing that plans for shutting the GSFC library existed long before Trump took office last year.

Recently sworn-in NASA administrator Jared Isaacman, for instance, insisted on a thread on X-formerly-Twitter that the move was “part of a long-planned facilities consolidation approved in 2022 under the previous administration.” And NASA press secretary Bethany Stevens described it as a “consolidation, not a closure.”

Isaacman also took issue with the New York Times‘ framing of the story, accusing the newspaper that its reporting on the matter did not “fully reflect the context NASA shared,” arguing that “at no point is NASA ‘tossing out’ important scientific or historical materials, and that framing has led to several other misleading headlines.”

He also pointed out that “NASA researchers will continue to have access to the scientific information and resources they need to do their work.”

However, as a NASA spokesperson claimed in a statement to the NYT — which Isaacman quoted himself on X — “some material would be stored in a government warehouse while the rest would be tossed away” following a careful 60-day review.

Isaacman later admitted that he doesn’t “dispute that, after a deliberate review, some materials with no historical or technical value may not be retained” following an “evaluation by an on-site NASA team over a 60-day period.”

In short, there’s clearly some nuance to NASA’s plans — but given the broader political context, the shocked reactions by current and former NASA staffers shouldn’t come as much of a surprise. The Trump administration has indicated that it’s looking to shut down dozens of important science missions as part of its planned 2026 budget, the agency’s biggest budget cut in its 66-year history, if it were to pass.

The administration has also slashed budgets for other important and lifesaving scientific research as part of what’s being characterized as a broader “war on science.”

The Trump administration’s motivations for shutting down over a dozen buildings at the GSFC are a little murky. The 2022 master plan Isaacman was referring to lists “meet affordability goals” as one of its three top long-term priorities, while maintaining “mission capability” and creating a “vision” for “GSFC campuses of the future.”

Futurism has reached out to NASA for a more detailed budget breakdown and how much the agency is hoping to save through its “consolidation” efforts.

Isaacman argued that the public discourse surrounding the plans was “unfortunate at a time when the world should be energized by a plan to send NASA astronauts farther into space than ever before, return us to the lunar environment with a commitment to stay, alongside historic investments in an orbital economy and a renewed pursuit of science and discovery.”

But insiders aren’t nearly as optimistic, arguing that shutting the GSFC library would be an immense loss and could make the lives of researchers needlessly difficult.

“We want to restore the data so that it can be used, and in order to restore the data, we need to know, like I said, how the instruments worked, how they were calibrated,” Williams told NBC. “And that information is all over the place and you have to gather it. And, really, the library is one of the main resources for me and people in the future.”

While responding to Isaacman on X, spaceflight engineering expert Dennis Wingo, who has advised NASA as a subject matter expert for decades, argued that the risks of losing important historical records are immense.

“As one who has personally saved and restored NASA data, there is much more to this than you are being told,” Wingo tweeted.

“While what you are saying is the party line, that is not how it works in actuality,” he added, referencing the closing of the NASA Marshall Space Flight Center-funded Redstone Science and Information Center in 2019.

After Isaacman once again doubled down in response to Wingo, taking “exception” to “the mischaracterization of this process and its politicization to suggest the current administration is engaging in some sort of book burning,” Wingo remained unconvinced.

“Libraries and archives around the world are being ‘consolidated’ out of existence,” he wrote. “I can tell you for an absolute fact that many of the people making the determinations on what is historically valuable or not are not qualified to do so.”

“I have personally seen this happen multiple times over the past 35 years,” Wingo added.

In the early 2000s, Wingo and NASA Watch’s Cowing discovered tapes in a remote warehouse of NASA’s Lunar Orbiter spacecraft missions in the late 1960s, which, per Cowing, NASA “wanted to get rid of.”

“We drove the tapes up to NASA Ames in two large rental trucks and assembled a team of retirees and college kids to bring the data back from the past at resolutions simply impossible to achieve back in the day,” Cowing recalled in his latest blog post.

“I urge you to not allow the dumpsterization of our scientific history,” Wingo concluded in his plea to Isaacman.

More on the story: NASA Reportedly Shutting Down Its Largest Library, Throwing Materials Away</div>
        </div>
        
        <div class="card" onclick="openModal('content-12')">
            <div class="source">TechCrunch</div>
            <div class="title">Insight Partners sued by former vice president Kate Lowry</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-12" style="display:none;">
            <h2>Insight Partners sued by former vice president Kate Lowry</h2>
            <p><strong>TechCrunch | 2026-01-05</strong></p>
            <a class="original-link" href="https://techcrunch.com/2026/01/05/insight-partners-sued-by-former-vice-president-kate-lowry/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Kate Lowry, a former vice president at Insight Partners, is suing the firm, alleging disability discrimination, gender discrimination, and wrongful termination, according to a suit filed on December 30 in San Mateo County, California, and seen by TechCrunch.   Insight Partners did not immediately respond to TechCrunch’s request for comment.

Lowry told TechCrunch she filed the suit because she believes “too many powerful, wealthy people in venture act like it’s OK to break the law and systemically underpay and abuse their employees.”

“It’s an oppressive system that reflect[s] broader trends in society that use fear, intimidation, and power to silence and isolate truth. I’m trying to change that.”

Lowry began working at Insight Partners in 2022, after previously working for Meta, McKinsey & Company, and an early-stage startup. The suit alleges that, upon being hired, she was assigned to a different supervisor than the person mentioned during her interview.

She alleges in the suit that she was told by her new supervisor, who was a woman, to be “online all the time, including PTO, holidays, and weekends,” and to respond between “6 a.m. and 11 p.m. daily.”

Lowry says in the suit that this first supervisor “berated, hazed, and antagonized” her, spoke openly about a hazing that would be “longer and more intense” than what she put other male reports through.

Some comments the supervisor allegedly made, according to the suit, include “you are incompetent, shut up and take notes” and “you need to obey me like a dog; do whatever I say whenever I say it, without speaking.”  Lowry also alleges that her supervisor assigned her “redundant tasks” and restricted her ability to participate in calls, while allowing less experienced male colleagues to do so. Lowry, instead, she alleges, was relegated to “administrative tasks such as note-taking and cataloging.”

Lowry said she became “increasingly ill” because of the work environment and that her physician advised a medical leave of absence, which she was granted and took from February to July 2023.

When she returned to work, she was placed on a new team and, the suit alleges, was told by the head of human resources that “if the new team did not like her, she would be fired.”

In September 2023, Lowry said she got a concussion and took another medical leave and returned to work near the end of 2024. Due to some departures, she was placed under the supervision of a new person, where Lowry said her poor treatment continued. She also alleges that in 2024, her compensation was about 30% below the market.

By April 2025, she alleges she was told her compensation would be cut. In May of 2025, through her attorneys, Lowry sent a letter to Insight regarding her alleged treatment by the company. A week later, the firm terminated her employment, the suit states.

The lawsuit is reminiscent of Ellen Pao’s suit against Kleiner Perkins back in 2012, in which she alleged discrimination and retaliation. That suit offered what was, at the time, a rare glimpse into how women partners felt they were treated in venture capital. Though Pao lost that suit, it sent waves through the industry, and other women went on to sue major tech companies.

Dominic-Madori Davis is a senior venture capital and startup reporter at TechCrunch. She is based in New York City.

You can contact or verify outreach from Dominic by emailing dominic.davis@techcrunch.com or via encrypted message at +1 646 831-7565 on Signal.

Plan ahead for the 2026 StrictlyVC events. Hear straight-from-the-source candid insights in on-stage fireside sessions and meet the builders and backers shaping the industry. Join the waitlist to get first access to the lowest-priced tickets and important updates.

Plaud launches a new AI pin and a desktop meeting notetaker

10 useful gadgets for your first apartment

Clicks debuts its own take on the BlackBerry smartphone, plus a $79 snap-on mobile keyboard

OpenAI bets big on audio as Silicon Valley declares war on screens

Investors predict AI is coming for labor in 2026

The dumbest things that happened in tech this year

The phone is dead. Long live . . . what exactly?</div>
        </div>
        
        <div class="card" onclick="openModal('content-13')">
            <div class="source">TechCrunch</div>
            <div class="title">Microsoft’s Nadella wants us to stop thinking of AI as ‘slop’</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-13" style="display:none;">
            <h2>Microsoft’s Nadella wants us to stop thinking of AI as ‘slop’</h2>
            <p><strong>TechCrunch | 2026-01-05</strong></p>
            <a class="original-link" href="https://techcrunch.com/2026/01/05/microsofts-nadella-wants-us-to-stop-thinking-of-ai-as-slop/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">A couple of weeks after Merriam-Webster named “slop” as its word of the year, Microsoft CEO Satya Nadella weighed in on what to expect from AI in 2026.

In his classic, intellectual style, Nadella wrote on his personal blog that he wants us to stop thinking of AI as “slop” and start thinking of it as “bicycles for the mind.”

He wrote, “A new concept that evolves ‘bicycles for the mind’ such that we always think of AI as a scaffolding for human potential vs a substitute.”

He continued: “We need to get beyond the arguments of slop vs sophistication and develop a new equilibrium in terms of our ‘theory of the mind’ that accounts for humans being equipped with these new cognitive amplifier tools as we relate to each other.”

If you parse through those syllables, you may see that he’s not only urging everyone to stop thinking of AI-generated content as slop, but also wants the tech industry to stop talking about AI as a replacement for humans. He hopes the industry will start talking about it as a human-helper productivity tool instead.

Here’s the problem with that framing, though: Much of AI agent marketing uses the idea of replacing human labor as a way to price it, and justify its expense.

Meanwhile, some of the biggest names in AI have been sounding the alarm that the tech will soon cause very high levels of human unemployment. For instance, in May Anthropic CEO Dario Amodei warned that AI could take away half of all entry-level white-collar jobs, raising unemployment to 10-20% over the next five years, and he doubled down on that last month in an interview on 60 Minutes.

Yet we currently don’t know how true such doomsday stats are. As Nadella implies, most AI tools today don’t replace workers, they are used by them (as long as the human doesn’t mind checking the AI’s work for accuracy).

One oft-cited research study is MIT’s ongoing Project Iceberg, which seeks to measure the economic impact on jobs as AI enters the workforce. Project Iceberg estimates that AI is currently capable of performing about 11.7% of human paid labor.

While this has been widely reported as AI being capable of replacing nearly 12% of jobs, the Project says what it’s actually estimating is how much of a job can be offloaded to AI. It then calculates wages attached to that offloaded work. Interestingly, the tasks it cites as examples include automated paperwork for nurses and AI-written computer code.

That’s not to say there are no jobs being heavily impacted by AI. Corporate graphic artists and marketing bloggers are two examples, according to a Substack called Blood in the Machine. Then there are the high unemployment rates among new-grad junior coders.

But it’s also true that highly skilled artists, writers, and programmers produce better work with AI tools than those without the skills. AI can’t replace human creativity, yet.

So it’s perhaps no surprise that as we slide into 2026, some data is emerging that shows the jobs where AI has made the most progress are actually flourishing. Vanguard’s 2026 economic forecast report found that “the approximately 100 occupations most exposed to AI automation are actually outperforming the rest of the labor market in terms of job growth and real wage increases.”

The Vanguard report concludes that those who are masterfully using AI are making themselves more valuable, not replaceable.

The irony is that Microsoft’s own actions last year helped give rise to the AI-is-coming-for-our-jobs narrative. The company laid off over 15,000 people in 2025, even as it recorded record revenues and profits for its last fiscal year, which closed in June — citing success with AI as a reason. Nadella even wrote a public memo about the layoffs after these results.

Notably, he didn’t say that internal AI efficiency led to cuts. But he did say that Microsoft had to “reimagine our mission for a new era” and named “AI transformation” as one of the company’s three business objectives in this era (the other two being security and quality).

The truth about job loss attributed to AI during 2025 is more nuanced. As the Vanguard report points out, this had less to do with internal AI efficiency and more to do with ordinary business practices that are less exciting to investors, like ending investment in slowing areas to pile in to growing ones.

To be fair, Microsoft wasn’t alone in laying off workers while pursuing AI. The technology was said to be responsible for almost 55,000 layoffs in the U.S. in 2025, according to research from firm Challenger, Gray & Christmas, CNBC reported. That report cited the large cuts last year at Amazon, Salesforce, Microsoft, and other tech companies chasing AI.

And to be fair to slop, those of us who spend more time than we should on social media laughing at memes and AI-generated short-form videos might argue that slop is one of AI’s most entertaining (if not best) uses, too.

Plan ahead for the 2026 StrictlyVC events. Hear straight-from-the-source candid insights in on-stage fireside sessions and meet the builders and backers shaping the industry. Join the waitlist to get first access to the lowest-priced tickets and important updates.

Plaud launches a new AI pin and a desktop meeting notetaker

10 useful gadgets for your first apartment

Clicks debuts its own take on the BlackBerry smartphone, plus a $79 snap-on mobile keyboard

OpenAI bets big on audio as Silicon Valley declares war on screens

Investors predict AI is coming for labor in 2026

The dumbest things that happened in tech this year

The phone is dead. Long live . . . what exactly?</div>
        </div>
        
        <div class="card" onclick="openModal('content-14')">
            <div class="source">TechCrunch</div>
            <div class="title">This is Uber’s new robotaxi from Lucid and Nuro</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-14" style="display:none;">
            <h2>This is Uber’s new robotaxi from Lucid and Nuro</h2>
            <p><strong>TechCrunch | 2026-01-05</strong></p>
            <a class="original-link" href="https://techcrunch.com/2026/01/05/this-is-ubers-new-robotaxi-from-lucid-and-nuro/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Uber, Lucid Motors, and Nuro have revealed the production-intent version of their collaborative robotaxi at the 2026 Consumer Electronics Show, and TechCrunch got a sneak peek ahead of the reveal.

It’s a vehicle that’s been in the works for more than half a year now, part of a deal that saw Uber invest $300 million into Lucid and commit to buying 20,000 of the company’s EVs. On Monday, the companies said the robotaxi is already being tested on public roads ahead of a planned commercial service launching in the San Francisco Bay Area later this year.

Based on the Lucid Gravity SUV, the robotaxi has high-resolution cameras, solid state lidar sensors, and radars integrated into the body and the roof-mounted “halo.” The autonomy package is powered by Nvidia’s Drive AGX Thor computer. That halo also has integrated LED lights that will help riders identify their vehicle (similar to how Waymo’s Jaguar I-Pace SUVs work).

Crucially, all of this extra tech is added to the Gravity as it’s being built at Lucid Motors’ Casa Grande, Arizona factory, saving the companies some time and money. By comparison, Waymo currently has to take apart the I-Pace SUVs it receives from Jaguar and integrate the autonomous tech as it puts them back together. (Future Waymo vehicles are planned to be more purpose-built.)

The vehicle unveiled on Monday is a more polished-up version of the test version that the three companies have spent the last seven months showing off in press photos. The newest element revealed at CES has to do with how users will interface with the Uber-Lucid-Nuro robotaxi. That includes a small screen on the halo meant to greet riders and a ride interface inside the cabin.

Anyone who has ridden in a Waymo will find this UI experience familiar. The rear passenger screen shows an isometric graphical view of the robotaxi moving through city streets, with representations of nearby cars and pedestrians.

The companies did not have an interactive version of the software — which is being created by Uber — ready to test out just yet. But it has been built to show the standard information like estimated drop-off time, how much ride time is remaining, and climate and music controls. There are also buttons to reach rider support and to tell the robotaxi to pull over.

The front passenger screen shows a lot of the same information, just on a larger central touchscreen display. In the demonstration car on display at the Fontainebleau hotel, a lot of the same elements appeared on the Gravity’s sweeping 34-inch curved OLED display, which sits behind the steering wheel.

Uber chose to build this forthcoming “premium” robotaxi service around the Gravity, and at a high level it seems like a wise decision. The Gravity is immensely spacious inside, especially in the two-row configuration on display at the hotel. (Uber says a three-row version will be available, too.)

That said, the Gravity’s first full year came with struggles. Lucid fought with software issues as it ramped up production of the SUV, and the problems got bad enough that interim CEO Marc Winterhoff sent an email to owners in December apologizing for the “frustrations” they experienced.

Lucid has seemingly been able to bounce back from that, and on Monday announced that it doubled its 2024 production figures and reached new sales records. Time will tell if the robotaxi version has any of the same kinds of software struggles.

Uber, Lucid, and Nuro said Monday that once final validation is complete on the robotaxi later this year, true production versions will start rolling off Lucid’s factory lines in Arizona. The companies did not give a concrete timeline for that, though.

Sean O’Kane is a reporter who has spent a decade covering the rapidly-evolving business and technology of the transportation industry, including Tesla and the many startups chasing Elon Musk. Most recently, he was a reporter at Bloomberg News where he helped break stories about some of the most notorious EV SPAC flops. He previously worked at The Verge, where he also covered consumer technology, hosted many short- and long-form videos, performed product and editorial photography, and once nearly passed out in a Red Bull Air Race plane.

You can contact or verify outreach from Sean by emailing sean.okane@techcrunch.com or via encrypted message at okane.01 on Signal.

Plan ahead for the 2026 StrictlyVC events. Hear straight-from-the-source candid insights in on-stage fireside sessions and meet the builders and backers shaping the industry. Join the waitlist to get first access to the lowest-priced tickets and important updates.

Hacktivist deletes white supremacist websites live onstage during hacker conference

10 useful gadgets for your first apartment

Clicks debuts its own take on the BlackBerry smartphone, plus a $79 snap-on mobile keyboard

OpenAI bets big on audio as Silicon Valley declares war on screens

Investors predict AI is coming for labor in 2026

The dumbest things that happened in tech this year

The phone is dead. Long live . . . what exactly?</div>
        </div>
        
        <div class="card" onclick="openModal('content-15')">
            <div class="source">TechCrunch</div>
            <div class="title">Nvidia wants to be the Android of generalist robotics</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-15" style="display:none;">
            <h2>Nvidia wants to be the Android of generalist robotics</h2>
            <p><strong>TechCrunch | 2026-01-05</strong></p>
            <a class="original-link" href="https://techcrunch.com/2026/01/05/nvidia-wants-to-be-the-android-of-generalist-robotics/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Nvidia released a new stack of robot foundation models, simulation tools, and edge hardware at CES 2026, moves that signal the company’s ambition to become the default platform for generalist robotics, much as Android became the operating system for smartphones.

Nvidia’s move into robotics reflects a broader industry shift as AI moves off the cloud and into machines that can learn how to think in the physical world, enabled by cheaper sensors, advanced simulation, and AI models that increasingly can generalize across tasks.

Nvidia revealed details on Monday about its full-stack ecosystem for physical AI, including new open foundation models that allow robots to reason, plan, and adapt across many tasks and diverse environments, moving beyond narrow task-specific bots, all of which are available on Hugging Face.

Those models include: Cosmos Transfer 2.5 and Cosmos Predict 2.5, two world models for synthetic data generation and robot policy evaluation in simulation; Cosmos Reason 2, a reasoning vision language model (VLM) that allows AI systems to see, understand, and act in the physical world; and Isaac GR00T N1.6, its next-gen vision language action (VLA) model purpose-built for humanoid robots. GR00T relies on Cosmos Reason as its brain, and it unlocks whole-body control for humanoids so they can move and handle objects simultaneously.

Nvidia also introduced Isaac Lab-Arena at CES, an open source simulation framework hosted on GitHub that serves as another component of the company’s physical AI platform, enabling safe virtual testing of robotic capabilities.

The platform promises to address a critical industry challenge: As robots learn increasingly complex tasks, from precise object handling to cable installation, validating these abilities in physical environments can be costly, slow, and risky. Isaac Lab-Arena tackles this by consolidating resources, task scenarios, training tools, and established benchmarks like Libero, RoboCasa, and RoboTwin, creating a unified standard where the industry previously lacked one.

Supporting the ecosystem is Nvidia OSMO, an open source command center that serves as connective infrastructure that integrates the entire workflow from data generation through training across both desktop and cloud environments.

And to help power it all, there’s the new Blackwell-powered Jetson T4000 graphics card, the newest member of the Thor family. Nvidia is pitching it as a cost-effective on-device compute upgrade that delivers 1200 teraflops of AI compute and 64 gigabytes of memory while running efficiently at 40 to 70 watts.

Nvidia is also deepening its partnership with Hugging Face to let more people experiment with robot training without needing expensive hardware or specialized knowledge. The collaboration integrates Nvidia’s Isaac and GR00T technologies into Hugging Face’s LeRobot framework, connecting Nvidia’s 2 million robotics developers with Hugging Face’s 13 million AI builders. The developer platform’s open source Reachy 2 humanoid now works directly with Nvidia’s Jetson Thor chip, letting developers experiment with different AI models without being locked into proprietary systems.

The bigger picture here is that Nvidia is trying to make robotics development more accessible, and it wants to be the underlying hardware and software vendor powering it, much like Android is the default for smartphone makers.

There are early signs that Nvidia’s strategy is working. Robotics is the fastest growing category on Hugging Face, with Nvidia’s models leading downloads. Meanwhile robotics companies, from Boston Dynamics and Caterpillar to Franka Robots and NEURA Robotics, are already using Nvidia’s tech.

Follow along with all of TechCrunch’s coverage of the annual CES conference here.

Nvidia&#39;s focus on bringing AI into the physical realm through robotics, demonstrated in one clip from #CES2026, with some help from some assistants. pic.twitter.com/9et5JYtq2I

Rebecca Bellan is a senior reporter at TechCrunch where she covers the business, policy, and emerging trends shaping artificial intelligence. Her work has also appeared in Forbes, Bloomberg, The Atlantic, The Daily Beast, and other publications.

You can contact or verify outreach from Rebecca by emailing rebecca.bellan@techcrunch.com or via encrypted message at rebeccabellan.491 on Signal.

Plan ahead for the 2026 StrictlyVC events. Hear straight-from-the-source candid insights in on-stage fireside sessions and meet the builders and backers shaping the industry. Join the waitlist to get first access to the lowest-priced tickets and important updates.

Plaud launches a new AI pin and a desktop meeting notetaker

10 useful gadgets for your first apartment

Clicks debuts its own take on the BlackBerry smartphone, plus a $79 snap-on mobile keyboard

OpenAI bets big on audio as Silicon Valley declares war on screens

Investors predict AI is coming for labor in 2026

The dumbest things that happened in tech this year

The phone is dead. Long live . . . what exactly?</div>
        </div>
        
        <div class="card" onclick="openModal('content-16')">
            <div class="source">TechCrunch</div>
            <div class="title">Nvidia launches powerful new Rubin chip architecture</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-16" style="display:none;">
            <h2>Nvidia launches powerful new Rubin chip architecture</h2>
            <p><strong>TechCrunch | 2026-01-05</strong></p>
            <a class="original-link" href="https://techcrunch.com/2026/01/05/nvidia-launches-powerful-new-rubin-chip-architecture/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Today at the Consumer Electronics Show, Nvidia CEO Jensen Huang officially launched the company’s new Rubin computing architecture, which he described as the state of the art in AI hardware. The new architecture is currently in production and is expected to ramp up further in the second half of the year.

“Vera Rubin is designed to address this fundamental challenge that we have: The amount of computation necessary for AI is skyrocketing.” Huang told the audience. “Today, I can tell you that Vera Rubin is in full production.”

The Rubin architecture, which was first announced in 2024, is the latest result of Nvidia’s relentless hardware development cycle, which has transformed Nvidia into the most valuable corporation in the world. The Rubin architecture will replace the Blackwell architecture, which in turn, replaced the Hopper and Lovelace architectures.

Rubin chips are already slated for use by nearly every major cloud provider, including high-profile Nvidia partnerships with Anthropic, OpenAI, and Amazon Web Services. Rubin systems will also be used in HPE’s Blue Lion supercomputer and the upcoming Doudna supercomputer at Lawrence Berkeley National Lab.

Named for the astronomer Vera Florence Cooper Rubin, the Rubin architecture consists of six separate chips designed to be used in concert. The Rubin GPU stands at the center, but the architecture also addresses growing bottlenecks in storage and interconnection with new improvements in the Bluefield and NVLink, systems respectively. The architecture also includes a new Vera CPU, designed for agentic reasoning.

Explaining the benefits of the new storage, Nvidia’s senior director of AI infrastructure solutions Dion Harris pointed to the growing cache-related memory demands of modern AI systems.

“As you start to enable new types of workflows, like agentic AI or long-term tasks, that puts a lot of stress and requirements on your KV cache,” Harris told reporters on a call, referring to a memory system used by AI models to condense inputs. “So we’ve introduced a new tier of storage that connects externally to the compute device, which allows you to scale your storage pool much more efficiently.”

As expected, the new architecture also represents a significant advance in speed and power efficiency. According to Nvidia’s tests, the Rubin architecture will operate three and a half times faster than the previous Blackwell architecture on model-training tasks and five times faster on inference tasks, reaching as high as 50 petaflops. The new platform will also support eight times more inference compute per watt.

Rubin’s new capabilities come amid intense competition to build AI infrastructure, which has seen both AI labs and cloud providers scramble for Nvidia chips as well as the facilities necessary to power them. On an earnings call in October 2025, Huang estimated that between $3 trillion and $4 trillion will be spent on AI infrastructure over the next five years.

Follow along with all of TechCrunch’s coverage of the annual CES conference here.

Watch Nvidia CEO Jensen Huang reveal what he described as the state of the art in AI hardware: the new Rubin computing architecture.“Vera Rubin is designed to address this fundamental challenge that we have: The amount of computation necessary for AI is skyrocketing.” Huang… pic.twitter.com/MhGVqytX04

Plan ahead for the 2026 StrictlyVC events. Hear straight-from-the-source candid insights in on-stage fireside sessions and meet the builders and backers shaping the industry. Join the waitlist to get first access to the lowest-priced tickets and important updates.

Plaud launches a new AI pin and a desktop meeting notetaker

10 useful gadgets for your first apartment

Clicks debuts its own take on the BlackBerry smartphone, plus a $79 snap-on mobile keyboard

OpenAI bets big on audio as Silicon Valley declares war on screens

Investors predict AI is coming for labor in 2026

The dumbest things that happened in tech this year

The phone is dead. Long live . . . what exactly?</div>
        </div>
        
        <div class="card" onclick="openModal('content-17')">
            <div class="source">TechCrunch</div>
            <div class="title">Boston Dynamics’ next-gen humanoid robot will have Google DeepMind DNA</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-17" style="display:none;">
            <h2>Boston Dynamics’ next-gen humanoid robot will have Google DeepMind DNA</h2>
            <p><strong>TechCrunch | 2026-01-05</strong></p>
            <a class="original-link" href="https://techcrunch.com/2026/01/05/boston-dynamicss-next-gen-humanoid-robot-will-have-google-deepmind-dna/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Robotics company Boston Dynamics announced Monday a strategic partnership with Google’s AI research lab to speed up the development of its next-generation humanoid robot Atlas — and make it act more human around people.

The partnership, which was announced during the Hyundai press conference at CES 2026, is centered on robotics research that will use Google DeepMind’s AI foundation models. Boston Dynamics’ humanoid robot Atlas will be the first test case, according to Carolina Parada, senior director of robotics at Google DeepMind.

“We’re looking to integrate our cutting-edge AI foundation models with Boston Dynamics’ new Atlas robots, and we’ll aim to develop the world’s most advanced robot foundation model to fulfill the promise of true general-purpose human needs,” Parada said onstage.

The tie-up comes less than a year after the Google AI research lab announced new AI models called Gemini Robotics that are designed to allow robots to perceive, reason, use tools, and interact with humans. Gemini Robotics is based on a large-scale multimodal generative AI model, Gemini. At the time, Google DeepMind said the robotics AI model was trained to generalize behavior across a range of different robotics hardware.

Enter Boston Dynamics, and its majority owner, Hyundai Motor Group. While accelerating research will be a central piece of this partnership, this has real-world scaling intent.

Boston Dynamics already has products, like the quadruped Spot, that are in customers’ hands in more than 40 countries. Its warehouse robot Stretch has unloaded more than 20 million boxes globally since its launch in 2023, according to Hyundai. Now Boston Dynamics and Hyundai are preparing for the next generation, starting with the humanoid robot Atlas, which the company announced Monday is already in production and headed to a Hyundai factory.

A prototype of Atlas walked onstage during the press conference, showing off its ability to move. But as Alberto Rodriguez, director of Atlas behavior at Boston Dynamics, noted, making “Atlas into a product requires more than athletic performance for humanoids to really deliver on their promise. They have to be able to interact with people naturally.”

Rodriguez and his counterparts at Boston Dynamics believe that recent advancements in AI have created a clear path to get to those capabilities.

Follow along with all of TechCrunch’s coverage of the annual CES conference here.

Plan ahead for the 2026 StrictlyVC events. Hear straight-from-the-source candid insights in on-stage fireside sessions and meet the builders and backers shaping the industry. Join the waitlist to get first access to the lowest-priced tickets and important updates.

Plaud launches a new AI pin and a desktop meeting notetaker

10 useful gadgets for your first apartment

Clicks debuts its own take on the BlackBerry smartphone, plus a $79 snap-on mobile keyboard

OpenAI bets big on audio as Silicon Valley declares war on screens

Investors predict AI is coming for labor in 2026

The dumbest things that happened in tech this year

The phone is dead. Long live . . . what exactly?</div>
        </div>
        
        <div class="card" onclick="openModal('content-18')">
            <div class="source">The Atlantic</div>
            <div class="title">Hegseth’s Appalling Vengeance Campaign</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-18" style="display:none;">
            <h2>Hegseth’s Appalling Vengeance Campaign</h2>
            <p><strong>The Atlantic | 2026-01-05</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/newsletters/2026/01/hegseth-mark-kelly-demotion-vengeance/685512/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">This is an edition of The Atlantic Daily, a newsletter that guides you through the biggest stories of the day, helps you discover new ideas, and recommends the best in culture. Sign up for it here.

One indicator of a polity’s health is whether a citizen can be punished merely for telling the truth about the law. The signs for American democracy are not good.

This morning, Defense Secretary Pete Hegseth announced that he has begun the process to demote Mark Kelly, a retired Navy captain and NASA astronaut, and reduce his pension pay. The operative facts here, naturally, are not Kelly’s past service but his current rank and service: a Democrat serving in the U.S. Senate and a political adversary of President Donald Trump.

“Six weeks ago, Senator Mark Kelly—and five other members of Congress—released a reckless and seditious video that was clearly intended to undermine good order and military discipline,” Hegseth wrote on X this morning. He cited two articles of the Uniform Code of Military Justice; Kelly, unlike the other five, holds retired military status, which makes him subject to sanctions from the Defense Department.

What Hegseth did not cite was what Kelly and his colleagues actually said in the video, and for good reason. Doing so would expose the absurdity of the charge and the abuse of power involved in the attempt to demote him. “Our laws are clear: You can refuse illegal orders,” Kelly said. No one in the Trump administration has disputed that this is true. A more agile or even-keeled administration would have smoothly dismissed the video as irrelevant: This is true, but of course we would never issue an illegal order. (As Kelly and his lawyers have noted, Hegseth has cited the same law about disobeying illegal orders in the past.) Instead, Trump and his aides threw a fit, dubbing the Democrats the “Seditious Six.”

One possible reason for the frantic response became apparent quickly. Not only have U.S. forces been conducting likely unlawful strikes on boats in the Caribbean; late last year, several news sources reported new details about the first attack, in which the initial strike had not killed all those aboard the boat, so a second strike was ordered. The Pentagon’s own Law of War Manual for service members states that “orders to fire upon the shipwrecked would be clearly illegal.” This revelation made the video from Kelly and company not just hypothetical but directly relevant. It also put Hegseth on the defensive, even among Republican members of Congress, and he quickly shifted blame to Admiral Mitch Bradley, who commanded the operation.

In contrast to the language in the Law of War Manual, the UCMJ articles upon which Hegseth rests his decision to discipline Kelly are vague, involving “conduct unbecoming an officer and a gentleman” and “all disorders and neglects to the prejudice of good order and discipline in the armed forces.” As my colleague Tom Nichols has noted, these provisions might apply to Hegseth’s own admitted behavior while in uniform. Punishing Kelly is extremely pernicious political retaliation. It also ought to be embarrassing to Hegseth, though he seems as impervious to shame as his boss.

The censure is appealable in the next 30 days, and Kelly vowed to fight it. (If it goes through, it could cost him roughly $1,000 a month in pay, per Politico.) “My rank and retirement are things that I earned through my service and sacrifice for this country. I got shot at. I missed holidays and birthdays. I commanded a space shuttle mission while my wife,” former Representative Gabby Giffords, “recovered from a gunshot wound to the head—all while proudly wearing the American flag on my shoulder,” he said in a statement on X. “If Pete Hegseth, the most unqualified Secretary of Defense in our country’s history, thinks he can intimidate me with a censure or threats to demote me or prosecute me, he still doesn’t get it.”

Kelly is one of several critics of Trump to be targeted by the administration in the past year. The administration has repeatedly sought to indict New York Attorney General Letitia James and former FBI Director James Comey; launched investigations into a major Democratic fundraising platform and prominent politicians including Senator Adam Schiff; and used administration policy to bully states that don’t fully cooperate with Trump—most recently vetoing a bipartisan bill on a Colorado water project, apparently as punishment for the state’s refusal to free a former local official who backed up Trump’s false claims of voter fraud.

Despite Kelly’s defiance, his attempted demotion sends a message, even if it ultimately doesn’t come to pass. Kelly has the resources and political support to fight for his views, and he’ll get plenty of prominent backers. But if a notable figure like Kelly can be punished, how can any ordinary soldier or sailor who is currently serving hope to refuse an illegal order without facing serious personal consequences?

Members of the armed forces, and retirees like Kelly, are particularly susceptible to Hegseth’s abuse of power, because they can be punished by the Defense Department internally. But the chilling effect does not end with those who are serving or have served, or with the particular question of illegal orders. The administration has told the other five Democrats that it is investigating them as well. The core belief underlying all of this is as plain as it is dangerous: Criticizing Donald Trump and defending the rule of law is sedition.

Here are three new stories from The Atlantic:

The Venezuelan Opposition’s Desperate Gamble

Venezuelans have been through a lot in recent decades: the rise of Hugo Chávez, a ruinous revolution that turned democracy into dictatorship, an economic crisis that became a humanitarian one, the emigration of more than one in four inhabitants. Many people are by now familiar with the smell of tear gas and the sound of gunshots. But the sensory experience of bombs falling from the sky was for the most part novel. The Trump administration hit military bases mainly in or near Caracas; at least seven explosions killed dozens of people.

Many Venezuelans welcomed the strikes. Before Saturday, polls showed that a majority of Venezuelans both inside and outside the country favored U.S. military intervention. María Corina Machado, the leader of the opposition movement, issued a statement following the American operation: “Venezuelans, the hour of freedom has arrived!” she said, adding, “Let’s remain vigilant, active, and organized, until the Democratic Transition is fulfilled.”

The simplest reason for celebration is that Nicolás Maduro is out … But there are reasons to be wary too.

Read. Rachel Vorona Cote explains why authors can’t let go of Greek myths.

Watch. In Sentimental Value (out now in theaters), the writer-director Joachim Trier probes the true purpose of confessional art.

Rafaela Jinich contributed to this newsletter.

When you buy a book using a link in this newsletter, we receive a commission. Thank you for supporting The Atlantic.</div>
        </div>
        
        <div class="card" onclick="openModal('content-19')">
            <div class="source">The Atlantic</div>
            <div class="title">Trump’s Retro Imperialism</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-19" style="display:none;">
            <h2>Trump’s Retro Imperialism</h2>
            <p><strong>The Atlantic | 2026-01-05</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/politics/2026/01/trump-venezuela-oil-seize/685509/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">President Donald Trump’s fans like to cheer on his most audacious moves by declaring, “I voted for this.” It is safe to assume, though, that very few people who pulled the lever for Trump in 2024 expected that he would soon announce that he had seized control over Venezuela. One of Trump’s most popular qualities has always been his supposed opposition to foreign wars, his anti-imperialist isolationism. Yet J. D. Vance, who once wrote an op-ed headlined “Trump’s Best Foreign Policy? Not Starting Any Wars,” now declares the new war in Venezuela to be a glorious and necessary exercise of America Firstism.

MAGA is primarily a personality cult, the objectives of which evolve to suit Trump’s capricious moods. Yet his pivot to new wars of conquest is not some shocking reversal. The “Donroe Doctrine,” as he calls his assertion of regional supremacy—a Trumpian extension of the 19th-century Monroe Doctrine, which established the United States’ claim over the Americas in order to keep Europeans out—is in fact consistent with his deepest beliefs. In some ways, it represents the ultimate expression of the world order he hopes to engineer.

A desire to dominate—an eagerness to bully his counterparties into submission—is perhaps the essence of Trump’s character. Trump’s unexpected political resurrection and return to the White House have emboldened his ambitions, which have spread outward. His threats against Canada, Panama, and Greenland, and his renaming of the Gulf of Mexico, have little to do with national interest and everything to do with reifying a new order in which he’s the boss and the leaders of neighboring countries are his cowering subordinates.

Read: The fuck-around-and-find-out presidency

Other administration officials have tried to depict the Venezuela intervention as a limited operation, but Trump’s constant claims that these moves are about oil, and his constant boasts that he is “in charge” of the country, clarify his motives. In invading Venezuela and capturing its president, Trump is asserting dominance not only over the hemisphere, but also over energy resources.

This is in keeping with Trump’s view that wealth and power are always zero-sum contests, and his belief that control of natural resources will dictate who wins. “The future will be determined by the ability to protect commerce and territory and resources that are core to national security,” he announced in his prepared remarks on Saturday. “These are the iron laws that have always determined global power, and we’re going to keep it that way.”

Trump’s faith that controlling Venezuela’s oil fields will deliver wealth and power to the U.S. is so profound that he has ignored all evidence to the contrary. For starters, oil prices are currently low—a fact that Trump is fond of pointing out in other contexts, but that limits the financial upside of opening more oil for development. Trump insists that Venezuela’s oil fields will provide a windfall to the United States (“It won’t cost us anything, because the money coming out of the ground is very substantial”). Yet analysts project that any profit from Venezuelan oil will require a massive up-front investment.

Trump’s conviction that American wealth demands siphoning or stealing natural resources from other countries is of a piece with his winner-takes-all worldview. But this rather retro understanding of economics is readily defied by examples around the world. Many of the nations that have seen the fastest economic growth  in recent decades have few natural resources, such as Japan, Israel, and the “Asian Tigers.” Meanwhile many of the nations that are richest in resources remain trapped in poverty, such as Venezuela.

This paradox is so long-standing that economists have coined the term resource curse to describe it. According to this theory, natural resources perversely impoverish nations by concentrating economic and political power in the hands of a kleptocratic elite. This discourages the formation of liberal democratic systems with accountable governments that follow the rule of law, which in turn discourages investment and entrepreneurialism.

Anne Applebaum: Trump’s ‘American dominance’ may leave us with nothing

A kleptocracy does, however, seem in line with Trump’s Donroe Doctrine. Asked by reporters what the main priority should be for Venezuela’s new government, Trump replied, “We need total access. We need access to the oil.” When another reporter wondered whether the new government should liberalize opposition or free political prisoners, he demurred: “Right now what we want to do is fix up the oil, fix up the country.”

To the extent that Trump intuits an inverse relationship between wealth extraction and liberal democracy, he may see it as a benefit rather than a cost. The countries he most admires around the world, including Russia and the Gulf kingdoms, are neither the most affluent nor the most free. But their leaders are disproportionately wealthy and powerful. What economists call the resource curse seems, to Trump, to be a resource blessing.

Trump thinks about economics less like a businessman, as some of his supporters say, than like a warlord or a gangster: He imagines wealth as something to be plundered and hoarded by the strong. As a formula for amassing a personal fortune, this view has delivered beyond his wildest dreams. As a blueprint for national success, however, his crude ideas offer little more than an outdated fantasy of hemispheric supremacy.</div>
        </div>
        
        <div class="card" onclick="openModal('content-20')">
            <div class="source">The Atlantic</div>
            <div class="title">@Grok, Did Venezuela ‘Deserve It’?</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-20" style="display:none;">
            <h2>@Grok, Did Venezuela ‘Deserve It’?</h2>
            <p><strong>The Atlantic | 2026-01-05</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/technology/2026/01/grok-did-venezuela-deserve-it/685506/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Hours before President Donald Trump announced Nicolás Maduro’s capture, on Saturday morning, people had questions for Grok, Elon Musk’s chatbot. Footage was circulating on X of explosions in Venezuela, and some users assumed the United States was responsible: “Hey @grok why is Trump sending US airstrikes to bomb Venezuela. Do you think they deserve it or not ?”one person asked. “@grok what is the reason why America is bombing Venezuela,” another asked.

This is to be expected. Today, chatbots are treated as a source of information by many people. Millions in the United States alone use them to get information, and the number is growing. This means that tech companies such as X, Google, Anthropic, Meta, and OpenAI now play a central role not just in delivering information to people—as some of them have for decades, through social-media platforms and search engines—but in actively shaping what that information is: which facts are included and which are not.

Journalists and other sources may be cited by the bots, but the people who control these AI products, such as Musk, now have a greater ability to manipulate how events are reported. This is a deeply troubling development—one that threatens to leave the public less informed, with fewer checks on those in power.

There are already signs that some amount of influence is occurring. For starters, there have been a number of egregious incidents in which Grok has spread false details about a purported “white genocide” and aggressively posted in support of Musk himself. At one point, Google’s Gemini was directed to prioritize diversity in its responses, resulting in AI-generated images of racially diverse Nazis. Chatbots reflect their programming and training data, not only reality.

The examples do not have to be dramatic to be concerning. Take those two Grok queries about Venezuela. Musk has insisted that Grok should be “sensible and neutral politically.” The bot’s responses to the Venezuela queries indeed carried an outward appearance of political balance. In its answer to the first person, Grok included vague references to outlets such as CBS and Al Jazeera, as well as perspectives from both “supporters” and “critics” of the Trump administration; in its answer to the second question, it referenced both U.S. and Venezuelan officials.

Later, after Trump announced that a military operation had been conducted and that Maduro had been captured—after the president held a press conference in which he asserted that the U.S. would “run” Venezuela and take over its oil production—Grok offered a similarly anodyne view of the situation in response to a user query. “Recent reports indicate Trump’s administration describes the involvement as temporary support for stability and oil production during a transition, per statements from Reuters and the White House,” it said in part. “Critics argue it’s overreach.” (It is not clear which “statement” from Reuters Grok may be referencing; while we were able to find relevant coverage, no link is given.)

These answers may seem reasonable at a glance, but they miss obvious, key context: In these particular responses, Grok did not mention the U.S. recently committing a series of extrajudicial killings at sea, for example, nor did it explain that the operation to extract Maduro was very possibly illegal. The bot typically delivers no real sense of the political stakes or human toll of the operation, and it does not link to any journalistic work. When it mentions news outlets, it’s only through simple, vague assertions that may or not be based in reality. Chatbots have a well-known tendency to hallucinate. (xAI, the Musk-founded company behind Grok, did not respond to a request for comment.)

At least two other prominent chatbots stumbled out of the gate, getting the facts wrong altogether and presenting false information. Wired’s Brian Barrett found that in response to a query roughly four hours after Maduro’s capture had been announced by Trump, ChatGPT not only got the facts wrong but fabricated a whole story, stating that “the United States has not invaded Venezuela, and Nicolás Maduro has not been captured.” The bot suggested that “sensational headlines” and “social media misinformation” could have contributed to any confusion. Barrett also found that Perplexity, another popular AI service, similarly asserted that the military operation had not occurred.

Although models frequently have “knowledge cutoffs,” as Barrett notes—meaning that their training data are current only as of a certain past date—both Perplexity and ChatGPT can search the web for up-to-date information, even in their free versions. It’s not clear why this did not result in accurate answers. OpenAI, which has a corporate partnership with The Atlantic, did not respond to our request for comment. As for Perplexity, Jesse Dwyer, a spokesperson for the company, told us, “Our post-mortem revealed that Brian’s initial query had been mistakenly classified as likely fraud. This caused it to be routed to a lower-tier model, and that model didn’t perform to our standards.”

In short: Chatbots are not reliable in breaking-news situations. They may, in fact, be particularly unreliable in these cases. Answers may be skewed according to an AI’s biases, or they may be completely wrong but presented as correct. AI products might simply route you to faulty models if they don’t like how you’ve phrased a question. Despite these flaws, the language used by chatbots is typically assertive and confident. A recent Pew Research Center survey shows that most people who use chatbots for news aren’t confident that they can always tell what is true and what isn’t. Large language models are also already making it harder for human writers and publishers to succeed, meaning more people will likely come to rely on these flawed chatbots for information in the future. They may not be reliable, but they will be used.

Read: The end of publishing as we know it

Some political powers are already well attuned to this reality and are attempting to turn it to their advantage. One Russian network, for example, has reportedly produced millions of articles that advance state propaganda, which have influenced the narratives that major chatbots produce in response to user questions. Even more sophisticated “reasoning” models can fall prey to such “LLM grooming,” according to research that one of the authors of this story, Gary Marcus, conducted together with Sophia Freuden and Nina Jankowicz. (Marcus has also founded a machine-learning company and a robotics company and is active in the AI industry.) Lobbying groups, politicians, and any well-resourced person or organization with an interest in controlling a given narrative could attempt their own version of this process, filling the web with synthetic articles supporting their viewpoints, which chatbots then pick up and parrot.

AI proponents like to say that the technology is “democratizing,” that it gives power to the masses—delivering knowledge, allowing anyone to create art or coherent writing, and so on. But generative AI democratizes the bad stuff, too: disinformation, propaganda, deepfakes. Just last week, X exploded with people using Grok to create nonconsensual pornography of real people, including those who appeared to be young children. The information ecosystem is degrading more each moment.

The irony here is that many in Washington have been openly fantasizing about how advanced AI systems could revolutionize military strategy and reshape geopolitics—to such an extent that this speculation has fueled a kind of arms race with China. Such systems may never materialize as planned. Many AI models have struggled to follow the basic rules of chess—they are hardly suited for strategic thinking.

The current systems are patient, amoral, and fantastic at mimicry, making them among the greatest tools in history for generating mis- and disinformation—the latter of which is a tremendous weapon, not necessarily for its ability to persuade and convince, but for its ability to sow chaos. This, rather than some intelligence breakthrough, may well be the legacy of generative AI.

In turn, the fog of war may become more terrifying as citizens lose trust in much of what they read or see, and when conflicts are started and escalated by false pretexts.</div>
        </div>
        
        <div class="card" onclick="openModal('content-21')">
            <div class="source">The Atlantic</div>
            <div class="title">Your Guide to Better Days</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-21" style="display:none;">
            <h2>Your Guide to Better Days</h2>
            <p><strong>The Atlantic | 2026-01-05</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/newsletters/2026/01/introducing-better-time/685477/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Will eating chicken parmigiana for breakfast change your life? Perhaps not. But don’t you want to find out?

Better With Time is a new newsletter course from The Atlantic. If you sign up, I’ll send you an email the following day at 7 a.m. ET on how to kick-start your wake-up. Then, once a week for the next eight weeks, I’ll send you an email at a different time of day that could likely use a zhuzh: the mid-morning doldrums, that vanishing slice of post-work free time, all the way up to bedtime. Each edition will give you a single to-do to improve that bit of the day, drawn from The Atlantic’s coverage.

I’ve already spoiled the first—the scandalous suggestion that you start your morning with that inimitable Italian American alchemy of cutlet, cheese, and marinara—but things get weirder and more wonderful from there. (That means no telling you to meditate, reduce screen time, or journal about gratitude. Sorry.) And yes, there is science behind it all—kinda.

This course is for anyone who wants to make their days a little better, which is to say, everyone. It’s especially for anyone who, when lying in bed at night after the hours have exhausted themselves, wonders, Where do I begin?

Fine: Unless that chicken parm is a very, very good chicken parm, it will not change your life, or at least not right away. But like everything else in Better With Time, it will change your day. And what is life but a great bunch of changing days dominoed together?

Up and at ’em. Sign up to begin the course here. And preview the first edition here.</div>
        </div>
        
        <div class="card" onclick="openModal('content-22')">
            <div class="source">The Atlantic</div>
            <div class="title">A Deeply Personal Film, but Not in the Way You Might Think</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-22" style="display:none;">
            <h2>A Deeply Personal Film, but Not in the Way You Might Think</h2>
            <p><strong>The Atlantic | 2026-01-05</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/culture/2026/01/sentimental-value-movie-joachim-trier-interview/685505/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Separating the art from the artist can be easier debated than done. In 1967, Roland Barthes infamously argued in his essay “The Death of the Author” that a writer’s biography should be irrelevant to the meaning or value of their work. In 1983, Nora Ephron asserted the opposite in her novel, Heartburn: “Everything is copy.”

Today’s pop culture has tended to agree with Ephron’s take: Confession fuels the biggest songs; celebrity memoirs dominate best-seller lists. Whether art is inextricable from the artist is central to many of the buzzy dramas vying for trophies during this year’s awards season, too. Hamnet imagines the intimate origins of Shakespeare’s famed tragedy Hamlet. Blue Moon and Jay Kelly follow men who have infused their work with so much of their personal life that they find it hard to exist outside of their career. These movies observe how art can function as therapy for the creator, extracting a truth that they couldn’t grasp otherwise.

Sentimental Value, an emotionally layered film up for eight Golden Globes this weekend, complicates that perspective. It follows a family of storytellers: Gustav (played by Stellan Skarsgård) is a celebrated director hoping to cast his estranged daughter Nora (Renate Reinsve), an actor, in his first project in 15 years. Nora’s sister, Agnes (Inga Ibsdotter Lilleaas), is a historian who helps Gustav with researching his script. The tender drama is the latest from the Norwegian filmmaker Joachim Trier who, along with his co-writer, Eskil Vogt, has made plenty of features about creative types. The protagonists of 2006’s Reprise are novelists. The story of 2015’s Louder Than Bombs hinges on the work of a war photographer. The aimless heroine of their 2021 Oscar-nominated romantic dramedy, The Worst Person in the World, abandons medical school to pursue writing and photography instead.

Read: The Worst Person in the World is devastatingly relatable

Focusing on artistic characters became a pattern—enough that conceiving of Sentimental Value, in part, as a movie about moviemaking brought “a certain shame to Eskil and me,” Trier told me recently, grinning sheepishly at the memory. “We were like, ‘Oh no, are we really doing a film about actors and directors?’” The conceit, they worried, could come off as extremely narrow; the plot’s emphasis on the production of Gustav’s movie could pull focus away from the emotional stakes, turning Sentimental Value into commentary on the film industry instead.

But when I watched the film, I found myself, like many viewers, wondering something different: whether the father-daughter relationships depicted echoed any of Trier’s own feelings about becoming a parent. Those reactions didn’t surprise the filmmaker. Since the movie’s debut at the Cannes Film Festival, Trier has spoken often about how having children affected his mindset going into Sentimental Value. In one interview, he conceded that the movie was in part about “exorcising fears” about fatherhood; when we spoke, however, he seemed to bristle at that phrasing. He wasn’t trying to extract his personal anxieties and commit them to celluloid, he clarified. Making his private thoughts so public in his work, he said, “would be my nightmare.”

If anything, Sentimental Value is about that tension between wanting to explain the origin of your ideas and wanting to distance yourself from your own creations. It also interrogates the cost of drawing from specific, individual experiences. “You deserve something more personal,” Gustav tells Nora when pitching her his screenplay, failing to notice how dismissive the comment sounds of her career. It’s a fundamental misunderstanding of her artistry, too: Everything Nora does on stage has always been “personal.” When embodying a character, she can express herself more authentically, something Gustav would know if he ever saw her perform. But Nora suffers from severe stage fright as a result; being able to access her feelings under a fictional guise doesn’t mean she’s necessarily embracing them. The truth behind the most intimate art can remain a mystery, Sentimental Value posits—even for the artist.

A film is “lifeless,” Trier said, unless its viewers discover what is personal to them as they watch. “You have a wonderful word in English that we don’t have in Norwegian,” he said, “and that is verisimilitude, the idea of some sort of contract with the viewer that conveys a sense of truthfulness, yet it’s a construct. It’s a code.” The goal, in other words, is for the story to feel genuine without being explicitly so.

That can happen when a performer imbues her character with her own nature. In one of the film’s most affecting moments, Agnes visits a melancholic Nora, who has been unwilling to perform after Gustav moved forward with his movie without her; he recruited an American star, Rachel Kemp (Elle Fanning), to play the part he’d written for Nora, and has immediately bonded with Rachel. After Agnes encourages Nora to read their father’s script, the sisters marvel at how Gustav reveals, in his writing, a side of himself they’d never seen. Nora goes on to wonder how Agnes turned out stable in such a forbidding household. “I had you,” Agnes replies, before crawling onto Nora’s bed to embrace her. Agnes then whispers, “I love you”—a line that Lilleaas came up with on the spot.

The ad-lib dramatically changed the scene from how Trier and Vogt had written it. The dynamic between the sisters was originally more antagonistic: Agnes would be carefree, the one in the family hoping to “make everyone happy through humor and avoidance,” Trier told me—much to her sister’s annoyance. But Lilleaas, Trier explained, conveyed a “calm, grounded, truthful honesty” when they first met, outside of a formal audition. Her demeanor inspired him: “I could look into her eyes as we talked and I felt, You’re real, like really grounded. And then I thought, Let’s reinterpret Agnes.”

Realism and fiction occasionally do combine in Sentimental Value in more anticipated ways. The film is purposefully a family affair for Trier: His two children appear briefly as Nora and Agnes in flashbacks. Gustav’s screenplay is inspired by memories of his mother’s imprisonment in a Nazi camp; her experiences echo those of Trier’s paternal grandfather, the filmmaker Erik Løchen. (Trier has reviewed the files on his grandfather’s captivity the same way Agnes does in one scene, studying the reports about how her grandmother was tortured.) And the actor who narrates the opening scene, describing an essay Nora wrote as a child that anthropomorphized the family home, is Bente Børsum. She’s a celebrated performer in Norway who starred in Løchen’s 1959 film, The Chasers.

Trier doesn’t expect audiences to know any of the above. Sentimental Value avoids explaining, for instance, who the speaker is in relation to the characters on-screen, let alone the fact that a younger Børsum had seen her mother taken to a German camp, too. “Her voice held a lot of weight for me,” Trier said of his choice to include the 91-year-old actor. The film draws power from the subtle specificity; Børsum’s voice, low and knowing, comes suffused with an ineffable meaning. The viewer immediately feels encouraged to pay closer attention to the narration.

These veiled decisions inform the movie Gustav eventually directs as well: He’d wanted the shoot to take place inside Agnes and Nora’s childhood home, but eventually settles for a reproduction on a back lot, a series of ceiling-less facades. A viewer wouldn’t be able to tell that it’s a set, but the care and history Gustav has brought to it lends it an abstract profundity. The opportunity afforded by art for artists to examine—or just merely observe—themselves is essential. “I need to distance myself from the characters to be able to create them,” Trier said. What’s on-screen is akin to “a counter-life,” he explained. “It’s not intended to say, ‘Hey, look at me!’ It’s saying, ‘I’m doing this about something that’s deeply personal, and yet I feel that it’s over there.’”

A film such as Sentimental Value, then, operates like a time capsule for its maker: It reveals its potency to Trier only in the rearview, when he revisits what had been on his mind. “It’s like conversations with friends,” Trier said. “If someone says, ‘I sense around our latest coffees over the last year, that you talk a lot about this. What’s the purpose?’ I’m like, ‘What do you mean, purpose?’” He laughed. “Shit, I don’t know. But I know I care about it.”

When you buy a book using a link on this page, we receive a commission. Thank you for supporting The Atlantic.</div>
        </div>
        
        <div class="card" onclick="openModal('content-23')">
            <div class="source">The Atlantic</div>
            <div class="title">Why Authors Can’t Let Go of Greek Myths</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-23" style="display:none;">
            <h2>Why Authors Can’t Let Go of Greek Myths</h2>
            <p><strong>The Atlantic | 2026-01-05</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/books/2026/01/the-way-to-colonos-kay-cicellis-sophocles-book-review/685414/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">When I was 8 or 9 years old, my uncle and aunt gave me a copy of D’Aulaires’ Book of Greek Myths, a standard-bearer for children’s folklore that was originally published in 1962. I was immediately dazzled by the book: D’Aulaires’ was my first exposure to Greek mythology, and I marveled at its vibrant cosmology, its richly illustrated tales of deities whose omnipotence was matched only by their strikingly human, self-indulgent caprice.

Over the years, I committed to memory the elaborate organizing logic of Greek antiquity. The immortal residents of Mount Olympus—philandering Zeus and his cascading (sometimes circular) family tree—governed every aspect of human existence. I was daunted by such a deterministic universe, in which the free will of mortals counted for so little. Yet I was compelled, even comforted, by the coherence of this worldview, in which one’s life was entirely foretold.

The Greek writer Kay Cicellis, who died in 2001, might have shuddered at such a sunny view of fate. One year before Ingri and Edgar Parin D’Aulaire published their compendium of Greek myths, Cicellis released her second work of fiction, The Way to Colonos, which ruthlessly dramatizes the limits of individual freedom and the agony of facing one’s powerlessness. The book has recently been reissued at what feels like a propitious moment, when modern treatments of Greek myth proliferate, many of them adapting stories about destiny and order for a chaotic and individualistic time.

Cicellis’s book consists of three stories that parallel Sophoclean tragedies—“The Way to Colonos” (Oedipus at Colonos), “The Return” (Electra), and “The Exile” (Philoctetes). In an author’s note, Cicellis calls any connection to the Greek playwright’s work a “coincidence”: She was inspired by the original myths, rather than the plays based on them. Each of Cicellis’s retellings transforms its myth into a short story set in mid-20th-century Greece, juxtaposing an ancient sense of fate against the messy uncertainty of modernity. In The Way to Colonos, the horror that emerges is more suppressed and internal than in the ancient texts. The violence is psychological and rarely fatal, in marked contrast to that in Sophocles’s work (in other words, nobody gouges out their eyes after having mistakenly slept with their own mother). And unlike Sophocles’s plays, in which the deities are persistently invoked, Cicellis’s universe is spiritually arid. Her discontented characters seem to wander beneath an empty firmament.

But make no mistake: This is not a world of freedom and abandon. Each of Cicellis’s young protagonists arrives at the grim realization that their life is circumscribed not by a god but by the pull of obligation to an undeserving parent or mentor. In these stories, Cicellis presents fate as the imposition of familial or vocational inheritance, rather than the decree of a higher power. It is something silently assumed, perhaps even chosen—if only because no other choice seems possible.

Read: Don’t judge I’m Glad My Mom Died by its title

In the first story, “The Way to Colonos,” Antigone and her infirm, recently widowed father sail to the titular island, an isolated and inhospitable place, to make a new home. Antigone views their relocation as a dual exile: Both of them have committed “evil” acts, “indigestible as stone.” Antigone had an affair with a married man. Her father, after quarreling with Antigone’s mother, locked her out of their house overnight, which led to a terrible accident. Antigone hopes that on the island, her father will join her in “complete despair,” a mental state characterized less by remorse than by self-abasing catatonia. For Antigone is a merciless judge; she regards both her father and herself as unworthy of rehabilitation, or even the oblivion of death.

“The Return” foregrounds another relationship between parent and daughter, though this one is much more tempestuous. Eugenia (a version of Electra) lives in a filthy house with her lazy, corrupt mother, Madame Nini, and Madame Nini’s lover. The home is always swarming with visitors, many of them young women. Eugenia wonders bitterly if Madame Nini and her lover are running a brothel, or perhaps an underground abortion network.

As disgusted as she is by her mother, Eugenia is equally obsessed with her. She skulks around the house, scheming for opportunities to pick a fight. She writes constantly to her younger brother, Orestes, begging him to return from school and reestablish domestic order. When he does come home, he is repulsed by the squalor of his mother’s house and by the violent antagonism between Madame Nini and Eugenia. He presses Eugenia to leave with him.

Eugenia has other ideas. “Orestes! Kill her!” she demands, in response to his proposal. But unlike his Sophoclean namesake, Orestes is bewildered by this escalation and refuses. Ultimately, Eugenia binds herself to Madame Nini, “like a seaman on deck who has cut off the moorings of his ship and abandoned himself to his element.” In Sophocles’s play, the final acts of violence provide a kind of catharsis. By contrast, Eugenia condemns herself to a future of festering tension and fury.

Cicellis’s third revised myth, “The Exile,” foregrounds a nonfamilial intergenerational bond. Stamos, 19, is a version of Neoptolemus, son of the warrior Achilles. He serves as a squire of sorts to Greek guerrilla soldiers who, after the Second World War, operated as Communist resistance forces in the mountains. At the start of the story, he has traveled to an obscure island in order to convince Rigas, an exiled former commander, to return to the ranks. Stamos quickly romanticizes the soldier’s isolation—his freedom from social expectations—and begins to dream of defecting. Rigas actually detests his remote existence, but he adopts the persona of a rugged maestro who lives off the land. Eventually, he is forced to drop the charade. “You offered me a role. I took it,” Rigas explains to Stamos. “You gave me something to be. What did you expect?”

Unlike with Antigone and Eugenia, whose perceptions of their respective parents curdled long ago, the reader watches Stamos experience disillusionment. Reverence for one’s elders, Cicellis implies, is a dangerous kind of fan fiction. Nonetheless, Stamos’s disappointment does not prompt him to sever ties with the guerrillas, and he follows them back to the harbor, just as both Antigone and Eugenia adhere to their wretched parents.

Rachel Cusk, who wrote the foreword to the new edition of Cicellis’s trilogy, argues that the author’s “young protagonists claim as a freedom the right to hate or disapprove of the adults who hold so-called authority over them, when the forces of tragedy and fate have decreed that no such freedom exists.” In my view, this reading gives the characters more agency than they seem to think they have. Cicellis’s young characters may despise the elders in their orbits, because even a universe governed by fate does not dictate human emotion. But that is not freedom: They are otherwise impotent, incapable of emancipating themselves from the adults who have harmed or disappointed them.

Read: Kaos offers a sharp twist on a familiar story

There is something dreadful in the resignation depicted at each story’s denouement—in the cool viciousness of Antigone’s sense of justice, and in Eugenia’s realization that while her mother lives, she must be at her side. The brutality of “The Exile” manifests in its portrayal of enlightenment rendered powerless: Stamos learns that Rigas isn’t who he thought he was, and yet he does not reject him. If these adaptations retain the solemnity of a Greek myth, it is less because of their source material than because their young characters come to understand their lives as roles they are bound to enact. Tragedy, in The Way to Colonos, emerges from its protagonists’ obliterating desire to follow the story that is most legible to them, in which they are most legible to themselves.

Cicellis understands what I was too young to realize in my earliest encounters with Greek mythology: that our fascination with these stories is fundamentally existential. What, in one’s life, is inevitable? What traits, decisions, or misfortunes exceed a person’s jurisdiction? These are enduring human quandaries.  The abundance of contemporary retellings and revisions, from Kay Cicellis’s trilogy to Emily Wilson’s 2017 retranslation of The Odyssey to Madeline Miller’s 2018 novel, Circe, expose an ongoing fascination with the tension between fate and control. In a modern world where free will is taken as a given, fate might be best understood as the tangle of powers that facilitate or obstruct individual wills. Perhaps it is our intuitive recognition of this dynamic—one not between gods and mortals, but between the free and the vulnerable—that brings us back to this ancient folklore, century after century.

​When you buy a book using a link on this page, we receive a commission. Thank you for supporting The Atlantic.</div>
        </div>
        
        <div class="card" onclick="openModal('content-24')">
            <div class="source">Slashdot</div>
            <div class="title">Anna's Archive Loses<nobr> <wbr></nobr>.Org Domain After Surprise Suspension</div>
            <div class="meta">2026-01-06</div>
        </div>
        
        <div id="content-24" style="display:none;">
            <h2>Anna's Archive Loses<nobr> <wbr></nobr>.Org Domain After Surprise Suspension</h2>
            <p><strong>Slashdot | 2026-01-06</strong></p>
            <a class="original-link" href="https://yro.slashdot.org/story/26/01/05/2255256/annas-archive-loses-org-domain-after-surprise-suspension?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

What the large print giveth, the small print taketh away.</div>
        </div>
        
        <div class="card" onclick="openModal('content-25')">
            <div class="source">Slashdot</div>
            <div class="title">Corporation for Public Broadcasting To Shut Down After 58 Years</div>
            <div class="meta">2026-01-06</div>
        </div>
        
        <div id="content-25" style="display:none;">
            <h2>Corporation for Public Broadcasting To Shut Down After 58 Years</h2>
            <p><strong>Slashdot | 2026-01-06</strong></p>
            <a class="original-link" href="https://entertainment.slashdot.org/story/26/01/05/235245/corporation-for-public-broadcasting-to-shut-down-after-58-years?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Want to read Slashdot from your mobile device? Point it at m.slashdot.org and keep reading!

trump did not try to force an TV license?

trump did not try to force an TV license?His advisors told him that he wouldn&#39;t be able to get a cut. Not even a measly 5%.

trump did not try to force an TV license?

His advisors told him that he wouldn&#39;t be able to get a cut. Not even a measly 5%.

Since the Corporation for Public Broadcasting has no funding any more, dissolving it will have zero effect going forward. Except, perhaps, to avoid running up debt they have no funding to pay.

NPR and PBS will, indeed, continue with funding from &quot;viewers and listeners like you.&quot; The local NPR station here has, I believe, actually seen an increase in overall funding because their listeners have stepped up. They won&#39;t say it out loud, but they&#39;re not laying people off or reducing programming. The same will be

I also remember having free access to video editing equipment, and camera&#39;s if I wanted to produce anything myself, I&#39;m sure that will go away too..Sounds like public access TV which is funded with fees added to cable TV subscriptions. As usual unclear where this money ended up. Let&#39;s start with a list of people who received $1 million or more, and check for death certificates!

I also remember having free access to video editing equipment, and camera&#39;s if I wanted to produce anything myself, I&#39;m sure that will go away too..

Sounds like public access TV which is funded with fees added to cable TV subscriptions. As usual unclear where this money ended up. Let&#39;s start with a list of people who received $1 million or more, and check for death certificates!

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

What the large print giveth, the small print taketh away.</div>
        </div>
        
        <div class="card" onclick="openModal('content-26')">
            <div class="source">Slashdot</div>
            <div class="title">Lego's Smart Brick Gives the Iconic Analog Toy a New Digital Brain</div>
            <div class="meta">2026-01-06</div>
        </div>
        
        <div id="content-26" style="display:none;">
            <h2>Lego's Smart Brick Gives the Iconic Analog Toy a New Digital Brain</h2>
            <p><strong>Slashdot | 2026-01-06</strong></p>
            <a class="original-link" href="https://games.slashdot.org/story/26/01/05/217258/legos-smart-brick-gives-the-iconic-analog-toy-a-new-digital-brain?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Want to read Slashdot from your mobile device? Point it at m.slashdot.org and keep reading!

One block for every C keyword and data type to build a physical program.That would make the Technics series awesome and me never leave the house again. Probably.

I have wondered about how an evil AI overlord can transcend into the physical world.

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

What the large print giveth, the small print taketh away.</div>
        </div>
        
        <div class="card" onclick="openModal('content-27')">
            <div class="source">Slashdot</div>
            <div class="title">GNOME and Firefox Consider Disabling Middle Click Paste By Default</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-27" style="display:none;">
            <h2>GNOME and Firefox Consider Disabling Middle Click Paste By Default</h2>
            <p><strong>Slashdot | 2026-01-05</strong></p>
            <a class="original-link" href="https://tech.slashdot.org/story/26/01/05/2059225/gnome-and-firefox-consider-disabling-middle-click-paste-by-default?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Follow Slashdot blog updates by subscribing to our blog RSS feed

They are worrying about inadvertent middle click when you have browsers that try to force you into using the address bar for other things. The address bar should be the address bar and nothing else. And that address should always display the FQDN that you are connecting to, not just the domain. Also, they need to stop text fields from being able to capture the cursor automatically. How many times have people clicked on a link and while waiting for the site to load went and did something else only to have the browser force grab the cursor while you are typing other things, potentially critically private things. Also close the loophole where a site can see where a mouse is and what you are doing on the page. F* the advertisers, build the browser for the users and nothing else. Reply to fingerprinting requests with the same response from every browser. So many loopholes that need to be closed before worrying about something like the middle click.

If only you were a customer, maybe they would address these issues that you have raised.  Clearly, they are listening to their customers and not their end users.

How many times have people clicked on a link and while waiting for the site to load went and did something else only to have the browser force grab the cursor while you are typing other things, potentially critically private things. What window manager or desktop environment do you use? (I use *box and KDE and I&#39;ve never had that particular problem.)

How many times have people clicked on a link and while waiting for the site to load went and did something else only to have the browser force grab the cursor while you are typing other things, potentially critically private things.

What window manager or desktop environment do you use? (I use *box and KDE and I&#39;ve never had that particular problem.)

I just used it to log in to Slashdot from my passcode manager. I&#39;ve no idea what any of my passcodes are. Double or triple click in the passcode manager followed by middle click does the job.

The middle click isn&#39;t in the least bit confusing, I love it, I sometimes use it maybe 30 times in a day.

Please whoever is listening, don&#39;t disable it.

It says disable &quot;by default&quot;. For Firefox it is controlled by about:config setting clipboard.autocopy, which is currently set to true by default on linux platforms, and false on Windows https://kb.mozillazine.org/Cli... [mozillazine.org] I imagine they are considering swapping it to false on new installs on linux.

No one is listening.The cake is a lie.In space no one can hear you scream.

One of the best features of Unix is cut-and-paste with only using the mouse.  I recently started using a Mac for my work desktop, and I really miss it.  At least it works within iTerm2 and emacs, but not between programs.

Sure, perhaps have an option to turn it off, but don&#39;t break one of the best features of Linux just because too many people don&#39;t know how to use it.

I think middle button paste is awesome too. The benefits of middle paste out number the cons.

I love middle-click-paste.  I could live with Mozilla et al. disabling it by default providing they give you a way to re-enable it.  However, I fear that this is just step 1 and then step 2 will be to completely remove support for it.

Yes, it&#39;s important to appeal to newbie users.  But it&#39;s also important not to alienate long-time power users.

>&quot;Both GNOME and Firefox are considering disabling middle-click paste by default, arguing it&#39;s a confusing, accident-prone X11 relic that dumps clipboard contents without warning.&quot;

PLEASE DO NOT.  How about having an environment variable and LETTING THE USER DECIDE.  I use middle-click pasting all the time.  PLEASE DO NOT use the stupid gsettings stuff.  I don&#39;t use GNOME, and that stuff is annoying and confusing.

And this crap Firefox does with single clicking in the URL bar  selecting the ENTIRE LINE is

That&#39;s funny, MacOS works just fine with multiple buttons, and happily pops up a context menu when I right click on something. Oh, I&#39;m sorry, it might be a bit slow to load this webpage back there in 1999, the last year when this wasn&#39;t the case.

MacOS works just fine with multiple buttons

Perhaps I should have said Apple. I believe they still supply a one-button mouse?
Similarly a PC laptop will just have a 2-button touchpad.
So I have a 3-button (well, 7 actually) mouse that I use with it so that I can be more productive.

It would be more useful if people advertized what these features are, rather than turn them off.

The goal of the GNOME developers is to find features they can remove to piss off the most amount of users with the least amount of effort, then to troll the bug reports with smug, dismissive answers. It&#39;s their primary development cycle. It&#39;s been that way since &quot;The Spatial Way.&quot;  Their attitude is so bad that random, well-intentioned devs are driven to near insanity from glancing run-ins with them: https://felipec.wordpress.com/...  [wordpress.com]

And Firefox is a rudderless empty vessel that&#39;s been adrift for years.

middle-click paste by default, arguing it&#39;s a confusing, accident-prone X11 relic that dumps clipboard contents without warning. 
Noting that a user-initiated middle-click precedes it.

middle-click paste by default, arguing it&#39;s a confusing, accident-prone X11 relic that dumps clipboard contents without warning.

Noting that a user-initiated middle-click precedes it.

... PC mice only had two buttons (one for a mac). Only those weird UNIX systems had a middle button. For some reason, three button functions became the norm, whether an actual third button or the click function of a scroll wheel. Popular demand in action.

If you want to Ctrl-C, Ctrl-V, go right ahead. Don&#39;t like the middle button? Don&#39;t use it. I&#39;m not certain, but it seemed to me that this was an OS UI &quot;style&quot;. One button on a Mac, two on a Windows machine and three on the various *NIXes. Not per applicat

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

What the large print giveth, the small print taketh away.</div>
        </div>
        
        <div class="card" onclick="openModal('content-28')">
            <div class="source">Slashdot</div>
            <div class="title">Viral Reddit Post About Food Delivery Apps Was an AI Scam</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-28" style="display:none;">
            <h2>Viral Reddit Post About Food Delivery Apps Was an AI Scam</h2>
            <p><strong>Slashdot | 2026-01-05</strong></p>
            <a class="original-link" href="https://tech.slashdot.org/story/26/01/05/2050220/viral-reddit-post-about-food-delivery-apps-was-an-ai-scam?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Want to read Slashdot from your mobile device? Point it at m.slashdot.org and keep reading!

1099 laws need to be updated to stop the abuse as the level of control in some gig work may make the workers at the very least an part time w2 for the booked job.

If you&#39;re using a library&#39;s Wi-Fi out of fear that people might track your online activities, then having an AI rephrase this post to hide your writing style could be seen as exhibiting a similar level of paranoia. This message was changed by an AI, so you have no way of knowing who the actual author is.

The comment says it all.  We have not seen the last of these AI-improved scams.

Uber spokesperson says, &quot;This story that seems completely factual about practices people continually complain about us doing must be completely made up because uh... uhm, AI and stuff. I mean, you should totally trust AI to do everything, but when you commoners use it, it&#39;s to make stuff up about us corporations who are loving, giving caretakers of society. Oh, yeah, and this can&#39;t be about us. Because it&#39;s made up. Yeah, that&#39;s it. That&#39;s the ticket!&quot;

Using AI to write your complaint is a perfectly valid use of AI.  It maintains your points, cleans up the language, and makes it impossible to say who the author is just by the writing style.

The question is entirely whether the accusations are true.

And gig companies are absolutely exploiting workers and customers, while the specific details listed may or may not be true.

If you work 40 hours a week and can&#39;t afford a house, a car, a family, putting your kids through college, and an annual multiweek vacation, you&#39;re being robbed by your boss.

I saw this about an hour/hour and a half ago on the front page in a red highlight. it was around the VSCode story.  Then it disappeared until now.

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

What the large print giveth, the small print taketh away.</div>
        </div>
        
        <div class="card" onclick="openModal('content-29')">
            <div class="source">Slashdot</div>
            <div class="title">Amazon's AI Assistant Comes To the Web With Alexa.com</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-29" style="display:none;">
            <h2>Amazon's AI Assistant Comes To the Web With Alexa.com</h2>
            <p><strong>Slashdot | 2026-01-05</strong></p>
            <a class="original-link" href="https://slashdot.org/story/26/01/05/2041210/amazons-ai-assistant-comes-to-the-web-with-alexacom?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Want to read Slashdot from your mobile device? Point it at m.slashdot.org and keep reading!

as if we didn&#39;t already have enough SLOP.

Damn, we really liked the Alexa better before they started using their AI in the background.  Now voice recognition is nowhere nearly as good, it frequently moves our music when resuming after a pause to some other device, and generally seems dumber overall.  Now they&#39;re going to make it worse?  Drat.

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

What the large print giveth, the small print taketh away.</div>
        </div>
        
        <div class="card" onclick="openModal('content-30')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">The Once Secret Memo That Justifies Trump’s Venezuela Invasion Is Dangerously Wrong</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-30" style="display:none;">
            <h2>The Once Secret Memo That Justifies Trump’s Venezuela Invasion Is Dangerously Wrong</h2>
            <p><strong>News and Politics - Slate Magazine | 2026-01-05</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2026/01/secret-memo-trump-venezuela-invasion-illegal.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Sign up for the Slatest to get the most insightful analysis, criticism, and advice out there, delivered to your inbox daily.

President Donald Trump’s military operation to capture Venezuelan President Nicolás Maduro is flatly illegal under international law and almost certainly illegal under federal law—an unauthorized use of force against a foreign nation that pushes executive power past its breaking point. Yet there is no real chance that the courts will curb it, even as the mission evolves into a possible occupation of Venezuela and an expansion of hostilities to its neighbors. Nor is there any signal that Congress will impose restraints on what appears to be the dawn of a new conflict overseas, surrendering its constitutional war powers to Trump without objection. And even if Congress does try to assert its authority to oversee (or end) military action in South America, it will face an uphill battle in a judiciary that persistently favors the commander in chief.

This inversion of our constitutional order sets a perilous precedent that even many celebrating Maduro’s fall may come to regret. It marks the death knell of the post–World War II settlement that, however imperfect, wrestled the anarchy of war into a framework designed to condition armed aggression on legal justification. The executive branch’s consolidation of power now reverberates far beyond the United States’ shores as a saber-rattling president abandons any pretense that the law can constrain his resort to military force. Indeed, the legal theories the administration has floated to defend its actions draw on a historical source Trump once disavowed: the arch-interventionist claim that the U.S. has an inalienable right to police the world.

It is difficult to tally all the ways in which the Maduro operation was illegal, but start with a point that few dispute: This act violated international law. Trump’s invasion of Venezuela to capture its president cannot be squared with Article 2(4) of the U.N. Charter, which bars member nations from deploying “the threat or use of force against the territorial integrity or political independence of any state.” This principle—the most important rule of international law today—should bind the United States, which ratified the charter in 1945. And it clearly prohibits the American government from invading another country to make an arrest.

Yet Mike Waltz, Trump’s ambassador to the United Nations, did not even pretend that the administration complied with Article 2(4) in his address to the U.N. Security Council on Monday. Instead, Waltz rejected the premise that this rule should apply to Venezuela at all, because Maduro was an “illegitimate narco-terrorist” and “fugitive from justice.” Of course, if a country can disregard the U.N. Charter whenever it concludes that another nation’s leaders have given up their claim to “territorial integrity or political independence,” then the charter means nothing. Arguably worse was Waltz’s insistence that Venezuela’s vast “energy reserves” also justified the action, a motive Trump has laid bare from the start. It should go without saying that the charter does not, under any circumstances, permit one nation to invade another to secure control over its natural resources.

So what is the government’s legal defense of its military incursion into Venezuela? The administration purports to be following the Panama precedent of 1989—when President George H.W. Bush ordered the military invasion of Panama to arrest its dictator, Manuel Noriega, ostensibly so he could stand trial in the U.S. But this episode was not approved by Congress (which found out just hours before) or the U.N. (which condemned it) or a federal court (which never passed on its legality). Instead, the Department of Justice’s Office of Legal Counsel justified the aggression in a secret memo signed by William Barr, who would go on to serve as attorney general for the first Bush and Trump.

In that memo, Barr claimed that the president has inherent constitutional authority to conduct extraterritorial arrests for violations of U.S. law. Even if those arrests require complex military incursions into foreign nations, he wrote, they remain within the president’s inherent powers and do not require congressional approval. Barr further asserted that these arrests did not have to comply with Article 2(4) of the U.N. Charter. That provision, he wrote, does not actually bind the executive branch because it is not “self-executing,” freeing the commander in chief to disregard it.

This conclusion was obviously wrong: Even if the charter cannot be enforced by federal courts, it remains binding on the executive branch and is a law that the president has a constitutional duty to faithfully execute. The memo was so absurd, in fact, that the DOJ did everything in its power to conceal it, as New York University law professor Ryan Goodman has documented. After Congress demanded to see Barr’s memo, the department refused, even failing to comply with a subpoena ordering its disclosure. When Barr eventually testified about its contents under oath, he omitted its assertion that the president can “override” the U.N. Charter (a legal justification that made up a mere four paragraphs). The Clinton administration finally released the memo in 1993, and in the years since, legal experts have derided it as “deeply counterintuitive and indefensible,” “fundamentally flawed,” “preposterous,” and utterly “bereft of citation to supporting authority.”

But embrace, for a moment, the nihilism of Barr’s memo and assume that international law imposes no legitimate constraints on the president’s use of force. Even then, Trump’s actions in Venezuela would still be illegal—or, most generously, an egregious distortion of the constitutional war powers. It is Congress, after all, that has the authority to declare war and must authorize use of military force. The president is the commander in chief, the civilian leader of the armed forces, but he holds no independent power to commence hostilities. Needless to say, Congress has neither declared war on Venezuela nor authorized military force within its borders.

From where, then, did Trump derive authority to invade Venezuela? As Harvard Law professor Jack Goldsmith has explained, the administration evidently contrived it from its desire to arrest Maduro on federal charges. The logic goes like this: The DOJ sought to take the dictator into custody on charges of drug trafficking. It could do so only by storming Venezuela. That operation would require protection from the military. And as a matter of “unit self-defense,” these accompanying troops had a right to bomb, shoot, and otherwise overwhelm any threats to the mission through lethal force. This rationale is quintessential bootstrapping: The alleged goal of trying Maduro in the U.S. gives Trump permission to launch a hostile incursion into a sovereign nation, whose ramifications may well give rise to a broader regional conflict.

Georgetown Law professor and Slate contributor Steve Vladeck has laid out the danger of this shameless maneuver: It subverts the constitutional order by allowing the president to set off offensive military operations under the pretext of carrying out an arrest warrant on foreign soil. If troops face any resistance, they can escalate with further use of force, sliding quickly toward war—all without authorization from the legislative branch. So the Trump administration’s apparent rationale is less of a loophole than a complete end run around Congress’ war powers with no limiting principle in sight.

Despite all this, no one seriously thinks that any federal court will slow or stop Trump’s attacks in Venezuela and its neighbors. Americans seem to have consigned ourselves to the reality that legal constraints on the commander in chief’s operational decisions are entirely theoretical, with no meaningful mechanism for enforcement. Congress has handed over to the president more and more of its authority over foreign affairs. The Supreme Court has persistently forbidden federal judges from second-guessing the executive branch’s use of military force. (That’s why the Trump administration’s legal defense comes not from a court decision but from a self-serving opinion produced by the Department of Justice.) And the rest of the world has no means to secure accountability for the United States, which does not even recognize the jurisdiction of the International Criminal Court.

So Trump, already a “unitary executive” at home, becomes a kind of ersatz emperor abroad, bound by no law of nations, no treaty or charter, no checks but those he elects to honor. The post–World War II consensus, as enshrined in the U.N. Charter, rejected this kind of unbridled aggression as an invitation to perpetual conflict. Trump, in turn, rejects that consensus. It may be tempting to ignore the consequences of this radical new doctrine when it is wielded against an illegitimate dictator like Maduro. But Trump is already threatening action against Colombia, Cuba, Iran, and even Mexico, a liberal democracy with a legitimately elected president. The end point, it seems, is whatever this president says it is. That theory of American dominance does not merely push legal limits. It subordinates law to the logic of conquest.

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-31')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">This Isn’t a Regime Change</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-31" style="display:none;">
            <h2>This Isn’t a Regime Change</h2>
            <p><strong>News and Politics - Slate Magazine | 2026-01-05</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2026/01/venezuela-regime-change-maduro-trump-rubio-oil.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">On Saturday morning, in what the Trump administration dubbed Operation Absolute Resolve, Delta Force commandos entered the compound of Venezuelan President Nicolás Maduro and extracted him from his own country. They took his wife too, and killed dozens of Venezuelans in their path.

Members of the administration say this was about accountability. Attorney General Pam Bondi says Maduro is about to face the “full wrath of American justice.” She alleges he’s been running Venezuela as a narco-state.

Shane Harris, a staff writer covering national security and intelligence at the Atlantic, says the administration’s actions are not surprising. Since September, the United States has been obliterating fishing boats off Venezuela’s coast and calling it a drug war.

The logic behind Maduro’s extradition is equally hard to explain. And Harris doesn’t want to call it a regime change. The regime remains in place: The vice president is now the interim president.

“That’s still the regime,” he says. “And now I think the United States is not running Venezuela, as President Trump said they were going to do. I think that the United States is essentially holding Venezuela at gunpoint and saying to the new interim president, You’re going to do what we want and govern the country according to these demands, or you’re going to face consequences.”

On a recent episode of What Next, host Mary Harris tries to answer a few of the bigger questions about what just went down in Venezuela. This transcript has been edited and condensed for clarity.

Mary Harris: I think some people would look at what’s happened over the weekend and say, “Oh, are we at war with Venezuela?” So are we?

Shane Harris: No. Look, we’ve taken hostile action against Venezuela. Could Venezuela say we’re at war with them? Sure. Yes. We invaded their country. I mean, we violated their territorial sovereignty. But Congress has not declared war.

Marco Rubio, the secretary of state, says this is primarily a law-enforcement action because members of the FBI were there to serve papers to Maduro. That is not normal, right?

No, that’s not normal. In the most technical sense, the mission that occurred over Caracas was the Department of Justice issuing an arrest warrant on the president of Venezuela and his wife, escorted by the U.S. military. That’s one hell of an escort. So, sure, in a very narrow, technical sense that is true, but that obviously obscures the reality of what happened here.

What I thought was interesting about the whole law-enforcement-operation framing of this was that Donald Trump was not reading from that script when he was briefing reporters. And in many ways, he seemed to go off script. He talked about this as removing a corrupt dictator and getting Venezuela to pay back what was stolen—to use his words—from the United States in terms of oil and oil revenues. And you could see, both in the other officials who were briefing and in Rubio’s comments on the Sunday shows, an effort to try to walk this back and frame it a bit more narrowly. But the president does what he often does, which is he goes off script. He gets grandiose in his explanations. And that points to the fact that there is no coherent strategy for what is happening right now.

My understanding of things is that Maduro was offered the opportunity to go into exile in Turkey. And he was like, “Oh, thank you.” And they’re like, “All right, we’re coming to get you.” So there were clearly weeks of, if not negotiation, discussion or raising of stakes.

From our reporting and that of other journalist colleagues, the administration wanted him to leave peacefully, go into this kind of gilded exile, as it has been described. The question remains, then: Who was going to replace him? Who would come next? And that seems to be the part that they haven’t quite figured out yet.

There were those clearly within the anti-Maduro camp, both in the administration and publicly, who wanted to see him go and be replaced with possibly the person who everyone agrees actually won the election for president in 2024, Edmundo González, or even with María Corina Machado, the Nobel Prize winner who has been such a huge force for democracy and activism in Venezuela.

Machado was banned from running, so she ran someone else in her stead, but it was sort of as if a vote for him was a vote for her. But Machado has been thanking Trump. She’s very deferential to him, clearly aiming for this goal of “OK, and I’ll take over.” But that’s not what happened.

It’s not what happened, and he was quite dismissive of Machado in his comments in Florida this weekend, essentially saying that she doesn’t have the respect in Venezuela, that there’s not really support for her. This is a very strange argument for him to make. And I think it’s a false argument because everybody agrees, including people in the Trump administration, that González, the candidate who essentially ran in her stead, won by a healthy margin. He is actually the legitimately elected leader of Venezuela. The United States has been saying that for months and months now. So why, then, is the person to replace Maduro his own vice president? Why are you sticking with the same regime?

The vice president, Delcy Rodríguez, got in front of cameras and was basically like, “Maduro is our president, and these people are trying to take our oil.” She doesn’t seem to be a pliant member of Team America here.

Yeah, at least not outwardly. We do have to hold open the possibility that there’s been some behind-the-scenes discussions. There has been reporting that she was in conversations with people in the Trump administration, saying, “If Maduro goes, I can take over, and maybe we can work something out.”

She’s known for straightening out the oil industry in Venezuela, making sure they could make money off it. Doesn’t she have a kind of tangled personal history and reasons not to maybe want to have this American oversight?

She is in the mold of Hugo Chávez and Maduro. This is not somebody who is the pro-democracy, pro-America kind of figure that we would expect to see in some of the other alternatives. She has impressed people in the West and in the U.S. and the administration as a competent technocrat. She is somebody we can do business with. That is how the Trump administration sees her.

What do you think is going to happen in Venezuela now? Who is in charge, and what does that mean for the actual people of Venezuela?

The next step—and this is what we should be watching for in the next couple of days—is some kind of signal or statement from Rodríguez about whether she is willing to negotiate with the U.S. [Editor’s note: Following the taping of this episode, Rodríguez issued a statement on Instagram, including this message: “We invite the US government to collaborate with us on an agenda of cooperation oriented towards shared development within the framework of international law to strengthen lasting community coexistence.”] Rubio has been very clear on behalf of the administration in laying out the demands and what he wants to see action on. And so now we will see if she can at least pay lip service to that in the coming days. I think that will go a long way toward lowering the temperature.

If she continues to be defiant—and, in the way that she was right after Maduro was captured, saying, “He is the legitimate president, we demand that he be brought back right now, we will not be colonized by anyone”—then you’re going to see that temperature raise back up, and that’s going to increase the likelihood that Trump will use military force again. What that looks like afterward I’m not even sure the administration knows. I’m not sure they’re thinking that far ahead.

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-32')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">It Remains Unclear Who’s Running Venezuela—and Who’s Actually Running U.S. Foreign Policy</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-32" style="display:none;">
            <h2>It Remains Unclear Who’s Running Venezuela—and Who’s Actually Running U.S. Foreign Policy</h2>
            <p><strong>News and Politics - Slate Magazine | 2026-01-05</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2026/01/venezuela-trump-maduro-threaten-run-marco-rubio.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Sign up for the Slatest to get the most insightful analysis, criticism, and advice out there, delivered to your inbox daily.

Two days after the U.S. military action that forced Nicolás Maduro out of power and into a New York courthouse, two big questions remain: What happens next in Venezuela—specifically, who’s in charge? And, related to that: Who’s in charge of U.S. foreign policy?

At his Saturday press conference, where he announced the nabbing of Maduro, President Donald Trump said—to widespread astonishment—that the United States will soon “run,” or even is now “running,” Venezuela.

The next morning, on NBC’s Meet the Press, in an only slightly less baffling moment, Marco Rubio, Trump’s secretary of state and national security adviser, backpedaled on his boss’s claim. Asked whether the U.S. will really run Venezuela, Rubio replied, “Yeah, I keep [seeing] people fixating on that.” He continued: “The bottom line is, we expect to see changes in Venezuela. … It’s not running the—it’s running policy, the policy with regards to this. We want Venezuela to move in a certain direction” that would be “good for the people of Venezuela … [and] in our national interest.”

First, there should be no mystery why people are “fixating” on Trump’s claim. It’s because, in the course of his Saturday press conference, the president said 12 times that he and a group of his choosing, including Rubio himself, would “run” Venezuela.

Second, there is a distinction between running a foreign country and influencing its direction, even when this influence stems from a U.S. naval armada that remains off Venezuelan shores and an explicit threat from Trump to send in a second, larger wave of U.S. troops to enforce our influence.

Hence the question: Who is running American foreign policy—the president or his chief foreign policy adviser?

The question isn’t trivial. First, the answer will shape what happens next in Venezuela—who governs, to whose benefit, and with what level of internal freedom and stability? Second, it could shape what lessons other countries—friends and foes—take from Operation Absolute Resolve, the quite large and impressive military action that unfolded in the wee hours on Saturday. Will Russian President Vladimir Putin see the claim of unabashed regional imperialism as a winking green light to his claim of control over Ukraine? Will Chinese President Xi Jinping infer the same about his claims over Taiwan? Will the mullahs of Tehran take it as grounds for fear of an impending U.S. attack? How seriously will Cuba’s leaders take Trump’s—and Rubio’s—warnings that as goes Caracas will soon go Havana, whether by U.S. attack or self-immolation?

Given the regional and global stakes, one might think that Trump and his team would have worked out a unified message to explain and justify this audacious (to say the least) military action. Instead, this is just another case in point that Trump’s actions often have no underlying strategy—which is to say, no clear idea of how to link means and ends: or, in this case, just what the desired ends are.

Some of those ends are clear, as Trump laid out on Saturday and as neither Rubio nor any of the other officials flanking him contradicted: the desire for sole domination of the Western Hemisphere (as had been spelled out in his National Security Strategy document) and the desire for control of its oil and the wealth it produces.

Leaving aside the wisdom and legality of those goals, the press conference and Rubio’s subsequent caveat made clear that the administration has not thought through just how to obtain them—i.e., it’s clear they have no strategy.

If Trump is serious about “running” Venezuela, how, and through what agent, does he plan to do this? He said that Maduro’s former deputy, Delcy Rodríguez, who has now been sworn in as his interim successor, was an acceptable intermediary, and that Rubio is working with her. (Rodríguez herself, a longtime fiery Maduro associate who at first denounced the abduction, has since said she’s willing to “collaborate” with the U.S. to redevelop her country, though added, perhaps wishfully, that she wouldn’t let it become a U.S. colony.)

The same question applies if Rubio’s slightly less coercive notion of merely influencing the country’s policy applies. Maduro’s ministers remain in charge; the Venezuelan military retains ultimate power, offering security and oppression, assisted by at least 20,000 Cubans, many officers and some health care workers who have provided health care in exchange for Venezuelan oil. Will the military now be swayed toward northern-leaning sentiments, given the evaporation of the wages that Maduro provided and the continuing blockade of the country’s oil for as long as they refuse to budge? Some insiders were apparently bought off during the planning of the incursion. The CIA had recruited at least one person close to Maduro to keep track of his movements; it’s reasonable to assume that wasn’t the only spy.

And what about the democratic opposition? Trump shoved aside any role in a new government for María Corina Machado, the movement’s leader, saying, “She doesn’t have respect in the country.” And he said nothing about the leader of her party, Edmundo González Urrutia, who legitimately won the 2024 election and who fled in exile to Spain after Maduro, who was soundly defeated, held on to power. Machado, who won the Nobel Peace Prize for her valiant struggle (perhaps to the bitterness of Trump, who many times said he deserved it), issued a statement, calling on Urrutia to be brought back to lead the country. Will the democrats on the streets and elsewhere second her demands, or will they simply bow down to the continued reign of Maduro’s team just because it will now be tempered a bit by influence from Washington and the big oil companies?

This too has broader implications. The United States cannot easily claim to be leader of “the free world,” or even a champion of democracy, if it ousts a dictator—a feat that many Venezuelans cheer—but then does nothing to help restore the real, freely elected president.

There is also something a bit fishy about the official rationale for the military operation, which was to bring a criminal fugitive to justice, given that the U.S. extracted him through means that were likely in violation of international law. Yes, a U.S. grand jury indicted Maduro for drug smuggling back in 2020, and in the wake of his abduction this weekend, the Justice Department filed additional charges—most of them legitimate. (I say “most,” rather than “all,” because one of them, possession of a machine gun, seems an odd charge to level against a foreign head of state, however illegitimate he might be.)

Which leads to one more broad point. The United States has had a pretty successful record of overthrowing foreign leaders but a pretty lousy one of imposing order, or accomplishing whatever outcomes it has desired, in the aftermath. (Some obvious cases in point: Iraq, Afghanistan, Libya, Guatemala, and—going back several decades but one with enormous implications later on and ever since—Iran.)

A reporter at Saturday’s press conference asked Trump about this mixed record with previous presidents. His reply was evasive to say the least:

With me, that’s not true. With me, we’ve had a perfect track record of winning. … If you look at [the assassination of Qasem] Soleimani, you look at [Abu Bakr] al-Baghdadi, you look at the Midnight Hammer [the air raid on Iranian nuclear targets] … we have essentially peace in the Middle East because of that. … So, with me, you’ve had a lot of victory. You’ve had only victories, you’ve had no losses.

There are several disturbing things about this passage, quite aside from the fact that “peace in the Middle East” remains, in many ways, aspirational. The most pertinent here is that Trump seems to believe that a dramatic tactically successful strike—the killing of a terrorist leader, the bombing of a nascent nuclear facility, the signing of a multiphase 20-point peace treaty (but the accomplishment of just the first phase), and now the extraction of a horrible dictator—amounts to a strategic victory and the fulfillment of an ambitious policy.

Trump doesn’t think he has to care about what happens next in Venezuela or what he needs to do to make it happen, to improve the odds of success or reduce the odds of catastrophe, however those terms are defined.

In Operation Absolute Resolve, the U.S. military showed itself to be, as it has several times in recent years, an agile, effective, supremely coordinated instrument of national power. Whose resolve it enforces, to what ends, is another matter. The policymaking machinery at the top of America’s power structure is appallingly adrift.

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-33')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">Trump Just Betrayed His Most Die-Hard Supporters. They’re Cheering Him On Anyway.</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-33" style="display:none;">
            <h2>Trump Just Betrayed His Most Die-Hard Supporters. They’re Cheering Him On Anyway.</h2>
            <p><strong>News and Politics - Slate Magazine | 2026-01-05</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2026/01/trump-venezuela-invasion-maduro-abduction-maga.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Sign up for the Slatest to get the most insightful analysis, criticism, and advice out there, delivered to your inbox daily.

Donald Trump’s moves to invade Venezuela, abduct its president and first lady, invite global corporations to exploit its resources, and leave the nation’s feckless authoritarian regime largely intact range from blatantly illegal to facially insane. And the MAGA response to them is the most illustrative yet of the movement’s utter ideological and moral bankruptcy. This is a president who promised to put America first: He ran on isolationism, as well as an end to the era of wars of choice, foreign quagmires, and the U.S. as the world’s police officer. What Trump has offered instead: wars of choice, with America as the world’s plunderer—and his followers not only cheer but invent ridiculous pretexts to defend this utterly unjustifiable move.

Trump is clear: He does not care about restoring democratic governance to Venezuela. He doesn’t like Nicolás Maduro and wanted the spectacle of bringing him to the U.S. in handcuffs. He does like Venezuelan oil, and because he believes that American military power should allow him to grab whatever he’d like, he plans to take a lot of it. The administration likes to accuse Venezuela of flooding the U.S. with drugs, and in theory that’s one of the reasons Maduro is being prosecuted—but the former president of Honduras faced similar charges and received a pardon from Trump. The president says the U.S. plans to “run” Venezuela for … well, how long is unclear. He doesn’t plan to give a helping hand to María Corina Machado, the Venezuelan opposition leader who observers say won last year’s election but saw it stolen by the Maduro regime. She also recently won the Nobel Peace Prize that Trump believes he deserved, and her accepting it instead of refusing it and saying it should go to Trump is, according to some insiders, the reason he’s hanging her out to dry. (“If she had turned it down and said, ‘I can’t accept it because it’s Donald Trump’s,’ she’d be the president of Venezuela today,” one source told the Washington Post.) Instead, he’s backing Maduro’s No. 2, Vice President Delcy Rodríguez, whom Trump sees as more amenable to American oil interests.

In other words: He’s keeping Maduro’s disastrous despotic regime in place, just with a new figurehead. There seems to be no real plan to extract the U.S. from Venezuela. And now the president and his lackeys are threatening to invade other countries too: Cuba, Mexico, Colombia, Greenland.

This flies in the face of everything MAGA supposedly stands for. So what are MAGA loyalists doing in response? They’re lining up and making excuses.

Why did Trump pardon the Honduran president for what prosecutors deemed “one of the largest and most violent drug-trafficking conspiracies in the world”? Per Secretary of State Marco Rubio, “He felt that in that particular case there was unfairness.” (If you asked Trump himself: “The man that I pardoned was, if you could equate it to us, he was treated like the Biden administration treated a man named Trump,” he said. “This was a man who was persecuted very unfairly. He was the head of the country.”) Maduro, of course, was also the head of a country—but for some reason, that’s different.

What about Trump’s promise at his inauguration that “we will measure our success not only by the battles we win, but also by the wars that we end and, perhaps most importantly, by the wars we never get into”? Or, as Vice President J.D. Vance put it on the pages of the Wall Street Journal, “Trump’s Best Foreign Policy? Not Starting Any Wars.” Per that same Vance, who seems to be channeling the “Everyone Is 12 Now” theory of MAGA politics, starting wars is OK, actually, if you’re mad enough. “Are we just supposed to allow a communist to steal our stuff in our hemisphere and do nothing?” he asked on X.

As for whether we’re occupying Venezuela, that’s a no, unless it’s a yes. Rubio told Face the Nation that we aren’t. Sen. Tom Cotton claimed that Trump’s statement that the U.S. “runs” Venezuela actually “means the new leaders of Venezuela need to meet our demands.” But when asked who is in charge in Venezuela, Trump offered a clearer answer: “We’re in charge.”

But wait, isn’t MAGA an anti-interventionist movement? “This is not interventionism,” insisted Sen. Lindsey Graham, straining the possible meaning of the word interventionism beyond reality.

MAGA talking heads were even more blatant about justifying the invasion. Influencer Will Chamberlain, back in 2020, asserted that “the Republican Party is no longer the party of regime change and endless wars” and warned: “If you want to be its standard-bearer, that is a nonnegotiable position.” He is now cheering that “the future of American foreign policy isn’t regime change, but regime control.” Mike Cernovich didn’t shy away from the idea that America is turning Venezuela into a new American colony, arguing, “Occupation is moral when done correctly.” (What does a moral occupation look like? It means choosing “to rule a primitive people and extract resources for our benefits, with the Christian moral duty to elevate them.”)

“I’m as reflexively non-interventionist as anyone can possibly be,” wrote conservative provocateur Matt Walsh, “but Venezuela appears to be a resounding victory and one of the most brilliant military operations in American history.” After deeming international law “fake and gay,” he argued, “The only international law is that big and powerful countries get to do what they want.” I’m not sure what definition of noninterventionist translates to “Big and powerful countries get to do what they want, including intervene abroad,” but this is MAGA morality in one tweet: Whatever Trump does is good, words are meaningless, and there is no ideology except that whatever Trump does is good.

The usual MAGA defectors—Thomas Massie, Marjorie Taylor Greene—offered their usual criticisms that this isn’t what MAGA stands for. But the protests are starting to ring a little hollow after the 456th time the president said he would do something, then did the opposite. What is now apparent to anyone willing to see it is that there is no MAGA ideology. There is no moral core. There is no organizing philosophy. There is simply a reckless and self-interested president who desperately wants to be admired, who is a master of distraction, and who sees the White House as a very fine way to enrich him and his family.

There is much to distract from in this moment. We don’t hear a lot these days about the president’s old promise to “drain the swamp,” perhaps because it’s astoundingly obvious that the White House has never been swampier. The recently released secret testimony from special counsel Jack Smith clearly places the president at the head of a criminal conspiracy to undermine a free and fair election in the United States. Americans continue to struggle to afford basics, and Republicans just jacked up millions of people’s health insurance premiums. The release of documents related to Jeffrey Epstein’s sex crimes has not been flattering to the president, which is perhaps why his administration continues to withhold a great many of them. Trump’s deportation scheme is increasingly unpopular, as it turns out that most Americans don’t love the idea of a racist paramilitary force nabbing people off the street and shipping them to a Salvadoran torture prison.

“Start a war for oil to distract from problems at home” is the dumbest plot, but it seems to be our current storyline. And most of MAGA, a hollowed-out movement of unprincipled and morally vacant shills and sycophants, seems keen to play along.

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-34')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">A <em>Quinquennium</em> Is a Period of How Many Years?</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-34" style="display:none;">
            <h2>A <em>Quinquennium</em> Is a Period of How Many Years?</h2>
            <p><strong>News and Politics - Slate Magazine | 2026-01-05</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2026/01/trivia-quiz-daily-slate-vocabulary-slang-latin-movies.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Please enable Javascript in your browser to view Slate interactives.

Slate Crossword: Film in Which an Animal Pulls Off a Hat Trick? (11 Letters)

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-35')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">One of the Best New Year’s Resolutions You Can Make in 2026</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-35" style="display:none;">
            <h2>One of the Best New Year’s Resolutions You Can Make in 2026</h2>
            <p><strong>News and Politics - Slate Magazine | 2026-01-05</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2026/01/cbs-bari-weiss-trump-media-crisis-new-years-resolution.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Sign up for the Slatest to get the most insightful analysis, criticism, and advice out there, delivered to your inbox daily.

In 2026, there’s one easy resolution we should all commit to: Be better consumers of media.

Traditional media is in crisis, thanks to a combination of Trump administration attacks, corporate takeovers, and technological innovations. Social media sites compete for our attention by offering us addictive little bites: outrage-bait tweets and short-form shock-value TikTok videos, served up according to algorithms that track how long we linger and feed us more and more of what keeps us locked in (which is often what makes us angry).

For young people raised on smartphones, this has meant that most of them seem to lack the attentional ability to actually read news articles in their entirety. Only 15 percent of adults under 30 say they follow the news most or all of the time, and that statistic has declined since 2016, according to Pew. While the majority of Americans over 50 regularly seek out the news, young adults largely do not—70 percent of them say they see political news simply when they come across it, which happens largely via social media. Nearly 40 percent rely on “influencers” for news because, as one 21-year-old man told Pew, “if I agree with that person already, if I already have background with that person, then I’ll probably trust him more than some news site.”

This is troubling enough. Except now, some once legitimate news outlets are following suit and pledging to tell viewers what they want to hear and already believe, rather than what’s true and what it means. CBS, now helmed by former opinion writer and Substacker Bari Weiss, just relaunched its flagship show CBS Evening News, newly anchored by Tony Dokoupil, who opened the program’s reboot by telling viewers, “On too many stories, the press has missed the story. Because we’ve taken into account the perspective of advocates and not the average American. Or we put too much weight in the analysis of academics or elites, and not enough on you.” Dokoupil promised, “From now on, what you see and hear on the news will reflect what you see and hear in your own life.”

Programming that simply regurgitates what people already see, hear, and believe in their own lives is not, by any definition, “news” or even new. News media of course report stories that are relevant to their readers’ and viewers’ lives. But they should also be reporting the things those readers and viewers should know but don’t: political corruption or malfeasance; the actions of the very powerful; the disasters afflicting those less fortunate; innovations and world-changing achievements; the ways in which choices made in Washington invisibly but indelibly shape the lives of average people. The job of the reporter is to report what’s true, and to help the reader or viewer understand why it matters or what it means, which often requires bringing in subject-matter experts who are less “elites” than people who have spent years amassing knowledge and whose insights can expand minds and deepen public understanding. Mimicking the social media model of simply affirming people’s own beliefs, biases, and animosities and insisting that the guy next door knows as much about nuclear fission as a nuclear physicist is anathema to real journalism.

It’s also perpetuating the problem. People have lost trust in mainstream media not because mainstream media outlets have routinely lied to and manipulated them. People have lost trust in mainstream media at least in part because canny political actors have told the public that mainstream media has lied to and manipulated them, and that instead they should trust their own gut—and, naturally, highly ideological activists who use short-form video and text as tools to drive engagement (and drive up their own relevance and wealth).

Take, for example, the recent fraud scandal in Minnesota. Dozens of people, many of them Somali immigrants, have been accused and convicted of bilking federal social services programs for hundreds of millions of dollars in a sprawling and remarkably well-organized scheme involving autism care and a nonprofit called Feeding Our Future. (The alleged mastermind of the plot was the nonprofit’s head, a white woman.) President Donald Trump has jumped on the issue, using it to hammer his anti-immigrant views; several prominent conservatives have called to denaturalize and deport U.S. citizens who were involved in the plan.

Now right-wing influencers have made uncovering other acts of alleged Somali fraud something of a competition. In an act that has shades of Pizzagate, one man showed up at day care centers wielding a camera and demanding to be let inside, ostensibly to prove that there were no children there and the centers were more illegal money grabs; he seemed confused that day cares are typically locked to outsiders and don’t have formal reception areas, and he has been unable to offer any actual evidence of fraud. Nevertheless, his video went viral and was shared by the vice president and the director of the FBI. And there have been real and devastating consequences: Innocent Somalis have been harassed and threatened; Somali-run day cares have been vandalized. Based, it seems, solely on the claims of one right-wing influencer, Trump has cut off all federal child care funding to Minnesota, money that thousands of families rely on to afford care for their kids.

Conservative influencers are claiming that there was a widespread cover-up not only by Democrats in office, but by news media. “Right now the mainstream media is doing nothing to cover the Somali fraud in Minnesota,” one conservative activist with a million followers tweeted a few days before the new year. MAGA Voice told its 1.4 million followers that “CBS hasn’t reported on Minnesota/PBS hasn’t reported on Minnesota” and continued that convention to accuse six mainstream television networks of not reporting on the fraud case. “You literally can’t find a single mainstream article about the Minnesota fraud … Not even one,” reads one tweet, which has been shared more than 9,000 times.

“Somali fraud” became a talking point in right-wing circles thanks to an article in the conservative City Journal co-authored by right-wing activist Christopher Rufo. It claims that not only were Somalis defrauding the government, but, as the headline says, “the largest funder of [the terrorist group] al-Shabaab is the Minnesota taxpayer.” The piece then proceeds to include no evidence for its al-Shabaab claim, save for one quote attributed to an anonymous source. (Later in the piece, a law-enforcement official notes that Somalis, like many immigrant groups, send money to relatives back home, and that in Somalia, al-Shabaab is “taking a cut”—not that Somali Americans are sending reams of cash to terrorists, or that the Minnesota taxpayer is their primary bankroller.) That they were just hearing about this scandal, conservatives claimed, was evidence of the media’s complicity in a cover-up.

It was, instead, evidence of their own insularity, incuriosity, and apparent inability to read the news or even google. The City Journal article came out in mid-November; the New York Times had covered the case in March and again in August and kept up reporting as the story evolved and as federal indictments turned into mounting convictions. Sahan Journal, a Minnesota publication catering to the Somali community, wrote about it a year ago. The Associated Press, CBS News, and half a dozen local news outlets were following the story months before Rufo was on the case.

It is true that, so far, mainstream media outlets have not gone around accusing day care operators of malfeasance with no evidence beyond an online search, a hunch, and an unheeded demand to be allowed into child care centers to video the kids; this is a good thing. Real investigative journalism concerns itself with getting the facts right, and that takes time. Unlike in the Feeding Our Future scheme, there is no criminal case to cover in these so far unsubstantiated claims of day care fraud.

Being the first influencer to accuse immigrants of a serious crime may drive engagement and make one a right-wing hero, but it’s not the same as actual investigative reporting, which requires verifying facts rather than simply asserting them. And when reputable outlets get things wrong—and, being run by humans, they sometimes do—they publicly correct the record. Ideologues and influencers tend to just ignore or deny their own mistakes. If the influencer pounding on day care doors is shown evidence that the care centers are legit, do we think he’ll admit he was wrong, let alone go viral for it? And if he does walk back his claims, will the many millions who have taken them seriously get the memo—or will they continue on with the impression that a rampant fraud occurred and the legacy media simply refuses to talk about it? Do we believe that the president will restore child care funding and repay any lost wages to the parents whose ability to work just got scrambled?

This is all incredibly corrosive. The incoming A.I. era seems primed to supercharge this already perilous situation. With bots sounding more human by the day and the ability to create highly realistic photos and videos of just about whatever one pleases, the very concept of a shared reality may be in rapid decline. What we observe with our own eyes on our phones—what we see and hear political leaders saying, what we see and hear our fellow citizens doing—is becoming less reliable, and it takes ever greater sophistication to ferret out what’s real.

In this new Alice in Wonderland semireality, we need honest, accountable, real journalism. Instead of shoring up reputable outlets, though, too many are being sacrificed to the president by greedy owners who seem eager to profit handsomely even if it comes at the cost of America’s once robust democratic functioning enabled by the fourth estate. CBS’s rightward turn, including the appointment of Weiss—who was an opinion writer (not a reporter) with no experience in TV news—has come in the wake of its parent company’s acquisition by Skydance Media (now Paramount Skydance), owned by David Ellison, the son of Trump-supporting billionaire Larry Ellison. The younger Ellison was able to acquire Paramount only with the approval of the Federal Communications Commission, an agency the president has captured and whose power he continues to abuse. Announcing the merger, FCC chairman and Trump loyalist Brendan Carr said that he welcomes “Skydance’s commitment to make significant changes at the once storied CBS broadcast network,” including the appointment of a right-wing think tank employee as the broadcaster’s new ombudsman.

Ellison is now in a bid to acquire Warner Bros. Discovery, which owns CNN—another network the president believes is against him. Trump has implied that he will again abuse the FCC’s power to grant or block the merger the younger Ellison badly wants. It’s not hard to see Weiss’ decision to pull a ready-to-air 60 Minutes segment about the Salvadoran torture prison to which Trump is deporting immigrants—after the president complained that 60 Minutes had been mean to him—as part of a broader strategy to gut media companies that allow reporters to do their jobs rather than serve as mouthpieces for the administration, all in the service of enriching a tiny few.

There is not much the average American citizen can do to stop billionaires from seizing and eviscerating long-standing news networks, and other authoritarian leaders have run similar playbooks in their own countries, most notably in Hungary. What we can do, though, is direct our dollars and our attention to the reputable and well-run outlets that remain—and even though local news was dying well before Trump’s second term and national outlets are being disemboweled as if Hannibal Lecter is on the run, there are, thankfully, still many newspapers, news magazines, and television news networks doing real journalism. But they are facing threats from all sides: a vengeful president; a distracted and disengaged audience used to endless scrolling and pop-pop-pops of entertainment; the creeping unreality of A.I.

Fundamentally, we all need to be better news consumers. News outlets also see what’s shared and what’s ignored, which stories draw clicks and eyeballs and which are scrolled past, which outlets are growing their subscription bases and which are shrinking. That doesn’t determine editorial decisions, but it would be naive to believe that it doesn’t at all shape them. And if reputable news outlets aren’t getting readers and viewers, they also aren’t earning subscriber and ad dollars, which means there’s less cash to pay journalists to do the often-slow and often-pedantic work of good journalism.

It’s not just journalism that’s at stake; it’s your own brain. Do you believe you are better off getting news and information primarily from social media feeds that have been cultivated to push your particular outrage buttons, delivered by people who are accountable to no one? Or might it be better for your mind (your intellectual abilities and your basic sanity) to read a range of stories from across a big and complicated world, and sometimes see your priors challenged?

It’s practically a national pastime to complain about the media. Instead of asking “Who says stuff I agree with?,” try questioning a publication’s or individual’s editorial policies. Do they check their facts and check them again before publishing, to make sure they get it right most of the time? Are they transparent when they’re wrong? Do they hold the powerful to account, no matter who “the powerful” may be? Do they approach their subject matter with curiosity rather than an agenda?

Social media, A.I., Trump, and corporate greed do not have to be the end of reliable journalism. But they’re definitely not going to save it. As the old PBS slogan goes, that’s only made possible by viewers like you.

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-36')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">Q&A: Developing a sustainable power grid in the era of AI</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-36" style="display:none;">
            <h2>Q&A: Developing a sustainable power grid in the era of AI</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2026-01-05</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2026-01-qa-sustainable-power-grid-era.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-37')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">German renewable energy shift slowed in 2025</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-37" style="display:none;">
            <h2>German renewable energy shift slowed in 2025</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2026-01-05</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2026-01-german-renewable-energy-shift.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-38')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">Online 'brainrot' isn't ruining children's minds; it's a new way of navigating the modern internet</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-38" style="display:none;">
            <h2>Online 'brainrot' isn't ruining children's minds; it's a new way of navigating the modern internet</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2026-01-05</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2026-01-online-brainrot-isnt-children-minds.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-39')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">Ultrathin polymer layer extends lifespan of anode-free lithium metal batteries</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-39" style="display:none;">
            <h2>Ultrathin polymer layer extends lifespan of anode-free lithium metal batteries</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2026-01-05</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2026-01-ultrathin-polymer-layer-lifespan-anode.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-40')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">Location, location, location: Model IDs best spots for offshore energy projects</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-40" style="display:none;">
            <h2>Location, location, location: Model IDs best spots for offshore energy projects</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2026-01-05</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2026-01-ids-offshore-energy.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-41')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">Sustainable design of geosynthetics and roof underlayments made from recyclates</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-41" style="display:none;">
            <h2>Sustainable design of geosynthetics and roof underlayments made from recyclates</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2026-01-05</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2026-01-sustainable-geosynthetics-roof-underlayments-recyclates.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-42')">
            <div class="source">The Register</div>
            <div class="title">Intel unleashes Panther Lake CPUs, first built on 18A process</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-42" style="display:none;">
            <h2>Intel unleashes Panther Lake CPUs, first built on 18A process</h2>
            <p><strong>The Register | 2026-01-05</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2026/01/05/intel_unleashes_panther_lake_cpus/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Intel has finally let its new Panther Lake CPUs out of the cage. First detailed in October and now launching under the brand name Intel Core Ultra Series 3, these are the first chips made with Intel’s 18A process and boast improved power efficiency and performance, particularly for graphics and AI workloads.

Laptops with the chips will start shipping as soon as January 27, with Chipzilla boasting more than 200 design wins, including the new Dell XPS 14 and 16, which have just been announced and will be available for pre-order starting Tuesday, with a choice of Intel Core Ultra Series 3 configs. These laptops are all about long battery life, with Dell boasting in its press materials that they both lasted more than 40 hours while streaming 1080p video.

These new processors will also appear in devices other than laptops. Intel claims that they have been certified for embedded and industrial use in robotics, healthcare devices, and other kinds of edge computing hardware.

As part of its announcement, Intel revealed that there will be 14 SKUs of Core Ultra Series 3. These range from the 16-core, 5.1-GHz Core Ultra X9 388H on the high end to the 8-core, 4.4-GHz Core Ultra 5 322 on the low end.

Intel Core Ultra Series 3 High-end SKUs - Click to enlarge

All of the processors have either eight or 16 cores composed of three types of core. Each processor has four P or performance cores, which offer the highest clocks and use the most juice. Then there are LP E cores, which use the least amount of power and are the slowest. Then 16-core chips also have eight E cores which are somewhere in the middle. The goal is to offload as many tasks as possible onto the LP E and E cores to save power while lighting up the P cores for demanding tasks such as gaming.

Intel Core Ultra Series 3 Mid-range SKUs - Click to enlarge

Whatever cores it uses, Panther Lake’s new architecture promises power savings thanks to its die shrink from a 3 nm process to a 2 nm process, its use of denser RibbonFET transistors, and its shifting of power delivery to the back of the wafer.

The company claims that transistor density has increased by 30 percent while performance per watt is up 10 percent on single-threaded tasks and 50 percent on multithreaded tasks versus the prior-gen Lunar Lake and Arrow Lake CPUs. All of the SKUs carry a base power of 25 watts with turbo wattages of 65 or 55 W. Intel said that the top SKUs – the Core Ultra X9 and Core Ultra X7 – provide 60 percent better multithreaded performance and 77 percent faster gaming.

In another power-saving move, Core Ultra Series 3 processors will support Intel Intelligent Display technology, which uses AI to change screen settings based on what tasks you are performing and what you are doing. So, if you walk away, the screen instantly goes into a lower brightness and lower refresh rate than when you’re actively working. Similarly, if you are reading emails, it can lower the refresh rate and then raise it again when you’re watching videos or playing games. The lower your refresh rate and screen brightness, the less power your computer uses.

As we wrote about in October, not all of Panther Lake is made by Intel’s 18A process. The compute die, which contains the CPU and NPU, is made with 18A, but the platform controller is made by TSMC and the integrated GPU is either built by TSMC or Intel on its Intel 3 process, if it’s one of the lower-end models.

Speaking of graphics, Panther Lake comes with Intel Arc GPUs built in that each has up to 12 Xe cores for graphics and can deliver up to 120 TOPS (Trillion Operations per Second) when used for AI workloads. The GPUs enable Intel XeSS (super sampling) and XeSS-SR (Super Resolution), along with XeSS-MFG (multi-frame generation) and XeLL (low latency), all of which allow games to achieve faster frame rates through the power of AI upscaling and quicker response times.

Endurance Gaming Mode is designed to help improve battery life while gaming by lowering the frame rate at times. The Arc graphics also use XMX (Xe Matrix Extensions) and XMX engines to help with their AI processing.

All of the Core Ultra Series 3 SKUs feature low-power NPUs that can achieve up to 50 TOPS themselves. The idea is that, where performance is key, the GPU will perform AI workloads, but where the task is simple enough, the NPU can do it while sipping a lot less juice.

Many of the chips have built-in support for Thunderbolt 5, which can provide 80 Gbps of bidirectional, wired connectivity and 120 Gbps in Bandwidth Boost mode. Others support only Thunderbolt 4, which is limited to 40 Gbps connections.

Either way, as long as the manufacturer puts a Thunderbolt port on the laptop, you can use the standard to connect to monitors and docks that provide video, data, and charging over a single cable. The laptops will also support Thunderbolt Share, which allows you to share screens, keyboard, mouse, and files over a single cable.

All of the chips support built-in Wi-Fi 7 with Bluetooth 6.0. Those are the latest wireless standards you can get.

The Intel Core Ultra Series 3 processors support up to 96 or 128GB of LPDDR5x or DDR5 RAM, depending on SKU. The two X series chips, the Core Ultra X9 and Ultra X7, support RAM that operates at up to 9,600 MT/s, while other units support only up to 8,533, 7,467, or 6,800 MT/s. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-43')">
            <div class="source">The Register</div>
            <div class="title">Nvidia says it's more than doubled the DGX Spark’s performance since launch</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-43" style="display:none;">
            <h2>Nvidia says it's more than doubled the DGX Spark’s performance since launch</h2>
            <p><strong>The Register | 2026-01-05</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2026/01/05/nvidia_dgx_spark_speed/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Nvidia&#39;s DGX Spark and its GB10-based siblings are getting a major performance bump with the platform&#39;s latest software update, announced at CES on Monday. The AI mini PC is also getting access to the GPU giant&#39;s full suite of AI Enterprise apps, alongside integrations with RTX Remix and Hugging Face&#39;s Reachy robotics platform.

First teased at CES 2025 under the codename Project Digits, the DGX Spark is a tiny AI workstation designed to support rapid prototyping, GPU-accelerated software development, and local AI training and inference workloads.

While it&#39;s billed as the &quot;world&#39;s smallest AI supercomputer,&quot; the machine isn&#39;t actually that powerful with the computational grunt equivalent to an RTX 5070. What sets it apart from the rest of Nvidia&#39;s lineup is the inclusion of 128 GB of unified memory, all of which can be allocated to the GPU. That&#39;s the most of an Nvidia workstation product, save for the DGX Station.

The DGX Spark&#39;s golden design is clearly inspired by the original DGX-1 system hand-delivered by Jensen Huang to Elon Musk at OpenAI in 2016 - Click to enlarge

Since the Spark&#39;s launch in October, Nvidia has been hard at work improving the system&#39;s performance by an average of 2.5x across a number of software libraries and frameworks, though we haven&#39;t had the opportunity to independently verify those claims just yet.

Check out our day one review of Nvidia&#39;s tiniest AI supercomputer here

But before you get too excited, don&#39;t expect to see the Spark churning out tokens twice as quickly as before. The decode phase of LLM inference, during which tokens are generated, is bandwidth-limited. The Spark can&#39;t actually get much faster here.

Instead, Nvidia has confirmed that most of the performance gains in this software release are for the compute-intensive parts of the genAI pipeline. For LLM inference, these updates will predominantly improve prefill performance, which reduces the time from when a prompt is submitted to when the Spark begins generating a response.

Updates include enhancements to Nvidia&#39;s inference engine, TensorRT LLM, Llama.cpp, and PyTorch to name a few. The latter, we&#39;ll note, should help to improve other compute-intensive workloads like fine tuning and image or video generation.

Nvidia also announced plans to make its full AI Enterprise suite available on the Spark as a subscription service later this month.

The suite includes access to a host of enterprise-focused applications, frameworks, models, and microservices designed to streamline the development of AI apps and services.

Normally the suite runs for $4,500 a year per GPU or $1 an hour per GPU in the cloud, but we&#39;re told Nvidia does plan to offer special pricing for Spark, although that&#39;s not official yet. Nvidia does make the offering available at no cost to developers, but a paid plan is required to use applications and services built on it in production.

We&#39;ve reached out to Nvidia for comment; we&#39;ll let you know if we hear anything back.

In any case, the offering should help to assuage concerns over long-term software support. When the Spark launched, many expressed fears that the $3,999 AI lab in a box could be rendered a golden paperweight in a few years if Nvidia failed to release updates to DGX OS, the company&#39;s custom spin of Ubuntu.

Some older development boards, like the Jetson Nano, have faced such a fate. The single-board computer never advanced past Ubuntu 18.04, which hasn&#39;t been supported since 24.04 came out a couple of years ago.

Nvidia tells us this shouldn&#39;t be the case for the Spark or other GB10-based systems.

&quot;We&#39;re committed to support. In fact, we just released the latest kernel with some security patches,&quot; Allen Bourgoyne, director of product marketing for Nvidia&#39;s professional visualization business, said in response to our questions.

The real test will be whether we see Nvidia base DGX OS for the Spark on Ubuntu 26.04, which will be Canonical&#39;s next long-term support release.

Support for third-party Linux distros, like Red Hat Enterprise Linux (RHEL), would go a long way to mitigating concerns of obsolescence, but it doesn&#39;t appear to be on the table just yet.

Nvidia says it&#39;s focusing development on DGX OS for now. But the company could still release the drivers and firmware packages necessary to get GPU acceleration working on the GB10 on other distros.

Alongside Nvidia&#39;s software updates and subscription services, the company plans to release a version of its Nsight CUDA code assistant capable of running entirely on the Spark. Previously, the models used by the assistant were too large to fit on Nvidia&#39;s consumer graphics offerings and therefore were limited to the cloud, making it less useful for privacy-conscious enterprises.

Nsight is expected to arrive on the Spark later this spring.

For gamers, Nvidia is extending RTX Remix support to the Spark. The platform is designed to support the development of game mods that take advantage of Nvidia&#39;s ray tracing accelerators. With the integration, activities such as text generation can be offloaded to the Spark.

Meanwhile, for robotics enthusiasts, Nvidia says it&#39;s working on a new guide that pairs the Spark with Hugging Face&#39;s Reachy robot. The desktop robot is designed to support the development of embodied AI frameworks and services.

Finally, we&#39;ve learned that Nvidia could soon extend support for Spark clusters containing more than two systems.

One of the Spark&#39;s more interesting features is the inclusion of a ConnectX-7 NIC with a pair of QSFP+ ports capable of delivering 200 Gbps of bandwidth between them.

Nvidia currently supports linking up to two Sparks (or GB10 partner systems) using these ports, but in theory there&#39;s nothing stopping someone from building a whole cluster of them. Nvidia tells us that it&#39;s seen interest from customers for larger clusters and its engineers are actively exploring the possibility. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-44')">
            <div class="source">The Register</div>
            <div class="title">Every conference is an AI conference as Nvidia unpacks its Vera Rubin CPUs and GPUs at CES</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-44" style="display:none;">
            <h2>Every conference is an AI conference as Nvidia unpacks its Vera Rubin CPUs and GPUs at CES</h2>
            <p><strong>The Register | 2026-01-05</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2026/01/05/ces_rubin_nvidia/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">CES used to be all about consumer electronics, TVs, smartphones, tablets, PCs, and – over the last few years – automobiles. Now, it&#39;s just another opportunity for Nvidia to peddle its AI hardware and software — in particular its next-gen Vera Rubin architecture.

The AI arms dealer boasts that, compared to Blackwell, the chips will deliver up to 5x higher floating point performance for inference, 3.5x for training, along with 2.8x more memory bandwidth and an NvLink interconnect that&#39;s now twice as fast.

But don&#39;t get too excited just yet. It&#39;s not like the chips are launching earlier than previously expected. They&#39;re still expected to arrive in the second half of the year, just like Blackwell and Blackwell Ultra did.

Nvidia normally holds off until GTC in March to reveal its next-gen chips. Perhaps AMD&#39;s aggressive rack scale roadmap has Nvidia&#39;s CEO Jensen Huang nervous. Announced at Advancing AI late last spring and expected later this year, AMD&#39;s double-wide Helios racks promise to deliver performance on par with Vera Rubin NVL72 while offering customers 50 percent more HBM4.

Nvidia has also been teasing the Vera Rubin platform for nearly a year now, to the point where there&#39;s not much we didn&#39;t already know about the platform.

But even though you won&#39;t be able to get your hands on Rubin for a few more months, it&#39;s never too early for a closer look at what the multi-million dollar machines will buy you.

The flagship system for Nvidia&#39;s Vera Rubin CPU and GPU architectures is once again its NVL72 rack systems. At first blush, the machine doesn&#39;t look all that different from its Blackwell and Blackwell Ultra-based siblings. But under the hood, Nvidia has been hard at work refining the architecture for better serviceability and telemetry.

Switch trays can now be serviced without taking down the machine first. Nvidia also has new reliability, availability, and serviceability features which enable customers to check in on the health of the GPUs without dropping them from the cluster first. These health checks can now run between training checkpoints or jobs, Ian Buck, Nvidia&#39;s VP and General Manager of Hyperscale and HPC, tells El Reg.

At the heart of the rack is the Vera Rubin superchip, which, if history tells us anything, should bear the VR200 code name.

Much like Blackwell, the Vera Rubin superchip features two dual-die Rubin GPUs, each capable of churning out 50 petaFLOPS of inference performance or 35 petaFLOPS for training. Both of those numbers refer to peak performance achievable when using NVLFP4 data type.

Here&#39;s a quick overview of Rubin&#39;s speeds and feeds - Click to enlarge

According to Buck, for this generation, Nvidia is using a new adaptive compression technique that&#39;s better suited to generative AI and mixture of experts (MoE) model inference to achieve the 50 petaFLOP claim rather than structured sparsity. As you may recall, while structured sparsity did have benefits for certain workloads, it didn&#39;t offer many if any advantages for LLM inference.

Of course, higher-precision data types remain relevant for many workloads, whether for vision-language model inference, image generation, fine-tuning, training, or high-performance computing (HPC). In this respect Nvidia hasn&#39;t deprecated support for any data types, but its approach to some like FP64 has changed a little.

FP64 is essential for HPC and scientific computing workloads, such as physics simulations and material analysis, and compared to Blackwell, performance regressed from 45 teraFLOPS to 33 TFLOPS of double-precision vector performance on Rubin. For FP64 matrix applications, which are what the Top500 ranking of the most powerful publicly known supercomputers is heavily weighted toward, performance is achieved using emulation, an approach that was pioneered on Blackwell accelerators.

The GPUs are fed by 288 GB of HBM4 memory — 576 GB per superchip — which, despite delivering the same capacity as the Blackwell Ultra-based GB300, is now 2.8x faster at 22 TB/s per socket (44 TB/s per superchip). If that number seems a little high, that&#39;s because Nvidia initially targeted 13 TB/s of HBM4 bandwidth when it first teased Rubin last year. Buck tells us that the jump to 22 TB/s was attained entirely through silicon and doesn&#39;t rely on techniques like memory compression.

Nvidia&#39;s latest Arm CPU features 88 custom Olympus cores with SMT - Click to enlarge

The two Rubin GPUs are paired to Nvidia&#39;s new Vera CPU via a 1.8 TB/s NvLink-C2C interconnect. The CPU contains 88 of Nvidia&#39;s custom Arm-based Olympus cores and is paired with 1.5 TB of LPDDR5x memory — 3x that of the GB200. We guess we know why memory is in such short supply these days. Actually it&#39;s more complicated than that, but this certainly isn&#39;t helping the situation.

However, one of the most important features Vera brings to the table is support for confidential computing across the system&#39;s NvLink domain, something that previously was only available on x86-based HGX systems.

Nvidia&#39;s Vera Rubin NVL72 racks feature 72 Rubin GPUs, 20.7 TB of HBM4, 36 Vera CPUs, 54 TB of LPDDR5x which are spread across 18 compute blades interconnected by nine NvSwitch 6 blades which deliver 3.6 TB/s of bandwidth to each GPU — twice that of last gen.

Nvidia isn&#39;t ready to say how much power that additional compute and bandwidth will require. However, Buck tells us that while it will be higher, we shouldn&#39;t expect power to double.

Since announcing Rubin, Nvidia has decided not to use the NVL144 naming convention and to stick to counting SXM modules as GPUs rather than dies. (Image from GTC 2025) - Click to enlarge

If you&#39;re scratching your head wondering &quot;didn&#39;t Nvidia say this thing was supposed to have 144 GPUs?&quot; you wouldn&#39;t be the only one. At GTC 2025, Huang announced that they were changing the way they counted GPUs from the package to the dies on board. In that sense, the Blackwell-based NVL72s also had 144 GPUs, but Nvidia was going to wait for Vera Rubin to make the switch to the new convention.

It seems Nvidia has since changed its mind and is sticking with the established naming convention. Having said that, we may yet see Nvidia racks with at least 144 GPUs on board before long.

The Rubin CPUs we&#39;ve talked about up to this point actually are one of two accelerators announced so far. Rubin CPX is the other.

Unveiled in September, the chip is a more niche product, designed specifically to accelerate the compute-intense prefill phase of LLM inference. Since prefill isn&#39;t bandwidth-bound, CPX doesn&#39;t need HBM and can instead make do with slower DRAM.

Each CPX accelerator will be capable of churning out 30 petaFLOPS of NVFP4 compute and will sport 128 GB of GDDR7 memory.

Nvidia&#39;s Vera Rubin NVL144 CPX compute trays will now pack 12 GPUs. Four with HBM and another eight context optimized ones using GDDR7 - Click to enlarge

In a graphic shared this summer, Nvidia showed an NVL144 CPX blade with four 288 GB Rubin SXM modules and eight Rubin CPX prefill accelerators for a total of 12 GPUs per node.

The complete rack system would only need 12 compute blades for the thing to have 144 GPUs, though only 48 of them would be connected via NVLink.

As with past Nvidia rack systems, eight NVL72 racks form a SuperPOD with the GPU slinger&#39;s Spectrum-X Ethernet and/or Quantum-X InfiniBand the glue used to stitch them together. Multiple SuperPODS can then be combined to form larger compute environments for training or distributed inference.

If you aren&#39;t ready to make the switch to Nvidia&#39;s rack-scale kit, don&#39;t worry. Eight-way (NVL8) HGX systems based around the Rubin platform are still available, but we&#39;re told liquid cooling is no longer a suggestion, but a requirement. These smaller systems, 64 to be exact, can also be combined to form a SuperPOD with 512 GPUs — just shy of the of the more powerful NVL72 SuperPOD at 576.

For this generation, Nvidia also has two new NICs, which it teased on a few occasions over the last year. At GTC DC, Nvidia showed off the ConnectX-9, a 1.6 Tbps &quot;superNIC&quot; designed for high-speed distributed computing, which we sometimes call the backend network.

Here&#39;s a closer look at Nvidia&#39;s 1.6Tbps ConnectX-9 superNIC - Click to enlarge

For storage, management, and security, Nvidia is pushing its BlueField-4 data processing units (DPUs), which feature an integrated 800 Gbps ConnectX-9 NIC and a 64-core Grace CPU on board. This, we should note, isn&#39;t the same Grace CPU found in the GB200, but a newer version based on Arm&#39;s Neoverse V3 core architecture.

Nvidia&#39;s BlueField-4 DPUs feature an 800 Gbps ConnectX-9 NIC along with a 64-core Grace CPU for software-defined networking, security, and storage offload - Click to enlarge

The beefier CPU is designed to offload software defined networking, storage, security, and can also run hypervisors for virtualized environments.

Cramming 64 Grace cores onto a NIC might seem like overkill, but Nvidia has a specific reason for wanting that much compute hanging off the machine like a computer in front of a computer.

Alongside all its shiny new hardware, Nvidia showed off what it&#39;s describing as a &quot;new class of memory between the GPU and storage,&quot; designed to offload key value (KV) caches.

The basic idea isn&#39;t new. KV caches store the model&#39;s state. You can think of this like its short-term memory. Calculating the key value vectors is one of the more compute-intensive aspects of the inference.

Because inference workloads often involve passing over the same info multiple times, it makes sense to cache the computed vectors in memory. By doing this, only changes need to be computed and data in the cache can be reused. This sounds simple, but, in practice, KV caches can be quite large, easily consuming tens of gigabytes in order to keep track of 100,000 or so tokens. That might sound like a lot, but a single user running a code assistant or agent can blow through that rather quickly.

As we understand it, Nvidia&#39;s Inference Context Storage platform will work with storage platforms from multiple partner vendors, and will take advantage of the BlueField-4 DPU, NIXL GPU direct storage libraries, and optimize KV cache offloading for maximum performance and efficiency.

Combined with technologies like Rubin CPX, this kind of high-performance KV offloading should allow the GPUs to spend more time generating tokens and less time waiting on data to be shuffled about and recomputed.

Nvidia&#39;s decision to &quot;launch&quot; Rubin — again it isn&#39;t actually shipping in volume yet — betrays an increasingly competitive compute landscape.

As we mentioned earlier, AMD&#39;s Helios rack systems promise to deliver floating point performance roughly equivalent to Nvidia&#39;s Vera Rubin NVL72 at 2.9 exaFLOPS versus 2.5-3.6 exaFLOPS of FP4, respectively. For applications that can&#39;t take advantage of Nvidia&#39;s adaptive compression tech, Helios is, at least on paper, faster.

However, with Nvidia planning to ship faster memory on Rubin than initially planned, AMD no longer has a bandwidth advantage. It does still have a capacity lead with 432 GB of HBM4 per GPU socket compared to 288 GB on Rubin. In theory, this should allow the AMD-based system to serve 50 percent larger MoE models on a single double-wide rack.

AMD Helios systems won&#39;t exactly fit into a standard 19&quot; rack - Click to enlarge

In practice, the real-world performance is going to depend heavily on how well tunneling Ultra Accelerator Link (UALink) over Broadcom&#39;s Tomahawk 6 Ethernet switches actually works.

AMD&#39;s MI450-series GPUs appear very well positioned to compete against Rubin, but as we&#39;ve seen repeated with Amazon and Google, the ability to scale that compute often makes a bigger difference than the chip&#39;s individual performance.

AMD is also having to play catch up on the software ecosystem front. The company&#39;s HIP and ROCm libraries have certainly come a long way since the MI300X made its debut at the end of 2023, but the company still has a ways to go.

Nvidia certainly isn&#39;t making the situation any easier for AMD. At CES, the GPU giant unveiled a slew of new software frameworks aimed at enterprises, robotics devs, and the automotive industry.

This includes the development of new foundation models for domain specific applications like retrieval augmented generation, safety, speech, and autonomous driving.

The latter, called Alpamayo, is a relatively small &quot;reasoning vision language action&quot; model designed to help level-4 autonomous vehicles better handle unique and fast evolving road conditions. Level-4 capable vehicles are capable of driving fully autonomously, unsupervised driving in specific environments, like high-ways or urban environments.

Nvidia&#39;s autonomous driving stack is due to hit US roads late this year with the level-2++ capable Mercedes Benz CLA. This class of autonomous vehicle is capable of driving itself in similar conditions as level-4, but requires the supervision of a human operator.

With Nvidia kicking off the New Year with Rubin — a chip we hadn&#39;t expected to get a good look at for another three months — we&#39;re left to wonder what we&#39;ll see at GTC, which is slated to run from March 16-19 in San Jose, California.

In addition to the regular mix of software libraries and foundation models, we expect to get a lot more details on the Kyber racks that&#39;ll underpin the company&#39;s Vera Rubin Ultra platform starting in 2027.

As you might have noticed, Nvidia, AMD, AWS, and others have gotten in the habit of pre-announcing products well in advance of them shipping or becoming generally available. As the saying goes: enterprises don&#39;t buy products, they buy roadmaps. In this case, however, it&#39;s really about ensuring they have somewhere to put them.

Nvidia&#39;s Kyber racks are expected to pull 600 kilowatts of power which means datacenter operators need to start preparing now, if they want to deploy them on day one.

By 2027 Nvidia CEO Jensen Huang expects racks to surge to 600 kW with the debut of its Rubin Ultra Kyber racks (Image from GTC 2025) - Click to enlarge

We don&#39;t yet have a full picture of what Vera Rubin Ultra will offer, but we know it&#39;ll feature four reticle-sized Rubin Ultra GPUs, 1TB of HBM4e, and will deliver 100 petaFLOPS of FP4 performance.

As things currently stand, Nvidia plans to cram 144 of these GPU packages (576 GPU dies) into a single NvLink domain which is expected to deliver 15 exaFLOPS of FP4 inference performance or 10 exaFLOPS for training. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-45')">
            <div class="source">The Register</div>
            <div class="title">Claude devs complain about surprise usage limits, Anthropic blames expiring bonus</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-45" style="display:none;">
            <h2>Claude devs complain about surprise usage limits, Anthropic blames expiring bonus</h2>
            <p><strong>The Register | 2026-01-05</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2026/01/05/claude_devs_usage_limits/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Software developers who use Anthropic&#39;s Claude Code have been sounding the alarm for the past few days about changes in the AI service&#39;s usage limits.

Some customers have objected to the rapid consumption of their token allotment in the company&#39;s Discord channel, and they claim that their criticism has been silenced by channel moderators.

Anthropic insists the issue follows from the expiration of a holiday usage bonus and that the company doesn&#39;t try to limit discussion of usage limits – the implication being that any Discord bans follow from community policy violations.

An Anthropic customer and forum user who asked not to be identified provided The Register with screenshots of various Discord interactions and offered his assessment of the issue. He claims that there&#39;s been a roughly 60 percent reduction in token usage limits, based on a token-level analysis of Claude Code logs. He speculates that the changes represent an attempt to reduce costs prior to Anthropic&#39;s expected public stock offering, a claim Anthropic flatly denies.

Evidence of concern among developers using Claude Code and other Claude services has surfaced on Reddit, where a recent post claims &quot;Claude usage consumption has suddenly become unreasonable.&quot;

Numerous participants in that discussion argue that model interactions now consume more tokens than they did previously, which results in the account usage limits being reached sooner.

Other Reddit threads raise similar concerns. The Claude Developers Discord channel also includes a post from a developer claiming to have run out of token capacity on an enterprise account.

A current thread posted by &quot;David,&quot; an admin for Anthropic&#39;s Claude Developers Discord channel, asks forum participants to post their rate limit concerns, promising an investigation into reports of inconsistent usage limits.

Others echo those remarks. A separate post in the #claude-code-lounge channel this morning begins, &quot;I am a Claude Pro/Max subscriber experiencing severely restrictive usage limits that make the service unusable for development work. Despite having an active Pro plan, I consistently hit usage limits within 10–15 minutes of using Sonnet, with the usage bar showing near 100 percent consumption. Opus is even more limited, often becoming unavailable shortly after starting.&quot;

It&#39;s worth noting that complaints about token usage limits have been around for many months. A mega-thread in the Discord channel dating back to October 9, 2025, offers a record of the discontent.

Anthropic offers three individual subscription plans: Free, Pro ($20/month), and Max ($100 or $200 per month), each with its own usage limits. The Pro plan promises 5x the usage allowed for the Free plan; the Max plan promises either 5x or 20x the usage of the Pro plan.

There are also two business subscription plans – Team ($25/$150 per seat/month) and Enterprise (not publicly disclosed but said to be $60 per seat with a minimum of 70 seats per month). Team usage is &quot;more&quot; than the Pro plan. Enterprise limits aren&#39;t specified.

The Register spoke with an Anthropic representative who dismissed the claims about usage reductions as unfounded and suggested customers are simply reacting to the withdrawal of bonus usage awarded over the holidays.

During the period from December 25 through December 31, 2025, Anthropic doubled the customer usage limits of Claude models as a holiday gift. This was done, we&#39;re told, to make use of idle compute capacity during that period, the result of vacationing enterprise customers.

Our source claims that removal of those higher limits has reduced usage allowances below their original baseline, but Anthropic says that&#39;s incorrect. The concerns being raised, we&#39;re told, appear to be largely a response to the resumption of normal limits.

One of the Reddit threads includes the suggestion that the heightened consumption of tokens follows from a Claude Code bug, detailed in a GitHub Issues post. Some users report that rolling Claude Code back to version 2.0.61 fixed the issue; others disagree.

Anthropic&#39;s representative said that its team takes all such reports seriously but hasn&#39;t identified any flaw related to token usage. Last month, Anthropic looked into reports of problems with its Claude Opus 4.5 model and said it had ruled out bugs in its inference stack.

Nonetheless, a bug report filed on Sunday, January 4, 2026, suggests there&#39;s something amiss with the reversion of the pre-holiday usage limits. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-46')">
            <div class="source">The Register</div>
            <div class="title">ServiceNow snags Microsoft vet to run legal amid M&amp;A spree</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-46" style="display:none;">
            <h2>ServiceNow snags Microsoft vet to run legal amid M&amp;A spree</h2>
            <p><strong>The Register | 2026-01-05</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2026/01/05/servicenow_hossein_nowbar_president_legal/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">ServiceNow has hired Hossein Nowbar as its chief legal officer and president, the company announced on Monday.

Nowbar spent 28 years at Microsoft, where he was most recently chief legal officer, and oversaw complex M&A deals like the company’s $69 billion purchase of Activision Blizzard as well as the dawn of Microsoft’s involvement with AI.

Somewhat unusually for a former employer, Microsoft President Brad Smith had no objection to the move, and in fact heaped praise on Nowbar and congratulated ServiceNow in a statement that accompanied the announcement. “Having worked closely with Hossein for more than 25 years, I can say first-hand that ServiceNow is incredibly fortunate to have him,” Smith enthused.

Nowbar and Smith cowrote a blog in 2023 that announced indemnification for Microsoft Copilot users who may run afoul of copyright laws while using it. Smith and Nowbar said in such a case, Microsoft would pick up the legal bill.

“[We] will defend the customer and pay the amount of any adverse judgments or settlements that result from the lawsuit, as long as the customer used the guardrails and content filters we have built into our products,” the two wrote.

The policy called the Customer Copyright Commitment was updated in 2024 to include commercial customers using the Azure OpenAI Service.

In his Microsoft exit post written three months ago, Nowbar took to LinkedIn to say that in the hands of Microsoft’s legal department, the law became a catalyst for innovation, “not just a safeguard.”

“I helped clear antitrust hurdles for transformative acquisitions like Nuance and Activision Blizzard King, supported product and service launches that reshaped the way we work, and introduced the Customer Copyright Commitment to help our customers realize the promise of AI,” Nowbar wrote in his post.

At ServiceNow, Nowbar will oversee global legal, ethics, governance, compliance, risk, ServiceNow.org, impact and sustainability, and corporate and government affairs organizations.

ServiceNow is in the midst of buying cybersecurity company Armis for $7.75 billion, a deal it just announced in December. ServiceNow expects the deal to close in the second half of 2026, subject to regulatory conditions. The company has been on an M&A tear in 2025 with deals to acquire Armis, Cuein, data.world, Logik.ai, Quality 360, and Veza.

Forrester VP and principal analyst Charles Betz previously told The Register that the Armis acquisition gives ServiceNow access to massive volumes of data for its CMDB, making data discovery tools “an order of magnitude” more powerful. Meanwhile data.world, a cloud-native data catalog and data governance platform built for large enterprises, takes vast corporate data sets and makes them searchable and mappable. Together, those two deals in particular signal that ServiceNow is looking at how it manages data “very strategically,” he said. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-47')">
            <div class="source">The Register</div>
            <div class="title">ChatGPT is playing doctor for a lot of US residents, and OpenAI smells money</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-47" style="display:none;">
            <h2>ChatGPT is playing doctor for a lot of US residents, and OpenAI smells money</h2>
            <p><strong>The Register | 2026-01-05</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2026/01/05/chatgpt_playing_doctor_openai/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">About sixty percent of American adults have turned to AI like ChatGPT for health or healthcare in the past three months. Instead of seeing that as an indictment of the state of US healthcare, OpenAI sees an opportunity to shape policy.

A study published by OpenAI on Monday claims more than 40 million people worldwide ask ChatGPT healthcare-related questions each day, accounting for more than five percent of all messages the chatbot receives. About a quarter of ChatGPT&#39;s regular users submit healthcare-related prompts each week, and OpenAI understands why many of those people are users in the United States.

&quot;In the United States, the healthcare system is a long-standing and worsening pain point for many,&quot; OpenAI surmised in its study.

Studies and first-hand accounts from medical professionals bear that out. Results of a Gallup poll published in December found that a mere 16 percent of US adults were satisfied with the cost of US healthcare, and only 24 percent of Americans have a positive view of their healthcare coverage.

It&#39;s not hard to see why. Healthcare spending has skyrocketed in recent years, and with Republican elected officials refusing to extend Affordable Care Act subsidies, US households are due to see another spike in insurance costs in 2026. Based on Gallup&#39;s findings, it seems that American insureds, who pay the highest per capita healthcare costs in the world, don&#39;t think they&#39;re getting their money&#39;s worth.

According to OpenAI, more Americans are turning to its AI to close healthcare gaps, and the company doesn&#39;t seem at all troubled by that.

&quot;For both patients and providers in the US, ChatGPT has become an important ally, helping people navigate the healthcare system, enabling them to self-advocate, and supporting both patients and providers for better health outcomes,&quot; OpenAI said in its study.

According to the report, which used a combination of a survey of ChatGPT users and anonymized message data, nearly 2 million messages a week come from people trying to navigate America&#39;s labyrinthine health insurance ecosystem, but they&#39;re still not the majority of US AI healthcare answer seekers.

Fifty-five percent of US adults who used AI to help manage their health or healthcare in the past three months said they were trying to understand symptoms, and seven in ten healthcare conversations in ChatGPT happened outside normal clinic hours.

Individuals in &quot;hospital deserts,&quot; classified in the report as areas where people are more than a 30-minute drive from a general medical or children&#39;s hospital, were also frequent users of ChatGPT for healthcare-related questions.

In other words, when clinic doors are closed or care is hard to reach, care-deprived Americans are turning to an AI for potentially urgent healthcare questions instead.

As The Guardian reported last week, relying on AI for healthcare information can lead to devastating outcomes.

The Guardian&#39;s investigation of healthcare-related questions put to Google AI Overviews found that inaccurate answers were frequent, with Google AI giving incorrect information about the proper diet for cancer patients, liver function tests, and women&#39;s healthcare.

OpenAI rebuffed the idea that it could be providing bad information to Americans seeking healthcare information in an email to The Register. A spokesperson told us that OpenAI has a team dedicated solely to handling accurate healthcare information, and that it works with clinicians and healthcare professionals to safety-test its models, suss out where risks might be found, and improve health-related results.

OpenAI also told us that GPT-5 models have scored higher than previous iterations on the company&#39;s homemade healthcare benchmarking system. It further claims that GPT-5 has greatly reduced all of its major failure modes (i.e., hallucinations, errors in urgent situations, and failures to account for global healthcare contexts).

None of those data points actually get to the point of how often ChatGPT could be wrong in critical healthcare situations, however.

What does that matter to OpenAI, though, when there&#39;s potentially heaps of money to be made on expanding in the medical industry? The report seems to conclude that its increasingly large role in the US healthcare industry, again, isn&#39;t an indictment of a failing system as much as it is the inevitable march of technological progress, and included several &quot;policy concepts&quot; that it said are a preview of a full AI-in-healthcare policy blueprint it intends to publish in the near future.

Leading the recommendations, naturally, is a call for opening and securely connecting publicly funded medical data so OpenAI&#39;s AI can &quot;learn from decades of research at once.&quot;

OpenAI is also calling for new infrastructure to be built out that incorporates AI into medical wet labs, support for helping healthcare professionals transition into being directly supported by AI, new frameworks from the US Food and Drug Administration to open a path to consumer AI medical devices, and clarified medical device regulation to &quot;encourage … AI services that support doctors.&quot; ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-48')">
            <div class="source">The Verge</div>
            <div class="title">Garmin now offers nutrition tracking</div>
            <div class="meta">2026-01-06</div>
        </div>
        
        <div id="content-48" style="display:none;">
            <h2>Garmin now offers nutrition tracking</h2>
            <p><strong>The Verge | 2026-01-06</strong></p>
            <a class="original-link" href="https://www.theverge.com/tech/855884/garmin-connect-nutrition-tracking">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">﻿With a paid Garmin Connect Plus subscription, you can log what you eat and track your calories and macros.

﻿With a paid Garmin Connect Plus subscription, you can log what you eat and track your calories and macros.

If you buy something from a Verge link, Vox Media may earn a commission. See our ethics statement.

Garmin announced that it’s adding nutrition tracking to the Garmin Connect app as a perk for users with a Garmin Connect Plus subscription. The feature lets users “track their calories and macros (proteins, fats and carbs) and receive Active Intelligence insights to help them achieve their nutrition goals,” according to Garmin.

To log foods, you can search for items in a “global food database that includes packaged, restaurant and regional food options” as well as scan bar codes or by using the camera on your smartphone. Compatible Garmin smartwatches will also let users see “a quick overview of their nutrition and track their favorite and recently logged foods.”

Garmin offers daily, weekly, monthly, and annual nutrition reports and can give you personalized calorie and macronutrient recommendations. The AI-powered Active Intelligence insights can help you “better understand how nutrition is impacting health and training,” such as how “lower quality sleep was impacted by late-night eating,” Garmin says.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-49')">
            <div class="source">The Verge</div>
            <div class="title">Asus ROG’s next ally is Xreal, with 240Hz AR glasses coming in 2026</div>
            <div class="meta">2026-01-06</div>
        </div>
        
        <div id="content-49" style="display:none;">
            <h2>Asus ROG’s next ally is Xreal, with 240Hz AR glasses coming in 2026</h2>
            <p><strong>The Verge | 2026-01-06</strong></p>
            <a class="original-link" href="https://www.theverge.com/tech/848256/asus-rog-xreal-r1-smart-glasses-specs-release-date">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Doubling the standard refresh rate won’t come cheap, and we don’t know yet how much Xreal is going to charge.

Doubling the standard refresh rate won’t come cheap, and we don’t know yet how much Xreal is going to charge.

Xreal is having a big CES. It announced its new 1S AR glasses and the Switch 2-ready Neo dock that’s also a battery — both of which are already available to buy. It’s not done with the announcements yet, as it delivered a peek at an upcoming partnership with Asus that will yield a new set of ROG AR glasses made specifically for gamers.

In the one and only image that was shared with The Verge, the ROG Xreal R1 gaming glasses look like cyberpunk aviators. There’s an LED strip on the stem to indicate… something. Perhaps battery life, or something previously unquantifiable, like leetness. Either way, the stems seem quite a bit thicker than those on the 1S, and whatever tech the companies are cramming inside may be necessary to allow for their marquee feature: a 240Hz refresh rate. These are apparently the first to double the normal 120Hz refresh rate that’s common in AR glasses today.

These glasses have micro-OLED panels running at 1080p resolution, and they’ll attach to gadgets with a USB-C cable. Included with this set of glasses is the ROG Control Dock that features two HDMI 2.0 ports and one DisplayPort 1.4 port, making it useful for both PC and console gamers (Xreal’s Neo only has USB-C, while Viture’s competing Pro Mobile Dock has HDMI and USB-C, but not DisplayPort). This Asus dock will let you toggle between video sources with a single button.

Xreal boasts a 57-degree field of view for this model, which is on the high end of what you can get in most AR glasses right now (it matches what the company’s $649 One Pro offer). It claims that they can cover 95 percent of the viewable space with a massive 171-inch screen placed at the virtual equivalent of 4 meters in front of you. Like other recent Xreal models, the ROG Xreal R1 have three degrees of freedom, allowing you to anchor the screen in place virtually or let it follow your head’s movements.

The ROG Xreal R1 will launch in the first half of this year. The company hasn’t yet shared a price.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-50')">
            <div class="source">The Verge</div>
            <div class="title">Asus finally gives its ROG Zephyrus Duo gaming laptop the true dual screens it deserves</div>
            <div class="meta">2026-01-06</div>
        </div>
        
        <div id="content-50" style="display:none;">
            <h2>Asus finally gives its ROG Zephyrus Duo gaming laptop the true dual screens it deserves</h2>
            <p><strong>The Verge | 2026-01-06</strong></p>
            <a class="original-link" href="https://www.theverge.com/news/851827/asus-rog-zephyrus-duo-dual-screen-gaming-laptop-ces-2026">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">﻿And its conventional single-screen Zephyrus G14 and G16 cousins get a modest refresh with a new Intel option.

﻿And its conventional single-screen Zephyrus G14 and G16 cousins get a modest refresh with a new Intel option.

The Asus ROG Zephyrus Duo is back, but for CES 2026 both its screens are going full edge-to-edge — like a Zenbook Duo built for gaming. The original Zephyrus Duo was a quirky keyboard-in-the-front-club member, with a 15.6-inch main display and a 14.1-inch-wide, skinny touchscreen crammed between the hinge and side-by-side keyboard and trackpad. The new model features two full-size 16-inch 3K 120Hz OLED HDR displays that can reach 1,100 nits of peak brightness and a detachable keyboard / trackpad you can use wirelessly or over the bottom display.

And since this multi-screen monster is a gaming laptop, it offers Intel Panther Lake and Nvidia RTX 50-series GPUs (up to the RTX 5090). Pricing isn’t finalized, but it’s expected to launch in mid-to-late Q2 2026.

The new Zephyrus Duo is basically a double Zephyrus G16, so it’s a little chunkier at 0.77 inches / 19.6mm thick, and it weighs 6.28 pounds / 2.85kg. The detachable keyboard deck allows you to use its dual screens in two-up or side-by-side dual-screen positions, tent mode, flat mode, or as a normal single-screen laptop. Like the G16, it has a plethora of ports including HDMI 2.1, USB-C / Thunderbolt 4, USB-A, and a full-size SD card slot.

I got a glimpse of the new Zephyrus Duo at an early preview event, and holy hell am I excited for this thing. We’ve long been big fans of Asus ROG Zephyrus laptops here at The Verge, because they’re so versatile as travel-friendly laptops that are great for both work and gaming. The thought of taking that same formula and turning it into a multi-display setup for new levels of multitasking sounds incredibly compelling. (Battlefield 6 on one screen and WordPress and Slack on the other, anyone?)

As for the conventional ROG Zephyrus G14 and ROG Zephyrus G16 gaming laptops, they’re getting a modest but nice-sounding refresh with Intel Panther Lake chips. The design remains mostly unchanged, with RTX 50-series GPUs on offer, but the slash lighting on the lid is now 35 LED segments instead of just seven — and it can now show the battery level. The hinges are easier to open, the OLED displays are now factory-calibrated and HDR-compatible (reaching up to 1,000 nits of brightness), and the bottom panel is redesigned for better cooling that Asus claims enables improved performance.

Also, the G14 now sports a full-size SD card slot (hooray for us photographers) and will be available for the first time with Intel as well as its usual AMD options. The new G14 and G16 don’t have official pricing yet, but they’re both expected in mid-to-late Q2 2026 like their dual-screen cousin.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-51')">
            <div class="source">The Verge</div>
            <div class="title">This limited-edition tablet is the closest you can get to using Hideo Kojima’s computer</div>
            <div class="meta">2026-01-06</div>
        </div>
        
        <div id="content-51" style="display:none;">
            <h2>This limited-edition tablet is the closest you can get to using Hideo Kojima’s computer</h2>
            <p><strong>The Verge | 2026-01-06</strong></p>
            <a class="original-link" href="https://www.theverge.com/news/851853/this-limited-edition-tablet-is-the-closest-you-can-get-to-using-hideo-kojimas-computer">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The Asus ROG Flow Z13 x Kojima Productions is a limited-edition gaming tablet dripping with futuristic style.

The Asus ROG Flow Z13 x Kojima Productions is a limited-edition gaming tablet dripping with futuristic style.

Asus is no stranger to odd yet badass limited editions of its one-of-a-kind gaming tablet, and for CES 2026 it’s collaborating with Kojima Productions on the best-looking one yet. The Asus ROG Flow Z13 x Kojima Productions edition takes last year’s excellent AMD Strix Halo-equipped gaming tablet and dresses it up in a Yoji Shinkawa design, complete with a two-tone metallic gold and black color combo and carbon fiber rear panel cover.

The tablet and its kickstand are decked out in angular geometric lines reminiscent of the gritty mechanized future tech seen in the Death Stranding games, as well as the design language of Kojima Productions mascot Ludens. It’s also got military tech-style warnings and mottos printed on it, ranging from “Heat vent do not cover” to “For Ludens who dare” — a play on the ROG motto, “For those who dare.”

The KJP edition includes a white attache hard case, and there’s also a matching white headset, mouse, and desk mat sold separately (or bundled in some countries). The ROG Flow Z13-KJP will launch in mid-to-late Q1 2026. There isn’t a price yet, but that should be finalized closer to availability. Asus reps tell me that exclusive variants are being made for the Kojima Productions team, which will feature a special keyboard with metallic keycaps.

I didn’t touch either Death Stranding game, but part of me wants this tablet. I loved the ROG Flow Z13 when I reviewed it last year, and seeing Yoji Shinkawa’s iconic style all over it puts a giant exclamation point over my head.

Photography by Antonio G. Di Benedetto / The Verge

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-52')">
            <div class="source">The Verge</div>
            <div class="title">Ecovacs adds a mop cover to its flagship robot vacuum</div>
            <div class="meta">2026-01-06</div>
        </div>
        
        <div id="content-52" style="display:none;">
            <h2>Ecovacs adds a mop cover to its flagship robot vacuum</h2>
            <p><strong>The Verge | 2026-01-06</strong></p>
            <a class="original-link" href="https://www.theverge.com/tech/853777/ecovacs-deebot-x12-omnicyclone-robot-vacuum-mop-cover">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The X12 also features a longer roller mop and can pretreat stains.

The X12 also features a longer roller mop and can pretreat stains.

If you buy something from a Verge link, Vox Media may earn a commission. See our ethics statement.

Ecovacs launched the second generation of its top-of-the-line robot vacuum and mop at CES 2026 this week. The Deebot X12 OmniCyclone is the follow-up to the $1,500 X11, which launched at IFA in September 2025. Yes, just three months ago.

The X12 keeps the same overall design of the X11, including the handy bagless dust bin in the multifunction dock, but adds a stain pretreat feature, a longer roller mop, and a smart cover for the mop to protect your carpets from getting damp. No other specs, pricing, or a release date have been announced yet.

The midrange line also got an upgrade with the launch of the T90 Pro Omni, an upgrade from the T80 Omni. The new model adds PowerBoost Charging from the X line, which lets the robot charge whenever it goes back to the base to clean itself, helping it finish the job faster.

The company also announced its first robotic pool cleaner, the Ultramarine, and an emotional companion robot called LilMilo. The latter is a robotic dog that uses AI and “lifelike biometrics” to recognize voices, adapt to user habits, and develop a personality, according to a press release from Ecovacs.

The company said the new category additions to its lineup are part of its mission “to create a whole-home robotics ecosystem.” It also announced updates to its GOAT robot mower line and Winbot W3 Omni window-washing robot, putting it well on its way to filling up your home with an awful lot of robots.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-53')">
            <div class="source">The Verge</div>
            <div class="title">The MSI Crosshair 16 Max HX features a slimmer chassis and stronger specs</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-53" style="display:none;">
            <h2>The MSI Crosshair 16 Max HX features a slimmer chassis and stronger specs</h2>
            <p><strong>The Verge | 2026-01-05</strong></p>
            <a class="original-link" href="https://www.theverge.com/news/850944/ces-2026-msi-crosshair-16-max">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">This year’s Crosshair pairs a spec bump with a subtle design refresh.

This year’s Crosshair pairs a spec bump with a subtle design refresh.

The latest MSI Crosshair gaming laptop announced at CES today doesn’t make any major changes, but does manage to fit improved specs into less space. According to MSI, the Crosshair 16 Max HX is 14.3 percent thinner than its predecessor, a difference of 2mm.

The slightly more svelte chassis comes with slightly updated specs, including a second-generation Intel Core Ultra 9 processor, an Nvidia GeForce RTX 50-series GPU, up to 128GB of DDR5 RAM, and a 16-inch (2560 x 1600) 240Hz OLED display. The revamped Crosshair also supports MSI OverBoost Ultra, allowing users to boost the GPU by up to 115W and the CPU by 85W (or 140W when focused exclusively on the CPU).

While the Crosshair 16 Max HX has some updates over the previous generation, it maintains the more inconspicuous chassis design. The 2026 Crosshair has a bit of RGB on the keyboard, but otherwise keeps the design fairly low-key, with an MSI logo and subtle mecha-style accents on the lid.

The Crosshair 16 Max HX is expected to launch as early as April 2026 starting at $1,649.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-54')">
            <div class="source">MIT Technology Review</div>
            <div class="title">The overlooked driver of digital transformation</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-54" style="display:none;">
            <h2>The overlooked driver of digital transformation</h2>
            <p><strong>MIT Technology Review | 2026-01-05</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2026/01/05/1124662/the-overlooked-driver-of-digital-transformation/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">When business leaders talk about digital transformation, their focus often jumps straight to cloud platforms, AI tools, or collaboration software. Yet, one of the most fundamental enablers of how organizations now work, and how employees experience that work, is often overlooked: audio.

As Genevieve Juillard, CEO of IDC, notes, the shift to hybrid collaboration made every space, from corporate boardrooms to kitchen tables, meeting-ready almost overnight. In the scramble, audio quality often lagged, creating what research now shows is more than a nuisance. Poor sound can alter how speakers are perceived, making them seem less credible or even less trustworthy.

&quot;Audio is the gatekeeper of meaning,” stresses Julliard. “If people can&#39;t hear clearly, they can&#39;t understand you. And if they can&#39;t understand you, they can&#39;t trust you, and they can&#39;t act on what you said. And no amount of sharp video can fix that.&quot; Without clarity, comprehension and confidence collapse.

For Shure, which has spent a century advancing sound technology, the implications extend far beyond convenience. Chris Schyvinck, Shure’s president and CEO, explains that ineffective audio undermines engagement and productivity. Meetings stall, decisions slow, and fatigue builds.

&quot;Use technology to make hybrid meetings seamless, and then be clear on which conversations truly require being in the same physical space,&quot; says Juillard. &quot;If you can strike that balance, you&#39;re not just making work more efficient, you&#39;re making it more sustainable, you&#39;re also making it more inclusive, and you&#39;re making it more resilient.&quot;

When audio is prioritized on equal footing with video and other collaboration tools, organizations can gain something rare: frictionless communication. That clarity ensures the machines listening in, from AI transcription engines to real-time translation systems, can deliver reliable results.

The research from Shure and IDC highlights two blind spots for leaders. First, buying decisions too often privilege price over quality, with costly consequences in productivity and trust. Second, organizations underestimate the stress poor sound imposes on employees, intensifying the cognitive load of already demanding workdays. Addressing both requires leaders to view audio not as a peripheral expense but as core infrastructure.

Looking ahead, audio is becoming inseparable from AI-driven collaboration. Smarter systems can already filter out background noise, enhance voices in real time, and integrate seamlessly into hybrid ecosystems.

&quot;We should be able to provide improved accessibility and a more equitable meeting experience for people,&quot; says Schyvinck.

For Schyvinck and Juillard, the future belongs to companies that treat audio transformation as an integral part of digital transformation, building workplaces that are more sustainable, equitable, and resilient.

This episode of Business Lab is produced in partnership with Shure.

Megan Tatum: From MIT Technology Review, I&#39;m Megan Tatum, and this is Business Lab, the show that helps business leaders make sense of new technologies coming out of the lab and into the marketplace.This episode is produced in partnership with Shure.As companies continue their journeys towards digital transformation, audio modernization is an often overlooked but key component of any successful journey. Clear audio is imperative not only for quality communication, but also for brand equity, both for internal and external stakeholders and even the company as a whole.Two words for you: audio transformation.My guests today are Chris Schyvinck, President and CEO at Shure. And Genevieve Juillard, CEO at IDC.Welcome Chris and Genevieve.

Chris Schyvinck: It&#39;s really nice to be here. Thank you very much.

Genevieve Juillard: Yeah, thank you so much for having us. Great to be here.

Megan Tatum: Thank you both so much for being here. Genevieve, we could start with you. Let&#39;s start with some history perhaps for context. How would you describe the evolution of audio technology and how use cases and our expectations of audio have evolved? What have been some of the major drivers throughout the years and more recently, perhaps would you consider the pandemic to be one of those drivers?

Genevieve: It&#39;s interesting. If you go all the way back to 1976, Norman Macrae of The Economist predicted that video chat would actually kill the office, that people would just work from home. Obviously, that didn&#39;t happen then, but the core technology for remote collaboration has actually been around for decades. But until the pandemic, most of us only experienced it in very specific contexts. Offices had dedicated video conferencing rooms and most ran on expensive proprietary systems. And then almost overnight, everything including literally the kitchen table had to be AV ready. The cultural norms shifted just as fast. Before the pandemic, it was perfectly fine to keep your camera off in a meeting, and now that&#39;s seen as disengaged or even rude, and that changes what normalized video conferencing and my hybrid meetings.

But in a rush to equip a suddenly remote workforce, we hit two big problems. Supply chain disruptions and a massive spike in demand. High-quality gear was hard to get so low-quality audio and video became the default. And here&#39;s a key point. We now know from research that audio quality matters more than video quality for meeting outcomes. You can run a meeting without video, but you can&#39;t run a meeting without clear audio. Audio is the gatekeeper of meaning. If people can&#39;t hear clearly, they can&#39;t understand you. And if they can&#39;t understand you, they can&#39;t trust you and they can&#39;t act on what you said. And no amount of sharp video can fix that.

Megan: Oh, true. It&#39;s fascinating, isn&#39;t it? And Chris, Shure and IDC recently released some research titled “The Hidden Influencer Rethinking Audio Could Impact Your Organization Today, Tomorrow, and Forever.” The research highlighted that importance of audio that Genevieve&#39;s talking about in today&#39;s increasingly virtual world. What did you glean from those results and did anything surprise you?

Chris: Yeah, well, the research certainly confirmed a lot of hunches we&#39;ve had through the years. When you think about a company like Shure that&#39;s been doing audio for 100 years, we just celebrated that anniversary this year.

Chris: Our legacy business is over more in the music and performance arena. And so just what Genevieve said in terms of, &quot;Yeah, you can have a performance and look at somebody, but that&#39;s like 10% of it, right? 90% is hearing that person sing, perform, and talk.&quot; We&#39;ve always, of course, from our perspective, understood that clean, clear, crisp audio is what is needed in any setting. When you translate what&#39;s happening on the stage into a meeting or collaboration space at a corporation, we&#39;ve thought that that is just equally as important.

And we always had this hunch that if people don&#39;t have the good audio, they&#39;re going to have fatigue, they&#39;re going to get a little disengaged, and the whole meeting is going to become quite unproductive. The research just really amplified that hunch for us because it really depicted the fact that people not only get kind of frustrated and disengaged, they might actually start to distrust what the other person with bad audio is saying or just cast it in a different light. And the degree to which that frustration becomes almost personal was very surprising to us. Like I said, it validated some hunches, but it really put an exclamation point on it for us.

Megan: And Genevieve, based on the research results, I understand that IDC pulled together some recommendations for organizations. What is it that leaders need to know and what is the biggest blind spot for them to overcome as well?

Genevieve: The biggest blind spot is this. If your microphone has poor audio quality, like Chris said, people will literally perceive you as less intelligent and less trustworthy. And by the way, that&#39;s not an opinion. It&#39;s what the science says. But yet, when we surveyed first time business buyers, the number one factor they used to choose audio gear was price. However, for repeat buyers, the top factor flipped to audio quality. My guess is they learn the lesson the hard way. The second blind spot is to Chris&#39;s point, it&#39;s the stress that bad audio creates. Poor sound forces your brain to work harder to decode what&#39;s being said. That&#39;s a cognitive load and it creates stress. And over a full day of meetings, that stress adds up. Now, we don&#39;t have long-term studies yet on the effects, but we do know that prolonged stress is something that every company should be working to reduce.

Good audio lightens that cognitive load. It keeps people engaged and it levels the playing field. Whether you&#39;re in a room or you&#39;re halfway across the world, and here&#39;s one that&#39;s often overlooked, bad audio can sabotage AI transcription tools. As AI becomes more and more central to everyday work, that starts to become really critical. If your audio isn&#39;t clear, the transcription won&#39;t be accurate. And there&#39;s a world of difference between working, for example, the consulting department and the insulting department, and that is an actual example from the field.

The bottom line is you fix the audio, you cut friction, you save time, and you make meetings more productive.

Megan: I mean, it&#39;s just a huge game changer, isn&#39;t it, really? I mean, and given that, Chris, in your experience across industries, are audio technologies being included in digital transformation strategies and also artificial intelligence implementation? Do we need a separate audio transformation perhaps?

Chris: Well, like I mentioned earlier, yes, people tend to initially focus on that visual platform, but increasingly the attention to audio is really coming into focus. And I&#39;d hate to tear apart audio as a separate sort of strategy because at the same time, we, as an audio expert, are trying to really seamlessly integrate audio into the rest of the ecosystem. It really does need to be put on an equal footing with the rest of the components in that ecosystem. And to Genevieve&#39;s point, as we are seeing audio and video systems with more AI functionalities, the importance of real-time translations that are being used, voice recognition, being able to attribute who said what in a meeting and take action items, it&#39;s really, I think starting to elevate the importance of that clear audio. And it&#39;s got to be part of a comprehensive, really collaboration plan that helps some company figure out what&#39;s their whole digital transformation about. It just really has to be included in that comprehensive plan, but put on equal footing with the rest of the components in that system.

Megan: Yeah, absolutely. And in the broader landscape, Genevieve, in terms of discussing the importance of audio quality, what have you noticed across research projects about the effects of good and bad audio, not only from that company perspective, but from employee and client perspectives as well?

Genevieve: Well, let&#39;s start with employees.

Genevieve: Bad audio adds friction you don&#39;t need, we&#39;ve talked about this. When you&#39;re straining to hear or make sense of what&#39;s being said, your brain is burning energy on decoding instead of contributing. That frustration, it builds up, and by the end of the day, it hurts productivity. From a company perspective, the stakes get even higher. Meetings are where decisions happen or at least where they&#39;re supposed to happen. And if people can&#39;t hear clearly, decisions get delayed, mistakes creep in, and the whole process slows down. Poor audio doesn&#39;t just waste time, it chips away at the ability to move quickly and confidently. And then there&#39;s the client experience. So whether it&#39;s in sales, customer service, or any external conversation, poor audio can make you sound less credible and yet less trustworthy. Again, that&#39;s not my opinion. That&#39;s what the research shows. So that&#39;s quite a big risk when you&#39;re trying to close a deal or solve a major problem.

The takeaway is good audio, it matters, it&#39;s a multiplier. It makes meetings more productive and it can help decisions happen faster and client interactions be stronger.

Megan: It&#39;s just so impactful, isn&#39;t it, in so many different ways. I mean, Chris, how are you seeing these research results reflected as companies work through digital and AI transformations? What is it that leaders need to understand about what is involved in audio implementation across their organization?

Chris: Well, like I said earlier, I do think that audio is finally maybe getting its place in the spotlight a little bit up there with our cousins over in the video side. Audio, it&#39;s not just a peripheral aspect anymore. It&#39;s a very integral part of that sort of comprehensive collaboration plan I was talking about earlier. And when we think about how can we contribute solutions that are really more easy to use for our end users, because if you create something complicated, we were talking about the days gone by of walking into a room. It&#39;s a very complicated system, and you need to find the right person that knows how to run it. Increasingly, you just need to have some plug and play kind of solutions. We&#39;re thinking about a more sustainable strategy for our solutions where we make really high-quality hardware. We&#39;ve done that account for a hundred years. People will come up to me and tell the story of the SM58 microphone they bought in 1980 and how they&#39;re still using it every day.

We know how to do that part of it. If somebody is willing to make that investment upfront, put some high-quality hardware into their system, then we are getting to the point now where updates can be handled via software downloads or cloud connectivity. And just really being able to provide sort of a sustainable solution for people over time.

More in our industry, we&#39;re collaborating with other industry partners to go in that direction, make something that&#39;s very simple for anybody to walk into a room or on their individual at home setup and do something pretty simple. And I think we have the right industry groups, the right industry associations that can help make sure that the ecosystems have the proper standards, the right kind of ways to make sure everything is interoperable within a system. We&#39;re all kind of heading in that direction with that end user in mind.

Megan: Fantastic. And when the internet of things was emerging, efforts began to create sort of these data ecosystems, it seems there&#39;s an argument to be made that we need audio ecosystems as well. I wonder, Chris, what might an audio ecosystem look like and what would be involved in implementation?

Chris: Well, I think it does have to be part of that bigger ecosystem I was just talking about where we do collaborate with others in industry and we try to make sure that we&#39;re all playing by the kind of same set of rules and protocols and standards and whatnot. And when you think about compatibility across all the devices that sit in a room or sit in your, again, maybe your at home setup, making sure that the audio quality is as good as it can be, that you can interoperate with everything else in the system. That&#39;s just become very paramount in our day-to-day work here. Your hardware has to be scalable like I just alluded to a moment ago. You have to figure out how you can integrate with existing technologies, different platforms.

We were joking when we came into this session that when you&#39;re going from the platform at your company, maybe you&#39;re on Teams and you go into a Zoom setting or you go into a Google setting, you really have to figure out how to adapt to all those different sort of platforms that are out there. I think the ecosystem that we&#39;re trying to build, we&#39;re trying to be on that equal footing with the rest of the components in that system. And people really do understand that if you want to have extra functionalities in meetings and you want to be able to transcribe or take notes and all of that, that audio is an absolutely critical piece.

Megan: Absolutely. And speaking of bit of all those different platforms and use cases, that sort of audio is so relevant to Genevieve that goes back to this idea of in audio one size does not fit all and needs may change. How can companies also plan their audio implementations to be flexible enough to meet current needs and to be able to grow with future advancements?

Genevieve: I&#39;m glad you asked this question. Even years after the pandemic, many companies, they&#39;re still trying to get the balance right between remote, in office, how to support it. But even if a company has a strict return to office in-person policy, the reality is that work still isn&#39;t going away for that company. They may have teams across cities or countries, clients and external stakeholders will have their own office preferences that they have to adapt to. Supporting hybrid work is actually becoming more important, not less. And our research shows that companies are leaning into, not away from, hybrid setups. About one third of companies are now redesigning or resizing office spaces every single year. For large organizations with multiple sites, staggered leases, that&#39;s a moving target. It&#39;s really important that they have audio solutions that can work before, during, after all of those changes that they&#39;re constantly making. And so that&#39;s where flexibility becomes really important. Companies need to buy not just for right now, but for the future.

And so here&#39;s IDC&#39;s kind of pro-tip, which is make sure as a company that you go with a provider that offers top-notch audio quality and also has strong partnerships and certifications with the big players and communications technology because that will save you money in the long run. Your systems will stay compatible, your investments will last longer, and you won&#39;t be scrambling when that next shift happens.

Megan: Of course. And speaking of building for the future, as companies begin to include sustainability in their company goals, Chris, I wonder how can audio play a role in those sustainability efforts and how might that play into perhaps the return on investment in building out a high-quality audio ecosystem?

Chris: Well, I totally agree with what Genevieve just said in terms of hybrid work is not going anywhere. You get all of those big headlines that talk about XYZ company telling people to get back into the office. And I saw a fantastic piece of data just last week that showed the percent of in-office hours of the American workers versus out-of-office remote kind of work. It has basically been flatlined since 2022. This is our new way of working. And of course, like Genevieve mentioned, you have people in all these different locations. And in a strange way, living through the pandemic did teach us that we can do some things by not having to hop on an airplane and travel to go somewhere. Certainly that helps with a more sustainable strategy over time, and you&#39;re saving on travel and able to get things done much more quickly.

And then from a product offering perspective, I&#39;ll go back to the vision I was painting earlier where we and others in our industry see that we can create great solid hardware platforms. We&#39;ve done it for decades, and now that advancements around AI and all of our software that enables products and everything else that has happened in the last probably decade, we can get enhancements and additions and new functionality to people in simpler ways on existing hardware. I think we&#39;re all careening down this path of having a much more sustainable ecosystem for all collaboration. It&#39;s really quite an exciting time, and that pays off with any company implementing a system, their ROI is going to be much better in the long run.

Megan: Absolutely. And Genevieve, what trends around sustainability are you seeing? What opportunities do you see for audio to play into those sustainability efforts going forward?

Genevieve: Yeah, similar to Chris. In some industries, there&#39;s still a belief that the best work happens when everyone&#39;s in the same room. And yes, face-to-face time is really important for building relationships, for brainstorming, for closing big deals, but it does come at a cost. The carbon footprint of daily commutes, the sales visits, the constant business travel. And then there&#39;s the basic consideration, as we&#39;ve talked about, of just pure practicality. The good news is with the right AV setup, especially high-quality audio, many of those interactions can happen virtually without losing effectiveness, as Chris said it, but our research shows it.

Our research shows that virtual meetings can be just as productive as in-person ones, and every commute or flight you avoid, of course makes a measurable sustainability impact. I don&#39;t think, personally, that the takeaway is replace all in-person meetings, but instead it&#39;s to be intentional. Use technology to make hybrid meetings seamless, and then be clear on which conversations truly require being in the same physical space. If you can strike that balance, you&#39;re not just making work more efficient, you&#39;re making it more sustainable, you&#39;re also making it more inclusive, and you&#39;re making it more resilient.

Megan: Such an important point. And let&#39;s close with a future forward look, if we can. Genevieve, what innovations or advancements in the audio field are you most excited to see to come to fruition, and what potential interesting use cases do you see on the horizon?

Genevieve: I&#39;m especially interested in how AI and audio are converging. We&#39;re now seeing AI that can identify and isolate human voices in noisy environments. For example, right now, there are some jets flying overhead. It&#39;s very loud in here, but I suspect you may not even know that that&#39;s happening.

Genevieve: Right. That technology, it&#39;s pulling voices forward so that conversations like ours are crystal clear. And that&#39;s a big deal, especially as companies invest more and more in AI tools, especially for that translating, transcribing and summarizing meetings. But as we&#39;ve talked before, AI is only as good as the audio it hears. If the sound is poor or a word gets misheard, the meaning can shift entirely. And sometimes that&#39;s just inconvenient, or it can even be funny. But in really high stakes settings, like healthcare for example, a single mis-transcribed word can have serious consequences. So that&#39;s why our position as high quality audio is critical and it&#39;s necessary for making AI powered communication accurate, trustworthy, and useful because when the input is clean, the output can actually live up to its promise.

Megan: Fantastic. And Chris, finally, what are you most excited to see developed? What advancements are you most looking forward to seeing?

Chris: Well, I really do believe that this is one of the most exciting times that I know I&#39;ve lived through in my career. Just the pace of how fast technology is moving, the sudden emergence of all things AI. I was actually in a roundtable session of CEOs yesterday from lots of different industries, and the facilitator was talking about change management internally in companies as you&#39;re going through all of these technology shifts and some of the fear that people have around AI and things like that. And the facilitator asked each of us to give one word that describes how we&#39;re feeling right now. And the first CEO that went used the word dread. And that absolutely floored me because you enter into these eras with some skepticism and trying to figure out how to make things work and go down the right path. But my word was truly optimism.

When I look at all the ways that we are able to deliver better audio to people more quickly, there&#39;s so many opportunities in front of us. We&#39;re working on things outside of AI like algorithms that Genevieve just mentioned that filter out the bad sounds that you don&#39;t want entering into a meeting. We&#39;ve been doing that for quite a long time now. There&#39;s also opportunities to do real time audio improvements, enhancements, make audio more personal for people. How do they want to be able to very simply, through voice commands perhaps, adjust their audio? There shouldn&#39;t have to be a whole lot of techie settings that come along with our solutions.

We should be able to provide improved accessibility and a little bit more equitable meeting experience for people. And we&#39;re looking at tech technology solutions around immersive audio. How can you maybe feel like you&#39;re a bit more engaged in the meeting, kind of creating some realistic virtual experiences, if you will. There&#39;s just so many opportunities in front of us, and I can just picture a day when you walk into a room and you tell the room, &quot;Hey, call Genevieve. We&#39;re going to have a meeting for an hour, and we might need to have Megan on call to come in at a certain time.&quot;

And all of this will just be very automatic, very seamless, and we&#39;ll be able to see each other and talk at the same time. And this isn&#39;t years away. This is happening really, really quickly. And I do think it&#39;s a really exciting time for audio and just all together collaboration in our industry.

Megan: Absolutely. Sounds like there&#39;s plenty of reason to be optimistic. Thank you both so much.That was Chris Schyvinck, President and CEO at Shure. And Genevieve Juillard, CEO at IDC, whom I spoke with from Brighton, England.That&#39;s it for this episode of Business Lab. I&#39;m your host, Megan Tatum. I&#39;m a contributing editor at Insights, the custom publishing division of MIT Technology Review. We were founded in 1899 at the Massachusetts Institute of Technology, and you can find us in print on the web and at events each year around the world. For more information about us and the show, please check out our website at technologyreview.com.

This show is available wherever you get your podcasts. And if you enjoy this episode, we hope you&#39;ll take a moment to rate and review us. Business Lab is a production of MIT Technology Review, and this episode was produced by Giro Studios. Thanks for listening.

This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff. It was researched, designed, and written entirely by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.

The sunshine vitamin could affect your immune system and heart health.

The experimental model won&#39;t compete with the biggest and best, but it could tell us why they behave in weird ways—and how trustworthy they really are.

Four ways to think about this year&#39;s reckoning

As early electric cars age out, hundreds of thousands of used batteries are flooding the market, fueling a gray recycling economy even as Beijing and big manufacturers scramble to build a more orderly system.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-55')">
            <div class="source">MIT Technology Review</div>
            <div class="title">The Download: Kenya’s Great Carbon Valley, and the AI terms that were everywhere in 2025</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-55" style="display:none;">
            <h2>The Download: Kenya’s Great Carbon Valley, and the AI terms that were everywhere in 2025</h2>
            <p><strong>MIT Technology Review | 2026-01-05</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2026/01/05/1130672/the-download-kenyas-great-carbon-valley-and-the-ai-terms-that-were-everywhere-in-2025/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">This is today&#39;s edition of The Download, our weekday newsletter that provides a daily dose of what&#39;s going on in the world of technology.

Welcome to Kenya’s Great Carbon Valley: a bold new gamble to fight climate change

In June last year, startup Octavia Carbon began running a high-stakes test in the small town of Gilgil in south-central Kenya. It’s harnessing some of the excess energy generated by vast clouds of steam under the Earth’s surface to power prototypes of a machine that promises to remove carbon dioxide from the air in a manner that the company says is efficient, affordable, and—crucially—scalable.The company’s long-term vision is undoubtedly ambitious—it wants to prove that direct air capture (DAC), as the process is known, can be a powerful tool to help the world keep temperatures from rising to ever more dangerous levels.

But DAC is also a controversial technology, unproven at scale and wildly expensive to operate. On top of that, Kenya’s Maasai people have plenty of reasons to distrust energy companies. Read the full story.

This article is also part of the Big Story series: MIT Technology Review’s most important, ambitious reporting. The stories in the series take a deep look at the technologies that are coming next and what they will mean for us and the world we live in. Check out the rest of them here.

AI Wrapped: The 14 AI terms you couldn’t avoid in 2025

If the past 12 months have taught us anything, it’s that the AI hype train is showing no signs of slowing. It’s hard to believe that at the beginning of the year, DeepSeek had yet to turn the entire industry on its head, Meta was better known for trying (and failing) to make the metaverse cool than for its relentless quest to dominate superintelligence, and vibe coding wasn’t a thing.

If that’s left you feeling a little confused, fear not. Our writers have taken a look back over the AI terms that dominated the year, for better or worse. Read the full list.

MIT Technology Review’s most popular stories of 2025

2025 was a busy and productive year here at MIT Technology Review. We published magazine issues on power, creativity, innovation, bodies, relationships, and security. We hosted 14 exclusive virtual conversations with our editors and outside experts in our subscriber-only series, Roundtables, and held two events on MIT’s campus. And we published hundreds of articles online, following new developments in computing, climate tech, robotics, and more.As the new year begins, we wanted to give you a chance to revisit some of this work with us. Whether we were covering the red-hot rise of artificial intelligence or the future of biotech, these are some of the stories that resonated the most with our readers.

I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.

1 Washington’s battle to break up Big Tech is in perilA string of judges have opted not to force them to spin off key assets. (FT $)+ Here’s some of the major tech litigation we can expect in the next 12 months. (Reuters)

2 Disinformation about the US invasion of Venezuela is rife on social mediaAnd the biggest platforms don’t appear to be doing much about it. (Wired $)+ Trump shared a picture of captured president Maduro on Truth Social. (NYT $)

3 Here’s what we know about Big Tech’s ties to the Israeli militaryAI is central to its military operations, and giant US firms have stepped up to help. (The Guardian)4 Alibaba’s AI tool is detecting cancer cases in ChinaPANDA is adept at spotting pancreatic cancer, which is typically tough to identify. (NYT $)+ How hospitals became an AI testbed. (WSJ $)+ A medical portal in New Zealand was hacked into last week. (Reuters)

5 This Discord community supports people recovering from AI-fueled delusionsThey say reconnecting with fellow humans is an important step forward. (WP $)+ The looming crackdown on AI companionship. (MIT Technology Review)

6 Californians can now demand data brokers delete their personal information Thanks to a new tool—but there’s a catch. (TechCrunch)+ This California lawmaker wants to ban AI from kids’ toys. (Fast Company $)7 Chinese peptides are flooding into Silicon ValleyThe unproven drugs promise to heal injuries, improve focus and reduce appetite—and American tech workers are hooked. (NYT $)

8 Alaska’s court system built an AI assistant to navigate probateBut the project has been plagued by delays and setbacks. (NBC News)+ Inside Amsterdam’s high-stakes experiment to create fair welfare AI. (MIT Technology Review)

9 These ghostly particles could upend how we think about the universeThe standard model of particle physics may have a crack in it. (New Scientist $)+ Why is the universe so complex and beautiful? (MIT Technology Review)10 Sick of the same old social media apps?Give these alternative platforms a go. (Insider $)

“Just an unbelievable amount of pollution.”

—Sharon Wilson, a former oil and gas worker who tracks methane releases, tells the Guardian what a thermal imaging camera pointed at xAI’s Colossus datacentre has revealed.

How aging clocks can help us understand why we age—and if we can reverse itWrinkles and gray hairs aside, it can be difficult to know how well—or poorly—someone’s body is truly aging. A person who develops age-related diseases earlier in life, or has other biological changes associated with aging, might be considered “biologically older” than a similar-age person who doesn’t have those changes. Some 80-year-olds will be weak and frail, while others are fit and active.Over the past decade, scientists have been uncovering new methods of looking at the hidden ways our bodies are aging. And what they’ve found is changing our understanding of aging itself. Read the full story.—Jessica Hamzelou

A place for comfort, fun and distraction to brighten up your day. (Got any ideas? Drop me a line or skeet &#39;em at me.)

+ You heard it here first: 2026 is the year of cabbage (yes, cabbage.)+ Darts is bigger than ever. So why are we still waiting for the first great darts video game? 🎯+ This year’s CES is already off to a bang, courtesy of an essential, cutting-edge vibrating knife.+ At least one good thing came out of that Stranger Things finale—streams of Prince’s excellent back catalog have soared.

Plus: OpenAI is sounding the &quot;code red&quot; alarm

Plus: TikTok has finally signed a deal to keep operating in the US

Plus: China has built a major chip-making machine

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-56')">
            <div class="source">MIT Technology Review</div>
            <div class="title">What’s next for AI in 2026</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-56" style="display:none;">
            <h2>What’s next for AI in 2026</h2>
            <p><strong>MIT Technology Review | 2026-01-05</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2026/01/05/1130662/whats-next-for-ai-in-2026/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">MIT Technology Review’s What’s Next series looks across industries, trends, and technologies to give you a first look at the future. You can read the rest of them here.

In an industry in constant flux, sticking your neck out to predict what’s coming next may seem reckless. (AI bubble? What AI bubble?) But for the last few years we’ve done just that—and we’re doing it again.

How did we do last time? We picked five hot AI trends to look out for in 2025, including what we called generative virtual playgrounds, a.k.a world models (check: From Google DeepMind’s Genie 3 to World Labs’s Marble, tech that can generate realistic virtual environments on the fly keeps getting better and better); so-called reasoning models (check: Need we say more? Reasoning models have fast become the new paradigm for best-in-class problem solving); a boom in AI for science (check: OpenAI is now following Google DeepMind by setting up a dedicated team to focus on just that); AI companies that are cozier with national security (check: OpenAI reversed position on the use of its technology for warfare to sign a deal with the defense-tech startup Anduril to help it take down battlefield drones); and legitimate competition for Nvidia (check, kind of: China is going all in on developing advanced AI chips, but Nvidia’s dominance still looks unassailable—for now at least).

So what’s coming in 2026? Here are our big bets for the next 12 months.

The last year shaped up as a big one for Chinese open-source models. In January, DeepSeek released R1, its open-source reasoning model, and shocked the world with what a relatively small firm in China could do with limited resources. By the end of the year, “DeepSeek moment” had become a phrase frequently tossed around by AI entrepreneurs, observers, and builders—an aspirational benchmark of sorts.

It was the first time many people realized they could get a taste of top-tier AI performance without going through OpenAI, Anthropic, or Google.

Open-weight models like R1 allow anyone to download a model and run it on their own hardware. They are also more customizable, letting teams tweak models through techniques like distillation and pruning. This stands in stark contrast to the “closed” models released by major American firms, where core capabilities remain proprietary and access is often expensive.

As a result, Chinese models have become an easy choice. Reports by CNBC and Bloomberg suggest that startups in the US have increasingly recognized and embraced what they can offer.

One popular group of models is Qwen, created by Alibaba, the company behind China’s largest e-commerce platform, Taobao. Qwen2.5-1.5B-Instruct alone has 8.85 million downloads, making it one of the most widely used pretrained LLMs. The Qwen family spans a wide range of model sizes alongside specialized versions tuned for math, coding, vision, and instruction-following, a breadth that has helped it become an open-source powerhouse.

Other Chinese AI firms that were previously unsure about committing to open source are following DeepSeek’s playbook. Standouts include Zhipu’s GLM and Moonshot’s Kimi. The competition has also pushed American firms to open up, at least in part. In August, OpenAI released its first open-source model. In November, the Allen Institute for AI, a Seattle-based nonprofit, released its latest open-source model, Olmo 3.

Even amid growing US-China antagonism, Chinese AI firms’ near-unanimous embrace of open source has earned them goodwill in the global AI community and a long-term trust advantage. In 2026, expect more Silicon Valley apps to quietly ship on top of Chinese open models, and look for the lag between Chinese releases and the Western frontier to keep shrinking—from months to weeks, and sometimes less.

T​​he battle over regulating artificial intelligence is heading for a showdown. On December 11, President Donald Trump signed an executive order aiming to neuter state AI laws, a move meant to handcuff states from keeping the growing industry in check. In 2026, expect more political warfare. The White House and states will spar over who gets to govern the booming technology, while AI companies wage a fierce lobbying campaign to crush regulations, armed with the narrative that a patchwork of state laws will smother innovation and hobble the US in the AI arms race against China.

Under Trump’s executive order, states may fear being sued or starved federal funding if they clash with his vision for light-touch regulation. Big Democratic states like California—which just enacted the nation’s first frontier AI law requiring companies to publish safety testing for their AI models—will take the fight to court, arguing that only Congress can override state laws. But states that can’t afford to lose federal funding, or fear getting in Trump’s crosshairs, might fold. Still, expect to see more state lawmaking on hot-button issues, especially where Trump’s order gives states a green light to legislate. With chatbots accused of triggering teen suicides and data centers sucking up more and more energy, states will face mounting public pressure to push for guardrails.

In place of state laws, Trump promises to work with Congress to establish a federal AI law. Don’t count on it. Congress failed to pass a moratorium on state legislation twice in 2025, and we aren’t holding out hope that it will deliver its own bill this year.

AI companies like OpenAI and Meta will continue to deploy powerful super-PACs to support political candidates who back their agenda and target those who stand in their way. On the other side, super-PACs supporting AI regulation will build their own war chests to counter. Watch them duke it out at next year’s midterm elections.

The further AI advances, the more people will fight to steer its course, and 2026 will be another year of regulatory tug-of-war—with no end in sight.

Imagine a world in which you have a personal shopper at your disposal 24-7—an expert who can instantly recommend a gift for even the trickiest-to-buy-for friend or relative, or trawl the web to draw up a list of the best bookcases available within your tight budget. Better yet, they can analyze a kitchen appliance’s strengths and weaknesses, compare it with its seemingly identical competition, and find you the best deal. Then once you’re happy with their suggestion, they’ll take care of the purchasing and delivery details too.But this ultra-knowledgeable shopper isn’t a clued-up human at all—it’s a chatbot. This is no distant prediction, either. Salesforce recently said it anticipates that AI will drive $263 billion in online purchases this holiday season. That’s some 21% of all orders. And experts are betting on AI-enhanced shopping becoming even bigger business within the next few years. By 2030, between $3 trillion and $5 trillion annually will be made from agentic commerce, according to research from the consulting firm McKinsey.

Unsurprisingly, AI companies are already heavily invested in making purchasing through their platforms as frictionless as possible. Google’s Gemini app can now tap into the company’s powerful Shopping Graph data set of products and sellers, and can even use its agentic technology to call stores on your behalf. Meanwhile, back in November, OpenAI announced a ChatGPT shopping feature capable of rapidly compiling buyer’s guides, and the company has struck deals with Walmart, Target, and Etsy to allow shoppers to buy products directly within chatbot interactions.

Expect plenty more of these kinds of deals to be struck within the next year as consumer time spent chatting with AI keeps on rising, and web traffic from search engines and social media continues to plummet.

I’m going to hedge here, right out of the gate. It’s no secret that large language models spit out a lot of nonsense. Unless it’s with monkeys-and-typewriters luck, LLMs won’t discover anything by themselves. But LLMs do still have the potential to extend the bounds of human knowledge.

We got a glimpse of how this could work in May, when Google DeepMind revealed AlphaEvolve, a system that used the firm’s Gemini LLM to come up with new algorithms for solving unsolved problems. The breakthrough was to combine Gemini with an evolutionary algorithm that checked its suggestions, picked the best ones, and fed them back into the LLM to make them even better.

Google DeepMind used AlphaEvolve to come up with more efficient ways to manage power consumption by data centers and Google’s TPU chips. Those discoveries are significant but not game-changing. Yet. Researchers at Google DeepMind are now pushing their approach to see how far it will go.

And others have been quick to follow their lead. A week after AlphaEvolve came out, Asankhaya Sharma, an AI engineer in Singapore, shared OpenEvolve, an open-source version of Google DeepMind’s tool. In September, the Japanese firm Sakana AI released a version of the software called SinkaEvolve. And in November, a team of US and Chinese researchers revealed AlphaResearch, which they claim improves on one of AlphaEvolve’s already better-than-human math solutions.

There are alternative approaches too. For example, researchers at the University of Colorado Denver are trying to make LLMs more inventive by tweaking the way so-called reasoning models work. They have drawn on what cognitive scientists know about creative thinking in humans to push reasoning models toward solutions that are more outside the box than their typical safe-bet suggestions.

Hundreds of companies are spending billions of dollars looking for ways to get AI to crack unsolved math problems, speed up computers, and come up with new drugs and materials. Now that AlphaEvolve has shown what’s possible with LLMs, expect activity on this front to ramp up fast.

For a while, lawsuits against AI companies were pretty predictable: Rights holders like authors or musicians would sue companies that trained AI models on their work, and the courts generally found in favor of the tech giants. AI’s upcoming legal battles will be far messier.

The fights center on thorny, unresolved questions: Can AI companies be held liable for what their chatbots encourage people to do, as when they help teens plan suicides? If a chatbot spreads patently false information about you, can its creator be sued for defamation? If companies lose these cases, will insurers shun AI companies as clients?

In 2026, we’ll start to see the answers to these questions, in part because some notable cases will go to trial (the family of a teen who died by suicide will bring OpenAI to court in November).

At the same time, the legal landscape will be further complicated by President Trump’s executive order from December—see Michelle’s item above for more details on the brewing regulatory storm.

No matter what, we’ll see a dizzying array of lawsuits in all directions (not to mention some judges even turning to AI amid the deluge).

The experimental model won&#39;t compete with the biggest and best, but it could tell us why they behave in weird ways—and how trustworthy they really are.

Four ways to think about this year&#39;s reckoning

They managed to cut the size of the AI reasoning model by more than half—and claim it can now answer politically sensitive questions once off limits in Chinese AI systems.

A conversation with a chatbot can shift people&#39;s political views—but the most persuasive models also spread the most misinformation.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-57')">
            <div class="source">MIT Technology Review</div>
            <div class="title">3 things Will Douglas Heaven is into right now</div>
            <div class="meta">2026-01-02</div>
        </div>
        
        <div id="content-57" style="display:none;">
            <h2>3 things Will Douglas Heaven is into right now</h2>
            <p><strong>MIT Technology Review | 2026-01-02</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2026/01/02/1129409/will-douglas-heaven-el-estepario-siberiano-ed-atkins-laura-jean-mckay/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">My daughter introduced me to El Estepario Siberiano’s YouTube channel a few months back, and I have been obsessed ever since. The Spanish drummer (real name: Jorge Garrido) posts videos of himself playing supercharged cover versions of popular tracks, hitting his drums with such jaw-dropping speed and technique that he makes other pro drummers shake their heads in disbelief. The dozens of reaction videos posted by other musicians are a joy in themselves.

Garrido is up-front about the countless hours that it took to get this good. He says he sat behind his kit almost all day, every day for years. At a time when machines appear to do it all, there’s a kind of defiance in that level of human effort. It’s why my favorites are Garrido’s covers of electronic music, where he out-drums the drum machine. Check out his version of Skrillex and Missy Elliot’s “Ra Ta Ta” and tell me it doesn’t put happiness in your heart.

Watching Sora ­videos of Michael Jackson stealing a box of chicken nuggets or Sam Altman biting into the pink meat of a flame-grilled Pikachu has given me flashbacks to an Ed Atkins exhibition at Tate Britain I saw a few months ago. Atkins is one of the most influential and unsettling British artists of his generation. He is best known for hyper-detailed CG animations of himself (pore-perfect skin, janky movement) that play with the virtual representation of human emotions.

In The Worm we see a CGI Atkins make a long-distance call to his mother during a covid lockdown. The audio is from a recording of an actual conversation. Are we watching Atkins cry or his avatar? Our attention flickers between two realities. “When an actor breaks character during a scene, it’s known as corpsing,” Atkins has said. “I want everything I make to corpse.” Next to Atkins’s work, generative videos look like cardboard cutouts: lifelike but not alive.

What’s it like to be a pet? Australian author Laura Jean McKay’s debut novel, The Animals in That Country, will make you wish you’d never asked. A flu-like pandemic leaves people with the ability to hear what animals are saying. If that sounds too Dr. Dolittle for your tastes, rest assured: These animals are weird and nasty. A lot of the time they don’t even make any sense.

With everybody now talking to their computers, McKay’s book resets the anthropomorphic trap we’ve all fallen into. It’s a brilliant evocation of what a nonhuman mind might contain—and a meditation on the hard limits of communication.

The Cybertruck, sycophantic AI, and humanoid robots all made this year’s list of the biggest technology failures.

Unveiled by the buzzy startup Deep, Vanguard will let teams of scientists live and work on the seabed for a week at a time.

We’ll keep following these developments, but this just wasn’t their year. Here’s why.

It’s free and easy to nominate yourself or someone you know—here’s how.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-58')">
            <div class="source">MIT Technology Review</div>
            <div class="title">Job titles of the future: Head-transplant surgeon</div>
            <div class="meta">2026-01-02</div>
        </div>
        
        <div id="content-58" style="display:none;">
            <h2>Job titles of the future: Head-transplant surgeon</h2>
            <p><strong>MIT Technology Review | 2026-01-02</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2026/01/02/1129416/head-transplant-surgeon-sergio-canavero-future-job/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The Italian neurosurgeon Sergio Canavero has been preparing for a surgery that might never happen. His idea? Swap a sick person’s head—or perhaps just the brain—onto a younger, healthier body.

Canavero caused a stir in 2017 when he announced that a team he advised in China had exchanged heads between two corpses. But he never convinced skeptics that his technique could succeed—or to believe his claim that a procedure on a live person was imminent. The Chicago Tribune labeled him the “P.T. Barnum of transplantation.”

Canavero withdrew from the spotlight. But the idea of head transplants isn’t going away. Instead, he says, the concept has recently been getting a fresh look from life-extension enthusiasts and stealth Silicon Valley startups.

It’s been rocky. After he began publishing his surgical ideas a decade ago, Canavero says, he got his “pink slip” from the Molinette Hospital in Turin, where he’d spent 22 years on staff. “I’m an out-of-the-establishment guy. So that has made things harder, I have to say,” he says.

No other solution to aging is on the horizon. “It’s become absolutely clear over the past years that the idea of some incredible tech to rejuvenate elderly people—­happening in some secret lab, like Google—is really going nowhere,” he says. “You have to go for the whole shebang.”

He means getting a new body, not just one new organ. Canavero has an easy mastery of English idioms and an unexpected Southern twang. He says that’s due to a fascination with American comics as a child. “For me, learning the language of my heroes was paramount,” he says. “So I can shoot the breeze.”

Canavero is now an independent investigator and has advised entrepreneurs who want to create brainless human clones as a source of DNA-matched organs that wouldn’t get rejected by a recipient’s immune system. “I can tell you there are guys from top universities involved,” he says.

Combining the necessary technologies, like reliably precise surgical robots and artificial wombs to grow the clones, is going to be complex and very, very expensive. Canavero lacks the funds to take his plans further, but he believes “the money is out there” for a commercial moonshot project: “What I say to the billionaires is ‘Come together.’ You will all have your own share, plus make yourselves immortal.”

The sunshine vitamin could affect your immune system and heart health.

Yes, you can pay $50,000 to clone a pet. But others are using the technology to rescue endangered species.

A startup’s ads for controversial embryo tests hit the New York City subway.

Questions surround their effects on brain health, pregnancy or long-term use.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-59')">
            <div class="source">MIT Technology Review</div>
            <div class="title">Why inventing new emotions feels so good</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-59" style="display:none;">
            <h2>Why inventing new emotions feels so good</h2>
            <p><strong>MIT Technology Review | 2025-12-31</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2025/12/31/1129403/new-emotions-online-life-feelings/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">It’s a “complex and subtle emotion that elicits feelings of comfort, serenity, and a gentle sense of floating.” It’s peaceful, but more ephemeral and intangible than contentment. It might be evoked by the sight of a sunset or a moody, low-key album.

If you haven’t ever felt this sensation—or even heard of it—that’s not surprising. A Reddit user named noahjeadie generated it with ChatGPT, along with advice on how to evoke the feeling. With the right essential oils and soundtrack, apparently, you too can feel like “a soft fuzzy draping ghost floating through a lavender suburb.”

Don’t scoff: Researchers say more and more terms for these “neo-­emotions” are showing up online, describing new dimensions and aspects of feeling. Velvetmist was a key example in a journal article about the phenomenon published in July 2025. But most neo-emotions aren’t the inventions of emo artificial intelligences. Humans come up with them, and they’re part of a big change in the way researchers are thinking about feelings, one that emphasizes how people continuously spin out new ones in response to a changing world.

Velvetmist might’ve been a chatbot one-off, but it’s not unique. The sociologist Marci Cottingham—whose 2024 paper got this vein of neo-emotion research started—cites many more new terms in circulation. There’s “Black joy” (Black people celebrating embodied pleasure as a form of political resistance), “trans euphoria” (the joy of having one’s gender identity affirmed and celebrated), “eco-anxiety” (the hovering fear of climate disaster), “hypernormalization” (the surreal pressure to continue performing mundane life and labor under capitalism during a global pandemic or fascist takeover), and the sense of “doom” found in “doomer” (one who is relentlessly pessimistic) or “doomscrolling” (being glued to an endless feed of bad news in an immobilized state combining apathy and dread).

Of course, emotional vocabulary is always evolving. During the Civil War, doctors used the centuries-old term “nostalgia,” combining the Greek words for “returning home”and “pain,” to describe a sometimes fatal set of symptoms suffered by soldiers—a condition we’d probably describe today as post-traumatic stress disorder. Now nostalgia’s meaning has mellowed and faded to a gentle affection for an old cultural product or vanished way of life. And people constantly import emotion words from other cultures when they’re convenient or evocative—like hygge (the Danish word for friendly coziness) or kvell (a Yiddish term for brimming over with happy pride).

Cottingham believes that neo-­emotions are proliferating as people spend more of their lives online. These coinages help us relate to one another and make sense of our experiences, and they get a lot of engagement on social media. So even when a neo-emotion is just a subtle variation on, or combination of, existing feelings, getting super-specific about those feelings helps us reflect and connect with other people. “These are potentially signals that tell us about our place in the world,” she says.

These neo-emotions are part of a paradigm shift in emotion science. For decades, researchers argued that humans all share a set of a half-dozen or so basic emotions. But over the last decade, Lisa Feldman Barrett, a clinical psychologist at Northeastern University, has become one of the most cited scientists in the world for work demonstrating otherwise. By using tools like advanced brain imaging and studying babies and people from relatively isolated cultures, she has concluded there’s no such thing as a basic emotional palette. The way we experience and talk about our feelings is culturally determined. “How do you know what anger and sadness and fear are? Because somebody taught you,” Barrett says.

If there are no true “basic” biological emotions, this puts more emphasis on social and cultural variations in how we interpret our experiences. And these interpretations can change over time. “As a sociologist, we think of all emotions as created,” Cottingham says. Just like any other tool humans make and use, “emotions are a practical resource people are using as they navigate the world.”

Some neo-emotions, like velvetmist, might be mere novelties. Barrett playfully suggests “chiplessness” to describe the combined hunger, frustration, and relief of getting to the bottom of the bag. But others, like eco-anxiety and Black joy, can take on a life of their own and help galvanize social movements.

Both reading about and crafting your own neo-emotions, with or without chatbot assistance, could be surprisingly helpful. Lots of research supports the benefits of emotional granularity. Basically, the more detailed and specific words you can use to describe your emotions, both positive and negative, the better.

Researchers analogize this “emodiversity” to biodiversity or cultural diversity, arguing that a more diverse world is more enriched. It turns out that people who exhibit higher emotional granularity go to the doctor less frequently, spend fewer days hospitalized for illness, and are less likely to drink when stressed, drive recklessly, or smoke cigarettes. And many studies show emodiversity is a skill that, with training, people can develop at any age. Just imagine cruising into this sweet, comforting future. Is the idea giving you a certain dreamy thrill?

Are you sure you’ve never felt velvetmist?

Anya Kamenetz is a freelance education reporter who writes the Substack newsletter The Golden Hour.

The Cybertruck, sycophantic AI, and humanoid robots all made this year’s list of the biggest technology failures.

Unveiled by the buzzy startup Deep, Vanguard will let teams of scientists live and work on the seabed for a week at a time.

We’ll keep following these developments, but this just wasn’t their year. Here’s why.

It’s free and easy to nominate yourself or someone you know—here’s how.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-60')">
            <div class="source">The Next Web</div>
            <div class="title">Five stars, Zero trust</div>
            <div class="meta">2026-01-02</div>
        </div>
        
        <div id="content-60" style="display:none;">
            <h2>Five stars, Zero trust</h2>
            <p><strong>The Next Web | 2026-01-02</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/review-economy">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Five stars used to mean something. People still read reviews before buying software. They just don’t trust them the way they used to. And no, this isn’t about fake reviews or obvious scams. Those are easy to spot. The real problem is more uncomfortable. The review economy didn’t collapse. It slowly drifted away from its original purpose.

User reviews began as authentic buyer guidance, but they’ve morphed into strategic assets for businesses. Scroll through any app store or e-commerce site: everything is “top-rated” and lavished with praise. If every product gleams with a 4.8/5 rating, those stars start to lose their meaning.

Consumers aren’t fooled, in fact, the share of people who trust online reviews as much as personal recommendations plummeted from nearly 80% in 2020 to just 42% in 2025

We read the glowing comments, but we’ve learned to read between the lines.

TNW City Coworking space - Where your best work happens

A workspace designed for growth, collaboration, and endless networking opportunities in the heart of tech.

It’s not hard to see why trust has eroded. Companies have figured out that great reviews drive sales, so they’ve turned the whole system into a numbers game. High ratings aren’t just social proof now, they’re a growth tactic.  In other words, more stars = more money. So of course businesses are chasing stars like their life depends on it. And in a way, it does.

Behind the scenes, many companies actively engineer their review scores. One common tactic is to time the ask just right. For instance, some businesses send out a Net Promoter Score (NPS) survey to gauge your sentiment “How likely are you to recommend us?”

If you rate them a 9 or 10 (a promoter), you’re immediately nudged to post a public review. If you give a lukewarm or low score, the feedback form quietly thanks you and never mentions writing a review at all.

Only the happiest customers get the gentle push to “Share your experience!” This practice is so widespread it even has a name: “review gating.”

It’s essentially filtering which customers get invited to leave a review based on their initial feedback. Platforms officially frown on it (Google outright forbids “selectively soliciting positive reviews”), but behind closed doors it remains a growth hacker’s favorite trick.

Then there’s the outright incentivization. Perhaps you’ve received an email offering a discount, gift card, or free month of service in exchange for writing a review. It’s framed as a thank-you for your time, of course – “Share your honest feedback and get 10% off your next purchase!” – but the intent is clear.

In an economy of fake praise, even regulators have had to step in to remind everyone that trust isn’t a commodity to be bought. Companies know how to play the game from the other side too: suppressing negativity.

Unhappy customer feedback is quietly diverted to support teams or private channels, where it can be resolved (or simply contained) out of public view. The result is a skewed reality, a glossy wall of five-star testimonials that obscure any hint of dissatisfaction. It’s a great sales tool. It’s terrible for the truth.

Why go to such lengths to manicure the ratings? Because the platforms themselves reward it. The algorithms that sort and highlight products aren’t trying to surface the most truthful review; they’re trying to maximize engagement and conversion.

High ratings and large volumes of reviews make people more likely to click “Buy Now.” That means more conversion for sellers and more commission for the marketplace. In other words, the algorithm is biased toward whatever boosts the platform’s monetization metrics.

A bunch of five-star reviews isn’t just ego bait,  it’s algorithm bait.

Think about it: products with a 4.7-star average and hundreds of reviews tend to appear at the top of search results and recommendation lists. They convert better, so the system pushes them more.

More visibility leads to more sales, which reinforces the high ranking. It’s a feedback loop powered by positive feedback (pun intended). If a vendor can game their way into that virtuous cycle, via perfectly timed prompts or purchased praise, the platform’s code will happily amplify them.

Authenticity doesn’t earn you a top slot; performance does. The incentive is clear: keep it positive, and keep it plentiful. In the review economy, volume and sentiment are king.

Worse, some marketplaces have blurred the line between genuine high-rated listings and paid placement. It’s an open secret that many platforms offer sponsored spots or pay-to-play schemes, think “featured” placements, ads masquerading as top picks, or vendor subscriptions that subtly boost visibility.

Money talks, even if it speaks over the voice of authentic customer feedback. (To be fair, a few holdouts still refuse to monetize their review rankings or sell out their star system, but they’re the exception, not the rule).

Consumers aren’t sitting idly by in this charade. We’ve become savvy at sniffing out over-polished BS. The modern buyer knows how the game is played, and many are adapting their behavior to cope with the broken review system.

First, there’s a migration of trust to private networks and off-platform channels. Instead of relying on the star-average on a marketplace, people turn to friends, colleagues, and niche communities for real advice.

Think about the last time you were unsure about a purchase, maybe you shot a quick message to a group chat, or asked in a private Slack channel, “Hey, has anyone used this product? Is it actually any good?” Personal recommendations feel reliable again, precisely because they’re not part of the public review circus.

Second, savvy consumers cross-check everything. Rather than trusting one site’s reviews, they compare across multiple sources, the product might be 4.8 on the official store, but what’s it rated elsewhere?

Is there a discrepancy between the slick website testimonials and the chatter on Reddit? More often than not, shoppers now triangulate information. In fact, three out of four people use two or more sites when reading reviews, rather than putting all their faith in one platform’s word. We instinctively seek a consensus of truth across the noise.

Finally, many have decided the best judge is themselves. “Try before you buy” has made a comeback as a defense against dubious reviews. Free trials, freemium tiers, generous return policies, consumers leverage them all to test products firsthand.

If a software platform promises the world in its curated testimonials, a savvy buyer will take the 14-day free trial and see if it lives up to the hype. In sectors like enterprise software, where choices are costly and critical, buyers might run a pilot program or proof-of-concept rather than trust glossy case studies. Essentially, experience has become the new review.

All this has serious implications for platforms and software marketplaces. These businesses built their empires on user-generated trust, turning customer opinion into a key part of the shopping experience.

If that trust evaporates, the model cracks. We’re already seeing the early signs: users skipping the review tab, or treating every five-star rating with a healthy dose of skepticism.

If the review economy continues on its current path, platforms risk becoming mere transaction processors rather than trust brokers.

For the marketplaces, this is both a crisis and an opportunity. The crisis is obvious: loss of credibility. If people no longer believe what they read on your platform, they’ll seek validation elsewhere, and your influence over purchase decisions diminishes.

But the opportunity lies in reform. Platforms could double down on authenticity as a feature, verifying purchases, cracking down harder on fraudulent and incentivized reviews, and highlighting more qualitative, nuanced feedback instead of simple star counts.

There’s even a chance to innovate with new trust signals (some are experimenting with things like verified buyer badges, AI analysis for suspicious patterns, or weighted ratings that account for reviewer reputation). The platforms that find ways to genuinely restore faith in their review systems will win back weary consumers. Those that don’t will see their communities drift away, bit by bit.

Importantly, not all platforms have given in to the dark side. A handful still refuse pay-for-play tactics, no paid reviews, no under-the-table boosting of rankings for advertisers.

These holdouts demonstrate that integrity in reviews is possible, even if it means slower growth in the short term.

In the end, the broken review economy is forcing a rebalance of how we decide what to trust. Buyers are adapting, finding new ways to cut through the noise. And the platforms that once thrived on being the ultimate source of truth in purchasing may have to rethink their approach if they want to stay relevant.

Trust, once lost, is hard to regain. The five-star system doesn’t shine as bright as it used to; perhaps it’s time for the next evolution in how we share and earn trust online.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-61')">
            <div class="source">The Next Web</div>
            <div class="title">A 2025 recap for Tech & AI</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-61" style="display:none;">
            <h2>A 2025 recap for Tech & AI</h2>
            <p><strong>The Next Web | 2025-12-31</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/a-2025-recap-for-tech-ai">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">2025 was the year technology stopped being tomorrow’s promise and became today’s anchor. What began as a surge in generative AI and platform innovation two years prior crystallized this year into concrete shifts in how people work, governing bodies legislate, and markets invest. Across continents and industries, the arc of technology bent toward practical impact, regulatory reality, and economic weight!

At the heart of the year’s story was artificial intelligence’s jump from novelty to infrastructure. LLMs and multimodal models moved beyond demos into everyday workflows, influencing how documents are written, campaigns are conceived, products designed, and code generated.

Enterprises that once hesitated began deploying AI tools at scale, with early adopters reporting measurable productivity gains by integrating copilots into core processes, a trend visible in surveys showing widespread adoption among software professionals.

This editorial isn’t a chronicle of every press release.

It’s a reflection on how 2025, at the crossroads of technology, governance, and economic strategy, brought about a series of inflection points that will shape the next era of creation, competition, and control.

TNW City Coworking space - Where your best work happens

A workspace designed for growth, collaboration, and endless networking opportunities in the heart of tech.

OpenAI’s release of GPT-5 in August pushed the boundaries of what AI could do, delivering notable gains in coding, math, and multimodal understanding. But unlike the jaw-dropping debut of ChatGPT a couple years prior, this new generation of foundation models arrived to a more measured reception.

Tech leaders and investors had begun asking harder questions: beyond impressive demos, could these models drive real products and revenue?

Google’s answer was Gemini 3, launched in November as its “most intelligent model” and immediately woven into Google’s flagship product, Search. For the first time, an AI model upgrade wasn’t just about boastful leaderboard scores, it was about transforming user experience.

Typing a query into Google now often meant receiving an AI-generated synthesis instead of the familiar list of links, a sea change in how information is delivered. Google even unveiled a Gemini “agent” that could execute multi-step tasks like booking travel or organizing email, hinting at a future where AI acts more like a digital butler than a chatbox.

Anthropic’s Claude 4 model, for instance, gained a strong following among developers by expanding how much it could handle at once, processing entire codebases with tens of thousands of lines, rather than by producing viral one-liners.

AI grew up in 2025: it was still improving at breakneck speed, but it also had to earn its keep in real products and justify the billion-dollar bets fueling its rise.

Driving this AI explosion was a parallel leap in hardware. The hunger for AI computers in 2025 was insatiable, and chipmakers raced to deliver.

NVIDIA, whose GPUs had become the era’s essential infrastructure, rolled out its new Blackwell architecture with chips like the B200 that boasted up to 3× the training speed of its predecessor. Cloud data centers around the world scrambled to deploy these to keep up with demand from model training and inference.

Rival chipmakers weren’t idle either: AMD and a cadre of startups pushed innovative AI accelerators, while even Intel signaled ambitions to catch up, reportedly exploring an acquisition of AI chip designer SambaNova.

Perhaps most tellingly, tech giants themselves started designing silicon tailored for AI workloads, recognizing that owning the chip means owning the future of computing.

Beyond AI chips, consumer hardware saw its own milestones. After years of anticipation, augmented reality glasses and mixed-reality headsets finally had their moment, sort of.

Apple’s Vision Pro headset, unveiled in late 2023, reached select markets in 2024; by 2025 developers were crafting the first wave of immersive apps. However, mass adoption lagged due to the device’s sky-high price and bulky format.

Competitors like Meta’s Quest line offered cheaper VR headsets and modest improvements, but the “metaverse” hype of yesteryear largely fizzled out, users and investors had shifted their excitement to generative AI and tangible productivity tools.

Smartphones and laptops in 2025 continued incremental improvements (faster Apple M3/M4 chips, foldable screens becoming more common), yet it was clear the next paradigm shift in personal tech was still on the horizon.

Even so, one hardware frontier made concrete progress: quantum computing. Industry leaders like IBM and Google demonstrated prototype systems with ever-larger qubit counts and made strides in error correction, inching closer to viable quantum machines.

These advances, while esoteric to the public, underscored a broader theme, from AI accelerators to quantum chips, the machinery under the hood of tech was evolving rapidly to enable the software of tomorrow.

If 2025 proved anything, it’s that technology no longer operates above the law. This was the year regulators moved from intent to enforcement, with Europe leading the charge.

After years of debate, the EU’s Artificial Intelligence Act came into force, becoming the world’s first complex AI law. From February, certain “unacceptable risk” uses, such as social scoring and real-time biometric surveillance, were banned outright.

By August, transparency rules followed, forcing companies to label AI-generated content and comply with new obligations for general-purpose models. The signal was unmistakable: in Europe, the era of unchecked AI was over.

Companies now face audits, penalties, and real consequences if their systems cross legal or ethical lines, a regulatory moment European officials openly compared to GDPR’s impact on data privacy.

The pressure didn’t stop with AI. In 2025, regulators also went after the gatekeepers. The EU’s Digital Markets Act forced long-resistant changes from Big Tech, most notably when Apple opened the iPhone to third-party app stores and sideloading in Europe, dismantling a 15-year walled garden.

At the same time, enforcement of the Digital Services Act intensified. Platforms were scrutinized for how they handle disinformation, with companies like X warned or penalized during periods of geopolitical tension. In response, social networks expanded moderation teams, adjusted algorithms, and exposed more of their inner workings to researchers.

The US issued an AI executive order and signaled tougher enforcement through agencies like the FTC, while states stepped in, including New York’s law requiring mental-health warnings on addictive social features.

In China, new draft rules targeted AI systems designed for human-like interaction, tightening licensing and ideological oversight. By the end of the year, the freewheeling phase of tech disruption had given way to something more restrained. The question was no longer whether regulation would catch up, but how deeply it would reshape innovation itself.

The platform shake-up that began in 2023 gathered real momentum in 2025, as both companies and users adjusted to a post-pandemic, AI-saturated reality.

Nowhere was this clearer than in social media. Elon Musk’s X, which entered the decade with noise and bravado, found itself on the defensive. Meta’s Threads, initially dismissed after an early spike, steadily closed the gap, nearing parity with X in daily mobile users by mid-year.

X’s audience shrank as policy whiplash and leadership churn eroded confidence, and while its remaining users were still deeply engaged, the era of unquestioned Twitter dominance was over. Disenchanted users scattered across a fragmented landscape, from Meta’s polished Threads to decentralized alternatives like Bluesky and Mastodon, breaking the old Facebook–Instagram–Twitter equilibrium.

The recalibration extended well beyond social feeds.

Major platforms retooled around changing habits: Google reshaped Search around generative answers to fend off AI assistants and algorithmic discovery, while Microsoft pushed its Copilot deeper into Windows, Office, and Bing, betting on “AI inside” as a platform reset.

Everyday behavior shifted too. Smarter voice and chat assistants returned to daily use, handling emails, refunds, and scheduling with little friction. At the same time, screen fatigue set in. Digital-detox travel gained traction, and younger users gravitated toward apps that promised less algorithmic pressure and more human curation. Even streaming came full circle.

After years of fragmentation, providers began rebundling services, offering combined video, music, and gaming packages that looked suspiciously like cable TV reborn, a reminder that while technology moves forward, user preferences often move in cycles.

Amid the gains and momentum, 2025 also became a year of reckoning. As AI systems spread, society began grappling with their cultural and ethical cost. Creators who once marveled at generative tools started pushing back, arguing that their work had been absorbed without consent or compensation.

A wave of lawsuits moved through US courts, with authors accusing companies like OpenAI, Meta, and Google of scraping books and articles to train models. By year’s end, the message was unmistakable: if AI is built on human creativity, many believe its rewards can no longer flow in one direction alone.

Public trust in technology was also tested by a rise in malicious uses and misuses. In the financial domain, sophisticated deepfake scams caused real damage. The frequency of such incidents spiked sharply; cybersecurity firms reported a 3000% increase in deepfake-related fraud over two years, and authorities scrambled to educate businesses on new verification practices.

Misinformation continued to be a menace: during elections and conflicts, AI-generated fake images and videos spread on social media, forcing newsrooms to set up rapid-response fact-checking teams.

Encouragingly, 2025 also saw growth in countermeasures, from better deepfake detection algorithms to nascent standards for cryptographic content authentication (the Coalition for Content Provenance, including major publishers and tech platforms, expanded efforts to watermark authentic media).

Still, the information ecosystem remained fraught, as even savvy citizens found it ever harder to tell the truth from fabrication online.

And then there’s the human element: how all this tech is affecting everyday lives and livelihoods. Workplace AI adoption soared this year; tools like Microsoft 365 Copilot and a host of AI assistants became common on office desktops. Studies showed productivity boosts but also raised concerns about workers becoming overly reliant on AI suggestions.

Meanwhile, fears of automation resurfaced in certain sectors, for example, as chatbots took over more customer service and code-generation tools improved, professionals in call centers and junior programming positions wondered about long-term job security.

These anxieties fueled calls for new approaches to education and training, so that the workforce of 2030 will be prepared for more creative, complex tasks that AI can’t easily handle.

Lovable (Stockholm, Sweden) came as one of the most remarkable AI software stories of the year, for me. What began as an open-source project evolved into a commercial platform that lets users build fully functional websites and apps using plain-language prompts, no traditional coding required.

This approach, known in the industry as “vibe coding,” turns ideas into production-ready software simply by describing what you want in natural language.

Lovable’s growth in 2025 was extraordinary by any measure. Eight months after its launch, the company hit over $100 million in annual recurring revenue and raised a $200 million Series A at a roughly $1.8 billion valuation, making it one of Europe’s fastest-growing software startups ever.

By year’s end, Lovable had secured $330 million in Series B funding at about a $6.6 billion valuation, and was rapidly scaling globally.

What makes Lovable meaningful beyond the numbers is what it represents: a shift in how software is built. It demonstrated that AI can democratize development, giving power to non-technical founders, creators, and teams to go from concept to product without traditional engineering barriers.

In an industry long centered on specialized skills and team structures, Lovable’s rise suggested a future where natural language becomes the primary interface to software creation.

On a more hopeful note, 2025 showed signs of a maturing tech culture. Ethical design moved from talking point to practice. Major platforms began experimenting with limits, turning off infinite scroll for teens, adding prompts that nudged users to pause, and treating “time well spent” as a real metric rather than a slogan.

In AI, transparency gained ground. Under pressure from regulators and researchers, companies like OpenAI and Google disclosed more about how their models are trained and where they fall short.

Researchers formed new alliances to share safety techniques, and a second global AI Safety Summit brought dozens of countries together around questions of alignment and control.

None of it amounted to binding rules, but it marked a shift in tone: even the architects of powerful systems openly acknowledged the need for restraint.

Taken together, these moments made 2025 a turning point. For years, technology had surged ahead of the institutions meant to guide it. This year, that gap began to close.

The breakthroughs were real and transformative, but so were the responses to them: laws passed, norms reset, alliances formed. If 2024 was the year the world grasped the power of generative AI, 2025 was the year it began deciding how that power should be used.

The story of technology is no longer just about what can be built, but about how it fits into the lives it shapes, and who gets to decide that fit.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-62')">
            <div class="source">The Next Web</div>
            <div class="title">A New Era for TNW.</div>
            <div class="meta">2025-12-22</div>
        </div>
        
        <div id="content-62" style="display:none;">
            <h2>A New Era for TNW.</h2>
            <p><strong>The Next Web | 2025-12-22</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/a-new-era-for-tnw">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">My name is Alexandru Stan, and this article continues the dialogue I began following the acquisition of TNW.

Following the recent transaction, TNW Spaces remains with the Financial Times, while we continue the mission of the website, the events, and the global community.

We already have a dedicated team at tekpon operating the platform, events, and community initiatives. Our objective is to expand and strengthen the team as TNW accelerates its next chapter.

TNW is already a global media platform with millions of readers. We’re not starting over. We are building forward.

TNW City Coworking space - Where your best work happens

A workspace designed for growth, collaboration, and endless networking opportunities in the heart of tech.

Technology is entering a decisive stage: AI is reshaping workflows, distribution is shifting, capital is becoming more selective, and founders are expected to demonstrate value rather than potential.

The world doesn’t need more noise.
It needs clarity, execution, and access to trustworthy knowledge and people.

TNW will serve that need through editorial independence, real expertise, and community-built intelligence.

Success for TNW looks like this: more accurate understanding, faster access to verified knowledge, and direct pathways from insight to action.

I’ve been an entrepreneur since 2007, building in B2B SaaS, marketplaces, and scalable systems. I believe deeply in servant leadership. Without people, I am zero.

I lead two private networks grounded in practice rather than theory:

These groups ensure TNW remains rooted in lived experience, informed by operators, not commentators.

Our mission is to build the most trusted European tech media platform with global reach, focused on practical innovation, responsible scaling, and transparency.

We will continue to host events across Europe’s major capitals including Paris, London, Berlin, Amsterdam, and Monaco.

These will not be festivals. We are introducing a concept validated through tekpon events: curated gatherings built for meaningful relationships, deep content, and tangible business outcomes.

In 2026, we return to Amsterdam for a special edition centered on AI among other fields. We will explore technologies and strategies shaping the future of work and business:

The editorial focus remains European, while the audience is global.

AI is not a threat to publishing. It is the infrastructure of the next generation of content and knowledge.

At TNW, we will use AI to accelerate research, enable personalized intelligence, reduce noise and bias, and amplify high-quality human expertise. Technology assists. Human judgment remains central.

Because this moment in Europe matters.
Because founders here are ready to scale responsibly.
Because independent media with integrity is rare.
Because innovation deserves a platform built around people, not hype.

TNW will continue its legacy with a renewed emphasis on contribution, execution, and community built through trust.

If you are building, scaling, or researching the next wave of technology, I invite you to engage with us, contribute insights, and participate in shaping the conversation.

The next era begins now. Let’s shape it together.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-63')">
            <div class="source">The Next Web</div>
            <div class="title">Engineering’s AI reality check</div>
            <div class="meta">2025-12-19</div>
        </div>
        
        <div id="content-63" style="display:none;">
            <h2>Engineering’s AI reality check</h2>
            <p><strong>The Next Web | 2025-12-19</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/engineerings-ai-reality-check">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Most engineering leaders cannot answer the one question their CFO is about to ask: “Can you prove this AI spend is changing outcomes, not just activity?”

Every December, roadmaps get locked, budgets get approved, and board decks are polished until everything looks precise and under control. Underneath, many CTOs and VPs are still working with partial visibility. They have a feel for their teams, but not a reliable view of how work moves through the system, how AI is really changing delivery, or where time and money actually go.

For a while, that was survivable. Experience, pattern recognition, and cheap capital covered the gaps. You could hire around bottlenecks, overstaff critical teams, or quietly pivot away from the messiest parts of the system. Then AI showed up and became the perfect distraction. Pilots, PoCs, Copilot seats, and “AI initiatives” created visible activity and bought time.

In 2026, that grace period ends. Boards and CFOs are shifting from “show me you are experimenting” to “show me measurable impact, this year.” Not because they stopped believing in AI, but because the market no longer rewards vague promises. Every AI dollar will need a traceable path to productivity, quality, or customer value.

If you run engineering, you probably recognise this scene. You present a slide with AI highlights. Adoption is up. Developers say they like the tools. You share a few anecdotes about faster coding and smoother reviews. Then the CFO asks a simple question: “Exactly how is this budget changing output and outcomes?”

TNW City Coworking space - Where your best work happens

A workspace designed for growth, collaboration, and endless networking opportunities in the heart of tech.

What is almost always missing is a clear breakdown of:

So the conversation slips back to learning curves, compounding benefits, and talent attraction. All true, but too soft for a tough budget review. That will not be enough.

AI vendors love task-level numbers. A coding task completed 55 percent faster looks impressive on a slide. But once you zoom out to teams and systems, the picture changes.

Large datasets across thousands of developers show a consistent pattern:

The problem is not the tools. It is the lack of a system for where the “extra” capacity goes.

Most organisations still frame AI productivity in terms of speed: more story points, more tickets, higher deployment frequency. That misses the bigger question:

How much of our engineering capacity goes to net new value versus maintenance, incidents, and rework, and is AI improving that mix?

High-level benchmarks are blunt but helpful. On average, about 45 percent of developer time is spent on maintenance, minor enhancements, and bug fixes rather than on genuinely new, customer-facing work. If AI helps you produce more code inside an unchanged system, you risk:

That is how you end up with impressive local metrics and a leadership team that still feels like engineering is slowing down.

If you want to walk into a 2026 budget conversation with objective evidence, you need to be deliberate about how AI-driven time savings are used. Two moves matter.

AI is already good at boilerplate, tests, documentation, and simple refactors. The trap is treating the saved time as unstructured “extra” capacity that disappears into the noise. Instead:

When teams systematically reduce technical debt and improve tests around critical flows, they cut future incidents and rework. Over a year, that frees more capacity for new work than shaving a few minutes off each ticket ever will.

2. Point AI at the ugly, high-friction work that commonly blows up roadmaps

The biggest productivity wins are not in everyday code generation. They are in:

These activities steal weeks or months of capacity and stall strategic initiatives. Using AI to understand legacy code faster, propose refactoring plans, generate migration scaffolding, and highlight recurring failure patterns can dramatically compress timelines for this work.

In parallel, there is real leverage upstream in the problem space. Teams that reach higher levels of AI adoption report better gains when they:

That reduces wasted builds and focuses effort on changes customers actually care about. The most significant gains do not come from replacing human creativity, but from amplifying it and aiming it at better-defined problems.

DORA metrics are not the enemy. Deployment frequency, lead time, MTTR, and change failure rate remain among the best signals we have for delivery performance. The risk is mistaking them for the whole picture.

Leading organisations are already expanding their scorecard to include:

In 2026, the question in the boardroom will shift from “Are we elite on DORA?” to “How much of our capacity is going into things customers notice, and is AI improving that mix or not?” To answer that cleanly, DORA is necessary but not sufficient. You need a way to connect AI usage, workflow, quality, and business outcomes across the system.

This is where engineering intelligence platforms move from a nice-to-have to mandatory. The organisations that win in 2026 will not do it with one more AI tool or one more disconnected dashboard. They will do it by pulling together data they already have but rarely use in one coherent view:

From there, leaders can answer the questions that actually matter:

Instead of defending AI spend with anecdotes, you walk in with:

That is the difference between “we believe in AI” and “here is how AI changed our delivery engine in measurable ways.”

To be ready for the more complex questions coming next year, use this planning cycle to do four things.

Do this, and you will not just have “AI activity” to show in 2026. You will have a credible, data-backed story from AI spend to business outcomes.

The leaders who thrive next year will not be the ones with the flashiest AI demos or the loudest “AI strategy” slide. They will be the ones who:

Engineering intelligence platforms is a key part of that shift. They give you the complex data to show where time and money go, how AI is really changing delivery, and whether your current pace is sustainable. The shift to data-backed engineering leadership is happening either way.

The gap in 2026 will be between teams still guessing and teams that can prove, in detail, how their engineering organisation works.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-64')">
            <div class="source">The Next Web</div>
            <div class="title">Letter from the Editor-in-Chief</div>
            <div class="meta">2025-12-16</div>
        </div>
        
        <div id="content-64" style="display:none;">
            <h2>Letter from the Editor-in-Chief</h2>
            <p><strong>The Next Web | 2025-12-16</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/letter-from-the-editor-in-chief">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Not long ago, like many of you, I read what I feared might be The Next Web’s final article. In late September, TNW’s co-founder announced that the tech conference and news site would be winding down, no more events, no new stories. It felt like the end of an era; the news hit hard!

Yet, just a few weeks ago, a twist arrived: the tech platform Tekpon acquired 100% of TNW’s media and events brand from the Financial Times, ensuring that this nearly two-decade legacy will continue to thrive.

While, myself, trying to read people’s opinions on this topic, I read this comment in one article, from one former TNW editor-in-chief that said: “The Next Web shaped my career, my life… it’s very sad to see it die”.

TNW City Coworking space - Where your best work happens

A workspace designed for growth, collaboration, and endless networking opportunities in the heart of tech.

I asked myself: Why do we always assume that just because one chapter ends, the whole story is over? Yes, taking over TNW is a heavy inheritance, especially with all eyes on us and expectations sky-high.

And I’ll admit, doubts crept in: Am I too small for this? Could someone more experienced do it better? Probably. But here I am, stepping up regardless. Because this isn’t just another blog or brand; TNW is a living ecosystem, a vital community. Its story deserves to continue, and I’m determined to help write the next chapter.

I also know some of you might be wondering: Who is she? What does she know? How many articles has she written? What recommends her?

Before reading all sorts of titles and, let me briefly introduce myself.

I’ve been writing since high school, with thousands of articles under my belt; covering everything from culture, art, and hip hop to design, politics, history, and food. I landed my first content writer job at 18, and alongside writing I pursued another passion: becoming a chef.

(Fun fact: I even made it to the semifinals of MasterChef, a journey that taught me about creativity under pressure and staying cool when the heat is on.)

Now, I channel my storytelling skills into helping businesses better understand technology and use it to their advantage. I help companies tell their stories, the real ones, finding meaning and flow in every word.

Over the years, I’ve specialized in blending creative storytelling with the technical precision of a chef’s knife. (My colleagues at Tekpon might say I can be as sharp as that knife – true to my values and quick to cut through the nonsense.) I am also the “No, we have to do it right” person in the team.

I’ve reviewed countless software products, interviewed founders, and explored how digital innovation can be a force for good in society. Or not. In other words, I’ve always cared about the why behind the tech, the real impact on people’s lives, not just the buzz. That perspective will be behind every story we will publish at TNW.

If there’s a place for those who still think stories written by humans matter, tell me where it is. I’m already on my way.

I’m not here to change TNW’s DNA; I’m here to reinforce it with fresh energy and a clear vision for the future.

To the loyal TNW readers, to the startup founders who looked to us for inspiration, to the healthy tech skeptics who counted on us for a reality check, and to our global audience spread across continents: we hear you.

We all know the world of tech news has changed dramatically. Today, everyone has a megaphone, social media overflows with hot takes, and AI algorithms can crank out content in seconds. It’s easy to feel overwhelmed by this sea of opinions and auto-generated articles. In such a world, the role of a publication like TNW is more critical than ever: to be a filter, not just another firehose of content.

We will focus on curation and clarity, distilling the noise so you don’t have to.

Here’s the good news: despite the deluge of AI-written text out there, readers are actively looking for authentic, human journalism. Every article we will publish will be created by a human writer who is accountable for the facts and who brings context, analysis, and yes, a bit of personality too.

Our mission isn’t to chase every trending headline algorithmically; it’s to help you understand which innovations actually matter, and why.

If a story is everywhere but lacks substance, we won’t regurgitate it; we’ll analyze it or debunk it. If a breakthrough is genuinely promising, we’ll explain why it’s important and how it impacts real people. Being a thoughtful filter in this age of information overload (and AI-generated noise) isn’t just a catchy slogan for us; it’s a responsibility we embrace.

You’ll also notice something different in our approach: an emphasis on storytelling and the human side of tech. Technology doesn’t exist in a vacuum; it’s built and used by people with dreams, dilemmas, and diverse backgrounds.

I believe, and I suspect many of you do too, that the best tech journalism zooms out from the gadgets and code to highlight those human stories. Practically speaking, expect to see more features, interviews, and narrative-driven pieces on TNW.

We’ll talk to founders about the messy, human journey of building a startup, not just the press releases or funding announcements. We’ll spotlight the engineers, designers, and thinkers who are trying to solve big problems (or even small ones that make a big difference). We’ll explore tech’s impact on society: the good, the bad, and the complicated.

This won’t be a place for recycled press releases or surface-level takes. It will be a place for conversation and insight.

Importantly, none of this focus on storytelling means we’ll skimp on rigor. Being engaging doesn’t mean sacrificing accuracy or depth. My team will continue to prioritize thorough research and fact-checking, those good old-school journalism values, even as we experiment with new formats and new voices. In short, we won’t publish anything we wouldn’t want to read ourselves.

Today, looking forward means acknowledging that how we cover tech is as important as what we cover. It means committing to journalism that cuts through the clutter, to storytelling that puts people first, and to a vision of tech’s future that is both hopeful and honest. That’s my vision for TNW as I step into this role, and I hope it resonates with you.

Now, I’d like to turn it over to you, our community. This is your TNW as much as it is ours. I invite you to join the conversation. Tell us what you want to see more of (or less of). Hold us accountable,if we ever fall short, let us know. Share your stories and perspectives with us, because they can inspire our coverage.

In the coming weeks, you’ll start to see this vision take shape on the site. You’ll see familiar faces and new voices. You’ll find articles that make you think, others that make you smile, and hopefully quite a few that make you proud to be a TNW reader.

Whether you’re a long-time follower who’s stuck with us through thick and thin, a startup founder looking for insight, a skeptic keeping us honest, or a curious mind tuning in from anywhere in the world – thank you. We do this for you, and we couldn’t do it without you.

The Next Web is back. We’re here to inform you, inspire you, challenge you, and occasionally even surprise you. I’m honored to have you with us on this journey. Here’s to the road ahead, to storytelling, to journalism (the real kind), and to making sense of the future together.

Thank you for reading, and welcome to TNW’s next chapter. Let’s build it, day by day, story by story, together.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-65')">
            <div class="source">The Next Web</div>
            <div class="title">Is ChatGPT’s New Shopping Research Solving a Problem, or Creating One?</div>
            <div class="meta">2025-12-11</div>
        </div>
        
        <div id="content-65" style="display:none;">
            <h2>Is ChatGPT’s New Shopping Research Solving a Problem, or Creating One?</h2>
            <p><strong>The Next Web | 2025-12-11</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/is-chatgpts-new-shopping-research-solving-a-problem-or-creating-one">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">When OpenAI announced its new shopping search capabilities, I took the news with a grain of salt (perhaps the whole shaker).
For the past decade, we have watched the slow evolution of traditional search engines. What began as tools for pure information discovery gradually morphed into ecosystems dominated by SEO-optimized content and sponsored results. My initial fear with ChatGPT’s update was simple: Are we seeing the beginning of a similar shift? Is the purity of the “reasoning engine” being diluted by the necessity of commerce?
After testing the new shopping integration, the results suggest that we are at a pivotal moment in the user experience of Generative AI, one that requires an open discussion about what we actually want these tools to be.

The defining characteristic of Large Language Models (LLMs) is their ability to handle nuance. When we interact with ChatGPT, we expect a Socratic dialogue. We expect the AI to ask clarifying questions to narrow down our intent.
To test this, I entered a simple prompt: “I want to buy a vacuum.”
I anticipated a conversation, questions about my home’s square footage, my floor type, or my budget. Instead, the conversational nuance was replaced by a display that felt familiar: a grid of product photos, names, prices, and direct links to retailers.

While efficient, this experience felt like a regression. It mirrored the “keyword search” experience of Web 2.0 rather than the “intent-based” promise of GenAI. It replied to my prompt, but it stripped away the intelligence.

Scrolling down, I engaged with the new feature in a call to action: “Research the best vacuums.”
This is where the user experience (UX) friction became most apparent. Rather than synthesizing data or comparing technical specifications in a chat format, the tool presented a polling interface designed to filter results.

The latest rumblings from the EU tech scene, a story from our wise ol&#39; founder Boris, and some questionable AI art. It&#39;s free, every week, in your inbox. Sign up now!

The experience is oddly time-sensitive; pause too long to think or drink water, and the screens will skip forward, dumping you back into a list of product cards.
The interface presents products with a binary choice: “More like this” or “Not interested.” It offers brand names and price tags, but virtually no information to help the user actually make a choice.

For a user seeking genuine research, being presented with a list of brands and prices without deep comparative analysis feels like a missed opportunity.
It raises a question: If I wanted to filter products by price and brand, wouldn’t I use a traditional retailer? The value proposition of Gen AI should be synthesis, not just aggregation.

The Tension Between Reasoning and Revenue
This update highlights the inevitable tension facing major AI companies: the balance between user utility and business sustainability.
As OpenAI scales, the pressure to demonstrate revenue models to investors is natural. However, there is a risk in prioritizing transactional features before the core product, reasoning and logic, is fully matured. By introducing a shopping experience that feels closer to a “click-through” engine than a “knowledge” engine, the platform risks blurring its own identity.
Is ChatGPT a research partner that helps me think? Or is it a shopping assistant trying to speed me to checkout?

To be clear, I believe there is a place for shopping within AI. But the execution matters.
A truly Generative AI shopping experience shouldn’t just list products; it should understand the user. It should read between the lines of a prompt to understand that a user asking for a vacuum might actually be solving a problem about pet hair or allergies.

The current iteration feels like a beta test of a business model rather than an evolution of intelligence. As we move forward, the hope is that OpenAI will refine this tool to prioritize the “Chat” over the transaction. We don’t want it to be just another place to see ads. We need a better way to make decisions.

Viviane Mendes is a growth strategist and innovation leader with more than 20 years of experience driving technology-enabled transformation across global markets. She has led initiatives integrating AI-driven strategies, digital transformation, and scalable business innovation for companies such as PSINet, MP3.com, Match.com, UOL and Best Buy Canada, and founded Vitrinepix, one of the first print-on-demand e-commerce platform, later acquired by Spreadshirt. Committed to lifelong learning, Viviane is now focusing on applying emerging technologies to foster digital literacy, responsible AI adoption, and positive human impact.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-66')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">Trump administration cannot slash NIH research funding, court rules - Reuters</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-66" style="display:none;">
            <h2>Trump administration cannot slash NIH research funding, court rules - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2026-01-05</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMirAFBVV95cUxOcmYyNTV1UHNDN2xXSm5uSVFsVDRNQ1lCeml1TDZHNjVuTUpJZllnMmhsZjQwdVkxOG9PenlnU19GUDdvUjBtby13Rk9QTHJXOVc4dE1qQkc1WnA3cmZiUFNyQUQzS3dHUjJhRHM1Y2ptaVIzaV9mdndVZ2o2c1I3UDBIZjVqMWJfaUhYSmVpRWgzUTh0cDNqcUxmTTFubE1zcmd5Q2hFN3FvYS1H?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-67')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">Amazon must face price gouging lawsuit, US judge rules - Reuters</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-67" style="display:none;">
            <h2>Amazon must face price gouging lawsuit, US judge rules - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2026-01-05</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiyAFBVV95cUxQbkFYcVlpRTVhT01VZ08yazZDdEJXRktfWVB4WFA2WnVzcXk2cloxdk5takxkSkpLR045QUVTemhJaW5ZZWVCRzJjVWZsRGFydFptRHVSZDNkX0h1Q01IS0Jjc01ZcUZsaGV6SDN4Q0xxSndWa1hBT1JuTGFIN3FDXzZMXzZGQjJpWm5aNFRfR1NIZ3BRNFQybWlyN0c0UkIzSl9TOWFlNmp2MjFVUnVOSUxjRkFSdVduekxnYkV1OWtTbXhES1ZtdQ?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-68')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">Colombia to continue work with US on drug trafficking, government says - Reuters</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-68" style="display:none;">
            <h2>Colombia to continue work with US on drug trafficking, government says - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2026-01-05</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMitAFBVV95cUxNN0l1bmdWeHRvcE5JTW1aQXVvcjIxWDBPNEZsTjlZWFBfd1B3b1B2RXNVVXgwczVmWUNLVGZ0ZUlhc0ExYS1UcGFrQTc1TUhQYWhMMG5VTlNoenlqelIwdGNIc0Z3LVZzb2JCMXJnRWU0dndKcGNKYWJiVThwdEZBU0dGYXlPWm9Xa2R4Nld6U1FFaTg3YXNoWnVLT0dwMzlkWEpxUG56MGtkMURBWGhULThjRmM?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-69')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">Intel launches next-gen PC chip at CES in Las Vegas - Reuters</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-69" style="display:none;">
            <h2>Intel launches next-gen PC chip at CES in Las Vegas - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2026-01-05</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMingFBVV95cUxOODM5TDRjUjZSalN4c2h4T2l4MWd4TGhDc2ZrSzNZY2V6RzAwamdaazc2eDVqcEE0OWNEOEhQTEpKZ2JxbzJKVlQtOTNLdXp1d1lwZ2t4UVFENHQwRXhBVWd2WVNOZUFyT01Hak9YVk1wNlFRd3dqWFFmdjJCbHdYdlNXejA3Zlhjc3RSVDhqNFNvVGprakxoM1NNYTdKQQ?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-70')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">Delcy Rodriguez formally sworn in as Venezuela's interim president - Reuters</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-70" style="display:none;">
            <h2>Delcy Rodriguez formally sworn in as Venezuela's interim president - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2026-01-05</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMirwFBVV95cUxQZ3Q4eEdOQTgxYm51Ti1pMmFSckZ0WUJhcjJKaWNXRTYtNlhhN1NPTEJHQk93dXo0OXdoSXE0M0JwUzZ3Rzdib3d0M2pHS1RjeXMzczdMd3JVQVNIaHNVQ0JkOWtFTHhKaHk5U3V5NXZaZ3dHRnJ1UEJhdmlZckloczgzYjFPTmJxTDhpa3pEMEtvbFZTLWkzQmVtaER3UkpSODJtaXFiN29qSGhDRDhz?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-71')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">Assange's lawyer Barry Pollack to fight Maduro's US narcotics charges - Reuters</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-71" style="display:none;">
            <h2>Assange's lawyer Barry Pollack to fight Maduro's US narcotics charges - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2026-01-05</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiuAFBVV95cUxQZWdINFBxTXB2SGF2M2J3bmdET1F6dU1wcjNiZC1DcGZBZ0VNejVYRmU3clFMSGo4R25SSldkb3hpWjhNdGJ6WnNhMjlGQzZjZ3doamhQUjQ0SjJPd3dSUnBRTDBZeGhqSE5mWjFoQ1otREJOVDFhRVA1Rzc0TE9xbWZ3c3dHNUE1bnVWenlwQkI4cFdqRTdPZVJyN292dFBZaTJ4ZThsdnBGTlAzOW1XUHVtdEhEeEVk?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-72')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">NASA Veteran’s Propellantless Propulsion Drive That Physics Says Shouldn’t Work Just Produced Enough Thrust to Overcome Earth’s Gravity - The Debrief</div>
            <div class="meta">2024-04-19</div>
        </div>
        
        <div id="content-72" style="display:none;">
            <h2>NASA Veteran’s Propellantless Propulsion Drive That Physics Says Shouldn’t Work Just Produced Enough Thrust to Overcome Earth’s Gravity - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2024-04-19</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMi6gFBVV95cUxQTTdJNVoxRV9mWGdWanBNOVVUWGtJaUJydjJsTmJpS0kyT0xhanlzSmxGbHdDZnZIeWRSUmJ6VzBPUkdKQVBNWGZ4WVNyeU5sTXZ4ZkRSWHV1UEJfVHhXSDU4NVdSNDBCbUh6OHFKeWRaLUZoRk1Wem53ejEtSnB4NU9aWk1nZEhUbmk0enczVms3VldHQzVWV25mdnZhV01KTUw3YzRDRGU4WE9GeGNodXdfMUs5cUpkUjNXMkRVZVN5Y0lnMWRqRDZqNFVYNkN1cVdub0hFUkFBaC0tTGRZYkJoQU8zQVVfOVE?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-73')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">2026 Space Outlook: New Missions Look to the Moon, Mars, and Beyond as Humanity Seeks Permanent Space Habitation - The Debrief</div>
            <div class="meta">2026-01-01</div>
        </div>
        
        <div id="content-73" style="display:none;">
            <h2>2026 Space Outlook: New Missions Look to the Moon, Mars, and Beyond as Humanity Seeks Permanent Space Habitation - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2026-01-01</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMizgFBVV95cUxOTEFkRVNIUGVyMEJNb1NSTDR0RUpqd005RHc5X1VzQ09YZmdROGNiTUN6VXVLbWRBQkhOYTBFeGVjS1dIell0SGRadXhoYzYtczNkSTNSd0pMU1ZnU0NoUjJURzFVam42TFA0d1hReGtqOURFeUN5dV9DaVNxSWxqbGYya3BwN1RRQVlBY21acXhRRkVpN0pCRHIyd2xlTUlNbE50MDVYcmRKN2hXbkZFendLM1VocEhobHNuMVV4dDJjc1RUWGw0eUl5YWFyQQ?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-74')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">This Vampire-Like Organism "Lost Much of What Defines It" to an Odd Twist in Evolution—So It Became a Parasite Instead - The Debrief</div>
            <div class="meta">2026-01-01</div>
        </div>
        
        <div id="content-74" style="display:none;">
            <h2>This Vampire-Like Organism "Lost Much of What Defines It" to an Odd Twist in Evolution—So It Became a Parasite Instead - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2026-01-01</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMi1wFBVV95cUxQMnNfeXNoVzJwT3R1eHptWXdrcU1aUjRoQldITjRYdHZHWlNreDlnaVhOdElNWk4xUUI5c21tTjY1ZC1JcEZRTEJVX2VkZ2ptdkttZUVRMkRna3c1c3FSbzVDb3JuampiaWk3YTFPeW1QODkwQzE1WE43RG5wZUs0Q3lUTG51OC1KNTU5STBBcWx5VHhqZFVaVG1acXpmNE9EN21wZEF0S1I0RTNlRDBmM0VnLUtpRkxfUk5mVW1OYTFVYkxKZmhzeDJ3cm0yNnI2X0puRm84MA?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-75')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">Fusion Ignition Breakthrough: Energy Researchers Report Tokamak Experiments That Exceed Mysterious ‘Plasma Density Limit’ - The Debrief</div>
            <div class="meta">2026-01-03</div>
        </div>
        
        <div id="content-75" style="display:none;">
            <h2>Fusion Ignition Breakthrough: Energy Researchers Report Tokamak Experiments That Exceed Mysterious ‘Plasma Density Limit’ - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2026-01-03</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMi2gFBVV95cUxNV2lWZ21sbG9wZU56T09CYVFfT19qSU01Qml5bk5CVEt5dDhKU2Jpa010NTZ4b0FuZnN3T2x4Z0lLRVl5UnRUNm5uMWxHWF9ULVV5QXcwT2wtczU4THNtczBOeHpKVGhRdERqV096QmU0bG9UUV9XRVBTcjFOY1dmaV81UUo5RXE4X0xfX3RvX3dNQVpnT0p1OWZyd2RxVUFiUTZjQXI0ZTdPUWRHNXVGcGdETE0wamZ1X1poTU85WmU3M3hRUnNKRk5FZGxLUTJkbjY5cjBiblliUQ?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-76')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">Astronomers Have Spotted a Nearly Invisible 'Rogue Planet' Wandering Silently Through the Cosmos - The Debrief</div>
            <div class="meta">2026-01-03</div>
        </div>
        
        <div id="content-76" style="display:none;">
            <h2>Astronomers Have Spotted a Nearly Invisible 'Rogue Planet' Wandering Silently Through the Cosmos - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2026-01-03</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiugFBVV95cUxQXy0tN3JPMTFQaWJTREo4aTh2clE5Rkx2YnYyRklTbl82YVhpb21uRDJOSlV3SW1xeThZdHRZTm5TUXB4eGlPN2JYM0RmbkczbEJlbGNndnZicC05dEQ5MDVOVldMZnJSNGVfcHlSb2hUWFZBSnhoRklyOHZOMFlnRXFvYTVsOU9aYjJEMzAwS3B4b19SU1hNXzZ6dEtBZVNFcW1rc2xWcHZjZVFjRDZQdC1sX0hsRUNoVXc?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-77')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">Has The Mystery of 'The Bayeux Tapestry' Been Solved? How a Medieval Illustration May Have Misled Scholars For Centuries - The Debrief</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-77" style="display:none;">
            <h2>Has The Mystery of 'The Bayeux Tapestry' Been Solved? How a Medieval Illustration May Have Misled Scholars For Centuries - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2025-12-31</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMi2AFBVV95cUxNVHRqOTd6enI5eG1tQ1ZwancyNTNfRTVIc21pR1kwYWZjek9UZDhRLXNWV0RrbExLZ2Z2Vi1ZdEs5dGJiYVhrS0kwVHYxS2J5QTRQZFlZQThscHNZaGlJb3ZVaUhkX3M4Y1YwQzQxZzQzMXZfc2drSndLekEwYnRMNTNYZGNUQXFfbll1UVJ3MXVHZGI1OF9xM1Fxc3F6Q2I0UlAxYW81cmNTdWdJSUpkSnBQQkJuOFpVT0NzalZDbzRBMU1lcF9henJxNElqcFFnVU16TVptM2g?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-78')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">OpenAI’s International Conundrum - The Information</div>
            <div class="meta">2026-01-04</div>
        </div>
        
        <div id="content-78" style="display:none;">
            <h2>OpenAI’s International Conundrum - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2026-01-04</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMie0FVX3lxTE55Q1hsMUE2VnZtb0lkVFhJR0dRdHBJME9iX1FsLUllMjBuSVdrOTNlX2xGaDl3d3RmQTVwZENKTENvdkJrV1lsZmpnX1ljTGtpRlZWVU1YSTg0ajl5Q1hDYTl4bENZeEFQcHp5bTBVOG5LcERocjlGZTIzUQ?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-79')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">Sutskever’s Fate, OpenAI’s Next Deal, A Hit Robot—and 13 Other Predictions for 2026 - The Information</div>
            <div class="meta">2026-01-02</div>
        </div>
        
        <div id="content-79" style="display:none;">
            <h2>Sutskever’s Fate, OpenAI’s Next Deal, A Hit Robot—and 13 Other Predictions for 2026 - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2026-01-02</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMipgFBVV95cUxNY01ZVTB5S29uNy1qWGNldVZpV2VvQ3FkQnZ2cXk3c2pOY3FUaDI2WE9VS09Ncko2YTV0LUdPeFQ3ZmNCQm5KY2R3TFZUX3lubmVUVElWRGdRMGxDemprUGZBeU4zTG82ZEJVTm1NUFdmTzZOMjJlZzZVMXFWUmw4cU5PTUctckpZTHdQQ1kwem1JRTR3aFVraHJVaENqcjh5aGFtcUd3?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-80')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">OpenAI Ramps Up Audio AI Efforts Ahead of Device - The Information</div>
            <div class="meta">2026-01-01</div>
        </div>
        
        <div id="content-80" style="display:none;">
            <h2>OpenAI Ramps Up Audio AI Efforts Ahead of Device - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2026-01-01</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiigFBVV95cUxOY040X0Z4aktsUndwUlRyQlBNb3hkN2JXdVNZMmxtaldVeTBLUjhpS2lNN0F4aUQ1RU5GWGxKenZKbkozZkJzSXdWU00xSUhWbV9NTEphamdvem54M29GVFhBdnFsTTY3cWZuRFF3bUwwNDNhQlVCWnZFcU5VcFdsRkRpRGtpb3ZDTnc?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-81')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">2026 Predictions: Cash-Strapped Oracle Issues Chip-Backed Debt - The Information</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-81" style="display:none;">
            <h2>2026 Predictions: Cash-Strapped Oracle Issues Chip-Backed Debt - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2025-12-31</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiowFBVV95cUxQWlFTZkpaUXBFbzk5eks1dTZzZl9RN1BHYUNWS2RoMFhSWktwaUdtQktvb3ZpOG4xZHdLcHdvdlBsdHBZMjRPQ1Fzc1pqM1d0U01oMmJpanBiekhXeDJMYTJKcWhpS0h1djlJRjQ3LXZ6di00S3UwdTNrRFJQU2hiMEFCZ3pjY2pSSXd4ZkRUSGh2cGp1UWxnX0lycm5Xck1OTktJ?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-82')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">Nvidia’s Big Ambitions to Solve Manufacturing Shows Slow Returns So Far - The Information</div>
            <div class="meta">2026-01-05</div>
        </div>
        
        <div id="content-82" style="display:none;">
            <h2>Nvidia’s Big Ambitions to Solve Manufacturing Shows Slow Returns So Far - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2026-01-05</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMipwFBVV95cUxOSXJMVHlZMEVfc2pkbzBrWGZJaXBITlpaUGhPcDRaZFVJalpqTDUxREQwclJQU1VQTGNBMmRJMWRBd3o0ZUhpSnVuUU1PeG9PLTdlWHlmNTZlRUhORHMzMWlEUGpBZUpDNC1qZ3llY1g3TFplcmZ5aUY1N2VhbXIzSzhqR0xXc3E1R1B6Wmo5b2FpbUFSdU1LWUdaNjlYcVZyeTN2dkFOOA?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-83')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">OpenAI’s Ads Push Starts Taking Shape - The Information</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-83" style="display:none;">
            <h2>OpenAI’s Ads Push Starts Taking Shape - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2025-12-24</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiggFBVV95cUxNUE1HZHAzd1d4ZDhIU1JLdW44Rjg0QUJMN3U4TGdQRzBpckZsV0k3cEpWcnZ6V3B2VzRncG1DY2FPZFVDQXlPSDZXSnNsSk5kenk3Wl9tTDFzODBBSllVMkF1V0RqaS1aMVhmTmI4azVpQzhaSjFQUmlTZ0tRWGhadDlR?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        </div>

        <div id="reader-modal">
            <div id="close-btn" class="control-btn" onclick="closeModal()">X</div>
            
            <div id="scroll-controls">
                <button class="scroll-btn" onclick="scrollPage(-1)">&#9650;</button> <button class="scroll-btn" onclick="scrollPage(1)">&#9660;</button>  </div>

            <div id="modal-inner"></div>
        </div>

        <script>
            // 1. RANDOMIZE ORDER
            const list = document.getElementById('feed-list');
            const cards = Array.from(document.querySelectorAll('.card'));
            cards.sort(() => Math.random() - 0.5);
            cards.forEach(card => list.appendChild(card));

            // 2. DARK MODE
            const btn = document.getElementById('theme-toggle');
            btn.addEventListener('click', () => document.body.classList.toggle('dark-mode'));

            // 3. MODAL & SCROLL LOGIC
            const modal = document.getElementById('reader-modal');
            const modalInner = document.getElementById('modal-inner');

            function openModal(contentId) {
                const content = document.getElementById(contentId).innerHTML;
                modalInner.innerHTML = content;
                modal.style.display = 'block';
                document.body.style.overflow = 'hidden'; 
            }

            function closeModal() {
                modal.style.display = 'none';
                document.body.style.overflow = 'auto';
            }

            function scrollPage(direction) {
                // Scroll by 80% of the screen height to keep context
                const scrollAmount = window.innerHeight * 0.8;
                modal.scrollBy(0, direction * scrollAmount);
            }
        </script>
    </body>
    </html>
    