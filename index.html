
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>KL-77's Feed</title>
        <style>
            :root {
                --bg: #ffffff;
                --text: #000000;
                --border: #000000;
                --modal-bg: #ffffff;
                --dim: #666666;
            }
            
            body.dark-mode {
                --bg: #000000;
                --text: #ffffff;
                --border: #ffffff;
                --modal-bg: #000000;
                --dim: #aaaaaa;
            }

            body { 
                font-family: Georgia, serif; 
                background-color: var(--bg);
                color: var(--text);
                margin: 0;
                padding: 10px;
                font-size: 22px;
                line-height: 1.5;
            }

            header {
                display: flex;
                justify-content: space-between;
                align-items: center;
                border-bottom: 3px solid var(--text);
                padding-bottom: 15px;
                margin-bottom: 25px;
            }
            
            h1 { margin: 0; font-size: 1.2em; }

            button#theme-toggle {
                background: transparent;
                color: var(--text);
                border: 2px solid var(--text);
                padding: 10px;
                font-size: 18px;
                font-weight: bold;
                border-radius: 4px;
                cursor: pointer;
            }

            .card {
                border: 2px solid var(--text);
                margin-bottom: 25px;
                padding: 15px;
                cursor: pointer;
            }
            
            .source { font-size: 0.7em; font-weight: bold; text-transform: uppercase; color: var(--dim); }
            .title { font-size: 1.1em; font-weight: bold; margin: 8px 0; display:block; }
            .meta { font-size: 0.7em; color: var(--dim); }

            /* MODAL STYLING */
            #reader-modal {
                display: none;
                position: fixed;
                top: 0; left: 0;
                width: 100%; height: 100%;
                background-color: var(--modal-bg);
                z-index: 1000;
                overflow-y: scroll; /* Allow scrolling */
                scroll-behavior: auto; /* Instant scrolling for e-ink */
            }

            #modal-inner {
                padding: 25px;
                max-width: 800px;
                margin: 0 auto;
                padding-top: 80px; 
                padding-bottom: 150px; /* Huge padding so text clears the buttons */
            }

            /* Controls (Close + Scroll) */
            .control-btn {
                position: fixed;
                background: var(--bg);
                color: var(--text);
                border: 3px solid var(--text);
                border-radius: 8px;
                font-weight: bold;
                cursor: pointer;
                z-index: 1001;
                display: flex;
                align-items: center;
                justify-content: center;
            }

            #close-btn {
                top: 15px; right: 15px;
                width: 60px; height: 60px;
                font-size: 30px;
                line-height: 55px;
            }

            /* Scroll Buttons */
            #scroll-controls {
                position: fixed;
                bottom: 20px;
                right: 20px;
                display: flex;
                flex-direction: column;
                gap: 15px;
                z-index: 1002;
            }

            .scroll-btn {
                width: 60px;
                height: 60px;
                font-size: 24px;
                background: var(--bg);
                color: var(--text);
                border: 3px solid var(--text);
                border-radius: 8px;
                cursor: pointer;
            }

            #article-text { white-space: pre-wrap; font-size: 1.1em; }
            
            a.original-link {
                display: inline-block;
                margin-bottom: 30px; /* Space before text starts */
                padding: 10px;
                border: 1px solid var(--text);
                color: var(--text);
                text-decoration: none;
                font-weight: bold;
                font-size: 0.8em;
            }
        </style>
    </head>
    <body>

        <header>
            <h1>KL-77's Feed</h1>
            <button id="theme-toggle">Light/Dark</button>
        </header>

        <div id="feed-list">
    
        <div class="card" onclick="openModal('content-0')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">EU launches formal investigation of xAI over Grok's sexualized deepfakes</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-0" style="display:none;">
            <h2>EU launches formal investigation of xAI over Grok's sexualized deepfakes</h2>
            <p><strong>Ars Technica - All content | 2026-01-26</strong></p>
            <a class="original-link" href="https://arstechnica.com/tech-policy/2026/01/eu-launches-formal-investigation-of-xai-over-groks-sexualized-deepfakes/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The EU has launched a formal investigation into Elon Musk’s xAI following a public outcry over how its Grok chatbot spread sexualized images of women and children.

The billionaire entrepreneur has come under scrutiny from regulators around the world this month after people began using Grok to generate deepfakes of people without consent. The images were posted on the X social network as well as the separate Grok app, both of which are run by xAI.

The probe, announced on Monday under the EU’s Digital Services Act, will assess if xAI tried to mitigate the risks of deploying Grok’s tools on X and the proliferation of content that “may amount to child sexual abuse material.”

“Non-consensual sexual deepfakes of women and children are a violent, unacceptable form of degradation,” the EU’s tech chief, Henna Virkkunen, said.

“With this investigation, we will determine whether X has met its legal obligations under the DSA, or whether it treated rights of European citizens—including those of women and children—as collateral damage of its service.”

If the company is found to be in breach of the rules, the bloc can impose fines worth up to 6 percent of the worldwide annual turnover. An EU official said there will be no interim measures during the investigation.

The European probe comes after UK media regulator Ofcom opened a formal investigation into Grok, while Malaysia and Indonesia have banned the chatbot altogether.

Following the backlash, xAI restricted the use of Grok to paying subscribers and said it has “implemented technological measures” to limit Grok from generating certain sexualized images.

Musk has also said “anyone using Grok to make illegal content will suffer the same consequences as if they upload illegal content.”

An EU official said that “with the harm that is exposed to individuals that are subject to these images, we have not been convinced so far by what mitigating measures the platform has taken to have that under control.”

The company, which acquired Musk’s social media site X last year, has designed its AI products to have fewer content “guardrails” than competitors such as OpenAI and Google. Musk called its Grok model “maximally truth-seeking.”

The commission fined X €120 million in December last year for breaching its regulations for transparency, providing insufficient access to data and the deceptive design of its blue ticks for verified accounts.

The fine was criticized by Musk and the US government, with the Trump administration claiming the EU was unfairly targeting American groups and infringing freedom of speech principles championed by the Maga movement.

X did not immediately reply to a request for comment.

© 2026 The Financial Times Ltd. All rights reserved. Not to be redistributed, copied, or modified in any way.</div>
        </div>
        
        <div class="card" onclick="openModal('content-1')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">Former astronaut on lunar spacesuits: "I don't think they're great right now"</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-1" style="display:none;">
            <h2>Former astronaut on lunar spacesuits: "I don't think they're great right now"</h2>
            <p><strong>Ars Technica - All content | 2026-01-26</strong></p>
            <a class="original-link" href="https://arstechnica.com/space/2026/01/former-astronaut-on-lunar-spacesuits-i-dont-think-theyre-great-right-now/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Crew members traveling to the lunar surface on NASA’s Artemis missions should be gearing up for a grind. They will wear heavier spacesuits than those worn by the Apollo astronauts, and NASA will ask them to do more than the first Moonwalkers did more than 50 years ago.

The Moonwalking experience will amount to an “extreme physical event” for crews selected for the Artemis program’s first lunar landings, a former NASA astronaut told a panel of researchers, physicians, and engineers convened by the National Academies.

Kate Rubins, who retired from the space agency last year, presented the committee with her views on the health risks for astronauts on lunar missions. She outlined the concerns NASA officials often talk about: radiation exposure, muscle and bone atrophy, reduced cardiovascular and immune function, and other adverse medical effects of spaceflight.

Scientists and astronauts have come to understand many of these effects after a quarter-century of continuous human presence on the International Space Station. But the Moon is different in a few important ways. The Moon is outside the protection of the Earth’s magnetosphere, lunar dust is pervasive, and the Moon has partial gravity, about one-sixth as strong as the pull we feel on Earth.

Each of these presents challenges for astronauts living and working on the lunar surface, and their effects are amplified for crew members who venture outside for spacewalks. NASA selected Axiom Space, a Houston-based company, for a $228 million fixed-price contract to develop commercial pressurized spacesuits for the Artemis III mission, slated to be the first human landing mission on the Moon since 1972.

NASA hopes to fly the Artemis III mission by the end of 2028, but the schedule is in question. The readiness of Axiom’s spacesuits and the availability of new human-rated landers from SpaceX and Blue Origin are driving the timeline for Artemis III.

Rubins is a veteran of two long-duration spaceflights on the International Space Station, logging 300 days in space and conducting four spacewalks totaling nearly 27 hours. She is also an accomplished microbiologist and became the first person to sequence DNA in space.

“What I think we have on the Moon that we don’t really have on the space station that I want people to recognize is an extreme physical stress,” Rubins said. “On the space station, most of the time you’re floating around. You’re pretty happy. It’s very relaxed. You can do exercise. Every now and then, you do an EVA (Extravehicular Activity, or spacewalk).”

“When we get to the lunar surface, people are going to be sleep shifting,” Rubins said. “They’re barely going to get any sleep. They’re going to be in these suits for eight or nine hours. They’re going to be doing EVAs every day. The EVAs that I did on my flights, it was like doing a marathon and then doing another marathon when you were done.”

Rubins is now a professor of computational and systems biology at the University of Pittsburgh School of Medicine. She said treks on the Moon will be “even more challenging” than her spacewalks outside the ISS.

The Axiom spacesuit design builds on NASA’s own work developing a prototype suit to replace the agency’s decades-old Extravehicular Mobility Units (EMUs) used for spacewalks at the International Space Station (ISS). The new suits allow for greater mobility, with more flexible joints to help astronauts use their legs, crouch, and bend down—things they don’t have to do when floating outside the ISS.

Astronauts on the Moon also must contend with gravity. Including a life-support backpack, the commercial suit weighs more than 300 pounds in Earth’s gravity, but Axiom considers the exact number proprietary. The Axiom suit is considerably heavier than the 185-pound spacesuit the Apollo astronauts wore on the Moon. NASA’s earlier prototype exploration spacesuit was estimated to weigh more than 400 pounds, according to a 2021 report by NASA’s inspector general.

“We’ve definitely seen trauma from the suits, from the actual EVA suit accommodation,” said Mike Barratt, a NASA astronaut and medical doctor. “That’s everything from skin abrasions to joint pain to—no kidding—orthopedic trauma. You can potentially get a fracture of sorts. EVAs on the lunar surface with a heavily loaded suit and heavy loads that you’re either carrying or tools that you’re reacting against, that’s an issue.”

On paper, the Axiom suits for NASA’s Artemis missions are more capable than the Apollo suits. They can support longer spacewalks and provide greater redundancy, and they’re made of modern materials to enhance flexibility and crew comfort. But the new suits are heavier, and for astronauts used to spacewalks outside the ISS, walks on the Moon will be a slog, Rubins said.

“I think the suits are better than Apollo, but I don’t think they are great right now,” Rubins said. “They still have a lot of flexibility issues. Bending down to pick up rocks is hard. The center of gravity is an issue. People are going to be falling over. I think when we say these suits aren’t bad, it’s because the suits have been so horrible that when we get something slightly less than horrible, we get all excited and we celebrate.”

The heavier lunar suits developed for Artemis missions run counter to advice from former astronaut Harrison “Jack” Schmitt, who spent 22 hours walking on the Moon during NASA’s Apollo 17 mission in 1972.

“I’d have that go about four times the mobility, at least four times the mobility, and half the weight,” Schmitt said in a NASA oral history interview in 2000. “Now, one way you can… reduce the weight is carry less consumables and learn to use consumables that you have in some other vehicle, like a lunar rover. Anytime you’re on the rover, you hook into those consumables and live off of those, and then when you get off, you live off of what’s in your backpack. We, of course, just had the consumables in our backpack.”

NASA won’t have a rover on the first Artemis landing mission. That will come on a later flight. A fully pressurized vehicle for astronauts to drive across the Moon may be ready sometime in the 2030s. Until then, Moonwalkers will have to tough it out.

“I do crossfit. I do triathlons. I do marathons. I get out of a session in the pool in the NBL (Neutral Buoyancy Laboratory) doing the lunar suit underwater, and I just want to go home and take a nap,” Rubins told the panel. “I am absolutely spent. You’re bruised. This is an extreme physical event in a way that the space station is not.”

Barratt met with the same National Academies panel this week and presented a few hours before Rubins. The committee was chartered to examine how human explorers can enable scientific discovery at sites across the lunar surface. Barratt had a more favorable take on the spacesuit situation.

“This is not a commercial for Axiom. I don’t promote anyone, but their suit is getting there,” Barratt said. “We’ve got 700 hours of pressurized experience in it right now. We do a lot of tests in the NBL, and there are techniques and body conditioning that you do to help you get ready for doing things like this. Bending down in the suit is really not too bad at all.”

Rubins and Barratt did not discuss the schedule for when Axiom’s lunar spacesuit will be ready to fly to the Moon, but the conversation illuminated the innumerable struggles of spacewalking, Moonwalking, and the training astronauts undergo to prepare for extravehicular outings.

I spoke directly with Rubins after her discussion with the National Academies. Her last assignment at NASA was as chief of the EVA and robotics branch in the astronaut office, where she assisted in the development of the new lunar spacesuits. I asked about her experiences testing the lunar suit and her thoughts on how astronauts should prepare for Moonwalks.

“The suits that we have are definitely much better than Apollo,” Rubins said in the interview. “They were just big bags of air. The joints aren’t in there, so it was harder to move. What they did have going for them was that they were much, much lighter than our current spacesuits. We have added a lot of the joints back, and that does get some mobility for us. But at the end of the day, the suits are still quite heavy.”

You can divide the weight of the suit by six to get an idea of how it might feel to carry it around on the lunar surface. While it won’t feel like 300 pounds, astronauts will still have to account for their mass and momentum.

Instead of kind of floating in microgravity and moving your mass around with your hands and your arms, now we’re ambulating. We’re walking with our legs. You’re going to have more strain on your knees and your hips. Your hamstrings, your calves, and your glutes are going to come more into play.

I think, overall, it may be a better fit for humans physically because if you ask somebody to do a task, I’m going to be much better at a task if I can use my legs and I’m ambulating. Then I have to pull myself along with my arms… We’re not really built to do that, but we are built to run and to go long distances. Our legs are just such a powerful force.

So I think there are a lot of things lining up that are going to make the physiology easier. Then there are things that are going to be different because we’re we’re now in a partial gravity environment. We’re going to be bending, we’re going to be twisting, we’re going to be doing different things.

It’s an incredibly hard engineering challenge. You have to keep a human alive in absolute vacuum, warm at temperatures that you know in the polar regions could go as far down as 40 Kelvin (minus 388° Fahrenheit). We haven’t sent humans anywhere that cold before. They are also going to be very hot. They’re going to be baking in the sunshine. You’ve got radiation. If you put all that together, that’s a huge amount of suit material just to keep the human physiology and the human body intact.

Then our challenge is ‘how do you make that mobile?’ It’s very difficult to bend down and pick up a rock. You have to manage that center of gravity because you’re wearing that big life support system on your back, a big pack that has a lot of mass in it, so that brings your center of gravity higher than you’re used to on Earth and a little bit farther backward.

When you move around, it’s like wearing a really, really heavy backpack that has mass but no weight, so it’s going to kind of tip you back. You can do some things with putting weights on the front of the suit to try to move that center of gravity forward, but it’s still higher, and it’s not exactly at your center of mass that you’re used to on the Earth. On the Earth, we have a center of our mass related to gravity, and nobody ever thinks about it, and you don’t think about it until it moves somewhere else, and then it makes all of your natural motion seem very difficult.

Those are some of the challenges that we’re facing engineering-wise. I think the new suits, they’ve gone a long way toward addressing these, but it’s still a hard engineering challenge. And I’m not talking about any specific suit. I can’t talk about the details of the provider’s suits. This is the NASA xEMU and all the lunar suits I have tested over the years. That includes the Mark III suit, the Axiom suit. They have similar issues. So this isn’t really anything about a specific vendor. These are just the difficulties of designing a spacesuit for the lunar environment.

NASA trains astronauts for spacewalks in the Neutral Buoyancy Laboratory, an enormous pool in Houston used for simulating weightlessness. They also use a gravity-offloading device to rehearse the basics of spacewalking. The optimal test environment, short of the space environment itself, will be aboard parabolic flights, where suit developers and astronauts can get the best feel for the suit’s momentum, according to Rubins.

Axiom and NASA are well along assessing the new lunar spacesuit’s performance underwater, but they haven’t put it through reduced-gravity flight testing. “Until you get to the actual parabolic flight, that’s when you can really test the ability to manage this momentum,” Rubins said.

Recovering from a fall on the lunar surface comes with its own perils.

“You’re face down on the lunar surface, and you have to do the most massive, powerful push up to launch you and the entire mass of the suit up off the surface, high enough so you can then flip your legs under you and catch the ground,” Rubins said. “You basically have to kind of do a jumping pushup… This is a risky maneuver we test a whole bunch in training. It’s really non-trivial.”

The lunar suits are sleeker than the suits NASA uses on the ISS, but they are still bulky. “If you’re trying to kneel, if you’re thinking about bending forward at your waist, all that material in your waist has nowhere to go, so it just compresses and compresses,” Rubins said. “That’s why I say it’s harder to kneel. It’s harder to bend forward because you’re having to compress the suit in those areas.

“We’ve done these amazing things with joint mobility,” Rubins said. “The mobility around the joints is amazing… but now we’re dealing with this compression issue. And there’s not an obvious engineering fix to that.”

The fix to this problem might come in the form of tools instead of changes to the spacesuit itself. Rubins said astronauts could use a staff, or something like a hiking pole, to brace themselves when they need to kneel or bend down. “That way I’m not trying to compress the suit and deal with my balance at the same time.”

The Moonwalker suit can comfortably accommodate a wider range of astronauts than NASA’s existing EMUs on the space station. The old EMUs can be resized to medium, large, and extra large, but that leaves gaps and makes the experience uncomfortable for a smaller astronaut. This discomfort is especially noticeable while practicing for spacewalks underwater, where the tug of gravity is still present, Rubins said.

“As a female, I never really had an EMU that fit me,” Rubins said. “It was always giant. When I’m translating around or doing something, I’m physically falling and slamming myself, my chest or my back, into one side of the suit or the other underwater, whereas with the lunar suit, I’ve got a suit that fits me right. That’s going to lead to less bruising. Just having a suit that fits you is much better.”

Mission planners should also emphasize physical conditioning for astronauts assigned to lunar landing missions. That includes preflight weight and endurance training, plus guidance on what to eat in space to maximize energy levels before astronauts head outside for a stroll.

“That human has to go up really maximally conditioned,” Rubins said.

Rubins and Barratt agreed that NASA and its spacesuit provider should be ready to rapidly respond to feedback from future Moonwalkers. Engineers modified and upgraded the Apollo spacesuits in a matter of months, iterating the design between each mission.

“Our general design is on a good path,” Rubins said. “We need to make sure that we continue to push for increasing improvements in human performance, and some of that ties back to the budget. Our first suit design is not where we’re going to be done if we want to do a really sustained lunar program. We have to continue to improve, and I think it’s important to recognize that we’re going to learn so many lessons during Artemis III.”

Barratt has a unique perspective on spacesuit design. He has performed spacewalks at the ISS in NASA’s spacesuit and the Russian Orlan spacesuit. Barratt said the US suit is easier to work in than the Orlan, but the Russian suit is “incredibly reliable” and “incredibly serviceable.”

“It had a couple of glitches, and literally, you unzip a curtain and it’s like looking at my old Chevy Blazer,” Barratt said. “Everything is right there. It’s mechanical, it’s accessible with standard tools. We can fix it. We can do that really easily. We’ve tried to incorporate those lessons learned into our next-generation EVA systems.”

Contrast that with the NASA suits on the ISS, where one of Barratt’s spacewalks in 2024 was cut short by a spacesuit water leak. “We recently had to return a suit from the space station,” Barratt said. “We’ve got another one that’s sort of offline for a while we’re troubleshooting it. It’s a really subtle problem that’s extremely difficult to work on in places that are hard to access.”

Harrison Schmitt, speaking with a NASA interviewer in 2000, said his productivity in the Apollo suit “couldn’t have been much more than 10 percent of what you would do normally here on Earth.”

“You take the human brain, the human eyes, and the human hands into space. That’s the only justification you have for having human beings in space,” Schmitt said. “It’s a massive justification, but that’s what you want to use, and all three have distinct benefits in productivity and in gathering new information and infusing data over any automated system. Unfortunately, we have discarded one of those, and that is the hands.”

Schmitt singled out the gloves as the “biggest problem” with the Apollo suits. “The gloves are balloons, and they’re made to fit,” he said. Picking something up with a firm grip requires squeezing against the pressure inside the suit. The gloves can also damage astronauts’ fingernails.

“That squeezing against that pressure causes these forearm muscles to fatigue very rapidly,” Schmitt said. “Just imagine squeezing a tennis ball continuously for eight hours or ten hours, and that’s what you’re talking about.”

Barratt recounted a conversation in which Schmitt, now 90, said he wouldn’t have wanted to do another spacewalk after his three excursions with commander Gene Cernan on Apollo 17.

“Physically, and from a suit-maintenance standpoint, he thought that that was probably the limit, what they did,” Barratt said. “They were embedded with dust. The visors were abraded. Every time they brushed the dust off the visors, they lost visibility.”

Getting the Artemis spacesuit right is vital to the program’s success. You don’t want to travel all the way to the Moon and stop exploring because of sore fingers or an injured knee.

“If you look at what we’re spending on suits versus what we’re spending on the rocket, this is a pretty small amount,” Rubins said. “Obviously, the rocket can kill you very quickly. That needs to be done right. But the continuous improvement in the suit will get us that much more efficiency. Saving 30 minutes or an hour on the Moon, that gives you that much more science.”

“Once you have safely landed on the lunar surface, this is where you got to put your money,” Barratt said.</div>
        </div>
        
        <div class="card" onclick="openModal('content-2')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">A decade of Star Trek-themed fart jokes: The Greatest Generation podcast turns 10</div>
            <div class="meta">2026-01-25</div>
        </div>
        
        <div id="content-2" style="display:none;">
            <h2>A decade of Star Trek-themed fart jokes: The Greatest Generation podcast turns 10</h2>
            <p><strong>Ars Technica - All content | 2026-01-25</strong></p>
            <a class="original-link" href="https://arstechnica.com/culture/2026/01/a-decade-of-star-trek-themed-fart-jokes-the-greatest-generation-podcast-turns-10/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">A decade is a long time for a TV series; no single iteration of Star Trek has made it that far.

But “a Star Trek podcast by two guys just a little bit embarrassed to have a Star Trek podcast” has now passed the milestone. January 25, 2026, marks a full decade since The Greatest Generation, my favorite podcast, debuted. Like a bottle of Château Picard, the show has only improved with age. (I interviewed the guys behind the show back in 2016 when they were just getting started.)

The podcast helped me rediscover, and appreciate more fully, Star Trek: The Next Generation—which is also my favorite TV show. The Greatest Generation continues to delight with its irreverent humor, its celebration of the most minor of characters, and its technical fascination with how a given episode was made.

Over the last decade, hosts Ben Harrison and Adam Pranica have both moved to Los Angeles and become full-time podcasters. They have completed an episode-by-episode recap of all of The Next Generation, Deep Space Nine, and Voyager, and they’re now nearing the end of Enterprise. When finished, they’re threatening/promising to start over again.

The podcast has spawned its own (sometimes NSFW!) lexicon (a “friend of DeSoto” means a listener to and fan of The Greatest Generation), its own recurring and hilarious segments (“Drunk Shimoda,” “Bad Bit Moment,” and “Polo? Polo? Or Pollo?”), and most importantly, its own delightful fandom. It’s the coolest and dorkiest secret club that I will ever be a part of.

In 2016, the podcast was folded into the Maximum Fun organization. Harrison and Pranica formed their own company, Uxbridge-Shimoda LLC, that takes its name from two obscure TNG-era characters.

Like the original Star Trek, the podcast even spawned its own 2017 spinoff—now called The Greatest Trek—entirely devoted to the newer series in the Star Trek universe.

Harrison and Pranica also produce two irregularly released, members-only podcasts called Santa Monica Mountains (about the 1980s and 1990s TV show Baywatch) and Factory Seconds (where they eat at various Cheesecake Factory restaurants). Last year, they also started—in conjunction with YouTube cooking star Adam Ragusea—yet another podcast, called Wholesome, which is only available to Patreon subscribers.

In a world replete with chaos and awfulness, I’m just here for the hang.

(This interview, which was conducted earlier this month, has been lightly edited for clarity and flow.)

Ars: When I first spoke to you guys back in 2016, Adam was living in Seattle. Ben, I believe you were living in New York. You guys were still working in film production. As best as I could tell, this was just a fun little side project. Who knew how long it would run?

Ben: I think that us talking to you has a lot to do with it taking over our lives.

Ars: Sorry, not sorry? I don’t know! [laughs]

Adam: Your Ars article was one of the reasons we catapulted into the sort of audience we got afterward. It’s an audience that has meant we’ve been able to do the show professionally for 10 years.

Ben: Yeah. And when we meet people—all the time—people will say: “Oh, I’ve been listening to you guys since the beginning. Like, I was on at episode five because of that Ars Technica article.”

Ars: Do you feel like you are over it? It’s been a decade now. Is Greatest Gen as we know it going to continue?

Adam: I think the thing that’s changed is that in the beginning, it felt like a fun hobby. But when you professionalize a thing and you hire employees and you are depended on for the thing that you make in a way that you’ve never been before, it’s serious business.

This is the best job I’ve ever had, but it’s also the most seriously I’ve ever taken a job because it means so much to our well-being, but also the folks who appreciate what we do.

Ben: Yeah, one thing that Adam has said many times is we’re going to die in these chairs.

And I think also, as we come toward the end of Enterprise and have sort of run out of the well of Old Trek, as it were, I have been thinking about [what] if I hadn’t had this show? I would still be about ready to start my next TNG rewatch.

Loving Star Trek is a lot about watching it over again, you know? In the same way that I’ll put on an old rerun of The Simpsons or Seinfeld. And I love rewatching those shows. I love rewatching Star Trek.

I think Adam and I have grown as both a comedy duo but also as observers of Star Trek and what it means on an ongoing basis. So I feel like it would be unfair for us not to go back and start painting the bridge from the beginning.

Adam: I think one of the things that we’ve learned from doing the show, especially live in front of people, is that we are told by the people who enjoy this show that it’s about Star Trek, sure, but that’s not the thing that people love the most about the show.

And I think that’s what makes a return to the beginning of it make so much sense in the way Ben’s describing. It’s about the hang and your life as it relates to a Star Trek rerun that you’re watching in that moment.

Ars: I have watched zero minutes of Baywatch in my life. But I have listened to every single episode of the Santa Monica Mountains. I enjoy hearing you guys talk about it.

I think you’ve hit on a format: “Let’s talk about a thing in the way that we like to talk about it and make jokes in the way that we like to make jokes about it.” Which for me really resonates more than the format of a podcast that’s like: “Let’s get comedians to talk about a thing.”

Adam: Or let’s get celebrities in a room to talk about anything and have that be good enough.

Ben: The format that our shows tend to follow is something that I think just kind of was an emergent property of the way Adam and I talked to each other, much more so than it was us attempting to create a show that was our version of anything else.

I don’t really listen to other recap podcasts. It’s kind of a funny thing, but we weren’t really inspired by any recap podcasts in particular. I guess the Flop House a little bit for me, but what they do is so different and such its own thing.

It’s hard to feel like we are connected to the universe of recap podcasts. Like when we go to add our show to a podcast service like iTunes or Apple Podcasts, you have to pick the category that you’re going to be in, and we’ve always picked comedy.

Properly, I guess we probably would be in the television recap podcast section. We just never really thought of ourselves as being that. We were just doing what we wanted to do.

You know, we’re just making a show that makes us laugh. Making each other laugh has always been the primary goal of the show.  So it’s very funny to me that we’re in a category that we’ve never really aspired to be in or compared ourselves to in any way.

Ars: Any favorite moments, perhaps at live shows, that have happened to you over the last 10 years?

Ben: Getting to do live shows at all has been a total shock to me. When we talked to you for that first article, we barely knew what we were doing as entertainers. And I’ve taken improv classes and stuff but never really had any personal aspirations to be someone who gets up on a stage and does something. And I found that I fucking love it!

I really love doing the show in front of an audience! And we just have had so many amazing adventures getting to go all over the country doing that.

And all over the world—we’ve done the show in Canada and London now. That was a total surprise to me.

Like, if you grabbed me on the street 15 years ago and said, “Hey, you’re going to have a show that you get to travel around and do in front of audiences of 300 people someday!” I would have said, “Get the hell out of here! That’s not possible. That’s not something I am working toward in any way.”

Adam: There’s an unexpected quality to the type of—I mean, barf, right? I’m going to say the word “celebrity.” But David Letterman said that when you achieve a certain amount of notoriety, the world becomes a neighborhood to you.

A week ago, I was at a bar with friends, and a stranger came up and told me that they really like our show and they thanked me for making it. And that is something that happens in my life in a way that I never could have anticipated at all.

It’s those little moments that you have with people. Those perfect interactions where it’s just like: “I like what you do and thanks for doing it.”

That makes my life seem meaningful in a way that any previous job did not create the conditions for, you know? You do the work and you think it matters and it’s important, and largely it is in its own way, in its own ecosystem.

But to have a broad interest from folks in what you do and that it matters to them and what they do in their lives? That’s the very best part of this entire thing: knowing that the times that I can make Ben laugh are also the times that I can make 500 people laugh in a room or 25,000 people laugh on a Monday when the episode drops, you know?

That’s really powerful stuff! And it keeps me on my best behavior when I’m out in public in case an FOD is out there watching what I’m doing.

Ben: Oh, yeah. You don’t want to see all the videos of Adam on Worldstar.

Ars: You try really hard to make the show sound great, which it does. It is well-engineered. It is well mixed. You guys put a lot of care into the production of the show.

But also, to my knowledge, you have never missed a show’s publish date. I’m curious about how you balance all of that with whatever else is going on in your lives. Ben, you have two young kids. I know Adam has martinis to drink and golf to play.

Ben: I think the best thing that has happened to us as a duo over the years has been all of the people who have been here to help us along the way.

You know, for a while, we were working with a producer named Rob Schulte, who was really great. And we’re now very fortunate to have a full-time producer named Wynde Priddy, who is so good at anticipating things that are coming up and keeping our minds on what we need to be prepping for the future. And also taking all of the stuff off of our plate that involves the day-in, day-out of editing and producing the shows.

So when it’s all running as it should be, which is most of the time—Adam and I get to focus on prepping, sitting down and recording, and then listening back to basically finished episodes. At that point, we’re just pitching jokes. Like: “Hey, we could add a little audio here to illustrate this point or whatever.” But 90 percent of the time we listen to an episode that’s pretty much ready to go and are just signing off on it for Wynde.

I think that the logistics of making this are complex in some ways. But at its core, it’s just me and Adam having to watch a TV show and then talk to each other about it. And that period of the day, that period of the week where I’m talking to my buddy about a thing we both really love is still the best part of my week.

Adam: We’ve been doing this for 10 years. If you need to take some time off, we know about it usually a month before, and we prepare for it. We know that we record two or three or four episodes a week, every week.

We know that if one of us gets sick, we will have to record more than that in a given week. And I think part of it is if you know that’s what your life is, it’s not stressful or disappointing when that’s your responsibility. That’s just what it takes.

We were both in alignment right away initially that you cannot miss a week doing this because people depend on it for the rhythm of their own weeks. But also, be a fucking professional! Are you telling me you don’t have an afternoon in a given week to do the thing that you’re doing professionally? Get out of here. Of course you do! Find a way.

And this is why, when people over the years have told us, “I really want to do a podcast,” the first advice is: “The same time, the same day, every week. Forever.” And that’s the only advice I give because if you can do that for a year and you ask me what else you need to do, then we can have that conversation.

But if you’re not willing to be a pro like that, good luck. I doubt your ability to get traction with an audience, because I think so much depends on that.

Ben: The podcasts that I listen to throughout the week are something I really look forward to—those shows being there at that time when I do the thing that I do when I listen to them. And so we’ve been very lucky to burrow under the skin of a lot of people—

Adam: I wonder if that’s how we know, Ben? Like, we’re not just the president of Hair Club, we’re also the clients? I think we know what’s meaningful to a podcast listener because we are them ourselves. In a way, I feel like nouveau podcasting right now is often made up of hosts who are doing it because it’s lucrative in their niche, you know?

Ben: Wait, this can be lucrative? Shit, what have we been doing?

Ars:  I’m at a place in my life right now—and maybe you guys are, too—where I find it very hard to emotionally engage with the news. I find myself turning off the news on the radio, on my phone, in ways that I didn’t three years ago, five years ago. I used to be hyper-on: all the news, all the things, all the time. And I just can’t now. I just want to hear some guys talk about martinis.

Ben, you mentioned earlier that this is a show about the hang, and it’s sort of loosely anchored around the thing that you love, Star Trek.

Do you have that same feeling when it’s chatting with Adam Pranica about Baywatch? Does the subject for you, both of you, matter at all? Or does Star Trek have a particular emotional resonance in a way that, you know, lawns don’t?

Ben: I think that the Trek of it all is still really important to the show. And I think that we’re in an era where the news is devastating and exhausting in equal measure, and, you know, Trek has a lot of politics in it.

Adam and I share a lot of politics, but we also, I think, are pretty conscious of this being a place where the horrors of the world aren’t the center of attention.

So we’ve been pretty intentional about trying to make a thing that is a refuge and not a giant bummer.

And I think in its own way, that is an act of defiance. Still being able to have the hang despite all of the horrific shit going on is a sort of powerful statement—no, we’re not going to be ground into bummer pulp.

Adam: Yeah, I agree. I mean, I’m not interested in introducing that into our programs at all. I think a person’s politics is largely their behavior, and I don’t want to compare the things that I’m watching to the things that are happening in the real world generally.

But I think I might take a different side than Ben, about how Star Trek-located the project needs to be for it to be—I don’t know—fun or enriching.

I think those other projects, whether they’re about Baywatch or food or whatever—I’m interested in interesting conversations that are challenging or comedically interesting to me. It largely doesn’t matter what the subject is at its core. I want to be the sort of person that could make anything funny in conversation and through our various other types of shows, that’s become the truth, I hope.

Ben: That’s very fair. I still sort of think it’s the on-ramp for a lot of people. Like, oh, yeah, I like Star Trek. I’ll give that a try. And then it becomes about more than that.

Ultimately, I couldn’t make a show with Adam Pranica and Adam Ragusea if I wasn’t delighted by their perspective on things on an ongoing basis. The thing that’s amazing about this is we’ve made 600-something episodes of The Greatest Generation and 300-something episodes of Greatest Trek and dozens and dozens of episodes of Wholesome, and Adam says stuff every single time we sit down that surprises and delights me. That’s a complete magic trick.

Adam: You can’t do this for 10 years if it’s a bummer-hate show with a bunch of politics in it. That would have been exhausting nine years ago, you know? I don’t listen to any news or politics podcasts. Why would you? Look for the light where you can find it.

Ars: Going back to our original interview, you guys didn’t have very much in the way of established bits and jokes in the way that you do now.

I’m looking here at the Wikia and there’s a long list of bits and phrases: 50-year-old Ensign. Anybody Canyon. Bangers. Ball-kicking machine. Big Rod. McLaughlin Group. Miriam. Mount Armis. Natural Yeager.

Do you feel like any bits are played out? As I read through this, I’m like, “Oh yeah, I totally forgot about ‘Fuck Bokai.’ That’s pretty funny!”

Ben: Oh man, Fuck Bokai. That may have been the high-water mark! I think that one of the cool things about some of these is that they sort of ebb and flow depending on what we’re covering, you know?

There were things that were kind of jokes that stayed within the confines of Deep Space Nine or Voyager that sometimes you get an idea and you can pull one out of the cold storage.

But often the group of active working runners is very influenced by what we are actively covering. I think it’ll be very interesting to see how that long list of old inside jokes interacts with the show when we start going back through the second time.

Because I’m kind of tempted to not reference any of that stuff. I don’t know. I will have to see what happens when we start doing it.

Adam: I feel the same way, Ben. I think we don’t do a bit just because it’s “time to do the bit.” I have felt for a long time that it’s not funny if you’re trying to be funny. If we choose to turn it around and go back from the beginning—these are going to be new experiences for the time that we record them.

And they’re going to feel brand new. I wouldn’t expect a retread of much of anything. Because that doesn’t sound funny to me.

Ben: Well, also 10 years older. Our lives are different. Our world is different.

We will see new things in the show. And that’s one of the things that’s so cool about Star Trek: I feel like I experience it in new ways each time I watch it. So I think it’s kind of inevitable that it will get something that is really different and novel. And maybe some of those old runners will find their way back because they happen to be the funny thing at that moment.

But generally speaking, I’m really excited for crumpling up the paper and throwing it away and writing something fresh, you know?

Adam: Cyrus, you mentioned the Wiki, and I just want to say, one of the best things that’s happened to us over the 10 years of making the show has been the community that formed around it to do things, like making the wiki, making the Discord, that have formed groups where they watch movies together and date each other and marry each other and whatever.

This is a thing that we didn’t intend—imagine doing a thing so important that a large audience would enjoy it—but this large audience has their own lives, and they’re enjoying this thing that we do completely separate from us in their own way.

In a way, that’s great. Neither Ben nor I have the time or the inclination to make a wiki about our show, for example. And yet the folks that put in the effort here to make the experience of listening to the show better for everyone—that’s selfless and good and appreciated.

Ars: Given that there’s such a large body of work that you guys have produced, do you ever get people asking: “You guys have done a thousand episodes. Where do I start?”

I’ll give my answer first. I always tell people who are Star Trek fans but who have maybe not listened to Greatest Gen, “Choose a Star Trek episode that you love or that is memorable to you in some way and listen to the podcast episode about that episode.”

Ben: I like that, too. I also get the question “Oh, you know a lot about Star Trek. I want to get my kid into it. Where should we start?” And I don’t really think that there’s a right answer to that kind of question. Like, going back to the beginning doesn’t necessarily work for me or doesn’t necessarily work as an answer for everybody.

So I like the suggestion to jump in somewhere where you feel like you’ve got some fluency, but I also think it’s totally cool to jump in midstream on the show now or, you know, start at the beginning of one of the series that you really like or jump around. We hear from people that do it all different kinds of ways.

We’ve heard from people who got into the Greatest Generation because of Greatest Trek. We’ve heard from people who started listening to the Greatest Generation and were like: “Well, there’s a lot of references to old stuff in here. So I better go back and listen from the beginning.”

And then they binge the entire thing in three months. And I’m concerned that there may be some kind of exposure toxicity!

Adam: It’s an interesting quality to consider because a lot of the podcasts I listen to are about sports, and the sports that just happened over the weekend. No one listens to that show a month after it comes out.

But 10 years of our conversations are still being listened to in a way that I feel [isn’t the case] if you’re podcasting about the football game.

Ben: As many things as we’ve done in the past of the show, they stay in the present for a lot of people—I think more than half of our downloads in a given week are old episodes.

So that is a place where people hang out, and I think a lot of people that have jobs where they’re working with their hands but they don’t need to be processing language—[they] love podcasts. So we hear from a lot of graphic designers and truckers who like the show.

And that huge back catalog is such a boon to them because by the time you’re on your second listen through, you’re not going to remember exactly how the bit went from episode 324. So the comedy works again for that person.

Ars: I presume you guys have received screeners for Starfleet Academy. How are you feeling about Starfleet Academy as a show? And how are you guys feeling about doing it for your own show?

Ben: I’ve watched two episodes now. And I remain pretty optimistic about Starfleet Academy as a show. I think that there is some melancholy to it being the only one that’s actively being made now of any of the shows. I think they’ve wrapped on Strange New Worlds, even though they haven’t released season four. And none of the others are, like, in production at this point.

Adam: I’m also two episodes in—two very long episodes. I think that one of the qualities to Starfleet Academy that’s been surprising is the hour-long nature of it.

I think many years ago I coined the phrase “Star Trek is a place.” And what that means definitionally is that it’s not a ship or a particular captain or a planet or a federation. It’s a place to tell stories.

That’s just my way of saying that Starfleet Academy at this point, two episodes in, feels like the expression of that idea. Like, Starfleet Academy exists in a place that is Star Trek.

So I don’t hate it because they put out a cheesy poster. I don’t hate it at all! I am enjoying what I’ve seen so far. It’s interesting and new. I think the feeling that I have about it is something that Ben touched on a little bit there, which was like, are we getting near the end of it? Are we going to go back into the desert of 10 years without Star Trek?

I hope not because I think my preference is going to always be that I would rather have Star Trek even if it’s difficult or disliked by folks or whatever, than to go without it at all because it provokes thought. I mean, even when it’s not your Star Trek, I think it’s still fun to talk about.

Ars: One of your greatest wishes—maybe the greatest wish of your lives—is to be blown out of an airlock in a new episode of Star Trek. How close are we to seeing that on screen?

Ars: Have you actually pitched this to somebody who could make it happen?

Ben: There are people inside the walled garden that are aware that a lot of people are invested in this idea. And yeah, it’s happened in comics, it’s happened in fan productions several times now.

We leap at every opportunity we have to get blown out of an airlock. If and when the call comes from inside the Star Trek house, it will be the thrill of a lifetime. That remains the overarching goal of the show, I would say.

We’ve gone so far as to say that if the offer is made, we will fly ourselves to Toronto. If [Paramount is] obligated by some kind of agreement with the union to pay us, we will donate that money to a charity.

This is not about fame or fortune for us. It is about getting blown out of an airlock, which…

Adam: It’s about finally experiencing the sweet, sweet peace of death.</div>
        </div>
        
        <div class="card" onclick="openModal('content-3')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">Poland's energy grid was targeted by never-before-seen wiper malware</div>
            <div class="meta">2026-01-24</div>
        </div>
        
        <div id="content-3" style="display:none;">
            <h2>Poland's energy grid was targeted by never-before-seen wiper malware</h2>
            <p><strong>Ars Technica - All content | 2026-01-24</strong></p>
            <a class="original-link" href="https://arstechnica.com/security/2026/01/wiper-malware-targeted-poland-energy-grid-but-failed-to-knock-out-electricity/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Researchers on Friday said that Poland’s electric grid was targeted by wiper malware, likely unleashed by Russia state hackers in an attempt to disrupt electricity delivery operations.

A cyberattack, Reuters reported, occurred during the last week of December. The news organization said it was aimed at disrupting communications between renewable installations and the power distribution operators but failed for reasons not explained.

On Friday, security firm ESET said the malware responsible was a wiper, a type of malware that permanently erases code and data stored on servers with the goal of destroying operations completely. After studying the tactics, techniques, and procedures (TTPs) used in the attack, company researchers said the wiper was likely the work of a Russian government hacker group tracked under the name Sandworm.

“Based on our analysis of the malware and associated TTPs, we attribute the attack to the Russia-aligned Sandworm APT with medium confidence due to a strong overlap with numerous previous Sandworm wiper activity we analyzed,” said ESET researchers. “We’re not aware of any successful disruption occurring as a result of this attack.”

Sandworm has a long history of destructive attacks waged on behalf of the Kremlin and aimed at adversaries. Most notable was one in Ukraine in December 2015. It left roughly 230,000 people without electricity for about six hours during one of the coldest months of the year. The hackers used general-purpose malware known as BlackEnergy to penetrate power companies’ supervisory control and data acquisition systems and, from there, activate legitimate functionality to stop electricity distribution. The incident was the first known malware-facilitated blackout.

ESET said the attack targeting Poland occurred on the 10th anniversary of that event. The security firm provided few other details about the attack other than the malware used has been dubbed DynoWiper.

Custom wipers have long been a preferred tool for Russian hackers. In 2022, government attackers used wiper malware dubbed AcidRain to knock out 270,000 satellite modems in Ukraine in an attempt to disrupt communications. At the time, it was the seventh wiper Russia had used since invading the neighboring country. ESET said last year that Sandworm had unleashed multiple wipers on universities and critical infrastructure in Ukraine.

The best known case of Russia’s use of wipers came in 2017 with the release of NotPetya. The destructive worm was intended to target only Ukraine, but quickly spread around the world and wreaked havoc as it disrupted computer operations. The event is estimated to have cost governments and businesses $10 billion, making it likely the most expensive computer intrusion in history.

There is no indication how or why DynoWiper failed to take out power. It’s possible Russia planned it to do so in an attempt to send a message without provoking Polish allies. Another possibility is that cyber defenses prevented the wiper from working as intended.</div>
        </div>
        
        <div class="card" onclick="openModal('content-4')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">Did Edison accidentally make graphene in 1879?</div>
            <div class="meta">2026-01-24</div>
        </div>
        
        <div id="content-4" style="display:none;">
            <h2>Did Edison accidentally make graphene in 1879?</h2>
            <p><strong>Ars Technica - All content | 2026-01-24</strong></p>
            <a class="original-link" href="https://arstechnica.com/science/2026/01/did-edison-accidentally-make-graphene-in-1879/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Graphene is the thinnest material yet known, composed of a single layer of carbon atoms arranged in a hexagonal lattice. That structure gives it many unusual properties that hold great promise for real-world applications: batteries, super capacitors, antennas, water filters, transistors, solar cells, and touchscreens, just to name a few. The physicists who first synthesized graphene in the lab won the 2010 Nobel Prize in Physics. But 19th century inventor Thomas Edison may have unknowingly created graphene as a byproduct of his original experiments on incandescent bulbs over a century earlier, according to a new paper published in the journal ACS Nano.

“To reproduce what Thomas Edison did, with the tools and knowledge we have now, is very exciting,” said co-author James Tour, a chemist at Rice University. “Finding that he could have produced graphene inspires curiosity about what other information lies buried in historical experiments. What questions would our scientific forefathers ask if they could join us in the lab today? What questions can we answer when we revisit their work through a modern lens?”

Edison didn’t invent the concept of incandescent lamps; there were several versions predating his efforts. However, they generally had a very short life span and required high electric current, so they weren’t well suited to Edison’s vision of large-scale commercialization. He experimented with different filament materials starting with carbonized cardboard and compressed lampblack. This, too, quickly burnt out, as did filaments made with various grasses and canes, like hemp and palmetto. Eventually Edison discovered that carbonized bamboo made for the best filament, with life spans over 1,200 hours using a 110 volt power source.

Lucas Eddy, Tour’s  grad student at Rice, was trying to figure out ways to mass produce graphene using the smallest, easiest equipment he could manage, with materials that were both affordable and readily available. He considered such options as arc welders and natural phenomena like lightning striking trees—both of which he admitted were “complete dead ends.” Edison’s light bulb, Eddy decided, would be ideal, since unlike other early light bulbs, Edison’s version was able to achieve the critical 2,000° C temperatures required for flash Joule heating—the best method for making so-called turbostratic graphene.

Plus, Eddy had access to Edison’s original 1879 patent describing the invention process. Eddy recreated Edison’s experiment, attaching light bulbs to a 110-volt power source and switching it on for 20 seconds at a time to rapidly heat the carbon-based material to between 2,000° to 3,000° C. (Switch it on for any longer and you get graphite rather than graphene.) Then he examined the results using a modern optical microscope.

His first attempt didn’t work out because the bulbs he bought turned out to use tungsten rather than carbon filaments. “You can’t fool a chemist,” said Eddy. “But I finally found a small art store in New York City selling artisan Edison-style light bulbs.” Those artisan bulbs used bamboo filaments, with diameters a mere 5 micrometers larger than Edison’s original filaments.

This time, Eddy noticed that the carbon filament turned to a “lustrous silver.” Raman spectroscopy revealed that parts of the filament had turned into turbostratic graphene. The team also took before and after images using transmission electron microscopy. Eddy and his co-authors acknowledge that this is not definitive proof that Edison produced graphene. The inventor lacked the means to detect it even if he had been aware that such a material existed. And even if one were to analyze Edison’s original bulb, any graphene would have long since turned into graphite.

The authors concluded by noting the research potential of revisiting other early technologies using the tools of modern materials science, such as vacuum tubes, arc lamps, and early X-ray tubes. These also may have accidentally produced unusual materials or reactions that weren’t analyzed or even noticed at the time. “Innovation can emerge from reinterpreting the past with fresh tools and new questions,” they wrote. “In the case of ‘Edison graphene,’ a 140-year-old invention continues to shed light not just literally but scientifically.”

DOI: ACS Nano, 2026. 10.1021/acsnano.5c12759  (About DOIs).</div>
        </div>
        
        <div class="card" onclick="openModal('content-5')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">A weird, itchy rash is linked to the keto diet—but no one knows why</div>
            <div class="meta">2026-01-24</div>
        </div>
        
        <div id="content-5" style="display:none;">
            <h2>A weird, itchy rash is linked to the keto diet—but no one knows why</h2>
            <p><strong>Ars Technica - All content | 2026-01-24</strong></p>
            <a class="original-link" href="https://arstechnica.com/health/2026/01/a-weird-itchy-rash-is-linked-to-the-keto-diet-but-no-one-knows-why/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">A 20-year-old man in Taiwan went to a dermatology clinic for a strange rash that had developed across his shoulders and chest. The raised, red, and itchy condition had been bothering him for a full month. By this point, he had also developed patches of pigmented skin interlaced with the red rash.

According to a case report in the New England Journal of Medicine, a skin biopsy showed swelling between his skin cells and inflammation around blood vessels, but testing came up negative for other common signs of skin conditions, leaving doctors with few leads. The doctors ultimately came to a diagnosis not by analyzing his skin further but by hearing about his diet.

The man told doctors that two months prior to his clinic appointment—a month before his rash developed—he had switched to a ketogenic diet, which is a high-fat but very low-carbohydrate eating pattern. This diet forces the body to shift from using glucose (sugar derived from carbohydrates) as an energy source to fat instead.

When this happens, the body can go into ketosis. This starts with fat tissue breaking down, leading to the release of free fatty acids. These fatty acids are transported to the liver, where they’re metabolized to acetyl-CoA. Excessive amounts of this molecule gum up metabolic processes and lead to the formation of ketone bodies, primarily acetoacetate and beta-hydroxybutyrate. (A ketone is a specific chemical structure that includes a single bond to two CH3 or R groups with a double bond to an oxygen molecule.) Ketone bodies made in the liver can enter the circulatory system and be used as a source of energy for tissues around the body, particularly the brain.

Ketogenic diets have clinical uses—they’ve proven useful for managing drug-resistant epilepsy and some rare genetic metabolic diseases. Studies have looked at them as possible ways to manage obesity and type 2 diabetes, and there’s interest in their use in cancer metabolism and neurodegenerative diseases, including Parkinson’s disease and Alzheimer’s disease.

Otherwise, the keto diet is popular among people trying to lose weight, particularly those trying to lose visceral fat, like the man in the case study. Anecdotal reports promote the keto diet as being effective at helping people slim down relatively quickly while also improving stamina and mental clarity. But robust clinical data supporting these claims is lacking, and medical experts have raised concerns about long-term cardiovascular health, among other things.

There are also clear downsides to the diet. Ketones are acidic, and if they build up too much in the blood, they can be toxic, causing ketoacidosis. This is a particular concern for people with type 1 diabetes and for people with chronic alcohol abuse. For everyone else, there’s a list of common side effects, including nausea, vomiting, constipation, diarrhea, bad breath, headache, fatigue, and dizziness. Ketogenic diets are also linked to high cholesterol and kidney stones.

But there’s one side effect that’s well established but little known and still puzzling to doctors: the “keto rash” or prurigo pigmentosa. This rash fits the man’s case perfectly—red, raised, itchy bumps on the neck, chest, and back, with areas of hyperpigmentation also developing.

The rash was first identified in Japan in 1971, where it was mostly seen in women. While it has been consistently linked to metabolic disorders and dietary changes, experts still don’t understand what causes it. It’s seen not only in people on a keto diet but also in people with diabetes and those who have had bariatric surgery or are fasting.

In a review this month, researchers in Saudi Arabia noted that a leading hypothesis is that the high levels of ketones in the blood trigger inflammation around blood vessels driven by a type of white blood cell called neutrophils, and this inflammation is what causes the rash, which develops in different stages.

While the condition remains poorly understood, effective treatments have at least been worked out. The most common treatment is to get the person out of ketosis and give them an antibiotic in the tetracycline class. Antibiotics are designed to treat bacterial infections (which this is not), but they can also dampen inflammation signals and thwart the activity of neutrophils.

In the man’s case, doctors gave him a two-week course of doxycycline and told him to ditch his keto diet. A week later, the rash was gone.</div>
        </div>
        
        <div class="card" onclick="openModal('content-6')">
            <div class="source">Futurism</div>
            <div class="title">Meta Just Quietly Admitted a Major Defeat on AI</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-6" style="display:none;">
            <h2>Meta Just Quietly Admitted a Major Defeat on AI</h2>
            <p><strong>Futurism | 2026-01-26</strong></p>
            <a class="original-link" href="https://futurism.com/future-society/meta-bans-teens-chatbots">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Meta says it’s cutting off teenagers’ access to its AI characters — at least until it can build “better” ones.

The Mark Zuckerberg company announced the change on Friday, signaling at least some degree of hesitation at the company over how young users are engaging with its chatbots amid mounting concern over the tech’s effects on mental health and safety.

“Starting in the coming weeks, teens will no longer be able to access AI characters across our apps until the updated experience is ready,” Meta said in an updated blog post. “This will apply to anyone who has given us a teen birthday, as well as people who claim to be adults but who we suspect are teens based on our age prediction technology.”

The update follows an announcement from Meta in October, when it said that parents would be able to use new tools for supervising their children’s interactions with AI characters, including the  ability to cut off their access to the characters entirely. The announcement also described a feature that would provide parents “insights” about the topics their teens were discussing in the AI conversations.

Meta originally promised to release these tools early this year, but that hasn’t come to pass. Now, in its new announcement, the company is saying that it’s building a “new version” of AI characters to “give people an even better experience,” so it’s developing the promised safety tools from scratch and cutting off teen access in the meantime.

Concerns over teenage use of AI chatbots has fueled the broader conversation around AI safety and the phenomenon of AI psychosis, the term some experts are using to describe delusional mental health spirals that are encouraged by an AI’s sycophantic responses. Numerous cases have ended in suicide, many of them being teenagers. The bots remain wildly popular, with one survey finding that one in five high schoolers in the US say they or a friend have had a romantic relationship with an AI.

Meta has come under particular scrutiny, with an internal document allowing underage kids to have “sensual” conversations with its AI — and chatbots based on celebrities including John Cena having wildly inappropriate sexual conversations with users who identified themselves as young teens.

Meta isn’t the only chatbot platform to buckle under scrutiny. The website Character.AI, which offers AI companions similar to Meta’s and was popular with teams, banned minors from the platform last October, after being sued by several families who accused the company’s chatbots of encouraging their children to take their own lives.

More on AI: Meta Caught Saying It’s OK for Underage Children to Have “Romantic or Sensual” Conversations With AI</div>
        </div>
        
        <div class="card" onclick="openModal('content-7')">
            <div class="source">Futurism</div>
            <div class="title">AI Agents Are Mathematically Incapable of Doing Functional Work, Paper Finds</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-7" style="display:none;">
            <h2>AI Agents Are Mathematically Incapable of Doing Functional Work, Paper Finds</h2>
            <p><strong>Futurism | 2026-01-26</strong></p>
            <a class="original-link" href="https://futurism.com/artificial-intelligence/ai-agents-incapable-math">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">A months-old but until now overlooked study recently featured in Wired claims to mathematically prove that large language models “are incapable of carrying out computational and agentic tasks beyond a certain complexity” — that level of complexity being, crucially, pretty low.

The paper, which has not been peer reviewed, was written by Vishal Sikka, a former CTO at the German software giant SAP, and his son Varin Sikka. Sikka senior knows a thing or two about AI: he studied under John McCarthy, the Turing Award-winning computer scientist who literally founded the entire field of artificial intelligence, and in fact helped coin the very term.

“There is no way they can be reliable,” Vishal Sikka told Wired.

When asked by the interviewer, Sikka also agreed that we should forget about AI agents running nuclear power plants and other strident promises thrown around by AI boosters.

Ignore the rhetoric that tech CEOs spew onstage and pay attention to what the researchers that work for them are finding, and you’ll find that even the AI industry agrees that the tech has some fundamental limitations baked into its architecture. In September, for example, OpenAI scientists admitted that AI hallucinations, in which LLMs confidently make up facts, were still a pervasive problem even in increasingly advanced systems, and that model accuracy would “never” reach 100 percent.

That would seemingly put a big dent in the feasibility of so-called AI agents, which are models designed to autonomously carry out tasks without human intervention, and which the industry universally decided last year would be its next big thing. Some companies that embraced AI agents to downsize their workforces quickly realized that the agents they weren’t anywhere near good enough to replace the outgoing humans, perhaps because they hallucinated so much and could barely complete any of the tasks given to them.

AI leaders insist that stronger guardrails external to the AI models can filter out the hallucinations. They may always be prone to hallucinating, but if these slip-ups are rare enough, then eventually companies will trust them to start doing tasks that they once entrusted to flesh and blood grunts. In the same paper that OpenAI researchers conceded that the models would never reach perfect accuracy, they also dismissed the idea that hallucinations are “inevitable,” because LLMs “can abstain when uncertain.” (Despite that, you’d be hard-pressed to find a single popular chatbot that actually does that, almost certainly because it would make the chatbots seem less impressive and less engaging to use.)

Even though he’s adamant LLMs have a hard ceiling, Sikka agrees with figures in the AI industry who insist that hallucinations can be reined in.

“Our paper is saying that a pure LLM has this inherent limitation — but at the same time it is true that you can build components around LLMs that overcome those limitations,” he told Wired.

More on AI: OnlyFans Rival Seemingly Succumbs to AI Psychosis, Which We Dare You to Try Explain to Your Parents</div>
        </div>
        
        <div class="card" onclick="openModal('content-8')">
            <div class="source">Futurism</div>
            <div class="title">Scientists Say Go Ahead, Keep Gooning</div>
            <div class="meta">2026-01-25</div>
        </div>
        
        <div id="content-8" style="display:none;">
            <h2>Scientists Say Go Ahead, Keep Gooning</h2>
            <p><strong>Futurism | 2026-01-25</strong></p>
            <a class="original-link" href="https://futurism.com/health-medicine/scientists-gooning">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Adult content has never been as accessible as it is now, thanks to the internet. Hell, online smut played a major role in the rise of the web itself in the 1990s.

With that glut of porn, some have voiced concerns that some people are consuming too much of the stuff or even becoming addicted, which they claim could have consequences like regulating emotions or impaired sexual functioning.

But as PsyPost reports, these concerns may be overblown. Researchers at the University of Pécs in Hungary have found that it doesn’t matter how frequently one watches porn; the reasons why somebody indulges in the stuff are far more predictive of their sexual health.

As detailed in a new paper published in the International Journal of Sexual Health, the researchers found that positive motivations, such as “enhancing sexual pleasure, exploring fantasies, or deepening intimacy,” were “associated with frequent but non-problematic pornography use and with adaptive sexual regulation.”

However, those with “negative motivations,” such as “stress reduction, emotional escape, or avoidance of discomfort,” were strongly linked to “sexual system hyperactivation, emotion regulation difficulties, and impaired relational functioning.”

The study involved  890 adult participants in Hungary, including 600 individuals assigned female at birth and 290 assigned male at birth. The participants submitted answers anonymously through an online survey.

“A major gap in the literature is that pornography use is often evaluated mainly by how frequently people use it, even though frequency alone tells us very little about whether use is actually harmful,” University of Pécs psychology professor Norbert Meskó told PsyPost.

“We were interested in whether these different motivations are linked to different patterns of sexual and emotional functioning,” he added.

Most strikingly, the researchers found that participants who reported frequent pornography use were less likely to experience problematic outcomes. However, those who primarily used it for coping and managing stress were more likely to experience symptoms of problematic use, indicating that frequency isn’t the main indicator of whether it’s actually harmful.

“One somewhat surprising finding was that frequent use, when driven by positive motivations, was linked to less sexual deactivation — meaning less emotional withdrawal from sexuality,” Meskó told PsyPost. “In contrast, only problematic use — not frequent use — was associated with these kinds of disengaged or avoidant sexual patterns.”

“Importantly, problematic use showed much stronger links to difficulties in sexual and emotional functioning than simple frequency did,” he added. “This suggests that from a practical standpoint, it is more useful to look at whether someone feels out of control or distressed by their use than at how often they watch pornography.”

Of course, as the researchers note in their paper, there are some limitations to their research. For one, the self-reported nature of their data may not be reliable, as it relies on memory. It also may not be generalizable to a broader population as a result.

Multiple motivations for pornography use may also overlap — for instance, seeking pleasure while also distracting from stress — meaning that some cases may not neatly fit into either positive or negative motivations. One category may also quickly shift to another, further complicating the picture.

“We would caution against thinking of pornography as either simply ‘good’ or ‘bad,&#39;” Meskó told PsyPost. “For some people, it may be part of healthy sexual expression, while for others it may function as a way to avoid emotional problems or relationship difficulties.”

More on pornography: Grok Is Being Used to Depict Horrific Violence Against Real Women</div>
        </div>
        
        <div class="card" onclick="openModal('content-9')">
            <div class="source">Futurism</div>
            <div class="title">Job Seekers Sue Company Scanning Their Résumés Using AI</div>
            <div class="meta">2026-01-25</div>
        </div>
        
        <div id="content-9" style="display:none;">
            <h2>Job Seekers Sue Company Scanning Their Résumés Using AI</h2>
            <p><strong>Futurism | 2026-01-25</strong></p>
            <a class="original-link" href="https://futurism.com/artificial-intelligence/ai-labor-scanning-eightfold">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Thanks to scores of competing AI systems clogging up online application portals, applying for a new job in 2026 can feel more like applying for a bank loan than seeking a job.

At least, that’s what a group of disgruntled job seekers is claiming in a lawsuit against an AI screening company called Eightfold AI. According to the New York Times, the plaintiffs allege that Eightfold’s employment screening software should be subjected to the Fair Credit Reporting Act — the regulations protecting information collected by consumer credit bureaus.

The reason, they say, can be found deep within Eightfold’s AI algorithm, which actively trolls LinkedIn to create a data set of “1 million job titles, 1 millions skills, and the profiles of more than 1 billion people working in every job, profession, industry, and geography.” That data set, in turn, is used in marketing material to help sell its services to potential clients.

Using an AI model trained on that data, plaintiffs say, Eightfold scores job applications on a scale of one to five, based on their skills, experience, and the hiring manager’s goals. In sum, their argument is that it’s not at all unlike the opaque rules used to govern consumer credit scores.

In the case of Eightfold, however, applicants have no way of knowing what their final score even is, let alone the steps the system took to come up with it. That creates a “black box”: a situation where the people subjected to an algorithmic decision can only see the system’s outcome, not the process that led to it. And if Eightfold’s AI starts making things up on the fly — an issue AI models are infamous for — the job seeker has no way of knowing.

There’s also the issue of data retention. With no way to take a peek under the hood, there’s no telling how much data from job applicants’ résumés Eightfold collects, or what the AI company and its clients are doing with it.

“I think I deserve to know what’s being collected about me and shared with employers,” Erin Kistler, one of the plaintiffs told the NYT. “And they’re not giving me any feedback, so I can’t address the issues.”

Kistler, who has decades of experience working in computer science, told the publication she’s kept a close score of every application she’s sent over the last year. Out of “thousands of jobs” she’s applied for, only 0.3 percent moved on to a follow-up or interview, she said.

It all underscores the sad state of the job market, which has become the stuff of dystopian nightmares thanks to AI hiring tools. Whether the lawsuit can gain enough momentum to challenge the massive legal grey area of AI hiring remains to be seen. If it does, it could bring relief to throngs of despondent job seekers whose careers quite literally hang in the balance.

Eightfold AI didn’t respond to the NYT‘s request for comment.

More on AI: Majority of CEOs Alarmed as AI Delivers No Financial Returns</div>
        </div>
        
        <div class="card" onclick="openModal('content-10')">
            <div class="source">Futurism</div>
            <div class="title">Scientists Intrigued by Unfamiliar Life Form</div>
            <div class="meta">2026-01-25</div>
        </div>
        
        <div id="content-10" style="display:none;">
            <h2>Scientists Intrigued by Unfamiliar Life Form</h2>
            <p><strong>Futurism | 2026-01-25</strong></p>
            <a class="original-link" href="https://futurism.com/science-energy/scientists-intrigued-unfamiliar-life-form">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">It’s a plant! It’s a fungus! It’s… an entirely new type of lifeform hitherto unknown to science?

That appears to be the case for a puzzling, spire-shaped organism that lived over 400 million years ago, according to a new study published in the journal Science Advances. After analyzing its internal structures, the authors argue that the mystifying ancient beings known as prototaxites don’t belong to any of the existing biological kingdoms.

“It feels like it doesn’t fit comfortably anywhere,” Matthew Nelsen, a senior research scientist at the Field Museum of Natural History who wasn’t involved in the work, told Scientific American. “People have tried to shoehorn it into these different groups, but there are always things that don’t make sense.”

The name Prototaxites means “early yew” or “first yew,” a misnomer that captures the debate that has surrounded its nature for over a century. With its resemblance to a tree trunk, scientists initially suspected it was some kind of extinct tree when its fossils were first unearthed in 1855.

This assumption would probably offend the prototaxites were they still alive to hear it. In reality, the peculiar pillars likely emerged before the first trees appeared on Earth some 400 million years ago, and at an estimated height of around 26 feet, would’ve absolutely towered over other land organisms at the time.

What was the nature of these colossi? Scientific speculation abounded once it became clear that it wasn’t a plant. In the decades that followed its discovery, the consensus flipped to it being a kind of algae. In more recent decades, the suspicion became that it was some kind of giant fungus, because it appeared that they contained carbon isotopes typically found in such organisms.

Boldly, the authors of the new paper — which we’ve been following since back before it was peer-reviewed — say that everyone’s got it all wrong. The tubelike structures in the fossils are wild and varied, unlike the structures in modern fungi, which are more ordered, SciAm noted. There were also no detectable traces of chitin, a chemical that makes up the cell walls of all known fungi.

“It doesn’t seem to have any of the characteristic features of the living fungal groups,” co-lead author Laura Cooper, a researcher at the University of Edinburg, told SciAm, adding that many facets of its biology elude our understanding, not just its taxonomy. “How it actually works energetically is still a complete mystery.”

Some argue that Prototaxites represent a completely extinct lineage of fungus, which, if true, means it would have had to independently evolve into a new form of complex life, according to Kevin Boyce, a paleobotanist at Stanford University who coauthored a 2022 paper with Nelsen on the organisms — something that would be astounding in its own right. “No matter what,” Boyce told SciAm, “it’s something weird doing its own thing.”

Cooper, however, remains adamant that the Prototaxites are too “fundamentally different” to shove it into the category of fungi. Science doesn’t like outliers, so if it is something entirely new, chances are there’s something else like it out there that we haven’t stumbled on yet. And so, according to Vivi Vajda, a paleobiologist at the Swedish Museum of Natural History, the “next step would be to find other fossil life forms with similar chemical fingerprints to trace this enigmatic life form through the tree of life,” she told Science.

More on biology: Tiny Deer Takes on 1.7-Ton Rhinoceros</div>
        </div>
        
        <div class="card" onclick="openModal('content-11')">
            <div class="source">Futurism</div>
            <div class="title">When You Learn How Low the 2025 Murder Rate Was, You’ll Realize How Profoundly the Media Has Failed the American People</div>
            <div class="meta">2026-01-25</div>
        </div>
        
        <div id="content-11" style="display:none;">
            <h2>When You Learn How Low the 2025 Murder Rate Was, You’ll Realize How Profoundly the Media Has Failed the American People</h2>
            <p><strong>Futurism | 2026-01-25</strong></p>
            <a class="original-link" href="https://futurism.com/future-society/murder-rate-media-2025">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The headlines of 2025 painted a portrait of America in chaos, driven by the financial logic of America’s media ecosystem. It’s number one product isn’t news, but fear.

“NYC youth crime doubled since controversial state Raise the Age Law kicked in,” exclaims one hysterical New York Post headline from September. “Business owners express frustration over crime surge in Federal Hill,” reads a banner from FOX45 News, a local outlet in Baltimore. “Office shooter’s rampage shows terrifying rise of motive-free violence, experts warn,” goes a Fox News heading from August.

The scary headlines were all underscored by inflammatory rhetoric from the Trump administration, which continued to insist that America’s cities are crime-ridden hell holes well into the new year.Selective media coverage of crime certainly isn’t a new phenomenon, though it’s worth revisiting — especially because new data suggests 2025 was actually one of the least violent years for the US in over a century.

According to fresh Council on Criminal Justice crime statistics, Axios reports, murder rates fell 21 percent last year across the 35 largest cities in the US. It’s the single largest one-year-drop ever, the publication reports, and possibly the lowest homicide rates we’ve seen as a nation since the year 1900 — when the last generation of frontier outlaws were still robbing train cars.

Homicide wasn’t the only crime that fell in 2025. Out of 13 crimes tracked by the Council on Criminal Justice, 11 of them were lower last year than in 2024. Aggravated assaults, for example, fell by 9 percent across the 35 cities, while gun assaults and robberies dropped off by 22 and 23 percent, respectively. (The only category that increased was drug crimes, up 7 percent — and which are nonviolent.)

To sum up it all up: the sensationalized crime coverage dominating the evening news stands in stark, frustrating contrast to the actual data. In 2026, American media is dominated by just six billion-dollar media conglomerates, an arrangement which has held for well over a decade.

Under this system, news becomes commodified — clicks and views drive revenue, the core function of any business. Media companies have a financial incentive to churn out hysterical headlines and “Nightcrawler”-esque violence porn over rational breakdowns of actual statistics, nevermind the social and financial conditions that give rise to crime.

With so many Americans reliant on the commercialized news cycle for information about the world, it’s no wonder our politics are still steeped in debates over “law and order,” driven by a crisis that doesn’t seem to exist.

More on media criticism: Media Execs Prepare for AI to Bring End of Journalism Industry</div>
        </div>
        
        <div class="card" onclick="openModal('content-12')">
            <div class="source">TechCrunch</div>
            <div class="title">SpaceX eyes mid-March for first test of upgraded Starship rocket</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-12" style="display:none;">
            <h2>SpaceX eyes mid-March for first test of upgraded Starship rocket</h2>
            <p><strong>TechCrunch | 2026-01-26</strong></p>
            <a class="original-link" href="https://techcrunch.com/2026/01/26/spacex-eyes-mid-march-for-first-test-of-upgraded-starship-rocket/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The delayed first test of SpaceX’s upgraded Starship rocket is now slated for mid-March, according to a post from CEO Elon Musk on his social media site X.

This third version of Starship, or V3, is larger and more powerful. Crucially, the company plans to use Starship V3 to launch its next-generation Starlink satellites, which will be capable of faster data speeds but weigh more and are larger. It’s also the first version of the rocket that is meant to dock with other Starships in Earth orbit, a capability the company needs in order to reach the moon or Mars.

This all comes as SpaceX is racing toward an IPO later this year, and under pressure from the Trump administration to return U.S. astronauts to the surface of the moon before the end of his second term. Starship, the most powerful rocket ever developed, is currently a key part of NASA’s mission to fulfill that goal.

SpaceX was making progress toward a launch of Starship V3 in late 2025. But in November, the booster stage suffered an explosion during testing that blew out an entire side of the steel rocket. The company said it was performing “gas system pressure testing” when the explosion happened, but has yet to offer a more detailed breakdown of what went wrong.

The company has been hoping to move on from the second version of Starship, which was a mixed bag. It was able to successfully reach orbit with Starship V2, deploy dummy versions of the next-generation Starlink satellites, and catch multiple booster stages after they returned to the launchpad.

But Starship V2 also suffered a number of explosions and setbacks of its own. Some of those came as a result of SpaceX’s developmental approach, which involves pushing the test vehicles to — or past — their limit and then iterating based on what the company learns. Others were more unexpected, like when one of the Starship vehicles that sits atop the booster stage erupted in a massive fireball during ground testing last June.

SpaceX has come to dominate the global launch market over the last decade, and it is relying on Starship to maintain that dominance. But competition is creeping in at the edges. Jeff Bezos’ space company Blue Origin launched its first mega-rocket, known as New Glenn, for the first time in January 2025 and again in November. The company launched its inaugural commercial payload for NASA on that second flight and also completed the first landing of its booster stage.

Blue Origin is planning a third launch of New Glenn in late February and hopes to send its own lunar lander to the moon sometime after that. While New Glenn is smaller than Starship, Blue Origin revealed late last year that it is developing a larger version of the vehicle that more directly competes with SpaceX’s super-heavy rocket.

Sean O’Kane is a reporter who has spent a decade covering the rapidly-evolving business and technology of the transportation industry, including Tesla and the many startups chasing Elon Musk. Most recently, he was a reporter at Bloomberg News where he helped break stories about some of the most notorious EV SPAC flops. He previously worked at The Verge, where he also covered consumer technology, hosted many short- and long-form videos, performed product and editorial photography, and once nearly passed out in a Red Bull Air Race plane.

You can contact or verify outreach from Sean by emailing sean.okane@techcrunch.com or via encrypted message at okane.01 on Signal.

Tickets are live at the lowest rates of the year. Save up to $680 on your pass — and if you’re among the first 500 registrants, score a +1 pass at 50% off.Meet investors. Discover your next portfolio company. Hear from 250+ tech leaders, dive into 200+ sessions, and explore 300+ startups building what’s next. Don’t miss these one-time savings.

TikTok users freak out over app’s ‘immigration status’ collection — here’s what it means

Researchers say Russian government hackers were behind attempted Poland power outage

Microsoft gave FBI a set of BitLocker encryption keys to unlock suspects’ laptops: Reports

Capital One acquires Brex for a steep discount to its peak valuation, but early believers are laughing all the way to the bank

Anthropic’s CEO stuns Davos with Nvidia criticism

Humans&, a ‘human-centric’ AI startup founded by Anthropic, xAI, Google alums, raised $480M seed round

SpaceX didn’t properly inspect crane before collapse at Starbase, OSHA says</div>
        </div>
        
        <div class="card" onclick="openModal('content-13')">
            <div class="source">TechCrunch</div>
            <div class="title">Only 5 days left: Over half of the first 500 TechCrunch Disrupt 2026 +1 passes at 50% off are already gone</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-13" style="display:none;">
            <h2>Only 5 days left: Over half of the first 500 TechCrunch Disrupt 2026 +1 passes at 50% off are already gone</h2>
            <p><strong>TechCrunch | 2026-01-26</strong></p>
            <a class="original-link" href="https://techcrunch.com/2026/01/26/only-5-days-left-over-half-of-the-first-500-techcrunch-disrupt-2026-1-passes-at-50-off-are-already-gone/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The clock is officially ticking. In just 5 days, the lowest ticket prices for TechCrunch Disrupt 2026 — plus the exclusive 50% off +1 pass for the first 500 registrations — will be gone. And with more than half of those first 500 already claimed, this window is closing fast. If Disrupt has been on your must-attend list, this is your moment to lock in the best deal and bring a +1 for half the price.

Register now to save up to $680 on your pass and get a second ticket at 50% off. This offer ends January 30, or the moment the first 500 tickets are claimed. Whichever comes first.

From October 13–15, San Francisco’s Moscone West becomes the global epicenter of tech. TechCrunch Disrupt is a curated, three-day experience designed to maximize signal over noise — uniting 10,000 founders, investors, operators, and tech leaders for 200+ expert-led sessions featuring 250+ influential voices.

Explore what’s next as 300+ startups debut their breakthroughs, experience the high-stakes energy of Startup Battlefield 200, and tap into curated, high-impact networking with the leaders shaping the future of tech.

Past speakers have included some of the industry’s greatest minds:

Disrupt isn’t about wandering between sessions. It’s about intentional connections and curated experiences designed for how you actually work in tech. Founders connect directly with investors. VCs cut through the noise to discover startups aligned with their theses. Operators exchange real-world insights on building, scaling, and shipping what’s next. If you’re hands-on in tech, Disrupt was built with you in mind.

Explore ticket options to find the right fit for you, your partner, and your team.

Founders and investors can unlock specialized passes designed to support your goals:

Founder Pass: Get the tools, insights, and connections you need to accelerate your startup’s growth. Learn more here.

Investor Pass: Access curated opportunities to connect with standout startups and expand your portfolio. Learn more here.

More than half of the first 500 +1 passes are already gone, and this offer ends in just 5 days. Register now to save up to $680 on your Disrupt ticket and bring a +1 at 50% off while discounted passes remain.

Tickets are live at the lowest rates of the year. Save up to $680 on your pass — and if you’re among the first 500 registrants, score a +1 pass at 50% off.Meet investors. Discover your next portfolio company. Hear from 250+ tech leaders, dive into 200+ sessions, and explore 300+ startups building what’s next. Don’t miss these one-time savings.

TikTok users freak out over app’s ‘immigration status’ collection — here’s what it means

Researchers say Russian government hackers were behind attempted Poland power outage

Microsoft gave FBI a set of BitLocker encryption keys to unlock suspects’ laptops: Reports

Capital One acquires Brex for a steep discount to its peak valuation, but early believers are laughing all the way to the bank

Anthropic’s CEO stuns Davos with Nvidia criticism

Humans&, a ‘human-centric’ AI startup founded by Anthropic, xAI, Google alums, raised $480M seed round

SpaceX didn’t properly inspect crane before collapse at Starbase, OSHA says</div>
        </div>
        
        <div class="card" onclick="openModal('content-14')">
            <div class="source">TechCrunch</div>
            <div class="title">Apple’s new AirTag is louder and can be found across longer distances</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-14" style="display:none;">
            <h2>Apple’s new AirTag is louder and can be found across longer distances</h2>
            <p><strong>TechCrunch | 2026-01-26</strong></p>
            <a class="original-link" href="https://techcrunch.com/2026/01/26/apples-new-airtag-is-louder-and-can-be-found-across-longer-distances/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Apple on Monday introduced the next version of its AirTag, which will now feature a longer Bluetooth range, a louder speaker, and improved precision finding capabilities. The latter is powered by Apple’s second-generation Ultra Wideband chip, which is also found in the iPhone 17 devices, iPhone Air, Apple Watch Series 11, and Apple Watch Ultra 3.

With Precision Finding, the new AirTag can offer haptic, visual, and audio feedback to guide users to their lost items. Now, those finding capabilities extend up to 50% farther away with the prior generation, Apple claims. The upgraded Bluetooth chip, meanwhile, also helps extend the range at which items can be located.

Notably, with this update, Precision Finding will be accessible from the Apple Watch Series 9 or later and Apple Watch Ultra 2 or later.

The device’s speaker is also 50% louder than the prior generation, which means you can hear the AirTag’s beep from up to 2 times farther away than before.

The AirTag devices will also integrate with Share Item Location, an iOS feature that allows users to temporarily share the AirTag’s location with third parties. Today, 50 airlines are partnered with Apple for luggage tracking.

One thing that hasn’t changed is the AirTag’s price: it’s still $29 for a single AirTag and $99 for a four-pack, including free personalized engraving.

First launched in 2021, AirTag quickly came to dominate the market for Bluetooth-connected lost item finders, essentially forcing previous market leaders like Tile to quickly find an exit. The company alleged that Apple was unfairly competing as its finding network was instantly as big as the iPhone install base, and Apple was pushing AirTag rivals to integrate with its own Find My app. Other companies, like Chipolo, took Apple up its offer to work with Find My and competed against AirTag with products that work across iOS and Android, or that have different features, like rechargeable batteries.

Still, Apple’s AirTag remains the one to beat, with third-party estimates suggesting that nearly 70% of trackers sold in the latter part of 2024 were AirTag devices. Apple does not disclose its AirTag sales.

Tickets are live at the lowest rates of the year. Save up to $680 on your pass — and if you’re among the first 500 registrants, score a +1 pass at 50% off.Meet investors. Discover your next portfolio company. Hear from 250+ tech leaders, dive into 200+ sessions, and explore 300+ startups building what’s next. Don’t miss these one-time savings.

TikTok users freak out over app’s ‘immigration status’ collection — here’s what it means

Researchers say Russian government hackers were behind attempted Poland power outage

Microsoft gave FBI a set of BitLocker encryption keys to unlock suspects’ laptops: Reports

Capital One acquires Brex for a steep discount to its peak valuation, but early believers are laughing all the way to the bank

Anthropic’s CEO stuns Davos with Nvidia criticism

Humans&, a ‘human-centric’ AI startup founded by Anthropic, xAI, Google alums, raised $480M seed round

SpaceX didn’t properly inspect crane before collapse at Starbase, OSHA says</div>
        </div>
        
        <div class="card" onclick="openModal('content-15')">
            <div class="source">TechCrunch</div>
            <div class="title">Nvidia’s new AI weather models probably saw this storm coming weeks ago</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-15" style="display:none;">
            <h2>Nvidia’s new AI weather models probably saw this storm coming weeks ago</h2>
            <p><strong>TechCrunch | 2026-01-26</strong></p>
            <a class="original-link" href="https://techcrunch.com/2026/01/26/nvidias-new-ai-weather-models-probably-saw-this-storm-coming-weeks-ago/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">In the run-up to the winter storm currently pummeling much of the U.S., weather forecasts for some regions were all over the map, with snowfall predictions varying wildly.

Nvidia couldn’t have timed the release of its new Earth-2 weather forecasting models any better. Or, given how accurate the company claims the new models are, maybe it knew something we didn’t?

The new AI models promise to make weather forecasting faster and more accurate. Nvidia claims that one model in particular, Earth-2 Medium Range, beats Google DeepMind’s AI weather model, GenCast, on more than 70 variables. GenCast, which Google released in December 2024, was itself significantly more accurate than existing weather models that were capable of generating forecasts up to 15 days out.

Nvidia announced the new tools Monday at the American Meteorological Society meeting in Houston.

“Philosophically, scientifically, it’s a return to simplicity,” Mike Pritchard, director of climate simulation at Nvidia, told reporters on a call before the meeting. “We’re moving away from hand-tailored niche AI architectures and leaning into the future of simple, scalable, transformer architectures.”

Traditionally, most weather forecasts rely on simulations of physics as observed in the real world. AI models are a relatively recent addition. The Earth-2 Medium Range model is based on a new Nvidia architecture called Atlas, about which the company said it would release more details on Monday.

Alongside Medium Range, Nvidia’s Earth-2 suite includes a Nowcasting model and Global Data Assimilation model.

Nowcasting produces short-term predictions from zero to six hours into the future, and it’s aimed at helping meteorologists forecast the impacts of storms and other hazardous weather.

“Because this model is trained directly on globally available geostationary satellite observations, rather than region-specific physics model outputs, Nowcasting’s approach can be adapted anywhere on the planet with good satellite coverage,” Pritchard said. That should help governments of states and smaller countries understand how severe weather systems might affect their territories.

The Global Data Assimilation model uses data from sources like weather stations and balloons to produce continuous snapshots of weather conditions at thousands of locations around the world. Those snapshots are then used as launching points for weather models to make their predictions.

Traditionally, those snapshots have required tremendous amounts of computing power before the forecasting work could begin. “It consumes roughly 50% of the total supercomputing loads of traditional weather [forecasting],” Pritchard said. “This model can do that in minutes on GPUs instead of hours on supercomputers.”

The three new models join two existing ones: CorrDiff, which uses coarse-grained forecasts to generate speedy, high-resolution predictions, and FourCastNet3, which models individual weather variables like temperature, wind, and humidity.

Pritchard said that the new models should give more users access to powerful weather forecasting tools, which have historically been the domain of wealthier countries and large corporations, which have the funds to pay for costly supercomputer time.

“This provides the fundamental building blocks used by everyone in the ecosystem — national meteorological services, financial service firms, energy companies — anyone who wants to build and refine weather forecasting models,” Pritchard said. Some of the tools are already in use. Meteorologists in Israel and Taiwan have been using Earth-2 CorrDiff, for example, while The Weather Company and Total Energies are evaluating Nowcasting, Nvidia said.

“For some users, it makes sense to subscribe to an enterprise centralized weather forecasting system. But for others like countries, sovereignty matters,” Pritchard said. “Weather is a national security issue, and sovereignty and weather are inseparable.”

Tim De Chant is a senior climate reporter at TechCrunch. He has written for a wide range of publications, including Wired magazine, the Chicago Tribune, Ars Technica, The Wire China, and NOVA Next, where he was founding editor.

De Chant is also a lecturer in MIT’s Graduate Program in Science Writing, and he was awarded a Knight Science Journalism Fellowship at MIT in 2018, during which time he studied climate technologies and explored new business models for journalism. He received his PhD in environmental science, policy, and management from the University of California, Berkeley, and his BA degree in environmental studies, English, and biology from St. Olaf College.

You can contact or verify outreach from Tim by emailing tim.dechant@techcrunch.com.

Tickets are live at the lowest rates of the year. Save up to $680 on your pass — and if you’re among the first 500 registrants, score a +1 pass at 50% off.Meet investors. Discover your next portfolio company. Hear from 250+ tech leaders, dive into 200+ sessions, and explore 300+ startups building what’s next. Don’t miss these one-time savings.

TikTok users freak out over app’s ‘immigration status’ collection — here’s what it means

Researchers say Russian government hackers were behind attempted Poland power outage

Microsoft gave FBI a set of BitLocker encryption keys to unlock suspects’ laptops: Reports

Capital One acquires Brex for a steep discount to its peak valuation, but early believers are laughing all the way to the bank

Anthropic’s CEO stuns Davos with Nvidia criticism

Humans&, a ‘human-centric’ AI startup founded by Anthropic, xAI, Google alums, raised $480M seed round

SpaceX didn’t properly inspect crane before collapse at Starbase, OSHA says</div>
        </div>
        
        <div class="card" onclick="openModal('content-16')">
            <div class="source">TechCrunch</div>
            <div class="title">Synthesia hits $4B valuation, lets employees cash out</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-16" style="display:none;">
            <h2>Synthesia hits $4B valuation, lets employees cash out</h2>
            <p><strong>TechCrunch | 2026-01-26</strong></p>
            <a class="original-link" href="https://techcrunch.com/2026/01/26/synthesia-hits-4b-valuation-lets-employees-cash-in/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">British startup Synthesia, whose AI platform helps companies create interactive training videos, has raised a $200 million Series E round of funding that brings its valuation to $4 billion — up from $2.1 billion just a year ago.

Unlike some other AI startups that are still a long way from turning a profit, Synthesia has found a lucrative business in transforming corporate training thanks to AI-generated avatars. With enterprise clients including Bosch, Merck, and SAP, the London-based company crossed $100 million in annual recurring revenue (ARR) in April 2025.

This milestone explains why Synthesia’s venture backers are literally doubling down. The Series E that nearly doubled its valuation was led by existing investor GV (Google Ventures), with participation from several other previous backers — including Series B lead Kleiner Perkins, Series C lead Accel, Series D lead New Enterprise Associates (NEA), NVIDIA’s venture capital arm NVentures, Air Street Capital, and PSP Growth.

Aside from ongoing support, this round will bring both new and departing investors. On one hand, Matt Miller’s VC firm Evantic and the secretive VC firm Hedosophia are joining the cap table as new entrants. On the other hand, Synthesia will facilitate an employee secondary sale in partnership with Nasdaq, TechCrunch has learned.

To be clear, Synthesia isn’t going public just yet — Nasdaq isn’t acting as a public exchange in this operation, but as a private markets facilitator that will help early team members turn their shares into cash. These employee stock sales often happen outside of this framework, but usually at prices either below or above the company’s official valuation, and are sometimes frowned upon by other shareholders. With this process, all sales will be tied to the same $4 billion valuation as Synthesia’s Series E, while the company keeps an element of control.

“This secondary is first and foremost about our employees,” Synthesia CFO Daniel Kim told TechCrunch. “It gives employees a meaningful opportunity to access liquidity and share in the value they’ve helped create, while we continue to operate as a private company focused on long-term growth.”

For Synthesia, this long-term growth involves going beyond expressive videos and embracing the AI agents trend. According to a press release, the company is developing AI agents that will let its clients’ employees “interact with company knowledge in a more intuitive, human-like way by asking questions, exploring scenarios through role-play, and receiving tailored explanations.”

The company said early pilots have received positive feedback from customers, who reported higher engagement and faster knowledge transfer compared to traditional formats. This positive response explains why Synthesia now plans to make agents a “core strategic focus” to invest in, alongside further product improvements to its existing platform.

While it didn’t disclose revenue forecasts, the company hopes its platform will offer a welcome answer to the struggles of enterprises in keeping their workforce adequately trained despite rapid changes. “We see a rare convergence of two major shifts: a technology shift with AI agents becoming more capable, and a market shift where upskilling and internal knowledge sharing have become board-level priorities,” Synthesia’s co-founder and CEO Victor Riparbelli said in a statement.

Seeing boards care more about employees as a result of AI wasn’t on anyone’s bingo card, except perhaps Riparbelli. Together with his cofounder, Synthesia COO Steffen Tjerrild, Riparbelli took the initiative of conducting a secondary sale so that employees could share in the success of the unicorn company. Founded in 2017, Synthesia now has more than 500 team members, a 20,000-square-foot HQ in London, and additional offices in Amsterdam, Copenhagen, Munich, New York City, and Zurich.

While unusual for a British startup, this coordinated secondary sale isn’t a first and likely not a last, Synthesia’s head of corporate affairs and policy, Alexandru Voica told TechCrunch. “My guess is that as [U.K.-based] private companies stay private longer, this type of structured, cross-border employee liquidity may become increasingly common, so I wouldn’t be surprised to see others do it, either with Nasdaq or others,” he predicted.

Anna Heim is a writer and editorial consultant.

You can contact or verify outreach from Anna by emailing annatechcrunch [at] gmail.com.

As a freelance reporter at TechCrunch since 2021, she has covered a large range of startup-related topics including AI, fintech & insurtech, SaaS & pricing, and global venture capital trends.

As of May 2025, her reporting for TechCrunch focuses on Europe’s most interesting startup stories.

Anna has moderated panels and conducted onstage interviews at industry events of all sizes, including major tech conferences such as TechCrunch Disrupt, 4YFN, South Summit, TNW Conference, VivaTech, and many more.

A former LATAM & Media Editor at The Next Web, startup founder and Sciences Po Paris alum, she’s fluent in multiple languages, including French, English, Spanish and Brazilian Portuguese.

Tickets are live at the lowest rates of the year. Save up to $680 on your pass — and if you’re among the first 500 registrants, score a +1 pass at 50% off.Meet investors. Discover your next portfolio company. Hear from 250+ tech leaders, dive into 200+ sessions, and explore 300+ startups building what’s next. Don’t miss these one-time savings.

TikTok users freak out over app’s ‘immigration status’ collection — here’s what it means

Researchers say Russian government hackers were behind attempted Poland power outage

Microsoft gave FBI a set of BitLocker encryption keys to unlock suspects’ laptops: Reports

Capital One acquires Brex for a steep discount to its peak valuation, but early believers are laughing all the way to the bank

Anthropic’s CEO stuns Davos with Nvidia criticism

Humans&, a ‘human-centric’ AI startup founded by Anthropic, xAI, Google alums, raised $480M seed round

SpaceX didn’t properly inspect crane before collapse at Starbase, OSHA says</div>
        </div>
        
        <div class="card" onclick="openModal('content-17')">
            <div class="source">TechCrunch</div>
            <div class="title">This founder cracked firefighting — now he’s creating an AI gold mine</div>
            <div class="meta">2026-01-25</div>
        </div>
        
        <div id="content-17" style="display:none;">
            <h2>This founder cracked firefighting — now he’s creating an AI gold mine</h2>
            <p><strong>TechCrunch | 2026-01-25</strong></p>
            <a class="original-link" href="https://techcrunch.com/2026/01/25/this-founder-cracked-firefighting-now-hes-creating-an-ai-gold-mine/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Sunny Sethi, founder of HEN Technologies, doesn’t sound like someone who’s disrupted an industry that has remained largely unchanged since the 1960s. His company builds fire nozzles — specifically, nozzles that it says put out fires up to three times faster than earlier products while conserving two-thirds of the water. But Sethi is matter-of-fact about this achievement, more focused on what’s next than what’s already been done. And what’s next sounds a lot bigger than fire nozzles.

His path to firefighting doesn’t follow a tidy narrative. After nabbing his PhD at the University of Akron, where he researched surfaces and adhesion, he founded ADAP Nanotech, an outfit that developed a carbon nanotube-based portfolio and won Air Force Research Lab grants. Next, at SunPower, he developed new materials and processes for shingled photovoltaic modules. When he landed next at a company called TE Connectivity, he worked on devices with new adhesive formulations to enable faster manufacturing in the automotive industry.

Then came a challenge from his wife. The two had moved from Ohio to the East Bay outside San Francisco in 2013. A few years later came the Thomas Fire — the only megafire they’d ever see, they thought. Then came the Camp Fire, then the Napa-Sonoma fires. The breaking point came in 2019. Sethi was traveling during evacuation warnings while his wife was home alone with their then three-year-old daughter, no family nearby, facing a potential evacuation order. “She was really mad at me,” Sethi recalls. “She’s like, ‘Dude, you need to fix this, otherwise you’re not a real scientist.’”

A background spanning nanotechnology, solar, semiconductors, and automotive had made his thinking “bias free and flexible,” as he puts it. He’d seen so many industries, so many different problems. Why not try to fix the problem?

In June 2020, he founded HEN Technologies (for high-efficiency nozzles) in nearby Hayward. With National Science Foundation funding, he conducted computational fluid dynamics research, analyzing how water suppresses fire and how wind affects it. The result: a nozzle that controls droplet size precisely, manages velocity in new ways, and resists wind.

In HEN’s comparison video, which Sethi shows me over a Zoom call, the difference is stark. It’s the same flow rate, he says, but HEN’s pattern and velocity control keep the stream coherent while traditional nozzles disperse.

But the nozzle is just the beginning — what Sethi calls “the muscle on the ground.” HEN has since expanded into monitors, valves, overhead sprinklers, and pressure devices, and is launching a flow-control device (“Stream IQ”) and discharge control systems this year. According to Sethi, each device contains custom-designed circuit boards with sensors and computing power — 23 different designs that turn dumb hardware into smart, connected equipment, some powered by Nvidia Orion Nano processors. Altogether, says Sethi, HEN has filed 20 patent applications with half a dozen granted so far.

The real innovation is the system these devices create. HEN’s platform uses sensors at the pump to act as a virtual sensor in the nozzle, tracking exactly when it’s on, how much water flows, and what pressure is required. The system captures precisely how much water was used for a given fire, how it was used, which hydrant was tapped, and what the weather conditions were.

Why it matters: Fire departments can run out of water otherwise, because there’s no communication between water suppliers and firefighters. It happened in the Palisades Fire. It happened in the Oakland Fire decades earlier. When two engines are connected to one hydrant, pressure variations can mean that one engine suddenly gets nothing as a fire continues to grow. In rural America, water tenders, which are tankers shuttling water from distant sources, face their own logistical nightmares. If they can integrate water usage calculations with their own utility monitoring systems to optimize resource allocation, that’s a giant win.

So HEN built a cloud platform with application layers, which Sethi likens to what Adobe did with cloud infrastructure. Think Individual à la carte systems for fire captains, battalion chiefs, and incident commanders. HEN’s system has weather data; it has GPS in all devices. It can warn those on the front lines that the wind is about to shift and they’d better move their engines, or that a particular fire truck is running out of water.

The Department of Homeland Security has been asking for exactly this kind of system through its NERIS program, which is an initiative to bring predictive analytics to emergency operations. “But you can’t have [predictive analytics] unless you have good quality data,” Sethi notes. “You can’t have good quality data unless you have the right hardware.”

If building a predictive analytics platform for emergency response sounds daunting, Sethi says actually selling it is tougher, and he’s proudest of HEN’s traction on that front.

“The hardest part of building this company is that this market is tough because it’s a B2C play when you think of convincing the customers to buy, but the procurement cycle is B2B,” he explains. “So you have to really make a product that resonates with people — with the end user — but you still have to go through government purchasing cycles, and we have cracked both of those.”

The numbers bear this out. HEN launched its first products into the market in the second quarter of 2023, lining up 10 fire departments and generating $200,000 in revenue. Then word started to spread. Revenue hit $1.6 million in 2024, then $5.2 million last year. This year, Hen, which currently has 1,500 fire department customers, is projecting $20 million in revenue.

HEN has competition, of course. IDEX Corp, a public company, sells hoses, nozzles, and monitors. Software companies like Central Square serve fire departments. A Miami company, First Due, which sells software to public safety agencies, announced a massive $355 million round last August.  But no company is “doing exactly what we are trying to do,” insists Sethi.

Either way, Sethi says that the constraint isn’t demand — it’s scaling fast enough. HEN serves the Marine Corps, US Army bases, Naval atomic labs, NASA, Abu Dhabi Civil Defense, and ships to 22 countries. It works through 120 distributors and recently qualified for GSA after a year-long vetting process (that’s a federal seal of approval that makes it easier for military and government agencies to buy).

Fire departments buy about 20,000 new engines each year to replace aging equipment in a national fleet of 200,000, so once HEN is qualified, it becomes recurring revenue (is the idea), and because the hardware generates data, revenue continues between purchase cycles.

HEN’s dual goal has required building a very specific team. Its software lead was formerly a senior director who helped build Adobe’s cloud infrastructure. Other members of HEN’s 50-person team include a former NASA engineer and veterans from Tesla, Apple, and Microsoft. “If you ask me technical questions, I would not be able to answer everything,” Sethi admits with a laugh, “but I have such good teams that [it] has been a blessing.”

Indeed, it’s the software that hints at where this gets interesting, because while HEN is selling nozzles, it’s amassing something more valuable: data. Highly specific, real-world data about how water behaves under pressure, how flow rates interact with materials, how fire responds to suppression techniques, how physics works in active fire environments.

It’s exactly what companies building so-called world models need. These AI systems that construct simulated representations of physical environments to predict future states require real-world, multimodal data from physical systems under extreme conditions. You can’t teach AI about physics through simulations alone. You need what HEN collects with every deployment.

Sethi won’t elaborate, but he knows what he’s sitting on. Companies training robotics and predictive physics engines would pay handsomely for this kind of real-world physics data.

Investors see it, too. Last month, HEN closed a $20 million Series A round, plus $2 million in venture debt from Silicon Valley Bank. O’Neil Strategic Capital led the financing, with NSFO, Tanas Capital, and z21 Ventures participating. The round brought the company’s total funding to more than $30 million.

Sethi, meanwhile, is already looking ahead. He says the company will return to fundraising in the second quarter of this year.

Tickets are live at the lowest rates of the year. Save up to $680 on your pass — and if you’re among the first 500 registrants, score a +1 pass at 50% off.Meet investors. Discover your next portfolio company. Hear from 250+ tech leaders, dive into 200+ sessions, and explore 300+ startups building what’s next. Don’t miss these one-time savings.

TikTok users freak out over app’s ‘immigration status’ collection — here’s what it means

Researchers say Russian government hackers were behind attempted Poland power outage

Microsoft gave FBI a set of BitLocker encryption keys to unlock suspects’ laptops: Reports

Capital One acquires Brex for a steep discount to its peak valuation, but early believers are laughing all the way to the bank

Anthropic’s CEO stuns Davos with Nvidia criticism

Humans&, a ‘human-centric’ AI startup founded by Anthropic, xAI, Google alums, raised $480M seed round

SpaceX didn’t properly inspect crane before collapse at Starbase, OSHA says</div>
        </div>
        
        <div class="card" onclick="openModal('content-18')">
            <div class="source">The Atlantic</div>
            <div class="title">The Sacredness of the Everyday</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-18" style="display:none;">
            <h2>The Sacredness of the Everyday</h2>
            <p><strong>The Atlantic | 2026-01-26</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/science/2026/01/consciousness-journey-zen-meditation/685647/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Anyone who thinks the contemplative life amounts to a form of quietism or a retreat from the world’s suffering should spend some time shadowing Joan Halifax, the Zen priest and anthropologist. I’d been curious about Halifax for years, ever since I heard about an annual trek that she leads through the mountains of Nepal, bringing a cadre of doctors and dentists to remote mountain villages with little access to health care.

Each summer over the course of two weeks or so, this Nomads Clinic covers more than 100 miles on foot and horseback, at altitudes of nearly 18,000 feet. These “medical mountaineers,” as they’ve been called,  all volunteers, sleep in tents, often in freezing temperatures. But after some 40 annual trips to Nepal—Halifax is normally based in Sante Fe—she recently decided it was time to hang it up. She had just turned 80.

In addition to bringing medical care to remote mountain villages half a world away, Halifax has ministered to the dying in hospice, worked with the homeless in New Mexico, cared for prisoners on death row, and led countless protests for peace. I don’t know if Halifax has shed the last remnants of her ego—she would say she hasn’t—but the selflessness she manifests in the conduct of her life is something to behold, a reminder of what the exploration of human consciousness can lead a person to do and be. This, too, is a Buddhist principle—that overcoming one’s own small self should lead to greater compassion for others, and that the suffering alleviated when we transcend the ego is not only our own.

For more than 30 years, Halifax has been the abbot at Upaya Zen Center, the retreat she founded in Santa Fe in 1990. I’ve had the chance to meet her a couple of times; once, we appeared together on a panel to talk about psychedelics. Halifax was married to the pioneering Czech psychiatrist Stanislav Grof for several years in the 1970s. Working together, they gave transformative doses of LSD to the dying. For a period of time, Halifax regularly took large doses of LSD herself. Her first psychedelic trip, while wandering the streets of Paris in 1968, showed her “that there was beauty behind the beauty I perceived, and that mind was both in here and out there. I was dumbstruck.”

I could relate. After years of curiosity about psychoactive plants, my own experimentation with mushrooms and LSD in recent years fundamentally changed the way I understand the mysteries of consciousness and the self. So in 2024, I emailed Halifax to see if I might pay a visit to Upaya. My idea was to spend a week or so in residence, meditating with the aspiring monks, performing monkish chores, interviewing Halifax, and seeing if I could make a little more progress untying the knot of self. “Upaya is a factory for the deconstruction of selves,” she had told me. I was curious to find out how that worked.

Read: Psychedelics open your brain. You might not like what falls in.

But Roshi Joan, as everyone calls her, had other plans for me. She decided I should spend a day or two at Upaya and then accompany her up to “the refuge,” an off-the-grid compound of tiny houses and huts stretched out across a broad hammock of meadow at 9,400 feet in the Sangre de Cristo Mountains, north of Santa Fe. Whenever she’s not traveling or running conferences or teaching, Halifax retreats to these mountains, where she meditates and hikes and paints and writes and doesn’t have to play the role of abbot. She dispatches students to the refuge when she deems them in need of a period of monastic solitude—for years at a time, in some cases.

“After you’ve acclimated to the altitude, we’ll drive up to the refuge,” she said by email before my arrival in Santa Fe. “You can stay in the cave.” This was not put in the form of a question.

Halifax explained that even though it had neither plumbing nor electricity nor an internet connection, this was “a five-star cave” and I would be comfortable—or, more likely, I’d be uncomfortable in a spiritually productive way. I’m not much of a camper but decided I might as well put myself in her hands to see what the experience would yield.

The first thing you notice about Joan Halifax is her undiminished beauty—the shining blue eyes and the easy smile and the generous sweep of white hair. That she’s 83 is hard to believe. She moves through Upaya’s little village of low-slung adobes and tended gardens with a graceful authority. Yet abbot is a role that, these days, she’s more than happy to trade for the solitude and freedom of the refuge.

The refuge is at the end of a 25-mile-long rutted dirt road that climbs through a shadowy forest of pine and spruce, punctuated by the sparkle of the occasional stream or meadow. Though it was well into June, spring was still unfolding at this altitude, the meadow grasses and spruce tips bright green and the groves of ivory-trunked aspen just leafing out. After we unloaded our SUV at the main house, where we would gather for meals (and connect to the outside world, as the house has a satellite internet connection), Halifax escorted me to my lodgings, a hike of half a mile along a path through meadows lined with aspen trees, their new leaves fluttering gently. Along the way, she identified the scat of elk, deer, and bears.

The cave was a 12-by-15-foot cell dug into a south-facing hillside and lined with brown stucco; it was windowless except for a sliding glass door overlooking the meadow. In one corner stood a spartan single bed, in the other a small woodstove. Between them, against the back wall, a meditation cushion sat on a raised platform, beneath an embroidered fabric depicting a Buddhist figure I didn’t recognize. I pictured myself seated cross-legged on the platform, like one of those levitating yogis in a New Yorker cartoon. The room also had a small sink fed by a five-gallon jug of water suspended above it, a two-burner camp stove, some shelving for clothes and books, and a car battery hooked up to a small solar panel outside. This produced just enough juice to power a reading light and charge a phone, though with no cell service or internet connection, what was the point?

What was the point? Why did Roshi Joan want me here rather than at Upaya or the main house, with its creature comforts? (And why did she keep putting off our interview?) I came to suspect she had decided that the questions I had for her—questions regarding Buddhist ideas about the self and consciousness and her own path from psychedelics to Zen—were best approached obliquely, perhaps by way of firsthand experience rather than words; that I should answer them myself. When I’d told her what I was working on, she had diagnosed me as hopelessly stuck in my head. Better to spend several days alone with myself meditating and navigating these hills than in the more familiar landscape of concepts, something to which I should have known a Zen priest would be allergic. When we finally did sit down for our interview, in the main house on the morning of the third day, Roshi Joan began by saying, somewhat cryptically, that she had “divested from meaning.” Okay.

It took me a while to realize that for Halifax, the practice of Buddhism was everything and theories were of little use or consequence. It was only through doing that she had learned her most enduring life lessons, whether that meant sitting with death-row inmates who taught her how powerlessness ferments into anger, or ministering to people in their last days and hours. “You learn to be nimble toward whatever is arising, because there’s no one death,” she said, “and if you cling to expectations, you will experience futility.” It was here, in doing the work, that Buddhist ideas about impermanence, conditioning, and dependent arising became flesh.

I took the hint. When I asked Halifax about herself or about Buddhist philosophy, she often ducked my questions or directed me elsewhere, so during one of our daily walks, I instead asked her to describe exactly how her factory for the deconstruction of selves operated.

People come on silent retreat for a week or two at a time and spend most of their days sitting in the Zendo—the meditation hall—facing a wall or tracing walking meditations on the gravel paths that meander through Upaya’s gardens. (I’d witnessed this glacial parade of earnest zombies.) I asked if novices received any guidance or technique. Not much, she said. Students are instructed about posture, and beginners are told to follow the breath, which “unifies body, mind, and space.” As Halifax has written, zazen, or sitting, “is not a mental exercise, a thing you do with your mind.” Rather, “it is about being radically open to things just as they are, not grasping at or rejecting phenomena, but simply being present and at ease with moment-to-moment uncertainty and groundlessness” and “letting openness or not-knowing deconstruct our version of reality. It is the method of non-method.” Just sitting, upright—that, apparently, is all there is to zazen.

“Zen is the hardest school,” Halifax explained, “because there is so little support.” But at Upaya, she told me, “there is the jungle gym of structure”—the strict rules and rituals and routines that govern life on retreat.

“There’s a certain point at about day three where you can feel the whole room go poof,” she said. “And everyone realizes we’re now in one body, one mind.” I asked her how this transformation was achieved. “We don’t say we’re deconstructing the self, but that is what we’re doing,” she told me. “Living in silence means you can’t start a conversation, so there’s no opportunity for self-presentation. Then there are the rituals that organize the day. These draw people into the group and relieve them of having to make decisions. Rituals take the place of a certain amount of volition.” It hadn’t occurred to me that ritual and silence could serve as tools to change consciousness and breach the hard shell of self.

Arthur C. Brooks: Five teachings of the Dalai Lama I try to live by

But it is the agony of meditating for hours at a time that finally breaks down the ego. I asked her what people meditate about. “Mostly they ruminate and plan,” she said. “They do that until they can’t stand the thought of themselves any longer. You’re just sitting there for hours on end, and the entertainment value of watching the same reruns all day long diminishes over time. Pretty soon, it becomes unsustainable; they’re exhausted and uncomfortable, and that’s when they drop in.”

To “drop in,” Halifax explained, is to enter a state of being completely present in time and space, experiencing “the sense field”—the world as it appears to our senses prior to thought—without conceptualizing, and surrendering the sense of a separate self. The recipe was simpler (and much less appetizing) than I would have imagined: To transcend the self, force yourself to be alone with it long enough to get so bored and exhausted that you are happy to let it go.

Halifax, who did anthropological fieldwork in Africa, thinks of the Zen retreat as an initiation ceremony, or rite of passage, and like most such rites, it involves the metaphorical death of the ego followed by rejoining the group. She regards the psychedelic trip as another rite of initiation, but “it’s a shortcut,” and one she’d rather her students not take. I wondered if this helped explain why she preferred that I stay at the refuge rather than mingle with her students at Upaya. Perhaps she thought contact with me would undermine the process by encouraging them to take the psychedelic shortcut.

“There is a lot gained when we give up the self,” she noted. “We break out of rumination. We discover we’re part of something larger, and we learn it feels good to care for others.” When I asked Halifax if she had succeeded in exorcising her own self, she allowed that she can be self-righteous at times. “There is moral injury, moral outrage, moral apathy—all of them are products of either a sense of superiority or inferiority,” she said. “So they’re all ego-based.”

I came to understand that Roshi Joan had sent me to the cave because there were no words or ideas she could offer that would teach me as much as simply being completely alone with myself in the middle of these mountains, with no phone or any other screens (and no toilet). Her idea, I eventually saw, was to pose a kind of experiential koan for me to puzzle and, perhaps, to help me unlearn some of the things I thought I had learned about consciousness and the self.

Cave life quickly stripped down to the bare essentials: collecting, splitting, and stacking wood; building fires; hauling water; digging pits in the woods; sweeping the floor and threshold; and, for hours each day, meditating on the platform. I’ve meditated for several years now, but never as easily or as deeply or as strangely as I did in my little cave. It may have been the silence, which felt bottomless, or the certainty that I would not be interrupted or distracted. Even the air there felt different, as if the absence of the electromagnetic waves that normally surround and pass through us made it easier to empty the mind of its usual detritus. I found I could sit for hours at a time, something I’d never managed to do before.

It helped that there was nothing else I needed to do, except maybe brew a cup of tea or sweep the cave again. Somehow, these seemed like particularly cave-appropriate activities. I fell into a routine so elemental and repetitive that it began to feel like ritual. The only snafu came the first time I attempted to use my hand-dug pit toilet and, failing to position myself properly, managed to pee into my sneaker. Now I was a shoeless monk. Which also seemed cave-appropriate.

One morning, I decided to try a meditation I’d learned from my time with the Nepalese French Buddhist monk Matthieu Ricard, who has written extensively on the self as an illusion. To see this, he suggested I explore the rooms of my mind, one by one, as if searching for a thief—what he called “the thief of self.” Looking within, I found all sorts of mental stuff but, as Ricard had predicted, none of it qualified as a self. Rather, I witnessed a parade of unbidden, free-floating perceptions, feelings, images, sensations, and thoughts, but I could locate no thinker of these thoughts or perceiver of these perceptions.

The longer I sat, the stranger these appearances became, as the space of my awareness became an empty stage. Picture a circus ring where all kinds of images might suddenly and inexplicably appear out of nowhere. Why is there now a bank of three old-timey telephone booths with men inside making calls? And what’s this hammer suddenly coming down on a knee?! Or that automatic glass door swinging open for no one? These stray images were then blasted away by a blazing sun that completely filled the space of awareness before transforming itself into a gigantic eyeball—a sighted sun with a black circle of iris. Could this be the anarchic mind that emerges when the ego relinquishes its hold?

Maybe, and yet these dreamy, hypnagogic images were more curious than frightening, probably because it was easy enough to chase them away, to change the mental channel, simply by willing it. So then who, or what, did the chasing? The source of that will, that inchoate “I,” might have escaped introspective detection, yet it could still make things happen or stop happening. The self might well be illusory, I decided, but no more so than color or any other construct of the mind. Put another way, the self can be both illusory and real, or real enough.

Initially, I found I was talking to myself out loud, trying to fill the vast space of silence, which made it feel as though I had doubled my self rather than eliminated it—given it a little company. “Should I brew a cup of tea? Put another log on the fire?” I would ask. And I would answer: “Sure,” or “Good idea.” But after a day or two, I fell in love with the silence, and the voices stopped. I found the handful of chores completely absorbing, as if nothing in the world mattered as much as splitting firewood, fully occupying my attention and leaving no remainder of thought, self-consciousness, or anticipation. The distance between living and meditating had narrowed to a sliver. When I described the satisfactions of my routine to Roshi Joan during one of our hikes, she smiled: “That’s the sacredness of the everyday.”

Something was happening to my sense of self, and it seemed to have everything to do with what was happening to my sense of time. I had never given much thought to the relationship between self and time, but it explains a lot. When the self is deprived of time past (memory) and future (anticipation), it melts away. Absorbed in meditation, or in my chores, or in watching a small herd of elk graze in the meadow below at sunset, I could feel my time horizon shrink. The feeling was unfamiliar, since my usual mental coordinates place me somewhere in the proximate future, a locus of anticipation and, all too often, unfocused worry. But now, for longer and longer stretches, I was simply here, being, with no thought of the past or the future.

To my surprise, these moments of simple and more or less self-less consciousness did not occur when my eyes were closed—in fact, the darkness sent me zooming off to all kinds of strange places. No, now it was when my eyes were open that the stream of thought stilled and pooled, and not only on the meditation platform; it could happen when I was moving around the cave doing chores or hiking in the woods. The miraculous everyday fact of consciousness loomed larger than “the hard problem” of how a brain produces subjective experience.

Had I “dropped in”? There were moments when all I experienced was what Roshi Joan had called the “sense field.” This happened especially upon opening my eyes in meditation, but it was never very long before I slipped back into reflection and then the inevitable jotting-down of notes, and all at once I was back in the self-world. To stay in that state of unthinking presence was like walking a tightrope only to suddenly look down, panic, and come plunging back to Earth.

Except once, when I managed to look not down but up. I had woken up in the middle of the night and stepped outside into the cold night air. There was a new moon, and the only light in the world was that of the stars, which were out in force, brighter and more numerous than I’d ever seen them, but also strangely different. Instead of dotting the same black scrim, like pinholes in a two-dimensional theater backdrop, the stars were scattered through space at dramatically varying distances, a vast swarm of them filling every last corner of an even vaster, more numinous, and emphatically three-dimensional darkness. Even stranger, the negative space between the stars had flipped to positive, forming a soft, almost palpable blackness that embraced the stars and reached all the way to Earth, enveloping it and me in the same intergalactic blanket. For the first time, I could see—no, could feel—that the stars and I shared the same infinite space.

Adam Frank: The truth physics can no longer ignore

My brain’s usual priors, predictions, and inferences about the night sky had broken down, it seemed, allowing me to see more of the galaxy and space itself than I ever had. There was hugely more of it and less of me, rendered infinitesimal in the presence of this immensity. I felt as though every previous experience I’d had of the night sky had been filtered through some idea or model or expectation and so had been something less than completely conscious. And I understood that this state—abstracted, distracted—had been my default. A line in a poem by Jorie Graham came to me:

This is what is wrong: we, only we, the humans, can retreat from ourselves and

Only we, the humans. Yes! What other animal can afford to be anything less than completely conscious?

This moment of being fully, freshly present to the universe stopped me cold and made me wonder if all my hard thinking about consciousness had missed something crucial about it. The more I focused the narrow beam of my attention on what consciousness is and what it does and how it came to be, the less of it I was actually experiencing—whatever it was. My time in the cave and, now, beneath this night sky showed me the price of my impatience with the mystery.

“Always keep a don’t-know mind,” Roshi Joan had said to me. Sometimes not knowing opens us to possibilities that knowing, or trying to know, or thinking we already know, closes off. In the years since I had embarked on this inquiry, desperate to know, I had narrowed the aperture of my awareness, sacrificing this, the glory of the night sky, for a keen intellectual focus. But as my days of solitude in these mountains had shown me, that wider circle of light, that numinous lantern of awareness, is still available to us, so long as we can break the spell of self and its distractions. Consciousness is a miracle, truly, and remains the deepest of mysteries, yes, but it is also so very simple that it can fit into a sentence: I open my eyes and a world appears.

This essay was adapted from Michael Pollan’s book, A World Appears: A Journey Into Consciousness, published next month.

​When you buy a book using a link on this page, we receive a commission. Thank you for supporting The Atlantic.</div>
        </div>
        
        <div class="card" onclick="openModal('content-19')">
            <div class="source">The Atlantic</div>
            <div class="title">Photos: Snow and Ice Blanket the U.S.</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-19" style="display:none;">
            <h2>Photos: Snow and Ice Blanket the U.S.</h2>
            <p><strong>The Atlantic | 2026-01-26</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/photography/2026/01/photos-snow-and-ice-across-usa/685756/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-20')">
            <div class="source">The Atlantic</div>
            <div class="title">Colleges Are Stuck Between Bad Options for Fighting Hateful Ideas</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-20" style="display:none;">
            <h2>Colleges Are Stuck Between Bad Options for Fighting Hateful Ideas</h2>
            <p><strong>The Atlantic | 2026-01-26</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/ideas/2026/01/college-antisemitism-free-speech-university-florida/685743/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Pity Chris Summerlin, the dean of students at the University of Florida. He’s being sued by an anti-Semite, and that’s not the worst of his predicament. So far, judges who have ruled on the case have given mixed verdicts on whether he is likely to win or lose at trial. Summerlin deserves to lose on the merits: He expelled a law-school student for speech that, while morally degenerate, is properly protected by the First Amendment. And––this is the pitiable part––it’s easy to see how he might have concluded that giving a bigot grounds to win a civil-rights lawsuit was his best option.

College deans and administrators keep confronting the same dilemma: They face intense pressure to punish speech that elicits fear or moral disgust on campus. They also have legal obligations—and face countervailing pressure—to refrain from violating the free-speech rights of students. They cannot always do both. The result is cases such as Damsky v. Summerlin—cases that might be avoided under a better approach to fighting anti-Semitism and other hateful ideas.

Preston Damsky was a law student at the University of Florida who was open about his belief that America was founded by and for the white race and that its racial character should be preserved, by force if necessary. According to court documents, he wrote in one assignment that “the founding generations” fought, killed, and died for their sovereignty, and argued, “We are not yet so outnumbered and so neutered that we cannot seize back what is rightfully ours.” To survive “as masters in the ancestral lands of their ancestors,” he wrote in another paper, “the People” must exercise “their revolutionary right to dismember or overthrow” the government, “a process which no deskbound jurist can gleefully look forward to; for it will be a controversy decided not by the careful balance of Justitia’s scales, but by the gruesome slashing of her sword.”

Neither passage was initially deemed to violate school rules, however much they upset Damsky’s peers. But they informed the way that administrators reacted when Damsky went on X on March 21 and posted the following:

My position on Jews is simple: whatever Harvard professor Noel Ignatiev meant by his call to “abolish the White race by any means necessary” is what I think must be done with Jews. Jews must be abolished by any means necessary.

Ignatiev, who died in 2019, was a factory worker who entered academia late in life as a Marxist and gained minor notoriety with his 1995 book, How the Irish Became White. A few years prior, he co-founded a journal called Race Traitor. He believed that whiteness and white privilege were social constructs that impeded working-class solidarity and that people ought to renounce their privilege and become “unwhite,” thus abolishing whiteness. “Without the privileges attached to it, the white race would not exist, and white skin would have no more social significance than big feet,” he once said.

After Damsky invoked Ignatiev in his X post, a Jewish law professor replied, “Are you saying you would murder me and my family? Is that your position?” To which Damsky retorted, “Did Ignatiev want Whites murdered? If so, were his words as objectionable as mine? If Ignatiev sought genocide, then surely a genocide of all Whites would be an even greater outrage than a genocide of all Jews, given the far greater number of Whites.”

The exchange troubled many observers inside and outside the university, though they differed on what to make of it. Should Damsky’s statement that “Jews must be abolished by any means necessary” be received as a portent of murderous violence? Was it the hateful rhetoric of a contemptible but presumably nonmurderous anti-Semite? Or, given the reference to a leftist academic who wanted to abolish whiteness, was it the snide trolling of a shitposter mocking a double standard? No one knew for sure. Even the closest readers of the post could trouble themselves wondering if Damsky’s words implied something more than a call for members of that group to voluntarily abjure their own identity.

Soon, Damsky was suspended, then expelled. In suspending Damsky, the school asserted that he’d “created a material and substantial disruption to the academic operation of the UF College of Law.” When it expelled him, it cited provisions in its student code that prohibit “disruptive conduct” and “harassment”––but both provisions state that whatever they prohibit does not include “conduct protected by the First Amendment.”

In subsequent legal proceedings, the University of Florida would defend the expulsion of the student, arguing that Damsky’s words constituted “true threats,” which are not protected by the First Amendment, and were disruptive. Though public schools can prohibit some speech that is “substantially disruptive to learning,” even if, outside of schooling, the same speech would be protected, there is disagreement about whether and how that precedent applies to higher education. “UF cannot hold its adult students to a standard created for students as young as five years old,” the ACLU stated in an amicus brief supporting Damsky as he sought a preliminary injunction to reverse his expulsion. “That is especially true when the adult is engaging in speech off-campus.”

To win at that preliminary stage, Damsky had to show a substantial likelihood that he would prevail in the case overall. He cleared that high hurdle, according to Judge Allen Winsor. “Some may assume that anyone uttering such commentary is more likely to act violently than someone who does not,” he wrote in his U.S. District Court opinion, but “the test is whether Damsky’s posts constituted a ‘serious expression’ that he meant ‘to commit an act of unlawful violence.’” Acknowledging that “many would not love the idea of attending school with someone who burns crosses, marches in Nazi parades, or engages in countless other forms of offensive expression,” Winsor noted—quoting Justice William Brennan’s landmark First Amendment ruling in Texas v. Johnson—it is still the case that “the government may not prohibit the expression of an idea simply because society finds the idea itself offensive or disagreeable.” Nor, the judge ruled, did the university meet the burden for showing the speech to be disruptive in a way that rendered it unprotected.

But the judge’s order to reinstate Damsky was paused pending appeal. And the Eleventh Circuit Court of Appeals ruled that in its estimation, the University of Florida was likely to prevail, because under the precedent set in Tinker v. Des Moines Independent Community School District, “the First Amendment does not protect speech that ‘materially disrupts classwork or involves substantial disorder or invasion of the rights of others.’” The trial court, and perhaps future appeals-court judges and the Supreme Court, will decide if they agree with the panel’s ruling that “UF students, faculty, and staff could reasonably interpret Damsky’s posts as threatening violence on UF’s campus,” and that the community “could reasonably interpret Damsky’s posts as promoting extralegal violence, and schools can regulate at least some speech that calls for illegal conduct.” (I hope other judges disagree: Such a precedent would suggest that college students can be expelled for political speech as common as “abolish whiteness,” “globalize the intifada,” and “no justice, no peace.”)

When a college decisively loses at any stage of free-speech litigation, civil libertarians typically point to the loss as a powerful case for honoring the First Amendment if only out of self-interest: Don’t expel a student like that dean did, or your school will get sued and lose too. But colleges are caught between conflicting incentives right now. Few in higher education have forgotten the 2023 congressional hearings in which Representative Elise Stefanik questioned the presidents of Harvard, MIT, and the University of Pennsylvania about anti-Semitism on campus. Each leader was asked, “Does calling for the genocide of Jews violate your rules, conduct codes, or harassment policies?” All attempted nuanced answers. For example, was the call for genocide targeted at an individual, thus amounting to harassing conduct, or was it mere vile speech?

Their answers, though legally sound, elicited a furious backlash. Stefanik called on the presidents to resign. The House passed a resolution calling the presidents “evasive and dismissive” and condemning “their failure to clearly state that calls for the genocide of Jews constitute harassment and violate their institutions’ codes of conduct.” Kathy Hochul, the governor of New York, wrote a letter to college presidents asserting that calls for genocide violate New York’s Human Rights Law, Title VI of the Civil Rights Act, and SUNY’s code of conduct; she threatened “enforcement action” if colleges and universities were found not in compliance. In Florida, Governor Ron DeSantis said that he wanted the college presidents to lose their jobs (the fate that befell Liz Magill, who resigned as Penn’s president because of that viral congressional hearing on anti-Semitism). Donald Trump and his administration would later target those same universities with anti-Semitism probes and regulatory actions that threatened billions of dollars in federal funding while severely constraining their autonomy.

For administrators at the University of Florida, who declined to comment while this litigation is ongoing, the message was presumably clear: If a student calls for the genocide of Jews, deciding whether to punish them based on whether the First Amendment technically protected the speech would be seen as suspect by federal and state officials––and might, if history repeated itself, result in job loss and significant funding losses.

Then along came Damsky with a social-media post that concluded, “Jews must be abolished by any means necessary.”

“Confronting the fact pattern in his case, an institution might well ask their legal advisers if they could justify punishing the speech,” Jackie Gharapour Wernz, an attorney who advises educational institutions about complying with nondiscrimination laws such as Title VI and Title IX, told me. And she could imagine a legal adviser signing off on a punishment, despite its risks. “If they act, they may get sued for violating free-speech rights,” she explained. “If they don’t act, they may face complaints or lawsuits from students or employees claiming they’re ignoring or contributing to a hostile environment. In a very real sense, the institution is choosing which lawsuit it wants.” Institutions may decide to consider a range of risks, she said, “including political pressure, federal attention, and backlash from different parts of the community, and sometimes those pressures drive decisions as much as the legal merits.” An institution might even want to lose in court, she said, “because that gives them cover later to say, We actually can’t punish this speech.”

Damsky’s lawyer, Anthony Sabatini, believes that the political climate is affecting what would normally be a simple case about unambiguously protected speech. “UF clearly tried to use heightened political concerns about antisemitism (or what gets called antisemitism) to pressure the district judge, as you’ll see in their pleadings,” he told me via email. “The Trump administration is clearly using Title VI to unlawfully attempt to stop lawful criticism of Israel by equating it with antisemitism and will lose in court on that.”

Of course, college administrators might also punish speech of the sort Damsky deployed out of a desire to oppose anti-Semitism or to protect the educational experience of Jews. Kenneth L. Marcus, the founder and leader of the Louis D. Brandeis Center for Human Rights Under Law, a legal organization focused on fighting anti-Semitism, argues that anti-discrimination law is a vital tool for protecting the rights of Jewish students and any others targeted on the basis of their race, color, or national origin. “Whenever we take seriously our civil-rights laws, there will be questions about conduct that falls in a gray area between protected speech and unprotected activity,” he told me. “Just because there are some tough cases doesn’t mean that we should throw out the rules altogether.”

It is dangerous, he argued, “to minimize threats and to assume that persons involved in threatening communications don’t mean what they’re saying seriously.” In the Damsky case, “administrators simply cannot wait for apparently violent threats to turn lethal before they take action,” he argued. “Can you imagine if the university had done nothing and then the speaker actually followed up on his apparent threat by making an actual effort to abolish Jews by any means necessary? The university would at a minimum be held liable for its failure to exercise due care, and it should be.”

While I agree with Marcus that “the world that we’re living in since October 7, 2023, is one in which Jewish Americans and others face continuing and real threats,” and that anti-Semitism must be fought in any healthy and morally decent society, there is no simple correlation between acts of violence and rhetoric of the sort Damsky spewed. His words clearly don’t meet the long-standing Supreme Court threshold for “true threats,” and insofar as a student is secretly planning violence, expulsion presumably wouldn’t stop them. I also doubt that compelling colleges to punish students like Damsky, despite the lack of a strong legal case, is an effective way to fight anti-Semitism.

While no one, least of all Jews, deserves to live in a world with anti-Semites, nonviolent ones included, we do live in such a world. In a country where Tucker Carlson and Candace Owens expose massive audiences to the most nonsensical conspiracy theories, and as vile an anti-Semite as Nick Fuentes has more than 1 million followers on X, insulating schools from anti-Semitism is impossible. Administrators cannot make it disappear. They can, however, help students improve at countering bad ideas.

The academic philosopher Dan Williams recently argued that establishment institutions “have clung to a set of habits and norms—most fundamentally, an aversion to engaging with illiberal ideas to avoid ‘platforming’ and ‘normalising’ them—adapted to a world that no longer exists.” From his perspective, which I find persuasive, the modern internet makes this sort of aversion unwise: Gatekeepers don’t exist in the digital era, and “once established institutions lost the privilege to control the public conversation, they acquired an obligation to participate within it.” I’d feel more hopeful about the ability of American institutions to adapt if universities prepared the rising generation to rebut history’s worst ideas rather than trying to suppress them.

If Damsky returns to law school, some classmates will treat him as a social pariah who deserves scorn. Some will fear for his everlasting soul as he transgresses morality by indulging hatred. To forbear bigots is no easy thing, and it is not for me to judge how others do it. But I hope some of his classmates would use the presence of an anti-Semitic white nationalist to hone the strongest and most persuasive arguments against his views. I hope some would study the example of Daryl Davis, the Black musician who has successfully talked multiple members of the Klu Klux Klan into giving up their hoods, and that others would follow the example of the New College of Florida students who converted a white-nationalist classmate into an anti-racist activist.

Anti-discrimination laws have a role to play in academia: College administrators have an obligation to ensure that no student is denied educational opportunities on the basis of their race, religion, ethnicity, or national origin, and that, insofar as their student bodies include bigots, they don’t harass or bully Jews or anyone else. But the policing of speech that is protected by the First Amendment is both unlawful and insufficient. Perhaps, in a world where hateful speech can be distributed to mass audiences more easily than ever before, it’s even counterproductive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-21')">
            <div class="source">The Atlantic</div>
            <div class="title">How the Bernie Goetz Shootings Explain the Trump Era</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-21" style="display:none;">
            <h2>How the Bernie Goetz Shootings Explain the Trump Era</h2>
            <p><strong>The Atlantic | 2026-01-26</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/ideas/2026/01/bernie-goetz-shooting-racial-resentment/685726/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Without Trumpism, Democrats and anti–Donald Trump conservatives tell themselves, America can once again be the nation it always was. This political moment, many feel certain, is an aberration, an unfortunate detour from who we are and what we stand for. Surely, they hope, if the MAGA Republicans can just be unseated in this fall’s midterm elections, then once Trump leaves office, this country can get back on track.

But the political space we inhabit has deep roots. It did not erupt out of nowhere in 2016. The racialized rage and contempt for the rule of law that so thoroughly mark the present are the products of a longer political project set in motion during the 1980s, when the Reagan Revolution—itself anchored in white resentment—recast racial violence as necessary and defensible, restoring to it a legitimacy that had not been seen since the Jim Crow era and the Gilded Age.

Clint Smith: Those who try to erase history will fail

One particularly notorious event, which took place four decades ago on a New York City subway car just three days before Christmas, both reflected and fueled this dramatic political shift. On December 22, 1984, a downtown-bound 2 train rattled out of the 14th Street station, its walls layered in graffiti, its riders reading newspapers or staring silently in the exhausted intimacy of a city still struggling to rebound from a major fiscal crisis in the 1970s—and finding this new decade even more challenging.

On the subway car that day were four Black teenagers who lived in the same housing project in the heart of the South Bronx—Darrell Cabey, James Ramseur, Barry Allen, and Troy Canty. This neighborhood had been especially ravaged in recent years: recreational opportunities ended, public libraries closed, streets left grim by an illegal economy of drugs and sex that had become one of the few remaining ways to make money. With little else to do on what was an unseasonably balmy afternoon, this group of friends decided to head into Manhattan. Their plan for the day was modest and desperate at once—to stop at a video arcade, jimmy open a few coin receptacles, and come away with at least a few stolen dollars in their pockets.

Seated in the same car, directly across from two of the teenagers, was a white loner named Bernie Goetz. A 37-year-old single, self-employed electronics nerd living in Greenwich Village, Goetz was also trying to simply live his life in a city coming apart at the seams. He still had a decent income and a roof over his head, but Goetz’s own material security did not temper the growing resentment he felt every time he stepped outside his apartment and onto city streets. Disconcerting numbers of unhoused people were in Union Square Park, and visibly ill men—gaunt, with lesions and ragged coughs—streamed each day into the emergency room at the nearby St. Vincent’s Hospital. Meanwhile, trash littered the sidewalks and piled up on stoops, and the illicit economy seemed to occupy every corner.

Goetz understood this disorder not as the product of scant civic resources or state retreat but rather as the result of liberal misrule—do-gooder bureaucrats, failed social programs, and a city that had coddled the undeserving and the criminal. He had long since concluded that ordinary men like him would just have to look out for themselves.

When he took his seat on the 2 train that Saturday, Goetz had just spent a frustrating morning working on a piece of electrical equipment and had decided to head downtown for a bit. As he now regularly did, he was carrying a loaded .38-caliber Smith & Wesson hidden in a quick-draw holster inside his waistband.

Canty took in the white guy who had boarded at Union Square, paused the fooling-around that he had been doing with his friends—slapping at the plastic straps that hung from the ceiling of the train car, joking loudly—and greeted the man. Encouraged when he got a terse “Fine” after a “How are you?” Canty asked if the man had $5. He didn’t mind panhandling. That had become a way of life for the city’s poorest residents, young and old alike.

Allen was even more encouraged when this man stood slowly, turning as if he might be getting his wallet. But then Goetz swung back around, assumed a combat stance, and began firing.

Within seconds, Goetz shot Canty in the chest and Allen, who had been standing nearby, in the back as he tried to flee. Goetz next aimed his weapon at Ramseur and then Cabey, who sat farther down the car. He hit Ramseur, who was also trying to run. The bullet pierced Ramseur’s arm and entered his chest through his side. But Goetz’s fourth bullet missed Cabey, and the shooter was, as he later made clear, determined to take every one of the kids out.

As Cabey cowered in his seat, Goetz walked over to him and said, “You seem to be all right. Here’s another,” before shooting at him again from point-blank range.

Goetz didn’t kill these teenagers, but not because he hadn’t tried. He later said, “If I had more bullets, I would have shot ’em all again and again. My problem was I ran out of bullets.”

Yet this man, who then disappeared into the tunnels of the NYC subway system and remained on the lam for nine days, was not reviled as a vicious and violent criminal by a stunning number of New Yorkers, particularly white ones. Goetz became an overnight celebrity, heralded as a real-life “Death Wish Vigilante,” a reference to the blockbuster movies of this era, in which Charles Bronson plays a regular white guy who chooses to meet urban threats with lethal force. Here was a man who had had enough, who had done what others wished they could.

Goetz’s victims were, in turn, villainized and bombarded with hate mail. No matter that these young people were all only 18 or 19, and also unarmed and slight, the tallest of them only 5 feet 6 inches. No matter that Goetz had severed Cabey’s spinal cord and permanently paralyzed him from the waist down. No matter that Ramseur was found dead, likely from suicide, on an anniversary of this horrific event, and that Allen would descend into drug addiction.

They were deemed thugs and animals, and were said to symbolize all that was wrong with America’s cities as well as with the liberals who had enabled the city’s poor, lazy, and criminal elements. They were proof that hard-working Americans were under siege. These teens had gotten exactly what they deserved.

But the public’s reaction to the subway shooting was neither obvious nor inevitable; it was actively cultivated. Doing much of the work to normalize hatred and violence after the event were conservative, misinformation-driven media that were themselves aggressive and ascendant. The Goetz case was a long-awaited opportunity, particularly for the conservative Australian media mogul Rupert Murdoch, who dreamed of making his paper the New York Post the dominant tabloid in NYC and then taking over the entire U.S. news-media market.

From the moment that Goetz pulled the trigger on Cabey, Ramseur, Allen, and Canty, columnists from both the New York Post and the other major New York tabloid trying to hold its own, the Daily News, framed the case as a referendum on self-defense rather than an act of attempted murder. Even though the teens were the ones in ICUs and Goetz had been carrying an illegal weapon on the train that day, they were the “predator” and he was the “prey.”

During the 1980s, both tabloids pandered to the racial resentments and fears of white New Yorkers when covering all of the city’s ills. The New York Post seemed to practically invite readers to cheer for acts of white rage—in the Goetz case and the brutal white-mob killings of Black New Yorkers in Howard Beach and later in Bensonhurst—as well as to steadfastly ignore the civic wreckage that had paved the way for such acts of lawlessness in the first place.

Facts had begun to matter less and less. For example, even though it was fiction, a story that the teenagers Goetz shot were wielding sharpened screwdrivers soon became gospel in tabloid and mainstream press alike. This very much mattered to how the public felt about the case.

But what mattered more was a political shift that was taking place, one that had made it possible for the right-leaning media to profit so handsomely off the resentment and rage of ordinary people.

In 1980, Ronald Reagan took the White House. He insisted that government was bloated and inefficient, that liberal social programs bred only dependency and crime, and that law-abiding citizens, implicitly white, had been abandoned in favor of a lazy “underclass,” often marked explicitly as Black. The Reagan administration counted on Murdoch’s newspapers to hammer away at these messages on its behalf.

According to Reagan Republicans, America’s problems could be solved by cutting federal spending, slashing taxes, and gutting regulations on business. If the rich thrived, their argument went, the benefits would trickle downward to the nation as a whole.

The desire to do all of these things was not new—it had long animated the ambitions of the country’s wealthiest Americans. Ever since the New Deal had constructed a meaningful social safety net in response to the devastation of the Great Depression, the rich had sought to weaken labor, shrink the public sector, delegitimize redistributive social policies, deregulate finance and industry, and drive taxes lower. They had long insisted that private control of public life simply made sense.

Yet it was politically risky for any administration to openly slash the tax base that funded public schools, affordable housing, city services, and public-health systems. As jobs disappear, wages fall, housing and health care grow scarce, and education becomes an engine of debt, people might not only be left poorer; they also might demand accountability and redress.

Reagan Republicans fully understood the political risks of dismantling more than 50 years of public policy, yet—more effectively than any of their predecessors—they succeeded in manufacturing the popular consent needed to do precisely that. The key to this achievement was a simple but devastating insight: The most effective way to discredit liberal social policy was to starve it of resources and then point to its inevitable failure. As the Reagan aide James Cicconi explained in an internal memo, the era of “decreasing governmental resources” would make  the “liberal approach” to governance “impossible to sustain financially.” This would force the adoption of “alternatives.”

With each passing year of the 1980s, this engineered collapse was recast as proof that the nation’s problems flowed from liberal social, political, and racial policies, and from the supposed moral failures of people who, it was claimed, simply did not want to work. Inequality was framed as meritocracy.

As the Reagan Revolution matured, taxes were slashed and regulations rolled back; in turn, the social programs and city services upon which ordinary Americans depended were devastated. And as the rich grew richer and the lives of ordinary people grew more difficult, the narratives emanating from the White House down continued to blame the deepening crisis—the rise in homelessness, the AIDS epidemic, the garbage-strewn streets, the turn to illegal economies—not on policy choices but on bad people. Crime, disease, and addiction were cast as moral failures rather than as the predictable consequences of political decisions.

Arguments such as these distracted the public from rethinking the true cost of stripping public coffers and actively widening the country’s income gap. In this sense, politicians interested in remaking the economy in ways more favorable to the rich did not merely rely on racialized resentment; they also helped ensure that anger would be directed downward, toward those even less fortunate than themselves.

White Americans in particular were offered a Faustian bargain during the Reagan ’80s: accept a thinner safety net, a harsher economy, and a more unequal society—but in return, receive the emotional satisfaction of seeing the “right” people punished by an ever-expanding criminal-justice system, and the tacit assurance that if they happened to visit their own frustrations on someone who did not look like them, that same system would protect them.

Ultimately, the fueling of racial fear did extraordinary political and cultural work, fixing public attention on crime rather than wage theft, on disorder rather than deregulation, on punishment rather than the public good. The Goetz saga proved just how effectively narratives of crime, and outright misinformation, could be used to discredit government, justify inequality, and legitimize extrajudicial violence—all while claiming the mantle of common sense.

When he was finally apprehended, Goetz claimed that he had no regrets for what he did. He made no apologies for wanting “to kill those guys; I wanted to maim those guys; I wanted to make them suffer in every way I could”—not because his victims were armed (they were not), but because he felt besieged and abandoned, and thus justified in striking back. He railed at the assistant district attorney who took his statement: The subway system was “a disaster,” crime in the city was “a disaster,” and the government in charge of all of it was “a disgrace.”

Goetz’s journey through the justice system reinforced the idea that his worldview had merit. A grand jury was convened despite extraordinary public pressure to simply let him skate, and then it declined to indict Goetz on attempted-murder charges. However, word got out that Goetz had confessed to gunning down the teens, had told detectives that “robbery had nothing to do [with] it,” and, what is more, had admitted to shooting Cabey a second time. A second grand jury was convened that indicted Goetz for a range of serious charges, including attempted murder. In the trial that followed, however, a jury of Goetz’s peers decided that, despite the evidence mounted against him, he was guilty of only the most minor gun charges he faced.

Goetz served eight months in jail. The message sent to the American public was unmistakable: It is perfectly okay for at least some people to take the law into their own hands.

Goetz’s case helped build the early architecture of conservative tabloid media and inflammatory talk radio. This seeded the ecosystem of social media and Fox News coverage that, together, perfected the art of viral outrage and the mobilization of economic anxiety for political ends. And although mainstream news outlets did not openly revel in—or explicitly justify—the Goetz shootings, they did privilege coverage of urban crime and disorder over careful, sustained attention to the structural conditions and policy choices that made cities less safe and eroded the material security of ordinary people.

Equally significant was the fact that the economic and cultural transformation that this country had undergone since the 1980s was never a project confined to conservative politicians. Politicians across party lines contributed to the steady dismantling of America’s social safety net and the stoking of resentment and rage, even as they worked to channel these for their own partisan ends. Bill Clinton would deliver the most devastating blow to welfare; Trump would perfect the art of turning fear into fury.

We are still living today through the long Reagan Revolution: A teenager crosses state lines with an assault rifle and is hailed as a patriot for killing protesters; a mob storms the Capitol, convinced that violence is necessary to “save” democracy, and is pardoned; an ICE agent shoots and kills a mother and is said to have acted in self-defense, despite all evidence to the contrary; politicians denounce crime while simultaneously cutting the very social programs that ordinary people need to survive and that help sustain safe communities.

Gal Beckerman: Minnesota had its Birmingham moment

Trump did not invent these dynamics; he inherited them. He did not create the legitimacy of white grievance. And he did not usher in a new age of white racial violence or escalating income inequality; he has merely decided to unabashedly incite the former and defend the latter.

As the country moves toward the 2026 midterms, the temptation will be to treat our current racial, political, and economic crisis as a sharp break from the past; to search for singular villains; and to imagine that a return to normalcy is just one election away. But political cultures do not change course simply because their most flamboyant representatives enter or exit the stage.

The hard and necessary task now is to reckon with how past moments such as the Bernie Goetz shootings of 1984 helped remake the boundaries of how much racial violence, inequality, hatred, and indifference we as a society are willing to quietly endorse or even embrace. Only by confronting our history honestly can we begin to understand why appeals to fear remain potent, why calls for punishment eclipse demands for justice, and why the promise of democracy has been so unevenly realized.</div>
        </div>
        
        <div class="card" onclick="openModal('content-22')">
            <div class="source">The Atlantic</div>
            <div class="title">What I Saw in Mashhad</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-22" style="display:none;">
            <h2>What I Saw in Mashhad</h2>
            <p><strong>The Atlantic | 2026-01-26</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/international/2026/01/what-i-saw-mashhad-iran/685746/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">On January 9, anti-regime protests gripped Iran, and President Trump declared that the northeastern city of Mashhad had “fallen” to the opposition.

I happened to be in Mashhad from December 26 to January 14. What I witnessed in those weeks was far more complex—certainly more complex than the American president’s pronouncement, but also than the narratives originating either with state propaganda or opposition media.

Mashhad has never felt foreign to me. I come from Herat, in the west of Afghanistan, which is part of the same historic region of Persia. For me and millions of my compatriots, Mashhad is a cultural, linguistic, and emotional center that feels very much like home.

This trip was for the research institute I direct, the Afghan Institute for Strategic Studies. In preparation for our international conference, I was there to discuss developments in Taliban-controlled Afghanistan with representatives of the Iranian government, think tanks, and universities. Part of my mission was also to reach out to the Afghan diaspora.

Mashhad is Iran’s second-largest city and the spiritual capital of the Islamic Republic. It encompasses the burial place of Shiite Islam’s eighth imam, Imam Reza. It also houses the tomb of Ferdowsi, the epic poet who preserved the Persian language and imagination through the “Shahnameh,” and is the hometown of the current supreme leader. For these reasons and others, what happens in Mashhad reverberates across Iran, perhaps second only to events in Tehran itself.

The protests began in Mashhad in mid-December, and they appeared to be an expression of economic grievance. The government had enacted reforms that triggered a sudden spike in the prices of basic commodities and placed immense pressure on ordinary households. Official figures already suggested that nearly 30 percent of Iranians lived below the poverty line. The Iranian president, a heart surgeon by training, framed the painful new measures as a necessary “surgery” on an ailing economy—an attempt to excise corruption and restore the patient’s long-term health. Iranian media abounded with debates among economists and market analysts, weighing the costs and benefits of the reforms.

The news media reported merchants’ strikes in several cities—most notably in Tehran’s Grand Bazaar—and scattered political protests alongside them. The official channels emphasized a distinction between economic-driven, “legitimate” protests and “opportunistic,” externally organized, anti-regime riots. The president’s spokesperson referred to all protesters as her “grieving children,” insisting that they must be heard rather than suppressed.

In Mashhad during these early days, I encountered some small protests in relatively affluent areas, such as along Ahmad Abad Street and Vakil Abad Boulevard. Young people, their faces covered by masks, circulated through traffic and on sidewalks, chanting political slogans. They easily could have been mistaken for agitated sports fans, and their actions were small and diffuse enough that they could be quickly dispersed. On January 6, I saw a gathering of several dozen merchants in the commercial district of Bazaar Reza. These protests were modest in scale and short-lived, befitting a spontaneous expression of frustration rather than a national rebellion.

The situation escalated dramatically on the evening of  January 8. Former Crown Prince Reza Pahlavi issued a video calling for nationwide protests at 8 p.m. local time. This message coincided with provocative posts from U.S. officials, including one by former Secretary of State Mike Pompeo, who insinuated that Mossad agents were interspersed among the demonstrators. By about 6 p.m., internet access and all mobile and landline services had been shut down. At first, the shutdown was strangely liberating: I would find out what was happening by speaking to and watching real people, rather than through the filters of partisan news agencies and social media.

From my room I could hear occasional gunshots echoing across the city. Just after midnight, a friend and I drove to Ahmad Abad Street and then to Vakil Abad Boulevard. The scenes were startling: burning buses and cars, destroyed footbridges, and shattered traffic lights. My friend told me that protests had also raged in working-class areas along Tabarsi Boulevard, on the other side of the city, and in the suburbs of Sakhtaman and Sayedi. So we drove to Tabarsi Boulevard too, and saw even more severe damage—public buildings vandalized, streets littered with debris. The protesters, however, were gone. Riot police still patrolled these areas on motorbikes, and the city’s fire brigade and municipal workers were out cleaning streets and extinguishing fires. We didn’t see or hear any ambulances.

The next day was Friday, and Supreme Leader Ali Khamenei gave a stern speech in Tehran, warning that the regime would no longer tolerate “agitators.” The state media abruptly changed the tenor of its coverage: What it earlier described as a social and economic crisis was now termed an armed insurrection. Protesters were now terrorists, Islamic State affiliates, and American or Zionist agents.

Mashhad was tense but calm during the day. Everyone I spoke with anticipated renewed unrest at 8 p.m., again in response to Pahlavi’s call. At about 2 a.m. on Saturday, I went back to Ahmad Abad, Vakil Abad, and Tabarsi. The streets were completely deserted—even the riot police and municipal workers were gone—and the scale of the destruction was even more shocking than it had been the previous night.

That day, Trump claimed that more than a million people were demonstrating in Mashhad and that the city had fallen under protesters’ control. His second claim was partially accurate, insofar as riot police and plainclothes security forces, very much in evidence the night before, did appear to have temporarily withdrawn. But the first claim, about the number of the protesters, seemed to me highly implausible. I visited four of what I’m told were about 10 protest locations around the city (the remaining ones were located in nearby neighborhoods). These were confined areas, and the protests within them lasted no more than three to five hours. To imagine tens of thousands of protesters in these urban pockets is already a stretch, and far shy of a million. This does not negate the existence of hundreds of thousands of angry and disillusioned Mashhadis, but anger does not automatically translate into street mobilization.

On Saturday, January 10, the city was quiet. Security forces were far more visible than during past days of protests—and more heavily armed. The riot police I’d seen on Thursday night had shotguns; now I saw some carrying AK-47s and even heavy machine guns. From Thursday onward, long queues formed outside bakeries, pharmacies, and grocery stores as people prepared for the worst. Pahlavi shifted his call to action from 8 p.m. to 6 p.m., and starting in the early afternoon, entire neighborhoods emptied, resembling the eerie calm of COVID lockdowns. That night, the protests were reportedly smaller and less violent.

The state organized pro-government demonstrations throughout the country for Monday, January 12. In Mashhad, these took place near the Imam Reza Shrine—the city’s focal monument and a center of pilgrimage and religious observance—during daylight hours. I happened to be visiting a museum within the shrine complex when thousands of people surged onto Imam Reza Boulevard. Pilgrims, tourists, and demonstrators were swept up together in the crowd. The event included a public burial for 20 security personnel reportedly killed during the unrest. Unlike the anti-government protesters, who had reason to fear recognition and reprisal, those carrying pro-government placards showed their faces. Still, uncertainty, bewilderment, and fear were palpable.

That day marked the beginning of a new phase. Life in Mashhad gradually returned to normal, with the so-called national internet (not connected to the outside world) and phone services partially restored. The opposition media and some of my local contacts began reporting mass casualties and mass arrests. I asked my Mashhadi acquaintances if they personally knew people who had been killed or injured: Two-thirds said they did. The city’s Rezvan cemetery and morgue were set aside for the victims, and three people I knew who went there told me that they saw hundreds of bodies awaiting identification. A few days later, state media quoted a senior security official who acknowledged that about 400 people had been killed in Mashhad and nearby towns, but asserted that 80 percent of them had been “martyred” by anti-regime elements. So many people had been arrested that a major police station was allocated for families seeking missing relatives.

Read: The online world where Iranians were free

Because of the limitations that remained on outside communication and the internet, most of us in Mashhad were still getting our information from state media, opposition satellite channels, and word of mouth. In the days following January 12, state media assured viewers that order had been restored to Iranian cities after an outburst of “anti-Islamic” unrest. The opposition outlets—most notably Iran International, a satellite channel based in London—reported that Iran was in the throes of a full-scale revolution, led by Reza Pahlavi, and that it was on the brink of victory. Both narratives seemed like exercises in cognitive dissonance for those of us on the ground.

Speculation about Iran’s future has since gone global. Four broad scenarios seem to hold sway. The first is stagnation under the continued rule of a supreme leader who is disinclined to bargain with protesters or foreign powers. The second is transformational reform from within, akin to China under Deng Xiaoping. The third is the eventual victory of a grassroots, nonviolent movement, as in East Germany, Poland, or South Africa. And the fourth is externally supported, violent regime change.

Each scenario has plausible foundations. The Islamic Republic has demonstrated an extraordinary capacity to project and absorb pain. Like many revolutionary regimes, it is more tolerant of violence—both inflicted and endured—than its opponents assume. And so this cycle of protest and repression, too, could pass.

But it is also true that for more than a century, popular movements in Iran have repeatedly sought more accountable governance. These groundswells have had some success. The Women, Life, Freedom movement of 2022 achieved a major cultural victory by effectively challenging the state’s enforcement of women’s dress codes. In Mashhad in January, I saw many young women in public without hijab, and they did not appear to face reprisals from either the government or the conservative segments of society. Khamenei is likely in his final years, and his succession could present a moment for transformative change from within. Some voices within the system have long called for this. Fatemeh Sepehri, a political prisoner from Mashhad, has openly advocated for removing the supreme leader and holding free elections to draft a new constitution.

The final scenario, violent regime change, has a precedent in the 1979 revolution. But unlike then, some of those calling for a revolution today are also pleading for American or Israeli intervention to help achieve it. Supporters of Pahlavi were particularly vocal in Mashhad this month, as attested by the prevalence of pro-monarchy graffiti on city walls, and the regime’s propaganda devoted particular attention to discrediting the former crown prince. During the state-orchestrated demonstration, Khamenei’s representative in Mashhad mocked Pahlavi by recalling how the shah, despite decades as “America’s puppet,” had been denied entry to the United States in the last days of his life.

Iranians can and will chart their country’s destiny. For the moment, however, the country is mourning its thousands of dead—their precise numbers, identities, and circumstances still unclear. Justice and accountability for these victims are not a peripheral issue; they are the foundation of any scenario for the future.

The scene at the Mashhad airport the day I left, January 14, was profoundly emotional. Only a small number of passengers had been fortunate enough to secure tickets for the day’s last flight to Istanbul. The departure lounge felt less like a transit space than a place of mourning. Passengers and their accompanying relatives wept openly. Not only grief but also anxiety infused the room, amid media reports of imminent U.S. military strikes that could usher in an uncertain and violent future.

As my plane ascended, I looked out at the light beams emanating from the Goharshad Mosque at the Imam Reza Shrine below. The historic region from which both Mashhad and Herat take their identity is Khorasan—literally, “where the sun rises.” I found this consoling in that moment, reminded of the dawn and its fragile but persistent promise.</div>
        </div>
        
        <div class="card" onclick="openModal('content-23')">
            <div class="source">The Atlantic</div>
            <div class="title">Why Is Trump Cozying Up to China?</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-23" style="display:none;">
            <h2>Why Is Trump Cozying Up to China?</h2>
            <p><strong>The Atlantic | 2026-01-26</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/international/2026/01/trump-china-xi-jinping/685708/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">As President Trump has charged into a conflict with American allies over Greenland in recent weeks, he has also been pursuing an unlikely new friend: Communist China. Even for a politician known for erratic policy shifts, this swap—of longtime democratic partners that have sacrificed much for America’s benefit in exchange for an authoritarian regime intent on undermining it—is bizarre. It also highlights the risks that Trump’s personalized form of diplomacy presents to American national security and the balance of global power.

Although a hard line on China was a centerpiece of Trump’s first term, he has gone soft in his second. The president has removed nearly all of the tariffs that he imposed on Chinese imports last year, and he has loosened controls on the sale of advanced American semiconductors to China—over the objections of national-security experts—on the condition that Nvidia coughs up a cut of its sales to the U.S. government. Trump also hailed his October 2025 summit with China’s leader, Xi Jinping, as a meeting of the “G2,” or “Group of 2,” a flattering nod to the idea that the United States and China are the two most powerful countries in the world.

Trump has also lately seemed to take Beijing’s side regarding Taiwan, which China continues to claim as its own. The Trump administration has scaled down its interactions with Taiwan’s government, and in November, the president reportedly asked Japanese Prime Minister Sanae Takaichi to not escalate a dispute with Beijing over comments she had made about China’s threat to Taiwan. That conversation took place shortly after Trump had spoken with Xi, who reinforced Beijing’s position on Taiwan.

Read: ‘Some foreign influence will be hard to reverse’

Even the most well-connected China experts in Washington are left guessing about what Trump hopes to achieve by placating Xi. One possibility is that Trump’s pivot is a strategic feint to secure a truce in a trade war that has revealed significant American vulnerabilities. Given China’s dominance of rare earth materials, which are vital to advanced manufacturing, Xi’s restrictions on exports in response to Trump’s tariffs had harmed U.S. industries. In negotiations with Washington, Xi pledged to restart supplies and temporarily suspend some of China’s export controls on these metals, but he could easily resume these measures if tensions escalate again.

Trump may be appeasing Xi to buy some time as he seeks alternative sources of rare earths—in Greenland and elsewhere. But considering that securing these commodities could take years of U.S. investment, Trump may be pacifying Xi for longer than he expected.

Trump’s approach to China may have changed with his political calculations. His earlier attacks shored up his appeal with blue-collar voters who had been hurt by international trade and the export of manufacturing jobs overseas. Trump entered office in 2017 vowing to right the injustices caused by liberal globalists. Now he seems to think that he has more to gain from cozying up to China. At his meeting with Xi in October, Trump secured a crackdown on China’s exports of the chemicals used to make illicit fentanyl, and a promise that China would buy significant quantities of soybean imports from American farmers—a key Republican constituency.

Trump’s softer touch seems to have won Beijing’s consent for an arrangement to keep TikTok operating in the U.S.—allowing him to fulfill a political promise. The deal, finalized this month with ByteDance, the Chinese internet company that owns TikTok, hands control of the U.S. operation to a consortium of investors that includes Larry Ellison of Oracle, a Trump ally. Xi further rewarded Trump’s shift in tone by inviting him to visit Beijing in April, appealing to the U.S. president’s penchant for high-profile diplomatic summits.

Trump has also always had a thing for autocrats. He has praised Xi as “highly respected”—a description he has also used for Hungarian Prime Minister Viktor Orbán, Russian President Vladimir Putin, and others. Trump’s diplomacy is often guided by his preference for strongmen over more trustworthy, democratically elected allies. And like any schoolyard bully, Trump prefers to pick on countries that can’t fight back. Yet Xi’s potent response to Trump’s trade war has shown that the Chinese leader can fight back—and will.

Despite his fiery rhetoric in his first term, Trump spent a great deal of time negotiating a trade pact with Beijing, which both sides signed in 2020. This time around, Trump seems to have gone rogue. A rare issue on which Republicans and Democrats agree is that China presents a real threat to the United States—economically, militarily, and otherwise. But Trump has been reluctant to press China on issues of urgent national interest. Although he imposed extra tariffs on India last year to curb the country’s purchase of Russian oil, which helps fund Putin’s war in Ukraine, he has largely given a pass to China, the biggest consumer of Russian crude. Earlier this month, the president green-lighted a bill imposing tariffs on countries that buy Russian oil, but the White House has insisted that the legislation grants Trump some latitude in how he applies these sanctions.

Anyone hoping to ascribe a grand strategy to these moves must reckon with the inconsistency of Trump’s approach to China. Following its capture of Venezuelan President Nicolás Maduro, his administration has reportedly pressured Venezuela to expel advisers from China. This, together with Trump’s threats to Greenland, seem to be part of a larger effort to push Beijing out of the Western Hemisphere. Such unpredictability drives home just how personal—and erratic—foreign policy has become under Trump. In a recent analysis of the administration’s new National Security Strategy, a group of Brookings Institution scholars noted just “how much U.S. foreign policy now hinges on one mercurial leader.”

From the March 2026 issue: America vs. the world

With this, China and the U.S. have something in common. In Beijing, Xi has centralized policy making in his own hands—and to a greater extent than Trump can ever hope for, given China’s authoritarian political system. Whereas Trump is a flip-flopper, Xi has proved relentlessly committed to a fixed agenda. Nearly everything he does is meant to expand China’s global power and advance its technological and industrial dominance. Although Trump’s desire for Greenland is ostensibly about reducing China’s influence in the Arctic, the president’s conflict with NATO allies must delight Xi because it precludes international coordination to contain China.

Some in China see Trump’s softening as a great opportunity for Xi to press for more concessions. Da Wei, the director of the Center for International Security and Strategy at Tsinghua University, in Beijing, recently suggested in Foreign Affairs that the U.S.-China relationship was at an “inflection point,” making this an opportune moment to further reduce tensions and move “toward a more normal relationship.” To help things along, he recommended that the U.S. curb its “politically provocative” naval missions near China. Although he didn’t say so explicitly, he likely meant operations in the South China Sea, which is officially international waters, but Beijing claims it as its own. Da also counseled Trump to declare U.S. opposition to Taiwanese independence—which would mark a radical change in U.S. policy. Both steps, if Trump were to take them, would be cause for alarm among American allies. In return, Da wrote, China should scale back military exercises around Taiwan and “increase cross-strait exchanges”—neither of which are really concessions to Washington.

China has a strong incentive to push for these compromises now, given how Trump’s fickle nature could suddenly shut the window of opportunity. Beijing is also well aware that American democracy is inherently prone to flip-flops and that the hard-line Washington consensus on China is likely to return with the next election. At this point, only one thing is certain: In what has become a contest between two men, victory will go to the leader who operates strategically and with discipline, not erratically and on impulse.</div>
        </div>
        
        <div class="card" onclick="openModal('content-24')">
            <div class="source">Slashdot</div>
            <div class="title">AI is Hitting UK Harder Than Other Big Economies, Study Finds</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-24" style="display:none;">
            <h2>AI is Hitting UK Harder Than Other Big Economies, Study Finds</h2>
            <p><strong>Slashdot | 2026-01-26</strong></p>
            <a class="original-link" href="https://news.slashdot.org/story/26/01/26/1428221/ai-is-hitting-uk-harder-than-other-big-economies-study-finds?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Want to read Slashdot from your mobile device? Point it at m.slashdot.org and keep reading!

Brexit didn&#39;t go far enough.Why, are you in Britain? If so, I agree, as it&#39;s failed to prevent me from seeing your comments.

Why, are you in Britain? If so, I agree, as it&#39;s failed to prevent me from seeing your comments.

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

The fancy is indeed no other than a mode of memory emancipated from the order
of space and time.  -- Samuel Taylor Coleridge</div>
        </div>
        
        <div class="card" onclick="openModal('content-25')">
            <div class="source">Slashdot</div>
            <div class="title">Angry Gamers Are Forcing Studios To Scrap or Rethink New Releases</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-25" style="display:none;">
            <h2>Angry Gamers Are Forcing Studios To Scrap or Rethink New Releases</h2>
            <p><strong>Slashdot | 2026-01-26</strong></p>
            <a class="original-link" href="https://games.slashdot.org/story/26/01/26/1359241/angry-gamers-are-forcing-studios-to-scrap-or-rethink-new-releases?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">I wouldn&#39;t mind AI in a lot of games. There are a lot of games where the stock assets, the quick and dirty pixel art, or even the 5-minutes-in-a-DAW music could benefit from AI replacement. Anything that isn&#39;t the selling point of the game anyway.

There is also a huge potential for AI IN games. I like narrative games, I also like open world games, why can&#39;t I have both at the same time?

But there&#39;s also the thing about quality signals. The best games in the world aren&#39;t worth anything if I&#39;ll never hear about

There is also a huge potential for AI IN games. I like narrative games, I also like open world games, why can&#39;t I have both at the same time?No thanks.  I&#39;ve seen AI writing.  I go out of my way to avoid that stuff.  It&#39;s not even as good as derivative fan fiction on you&#39;d find on a Star Wars forum.  I&#39;d rather have less story content that content authored by an AI, especially one pulling stuff out of thin air on the fly with no human guiding the prompting.  If you want to use an AI-generated algorithm to handle crown dynamics or something, then sure, but keep it out of anything with narrative or artistic significance.

There is also a huge potential for AI IN games. I like narrative games, I also like open world games, why can&#39;t I have both at the same time?

No thanks.  I&#39;ve seen AI writing.  I go out of my way to avoid that stuff.  It&#39;s not even as good as derivative fan fiction on you&#39;d find on a Star Wars forum.  I&#39;d rather have less story content that content authored by an AI, especially one pulling stuff out of thin air on the fly with no human guiding the prompting.  If you want to use an AI-generated algorithm to handle crown dynamics or something, then sure, but keep it out of anything with narrative or artistic significance.

> gamers suck, the worst and most annoying and most entitled group of fans who never know what they want and demand everything.

While I&#39;m no fan of the people whining about AI-generated content in games, game companies hating their customers is exactly the reason why games are flopping.

&quot;You will buy our slop and thank us for it!&quot; is not a great marketing slogan.

I don&#39;t remember the last time I bought an &quot;AAA&quot; game. I buy indie games from developers who provide what their customers want and don&#39;t try to fi

I would say it&#39;s the straw that broke the camel&#39;s back. It&#39;s also likely the one everyone is focusing on the most because it has the largest cross-demographic appeal, even among people who previously had mocked and scorned gamers when they spoke out about corporate abuses and the degradation of property rights and basic truth in advertising.

It&#39;s not like PC gamers can afford to upgrade their hardware to play the new titles anyway. Thanks to Rampopolypse, memory and storage upgrades cost over twice as much as they did a year ago.

Important we keep malware out of games. Raise a fuss, extinguish any hype around games with the Denuvo malware.

Nothing&#39;s going to change there until there&#39;s legislation about it, or until microsoft decides to stop allowing kernel level malware.

I feel a bit bad for these developers just trying new tools but also read the room guys, the AI companies making those tools you want to use and the people on social media and working at the companies being the absolute worst representatives of the tech.  Feels like for the last 3 years I&#39;ve just seen them reveling in the fact that these tools will put &#39;wokey-artist-types&#39; out of business, put developers and coders out of jobs, that they can&#39;t wait to inundate everyone with trash art and more advertising.

Like the AI companies have engaged in possibly some of the worst PR in my lifetime for something with actual use cases.  As soon as they saw how many of the crtpyo-booster folks had so easily slipped into becoming AI boosters should have been a warning and they should have distanced themselves instead of taking the easy money.

Personally I find this story a bit heartwarming as we see a sustained public backlash to what is in my opinion just awful corporate messaging and behavior.  Unfortunate that a place like Larian is swept up in it but try and read the room guys.

How is this new or surprising? Consumers organizing into consumer protection groups is almost as old as time. And those groups have always had the goal of getting the filthy fat cats to listen.Now we are protecting the oh so poor good guy billionaires suddenly?

And since the studios tried their hardest to make even the most minuscule and ridiculous decisions into massive political marketing campaigns, now they will have to face the tribal political backlash as well.

I see nothing wrong in this - it is supposed to primarily be entertainment and a good entertainment product, so vote with your wallet and let them face all the backlash for their terrible products.

Sandfall with Exp33 or even embark with ARCRaiders are showing what good, successful and awesome modern gaming built by actually talented teams looks like while so called triple A is in freefall.A much deserved win for the consumers, and the actually talented teams.

Let AI create graphics, then check then and fix as needed. AI doesn&#39;t create - it wholesale steals and then mass generates derivative works.  It&#39;s a fancy probabilistic token generator that gets its p-values by mass ingesting artists&#39; works without permission.  The fact that those tokens can be either pixels or words doesn&#39;t matter, the AI doesn&#39;t even understand the difference.

Let AI create graphics, then check then and fix as needed.

AI doesn&#39;t create - it wholesale steals and then mass generates derivative works.  It&#39;s a fancy probabilistic token generator that gets its p-values by mass ingesting artists&#39; works without permission.  The fact that those tokens can be either pixels or words doesn&#39;t matter, the AI doesn&#39;t even understand the difference.

You want meaningful human connection. To this,AI is cheap, uncanny sugar. You may argue that it has its useless (and it does) or that it can be used cleverly to unlock new play experience (and it can), but overall AI will simply poison everything from your video games to your customer support experiences to your medical diagnoses.

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

The fancy is indeed no other than a mode of memory emancipated from the order
of space and time.  -- Samuel Taylor Coleridge</div>
        </div>
        
        <div class="card" onclick="openModal('content-26')">
            <div class="source">Slashdot</div>
            <div class="title">Richard Stallman Was Asked: Is Software Piracy Wrong?</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-26" style="display:none;">
            <h2>Richard Stallman Was Asked: Is Software Piracy Wrong?</h2>
            <p><strong>Slashdot | 2026-01-26</strong></p>
            <a class="original-link" href="https://news.slashdot.org/story/26/01/25/1952231/richard-stallman-was-asked-is-software-piracy-wrong?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Catch up on stories from the past week (and beyond) at the Slashdot story archive

He advocates for ignoring copyright law, which is fine, but on the other hand, copyright law is the basis of how the GPL actually has meaning.

If he advocated for everything always being public domain, that&#39;s a consistent stance.  However, it&#39;s a bit weird to say that people shouldn&#39;t respect copyright, unless it&#39;s respecting the copyright as it pertains to GPL software.

He advocates for ignoring copyright law, Based on the summary he didn&#39;t advocate ignoring copyright law. In the link in the summary, he advocated changing copyright law. I didn&#39;t watch the video in the summary, but it&#39;s summarized in the summary. 
Where are you quoting him that he advocated ignoring copyright law?

Based on the summary he didn&#39;t advocate ignoring copyright law. In the link in the summary, he advocated changing copyright law. I didn&#39;t watch the video in the summary, but it&#39;s summarized in the summary. 
Where are you quoting him that he advocated ignoring copyright law?

Stallman said &quot;I don&#39;t hesitate to share copies of anything,&quot; but added that &quot;I don&#39;t have copies of non-free software, because I&#39;m disgusted by it.&quot;

&quot;The only way I can see a movie is if I get a file — you know, like an MP4 file or MKV file. And I would get that, I suppose, by copying from somebody else.&quot;

So he doesn&#39;t like pirating closed source software, not because of the copyright but because no source is provided and in that scenario he demands source code.

He advocates for ignoring copyright law, which is fine, but on the other hand, copyright law is the basis of how the GPL actually has meaning.Would we need the GPL if copyright law didn&#39;t exist?

He advocates for ignoring copyright law, which is fine, but on the other hand, copyright law is the basis of how the GPL actually has meaning.

Would we need the GPL if copyright law didn&#39;t exist?

Interesting question. GPL forces people to share their modifications, and disallows tivoization (using technical means to prevent running modified software). It&#39;s a contract, but I&#39;m not sure you could force people to enter into it without copyright.

Arguably yes; Without it you&#39;d see everything locked up behind various DRM, signed code only, and other schemes.

You&#39;d have the source but it would be nearly useless because no manufacturer would make any contemporary hardware that can run code that has not been blessed. Good luck getting TSMC to fab your FOSS hardware on a useful process.

For non-copyright scenario, that would be public domain, and we have that option already. Anyone can take any code they find and do whatever they want.  Make a totally closed source solution that did come from linux, but refuse to acknowledge Linux had anything to do with it? Without copyright law, that&#39;s fine.

GPL wants to protect the original creative intent, to make sure that someone doesn&#39;t just close up your code and make something out of it without sharing your principles or throwing away credit for it

He advocates sharing, and the GPL allows sharing.

He says to ignore laws that block sharing. That means ignoring some parts of copyright law.  Some other parts of copyright law are fine.  There&#39;s no contradiction.

(And if someone has a follow up question about sharing everything, no, he doesn&#39;t advocate for sharing everything.  Some stuff is personal, for example.  He&#39;s in favour of sharing generally useful technical information, such as the source code of software that has been given to you.)

Nah, it&#39;s not the realisation about the cost at all. I couldn&#39;t give a flying fuck about the cost.

It&#39;s about convenience. If $15 a month saves me hours searching for and downloading pirated films, it&#39;s money well spent.

Piracy is more convenient. I use the TV calendar site to track shows I&#39;m interested in, and Greasemonkey to inject some Javascript that adds links directly to The Pirate Bay searches for each episode. After a few clicks I have a DRM free file that just works, and I can use Kodi rather than some crappy app that is little more than a wrapper around a broken website.

I wouldn&#39;t mind buying Bluray discs, except that they keep trying to stop me ripping them into a more convenient format. So I just buy other merch

A few problems with that:1. You&#39;ve got to spend extra time setting it all up.2. Then your setup may break at any point when they introduce more anti-piracy measures.3. You can&#39;t just sit down after a hard day, press one button and make it work immediately.4. Limited content.5. Quality issues.6. Unnecessary faff.7. One day you may end up in legal trouble.8. Probably many more other problems which I can&#39;t even be bothered thinking about.

At some point you wake up to a realisation that sure - you can make it wo

To each his own. I want to have a movie and music collection, whether on hard drives or on physical media. If I can buy it, I do (maybe not all the time though), but I am not going to continuously pay for the same thing.

It&#39;s been working for many, many years now. I find it low maintenance.

As for limited content, there is more than is on streaming. Quality is the same or better.

Friends tell me that there is the occasional setup and configuration overhead. But once done, itâ(TM)s as easy as one or two clicks to be watching. The biggest problem exists on any platform-what is actually worth watching?

The problem with that logic is that any given $15 a month streaming service in 2026 only has about 1/4 of the content that you want to watch.

In order to be able to watch all of the shows that I like to watch, I&#39;d need:

Apple TV+Disney+ and HuluNetflixAmazon PrimeParamount+Peacockand HBO Max (or whatever it called now)

So, that&#39;s 7 different premium streaming services, all charging around $15 a month each if you want to watch them without ads.

Suddenly, piracy looks like the easier option. One site, ALL of the

When I was young or a young adult, both the young and the old were copying music and videos (reel-to-reel or cassette tapes, VHS cassettes) for personal use among friends and the wider family all day long. Actually, in many jurisdictions, like the one where I grew up right in the middle of capitalist Europe, it was perfectly legal, too. And what do you know – movies and music records and concerts kept coming in nonetheless. Because, by tendency, many of those who were the biggest sharers were also the

When I was young or a young adult, both the young and the old were copying music and videos (reel-to-reel or cassette tapes, VHS cassettes) for personal use among friends and the wider family all day long. Actually, in many jurisdictions, like the one where I grew up right in the middle of capitalist Europe, it was perfectly legal, too. And what do you know – movies and music records and concerts kept coming in nonetheless. Because, by tendency, many of those who were the biggest sharers were also the biggest buyers. There also were sensible flat surcharges on tapes and cassettes and recording equipment which were distributed among artists.Anyway, I also seriously question today&#39;s movie industry. Can any movie be worth hundreds of millions of dollars? Are hundreds of millions of dollars, the least of which, by the way, find their way to the ground personnel in such productions, well spent in making a movie, of all things? I, for one, don&#39;t think so.No it wasn&#39;t legal at any time. It was just not enforced heavily as people were still buying records and it required physical interaction to make EACH copy. However when digital copying became possible, record industry became really scared. ;)

Regarding costs, yes, they are overblown. In part due to inflation too. But making those lifelike visual effects takes time and effort and that needs money to pay for expertise and resources. Plus actor payments also have been inflated to the high orbit...

When I was young or a young adult, both the young and the old were copying music and videos (reel-to-reel or cassette tapes, VHS cassettes) for personal use among friends and the wider family all day long. Actually, in many jurisdictions, like the one where I grew up right in the middle of capitalist Europe, it was perfectly legal, too. And what do you know – movies and music records and concerts kept coming in nonetheless. Because, by tendency, many of those who were the biggest sharers were also the biggest buyers. There also were sensible flat surcharges on tapes and cassettes and recording equipment which were distributed among artists.

Anyway, I also seriously question today&#39;s movie industry. Can any movie be worth hundreds of millions of dollars? Are hundreds of millions of dollars, the least of which, by the way, find their way to the ground personnel in such productions, well spent in making a movie, of all things? I, for one, don&#39;t think so.

No it wasn&#39;t legal at any time. It was just not enforced heavily as people were still buying records and it required physical interaction to make EACH copy. However when digital copying became possible, record industry became really scared. ;)

Regarding costs, yes, they are overblown. In part due to inflation too. But making those lifelike visual effects takes time and effort and that needs money to pay for expertise and resources. Plus actor payments also have been inflated to the high orbit...

It definitely not only used to be legal in parts of Western Europe, it even still is. According to Section 15 of the German Copyright Act (UrhG), for example, in general, only the author of a work has the right to reproduce their work, but private copies are literally excepted according to Section 53 UrhG. And private use specifically includes distributing private copies to friends or family members. This is even still valid for digital copies, but has been restricted insofar as circumventing digital copy p

https://en.wikipedia.org/wiki/... [wikipedia.org]

1) Doing something you know is wrong2) Doing something wrong but you believe its right

We&#39;ve all done 1 wrt copying media but most of us also do pay for some stuff too because we know musicians etc have to eat.

Stallman OTOH fits in category 2. He doesn&#39;t seem to believe anyone should financially benefit from their intellectual property unless others voluntarily decide to donate to it. I&#39;m afraid the world and human nature simply doesn&#39;t work like that.

What you describe makes perfect sense if costs represented effort and everybody got paid what they deserve. That&#39;s not the case for a lot of things, especially movies, so I don&#39;t think your example is great.

but when piracy works better then shit DRM?

Most of us are smart enough to see that&#39;s going to result in zero movies being madeThis. 100%. It&#39;s a bit like people who don&#39;t get vaccinated (without a very good reason). A few of them and it&#39;s no problem, we (and they) still benefit from herd immunity. But if everyone acted as selfishly, then we&#39;d be back in Victorian times with a third of children dying before they reach five years old. To say that he&#39;ll only watch a film if he gets it for free by copying it from someone else is such a dick move. It&#39;s not like saying &quot;I wouldn&#39;t have bought it anyway so no one is losing out&quot;, because

Most of us are smart enough to see that&#39;s going to result in zero movies being made

This. 100%. It&#39;s a bit like people who don&#39;t get vaccinated (without a very good reason). A few of them and it&#39;s no problem, we (and they) still benefit from herd immunity. But if everyone acted as selfishly, then we&#39;d be back in Victorian times with a third of children dying before they reach five years old. To say that he&#39;ll only watch a film if he gets it for free by copying it from someone else is such a dick move. It&#39;s not like saying &quot;I wouldn&#39;t have bought it anyway so no one is losing out&quot;, because

The problem inst copyright it is the cartel pricing and nearly forever terms around a lot of classes of works.

Why should I still have to pay 3.99 more if I want it in HD for a movie made in 1969? None of that long tail revenue was figured into the cost / revenue analysis when the picture was made. Many, maybe most of the people involved directly are 6 feet under.

Heck even to think we should refund the people who watched it 40 years ago, many of them are not even alive. They got what they paid for / agreed t

My favorite movie was made in 1968 - 2001, space odyssey. The latest 4K transfer made a few years ago by Christopher Nolan was a massive improvement over the previous transfers. It cost money. Many of the original analog films were significantly degraded. I saw one in 70mm in San Francisco not long ago, and it was very hard to watch due to all the damage. I&#39;m glad that I was able to buy the 4k UHD blu ray discount. I also have DVD and HD BD disc versions, from their respective eras. Digital tech wasn&#39;t ther

I too used to believe that pirating content was wrong... back when I could order almost any movie or TV show from Netflix and have the DVD of it delivered to me the next day.

Now that all of the good TV shows and movies are buried behind 7 different premium streaming services that all cost around $15 a month to subscribe to if you want to watch them without ads... well... let&#39;s just say that my feelings about pirating content and moderated somewhat.

Thereâ(TM)s a few problems with your proposition.

First is, a lionâ(TM)s share of that cost goes to layers of rent seeking, entrenched âoeproduction and distributionâ outfits that add little value.

Second, for the zillions of creative and technical credits, itâ(TM)s not like those folks entire income depends on their contribution to that particular production.

I would agree that the people who do actual work on a production deserve adequate compensation. But the current model is broken

72 year old male arrested on suspicion of piracy and wire fraud after a warrant was executed at his home. (they always throw in wire fraud as a bonus, regardless of the actual crime).

We all have strong opinions about rms. Some of his ideas are wacky. Some of his ideas are brilliant. I think this is one of his more insightful takes.

Copyright law has a distinction between commercial for-profit infringement, which is regarded as a criminal offense [cornell.edu] vs. noncommercial infringement which is regarded as a civil offense.

I think this distinction is useful, but it&#39;s one degree too severe. For-profit infringement should be the civil offense, and noncommercial infringement (consumer copying) should be fully legal [freepubliclibrary.org], just as rms is saying.

Why? Because copyright wasn&#39;t created to allow authors to impose a toll on every individual consumption of every individual work, otherwise libraries wouldn&#39;t have been widespread alongside early copyright laws.

Instead, copyright law was created to make sure the author of a work was the only one who had any right to make any profit at all off of their work.

People often forget this, but the origin of copyright law is important to remember. The Statute of Anne [american.edu] was passed to address the growing problem of people making and selling copies of books they were not the author of, an activity which became much more common once the printing press was invented. The law was passed with the intention of protecting London&#39;s publishing business from this unfair competition and in the centuries that followed, other countries passed similar laws. Notably absent from this law: a ban on libraries or noncommercial sharing of books.

That&#39;s why file sharing should be legal, and business models should adapt to the decades-old reality that file sharing is widespread and inevitable. Some businesses have adapted rather well. While it&#39;s unfortunate that DRM is widespread, things like streaming services aren&#39;t that bad an adaptation. They just need a bit more adapting to truly embrace the 21st century.

Also, as a fun aside, one thing that baffles me is if for-profit copyright infringement is a criminal offense, as described above, then why aren&#39;t the major AI companies who commit mass copyright infringement with a profit motive in the training and development of their models being held criminally liable for their actions? The courts are currently twisting themselves into pretzels to try to invent some kind of fair use exception for them out of whole cloth because it feels wrong to charge them all with criminal behavior. But the truth is the law is not being interpreted in good faith, in part because the law itself is horrifyingly outdated and needs to be updated and modernized.

But the modernization we need is simple: Reduce for-profit infringement to a civil offense and reduce noncommercial infringement to being legal. We don&#39;t need to tinker with copyright terms, we don&#39;t need a vast expansion of the public domain, none of that. Just make file sharing legal.

if for-profit copyright infringement is a criminal offense, as described above, then why aren&#39;t the major AI companies who commit mass copyright infringement with a profit motive in the training and development of their models being held criminally liable for their actions?The obvious answer is campaign contributions.Another answer is that the nature of their activity is novel. As such it&#39;s arguable that the creation of the training corpus is fair use. The models themselves don&#39;t include the works in question and they don&#39;t reproduce them verbatim. You can train a model at home which will do it, but only by absurd overtraining, and by including basically nothing else. None of them are redistributing models like that. A derivative work has to include sufficiently recognizable

if for-profit copyright infringement is a criminal offense, as described above, then why aren&#39;t the major AI companies who commit mass copyright infringement with a profit motive in the training and development of their models being held criminally liable for their actions?

The obvious answer is campaign contributions.

Another answer is that the nature of their activity is novel. As such it&#39;s arguable that the creation of the training corpus is fair use. The models themselves don&#39;t include the works in question and they don&#39;t reproduce them verbatim. You can train a model at home which will do it, but only by absurd overtraining, and by including basically nothing else. None of them are redistributing models like that. A derivative work has to include sufficiently recognizable

They had to use a huge piece of the article as the prompt, and their own examples show that it still generated text that wasn&#39;t in the articles.

My understanding was that they were trying to prove it was an original or derivative work because of its ability to reproduce the story. We already knew they were training on their articles.

It certainly wouldn&#39;t be intelligent for them to admit to anything, due to how our courts work.

People have always overlooked the fact Stallman is a nut because he also advocated for linux and did a pretty good job of it in the early days. But then I think he did a lot to sideline himself by appearing too extreme. When someone can see themselves in you, you can lead by example. But, people stopped seeing anything they had in common with Stallman.

The fact he always tries to coin juvenile little catch phrases doesn&#39;t help his case any: &quot;internet of stings&quot;, &quot;forbidden sharing&quot;, etc. Of course, the whole sexual misconduct thing stuck a fork in him, but he was already done.

Richard Stallman is clearly a man of at least average intelligence and hence is aware that copying and sharing are entirely different things. &quot;Sharing&quot;, means that there is only one copy of the resource and I am simply giving you a share of my resource, whether that&#39;s  lending you something or giving you half my pie.

Copying means there are now two of them and you and I have one each.

It&#39;s called COPYright not SHAREright for a reason, which is also why the whole libraries comparison is irrelevant.

&quot;Sharing&quot;, means that there is only one copy of the resource

Bollocks. You can share knowledge and ideas.

I do not understand how or why this discussion is coming up now, this is not the 90s anymore and we have seen what the riaa and mpaa cronies have done for 30+ years, so it is a dead discussion.

But nowadays, I am honestly baffled what anyone would copy or share anymore, the overwhelming majority of shows and movies have gotten so terrible I would not even waste the download on them. And the actually good shows and movies, I had eventually bought multiple copies and different formats of over the years anyway,

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

The fancy is indeed no other than a mode of memory emancipated from the order
of space and time.  -- Samuel Taylor Coleridge</div>
        </div>
        
        <div class="card" onclick="openModal('content-27')">
            <div class="source">Slashdot</div>
            <div class="title">Is Google Prioritizing YouTube and X Over News Publishers on Discover?</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-27" style="display:none;">
            <h2>Is Google Prioritizing YouTube and X Over News Publishers on Discover?</h2>
            <p><strong>Slashdot | 2026-01-26</strong></p>
            <a class="original-link" href="https://news.slashdot.org/story/26/01/26/008257/is-google-prioritizing-youtube-and-x-over-news-publishers-on-discover?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Please create an account to participate in the Slashdot moderation system

It used to be a place to quickly get content on things from home improvement, to news, documentaries, music, etc.  Now it&#39;s inundated with inane AI-generated clickbait.  When you spend more time filtering the junk than consuming the content you were searching for, it&#39;s a loss.

It&#39;s the recommendation algorithm. If you keep watching AI clickbait, it will feed you more AI clickbait.

My recommended is still my interests with only AI content being AI I actually consume. Music videos of a specific genre. Every once in a while my feed contains &quot;try this new thing&quot; single video, and it&#39;s sometimes AI slop.

Do you know why my timeline is free of it? I don&#39;t click on that link and watch that video.

like he was advocating violenceTrump has been advocating violence for a long time already  [youtube.com], it is not like that is something new. Like a lot of times [theatlantic.com]. Even back in the 80s he was advocating for killing innocent children in the Central Park Five case.The BBC clip was not fake despite what Trump cultist claim. It was just a normal collection of excerpts of a longer speech he gave, condensed down to something shorter for consumption in a news program. That is what all TV news programs does all the time, every single day, thousands of times a

Trump has been advocating violence for a long time already  [youtube.com], it is not like that is something new. Like a lot of times [theatlantic.com]. Even back in the 80s he was advocating for killing innocent children in the Central Park Five case.

The BBC clip was not fake despite what Trump cultist claim. It was just a normal collection of excerpts of a longer speech he gave, condensed down to something shorter for consumption in a news program. That is what all TV news programs does all the time, every single day, thousands of times a

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

The fancy is indeed no other than a mode of memory emancipated from the order
of space and time.  -- Samuel Taylor Coleridge</div>
        </div>
        
        <div class="card" onclick="openModal('content-28')">
            <div class="source">Slashdot</div>
            <div class="title">Startup Uses SpaceX Tech to Cool Data Centers With Less Power and No Water</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-28" style="display:none;">
            <h2>Startup Uses SpaceX Tech to Cool Data Centers With Less Power and No Water</h2>
            <p><strong>Slashdot | 2026-01-26</strong></p>
            <a class="original-link" href="https://hardware.slashdot.org/story/26/01/26/0317225/startup-uses-spacex-tech-to-cool-data-centers-with-less-power-and-no-water?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Slashdot is powered by your submissions, so send in your scoop

U.S. data centers will consume about 8% of all electricity in the country by 2030, according to the International Energy Agency... Is the bubble going to last that long? I have some doubts.

U.S. data centers will consume about 8% of all electricity in the country by 2030, according to the International Energy Agency...

Is the bubble going to last that long? I have some doubts.

Lord, you went off the rails in your second sentence!

Why can&#39;t you stick to the topic, cooling data centers? This has nothing to do with vibe coding, the stock market, or the Fed...

It has the rarer form with 18 atomic weight oxygen which is another stable isotope so is slightly more efficent...ok that&#39;s bullshit it&#39;s just regular co2 but just think of them using that $1600 a liter tank stuff for snooty investors who use gold plated monster cables

I guess it could be supercritical, which is just over 1000 psi, so not extremely high pressure but you wouldn&#39;t want to be near a leak.

That doesn&#39;t make a lot of sense thermodynamically, though, because it&#39;s a phase change that does the bulk of the energy transfer in a heat pump cycle. So you would need to cross that boundary line into a two-phase region.

You cannot exceed carnot efficiency, no matter what. There are no tricks. Draw your box around the system doing the work (physics work) and it doesn&#39;t matt

It doesn&#39;t matter if you use water to cool in a closed loop system.   The problem is only if you&#39;re using fresh water and just heating it up and dumping it and pulling in more fresh water.

So in this case, it&#39;s completely irrelevant.

The radiators get awful big at MWs of power and only 25 or so degrees C relative to ambient. So you spray water on them and they work a lot better.

Or rather you just spray the hot water into the air, I forgot how they worked.

Actually it&#39;s a combination of both. Most cooling systems have a closed loop and an evaporative one with heat exchangers involved moving heat from one to another. The reason being you want to carefully control the chemistry of the liquid required to get heat from a concentrated area (such as the fins on a waterblock on your CPUs), but don&#39;t want the expense of blasting that expensive liquid into the air.

they use the heat of evaporation of water to cool the hot refrigerant and release that to the atmosphere, because it&#39;s more efficient than just air cooling.

it&#39;s somewhat like setting up a small water sprayer on your AC condenser outside.  (they actually sell kits... and iirc they&#39;re cost effective, though I&#39;ve never tried one).

Directly? I find that hard to believe. Are you sure you&#39;re not running two loops with a heat-exchanger between? That would be how nearly every other datacentre in the world works regardless if the actual cooling element is liquid or air via a chiller. My mind would be blown if the actual liquid hitting your servers isn&#39;t running in a closed loop as you would expose yourself to a world of hurt with water chemistry having to have that continuously replaced and bio controlled. It&#39;s hard enough to prevent growt

Directly? I find that hard to believe.Alright.Are you sure you&#39;re not running two loops with a heat-exchanger between?Yes.That would be how nearly every other datacentre in the world works regardless if the actual cooling element is liquid or air via a chiller.Incorrect. Though many very large systems do for obvious reasons. The larger the loop, the more work you need, and not to mentioned a generally larger pumping requirement. There&#39;s also the limitations that you had better hope you never have high humidity, or freezing temps. Not a problem in our area.My mind would be blown if the actual liquid hitting your servers isn&#39;t running in a closed loopYou mean near our servers, I imagine... I was definitely not trying to imply that we&#39;re pumping this shit into water blocks on our CPUs.as you would expose yourself to a world of hurt with water chemistry having to have that continuously replaced and bio controlled.We had problems at first. Once we got the chemical and biologic

Are you sure you&#39;re not running two loops with a heat-exchanger between?Yes.That would be how nearly every other datacentre in the world works regardless if the actual cooling element is liquid or air via a chiller.Incorrect. Though many very large systems do for obvious reasons. The larger the loop, the more work you need, and not to mentioned a generally larger pumping requirement. There&#39;s also the limitations that you had better hope you never have high humidity, or freezing temps. Not a problem in our area.My mind would be blown if the actual liquid hitting your servers isn&#39;t running in a closed loopYou mean near our servers, I imagine... I was definitely not trying to imply that we&#39;re pumping this shit into water blocks on our CPUs.as you would expose yourself to a world of hurt with water chemistry having to have that continuously replaced and bio controlled.We had problems at first. Once we got the chemical and biologic

Are you sure you&#39;re not running two loops with a heat-exchanger between?

That would be how nearly every other datacentre in the world works regardless if the actual cooling element is liquid or air via a chiller.Incorrect. Though many very large systems do for obvious reasons. The larger the loop, the more work you need, and not to mentioned a generally larger pumping requirement. There&#39;s also the limitations that you had better hope you never have high humidity, or freezing temps. Not a problem in our area.My mind would be blown if the actual liquid hitting your servers isn&#39;t running in a closed loopYou mean near our servers, I imagine... I was definitely not trying to imply that we&#39;re pumping this shit into water blocks on our CPUs.as you would expose yourself to a world of hurt with water chemistry having to have that continuously replaced and bio controlled.We had problems at first. Once we got the chemical and biologic

That would be how nearly every other datacentre in the world works regardless if the actual cooling element is liquid or air via a chiller.

Incorrect. Though many very large systems do for obvious reasons. The larger the loop, the more work you need, and not to mentioned a generally larger pumping requirement. There&#39;s also the limitations that you had better hope you never have high humidity, or freezing temps. Not a problem in our area.

My mind would be blown if the actual liquid hitting your servers isn&#39;t running in a closed loopYou mean near our servers, I imagine... I was definitely not trying to imply that we&#39;re pumping this shit into water blocks on our CPUs.as you would expose yourself to a world of hurt with water chemistry having to have that continuously replaced and bio controlled.We had problems at first. Once we got the chemical and biologic

My mind would be blown if the actual liquid hitting your servers isn&#39;t running in a closed loop

You mean near our servers, I imagine... I was definitely not trying to imply that we&#39;re pumping this shit into water blocks on our CPUs.

as you would expose yourself to a world of hurt with water chemistry having to have that continuously replaced and bio controlled.We had problems at first. Once we got the chemical and biologic

as you would expose yourself to a world of hurt with water chemistry having to have that continuously replaced and bio controlled.

We had problems at first. Once we got the chemical and biologic

Many, many cooling systems use direct evaporation. Especially, but not only, in drier environments.

There are maintenance concerns, but the operating and initial capital costs are lower for those systems, so they are attractive on that level.

It doesn&#39;t matter if you use water to cool in a closed loop system.The closed part of the closed loop system only moves heat from one area to another. There&#39;s a whole different part of the system involved in actually moving that heat out to the environment, that system is open. The water consumption being discussed is usually due to evaporative cooling - which is still the cheapest way to run a cooling system unless you have a specific environment that allows for some other alternative (e.g. dumping heat into a river).

It doesn&#39;t matter if you use water to cool in a closed loop system.

The closed part of the closed loop system only moves heat from one area to another. There&#39;s a whole different part of the system involved in actually moving that heat out to the environment, that system is open. The water consumption being discussed is usually due to evaporative cooling - which is still the cheapest way to run a cooling system unless you have a specific environment that allows for some other alternative (e.g. dumping heat into a river).

Bigger facilities pass cold liquid through tubes near the chips to absorb the heat. This hot liquid is sent outside to a cooling yard, where sprawling networks of pipes use as much water as a city of 50,000 people to remove the heat. And from the cooling yard the water goes where? Oh, yeah, back into the cooling system. The water is not &quot;used,&quot; it is &quot;re-used&quot; - yes, some evaporates, but not 50,000 people worth of water (BTW, how much water does &quot;one people&quot; use?)

Bigger facilities pass cold liquid through tubes near the chips to absorb the heat. This hot liquid is sent outside to a cooling yard, where sprawling networks of pipes use as much water as a city of 50,000 people to remove the heat.

And from the cooling yard the water goes where? Oh, yeah, back into the cooling system. The water is not &quot;used,&quot; it is &quot;re-used&quot; - yes, some evaporates, but not 50,000 people worth of water (BTW, how much water does &quot;one people&quot; use?)

The system uses a special type of carbon dioxide...As far as I can tell, the only way CO2 can be &quot;special&quot; is if it&#39;s in a liquid state. (Normally, it transitions between solid and gas with no intermediate liquid state, but it does become liquid at about a little over 5 bars). But liquid CO2 is commonly used for preserving food and in other industries, so I&#39;m confused as to what might be special about the stuff they plan to use for cooling data centres.

The system uses a special type of carbon dioxide...

As far as I can tell, the only way CO2 can be &quot;special&quot; is if it&#39;s in a liquid state. (Normally, it transitions between solid and gas with no intermediate liquid state, but it does become liquid at about a little over 5 bars). But liquid CO2 is commonly used for preserving food and in other industries, so I&#39;m confused as to what might be special about the stuff they plan to use for cooling data centres.

But liquid CO2 is commonly used for preserving food and in other industries, so I&#39;m confused as to what might be special about the stuff they plan to use for cooling data centres.What&#39;s special is they&#39;re using a high-tech emulsion - liquid CO2 blended with equal parts Elonium and Baloneum.

But liquid CO2 is commonly used for preserving food and in other industries, so I&#39;m confused as to what might be special about the stuff they plan to use for cooling data centres.

What&#39;s special is they&#39;re using a high-tech emulsion - liquid CO2 blended with equal parts Elonium and Baloneum.

I saw that in a motion picture once - Return of the Jedi.

&#39;Carbonite&#39; was used as a liquid solution for cryostasis.

Some gasses work better than others for given temperatures in heat-pumps. CO2 is best suited to very high temperatures, like increasing the temp from say 50C coming from the GPU to say 90C.

It&#39;s sometimes used for domestic hot water heat pumps, mainly in Japan because they do love their baths and hotter water means it can use a smaller tank to fill the tub.

I think it&#39;s just an article written by a generalist  so I think he means to say &quot;special refrigerant&quot;as in different from what&#39;s used in normal HVAC  and is probably unfamiliar that, as you say, it&#39;s existing technologye.g. https://www.scmfrigo.com/en/bl...  [scmfrigo.com]

the only new thing mentioned is maybe using some snake faster compressors... but it&#39;s not mentioned of those are more efficient somehow.

the only new thing mentioned is maybe using some snake faster compressors

Yeah, but the quoted 30,000 RPM is not that high of a speed for centrifugal compressors using standard refrigerants.
TFA doesn&#39;t really say much, but I&#39;m guessing that it&#39;s some system that runs CO2 at high pressures and temperatures to cool the CPUs directly, and reject the heat to the outside air without a mechanical refrigeration cycle to raise the heat rejection temperature, since you&#39;re already running the CPUs at above-ambient t

None of it is new. They just want to say &quot;we are former spacex guys using spacex technology, give us money.&quot;

Its just like all the former Google or (now) OpenAI people - put that on your resume and convince people to give you their money.

&quot;Special&quot; here means supercritical, because apparently the editors at the LA Times don&#39;t trust their readers with words of more than four syllables.

Apart from that, I don&#39;t know. I&#39;ve seen press releases disguised as news before but this one really takes the biscuit. I think they&#39;re plugging some kind of pump, because engineers are always coming up with ways to use supercritical CO2 for seemingly random things (I read an article about thirty years ago for using it in industrial dishwashers) and the idea of

Can&#39;t exceed carnot efficiency, no matter what sleight of hand they use. I doubt the energy reduction touted is even possible.

Posting here because it&#39;s currently the last comment on my screen: Thanks to all for informative and/or funny answers. It&#39;s always good to learn and to see things from other perspectives. I hadn&#39;t heard about supercritical CO2, and hadn&#39;t considered direct-to-air cooling of the coils versus water-cooling them. Also didn&#39;t know that it was used in hot-water heat pumps

I also learned about two new elements, Elonium and Baloneum. I&#39;m guessing they&#39;re one above the other in the periodic table... ;-)

When it&#39;s hot outside, you could probably get the radiator temp difference to ambient around 2x higher with the heatpump at good COP. If radiator cooling requires too much radiator volume with normal liquid cooling, 2x is unlikely to make the difference.

Cooling towers with evaporation are used because of the far higher power density they allow.

Cooling towers with evaporation are used because of the far higher power density they allow.Yup. This is why we swapped out our traditional refrigerant HVACs. Denser, and cheaper. Though part of that reduced cost is the fact that we get too good of a price on the water we use.

Cooling towers with evaporation are used because of the far higher power density they allow.

Yup. This is why we swapped out our traditional refrigerant HVACs. Denser, and cheaper. Though part of that reduced cost is the fact that we get too good of a price on the water we use.

&quot;its pumps use liquid carbon dioxide as refrigerant, which is circulated using rocket engine technology rather than fans.&quot;So these guys thought that a common way to circulate liquid CO2 is using fans?!? Or was it just the AI that wrote the startup&#39;s business plan, or perhaps just this announcement, its summary?

&quot;its pumps use liquid carbon dioxide as refrigerant, which is circulated using rocket engine technology rather than fans.&quot;

So these guys thought that a common way to circulate liquid CO2 is using fans?!? Or was it just the AI that wrote the startup&#39;s business plan, or perhaps just this announcement, its summary?

And since when is a turbopump âoeSpaceX technologyâ, as if no one had done it before.

Hey, growing up my morning breakfast used NASA Technology to create a healthy powdered morning drink mix that reduced the number of oranges required to fill my juice glass!

I bet there&#39;s some misunderstanding on the reporter/marketer&#39;s side, whether deliberate or not, to make this seem cooler (heh) than it is.  Conventional refrigeration systems already exist that use carbon dioxide, though they seem to be more focused on walk-in coolers and such rather than air conditioners.  The only technical challenge to using carbon dioxide as a refrigerant is that the whole system runs at a much higher pressure than those using more conventional fluorocarbon refrigerants.  That means the

Karman has developed a cooling system similar to the heat pumps in the average home, except its pumps use liquid carbon dioxide as refrigerant, which is circulated using rocket engine technology rather than fans.Heat pumps don&#39;t circulate refrigerant with fans. Get this fucking bullshit the fuck out of here.

Karman has developed a cooling system similar to the heat pumps in the average home, except its pumps use liquid carbon dioxide as refrigerant, which is circulated using rocket engine technology rather than fans.

Heat pumps don&#39;t circulate refrigerant with fans. Get this fucking bullshit the fuck out of here.

&quot;liquid carbon dioxide&quot;  You get how that&#39;s worse right?

Maybe there is something valuable here, but it does a pretty bad job of conveying what that would be.

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

The fancy is indeed no other than a mode of memory emancipated from the order
of space and time.  -- Samuel Taylor Coleridge</div>
        </div>
        
        <div class="card" onclick="openModal('content-29')">
            <div class="source">Slashdot</div>
            <div class="title">New Linux/Android 2-in-1 Tablet 'Open Slate' Announced by Brax Technologies</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-29" style="display:none;">
            <h2>New Linux/Android 2-in-1 Tablet 'Open Slate' Announced by Brax Technologies</h2>
            <p><strong>Slashdot | 2026-01-26</strong></p>
            <a class="original-link" href="https://news.slashdot.org/story/26/01/25/2226239/new-linuxandroid-2-in-1-tablet-open-slate-announced-by-brax-technologies?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Want to read Slashdot from your mobile device? Point it at m.slashdot.org and keep reading!

Brax has already created an open thread with preliminary design specs.  &quot;The planned retail price is 599$ for the base version and 799$ for the Pro version,&quot; they write.  &quot;We will be offering open_slate (both versions) at a discount during our pre-order campaign, starting as low as 399$ for the base version and 529$ for the Pro version for limited quantities only which may sell out in a day or two from launching pre-orders...  

&quot;Pre-orders will open in February, via IndieGoGo. Make sure to subscribe for notifications if you don&#39;t want to miss the launch date.&quot; 
Thanks to long-time Slashdot reader walterbyrd for sharing the news.

I saw Rob&#39;s video earlier today. Very impressive tablet. The multiple physical kill switches are a nice touch, as is the replaceable battery and M2 slot. The claimed 20 hour battery life is impressive as well. I had a few Asus B121 Slate tablets years ago. While those were clunky and had disappointing battery life I do miss the convenience they offered. This Brax tablet may be the reason to try again.

I have a Star Labs StarLite. It&#39;s getting a bit long in the tooth but I&#39;m pretty happy with it. It&#39;s not perfect of course, few 2-in-1 computers are. I&#39;m not a fan of keyboard cases for tablets in general, this one tends to pop loose easily so I prefer using a simple stand and mechanical keyboard. The main difference with what I have is it&#39;s just an x86, so pretty easy to deal with and pretty decent performance across the board. For my purposes it has decent stylus support, so I can use an off-the-shelf generic surface 3 pen (4K) with it. I can code, use discord with my D&D group, and draw.

ARM is probably the future. But I won&#39;t tough another ARM tablet unless it has UEFI or u-boot. And the chip vendor&#39;s support absolutely has to be upstream before considering it. Else you will be stuck on some old distro and it will be a real struggle to upgrade.Wish I could comment more on the Brax specifically but getting a nice summary of specs from the website was too hard. I got a lot of nice marketing buzzwords though.

Agreed about the boot thing.  If Google is to be believed the modern term is now &quot;SystemReady.&quot; That means UEFI and ACPI, and supports the various ARM system standards, and can boot generic distros with stock, unmodified kernels without needing devicetree.

ARM is currently a bit of wasteland when it comes to proprietary kernels and downloading OS images from dodgy download sites.  Sadly RISC-V is no better currently.

There are ARM systems out there that meet these requirements, but they are expensive.  System

>ARM is probably the future. But I won&#39;t tough another ARM tablet unless it has UEFI or u-boot. And the chip vendor&#39;s support absolutely has to be upstream before considering it. Else you will be stuck on some old distro and it will be a real struggle to upgrade.

Agree 100%. There&#39;s a disturbing lack of realization of this fact in the official forum for this tablet... people are focused on  requesting luxury features such as built in cellular instead of making sure the base is solid.

We&#39;re working directly with Linux integrators and chipset partners to ensure proper mainline Linux support, rather than one-off ports that break over time.

So it&#39;s essentially a crowd-funded Android tablet that they&#39;re hoping will gain enough traction for upstream Linux. Who does the programming legwork is unclear.

If they&#39;re serious they would throw a few free ones to free software communities such as Mobian and postmarketOS as Pine64 has done with various bits of hardware such as the

I want my phone to support a full desktop with at least two full-size, external screens.

I would love a cheap Linux tablet (maybe running Android apps via Waydroid? Or having the ability to multi-boot between Linux and, say, LineageOS) available at a normal retailer. Sadly, this tablet is neither cheap nor at a place I&#39;d want to buy from (remember that Indiegogo projects can take all your money up front and either deliver nothing with no refunds or deliver it potentially years later). Wake me up when it&#39;s half the price on Amazon or somewhere equivalent.

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

The fancy is indeed no other than a mode of memory emancipated from the order
of space and time.  -- Samuel Taylor Coleridge</div>
        </div>
        
        <div class="card" onclick="openModal('content-30')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">What Word Refers to Someone Who Has Supposedly Returned From the Dead?</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-30" style="display:none;">
            <h2>What Word Refers to Someone Who Has Supposedly Returned From the Dead?</h2>
            <p><strong>News and Politics - Slate Magazine | 2026-01-26</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2026/01/trivia-quiz-daily-slate-vocabulary-definitions-bible-synonyms.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Please enable Javascript in your browser to view Slate interactives.

Slate Crossword: Genre-Defying Film That Received a Record-Breaking 16 Oscar Nominations (Seven Letters)

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-31')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">Everyone Saw CBP Kill Alex Pretti</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-31" style="display:none;">
            <h2>Everyone Saw CBP Kill Alex Pretti</h2>
            <p><strong>News and Politics - Slate Magazine | 2026-01-26</strong></p>
            <a class="original-link" href="https://slate.com/podcasts/what-next/2026/01/why-dhs-is-refusing-to-investigate-the-killing-of-alex-pretti?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Another person is dead in Minneapolis. Will anyone see justice?

Please enable javascript to get your Slate Plus feeds.

If you can&#39;t access your feeds, please contact customer support.

Thanks! Check your phone for a link to finish setting up your feed.

Enter your phone number and we&#39;ll text you a link to set up the
        podcast in your app:

We&#39;ll only text you about setting up this podcast, no spam.

Apple Podcasts will only work on MacOS operating systems since Catalina. We do not support Android apps on desktop at this time.

These links will only work if you&#39;re on the device you listen to podcasts on.

We&#39;re sorry, but something went wrong while fetching your podcast feeds. Please contact us at plus@slate.com for help.

Once again, federal agents have shot and killed a legal observer in Minneapolis. Once again, the shooting is on video. And once again, the Trump Administration has closed ranks around the officers. But could the fallout from Alex Pretti’s death be different? And Minnesotans want to know – when will the feds finally leave?

Guest: Will Stancil, lawyer and observer in Minneapolis

Want more What Next? Subscribe to Slate Plus to access ad-free listening to the whole What Next family and across all your favorite Slate podcasts. Subscribe today on Apple Podcasts by clicking “Try Free” at the top of our show page. Sign up now at slate.com/whatnextplus to get access wherever you listen.

Podcast production by Elena Schwartz, Paige Osburn, Anna Phillips, Madeline Ducharme and Rob Gunther.

The problem with the news right now? It’s everywhere. And each day, it can feel like we’re all just mindlessly scrolling. It’s why we created What Next. This short daily show is here to help you make sense of things. When the news feels overwhelming, we’re here to help you answer: What next? Look for new episodes every weekday morning.

Mary Harris is the host and managing editor of What Next, Slate&#39;s new daily news podcast. She has reported throughout the public radio system, for NPR, Marketplace, and WNYC.</div>
        </div>
        
        <div class="card" onclick="openModal('content-32')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">Don’t Let Them Tell You That Was Self-Defense</div>
            <div class="meta">2026-01-25</div>
        </div>
        
        <div id="content-32" style="display:none;">
            <h2>Don’t Let Them Tell You That Was Self-Defense</h2>
            <p><strong>News and Politics - Slate Magazine | 2026-01-25</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2026/01/alex-pretti-execution-lie-self-defense-myths.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Sign up for the Slatest to get the most insightful analysis, criticism, and advice out there, delivered to your inbox daily.

Early Saturday morning in downtown Minneapolis, 37-year-old Alex Pretti was killed by federal agents in full public view. Within hours, Immigration and Customs Enforcement and Customs and Border Protection officials released a familiar statement: an agent, they said, had acted in lawful self-defense against an armed and violent agitator. According to this narrative, Pretti instigated the violence that led to his death. A multitude of videos filmed by witnesses from multiple angles show this to be a lie.

They show Alex Pretti holding up his phone, filming as masked ICE and CBP agents shoved demonstrators and sprayed pepper spray into the crowd. They show an agent shoving a woman in the street. They show Pretti stepping forward, without striking anyone or reaching for a weapon, attempting to shield the woman from the agent’s blows. They show an agent spraying Pretti directly in the face with chemical irritant. They show Pretti being tackled to the ground. They show six or seven agents piling on top of him, striking him while he lay immobilized. And then, they show one agent removing Pretti’s licensed handgun—which he was carrying in compliance with state law—from his waistband.

Then, while he remained pinned to the pavement, helpless beneath a mass of armed bodies, gunshots rang out. Agents scattered, and one of them appeared to clap. Pretti did not get up. This is not self-defense. It is much more akin to an execution.

Pretti was a licensed, law-abiding gun owner, registered nurse, and worked at a veteran’s hospital.

The sequence of events matters, not only because it starkly contradicts the official account, but because it exposes how the language of self-defense has been distorted to the point that it now functions as a near-automatic exoneration for state violence. When authorities invoke “self-defense” today, they rarely describe a factual necessity. They are deploying a rhetorical shield with deep historical roots and devastating contemporary consequences.

Just weeks earlier, on Jan. 7, Renee Good was shot three times and killed by an ICE agent as she attempted to flee in her car. In that case, too, officials framed the killing as justified and necessary, as self-defense rather than aggression. In that case, too, video evidence and eyewitness accounts—including an agent muttering “fucking bitch” after the shooting—raised serious questions about the agents’ alleged “fear for their lives.” There is little to suggest that lethal force was unavoidable in this case, and yet Donald Trump’s Department of Justice is refusing to investigate the killing as a homicide. Instead, they are investigating Good’s widow. The pattern should be clear: use an empty claim of self-defense to exonerate the shooter, and then frame the victim as the perpetrator.

What we are witnessing is not a series of isolated tragedies. We have reached the logical endpoint of a political and legal culture that has long distorted claims of vulnerability, of “reasonable fear,” in the service of power, conflating aggressive, state-sanctioned violence with necessary self-protection.

From the nation’s founding, claims of self-defense have been used to justify extraordinary brutality. Systematic colonial violence against Indigenous nations was routinely rationalized as necessary to the protection of settler families and communities. Entire Indigenous communities were eradicated under the guise of lawful defense, with Indigenous resistance labeled “Savage Wars,” as a confrontation among equals rather than a genocidal onslaught.

After the Civil War, the Ku Klux Klan organized itself “to maintain forever the supremacy of the white race.” At the center of their mission lay the claim that white society required urgent protection from formerly enslaved people. Their founding documents emphasized “the sacred duty of protecting [white] womenhood” from sexual violence, with violence as necessary.

This mandate of protection congealed into widespread racial terror, claiming the lives of thousands of Black men, women, and children between Reconstruction and the mid-twentieth century. The Equal Justice Institute estimates that 4,400 lynchings took place during this time period, which was also characterized by legalized segregation, mass disenfranchisement, economic coercion, and sexual violence perpetrated against Black women. And yet, when anti-lynching bills appeared before Congress—again and again—white leaders defended ritualized, spectacular acts of racial terror as a regrettable but necessary response to generally false claims of sexual violence by Black men against white women.

This “rape-lynch” mythology, “that Negro men rape white women” was a “threadbare lie,” as journalist Ida B. Wells painstakingly documented in 1892, and she was almost murdered for speaking the truth. But truth was never the point. The claim of self-defense functioned as a form of camouflage to shroud the economic, political, and social project of keeping Black Americans subordinate under a blanket of legitimacy. It worked because enough people were willing to accept it, to pretend that racial terror was necessary to (white) public safety.

A similarly pernicious logic has insulated law enforcement from legal accountability for generations. Police violence, no matter how extreme, is routinely reframed as a defensive reaction to a threat rather than aggression. “The officer feared for his life.” “The suspect was reaching…for something.” “The situation escalated quickly, and the officer had no choice but to shoot.” The language is reflexive, ritualized, and remarkably effective. It is baked into our nation’s DNA to frame the victims of state-sanctioned violence as perpetrators.

In recent decades, that logic has been codified into law and expanded to select citizens through “Stand Your Ground” laws and permissive gun regulations that collapse the distinction between defense and dominance. These laws encourage armed confrontation while removing the legal duty to retreat or de-escalate. They transform subjective fear into legal justification while inviting ordinary citizens to imagine themselves as lone sentinels in a hostile world, as heroic “good guys with guns,” and as “Armed Citizens” exercising their Second Amendment rights. The laws reward those who act on that fantasy with legal immunity.

But only when they are acting in the service of repressive power. By all accounts, including the video evidence, Alex Pretti was a law-abiding, good guy with a gun, who stepped in to protect an unarmed woman from an assault. He did not draw his weapon, nor did he attack the agents who disarmed him before shooting him multiple times while he was pinned to the ground.

What is new today is not the twisted rhetoric of self-defense, but its escalation, and its targets. Masked federal agents, many of them poorly trained, now patrol public streets with military-grade weapons and broad discretionary authority. They detain, assault, and, increasingly, kill people based on vague or erroneous claims of public safety. They do so while invoking the same exonerating language that has long enabled state violence.

For generations, public state violence has been normalized precisely because it was disproportionately inflicted on non-white people, immigrants, low-income and other marginalized individuals. Many learned to look away or to justify this violence as the necessary price of “law and order.” Part of race and class privilege was the capacity to see such violence as a regrettable but necessary byproduct of maintaining order and keeping “us” safe.

We are now witnessing—some of us in incredulous horror—what happens when a society confuses authority with innocence and violence with virtue. We have built legal doctrines that reward escalation. We have granted weapons to institutions without demanding restraint. We have taught ourselves that “good guys” with guns will keep us safe from “bad guys.” Maybe now we are learning that the boundary separating the two was never clear in the first place.

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-33')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">In Minnesota, the Fight Against ICE Is Also the Fight Against Authoritarianism</div>
            <div class="meta">2026-01-25</div>
        </div>
        
        <div id="content-33" style="display:none;">
            <h2>In Minnesota, the Fight Against ICE Is Also the Fight Against Authoritarianism</h2>
            <p><strong>News and Politics - Slate Magazine | 2026-01-25</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2026/01/minnesota-community-fight-against-ice.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">This is part of a series of on-the-ground reports from Minneapolis.

On Thursday, I ended my day on daycare patrol as the windchill crept close to 25 degrees below zero. The patrols began after ICE appeared at my son’s daycare two weeks ago; that same day, a daycare worker for the same provider was taken by agents at a nearby location while trying to get in to work. During my recent patrol, ICE agents were spotted in the neighborhood, as they nearly always are, but everybody made it out of the building safely.

As I write this, a helicopter is circling over my neighborhood, as happens most days now. My phone is pinging near constantly with alerts from Signal groups that exist to defend and support our community. A friend texted to ask how concerned we should be that the president will invoke the Insurrection Act and send the military into our city; my husband just learned that workers at a nearby small business were taken by the government; a friend’s school went on lockdown today because ICE was nearby.

Our neighborhood has never been more united, but you wouldn’t know it from how few people are out on the streets. Nobody opens their door anymore, knowing that the next knock might be a federal agent demanding to know where the Brown people live in your neighborhood. People are making a point to support immigrant-owned restaurants, but you have to check if they’re open before you go, because so many aren’t. Folks are out delivering food and essentials to neighbors who are unable to leave their homes for fear, but they have to be careful to use a different car than they drive when they’re observing ICE, because the government is tracking license plates.

Earlier this week, students in our city lost  two days of learning because schools closed—the teachers needed time to shift to the virtual learning model which began on Thursday. This time, it’s not because of an unknown and deadly illness; it’s because the government is attacking our students. People are being shipped out of the state so fast that their families don’t have time to get to their holding cell with the paperwork proving they’re legally authorized to be here before they’re gone.

The horrors have not ceased since Renee Good’s death, instead they have increased. Protestors are being attacked and shot. On Tuesday, a five-year-old was detained by ICE and used to bait his family into leaving their home. The preschooler and his father have now been sent to Texas, and it is unclear if or when they’ll return. On Thursday, multiple civil rights leaders, including Saint Paul Public School board member Chauntyll Allen, were arrested for exercising their First Amendment right to protest, in a DOJ action that the NAACP has said was a likely violation of First Amendment rights. And on Saturday, Alex Pretti was killed by ICE agents, shot multiple times at close range. Every day, there is a new horror to process, a new way in which the federal government inflicts irreparable harm on our community.

I serve as a Saint Paul City Councilmember, and our community is under a violent attack at the hands of the federal government. And so we are fighting back in all the ways we know how.

On January 12th, Saint Paul announced a joint lawsuit with the city of Minneapolis and the state of Minnesota against the Department of Homeland Security, seeking to end this unconstitutional operation. Our City Council is working to strengthen our separation ordinance and develop other legal tools to make certain that our city resources—including our police department—cannot and will not support the work of immigration enforcement. We are calling on the governor to declare a state of emergency and enact a state-wide eviction moratorium to ensure that nobody loses their home because the federal government is making it impossible for them to earn a living. Every elected official in our city is working to connect our residents with whatever support they need right now. We are also demanding that Congress act—that our representatives and senators use every tool at their disposal to end this occupation—because neither cities nor states alone have enough tools to protect our people from the federal government.

None of this feels like enough. Individually, none of it is. But what we know from other countries that have successfully defeated authoritarianism is that democratic resurgence is possible. Over the last 30 years, 52 percent of “autocratization episodes” were followed by democratic resurgence. In 90 percent of those cases, countries were ultimately as or more democratic than they were previously.

In Saint Paul and across Minnesota, we’re showing that we have what it will take to win. We are cultivating solidarity and pushing back through every channel that we have—and building more capacity to fight for our community every day. We are demonstrating our commitment to nonviolence, even in the face of incredible levels of violence being used against us. We might get tired, but we are not succumbing to despair. Our civil resistance movement is strong, and it is growing.

Most importantly, we know what we’re fighting for, because we’ve already lived it. Saint Paul has always been at its strongest when we’ve embraced our immigrant neighbors. Minnesota has always been at its best when we’ve built structures that allow everybody in our state to flourish, whether they’ve been here for months or for generations. This is a place where we take seriously Paul Wellstone’s immortal words that “we all do better when we all do better.” The cruel, painful world that Donald Trump is trying to force on us is not one that we will ever, ever settle for. The path ahead is not clear, but we will continue to put one foot in front of the other until the day we win.

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-34')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">Alex Pretti Was Killed in My Neighborhood. I Still Can’t Believe What the Next Few Hours Were Like.</div>
            <div class="meta">2026-01-25</div>
        </div>
        
        <div id="content-34" style="display:none;">
            <h2>Alex Pretti Was Killed in My Neighborhood. I Still Can’t Believe What the Next Few Hours Were Like.</h2>
            <p><strong>News and Politics - Slate Magazine | 2026-01-25</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2026/01/alex-pretti-killing-ice-minneapolis-neighborhood-warzone.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Sign up for the Slatest to get the most insightful analysis, criticism, and advice out there, delivered to your inbox daily.

Shortly after 9 a.m. Saturday morning, my wife Julia woke up from a nightmare that federal agents were trying to break into our home, one of many nightmares she’s had since I was arrested by ICE, detained for 8 hours, then released without charges. I had been peacefully observing ICE when it happened, like so many Minnesotans have over the past weeks and days. That morning, she instinctively checked our neighborhood group chat. For the third time this month, someone in Minneapolis has been shot by federal agents. This time it had happened a mile from our home, to a man I would learn was Alex Pretti.

We haphazardly dressed in our cleanest warm clothes. As we opened our car doors we saw neighbors of ours, who we’ve never spoken to, doing the same. The entire neighborhood was converging. As we approached the intersection where Alex was shot 10 times, we heard chants of “ICE out” ringing out on Nicollet Ave, known locally as ‘Eat Street’ because of its dozens of globally minded restaurants.

What normally would have been an intersection full of chilly Saturday morning brunch-goers had become something akin to a warzone, as federal agents tried to break up the protestors gathered around the site of the shooting, at the intersection of Nicollet and 26th Street. Our presence, our bodies, were the only sign of solidarity and resistance we could offer, so that’s what we did. Agents assembled with weapons of war, and all we had was our outrage and our cameras.

We stood in the cold for a couple of minutes as the crowd swelled. At one point, someone threw a snowball at an agent. Two agents started chasing the man who’d tossed it westbound down 26th St. I tried to follow, but then heard an explosion from behind me. Flashbangs and chemical weapons were being shot or thrown into the crowd. I fled.

My sister-in-law, Eva Rose, who also lives nearby and also came to the intersection separately, described to me the moment the agents’ anger was unleashed a second time as she arrived 15 minutes later. Without warning, agents in tactical gear started throwing chemical weapons and chasing down protestors.

“The four of us ended up in a loading dock, in front of us were 10 agents and three things of tear gas, blowing in our faces.” Panicked and hardly able to see through the thick fog of chemical weapons, Eva and her friends wanted to escape, but they didn’t know how. In front of them, they saw a man getting randomly tackled by agents, his arms pinned behind his back, his face pressed inches from a billowing tear gas canister.  “We had nowhere to go, if we go straight we’ll get arrested or tackled, if we stay we’ll get gassed,” she told me later. As the tear gas filled their lungs and vision, they eventually decided to bolt. One of Eva’s friends threw up in the snow. Eva spit, and her saliva was neon orange.

“We were blindly running, I couldn’t breathe, I was choking on tear gas. My eyesight went black and I collapsed on the snow.” Eva’s fiancee helped her up, and they were able to make it home safely.

I was separated from Julia, and as my phone battery drained in the subzero air as I tried to reconvene with her. We found each other eventually, and went back to Nicollet to try to document what was happening. I watched as agents started rushing towards us with weapons drawn.

As I backed up, a short middle aged woman opened the door of a restaurant. “Come in, come in!” she yelled in a panic. She ushered in people on the street to save them from the chemical weapons.

We crowded into the restaurant. The owner paced back and forth in tears. Outside her window we saw a scene out of a warzone.

Over the next two hours, a pattern emerged. ICE agents would launch an assault down Eat Street, launching countless chemical weapons and flashbangs at protestors, then they would tackle and arrest people, seemingly at random. Then, they would retreat back to the intersection of 26th and Nicollet to resupply. Protesters would reconverge at the intersection, and the spectacle would repeat through the restaurant window.

We stayed in the restaurant, which became a makeshift refuge site. “I just wanted people to be safe,” the owner told me later. “I want businesses to do what I do, give water, let people come in.”

People did keep coming in, between the spurts of dispute. “I saw three [arrests],” a young woman told me, she was documenting on her phone. “One man looked unconscious when they dragged him in.” A backpack was brought in, the owner had been arrested. We searched it for identifying information, but found nothing.

Each time terrified people rushed into the restaurant, the owner would offer bottled water or hot water in plastic glasses. There were phone chargers, food, hugs. She waved away any attempt to pay her. It was in that restaurant I learned that Alex Pretti had died.

During yet another skirmish outside, a woman came in sobbing. We witnessed from the window her partner being tackled and snatched by ICE. Julia started making calls to lawyers to help, as she had when I had been arrested the week before. Today, the lawyer’s first question was: Were they a witness to the shooting? One woman who had seen it later said in a sworn affidavit that she heard ICE was looking for her.

Gas victims kept being brought to the restaurant, “like a field hospital,” as I overheard a passerby describe it. Their heads were tilted back and bottled water poured into their eyes. I watched a medic spray a man with saline solution, while another medic treated a man with frostbite, at tables that would normally be set for lunch.

A man whose eye was swollen shut was brought to a chair. He had to wait for a medic because they were busy. I offered him water and waited with him. He told me he’d only been on the scene for 10 minutes when he was sprayed from close range. If Alex, the 37-year-old ICU nurse had still been alive, if he had made it into this restaurant, he probably could have offered real help. All I could offer was water.

Later, outside, I talked to another volunteer medic who had helped two protestors that were having a severe allergic reaction to the gas. And I asked how many people he treated.

Around 12:40 p.m., someone came into the restaurant and told us, “ICE are gone, it’s safe now.” There was a palpable diffusion of tension.

Outside, Minneapolitans were cleaning up the gas canisters ICE left behind and hugging each other. A man was trying to put up some trash bins that had been knocked over, and re-string police tape to form a perimeter. I started to help him, only then realizing we were blocking off the site of Pretti’s shooting. He told me ICE had knocked over the police tape during one of their advances, and no police or first responders remained. I wasn’t sure if it was a crime scene or not, and no officials remained. We did our best to cordon off the area so no one would walk through.

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-35')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">The Minneapolis Shooting Videos Are Horrifying—and Incredibly Clear. Stephen Miller’s Response Is Downright Chilling.</div>
            <div class="meta">2026-01-25</div>
        </div>
        
        <div id="content-35" style="display:none;">
            <h2>The Minneapolis Shooting Videos Are Horrifying—and Incredibly Clear. Stephen Miller’s Response Is Downright Chilling.</h2>
            <p><strong>News and Politics - Slate Magazine | 2026-01-25</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2026/01/minneapolis-ice-shooting-today-alex-pretti-trump-stephen-miller.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Sign up for the Slatest to get the most insightful analysis, criticism, and advice out there, delivered to your inbox daily.

Believe your federal government, not your own eyes. If you are big on the right to bear arms, make an exception this time. These are the Trump administration’s messages after a horrible Saturday in Minnesota.

Homeland Security agents shot 37-year-old Minneapolis ICU nurse and researcher Alex Pretti dead on Saturday morning in broad daylight. A few things are already clear from the best video angle out now: Pretti was directing traffic on a Minneapolis street. He was filming agents out in public, as is his undisputed right. An agent approached Pretti and then shoved a woman, hard, into a snowbank. Pretti put his hand up as he went to assist the woman. The masked agent who threw the woman to the ground draped himself over Pretti, then was joined by several of his colleagues. They got Pretti to the ground, struggled for a moment, and shot him until he was dead. Was this death sentence the result of sheer incompetence by agents who had no idea how to handle conflict? Was it a summary execution? Or, as the Trump administration would have you believe, did the dead man have it coming?

Pretti had a gun on him. An administration that once wrapped Kyle Rittenhouse in a loving embrace after he brought a rifle to a protest and killed two men took an interesting view of that fact. “This looks like a situation where an individual wanted to do maximum damage and massacre law enforcement,” an unsigned Homeland Security post said. “An assassin tried to murder federal agents,” Stephen Miller said. (JD Vance, the heir apparent to the Republican presidential nomination, reposted Miller.)  And what about the man who is nominally still running the country? Donald Trump pointed to a picture of Pretti’s handgun, confiscated by the agents, and noted it was loaded and “ready to go – What is that all about?”

Perhaps we will learn more in the coming days about what exactly happened when. But the early videos are already quite clear, as is what Trump and Miller and Vance are not saying. Nobody argued that Pretti brandished the gun before agents shot him several times. Moreover, no one argued that Pretti wasn’t allowed to have the gun. Minnesota allows people to carry a gun if they have a permit, and the Minneapolis police chief told reporters that Pretti had one. He had no criminal history beyond traffic tickets.

But the Trump administration has already told you what happened. One, the man had a gun, which is bad now. Two, the man was out to kill federal agents, which is obvious, because he had a gun.

We all have to decide for ourselves what we’ll believe about this case.

On the one hand, Pretti was a nurse who worked at the Veterans’ Administration. (If there’s one job that screams “disrespect for federal officers,” it’s “nurse at the VA.”)  Pretti was reaching for a woman whom an anonymous federal agent had just launched into a snowbank in frigid weather. It even looks like if anyone fired Pretti’s gun, it was a federal agent who had disarmed him and accidentally shot it into the pavement. And, fine, the physical altercation was initiated entirely by the agents, who put the woman on the ground and mobbed Pretti before shooting him to death.

But on the other hand, Stephen Miller says the man was an assassin. Would Stephen Miller lie?

Then there’s the matter of the gun itself. As Trump noted, the gun was “ready to go.” Pretti, though, had a legal right to carry that gun, thanks in large part to the gun-rights movement that has been part of Trump’s base for his entire political career. And most people who carry guns also carry bullets for those guns, as bullets are the primary projectile that guns send flying through the air.

But on the other hand, Alex Pretti had a gun. And would any American carry a gun in public without the intention to murder federal agents in cold blood? Remember, the sum total of violent crimes this ICU nurse had been charged with in his life was zero.

Miller says Pretti was a “domestic terrorist,” a label the administration also applied to the also-37-year-old Renee Good after one of its agents shot her through her car’s side window. The feds left their victim’s body splayed out on the road after taking the life from it, but they were at least a bit more dignified with him in one way. Nobody appears to have called Pretti a “fucking bitch,” as Good’s killer did right after shooting her.

You might get the impression from this series of federal killings that the real crime against this administration is opposing it in any way. But can you really trust yourself?

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-36')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">Coinbase power play sparks crypto rift as key bill gets delayed</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-36" style="display:none;">
            <h2>Coinbase power play sparks crypto rift as key bill gets delayed</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2026-01-26</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2026-01-coinbase-power-play-crypto-rift.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-37')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">Social media giants face landmark trial over addiction claims</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-37" style="display:none;">
            <h2>Social media giants face landmark trial over addiction claims</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2026-01-26</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2026-01-social-media-giants-landmark-trial.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-38')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">Macron pushes for fast-track ban on social media for children under 15</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-38" style="display:none;">
            <h2>Macron pushes for fast-track ban on social media for children under 15</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2026-01-26</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2026-01-macron-fast-track-social-media.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-39')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">How Americans are using AI at work, according to a new Gallup poll</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-39" style="display:none;">
            <h2>How Americans are using AI at work, according to a new Gallup poll</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2026-01-26</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2026-01-americans-ai-gallup-poll.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-40')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">Detection of concealed explosives using terahertz spectral imaging and deep learning</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-40" style="display:none;">
            <h2>Detection of concealed explosives using terahertz spectral imaging and deep learning</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2026-01-26</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2026-01-concealed-explosives-terahertz-spectral-imaging.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-41')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">Origami-inspired ring lets users 'feel' virtual worlds</div>
            <div class="meta">2026-01-25</div>
        </div>
        
        <div id="content-41" style="display:none;">
            <h2>Origami-inspired ring lets users 'feel' virtual worlds</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2026-01-25</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2026-01-origami-users-virtual-worlds.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-42')">
            <div class="source">The Register</div>
            <div class="title">Knee-Deep in the CAD: Boffin gets Doom running inside a design modeler</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-42" style="display:none;">
            <h2>Knee-Deep in the CAD: Boffin gets Doom running inside a design modeler</h2>
            <p><strong>The Register | 2026-01-26</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2026/01/26/openscad_doom/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Not content with rendering Doom in PCB design software or playing it on an oscilloscope, engineer Mike Ayles has got the 1990s shooter running in a computer-aided design (CAD) modeler.

Everybody has a personal mountain to climb simply because it is there. In the case of Ayles, that mountain is finding ever more unlikely ways of rendering Doom. In November 2025, he showed off Doom rendered in vector graphics using KiCad PCB design software. He also produced ScopeDoom, which used the MacBook headphone jack to generate crude, but recognizable, vectors on an oscilloscope.

At the time, we wondered what he might come up with over Christmas. The answer is OpenSCAD-Doom. Or as Ayles put it in his blog: &quot;The third entry in an increasingly unhinged series of projects that answer the question: &#39;Can I run Doom on engineering tools that were absolutely not designed for games?&#39;&quot;

There is an educational aspect to the insanity. A deep understanding of the technology is required to make this silly thing work. &quot;Yes, it&#39;s absurd,&quot; Ayles said, &quot;but it&#39;s also R&D disguised as entertainment.&quot;

Ayles told The Register that he&#39;d planned to release the third in the series at Christmas, but performance refused to get above slideshow levels. &quot;Then last week, I had to fix OpenSCAD rendering for another project and discovered the npm openscad-wasm package was from 2022 and silently ignoring the Manifold flag,&quot; he said.

&quot;The fix took renders from 2 minutes to 2 seconds. Rolled that back to OpenSCAD-Doom and suddenly it was playable.&quot;

Doom rendered using the openSCAD software

As for how it works, Ayles said: &quot;It&#39;s a custom Python engine that reads WAD files and outputs OpenSCAD code. Pygame handles input and runs a parallel software renderer. The OpenSCAD side uses Animation mode to bypass the file watcher&#39;s 200ms debounce.&quot; Performance-wise, the game runs at 10-20 FPS and renders well enough for the player to work out what is happening. It is, however, blocks of color.

&quot;Unfortunately, OpenSCAD doesn&#39;t support image wrapping for textures, so solid block colors were the order of the day,&quot; Ayles said.

&quot;It was more difficult than I was expecting it to be, the viewport still looks pretty awful, but it is recognisable as Doom at least. One little bug is the smiley faces on the monsters, they were supposed to be frowns but I messed up. It made me laugh so I kept it.&quot;

As for what&#39;s next, Ayles has some unfinished business with Autodesk&#39;s Fusion 360, a popular CAD tool. &quot;I am fully prepared to get banned by Autodesk by rendering in Fusion 360, although its plugin system is a bit more fully featured than what I&#39;ve done in the past, so it may be plausible to run 100 percent inside Fusion 360.&quot; ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-43')">
            <div class="source">The Register</div>
            <div class="title">Sandia boffins let three AI agents loose in the lab. Science, not chaos, ensued</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-43" style="display:none;">
            <h2>Sandia boffins let three AI agents loose in the lab. Science, not chaos, ensued</h2>
            <p><strong>The Register | 2026-01-26</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2026/01/26/sandia_ai_agents_feature/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Boffins at the Department of Energy&#39;s Sandia National Labs are working to develop cheap and power efficient LEDs to replace lasers. One day, they let a trio of AI assistants loose in their lab.

Unlike most of AI agents, the lab&#39;s tools aren&#39;t just making API calls to third party models

Five hours later, the bots had churned through more than 300 tests and uncovered a novel approach for steering LED light that is four times better than methods the researchers developed using their own wetware.

The work, detailed in a paper published in the journal Nature Communications underscores how AI agents are changing the way scientists work.

&quot;We are one of the leading examples of how a self-driving lab could be set up to aid and augment human knowledge,&quot; Sandia researcher Prasad Iyer said in a recent blog post.

The experiment builds on a 2023 paper in which Iyer and his team demonstrated a method for steering LED light that has applications in everything from autonomous vehicles to holographic projectors. The trick was finding the right combination of parameters to steer the light in the desired manner, a process researchers expected to take years.

To speed this process up, Iyer enlisted the help of his colleague Saaketh Desai to develop a series of artificially intelligent lab assistants.

Unlike most of AI agents, the lab&#39;s tools aren&#39;t just making API calls to third party models. Instead, the team developed a trio of domain-specific models based on well-established machine-learning algorithms.

&quot;We didn&#39;t do any LLMs. There is significant interest in that. There are lots of people trying those ideas out, but I think they&#39;re still in the exploratory phase,&quot; Desai told El Reg.

As it turned out, the researchers didn&#39;t need them. &quot;We used a simpler model called a variational auto encoder (VAE). This model was established in 2013. It&#39;s one of the early generative models,&quot; Desai said.

By sticking with domain-specific models based on more mature architectures, Sandia also avoided hallucinations – the errors that arise when AI makes stuff up – which have become one of the biggest headaches associated with deploying generative AI.

&quot;Hallucinations were not that big a concern here because we build a generative model that is tailored for this very specific task,&quot; Desai explained.

The first of these models utilized a VAE architecture, a type of model commonly used to generate images before diffusion models came on the scene in 2015. That model pre-processed the lab&#39;s data sets.

Researchers then fed the outputs of that model into a second model that was connected directly to the optical equipment used to conduct the experiments.

This active learning model is based on a Bayesian optimization algorithm which was responsible for generating and running an experiment then analyzing the results. This process was conducted in a closed loop, with the models repeatedly refining the experiments.

However, it wasn&#39;t enough to know which combination of parameters results in the best results. The real science is in uncovering why that particular configuration works at all.

The team therefore added a third model to the loop, to essentially act as a fact-checker. Researchers tasked this simple feed-forward neural network with devising the formula for the data generated, to later verify results.

And while many AI models are trained on hundreds of thousands of GPUs, the team managed to do all of this using comparatively modest hardware in the form of a Lambda Labs workstation equipped with three RTX A6000 graphics cards.

Together these models not only resulted in a speed-up in testing, but also surfaced approaches to LED beam steering the researchers hadn&#39;t previously considered.

While the research focused on the application of AI to steering light emitted by LEDs, Desai believes the underlying approach may have applications in materials design for things like alloys or printable electronics.

For other scientists interested in replicating this kind of &quot;self-driving lab,&quot; Desai says it&#39;s important to have equipment that&#39;s tightly integrated into the model framework.

&quot;There&#39;s progress and development there, but there&#39;s still a long way to go in terms of making sure that the tools that are in the lab, the physical tools, are able to interact with these models,&quot; he said. &quot;If you&#39;re using a piece of equipment from 1975 you&#39;re already in a tough place to start.&quot;

As for the models themselves, he emphasizes the importance of skepticism. &quot;If you&#39;re going into more advanced architectures and machine learning — transformer based LLM and what not — I would say my advice is to be really skeptical of what it gives you.&quot; ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-44')">
            <div class="source">The Register</div>
            <div class="title">EU looking into Elon Musk's X after Grok produces deepfake sex images</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-44" style="display:none;">
            <h2>EU looking into Elon Musk's X after Grok produces deepfake sex images</h2>
            <p><strong>The Register | 2026-01-26</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2026/01/26/ec_open_new_investigation_into/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The European Commission has launched an investigation into X amid concerns that its GenAI model Grok offered users the ability to generate sexually explicit imagery, including sexualized images of children.

The executive branch of the EU said it begun the new probe under the Digital Services Act (DSA), introduced to regulate illegal content, disinformation, and other systemic risks on online platforms, and assess whether the company properly assessed and mitigated risks associated with the deployment of Grok&#39;s functionalities into X in the EU.

Enacted in 2022, the DSA includes powers to prevent the dissemination of illegal content in the EU, such as manipulated sexually explicit images, including content that may amount to child sexual abuse material.

In a statement, the Commission said risks from Grok appear to have exposed citizens in the EU to serious harm.

&quot;Sexual deepfakes of women and children are a violent, unacceptable form of degradation. With this investigation, we will determine whether X has met its legal obligations under the DSA, or whether it treated rights of European citizens - including those of women and children - as collateral damage of its service,&quot; said Henna Virkkunen, Commission executive vice-president for tech sovereignty, security and democracy.

X referred to a previous statement, telling The Register: &quot;We remain committed to making X a safe platform for everyone and continue to have zero tolerance for any forms of child sexual exploitation, non-consensual nudity, and unwanted sexual content.

The company added: &quot;We take action to remove high-priority violative content, including Child Sexual Abuse Material (CSAM) and non-consensual nudity, taking appropriate action against accounts that violate our X Rules. We also report accounts seeking Child Sexual Exploitation materials to law enforcement authorities as necessary.&quot;

Officials said that since they began discussions with X over how Grok was implemented, the platform had made changes to the system, including turning off the image-generation tool for users who don&#39;t pay subscriptions.

While the Commission recognized X had already taken some measures related to the intimate images, it said its investigation was much broader than the specific incident which hit the headlines earlier this month.

The DSA gives the EU the power to fine digital platforms up to 6 per cent of their total annual worldwide turnover, which in X&#39;s case might be $174 million, based on an estimate of $2.9 billion turnover. X, formerly known as Twitter, was taken private in 2022 and no longer has to report figures.

Separately, the EC has extended the proceedings it initiated against X in December 2023 to determine whether the platform assessed and mitigated all systemic risks as set out in the Act. The extension includes the impact of the decision to switch X to Grok-based recommendations.

The Commission has already used the DSA to fine X €120 million for breaching the rules on ad transparency, data access for researchers, and its revamped blue-checkmark system.

The EU has said it would stand firm against American demands to tone down the regulation of US tech giants. Late in 2025, the US Trade Representative, a government body for trade and economic policies, slammed the EU for pursuing policies that restrict, limit, and deter the competitiveness of US tech giants through discriminatory means. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-45')">
            <div class="source">The Register</div>
            <div class="title">Data thieves borrow Nike's 'Just Do It' mantra, claim they ran off with 1.4TB</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-45" style="display:none;">
            <h2>Data thieves borrow Nike's 'Just Do It' mantra, claim they ran off with 1.4TB</h2>
            <p><strong>The Register | 2026-01-26</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2026/01/26/data_thieves_claim_nike_data_haul/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Nike says it is probing a possible breach after extortion crew WorldLeaks claimed to have lifted 1.4TB of internal data from the sportswear giant and posted samples on its leak site.

In a listing seen by The Register, WorldLeaks alleges it has stolen 188,347 files from Nike&#39;s systems. The group has published the data with filenames pointing toward design and manufacturing workflows, rather than customer databases.

Examples include directories labeled &quot;Women&#39;s Sportswear,&quot; &quot;Men&#39;s Sportswear,&quot; &quot;Training Resource – Factory,&quot; and &quot;Garment Making Process,&quot; suggesting the alleged haul centers on product development and production processes.

Nike confirmed it&#39;s looking into the matter but stopped short of validating the criminals&#39; claims. &quot;We always take consumer privacy and data security very seriously,&quot; a spokesperson told The Register. &quot;We are investigating a potential cybersecurity incident and are actively assessing the situation.&quot;

When asked, the company declined to say what data was stolen and whether it planned to pay a ransom demand.

There&#39;s nothing so far to suggest customer or employee records were involved, which keeps regulators at arm&#39;s length for now. That said, design files, factory training notes, and process documentation are the sort of internal plumbing companies don&#39;t expect to lose control of, even if they don&#39;t trigger formal breach notices. It doesn&#39;t take much imagination to see how copycats or grey-market factories might make use of it.

Crews like WorldLeaks aren&#39;t bothering with ransomware theatrics anymore and are going straight for whatever files they can grab. The crew is said to be a rebrand of Hunters International, a ransomware gang that&#39;s been around since 2023. These days they don&#39;t bother encrypting anything; they just take the data and start leaning on victims with the threat of leaks. With police pressure up and fewer companies paying for decryptors, that&#39;s where the leverage is now.

WorldLeaks claims hundreds of victims so far, with manufacturers and industrial firms cropping up again and again. Dell made the crew&#39;s hitlist in July last year, but claimed WorldLeaks didn&#39;t make off with any important data.

The Nike claim lands just weeks after another US sportswear heavyweight was forced into cleanup mode. Under Armour disclosed a breach following an attack by the Everest ransomware gang. According to Have I Been Pwned, the extortion crew exposed the details of 72.7 million Under Armour accounts, including names, email addresses, dates of birth, genders, geographic locations, and purchase information.

As with most extortion claims, the true size and value of the haul is hard to judge without Nike putting more on the record. What does seem clear is that fashion and sportswear firms, with messy global supply chains and a steady stream of new designs moving between partners, have become a target for data thieves who don&#39;t need customer databases to cause real damage. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-46')">
            <div class="source">The Register</div>
            <div class="title">Microsoft probes Windows 11 boot failures tied to January security updates</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-46" style="display:none;">
            <h2>Microsoft probes Windows 11 boot failures tied to January security updates</h2>
            <p><strong>The Register | 2026-01-26</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2026/01/26/microsoft_probes_windows_11_boot/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Microsoft is investigating reports that its January 2026 security updates are leaving some Windows 11 machines stuck in a boot loop, adding another entry to this month&#39;s bumper post–Patch Tuesday borkage list.

The issue affects a &quot;limited number&quot; of physical Windows 11 devices that fail to start after installing the January security updates and later patches, instead showing an &quot;UNMOUNTABLE_BOOT_VOLUME&quot; stop code and a black screen offering little more than a restart prompt.

&quot;Your device ran into a problem and needs a restart. You can restart,&quot; the message reads, according to a Microsoft advisory spotted by Ask Woody. At this stage, Microsoft says, the system cannot complete startup and needs manual recovery steps to get going again.

According to Redmond&#39;s own incident note, the problem has been observed on Windows 11 versions 24H2 and 25H2, with no server editions affected and no reports of the same behavior on virtual machines.

The first signs of trouble appeared in user forums, where people reported that machines which had been working fine suddenly wouldn&#39;t boot after the January updates were installed. Security-focused updates are supposed to be among the least exciting parts of Windows maintenance, but for those hit by the bug, they have resulted in downtime and hands-on repair work rather than a quiet reboot.

Microsoft says it has received only a small number of reports so far and is still trying to determine whether the failures are definitely caused by a regression introduced by the January updates. Customers experiencing the issue are being told to contact business support or submit reports through the Feedback Hub while the investigation continues. The company says it will update its documentation once more details are confirmed.

While this particular problem appears limited in scope, it lands in the middle of a rough January for Microsoft&#39;s update machinery. Earlier this month, Redmond was already dealing with fallout from a Secure Launch bug that could prevent systems from shutting down cleanly, separate Windows app credential failures that broke sign-ins for some users, and an Outlook issue that causes the app freeze when saving files to cloud storage services.

The boot failure issue is the latest reminder that January&#39;s patches have been unusually good at introducing new headaches alongside their promised security fixes. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-47')">
            <div class="source">The Register</div>
            <div class="title">When AI 'builds a browser,' check the repo before believing the hype</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-47" style="display:none;">
            <h2>When AI 'builds a browser,' check the repo before believing the hype</h2>
            <p><strong>The Register | 2026-01-26</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2026/01/26/cursor_opinion/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Opinion AI-integrated development environment (IDE) company Cursor recently implied it had built a working web browser almost entirely with its AI agents. I won&#39;t say they lied, but CEO Michael Truell certainly tweeted: &quot;We built a browser with GPT-5.2 in Cursor.&quot;

He followed up with: &quot;It&#39;s 3M+ lines of code across thousands of files. The rendering engine is from-scratch in Rust with HTML parsing, CSS cascade, layout, text shaping, paint, and a custom JS VM.&quot;

That sounds impressive, doesn&#39;t it? He also added: &quot;It *kind of* works,&quot; which is not the most ringing endorsement. Still, numerous news sources and social media chatterboxes ran with the news that AI built a web browser in a week.

Too bad it wasn&#39;t true. If you actually looked at Cursor engineer Wilson Lin&#39;s blog post about FastRender, the AI-created web browser, you won&#39;t see much boasting about a working web browser. Instead, there&#39;s a video of a web browser sort of working, and a much less positive note that &quot;building a browser from scratch is extremely difficult.&quot;

The thing about making such a software announcement on GitHub is that while the headlines are proclaiming another AI victory, developers have this nasty trick. They actually git the code and try it out.

Developers quickly discovered the &quot;browser&quot; barely compiles, often does not run, and was heavily misrepresented in marketing.

As a techie, the actual blog post about how they tried and didn&#39;t really succeed was much more interesting. Of course, that Cursor sicced hundreds of GPT-5.2-style agents which ran for a week to produce three million lines of new code, to produce, at best, a semi-functional web browser from scratch, doesn&#39;t make for a good headline.

According to Perplexity, my AI chatbot of choice, this week‑long autonomous browser experiment consumed in the order of 10-20 trillion tokens and would have cost several million dollars at then‑current list prices for frontier models.

I&#39;d just cloned a copy of Chromium myself, and for all that time and money, independent developers who cloned the repo reported that the codebase is very far from a functional browser. Recent commits do not compile cleanly, GitHub Actions runs on main are failing, and reviewers could not find a single recent commit that was built without errors.

Where builds succeeded after manual patching, performance was abysmal, with reports of pages taking around a minute to load and a heavy reliance on existing projects like Servo, a Rust-based web rendering engine, and QuickJS, a JavaScript engine, despite &quot;from scratch&quot; claims.

Lin defended the project on Y Combinator, saying, for instance: &quot;The JS engine used a custom JS VM being developed in vendor/ecma-rs as part of the browser, which is a copy of my personal JS parser project vendored to make it easier to commit to.&quot; If it&#39;s derived from his personal JavaScript parser, that&#39;s not really from scratch, is it? Nor is it, from the sound of the argument, written by AI.

Gregory Terzian, a Servo maintainer, responded: &quot;The actual code is worse; I can only describe it as a tangle of spaghetti... I can&#39;t make much, if anything, out of it.&quot; He then gave the backhanded compliment: &quot;So I agree this isn&#39;t just wiring up of dependencies, and neither is it copied from existing implementations: it&#39;s a uniquely bad design that could never support anything resembling a real-world web engine.&quot; Now that&#39;s a burn.

From where I sit, what makes the Cursor case more dangerous than just a failed hack‑week project is that the hype is baked into its methodology. The &quot;experiment&quot; wasn&#39;t presented as what it really was: an interesting, but messy, internal learning exercise. No, it was rolled out as a milestone that conveniently confirmed the company&#39;s long‑running autonomous agent advertising. Missing from the story were basics any senior engineer would demand: passing Continuous Integration (CI), reproducible builds, and real benchmarks that show the browser doing more than limping through a hello-world page.

Zoom out, and CEOs are still predicting that AI will write 90 percent of code in a year, while most enterprise AI pilots still fail to deliver meaningful return on investment.

We&#39;re now in a kind of AI uncanny valley for developers. Sure, tools like Cursor can be genuinely helpful as glorified autocomplete and refactoring assistants, but marketing keeps insisting junior engineers can take whole projects from spec to shipping. When you start believing your own sizzle reel, you stop doing the tedious validation work that separates a demo from a deliverable.

Enough already. The hype has grown cold. Sarah Friar, OpenAI&#39;s CFO, recently blogged that in 2026, its focus would be on &quot;practical adoption.&quot; Let&#39;s see real-world practical results first, and then we can talk about practical AI adoption. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-48')">
            <div class="source">The Verge</div>
            <div class="title">Experian’s tech chief defends credit scores: ‘We’re not Palantir’</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-48" style="display:none;">
            <h2>Experian’s tech chief defends credit scores: ‘We’re not Palantir’</h2>
            <p><strong>The Verge | 2026-01-26</strong></p>
            <a class="original-link" href="https://www.theverge.com/podcast/866751/experian-ceo-alex-lintner-credit-scores-ai-privacy-interview">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Alex Lintner, head of tech for the global credit reporting company, on AI, privacy, and what data brokerages really do.

Today, I’m talking with Alex Lintner, who is the CEO of technology and software solutions at Experian, the credit reporting company. Experian is one of those multinationals that’s so big and convoluted that it has multiple CEOs all over the world, so Alex and I spent quite a lot of time talking through the Decoder questions just so I could understand how Experian is structured, how it functions, and how the kinds of decisions Alex makes actually work in practice.

There’s a lot there, especially since Alex is in charge of the company’s entire tech arm. That means he oversees big operations like security and privacy, and now, of course, AI — all of which is always important, but is even more critical when you factor in what kind of information Experian collects and stores about, well, literally everyone.

See, if you want to participate in the economy in the way the vast majority of us do — renting an apartment, buying a car, getting a job, or applying for a mortgage or a student loan — you’re part of Experian’s ecosystem, whether you like it or not. You’ll hear Alex talk about “consent” a whole lot in this episode, and he’ll argue that you can opt out, but the reality is, interacting with Experian is pretty much non-negotiable in the economy we live in today. It’s hard to do basically anything involving money without a credit score.

Verge subscribers, don’t forget you get exclusive access to ad-free Decoder wherever you get your podcasts. Head here. Not a subscriber? You can sign up here.

That’s really the tension at the heart of a company like Experian: Credit scores dominate so many aspects of our lives, and they are controlled and calculated in ways that it feels like we have very little direct influence over. At its heart, Experian’s core service is data — data about people, about their money and what they do with it, about the decisions they make, the bills they pay or don’t pay. And this extremely valuable data weirdly makes Experian a part of your life — a life that becomes much smoother if the data the company collects about you tells a good story. So Alex and I spent a good chunk of time talking about the responsibility Experian feels toward the people it serves, not just on a security and privacy level, but also a moral one.

A lot of people don’t like the power Experian has, and by extension, they don’t like the company, either. I asked Alex pretty directly about that, and I found his answer to be a little surprising. Maybe one of the most memorable answers we’ve ever gotten on Decoder, really.

I also asked Alex pretty directly about the other big, messy question taking up the room: generative AI, and how exactly we can trust nondeterministic systems when they start interacting with really sensitive data.

You’ll hear Alex talk a lot about AI oversight, and how it’s being woven into the systems Experian uses for everything from risk assessment to predictive financial modeling. But the AI systems themselves are inherently risky — they get things wrong, they hallucinate, they might make incomplete or incorrect conclusions about very real human beings in ways that drastically affect lives.

So I really dug into how Experian sees AI technology being used internally and within the broader scope of credit reporting. And I also pressed Alex on the capability gap between what AI might be able to do today, what we think it can do or what AI executives tell us it can do, and then the reality of what it actually does and how well it does it.

The stakes for this stuff are very, very high at a company like Experian, and more than just its reputation relies on people thinking it’s being a responsible steward of their personal data and that the institutions it hands that data over to are using it to make responsible, fair decisions.

This was a really in-depth conversation about a really knotty set of subjects, and I really appreciated Alex’s willingness to get into the complexity with me.

Okay: Experian CEO of technology and software Alex Lintner. Here we go.

This interview has been lightly edited for length and clarity.

Alex Lintner, you are the CEO of Software and Technology at Experian. Welcome to Decoder.

I am very excited to talk to you. There’s a lot to talk about. Experian is a fascinating company. A lot of people have a lot of feelings about Experian, which I want to talk to you about. Every company that comes on the show lately, every executive tells me that they’re an AI company. I think Experian wants to be known as an AI company. We’re going to get into that. Why don’t you tell me what you think Experian is today and what it has been and what you think it should be in the future?

Experian is a global data and technology company. We help consumers and businesses to make financial decisions and protect their data and identities. On the B2B [business-to-business] side, we have four verticals: financial services, healthcare, automotive, and marketing services. On the D2C [direct-to-consumer] side, we provide consumers with information that helps them understand, protect, and manage their financial lives. So we help them build credit and qualify for their next desired loan.

My favorite example is they’re getting their first mortgage, which is a hard thing to do in America, but a major wealth builder for Americans. We give them access to comparing financial products so they can lower their borrowing costs. We protect them from fraud and identity theft, like I mentioned earlier, and we help them save when they buy car insurance. So that’s Experian to me.

This is going to be very reductive, and I’m saying it on purpose because I’m curious if it really is this simple or if there’s more complexity there. That sounds like Experian maintains a big database of information about people, mostly about their credit.

When you say it protects that information, that’s because having all that data is very important and very powerful and very valuable, but it’s also the information that mortgage lenders use. It’s the information that car insurance brokers use. How do you think about the core product? Is it just a database or do you think about it differently?

Maybe we should back up a little bit. If AI is a platform capability, it’s not a feature. We use AI primarily to help embed governance, help explain ability — which is required by law and desired by the consumer — and to actually facilitate human oversight.

When you then back up into where we came from and your question at the core with all the data that we hold, from a technology perspective — and I’m the tech guy, so I’m going to talk about the technology — that means that we apply data analytics and AI into the hands of decision-makers. And those can be in businesses, financial institutions, and mortgage companies like you just said, but we also supply it to the consumer directly.

And the objective is the same. The objective is to turn complex data, complex information into easy-to-understand, actionable guidance so that either the lender or the consumer can make a confident decision. That’s the objective. You need the same data for that and both sides need to see it because the data is the objective truth and then the consumer can make a decision and the lender can make a decision, if you’re talking about financial services in particular, which you’re examining.

I’m way at the bottom, I’m at the primitives here. The main thing is a big database of financial information about consumers and their credit history and their ability to pay for things. Is that the main thing or is there another core element of the product?

It’s a core element. I think you’re overemphasizing the financial information. Financial services is one of the sectors, but like I said earlier, we have a lot of other information that is useful, that has nothing to do with the core lending information that we have. For example, the history of people’s lending behaviors. And the other information is just as useful.

If you look in the automotive vertical, for example, we have an equivalent to CARFAX called AutoCheck. It has vehicle history, ownership history, maintenance and repair history, accident history. So there is a lot of other information that is actually relevant for these decisions. It’s not only the financial information that we have about people.

And by the way, when people say “financial information,” often it’s interpreted as we have account numbers, et cetera. We do need account numbers to match the accounts to people, but it never goes out. And it’s double encrypted, so super protected. We don’t use any of that information for any of the services that we provide, except for the pinning so that we can match it to a person.

Can I offer you my feature suggestion for AutoCheck? I do a lot of idly shopping for cars I’m never going to buy, and I love feeding the AutoCheck report into ChatGPT, and then ChatGPT tells you a little story about the car. If you find a particularly sketchy AutoCheck report, it tells you a story about how the car was obviously stolen and is being laundered.

I’ve got to try that. That sounds like fun.

It’s a good time. If you’re holding a crying baby and you’re like, “I’ve got to sit here for another hour,” it’s a very good way to spend the time.

I just had my third grandchild and she’s two weeks old, so that’s actually very, very current. I love holding her and now I know what to do while I do that.

I’ll send you some specific models of cars where it’s like all of them are stolen for some reason. It’s very good.

The reason I keep asking about the database is that I have a thesis for 2026, that maybe what we’re all discovering is that all of our lives are captured in databases, that there are these huge stores of information held by various companies, held by various governments, held by various agencies inside the government.

Maybe what AI is going to do is make those databases more legible. And maybe what it’s also going to do is make the holders of those databases far more powerful, right? Because you suddenly have more access to the data, you can use it in different ways, you can connect all these databases in different ways.

I hear this pitch from a lot of people. You have the biggest database, right? Experian is one of the most powerful databases in American life. So there’s a reason I’m starting with that. I’m curious how you think about that power, as it becomes easier to express that power, it becomes easier to share the contents of that database with people, and it becomes easier to query that database. How do you think about that responsibility at Experian?

It’s a giant responsibility and we take it very seriously. There are a couple of aspects to that. Our business is based on consumer trust. Once the consumer starts losing trust, the brand goes nowhere. Investors start losing faith and everything goes down the drain. So if we don’t do that part of our business well, there is all the other stuff that I could talk about — and then maybe we’ll talk about that in a little while — it goes away.

You talk about it as a database. Nilay, the way I would talk about it is that our largest businesses are on modern cloud-native and AI-enabled platforms. And these platforms that let us securely ingest massive amounts of data, like you’re saying, in real time, then apply advanced analytics and machine learning while we keep privacy, consent, and security at the center. That’s how I think about it. The database as a function has morphed into data lakes and then now I would refer to it as a platform.

I start with the last part that I talked about. So keeping privacy, consent, and security at the center. What you really need to think about is, how do you do that? And how do you do that better than anybody else? And how do you do that in light of the fact that the bad actors know everything that you just said? What you just said is we’re one of the largest data companies in the world and therefore we got a lot of information and bad guys like information. So to keep it secure, you need to have a — I’m going to call it a bulletproof setup, from front to back, of every application.

Most people talk only about encryption, but it goes way beyond that. It goes to access rights. I named that consent earlier. It goes to, how do you store the information? You can shorten it, which I really like. Break it up. So when people find Nilay’s information, they find maybe only your first name, not your last name. They maybe find your street address stored somewhere else and your account information stored again in another place. In other words, if you break it up into 25 shards, they’d have to break 25 encryption keys, know how to pin it back together to one individual in order to really understand Nilay. And that’s complicated.

So the game is we need to have security systems that stay ahead of the bad guy. And we need to have at the core of our mission, the core of our purpose as a company, that every employee needs to act to a purpose that says what I now say for the third time: keep privacy, consent, and security at the center of everything we do.

Let me ask you an existential question about that: What if I don’t want you to know me? I mean, what we’re talking about is you’re collecting a massive amount of data on regular people. I think I hear from our audience every day, “Why is this happening to me? Why do these companies already know so much about me? How come when I use my loyalty card at the grocery store that gets meshed up with a bunch of purchase data on Instagram that gets combined with a bunch of data? Why is my phone listening to me?” That is basically the end result of that.

I’m like, I don’t know that it’s listening to you. I think there’s a lot of data about you that makes it appear that the phone is listening to you and that is more scary and less legible than “the phone is listening to you.” Have we opted into Experian? Do you think about that level of, maybe we should ask everybody if we want to be tracked in this way or track as many people as we do?

I have two answers to that. So the first answer is privacy laws are such that you can opt out anytime. So if you, Nilay, don’t want your information stored, you can do that. You could do it on your phone so it doesn’t listen to it and you can do it with us. The bigger answer I have is the following. And this is based on research, this is an absolute truth proven over many decades, and that is that prosperity in an economy, prosperity for a family and prosperity for an individual is strongly linked to access to credit. In other words, you can look at countries that don’t have access to credit like we have here in America, and you can see that their economic evolution lags behind that of the United States.

You can look at families where maybe the parents didn’t have access to credit and therefore they couldn’t do what now their children can do who have access to credit. Or you can look at an individual on how fast they advance because credit allows them to pay forward their earning power and their ability to repay a loan and therefore make investments that then can be accretive to their wealth.

So put in another way, if a lender would not have information about an individual, Alex or Nilay, they cannot make a decision about whether they’re going to lend money for you. And let’s be clear, lending is one of the riskiest businesses there are. Let me describe it in the following way. I look at you, Nilay, and I ask you a couple of questions about, “Hey, have you had a couple of loans before? What do you want to do with the money? How are you going to pay me back?” And then I decide whether you’re a good guy, worthy of getting this loan or not.

If I give you the money, at that point, I’m at risk because the money leaves my account, the lender’s account, goes into your account, and you can do with the money as you please. It’s a very high risk business. The lender needs to have the information in order to make the decision. You, the consumer, need access to credit because it will advance your standard of living, your quality of life, and your wealth creation. So privacy laws allow you to opt out, but it is actually in your and the consumer’s interest that you make the information available for lending.

One of the questions I have about that — and I think, again, this is going to be a theme of 2026 in our coverage — is that AI enables these things to happen at a different kind of scale. Because you can automate the systems in different way, you can query the systems in different way, you can extract value from the data in different ways. And I wonder… I agree with you, right? Lenders need to mitigate their risk in some way. They need to know who they’re lending to. They need to manage whether or not they think they’re going to get paid back.

But being able to do that at scale and saying all of these should be centralized stores of information and not more local… It’s my local bank and my local community that needs to evaluate my risk profile. There’s something about that scale that feels different, and obviously Experian enables massive scale. Do you think your responsibility is different with scale?

That’s a really interesting question, but I’m the tech guy here, and from a technology perspective, I don’t want to make a sort of macroeconomic or regulatory statement. From a technology perspective, it’s definitely true because if you have scale, you hold more information, and as you hold in more information, you need to deal with it responsibly. And again, it gets me back to those three tenets. We need to protect privacy, consent, and security. And if you have more information, you better do it really, really, really well.

To get back to your local or national or global scale — first of all, there are very few global financial players. So let’s start there. We can probably count them on two hands. And even then, I know those companies from the inside, they don’t always act globally. They often act locally. I don’t want to name any names, but large international banks born in Europe, large international banks born in New York City where you’re at, they have an American business strategy and then they have a British and Australian business strategy. It’s actually different and our models are different and lending criteria are different and the lending products are different. Global presence is rare.

Now, let’s talk locally versus nationally or super regionally. In North America, we have the good luck that we have 7,000 financial institutions. That is a model that’s unique in the world. We don’t have that anywhere else. And if you go all the way from the top to the bottom, at the bottom, you would find these credit unions. And credit unions are typically very local, though there are now large ones like Navy Federal Credit Union. You’re familiar with all of those that serve the armed forces everywhere, or USAA which serves members and relatives of armed forces members for insurance and banking around the country.

There are some exceptions, but largely credit unions are very local. They do not have access to capital like the large super regional or national lenders have. And access to capital is important because it is a volume game. The more you buy capital as a reseller, which is what a bank is, the better the terms you get. And therefore you have the potential of offering better terms to your borrowers, to the consumer. And therefore, I think the mix of local and national is a good mix. It has worked here in the US.

It’s definitely worked to make the cost of capital come down in various ways, although who knows what’s going on right now. Every day it could be different, but I think my question is—

It’s less predictable than it’s been in a long time.

But I wonder if the trade-off is a feeling of disempowerment for the actual consumer, right? And that’s one of those hard trade-offs. Yes, there are some privacy laws in the United States. There are not very many, right? Yes, there’s some recourse against a financial institution or if there’s a data breach, but there are not many. And so I’m just interested in that trade-off and your perspective in that trade-off.

I will say that you have perfectly teed up the Decoder questions because you described the structure of multinational banks, because Experian’s org chart to me from the outside is bananas. Straightforwardly, there’s Brian Cassin, who is the CEO of Experian, then there are CEOs of regions. So there’s a CEO of Latin America, one for North America, and then there’s you, and you are the CEO of technology and software. So explain to me how that all works.

All right, let’s get into that. So the way we work is that we are a federated system, and it’s not unusual. Maybe our titles aren’t super intuitive and don’t explain it, but let me try to explain it. You have central functions where everything is the same regardless of where you are in the world. Think of finance, think of HR, and think of technology. So you want to have technology standards, you want to have security standards that you apply everywhere in the world.

There are economic reasons for that. You don’t want to have a slew of vendors. You want to have golden pathways. That is what keeps everybody secure, and that’s how you manage consent, and that’s how you manage privacy. And all of that should be done in the same way so that we have control over it. Our governance can look at it. Auditors can look at it because we are auditable by the SEC, and they all can say, okay, we apply those standards the same way, regardless of where you are in the world.

Now, if you look at the context — call it the economic context, call it the socioeconomic context, or how much do people make, et cetera, et cetera. That differs everywhere in the world. It differs whether you’re in the United States or my native Germany or India or Australia. We’re active in all these countries and the context is different. And therefore our go-to-market oriented business units, they have CEOs that look over the region, understand that context real well, and then the product is applied appropriately for that country.

And by the way, regulation varies. We do have to adjust some of our security and privacy dials to comply with the country-specific regulations, and that’s why we have the matrix function. Some central functions look at achieving scale, look at achieving clear governance, doing everything the same way, and market specific to the consumer needs. The context is specific to a specific country. Our region, that’s how you should think about it.

I have a direct reporting line of 4,000. We have 11,000 technologists. So think of my function, 4,000 on my direct reporting line. They roll up to me.

I was going to say that 4,000 direct reports is a little over the guidelines, I think.

In my direct reporting line. So all the way down.

I have seven direct reports and then it goes down. The other 7,000 are in technology organizations. I still set the standards and the policies, our technology policy that everybody needs to work by, but they’re not in my direct reporting line.

And is that structured so it meets the needs of the regions or how does that work?

We’re trying to walk that fine line exactly like I explained. My job is to build a backend that is superb, make our platforms the most secure and least expensive way for us to deploy software to our customers. And the regions and the business unit’s job is to build products that respond to consumer needs. And there are functional needs depending on the use case — that’s the business unit — and there are regional needs that are based on the context that I just talked about that can vary by country.

It’s working well enough, but we’re evolving. We’re growing as a company, which is a nice thing to do. And I would say — I’ve worked at other large corporations, as you know — the pendulum swings. Sometimes you do things a little more centrally, sometimes you do a little more locally, and you always reevaluate and see what’s working. In the AI world, I would tell you doing more centrally is probably a good idea because like I said earlier, I think about AI as a platform capability, not a feature, and therefore you have to have that capability everywhere and you have to allow reuse of models and you have to govern it very carefully. And I think doing that once rather than 23 times in 23 countries is a good idea.

It does seem that whenever there’s a technology shift, the push towards centralization appears. “We need to get a hold of this. We need to understand how to use it and we can spread it back out to the divisions.” I’m just curious, you describe yourself as a provider of backend solutions. That’s your job. Your title is CEO. Do you think of yourself as the CEO of an infrastructure provider inside of Experian? Are you a vendor to the other divisions?

Well, think about it this way. My title is CEO for Experian Software and Technology. The Software stands for all the software we sell to our clients. On that side, I’m in charge of what the product looks like. Is it evolving the way it is? Do we have competitive advantage versus everybody who competes with us? And the product needs to be the best. Certainly we try to always be the first or the most innovative, the first, best, and, in some cases, only product that can do what our products do. And that’s how we make money, that’s how we grow those businesses. It’s a typical market-going role.

The other part of my title, Technology, stands for our technology infrastructure, and that’s a little bit of what we have talked about so far. That’s empowering all the business units with all the services that they need. And we do have platform builds. The way I think about it is, we want to apply data, analytics, and AI into the hands of all of the business units that build our product. So the question is, what can I build centrally that enables them to do that faster so that we can stay innovative and they can stay innovative?

So you have shared data foundations and shared backend services. You have modular services that people can use. And then you have AI models that could also be reused if they access the same type of information. Typically, that’s appropriate when it’s depersonalized information, not personalized information. And that saves us then from building — if you put the three together, so there is a shared data foundation, backend services, modular services, and AI models, you then don’t have to build one-off apps anymore, but you can reuse a lot and focus on the feature functionality that’s specific to that industry, to that vertical or to that country.

One more question here, and then I want to ask the other Decoder question. You mentioned the divisions making products. Do they have their own engineers, designers, or is that all in your group?

So 4,000 plus 7,000 equals 11,000. Of the 23,000 employees that we have at Experian, 11,000 work in technology organizations. 4,000 work in the central group that’s mine, and the other 7,000 work in the business units.

So how do you align those roadmaps? You can very quickly see how you might have one division working in one product that another division is also working on, and that is redundancy you might not need, or you might decide actually they need to be more different than similar. How do you align that?

I mean, that’s the work every day, Nilay. It’s not always easy. People think, “Oh, my division can build it better or faster or differently and therefore we should.” So we communicate. We have what we call a technology executive board, which I run. I’m the chair of that. All the CTOs sit on that and we disclose roadmaps. We talk about standards and make sure that once we have a standard defined, there is no rebuilding, then it’s all about reuse. So that’s our governance model in order to coordinate everybody, the technology executive board.

Tell me about that meeting. Just take me inside that room. Very, very few people will ever be in that room, right? Who makes the agenda? Is it you? How does that work?

I have a right-hand person, a group CTO, Rodrigo [Rodigues]. He works with the CTOs to say, “What do you think we should talk about?” And then he makes a decision on what’s on the agenda. It gets to me, call it a week before the meeting. I say, “Yeah, I like it,” or “I don’t want to talk about this. I want to talk about that.” He goes back out and then it’s sent to them so that everybody can prepare.

Everybody dials in. It’s a worldwide meeting; you know how complicated that makes early mornings for me because I sit here in Colorado and just because time differences go both ways, we try to do this in the early morning hours for California, 6:00 AM, 7:00 AM my time, and then everybody dials in. Altogether, I think we have 20 people dialing in. There are 10 CTOs and CIOs dialing in. And then there’s our CISO on that meeting, our risk officer is on that meeting.

We have some people who drive specific topics. So for example, the person who drives our AI initiatives and coordinates it across the company, et cetera, et cetera. When we did the cloud migration, we are at the tail end of that. There was a person on the call who was responsible for the cloud migration. They’re all high-level people that I’m going to call it an expensive meeting with real decision-makers. The meeting lasts about three hours and we have it monthly.

This is going to lead right into the next question. Tell me what the spiciest thing that you had to make a decision on was in that meeting?

Well, there are so many. Spicy is when it comes to enforcing a standard where people need to maybe decommission a tool that they love, decommission a tool that their developers love, decommission a tool that’s embedded in all the customers. And then adopting the standard means of migration at a minimum for our internal technology teams and maybe even for the clients, because it becomes an effort that takes time. It becomes an effort that costs money. It becomes an effort that clients don’t like.

And therefore making such a decision is long contemplated and requires detailed plans, because you don’t only need to think about, well, is it the right standard or not, but what are the consequences, the secondary and tertiary consequences of the decision? That gets spicy. And we’re not an autocratic organization, so we err on the side of letting everybody speak their piece and hearing everybody out. And if that takes several meetings, then we let that happen. But at the end, we all align, even those who would have preferred a different decision. Those are the spiciest of all decisions. And there are many examples.

And it’s always migrations. It’s never anything but migrations. It’s lurking in the background of every company. This is the other question I ask everybody who comes on Decoder: You’re describing the kinds of decisions you make and the manner in which you make them. How do you make decisions? What’s your framework?

I think God has given us two ears and one mouth because we should listen twice as much as we talk. So as a leader, what you need to do is hire world-class teams and people who are better at what they do than you are, and then you need to let them do their work and you need to let them speak. At the end of the day, I try to surround myself with people who can scrutinize what people have in their brains and what’s being shared. And if they come to a consensus, I usually go with the consensus. You can probably count on a couple of fingers how often in a year I will go against what that group of CTOs would want to do. And if that happens, it is usually because I refer to a principle that they did not take into account and I try to be a principle-based leader.

I have a clear hierarchy of how I make decisions. I talked earlier about privacy, consent, security: those are at the top of my list and it’s not always the most economic decision, and therefore my CTOs might suggest something that makes more sense from an economic perspective, but maybe isn’t as tight from a security perspective. And then I veto it and I say, “Well, we’re going to pay the extra money and we’re going to do it anyway.” But it happens very, very rarely because people know the principles that we work by.

So if you have clear principles, you listen to people, you surround yourself with strong people, you make room for a debate that is open, transparent, and very inclusive. Everybody can speak. There is no hierarchy in the room. You take your time for it and then you make the best call you can with the information available.

Let’s put this into practice. Let’s talk about how AI might be changing your business and what you’re doing. The foundation here is that even the idea of the credit score is relatively recent. This is a creation of basically the late 1980s and a lot of people can have a lot of feelings about their credit scores. I would say Experian, TransUnion, Equifax, you can have a lot of feelings about whether or not those companies are responsive to you if you have feelings about your credit score and where they come from.

In a world of AI, you have vastly more opportunity to make something richer in the data because you can query it differently. You have vastly more opportunity to collect information because you can ingest more unstructured information and provide predictions. And then you have vastly more risk because the models might hallucinate the data or they might reflect some underlying bias in the data set as a whole. Or you might have huge security problems as we build out how the AI models might talk to each other in databases. How do you evaluate all of that risk and still be trusted as Experian? Because that seems like an awful amount of new risk as the technology shifts.

Nilay, a great question and really perfectly articulated. Let me give you two answers to that. One is just explaining how we think about the credit score. You called it relatively recent from the ‘80s. So if it’s okay, I’m going to provide a different perspective to that. And then I’m going to talk about just how we apply AI.

Let me start first with the history of our company. We have a guy in our history, his name was Sy Ramo, an Indian immigrant into the United Kingdom and he ran a large merchant store. He sold everything between Nottingham and Birmingham there in the Midlands of England. And he had a big heart. And one of the things that he did was, when there were people who he knew well, he did give them drugs, pharmaceuticals on loan. They came and said, “Look, I’m sick. I have this. I can’t pay for it. Can I just have the medicine so I can get better and I’ll pay you in the future?” And he trusted and did that.

Then his immediate relatives, people he knew well, told other people, “Hey, Sy Ramo does this.” And then people started coming who he knew less well. And he said, “Well, who are you? I know your brother or your employer or this or that person.” And he expanded it. Fast forward a bit, there was a line outside of his general merchandising store with people who he didn’t know anymore. People coming to him because he had a big heart. He gave away pharmaceuticals, drugs without any securitization. And he was a smart man. And so he started writing down on paper what the attributes were of those people who he gave drugs and pharmaceuticals to, who paid him back and who didn’t.

And that, to me, to us, was the beginning of credit scores. He just looked at how people behaved and what people had in common who were good loan risks, because he gave away the pharmaceuticals without having money in his hand, and who were bad lending risks. That is part of how our company started and that’s still how we practice our business. If you understand how people behave, you don’t have to know their age, their gender, their ethnic background, their sexual preferences, all the stuff that’s written down in law anyway. We should all think about that and our business should work like that.

There’s plenty of regulation that stipulates that it is. That’s our very heritage. You look at people’s behavior. What we do with the data is that usually the data is depersonalized, because what I just described, you can do that without knowing it’s Nilay, it’s Alex. You don’t have to know you live in New York, I live in Colorado, you don’t have to know your background, my background, you just look at how we behave. It’s depersonalized data on which all those services are provided.

Then let me move to the second part of the question, which was about AI. And you implied in how you asked the question that there is access to that data. So let me first say, our data is not accessible by any public AI or gen AI models. And we currently don’t see a way that we’re going to go there. What we use AI for primarily is to make sure that governance is done correctly, explainability is provided, and human oversight is better than it was before. Let me give you an example. The way that financial services are creating their products is basically through a model. The model says, “I have this loan product and I think the acceptable risk is this type of person that behaves in the following way.”

Our data feeds that. It can be the credit score. It can be where you reside, if it’s a local or a regional bank, it can be your lending history. Do you have the capacity to take on another car loan? It can be your income. Has it increased over time and therefore is it projected to continue to increase? Et cetera, et cetera. There’s a whole bunch of data that goes into those models, none of which need to know whether it’s Nilay or Alex or who specifically we are. It’s all about, do we fit that model? The lenders need to file what those models look like and how the models are supposed to behave, meaning what kind of person qualifies, how many loans do they think they have, what would the loan losses be with the regulator?

So they do that, they develop the model, the lending product goes out, people start applying, the bank starts paying out the loans, and then loan losses start coming in. People start missing payments. That’s the model behavior, because there’s a prediction of how much of that will there be. If those variables come off, the industry term for that is “model drift.” Maybe the loan losses are higher. Maybe we’re not getting as many people of those age groups. Maybe late payments are more than we thought. All those kind of metrics, it’s called model drift if it comes off. We use artificial intelligence when those models drift to prompt the person who has created the model, or the oversight department in the financial institution, that there is model drift.

Not only do we tell them that there is model drift, we also tell them what variables in their model are the reason for the drift. You’re missing a data element, you set it too low, you set it too high, you need to open your funnel to people with lower credit scores, and then we allow them to adjust the model so that it behaves the way that they had filed it with the regulator. What I’m trying to tell you is that it’s not that we use AI to access all of the personal information of people. We use AI to look at outcomes, derive the data, and interpret that, and then make it available to humans so that they can use it in the way that it needs to be done in the example, so the human oversight of model performance.

By the way, that happens today, but it happens with slews of people, not automated, not real time, not as accurate as AI can do. And so we think there’s a real improvement of the process there because it makes lending fairer, more accurate. It allows the lending products to behave the way that the regulator intends them to behave, and therefore it’s AI for good, just like we try to make data available for good. And that’s important for people to understand. A data company like ours, like I said, currently I cannot see that we make our data accessible to any public AI provider and therefore let them build their large language model based on our data. By the way, the large language models are much better at text than they are at math.

This was going to be my next question. You’re describing a lot of math. My experience with every LLM is they’re pretty bad at math. Are you using LLMs? When you say AI here, are you using a different kind of AI?

No, LLMs. We’ve built our own large language model, we built SLMs, small language models for smaller tasks. We have about 200 agents built into our products already now. There are different ways in which we use AI, but yeah, we built an LLM based on information we have.

But when you’re calculating model drift, that’s an LLM doing it, or what kind of technology is doing it?

Yeah, that would be a small language model because basically what the model does is, it reports out what’s happening and just one number is smaller than the other. That’s not math. It doesn’t do the calculation, it just recognizes it.

We wrote an entire story about how ChatGPT can’t tell time. Sometimes one number is bigger than the other, it’s actually quite difficult for these models. Or increments are actually quite difficult for these models. You think that’s trustworthy? I’m asking you very directly because the problems of hallucination here compound, right? They get exponentially worse as you add more and more AI tools to the system. The problems of reflecting biases in the data get exponentially worse as you add scale, as we’ve talked about. How are you making sure the AI systems aren’t either hallucinating or reflecting an underlying bias that you can’t see?

Human oversight through data scientists. I think we’re too early in the journey that we can let it run on its own. We need to all practice responsible use. For a data company, it means we lean on some of the strongest human assets that we have, and those are our data scientists. They need to look at the output and they need to look at whether it’s accurate or not. And if it’s not accurate, we turn it off and we fix it. Or if it’s not fixable, we would throw it away. We haven’t run across that, by the way, but we would do that.

Have you run into this situation yet where the data scientists have said, “We can’t use this tool yet”?

Oh yeah, because we test everything before we put it in production. So it happens all the time. Nothing goes into production without going through that kind of process. We have synthetic data and we have depersonalized data that we use for testing new models, new agents, and we don’t put anything into production until we know it works. Nobody should, right?

That makes sense to me. What’s been the biggest gap between a capability you want an AI system to have and the one that you tested? I’ll give you this example. I think of Siri and Alexa and Google Assistant, right? Everyone knows what they want them to do.

And then I’m watching all of these companies try to add AI into the mix with their voice assistants and they’re not there. They just can’t quite do it. And Apple had to start over and Google is pushing out in stages and however that’s working, it’s working. What’s been your experience of, “Okay, we’re going to ship an AI tool and we want it to work this way, but it’s not quite good enough”?

I think it has to do with the interaction of AI with humans. The way I look at AI, and I think a lot of people do, is it’s a digital teammate or a digital workforce. So if it is that, then that teammate or that team would perform a certain task and it would contribute to the work of the overall team.

So we assume, hey, if we provide the following information to a team, to a person as an assistant in their workflow, they’re going to use it that way and therefore it’s a good thing. Well, we’re not always right. I sometimes compare it with — I drive a Mercedes car and I can talk to the car and it has a map that I can talk to and say, “Hey, Mercedes, tonight I’m seeing the Colorado Avalanche play hockey. Take me to the Ball Arena in Denver.” And so it will put in the directions from where I’m at and I will be taken there. I got so used to the tool that I now listen to the tool all the time. Though I know the area really well and sometimes it doesn’t give me the right route.

No, it’s not a good outcome and that is the outcome you want to avoid. It’s the answer to your question. If you trust AI to the point where you blindly trust it and always follow it, and you don’t check yourself through the data scientist in the example that we discussed a couple minutes ago, it bears risk. So the real job that we have is to make sure that doesn’t happen and the interaction with the human still happens. You can force it in rather than AI automatically doing what it does.

We’ve had [CEO] Ola [Källenius] from Mercedes on the show and I think he’ll be happy to know that you’re the single customer of the Hey Mercedes voice assistant in his cars, because I’ve been dying to know who else is using this thing.

In my car, I can turn on the lights, I can turn on the radio, I can switch radio stations, I can turn on my seat heater. You tell him I like it.

The next time he’s on, we’ll be like, “We found one.”

Let me ask you, this is going to be the hardest question. When I hear from our readers, when I hear from people about what AI might do, the idea that a company like Experian can make decisions that affect their lives using AI is terrifying. There’s not a lot of hope when people think about this outcome, that there’s an all-knowing AI that can generate scores about you based on your behavior and allow other people to make decisions.

And we see this in countries like China, where there are reputation scores, there are other kinds of centralized data providers that very directly affect people’s lives. You’re in the position to do that. So I’m going to ask this question in two parts. First, do you think people like Experian today? Do you think you have the foundation to build this next generation of products?

First of all, we’re not Palantir, so we don’t do reputation scores. We are very much in, like I said earlier, financial services, healthcare, automotive, and digital marketing. So that’s where we play. And I think I answered that question earlier. Why is it in the interest of people that their data gets used? It’s so that they get access to credit, access to healthcare, so that they know the vehicle history of the car they’re going to purchase, et cetera, et cetera. We try to use data for good. We do not make decisions. You used this phrase, “do you think people are comfortable that Experian can make decisions?” We don’t do that. We provide information.

You provide the tools that allow others to make decisions. Sure, I understand.

That’s right. To lenders, yes. They will make a decision anyway, won’t they? I told you the story about Sy Ramo, who is long gone. He made decisions. People will make decisions about you and about whether they lend to you. And the more you have to do that at scale — In North America, we have 247 million Americans. If you want the economy to blossom, if you want people to have access to credit, you need a scalable model.

I’m not saying that our system’s perfect, but you can draw a worldwide comparison and you still have to say it is the best credit economy in the world. It really is. And there’s lots of stochastic data around it. We are part of that connected ecosystem. We’re not all of it. We are part of that and we try to perform our role within that connected ecosystem responsibly and the best we can. If somebody has an idea on how to make it better, we’ll be first in line.

Sure. But let me just try it again. If the answer to the question, “Do you think people like Experian?” is, “We’re not Palantir,” that sets a very low floor in a very specific way. You’ve talked a lot about trust. I’m saying right now, the way individual Americans encounter the brand of Experian is not always positive. And in many cases, it’s a faceless entity that controls a downstream decision that yes, a financial institution’s making, but the recourse is low.

This is the trade-off we’ve been talking about with scale this whole time. AI might allow you to change the amount of recourse people have. It also might allow, I don’t know, a bunch of bad guys to launch ever more sophisticated attacks and get that data out. There’s more trade-offs here than not. So I’m just asking about the foundation of trust that you’re working with to begin with. Do you think enough people like and trust Experian for you to build this next set of capabilities, which might make you even more powerful?

I think enough people do. Let me maybe answer the question not with one sentence, but be a little more granular. I could point to data of the consumers who give us their data. So we have a direct-to-consumer business, and in the various countries that we are active with our direct-to-consumer business, we have hundreds of millions of consumers who proactively make their data available to us. We protect their identity. We do everything that I described earlier. We give them access to comparing financial products so they can lower their cost of borrowing. We give them access to lower cost car insurance, et cetera. And those consumers like us. And I know that because we ask them and we get a net promoter score and we look at that religiously every month to see how we are doing. Are we doing right by all these people? Et cetera, et cetera.

Now there is another population that may not have that relationship with us that have, through life’s circumstances, a bad credit score, and those people sometimes don’t like us. And I want to make it really personal, Nilay, Alex was one of them. I’m an immigrant. I came here just about exactly 30 years ago and when you’re an immigrant, you don’t have a credit score. You don’t have access to credit. Life’s really hard. Really, really hard for us immigrants in the beginning years. And I wish there were a system that the law would allow to make life easier for people like us, but there isn’t. And my life became difficult because I wanted to stay here. I went to school here, that’s initially how I came here, and then I wanted to stay here and get a job and all of that. And if you don’t have credit, you’re riding public transportation to work, et cetera, et cetera.

I had an hour and a half commute for years and years because I couldn’t afford a car, couldn’t buy the car because I didn’t have enough cash. Life’s hard. And in those situations, there are much worse stories than my personal story, but I just want you to know I’ve felt it before. What we try to do is we try to do away with people having low credit scores by giving them tools to improve their credit score. The way that the initial formula was written, it allowed for all recurring financial transactions to become part of the score.

I don’t want to pick on our competition, so I’ll phrase it this way. We’re the only ones who allow that. Credit bureaus, other credit bureaus, they only take lending history. So have you had a loan before taken into account? Well, there are other recurring financial payments, your streaming service, your cell phone bill, et cetera, et cetera. There are so many payments that you make, your utility bills, that you make every month and if you make it reliably every month, that should be part of your score and therefore increase your score.

We’ve created a system called Boost, Experian Boost, where people can upload that information and their credit score goes up. So they don’t have to go through that period that I did because I did rent an apartment, I did pay all my utilities, et cetera, et cetera, and I wanted to have access to credit. So we tried to lower the hurdle and therefore have fewer of those people who are impacted by life circumstances. I don’t think people don’t like Experian. They don’t like what that score expresses at the time. And if we have issued it to whatever lender they talk to, then the finger gets pointed at us.

Sure. I just think there’s a feeling of helplessness that comes with that score sometimes, right? There’s a feeling of lack of recourse, particularly if you feel that score is wrong, right? And that’s where I think a lot of the —

Well, sure. But Boost is like an interesting set of incentives, right? For you, it’s a product you sell. It might help some under-banked or low-credit people immediately —

We don’t sell it. It’s free. We don’t sell it. We provide it for free because it’s the right thing to do. It’s free for the consumer, it’s free for the bank.

I didn’t realize it was also free for the bank. I assumed the bank paid. So there’s no economic incentives for Boost at all?

No, no, no. It’s the right thing to do because what you’re pushing on, Nilay, is you are expressing in your own words what kind of company we are. I would probably express it differently, but directionally, you’re describing it right. When you’re in that business, you need to have a really clear, ethical compass on how you conduct business. We have that at Experian. Boost is an expression of that. Let’s help the consumer get it right. Let’s help the consumer fix their score if the score is wrong. It’s not okay if the score is wrong because it makes life really difficult. And therefore we have provided the mechanism to do that.

By the way, for that, you need a real-time bureau. We’re the only real-time bureau in the world. Nobody else is real-time. Your delay at other companies is 30 days. So if they had a functionality like that, our competition, you put in your information, 30 days later, you get your score updated. It’s useless. We built it in real time. You put your data and it changes right then and you can go back in the door, not that people still go to the branches, but back in the door, talk to the lending office and say, “Hey, take a look at my score. It’s not what it was 10 minutes ago.”

I’m curious about that because again, there are the trade-offs as you attract more scale, as you provide more products, as you use AI to build even more scale. Down at the bottom, the individual consumer, the thing I’m pushing on is, will they feel more recourse or more control or less? And over time, I would say increasing centralization and scale in the economy has led to feeling less empowered.

I’ll slightly change the subject here because I want to end on security. You have a lot of data. I know you’re moving a bunch of your data to AWS, you’re moving to the cloud that will help you with security and in some ways it’ll help you with AI in other ways.

Sometimes the only way people hear about companies like Experian is because of data breaches. Your competitor, Equifax, had a massive data breach. How do you think about that? “As we collect more data, we’re a much richer target, and then the bad guys are going to use AI to launch automated attacks”? We’ve seen the studies from the frontier labs already. It’s like this is going to start happening.

That’s another place where the consumer basically has to trust you, right? That’s just how it’s going to be.

How do you think about the cost of mitigating against the increased attack surface of your scale, the increased capability of the attackers, and all of the products that you want to provide to people?

It’s the first dollar we should spend. If we don’t do that well, we don’t have a reason for existing because a bad actor will go in. Just to say it for a second, I’ve been here 10 years. The last time we had a breach occurred two weeks into my tenure at Experian, so 10 years ago. We are in a business where we actually protect the identities of people whose identities were stolen because we have access to the dark web, we know how to clean it up. When Equifax had their breach, they paid us to protect the consumers whose information was stolen.

So I’m not saying we’re perfect at it, but we’re pretty darn good at it, so good that even our competitors give us their business. It’s job number one, Nilay. There are no two ways about it. That is the biggest risk in this sector. That is the biggest risk for anybody who has a business similar to us. It’s the biggest risk for us and therefore it’s the first dollar we’re going to spend.

When you say first dollar we’re going to spend, do you think about that in terms of return on the investment specifically or just “This is the enabling cost of all of the other investments we’re going to make”?

This is the enabling cost of all the other investments we’re going to make. So I’m going to buy all the tooling, I’m going to hire all the people that we need to keep us safe, we’re going to deploy the technologies that do that the best, and we’re going to try to stay ahead of the bad actors who do deploy AI, who do, now, as you said, use bots to get in. We bought a company called Neuro-ID, which detects bots in a much better way than anything else that we have seen and banks are eating it up. There’s an economic incentive, by the way, to do that well because it’s a service we provide and we got to stay on it.

Experian’s a public company, obviously there’s some amount of pressure to deliver increasing profits. Enabling costs, especially big enabling costs, can come under pressure. Is that just you who has to defend it? Is it the ethos of the company? How does that work?

So if you show up and say “We need to double the cost of security,” it’s just going to be fine? Because I hear from our listeners who have similar situations as you that the incremental cost of security sometimes is hard to defend.

Not at Experian. I don’t know who you’re referring to, but not at Experian. And I will tell you this. The good thing about the business model that we have, it’s a scale model. We talked about scale a lot and you talked about the risk of scale, but the benefit of scale is, as you scale, there are some costs that are fixed, that are then distributed over a greater amount of business, and therefore you actually have natural scale benefits, meaning your fixed costs are a larger part of your total cost, the variable costs are a lower part of your variable costs.

So when it comes to security, what does that mean? That means if today we have 200 million consumers that give us their information and tomorrow we have 300 million, there’s not a 50% increase in security costs, even if I buy the leading-edge technology. And therefore our scale I think actually allows us to buy all the best tools, hire all the best brains in the industry to defend against bad actors.

Let me wrap up by just trying to tie all this together. I’ve talked a lot about the individual consumer. That’s a lot of our audience, people who build things, people who think about the kinds of products AI might help them build, the kinds of scale that you might operate at. Some people who just want the kind of scale that you might operate at, right? That’s the ambition.

As you see us go into this next era where there is more legibility of data — that’s what I would call it, right? That’s really what the AI that you’re describing will provide to financial institutions — how do you make sure that Experian actually empowers consumers, not just in access to credit, which is what you’ve come back to over and over again, but increases the feeling that our agency as individuals in the economy is going up instead of down? Because I would say right now, a lot of people feel like their agency in the economy is actually going down.

I don’t want to make any political statements, but that is... Unfortunately, I would say you’re correct with that. We try to have our own compass of what’s right and what’s wrong, and we try to empower consumers. So opting out needs to be easy. Opting back in needs to be easy. We have several ways of doing that. I was going to call it stages. So more severe [ways], like a credit freeze, that’s harder to undo, or to create a lock, [which is] easier to do and undo, depending on what happened to you, identity theft or not, or just as a precaution or just because you don’t like it.

So we allow you to lock your data away and we should make that easy. We should make that easy in whichever way you want to contact us, whether you want to do it online — which is economically better for us, it costs us less per interaction with the consumer — whether you want to call us. We have a call center with thousands of people. It is a US-based call center. A lot of people complain about, “Oh, I talked to a person in country X in an accent I couldn’t understand.” We don’t do anything like that because we want to do right by the consumer. We are, even in our B2B business, really it’s a B2B2C business, because at the end we affect our consumer, which is what you keep emphasizing. And we are very conscious of that responsibility and try to show it in how we continue to evolve our services.

Alex, this has been great. Thank you for being so candid. Thank you for being on Decoder. We’ll have to have you back soon.

Nilay, thank you so much for the invite. It’s good to talk to you.

Questions or comments about this episode? Hit us up at decoder@theverge.com. We really do read every email!

A podcast from The Verge about big ideas and other problems.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-49')">
            <div class="source">The Verge</div>
            <div class="title">Apple&#8217;s new AirTag has more range and a better speaker</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-49" style="display:none;">
            <h2>Apple&#8217;s new AirTag has more range and a better speaker</h2>
            <p><strong>The Verge | 2026-01-26</strong></p>
            <a class="original-link" href="https://www.theverge.com/news/867757/apple-airtag-new-uwb-bluetooth-range-speaker">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Five years after releasing its first AirTag, Apple’s giving it an upgrade.

Five years after releasing its first AirTag, Apple’s giving it an upgrade.

Apple has revealed a new AirTag that comes with the company’s upgraded ultra wideband chip, allowing for more precise location tracking. It has the same $29 for one or $99 for a four-pack price as the AirTag it’s replacing, while the new chip powers Apple’s Precision Finding feature, which uses haptic, visual, and audio feedback to guide you to items from up to “50 percent farther away.”

Along with more accurate location tracking, the new AirTag has an updated speaker that Apple says is 50 percent louder, as well as a Bluetooth chip that “expands the range at which items can be located. You can also use the Precision Finding feature with an Apple Watch Series 9 or later, or Apple Watch Ultra 2 or later, with watchOS 26.2.1.

The new AirTag is compatible with all existing accessories. Apple notes that the AirTag “doesn’t physically store location data or history on device,” while end-to-end encryption secures communication with its Find My network. It adds that the AirTag also includes measures to protect against unwanted tracking, “including cross-platform alerts and unique Bluetooth identifiers that change frequently.” Apple partnered with Google in 2023 on an industry standard designed to help limit AirTag tracking.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-50')">
            <div class="source">The Verge</div>
            <div class="title">As Marvel pivots back to the Avengers, Wonder Man goes its own way</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-50" style="display:none;">
            <h2>As Marvel pivots back to the Avengers, Wonder Man goes its own way</h2>
            <p><strong>The Verge | 2026-01-26</strong></p>
            <a class="original-link" href="https://www.theverge.com/entertainment/866197/wonder-man-review-mcu-disney-plus">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">﻿Disney Plus’ latest superhero series is dropping at a time when the MCU feels like it’s moving back to square one.

﻿Disney Plus’ latest superhero series is dropping at a time when the MCU feels like it’s moving back to square one.

When Marvel first announced that Avengers: Doomsday would be directed by the Russo Brothers and star Robert Downey Jr. as Doctor Doom, it seemed like the studio might be using the feature as a massive nostalgia play. Though the film will feature a number of characters from more recent projects like Thunderbolts* and The Fantastic Four: First Steps, the studio made a big deal out of revealing that Chris Evans will reprise his role as Steve Rogers. It’s not clear whether Doomsday will bring back even more actors from the original Avengers whose characters either died or aged out of the team. But the project feels primed to work as a kind of reset that could give Marvel a way to reintroduce familiar faces and pivot out of its meandering Multiverse Saga.

Those aspects of Doomsday’s story — which will continue in Avengers: Secret Wars — are part of what makes the timing of Disney Plus’ new Wonder Man miniseries feel somewhat odd. Like Echo before it, Wonder Man is one of Marvel’s Spotlight projects that the studio doesn’t consider required viewing in order to keep up with the MCU’s larger ongoing story. At a time when Marvel seems more focused on reintroducing familiar faces in epic crossover events, Wonder Man stands out as an almost entirely self-contained character study that zooms in on the life of a comics hero that many casual fans probably aren’t all that familiar with. But as unusually timed as Wonder Man is, it’s also one of Marvel’s most compelling shows yet.

Set in sunny Los Angeles at some point after the events of Iron Man 3 and Shang-Chi and the Legend of the Ten Rings, Wonder Man follows struggling actor Simon Williams (Yahya Abdul-Mateen II) as he sets out to book the gig of a lifetime. Simon is a talented performer who has been able to land jobs on major series like American Horror Story. But his tendency to overthink his roles makes it hard for him to find consistent work. When Simon is fired after giving a little too much feedback during a shoot, he doesn’t want his supportive motherr, Martha (Shola Adewusi), or disapproving brother, Eric (Demetrius Grosse), to know.

The news sends Simon’s agent, Janelle (X Mayo), into a fit of rage, but he’s confident that he can turn his luck around when he hears from disgraced actor Trevor Slattery (Sir Ben Kingsley) that a studio is rebooting Wonder Man — the classic (fictional, in-universe) superhero film that first sparked Simon’s passion for acting.

From the moment that Wonder Man first name-drops real-world entertainment like The Matrix and Twilight, you can start to feel the meta sense of humor co-creators Destin Daniel Cretton and Andrew Guest use to shape the series. In Simon’s bubble, people remember Slattery’s involvement in a bit of global terrorism, but they are much more concerned about what’s happening in Hollywood. That kind of tunnel vision makes it easy for Simon and his peers to believe that, after spending some time in prison, Slattery’s back in town and eager to find his next role.

Simon and Slattery’s shared love for the arts quickly turns the pair into unlikely friends who genuinely believe that they are both perfect for the lead roles in the Wonder Man movie — a cheesy sci-fi space opera that looks like a cross between Flash Gordon and Star Wars. Both men are shocked / elated when they receive callbacks for the movie, but Simon is uniquely concerned about what might happen if anyone involved with the production learns that he has been hiding real, innate superhuman abilities since he first hit puberty.

While Wonder Man (the series) doesn’t feature all that many firm connections to the larger MCU aside from Slattery, the show uses Simon’s powers to explore what life is like for “enhanced” but otherwise ordinary people who live in a world that has repeatedly been devastated by superhumans. Rather than worrying about violating the Sokovia Accords, Simon lives in fear of the Doorman Clause — a mandate barring superhumans from working in Hollywood because of the danger (and astronomical insurance costs) their powers might cause. He’d no longer be able to work in Hollywood if anyone knew what he could really do, and he would be imprisoned by the United States Department of Damage Control.

Though Simon’s super secret looms large in Wonder Man’s drama-forward story, the show is more about his relationship with Slattery and the psychological toll that hiding core aspects of one’s identity can take on a person. Here, Abdul-Mateen is clearly poking fun at himself and other actors who have signed onto splashy comics-inspired projects, but he also brings a quiet vulnerability to Simon that underlines his being a regular man who just wants to be recognized for his artistic talent.

After two turns as Slattery in previous Marvel projects, Kingsley finally has the chance to make the character feel like a real person whose ridiculous airs belie a genuine complexity. The two actors’ chemistry carries the series in moments when its The Studio-esque comedic subplots go a little off the rails. And by the end of the season, you get the sense that Simon and Slattery could go on to become one of Marvel’s more novel riffs on a superhero team.

All of that promise reinforces how curious the timing is. Marvel is premiering Wonder Man at a point in the MCU when it feels like significant portions of the franchise may be effectively reset in order to bring back actors and characters that first made the studio a massive success. Wonder Man’s release almost certainly reflects the way that Marvel’s long-term production scheduling has often shifted over the past few years in response to factors largely out of the studio’s control. But in a moment when the studio is making a big bet on another Avengers event to get audiences excited about this universe again.

Wonder Man is an example of how the studio can still put out strong stories that stand on their own.Wonder Man also stars Zlatko Burić, Arian Moayed, Béchir Sylvain, Olivia Thirlby, Byron Bowers, Joe Pantoliano, and Josh Gad. All eight episodes hit Disney Plus on January 27th.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-51')">
            <div class="source">The Verge</div>
            <div class="title">Intel Panther Lake laptop CPU review: call it a comeback</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-51" style="display:none;">
            <h2>Intel Panther Lake laptop CPU review: call it a comeback</h2>
            <p><strong>The Verge | 2026-01-26</strong></p>
            <a class="original-link" href="https://www.theverge.com/tech/867214/intel-core-ultra-x9-panther-lake-388h-laptop-cpu-review">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The first chip of Intel’s 18A process is speedy, even on battery power. And it’s a solid option for 1080p gaming.

Intel’s been talking the talk for months about its new generation of laptop chips, the first made on its long-anticipated 18A process. 18A is meant to steer Intel back toward bluer waters by making its chips better, and, if possible, attracting chip designers like Qualcomm and Nvidia to use Intel’s foundries, not just its rival TSMC’s. Last year’s Arrow Lake chips received a mixed reception, particularly desktop versions. The mobile-only Lunar Lake chips, on the other hand, were great, showing that the x86 architecture still has plenty of fight in it against a slowly rising tide of Arm-based Windows laptops. But Lunar Lake was a one-off that Intel designed more than manufactured, relying on TSMC silicon to do the heaviest lifting. Panther Lake puts homegrown Intel inside once again.

I’ve been testing the flagship Intel Core Ultra X9 388H Panther Lake chip in the 2026 Asus Zenbook Duo dual-screen laptop, and it’s been a treat. It’s fast enough for intensive work and multitasking, powerful enough for 1080p gaming at high settings, and lasts well over a full workday using productivity apps on battery power. With Panther Lake, Intel is walking the walk.

Panther Lake CPUs come in 8- and 16-core versions, made up of Cougar Cove performance cores (P-cores) and Darkmont efficiency cores (E-cores). The Core Ultra X9 388H in the Zenbook Duo is the top-tier 16-core model with an Intel Arc B390 GPU (consisting of 12 Xe graphics cores), a base power of 25W and a maximum turbo power up to 80W. Intel hyped it as more efficient than Lunar Lake while simultaneously more powerful than the Arrow Lake chips that are typically found in higher-power workstation and desktop replacement laptops.

Against its closest competition, Panther Lake isn’t an outright winner. Most benchmark scores in our table below are dominated by Apple’s M5 and AMD’s top-tier Strix Halo. But the Intel 388H Panther Lake chip handily beats AMD’s highest-end Strix Point chip in all but one of the tests we ran. That’s a solid leapfrogging by Intel, considering Strix Point handily beat Lunar Lake just a year ago. Now, Panther Lake also trounces our examples of both Lunar Lake and Arrow Lake-H.

While Apple is still the speed champ in most of these categories, I was pleasantly surprised to see Panther Lake slightly edge out the MacBook Pro in our 4K video export in Adobe Premiere Pro. That’s those 12 graphics cores at work.

In real-world use, Panther Lake’s speed is palpable. When I fired up my Adobe Lightroom Classic catalog and started editing some of my 50-megapixel RAW files, it felt as quick — or nearly as quick — as a MacBook Pro. I could make heavy-handed changes in the Develop module, and bounce around between images, without everything bogging down as it often does on other Windows laptops. Even subject detection and healing brush removal were snappy.

And I did my photo editing on battery power. Unlike most Windows laptops I’ve used up till now, the Zenbook Duo is just about as fast on battery power as it is connected to the wall. This is often something that Windows laptop makers restrict in their hardware designs, but I’m relieved it’s not the case with Panther Lake on the Zenbook Duo. It’s a big win for editing and content creation on Windows, as it lets the platform match one of the major strengths of modern MacBooks. I just hope all Windows laptop manufacturers follow suit.

Speaking of battery power, Panther Lake in the Zenbook Duo is a champ. Especially when you consider it’s powering two bright, high-resolution OLED displays. You can read deeper details on my real-world experience with the Zenbook Duo’s battery life in my full review of the laptop, but here are a couple quick hits: It lasted over 14 hours in our rundown test, and I could easily last a nine-hour workday of dual-screen multitasking with enough juice left over for some lighter casual use in the evening.

As for gaming, Intel claims that Panther Lake’s 12 Xe graphics cores are on par with Nvidia’s discrete RTX 4050 laptop GPU, much like how Strix Halo goes toe-to-toe with the RTX 4060. Digital Foundry’s early testing at CES found Panther Lake to be nipping at the heels of a desktop RTX 3050 card at 1080p resolution.

I only did a handful of scripted gaming benchmarks, because I wanted to spend more time actually playing. But one benchmark that stood out to me was Cyberpunk 2077, which averaged 40fps at 1920 x 1200 resolution on Ultra settings. That’s without ray tracing, but also without any XeSS (Intel’s version of super resolution upscaling). Panther Lake is no slouch, even if AMD’s beefy Strix Halo chip still has the edge on graphics.

Once I dove into playing titles like Cyberpunk, Helldivers 2, Battlefield 6, and a few others, I discovered that Panther Lake can typically hit 60fps or slightly below at 1920 x 1200 resolution on High settings with XeSS Balanced enabled. You can push the graphics quality further by turning on ray tracing or flipping XeSS from Balanced to Quality, but I’d only do that if you’re comfortable playing closer to 30fps. I prefer 60fps as my baseline.

Setting game graphics to hit a baseline of 40 to 60fps means you can flip on the new XeSS multi-frame generation, which can make games look buttery smooth at well above 120fps. You can control multi-frame generation in Intel’s app, and pick between 2x, 3x, and 4x frame generation. It felt smooth enough to use in Battlefield 6 and got close to the Zenbook Duo’s native 144Hz refresh (though I turn it off in multiplayer to ensure there’s no chance of increased input latency). Nvidia may be marching on toward 6x Multi Frame Generation with DLSS 4.5, but Intel’s doing a fine job on its slower cadence — and it’s still ahead of AMD’s Redstone, which doesn’t support multi-frame gen.

As excited as I am for Panther Lake to finally arrive, and to stick its landing this well, I’m now looking forward to further testing of slightly lower-end versions — ones found in more moderately priced laptops than this $2,300 dual-screen with a massive battery. (A handheld, perhaps?) And I’m equally excited to see how new contenders from AMD and Qualcomm stack up, including those cheaper gaming-focused Strix Halo variants. It’s an exciting time for new laptop releases (rising prices aside, of course).

There’s plenty of upcoming competition, but Panther Lake is first out of the gate and looking like the Windows laptop chip to beat. Welcome back to the show, Intel.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-52')">
            <div class="source">The Verge</div>
            <div class="title">Asus Zenbook Duo (2026) review: twice as nice — for a price</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-52" style="display:none;">
            <h2>Asus Zenbook Duo (2026) review: twice as nice — for a price</h2>
            <p><strong>The Verge | 2026-01-26</strong></p>
            <a class="original-link" href="https://www.theverge.com/tech/867548/asus-zenbook-duo-2026-intel-panther-lake-review">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">﻿Asus made all the right tweaks, and the new Panther Lake chip delivers.

If you buy something from a Verge link, Vox Media may earn a commission. See our ethics statement.

If you buy something from a Verge link, Vox Media may earn a commission. See our ethics statement.

The most helpful thing you can add to any laptop for productivity is a second screen. That’s why I love laptops like the Asus Zenbook Duo. Its twin 14-inch OLED displays are attached by a redesigned hinge that now holds them closer together and on a single plane, for a more seamless look than previous models. The Zenbook Duo and its nearest rival look odd at first glance, but having a twin monitor setup available to you anywhere is incredibly handy. And so cool, too. Let them stare.

In addition to the new hinge, the 2026 Zenbook Duo gets Asus’ lightly textured Ceraluminum coating (which sounds silly but looks and feels great), a much larger battery, and — most importantly — a new Intel Panther Lake CPU. With this streamlined design, all-day battery life, and plentiful power, the Duo is a dual-screen that’s capable enough and versatile enough for most anyone.

Lovely dual OLEDs that now sit closer togetherVersatile dual-screen form factorStill a great single-screen clamshellStrong performance and battery life

Gets warm, but not lap-roasting hotA little heavy and thick for a 14-inchVertical orientation compromises sound qualityMuch pricier than last-gen

Our review configuration of the 2026 Zenbook Duo, which is due to launch sometime in Q1 2026, has an Intel Core Ultra X9 388H, 32GB of RAM, and 1TB of storage for $2,299.99. That’s $500 more than the last-gen model with similar specs.

I cover the Zenbook Duo’s performance at length in my dedicated Intel Panther Lake review, but the short version is that the Core Ultra X9 388H chip in this laptop is excellent, and it makes the Duo both powerful and power-efficient. It can handle heavy multitasking, breeze through content creation in Adobe apps, and even play games well in 1080p / 1200p resolution. It even delivers near-full-power performance when not plugged in — not often the case for Windows laptops.

The Zenbook Duo’s giant 99Wh battery lasted over 14 hours in our rundown test, and in everyday use I could easily get through an eight-to-nine-hour workday and then some while using both screens at fairly high brightness. I even ran it for six hours straight in dual-screen mode with both panels at 80 percent brightness without letting Windows 11’s aggressive power management suspend it or let it sleep, all while working across two virtual desktops in many Chrome tabs and with music playing on its solid-sounding speakers via Spotify. In those six hours it went from a full charge down to 24 percent. Impressive. And it lasts even longer when you use it like a standard clamshell laptop, with only one of its 14-inch 2880 x 1800 / 144Hz OLEDs active.

One of the Duo’s best tricks is that it can transform from a conventional 14-inch laptop to its towering dual-screen mode as quickly as you can rip the keyboard deck from its magnetic pogo pins and deploy the built-in kickstand. The keyboard and mechanical trackpad on the Duo are both great.

The keyboard’s typing feel is decently tactile, with a deep 1.7mm key travel. The trackpad has gesture controls at its edges that I found prone to accidental activation, so I turned them off in the MyAsus app. When detached, the keyboard deck works over Bluetooth for a claimed 11.6 hours of use with its backlight on. I never had to worry about keyboard battery life, as I switched to clamshell mode often enough to keep it topped up from the pogo pins — and you can also charge the keyboard via USB-C while it’s off the laptop.

The Zenbook Duo is a lot more travel-friendly than the 2024 Lenovo Yoga Book 9i: The Yoga Book’s stand is in a magnetic folio case, not built in; its keyboard doesn’t have a trackpad, and you can’t close the Yoga Book’s lid with the keyboard inside, so it and the mouse it ships with take up more room in your bag. The only tradeoffs of the Zenbook Duo design compared to the Lenovo are that it doesn’t fold over backward for tablet mode, and it’s a bit of a chunker at 3.65 pounds / 1.66 kg and nearly an inch thick at its hinge.

But I prefer the Zenbook Duo’s more conventional approach to dual-screen laptop life over the Yoga Book 9i. In addition to being more travel-friendly, the Duo has more ports and better port variety than the Lenovo, including a USB-A and full-size HDMI 2.1. The dual-screen Lenovo is also great, with unique style from its folio stand and bright blue color, but the Zenbook Duo is a tidier package.

As I found when I tested Lenovo’s rollable laptop, getting more screen real estate whenever you need will absolutely spoil you. Lots of people use portable monitors for this, but having your second screen integrated into your laptop and perfectly matched to the main screen in resolution, size, and color is better. There’s more room to tile apps and windows across your workspace, and it’s easier to work on two documents at the same time with side-by-side vertical screens — which is what I’m doing as I write this review. And with the screens in extra-tall orientation you get a nice webcam angle that’s closer to eye level, easier on your neck, and a more pleasing representation of your mug — no tickets to double-chin city here.

As awesome as this dual-screen experience is, you’re bound to run into little bits of friction. For example, I like turning the Duo’s orientation between horizontal and vertical depending on what I’m working on. But the two-up vertical position requires resting the laptop on its side, blocking some ports. Do I need my USB-A port for a mechanical keyboard or mouse dongle? Am I plugging into an external monitor via HDMI? Either of these means temporarily losing access to the other, and blocks half the Zenbook Duo’s six speakers, making music sound unbalanced and a little odd. Within Windows lie some quirks too: If you rest the Duo on its left edge, you have to change which display is the main screen in Settings, to keep the System Tray in the bottom right where it belongs. (Imagine using a center-aligned Start menu and a center-left-aligned System Tray? Madness.)

Asus’ ScreenXpert overlay software is designed to assist with dual-screen management. It’s helpful for things like simultaneously launching grouped apps across the two screens, but it’s still clunky and limited in scope. The same goes for all the multi-finger touch gestures you have to remember if you want to call up the virtual keyboard and trackpad or move them around the bottom screen. (My solution is to just not bother with the touch keyboard.)

But the odd, minor pain points are far outweighed by the usefulness and fun of the Zenbook Duo’s twin displays. It’s an incredibly versatile setup, and both performance and battery life are great. Asus nailed most aspects of the Zenbook Duo, making it an easy recommendation. Later in the year Asus will also bring a model with the same design, but a last-gen Arrow Lake H chip, which may be cheaper. And it’s also launching a dual-screen gaming laptop, the Zephyrus Duo, which I am really looking forward to. Dual-screen laptops remain niche for now, but the Zenbook Duo proves they shouldn’t be as rare as they are.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-53')">
            <div class="source">The Verge</div>
            <div class="title">Microsoft’s first Windows 11 update of 2026 has been a mess</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-53" style="display:none;">
            <h2>Microsoft’s first Windows 11 update of 2026 has been a mess</h2>
            <p><strong>The Verge | 2026-01-26</strong></p>
            <a class="original-link" href="https://www.theverge.com/news/867647/microsoft-windows-11-january-2026-update-bugs-issues">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Microsoft has had to issue two out-of-band updates to fix its buggy Windows 11 patch.

Microsoft has had to issue two out-of-band updates to fix its buggy Windows 11 patch.

Microsoft’s first update for Windows 11 in 2026 has been a buggy mess, to say the least. After reports of shutdown issues on some machines, Microsoft issued an emergency update to fix its January 2026 Windows 11 update last weekend. Now, exactly a week later, the software maker has been forced to issue a second unusual out-of-band fix to address OneDrive and Dropbox crashes.

Microsoft is also investigating reports of boot failures that could be related to its January 2026 security update.

While the first shutdown bug was limited to machines running Enterprise and IoT editions of Windows 11 version 23H2, the latest out-of-band update fixes crashes and unresponsiveness in OneDrive and Dropbox on the latest 24H2 and 25H2 versions of Windows 11.

Just like the first emergency patch to fix this problematic January 2026 update, the second out-of-band update was released over a weekend, leaving IT admins with a busy Monday morning. There could be further headaches ahead for IT admins, too.

Microsoft warned over the weekend that its January 2026 update may also be creating boot failures on some machines. In an alert to IT admins, the company said it was investigating reports of boot failures with 24H2 and 25H2 after installing the January 2026 update. Some PCs have been bluescreening with a UNMOUNTABLE_BOOT_VOLUME stop code, and Microsoft warns these machines need to be manually recovered.

Microsoft hasn’t completed its investigation into the boot failures, so it’s not clear if it’s definitely this update causing the problems. A similar security update last year was initially blamed for SSD issues, but the root cause was actually early versions of firmware and motherboard BIOS.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-54')">
            <div class="source">MIT Technology Review</div>
            <div class="title">The power of sound in a virtual world</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-54" style="display:none;">
            <h2>The power of sound in a virtual world</h2>
            <p><strong>MIT Technology Review | 2026-01-26</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2026/01/26/1124655/the-power-of-sound-in-a-virtual-world/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">In an era where business, education, and even casual conversations occur via screens, sound has become a differentiating factor. We obsess over lighting, camera angles, and virtual backgrounds, but how we sound can be just as critical to credibility, trust, and connection.

That’s the insight driving Erik Vaveris, vice president of product management and chief marketing officer at Shure, and Brian Scholl, director of the Perception & Cognition Laboratory at Yale University. Both see audio as more than a technical layer: It’s a human factor shaping how people perceive intelligence, trustworthiness, and authority in virtual settings.

&quot;If you&#39;re willing to take a little bit of time with your audio set up, you can really get across the full power of your message and the full power of who you are to your peers, to your employees, your boss, your suppliers, and of course, your customers,&quot; says Vaveris.

Scholl’s research shows that poor audio quality can make a speaker seem less persuasive, less hireable, and even less credible.

&quot;We know that [poor] sound doesn&#39;t reflect the people themselves, but we really just can&#39;t stop ourselves from having those impressions,&quot; says Scholl. &quot;We all understand intuitively that if we&#39;re having difficulty being understood while we&#39;re talking, then that&#39;s bad. But we sort of think that as long as you can make out the words I&#39;m saying, then that&#39;s probably all fine. And this research showed in a somewhat surprising way, to a surprising degree, that this is not so.&quot;

For organizations navigating hybrid work, training, and marketing, the stakes have become high.

Vaveris points out that the pandemic was a watershed moment for audio technology. As classrooms, boardrooms, and conferences shifted online almost overnight, demand accelerated for advanced noise suppression, echo cancellation, and AI-driven processing tools that make meetings more seamless. Today, machine learning algorithms can strip away keyboard clicks or reverberation and isolate a speaker’s voice in noisy environments. That clarity underpins the accuracy of AI meeting assistants that can step in to transcribe, summarize, and analyze discussions.

The implications across industries are rippling. Clearer audio levels the playing field for remote participants, enabling inclusive collaboration. It empowers executives and creators alike to produce broadcast-quality content from the comfort of their home office. And it offers companies new ways to build credibility with customers and employees without the costly overhead of traditional production.

Looking forward, the convergence of audio innovation and AI promises an even more dynamic landscape: from real-time captioning in your native language to audio filtering, to smarter meeting tools that capture not only what is said but how it’s said, and to technologies that disappear into the background while amplifying the human voice at the center.

&quot;There&#39;s a future out there where this technology can really be something that helps bring people together,&quot; says Vaveris. &quot;Now that we have so many years of history with the internet, we know there&#39;s usually two sides to the coin of technology, but there&#39;s definitely going to be a positive side to this, and I&#39;m really looking forward to it.

In a world increasingly mediated by screens, sound may prove to be the most powerful connector of all.

This episode of Business Lab is produced in partnership with Shure.

Megan Tatum: From MIT Technology Review, I&#39;m Megan Tatum, and this is Business Lab, the show that helps business leaders make sense of new technologies coming out of the lab and into the marketplace.This episode is produced in partnership with Shure.Our topic today is the power of sound. As our personal and professional lives become increasingly virtual, audio is emerging as an essential tool for everything from remote work to virtual conferences to virtual happy hour. While appearance is often top of mind in video conferencing and streaming, audio can be as or even more important, not only to effective communication, but potentially to brand equity for both the speaker and the company.Two words for you: crystal clear.My guests today are Erik Vaveris, VP of Product Management and Chief Marketing Officer at Shure, and Brian Scholl, Director of the Perception & Cognition Laboratory at Yale University.Welcome, Erik and Brian.

Erik Vaveris: Thank you, Megan. And hello, Brian. Thrilled to be here today.

Megan: Fantastic. Thank you both so much for being here. Erik, let&#39;s open with a bit of background. I imagine the pandemic changed the audio industry in some significant ways, given the pivot to our modern remote hybrid lifestyles. Could you talk a bit about that journey and some of the interesting audio advances that arose from that transformative shift?

Erik: Absolutely, Megan. That&#39;s an interesting thing to think about now being here in 2025. And if you put yourself back in those moments in 2020, when things were fully shut down and everything was fully remote, the importance of audio quality became immediately obvious. As people adopted Zoom or Teams or platforms like that overnight, there were a lot of technical challenges that people experienced, but the importance of how they were presenting themselves to people via their audio quality was a bit less obvious. As Brian&#39;s noted in a lot of the press that he&#39;s received for his wonderful study, we know how we look on video. We can see ourselves back on the screen, but we don&#39;t know how we sound to the people with whom we&#39;re speaking.

If a meeting participant on the other side can manage to parse the words that you&#39;re saying, they&#39;re not likely to speak up and say, &quot;Hey, I&#39;m having a little bit of trouble hearing you.&quot; They&#39;ll just let the meeting continue. And if you don&#39;t have a really strong level of audio quality, you&#39;re asking the people that you&#39;re talking to devote way too much brainpower to just determining the words that you&#39;re saying. And you&#39;re going to be fatiguing to listen to. And your message won&#39;t come across. In contrast, if you&#39;re willing to take a little bit of time with your audio set up, you can really get across the full power of your message and the full power of who you are to your peers, to your employees, your boss, your suppliers, and of course your customers. Back in 2020, this very quickly became a marketing story that we had to tell immediately.

And I have to say, it&#39;s so gratifying to see Brian&#39;s research in the news because, to me, it was like, &quot;Yes, this is what we&#39;ve been experiencing. And this is what we&#39;ve been trying to educate people about.&quot; Having the real science to back it up means a lot. But from that, development on improvements to key audio processing algorithms accelerated across the whole AV industry.

I think, Megan and Brian, you probably remember hearing loud keyboard clicking when you were on calls and meetings, or people eating potato chips and things like that back on those. But you don&#39;t hear that much today because most platforms have invested in AI-trained algorithms to remove undesirable noises. And I know we&#39;re going to talk more about that later on.

But the other thing that happened, thankfully, was that as we got into the late spring and summer of 2020, was that educational institutions, especially universities, and also businesses realized that things were going to need to change quickly. Nothing was going to be the same. And universities realized that all classrooms were going to need hybrid capabilities for both remote students and students in the classroom. And that helped the market for professional AV equipment start to recover because we had been pretty much completely shut down in the earlier months. But that focus on hybrid meeting spaces of all types accelerated more investment and more R&D into making equipment and further developing those key audio processing algorithms for more and different types of spaces and use cases. And since then, we&#39;ve really seen a proliferation of different types of unobtrusive audio capture devices based on arrays of microphones and the supporting signal processing behind them. And right now, machine-learning-trained signal processing is really the norm. And that all accelerated, unfortunately, because of the pandemic.

Megan: Yeah. Such an interesting period of change, as you say. And Brian, what did you observe and experience in academia during that time? How did that time period affect the work at your lab?

Brian: I&#39;ll admit, Megan, I had never given a single thought to audio quality or anything like that, certainly until the pandemic hit. I was thrown into this, just like the rest of the world was. I don&#39;t believe I&#39;d ever had a single video conference with a student or with a class or anything like that before the pandemic hit. But in some ways, our experience in universities was quite extreme. I went on a Tuesday from teaching an in-person class with 300 students to being on Zoom with everyone suddenly on a Thursday. Business meetings come in all shapes and sizes. But this was quite extreme. This was a case where suddenly I&#39;m talking to hundreds and hundreds of people over Zoom. And every single one of them knows exactly what I sound like, except for me, because I&#39;m just speaking my normal voice and I have no idea how it&#39;s being translated through all the different levels of technology.

I will say, part of the general rhetoric we have about the pandemic focuses on all the negatives and the lack of personal connection and nuance and the fact that we can&#39;t see how everyone&#39;s paying attention to each other. Our experience was a bit more mixed. I&#39;ll just tell you one anecdote. Shortly after the pandemic started, I started teaching a seminar with about 20 students. And of course, this was still online. What I did is I just invited, for whatever topic we were discussing on any given day, I sent a note to whoever was the clear world leader in the study of whatever that topic was. I said, &quot;Hey, don&#39;t prepare a talk. You don&#39;t have to answer any questions. But just come join us on Zoom and just participate in the conversation. The students will have read some of your work.&quot;

Every single one of them said, &quot;Let me check my schedule. Oh, I&#39;m stuck at home for a year. Sure. I&#39;d be happy to do that.&quot; And that was quite a positive. The students got to meet a who&#39;s who of cognitive science from this experience. And it&#39;s true that there were all these technological difficulties, but that would never, ever have happened if we were teaching the class in real life. That would&#39;ve just been way too much travel and airfare and hotel and scheduling and all of that. So, it was a mixed bag for us.

Erik: That is really interesting. And that&#39;s such a cool idea. And it&#39;s so wonderful that that worked out. I would say that working for a global company, we like to think that, &quot;Oh, we&#39;re all together. And we&#39;re having these meetings. And we&#39;re in the same room,&quot; but the reality was we weren&#39;t in the same room. And there hadn&#39;t been enough attention paid to the people who were conferencing in speaking not their native language in a different time zone, maybe pretty deep into the evening, in some cases. And the remote work that everybody got thrown into immediately at the start of the pandemic did force everybody to start to think more about those types of interactions and put everybody on a level playing field.

And that was insightful. And that helped some people have stronger voices in the work that we were doing than they maybe did before. And it&#39;s also led businesses really across the board, there&#39;s a lot written about this, to be much more focused on making sure that participants from those who may be remote at home, may be in the office, may be in different offices, may be in different time zones, are all able to participate and collaborate on really a level playing field. And that is a positive. That&#39;s a good thing.

Megan: Yeah. There are absolutely some positive side effects there, aren&#39;t there? And it inspired you, Brian, to look at this more closely. And you&#39;ve done a study that shows poor audio quality can actually affect the perception of listeners. So, I wonder what prompted the study, in particular. And what kinds of data did you gather? What methodology did you use?

Brian: Yeah. The motivation for this study was actually a real-world experience, just like we&#39;ve been talking about. In addition to all of our classes moving online with no notice whatsoever, the same thing was true of our departmental faculty meetings. Very early on in the pandemic, we had one of these meetings. And we were talking about some contentious issue about hiring or whatever. And two of my colleagues, who I&#39;d known very well and for many, many years, spoke up to offer their opinions. And one of these colleagues is someone who I&#39;m very close with. We almost always see eye to eye. He was actually a former graduate student of mine once upon a time. And we almost always see eye to eye on things. He happened to be participating in that meeting from an old not-so-hot laptop. His audio quality had that sort of familiar tinny quality that we&#39;re all familiar with. I could totally understand everything he was saying, but I found myself just being a little skeptical.

I didn&#39;t find his points so compelling as usual. Meanwhile, I had another colleague, someone who I deeply respect, I&#39;ve collaborated with, but we don&#39;t always see eye to eye on these things. And he was participating in this first virtual faculty meeting from his home recording studio. Erik, I don&#39;t know if his equipment would be up to your level or not, but he sounded better than real life. He sounded like he was all around us. And I found myself just sort of naturally agreeing with his points, which sort of was notable and a little surprising in that context. And so, we turned this into a study.

We played people a number of short audio clips, maybe like 30 seconds or so. And we had these being played in the context of very familiar situations and decisions. One of them might be like a hiring decision. You would have to listen to this person telling you why they think they might be a good fit for your job. And then afterwards, you had to make a simple judgment. It might be of a trait. How intelligent did that person seem? Or it might be a real-world decision like, &quot;Hey, based on this, how likely would you be to pursue trying to hire them?&quot; And critically, we had people listen to exactly the same sort of scripts, but with a little bit of work behind the scenes to affect the audio quality. In one case, the audio sounded crisp and clear. Recorded with a decent microphone. And here&#39;s what it sounded like.

Audio Clip: After eight years in sales, I&#39;m currently seeking a new challenge which will utilize my meticulous attention to detail and friendly professional manner. I&#39;m an excellent fit for your company and will be an asset to your team as a senior sales manager.

Brian: Okay. Whatever you think of the content of that message, at least it&#39;s nice and clear. Other subjects listened to exactly the same recording. But again, it had that sort of tinny quality that we&#39;re all familiar with when people&#39;s voices are filtered through a microphone or a recording setup that&#39;s not so hot. That sounded like this.

Audio Clip: After eight years in sales, I&#39;m currently seeking a new challenge which will utilize my meticulous attention to detail and friendly professional manner. I&#39;m an excellent fit for your company and will be an asset to your team as a senior sales manager.

Brian: All right. Now, the thing that I hope you can get from that recording there is that although it clearly has this what we would call, as a technical term, a disfluent sound, it&#39;s just a little harder to process, you are ultimately successful, right? Megan, Erik, you were able to understand the words in that second recording.

Brian: And we made sure this was true for all of our subjects. We had them do word-for-word transcription after they made these judgments. And I&#39;ll also just point out that this kind of manipulation clearly can&#39;t be about the person themselves, right? You couldn&#39;t make your voices sound like that in real world conversation if you tried. Voices just don&#39;t do those sorts of things. Nevertheless, in a way that sort of didn&#39;t make sense, that was kind of irrational because this couldn&#39;t reflect the person, this affected all sorts of judgments about people.

So, people were judged to be about 8% less hirable. They were judged to be about 8% less intelligent. We also did this in other contexts. We did this in the context of dateability as if you were listening to a little audio clip from someone who was maybe interested in dating you, and then you had to make a judgment of how likely would you be to date this person. Same exact result. People were a little less datable when their audio was a little more tinny, even though they were completely understandable.

The experiment, the result that I thought was in some ways most striking is one of the clips was about someone who had been in a car accident. It was a little narrative about what had happened in the car accident. And they were talking as if to the insurance agent. They were saying, &quot;Hey, it wasn&#39;t my fault. This is what happened.&quot; And afterwards, we simply had people make a natural intuitive judgment of how credible do you think the person&#39;s story was. And when it was recorded with high-end audio, these messages were judged to be about 8% more credible in this context. So those are our experiments. What it shows really is something about the power of perception. We know that that sort of sound doesn&#39;t reflect the people themselves, but we really just can&#39;t stop ourselves from having those impressions made. And I don&#39;t know about you guys, but, Erik, I think you&#39;re right, that we all understand intuitively that if we&#39;re having difficulty being understood while we&#39;re talking, then that&#39;s bad. But we sort of think that as long as you can make out the words I&#39;m saying, then that&#39;s probably all fine. And this research showed in a somewhat surprising way to a surprising degree that this is not so.

Megan: From an industry perspective, Erik, what are your thoughts on those study results? Did it surprise you as well?

Erik: No, like I said, I found it very, very gratifying because we invest a lot in trying to make sure that people understand the importance of quality audio, but we kind of come about that intuitively. Our entire company is audio people. So of course, we think that. And it&#39;s our mission to help other people achieve those higher levels of audio in everything that they do, whether you&#39;re a minister at a church or you&#39;re teaching a class or you&#39;re performing on stage. When I first saw in the news about Brian&#39;s study, I think it was the NPR article that just came up in one of my feeds. I read it and it made me feel like my life&#39;s work has been validated to some extent. I wouldn&#39;t say we were surprised by it, but iIt made a lot of sense to us. Let&#39;s put it that way.

Brian: This is what we&#39;re hearing. Oh, sorry. Megan, I was going to say this is what we&#39;re hearing from a lot of the audio professionals as they&#39;re saying, &quot;Hey, you scientists, you finally caught up to us.&quot; But of course-

Brian: Erik, you&#39;re in an unusual circumstance because you guys think about audio every day. When we&#39;re on Zoom, look, I can see the little rectangle as well as you can. I can see exactly how I look like. I can check the lighting. I check my hair. We all do that every day. But I would say most people really, they use whatever microphone came with their setup, and never give a second thought to what they sound like because they don&#39;t know what they sound like.

Megan: Avoid listening to yourself back as well. I think that&#39;s common. We don&#39;t scrutinize audio as much as we should. I wonder, Erik, since the study came out, how are you seeing that research play out across industry? Can you talk a bit about the importance of strong, clear audio in today&#39;s virtual world and the challenges that companies and employees are facing as well?

Erik: Yeah. Sure, Megan. That&#39;s a great question. And studies kind of back this up, businesses understand that collaboration is the key to many things that we do. They know that that&#39;s critical. And they are investing in making the experiences for the people at work better because of that knowledge, that intuitive understanding. But there are challenges. It can be expensive. You need solutions that people who are going to walk into a room or join a meeting on their personal device, that they&#39;re motivated to use and that they can use because they&#39;re simple. You also have to overcome the barriers to investment. We in the AV industry have had to look a lot at how can we bring down the overall cost of ownership of setting up AV technology because, as we&#39;ve seen, the prices of everything that goes into making a product are not coming down.

Simplifying deployment and management is critical. Beyond just audio technology, IoT technology and cloud technology for IT teams to be able to easily deploy and manage classrooms across an entire university campus or conference rooms across a global enterprise are really, really critical. And those are quickly evolving. And integrations with more standard common IT tools are coming out. And that&#39;s one area. Another thing is just for the end user, having the same user interface in each conference room that is familiar to everyone from their personal devices is also important. For many, many years, a lot of people had the experience where, &quot;Hey, it&#39;s time we&#39;re going to actually do a conference meeting.&quot; And you might have a few rooms in your company or in your office area that could do that. And you walk into the meeting room. And how long does it take you to actually get connected to the people you&#39;re going to talk with?

There was always a joke that you&#39;d have to spend the first 15 minutes of a meeting working all of that out. And that&#39;s because the technology was fragmented and you had to do a lot of custom work to make that happen. But these days, I would say platforms like Zoom and Teams and Google and others are doing a really great job with this. If you have the latest and greatest in your meeting rooms and you know how to join from your own personal device, it&#39;s basically the same experience. And that is streamlining the process for everyone. Bringing down the costs of owning it so that companies can get to those benefits to collaboration is kind of the key.

Megan: I was going to ask if we could dive a little deeper into that kind of audio quality, the technological advancements that AI has made possible, which you did touch on slightly there, Erik. What are the most significant advancements, in your view? And how are those impacting the ways we use audio and the things we can do with it?

Erik: Okay. Let me try to break that down into-

Erik: ... a couple different sections. Yeah. No, and one that&#39;s just so exciting. Machine-learning-based digital signal processing, or DSP, is here and is the norm now. If you think about the beginning of telephones and teleconferencing, just going way back, one of the initial problems you had whenever you tried to get something out of a dedicated handset onto a table was echo. And I&#39;m sure we&#39;ve all heard that at some point in our life. You need to have a way to cancel echo. But by the way, you also want people to be able to speak at the same time on both ends of a call. You get to some of those very rudimentary things. Machine learning is really supercharging those algorithms to provide better performance with fewer trade-offs, fewer artifacts in the actual audio signal.

Noise reduction has come a long way. I mentioned earlier on, keyboard sounds and the sounds of people eating, and how you just don&#39;t hear that anymore, at least I don&#39;t when I&#39;m on conference calls. But only a few years ago, that could be a major problem. The machine-learning-trained digital signal processing is in the market now and it&#39;s doing a better job than ever in removing things that you don&#39;t want from your sound. We have a new de-verberation algorithm, so if you have a reverberant room with echoes and reflections that&#39;s getting into the audio signal, that can degrade the experience there. We can remove that now. Another thing, the flip side of that is that there&#39;s also a focus on isolating the sound that you do want and the signal that you do want.

Microsoft has rolled out a voice print feature in Teams that allows you, if you&#39;re willing, to provide them with a sample of your voice. And then whenever you&#39;re talking from your device, it will take out anything else that the microphone may be picking up so that even if you&#39;re in a really noisy environment outdoors or, say, in an airport, the people that you&#39;re speaking with are going to hear you and only you. And it&#39;s pretty amazing as well. So those are some of the things that are happening today and are available today.

Another thing that&#39;s emerged from all of this is we&#39;ve been talking about how important audio quality is to the people participating in a discussion, the people speaking, the people listening, how everyone is perceived, but a new consumer, if you will, of audio in a discussion or a meeting has emerged, and that is in the form of the AI agent that can summarize meetings and create action plans, do those sorts of things. But for it to work, a clean transcription of what was said is already table stakes. It can&#39;t garbled. It can&#39;t miss key things. It needs to get it word for word, sentence for sentence throughout the entire meeting. And the ability to attribute who said what to the meeting participants, even if they&#39;re all in the same room, is quickly upon us. And the ability to detect and integrate sentiment and emotion of the participants is going to become very important as well for us to really get the full value out of those kinds of AI agents.

So audio quality is as important as ever for humans, as Brian notes, in some ways more important because this is now the normal way that we talk and meet, but it&#39;s also critical for AI agents to work properly. And it&#39;s different, right? It&#39;s a different set of considerations. And there&#39;s a lot of emerging thought and work that&#39;s going into that as well. And boy, Megan, there&#39;s so much more we could say about this beyond meetings and video conferences. AI tools to simplify the production process. And of course, there&#39;s generative AI of music content. I know that&#39;s beyond the scope of what we&#39;re talking about. But it&#39;s really pretty incredible when you look around at the work that&#39;s happening and the capabilities that are emerging.

Megan: Yeah. Absolutely. Sounds like there are so many elements to consider and work going on. It&#39;s all fascinating. Brian, what kinds of emerging capabilities and use cases around AI and audio quality are you seeing in your lab as well?

Brian: Yeah. Well, I&#39;m sorry that Brian himself was not able to be here today, but I&#39;m an AI agent.

Brian: Just kidding. The fascinating thing that we&#39;re seeing from the lab, from the study of people&#39;s impressions is that all of this technology that Erik has described, when it works best, it&#39;s completely invisible. Erik, I loved your point about not hearing potato chips being eaten or rain in the background or something like that. You&#39;re totally right. I used to notice that all the time. I don&#39;t think I&#39;ve noticed that recently, but I also didn&#39;t notice that I haven&#39;t noticed that recently, right? It just kind of disappears. The interesting thing about these perceptual impressions, we&#39;re constantly drawing intuitive conclusions about people based on how they sound. And that might be a good thing or a bad thing when we&#39;re judging things like trustworthiness, for example, on the basis of a short audio clip.

But clearly, some of these things are valid, right? We can judge the size of someone or even of an animal based on how they sound, right? A chihuahua can&#39;t make the sound of a lion. A lion can&#39;t make the sound of a chihuahua. And that&#39;s always been true because we&#39;re producing audio signals that go right into each other&#39;s ears. And now, of course, everything that Erik is talking about, that&#39;s not true. It goes through all of these different layers of technology increasingly fueled by AI. But when that technology works the best way, it&#39;s as if it isn&#39;t there at all and we&#39;re just hearing each other directly.

Erik: That&#39;s the goal, right? That it&#39;s seamless open communication and we don&#39;t have to think about the technology anymore.

Brian: It&#39;s a tough business to be in, I think, though, Erik, because people have to know what&#39;s going on behind the surface in order to value it. Otherwise, we just expect it to work.

Erik: Well, that&#39;s why we try to put the logo of our products on the side of them so they show up in the videos. But yeah, it&#39;s a good point.

Megan: And we&#39;ve talked about virtual meetings and conversations quite a bit, but there&#39;s also streamed and recorded content, which are increasingly important at work as well. I wondered, Erik, if you could talk a bit about how businesses are leveraging audio in new ways for things like marketing campaigns and internal upskilling and training and areas like that?

Erik: Yeah. Well, one of the things I think we&#39;ve all seen in marketing is that not everything is a high production value commercial anymore. And there&#39;s still a place for that, for sure. But people tend to trust influencers that they follow. People search on TikTok, on YouTube for topics. Those can be the place that they start. And as technology&#39;s gotten more accessible, not just audio, but of course, the video technology too, content creators can produce satisfying content on their own or with just a couple of people with them. And Brian&#39;s study shows that it doesn&#39;t really matter what the origins of the content are for it to be compelling.

For the person delivering the message to be compelling, the audio quality does have to hit a certain level. But because the tools are simpler to use and you need less things to connect and pull together a decent production system, creator-driven content is becoming even more and more integral to a marketing campaign. And so not just what they maybe post on their Instagram page or post on LinkedIn, for example, but us as a brand being able to take that content and use that actually in paid media and things like that is all entirely possible because of the overall quality of the content. So that&#39;s something that&#39;s been a trend that&#39;s been in process really, I would say, maybe since the advent of podcasts. But it&#39;s been an evolution. And it&#39;s come a long, long way.

Another thing, and this is really interesting, and this hits home personally, but I remember when I first entered the workforce, and I hope I&#39;m not showing my age too badly here, but I remember the word processing department. And you would write down on a piece of paper, like a memo, and you would give it to the word processing department and somebody would type it up for you. That was a thing. And these days, we&#39;re seeing actually more and more video production with audio, of course, transfer to the actual producers of the content.

In my company, at Shure, we make videos for different purposes to talk about different initiatives or product launches or things that we&#39;re doing just for internal use. And right now, everybody, including our CEO, she makes these videos just at her own desk. She has a little software tool and she can show a PowerPoint and herself and speak to things. And with very, very limited amount of editing, you can put that out there. And I&#39;ve seen friends and colleagues at other companies in very high-level roles just kind of doing their own production. Being able to buy a very high quality microphone with really advanced signal processing built right in, but just plug it in via USB and have it be handled as simply as any consumer device, has made it possible to do really very useful production where you are going to actually sound good and get your message across, but without having to make such a big production out of it, which is kind of cool.

Megan: Yeah. Really democratizes access to sort of creating high quality content, doesn&#39;t it? And of course, no technology discussion is complete without a mention of return on investment, particularly nowadays. Erik, what are some ways companies can get returns on their audio tech investments as well? Where are the most common places you see cost savings?

Erik: Yeah. Well, we collaborated on a study with IDC Research. And they came up with some really interesting findings on this. And one of them was, no surprise, two-thirds or more of companies have taken action on improving their communication and collaboration technology, and even more have additional or initial investments still planned. But the ROI of those initiatives isn&#39;t really tied to the initiative itself. It&#39;s not like when you come out with a new product, you look at how that product performs, and that&#39;s the driver of your ROI. The benefits of smoother collaboration come in the form of shorter meetings, more productive meetings, better decision-making, faster decision-making, stronger teamwork. And so to build an ROI model, what IDC concluded was that you have to build your model to account for those advantages really across the enterprise or across your university, or whatever it may be, and kind of up and down the different set of activities where they&#39;re actually going to be utilized.

So that can be complex. Quantifying things can always be a challenge. But like I said, companies do seem to understand this. And I think that&#39;s because, this is just my hunch, but because everybody, including the CEO and the CFO and the whole finance department, uses and benefits from collaboration technology too. Perhaps that&#39;s one reason why the value is easier to convey. Even if they have not taken the time to articulate things like we&#39;re doing here today, they know when a meeting is good and when it&#39;s not good. And maybe that&#39;s one of the things that&#39;s helping companies to justify these investments. But it&#39;s always tricky to do ROI on projects like that. But again, focusing on the broader benefits of collaboration and breaking it down into what it means for specific activities and types of meetings, I think, is the way to go about doing that.

Megan: Absolutely. And Brian, what kinds of advancements are you seeing in the lab that perhaps one day might contribute to those cost savings?

Brian: Well, I don&#39;t know anything about cost savings, Megan. I&#39;m a college professor. I live a pure life of the mind.

Brian: ROI does not compute for me. No, I would say we are in an extremely exciting frontier right now because of AI and many different technologies. The studies that we talked about earlier, in one sense, they were broad. We explored many different traits from dating to hiring to credibility. And we isolated them in all sorts of ways we didn&#39;t talk about. We showed that it wasn&#39;t due to overall affect or pessimism or something like that. But in those studies, we really only tested one very particular set of dimensions along which an audio signal can vary, which is some sort of model of clarity. But in reality, the audio signal is so multi-dimensional. And as we&#39;re getting more and more tools these days, we can not only change audio along the lines of clarity, as we&#39;ve been talking about, but we can potentially manipulate it in all sorts of ways.

We&#39;re very interested in pushing these studies forward and in exploring how people&#39;s sort of brute impressions that they make are affected by all sorts of things. Meg and Erik, we walk around the world all the time making these judgments about people, right? You meet someone and you&#39;re like, &quot;Wow, I could really be friends with them. They seem like a great person.&quot; And you know that you&#39;re making that judgment, but you have no idea why, right? It just seems kind of intuitive. Well, in an audio signal, when you&#39;re talking to someone, you can think of, &quot;What if their signal is more bass heavy? What if it&#39;s a little more treble heavy? What if we manipulate it in this way? In that way?&quot;

When we talked about the faculty meeting that motivated this whole research program, I mentioned that my colleague, who was speaking from his home recording studio, he actually didn&#39;t sound clear like in real life. He sounded better than in real life. He sounded like he was all around us. What is the implication of that? I think there&#39;s so many different dimensions of an audio signal that we&#39;re just being able to readily control and manipulate that it&#39;s going to be very exciting to see how all of these sorts of things impact our impressions of each other.

Megan: And there may be some overlap with this as well, but I wondered if we could close with a future forward look, Brian. What are you looking forward to in emerging audio technology? What are some exciting opportunities on the horizon, perhaps related to what you were just talking about there?

Brian: Well, we&#39;re interested in studying this from a scientific perspective. Erik, you talked about how when you started. When I started doing this science, we didn&#39;t have a word processing department. We had a stone tablet department. But I hear tell that the current generation, when they send photos back and forth to each other, that they, as a matter, of course, they apply all sorts of filters-

Brian: ... to those video signals, those video or just photographic signals. We&#39;re all familiar with that. That hasn&#39;t quite happened with the audio signals yet, but I think that&#39;s coming up as well. You can imagine that you record yourself saying a little message and then you filter it this way or that way. And that&#39;s going to become the Wild West about the kinds of impressions we make on each other, especially if and when you don&#39;t know that those filters have been operating in the first place.

Megan: That&#39;s so interesting. Erik, what are you looking forward to in audio technology as well?

Erik: Well, I&#39;m still thinking about what Brian said.

Erik: I have to go back again. I&#39;ll go back to the past, maybe 15 to 20 years. And I remember at work, we had meeting rooms with the Starfish phones in the middle of the table. And I remember that we would have international meetings with our partners there that were selling our products in different countries, including in Japan and in China, and the people actually in our own company in those countries. We knew the time zone was bad. And we knew that English wasn&#39;t their native language, and tried to be as courteous as possible with written materials and things like that. But I went over to China, and I had to actually be on the other end of one of those calls. And I&#39;m a native English speaker, or at least a native Chicago dialect of American English speaker. And really understanding how challenging it was for them to participate in those meetings just hit me right between the eyes.

We&#39;ve come so far, which is wonderful. But I think of a scenario, and this is not far off, there are many companies working on this right now, where not only can you get a real time captioning in your native language, no matter what the language of the participant, you can actually hear the person who&#39;s speaking&#39;s voice manipulated into your native language.

I&#39;m never going to be a fluent Japanese or Chinese speaker, that&#39;s for sure. But I love the thought that I could actually talk with people and they could understand me as though I were speaking their native language, and that they could communicate to me and I could understand them in the way that they want to be understood. I think there&#39;s a future out there where this technology can really be something that helps bring people together. Now that we have so many years of history with the internet, we know there&#39;s usually two sides to the coin of technology, but there&#39;s definitely going to be a positive side to this, and I&#39;m really looking forward to it.

Megan: Gosh, that sounds absolutely fascinating. Thank you both so much for such an interesting discussion.

That was Erik Vaveris, the VP of product management and chief marketing officer at Shure, and Brian Scholl, director of the Perception & Cognition Laboratory at Yale University, whom I spoke with from Brighton in England.That&#39;s it for this episode of Business Lab. I&#39;m your host, Megan Tatum. I&#39;m a contributing editor at Insights, the custom publishing division of MIT Technology Review. We were founded in 1899 at the Massachusetts Institute of Technology. And you can find us in print on the web and at events each year around the world. For more information about us and the show, please check out our website at technologyreview.com.This show is available wherever you get your podcasts. If you enjoyed this episode, we hope you&#39;ll take a moment to rate and review us. Business Lab is a production of MIT Technology Review. And this episode was produced by Giro Studios. Thanks for listening.

This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff. It was researched, designed, and written entirely by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.

Here are our picks for the advances to watch in the years ahead—and why we think they matter right now.

Four ways to think about this year&#39;s reckoning.

As early electric cars age out, hundreds of thousands of used batteries are flooding the market, fueling a gray recycling economy even as Beijing and big manufacturers scramble to build a more orderly system.

The Cybertruck, sycophantic AI, and humanoid robots all made this year’s list of the biggest technology failures.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-55')">
            <div class="source">MIT Technology Review</div>
            <div class="title">The Download: why LLMs are like aliens, and the future of head transplants</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-55" style="display:none;">
            <h2>The Download: why LLMs are like aliens, and the future of head transplants</h2>
            <p><strong>MIT Technology Review | 2026-01-26</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2026/01/26/1131717/the-download-why-llms-are-like-aliens-and-the-future-of-head-transplants/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">This is today&#39;s edition of The Download, our weekday newsletter that provides a daily dose of what&#39;s going on in the world of technology.

Meet the new biologists treating LLMs like aliens

How large is a large language model? We now coexist with machines so vast and so complicated that nobody quite understands what they are, how they work, or what they can really do—not even the people who build them.That’s a problem. Even though nobody fully understands how it works—and thus exactly what its limitations might be—hundreds of millions of people now use this technology every day.

To help overcome our ignorance, researchers are studying LLMs as if they were doing biology or neuroscience on vast living creatures—city-size xenomorphs that have appeared in our midst. And they’re discovering that large language models are even weirder than they thought. Read the full story.—Will Douglas Heaven

This is our latest story to be turned into a MIT Technology Review Narrated podcast, which we publish each week on Spotify and Apple Podcasts. Just navigate to MIT Technology Review Narrated on either platform, and follow us to get all our new content as it’s released.

And mechanistic interpretability, the technique these researchers are using to try and understand AI models, is one of our 10 Breakthrough Technologies for 2026. Check out the rest of the list here!

Job titles of the future: Head-transplant surgeon

The Italian neurosurgeon Sergio Canavero has been preparing for a surgery that might never happen. His idea? Swap a sick person’s head—or perhaps just the brain—onto a younger, healthier body.Canavero caused a stir in 2017 when he announced that a team he advised in China had exchanged heads between two corpses. But he never convinced skeptics that his technique could succeed—or to believe his claim that a procedure on a live person was imminent.

Canavero may have withdrawn from the spotlight, but the idea of head transplants isn’t going away. Instead, he says, the concept has recently been getting a fresh look from life-extension enthusiasts and stealth Silicon Valley startups. Read the full story.

This story is from the latest print issue of MIT Technology Review magazine, which is all about exciting innovations. If you haven’t already, subscribe now to receive future issues once they land.

I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.

1 Big Tech is facing multiple high-profile social media addiction lawsuits Meta, TikTok and YouTube will face parents’ accusations in court this week. (WP $)+ It’s the first time they’re defending against these claims before a jury in a court of law. (CNN)2 Power prices are surging in the world’s largest data center hubVirginia is struggling to meet record demand during a winter storm, partly because of the centers’ electricity demands. (Reuters)+ Why these kinds of violent storms are getting harder to forecast. (Vox)+ AI is changing the grid. Could it help more than it harms? (MIT Technology Review)3 TikTok has started collecting even more data on its usersIncluding precise information about their location. (Wired $)4 ICE-watching groups are successfully fighting DHS efforts to unmask themAn anonymous account holder sued to block ICE from identifying them—and won. (Ars Technica)5 A new wave of AI companies want to use AI to make AI betterThe AI ouroboros is never-ending. (NYT $)+ Is AI really capable of making bona fide scientific advancements? (Undark)+ AI trained on AI garbage spits out AI garbage. (MIT Technology Review)

6 Iran is testing a two-tier internetMeaning its current blackout could become permanent. (Rest of World)7 Don’t believe the humanoid robot hypeEven a leading robot maker admits that at best, they’re only half as efficient as humans. (FT $)+ Tesla wants to put its Optimus bipedal machine to work in its Austin factory. (Insider)+ Why the humanoid workforce is running late. (MIT Technology Review)

8 AI is changing how manufacturers create new productsIncluding thinner chewing gum containers and new body wash odors. (WSJ $)+ AI could make better beer. Here’s how. (MIT Technology Review)9 New Jersey has had enough of e-bikes 🚲But will other US states follow its lead? (The Verge)10 Sci-fi writers are cracking down on AIHuman-produced works only, please. (TechCrunch)+ San Diego Comic-Con was previously a safe space for AI-generated art. (404 Media)+ Generative AI is reshaping South Korea’s webcomics industry. (MIT Technology Review)

“Choosing American digital technology by default is too easy and must stop.”

—Nicolas Dufourcq, head of French state-owned investment bank Bpifrance, makes his case for why Big European companies should use European-made software as tensions with the US rise, the Wall Street Journal reports.

The return of pneumatic tubesPneumatic tubes were once touted as something that would revolutionize the world. In science fiction, they were envisioned as a fundamental part of the future—even in dystopias like George Orwell’s 1984, where they help to deliver orders for the main character, Winston Smith, in his job rewriting history to fit the ruling party’s changing narrative.In real life, the tubes were expected to transform several industries in the late 19th century through the mid-20th. For a while, the United States took up the systems with gusto.But by the mid to late 20th century, use of the technology had largely fallen by the wayside, and pneumatic tube technology became virtually obsolete. Except in hospitals. Read the full story.

A place for comfort, fun and distraction to brighten up your day. (Got any ideas? Drop me a line or skeet &#39;em at me.)

+ You really can’t beat the humble jacket potato for a cheap, comforting meal. + These tips might help you whenever anxiety strikes. ($)+ There are some amazing photos in this year’s Capturing Ecology awards.+ You can benefit from meditation any time, anywhere. Give it a go!

Plus: OpenAI is sounding the &quot;code red&quot; alarm

Plus: TikTok has finally signed a deal to keep operating in the US

Plus: This company is developing gene therapies for muscle growth, erectile dysfunction, and “radical longevity”

Plus: China has built a major chip-making machine

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-56')">
            <div class="source">MIT Technology Review</div>
            <div class="title">The Download: chatbots for health, and US fights over AI regulation</div>
            <div class="meta">2026-01-23</div>
        </div>
        
        <div id="content-56" style="display:none;">
            <h2>The Download: chatbots for health, and US fights over AI regulation</h2>
            <p><strong>MIT Technology Review | 2026-01-23</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2026/01/23/1131708/the-download-chatbots-for-health-and-us-fights-over-ai-regulation/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">This is today&#39;s edition of The Download, our weekday newsletter that provides a daily dose of what&#39;s going on in the world of technology.

For the past two decades, there’s been a clear first step for anyone who starts experiencing new medical symptoms: Look them up online. The practice was so common that it gained the pejorative moniker “Dr. Google.” But times are changing, and many medical-information seekers are now using LLMs. According to OpenAI, 230 million people ask ChatGPT health-related queries each week.

That’s the context around the launch of OpenAI’s new ChatGPT Health product, which debuted earlier this month. The big question is: can the obvious risks of using AI for health-related queries be mitigated enough for them to be a net benefit? Read the full story.

In the final weeks of 2025, the battle over regulating artificial intelligence in the US reached boiling point. On December 11, after Congress failed twice to pass a law banning state AI laws, President Donald Trump signed a sweeping executive order seeking to handcuff states from regulating the booming industry.

Instead, he vowed to work with Congress to establish a “minimally burdensome” national AI policy. The move marked a victory for tech titans, who have been marshaling multimillion-dollar war chests to oppose AI regulations, arguing that a patchwork of state laws would stifle innovation.

In 2026, the battleground will shift to the courts. While some states might back down from passing AI laws, others will charge ahead. Read our story about what’s on the horizon.

This story is from MIT Technology Review’s What’s Next series of stories that look across industries, trends, and technologies to give you a first look at the future. You can read the rest of them here.

This week marked a rather unpleasant anniversary: It’s a year since Texas reported a case of measles—the start of a significant outbreak that ended up spreading across multiple states. Since the start of January 2025, there have been over 2,500 confirmed cases of measles in the US. Three people have died.

As vaccination rates drop and outbreaks continue, scientists have been experimenting with new ways to quickly identify new cases and prevent the disease from spreading. And they are starting to see some success with wastewater surveillance. Read the full story.

This story is from The Checkup, our weekly newsletter giving you the inside track on all things health and biotech. Sign up to receive it in your inbox every Thursday.

I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.

1 The US is dismantling itselfA foreign enemy could not invent a better chain of events to wreck its standing in the world. (Wired $)  + We need to talk about whether Donald Trump might be losing it.  (New Yorker $)2 Big Tech is taking on more debt to fund its AI aspirationsAnd the bubble just keeps growing. (WP $)+ Forget unicorns. 2026 is shaping up to be the year of the “hectocorn.” (The Guardian)+ Everyone in tech agrees we’re in a bubble. They just can’t agree on what happens when it pops. (MIT Technology Review)

3 DOGE accessed even more personal data than we thought Even now, the Trump administration still can’t say how much data is at risk, or what it was used for. (NPR)

4 TikTok has finalized a deal to create a new US entity Ending years of uncertainty about its fate in America. (CNN)+ Why China is the big winner out of all of this. (FT $)

5 The US is now officially out of the World Health Organization And it’s leaving behind nearly $300 million in bills unpaid. (Ars Technica) + The US withdrawal from the WHO will hurt us all. (MIT Technology Review)6 AI-powered disinformation swarms pose a threat to democracyA would-be autocrat could use them to persuade populations to accept cancelled elections or overturn results. (The Guardian)+ The era of AI persuasion in elections is about to begin. (MIT Technology Review)7 We’re about to start seeing more robots everywhereBut exactly what they’ll look like remains up for debate. (Vox $)+ Chinese companies are starting to dominate entire sectors of AI and robotics. (MIT Technology Review)8 Some people seem to be especially vulnerable to lonelinessIf you’re ‘other-directed’, you could particularly benefit from less screentime. (New Scientist $)9 This academic lost two years of work with a single clickTL;DR: Don’t rely on ChatGPT to store your data. (Nature)10 How animals develop a sense of direction 🦇🧭Their ‘internal compass’ seems to be informed by landmarks that help them form a mental map. (Quanta $)

“The rate at which AI is progressing, I think we have AI that is smarter than any human this year, and no later than next year.”

—Elon Musk simply cannot resist the urge to make wild predictions at Davos, Wired reports.

After falling steadily for decades, the prevalence of global hunger is now on the rise—nowhere more so than in sub-Saharan Africa.

Africa’s indigenous crops are often more nutritious and better suited to the hot and dry conditions that are becoming more prevalent, yet many have been neglected by science, which means they tend to be more vulnerable to diseases and pests and yield well below their theoretical potential.

Now the question is whether researchers, governments, and farmers can work together in a way that gets these crops onto plates and provides Africans from all walks of life with the energy and nutrition that they need to thrive, whatever climate change throws their way. Read the full story.

A place for comfort, fun and distraction to brighten up your day. (Got any ideas? Drop me a line or skeet &#39;em at me.)

+ The only thing I fancy dry this January is a martini. Here’s how to make one.+ If you absolutely adore the Bic crystal pen, you might want this lamp. + Cozy up with a nice long book this winter. ($)+ Want to eat healthier? Slow down and tune out food ‘noise’. ($)

Plus: OpenAI is sounding the &quot;code red&quot; alarm

Plus: TikTok has finally signed a deal to keep operating in the US

Plus: This company is developing gene therapies for muscle growth, erectile dysfunction, and “radical longevity”

Plus: China has built a major chip-making machine

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-57')">
            <div class="source">MIT Technology Review</div>
            <div class="title">America’s coming war over AI regulation</div>
            <div class="meta">2026-01-23</div>
        </div>
        
        <div id="content-57" style="display:none;">
            <h2>America’s coming war over AI regulation</h2>
            <p><strong>MIT Technology Review | 2026-01-23</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2026/01/23/1131559/americas-coming-war-over-ai-regulation/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">MIT Technology Review’s What’s Next series looks across industries, trends, and technologies to give you a first look at the future. You can read the rest of them here.

In the final weeks of 2025, the battle over regulating artificial intelligence in the US reached a boiling point. On December 11, after Congress failed twice to pass a law banning state AI laws, President Donald Trump signed a sweeping executive order seeking to handcuff states from regulating the booming industry. Instead, he vowed to work with Congress to establish a “minimally burdensome” national AI policy, one that would position the US to win the global AI race. The move marked a qualified victory for tech titans, who have been marshaling multimillion-dollar war chests to oppose AI regulations, arguing that a patchwork of state laws would stifle innovation.

In 2026, the battleground will shift to the courts. While some states might back down from passing AI laws, others will charge ahead, buoyed by mounting public pressure to protect children from chatbots and rein in power-hungry data centers. Meanwhile, dueling super PACs bankrolled by tech moguls and AI-safety advocates will pour tens of millions into congressional and state elections to seat lawmakers who champion their competing visions for AI regulation.

Trump’s executive order directs the Department of Justice to establish a task force that sues states whose AI laws clash with his vision for light-touch regulation. It also directs the Department of Commerce to starve states of federal broadband funding if their AI laws are “onerous.” In practice, the order may target a handful of laws in Democratic states, says James Grimmelmann, a law professor at Cornell Law School. “The executive order will be used to challenge a smaller number of provisions, mostly relating to transparency and bias in AI, which tend to be more liberal issues,” Grimmelmann says.

For now, many states aren’t flinching. On December 19, New York’s governor, Kathy Hochul, signed the Responsible AI Safety and Education (RAISE) Act, a landmark law requiring AI companies to publish the protocols used to ensure the safe development of their AI models and report critical safety incidents. On January 1, California debuted the nation’s first frontier AI safety law, SB 53—which the RAISE Act was modeled on—aimed at preventing catastrophic harms such as biological weapons or cyberattacks. While both laws were watered down from earlier iterations to survive bruising industry lobbying, they struck a rare, if fragile, compromise between tech giants and AI safety advocates.

If Trump targets these hard-won laws, Democratic states like California and New York will likely take the fight to court. Republican states like Florida with vocal champions for AI regulation might follow suit. Trump could face an uphill battle. “The Trump administration is stretching itself thin with some of its attempts to effectively preempt [legislation] via executive action,” says Margot Kaminski, a law professor at the University of Colorado Law School. “It’s on thin ice.”

But Republican states that are anxious to stay off Trump’s radar or can’t afford to lose federal broadband funding for their sprawling rural communities might retreat from passing or enforcing AI laws. Win or lose in court, the chaos and uncertainty could chill state lawmaking. Paradoxically, the Democratic states that Trump wants to rein in—armed with big budgets and emboldened by the optics of battling the administration—may be the least likely to budge.

In lieu of state laws, Trump promises to create a federal AI policy with Congress. But the gridlocked and polarized body won’t be delivering a bill this year. In July, the Senate killed a moratorium on state AI laws that had been inserted into a tax bill, and in November, the House scrapped an encore attempt in a defense bill. In fact, Trump’s bid to strong-arm Congress with an executive order may sour any appetite for a bipartisan deal.

The executive order “has made it harder to pass responsible AI policy by hardening a lot of positions, making it a much more partisan issue,” says Brad Carson, a former Democratic congressman from Oklahoma who is building a network of super PACs backing candidates who support AI regulation. “It hardened Democrats and created incredible fault lines among Republicans,” he says.

While AI accelerationists in Trump’s orbit—AI and crypto czar David Sacks among them—champion deregulation, populist MAGA firebrands like Steve Bannon warn of rogue superintelligence and mass unemployment. In response to Trump’s executive order, Republican state attorneys general signed a bipartisan letter urging the FCC not to supersede state AI laws.

With Americans increasingly anxious about how AI could harm mental health, jobs, and the environment, public demand for regulation is growing. If Congress stays paralyzed, states will be the only ones acting to keep the AI industry in check. In 2025, state legislators introduced more than 1,000 AI bills, and nearly 40 states enacted over 100 laws, according to the National Conference of State Legislatures.

Efforts to protect children from chatbots may inspire rare consensus. On January 7, Google and Character Technologies, a startup behind the companion chatbot Character.AI, settled several lawsuits with families of teenagers who killed themselves after interacting with the bot. Just a day later, the Kentucky attorney general sued Character Technologies, alleging that the chatbots drove children to suicide and other forms of self-harm. OpenAI and Meta face a barrage of similar suits. Expect more to pile up this year. Without AI laws on the books, it remains to be seen how product liability laws and free speech doctrines apply to these novel dangers. “It’s an open question what the courts will do,” says Grimmelmann.

While litigation brews, states will move to pass child safety laws, which are exempt from Trump’s proposed ban on state AI laws. On January 9, OpenAI inked a deal with a former foe, the child-safety advocacy group Common Sense Media, to back a ballot initiative in California called the Parents & Kids Safe AI Act, setting guardrails around how chatbots interact with children. The measure proposes requiring AI companies to verify users’ age, offer parental controls, and undergo independent child-safety audits. If passed, it could be a blueprint for states across the country seeking to crack down on chatbots.

Fueled by widespread backlash against data centers, states will also try to regulate the resources needed to run AI. That means bills requiring data centers to report on their power and water use and foot their own electricity bills. If AI starts to displace jobs at scale, labor groups might float AI bans in specific professions. A few states concerned about the catastrophic risks posed by AI may pass safety bills mirroring SB 53 and the RAISE Act.

Meanwhile, tech titans will continue to use their deep pockets to crush AI regulations. Leading the Future, a super PAC backed by OpenAI president Greg Brockman and the venture capital firm Andreessen Horowitz, will try to elect candidates who endorse unfettered AI development to Congress and state legislatures. They’ll follow the crypto industry’s playbook for electing allies and writing the rules. To counter this, super PACs funded by Public First, an organization run by Carson and former Republican congressman Chris Stewart of Utah, will back candidates advocating for AI regulation. We might even see a handful of candidates running on anti-AI populist platforms.

In 2026, the slow, messy process of American democracy will grind on. And the rules written in state capitals could decide how the most disruptive technology of our generation develops far beyond America’s borders, for years to come.

Four ways to think about this year&#39;s reckoning.

Our AI writers make their big bets for the coming year—here are five hot trends to watch.

By studying large language models as if they were living things instead of computer programs, scientists are discovering some of their secrets for the first time.

In an exclusive interview, the AI pioneer shares his plans for his new Paris-based company, AMI Labs.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-58')">
            <div class="source">MIT Technology Review</div>
            <div class="title">Measles is surging in the US. Wastewater tracking could help.</div>
            <div class="meta">2026-01-23</div>
        </div>
        
        <div id="content-58" style="display:none;">
            <h2>Measles is surging in the US. Wastewater tracking could help.</h2>
            <p><strong>MIT Technology Review | 2026-01-23</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2026/01/23/1131698/measles-surging-us-wastewater-tracking/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">This week marked a rather unpleasant anniversary: It’s a year since Texas reported a case of measles—the start of a significant outbreak that ended up spreading across multiple states. Since the start of January 2025, there have been over 2,500 confirmed cases of measles in the US. Three people have died.

As vaccination rates drop and outbreaks continue, scientists have been experimenting with new ways to quickly identify new cases and prevent the disease from spreading. And they are starting to see some success with wastewater surveillance.

After all, wastewater contains saliva, urine, feces, shed skin, and more. You could consider it a rich biological sample. Wastewater analysis helped scientists understand how covid was spreading during the pandemic. It’s early days, but it is starting to help us get a handle on measles.

Globally, there has been some progress toward eliminating measles, largely thanks to vaccination efforts. Such efforts led to an 88% drop in measles deaths between 2000 and 2024, according to the World Health Organization. It estimates that “nearly 59 million lives have been saved by the measles vaccine” since 2000.

Still, an estimated 95,000 people died from measles in 2024 alone—most of them young children. And cases are surging in Europe, Southeast Asia, and the Eastern Mediterranean region.

Last year, the US saw the highest levels of measles in decades. The country is on track to lose its measles elimination status—a sorry fate that met Canada in November after the country recorded over 5,000 cases in a little over a year.

Public health efforts to contain the spread of measles—which is incredibly contagious—typically involve clinical monitoring in health-care settings, along with vaccination campaigns. But scientists have started looking to wastewater, too.

Along with various bodily fluids, we all shed viruses and bacteria into wastewater, whether that’s through brushing our teeth, showering, or using the toilet. The idea of looking for these pathogens in wastewater to track diseases has been around for a while, but things really kicked into gear during the covid-19 pandemic, when scientists found that the coronavirus responsible for the disease was shed in feces.

This led Marlene Wolfe of Emory University and Alexandria Boehm of Stanford University to establish WastewaterSCAN, an academic-led program developed to analyze wastewater samples across the US. Covid was just the beginning, says Wolfe. “Over the years we have worked to expand what can be monitored,” she says.

Two years ago, for a previous edition of the Checkup, Wolfe told Cassandra Willyard that wastewater surveillance of measles was “absolutely possible,” as the virus is shed in urine. The hope was that this approach could shed light on measles outbreaks in a community, even if members of that community weren’t able to access health care and receive an official diagnosis. And that it could highlight when and where public health officials needed to act to prevent measles from spreading. Evidence that it worked as an effective public health measure was, at the time, scant.

Since then, she and her colleagues have developed a test to identify measles RNA. They trialed it at two wastewater treatment plants in Texas between December 2024 and May 2025. At each site, the team collected samples two or three times a week and tested them for measles RNA.

Over that period, the team found measles RNA in 10.5% of the samples they collected, as reported in a preprint paper published at medRxiv in July and currently under review at a peer-reviewed journal. The first detection came a week before the first case of measles was officially confirmed in the area. That’s promising—it suggests that wastewater surveillance might pick up measles cases early, giving public health officials a head start in efforts to limit any outbreaks.

There are more promising results from a team in Canada. Mike McKay and Ryland Corchis-Scott at the University of Windsor in Ontario and their colleagues have also been testing wastewater samples for measles RNA. Between February and November 2025, the team collected samples from a wastewater treatment facility serving over 30,000 people in Leamington, Ontario.

These wastewater tests are somewhat limited—even if they do pick up measles, they won’t tell you who has measles, where exactly infections are occurring, or even how many people are infected. McKay and his colleagues have begun to make some progress here. In addition to monitoring the large wastewater plant, the team used tampons to soak up wastewater from a hospital lateral sewer.

They then compared their measles test results with the number of clinical cases in that hospital. This gave them some idea of the virus’s “shedding rate.” When they applied this to the data collected from the Leamington wastewater treatment facility, the team got estimates of measles cases that were much higher than the figures officially reported.

Their findings track with the opinions of local health officials (who estimate that the true number of cases during the outbreak was around five to 10 times higher than the confirmed case count), the team members wrote in a paper published on medRxiv a couple of weeks ago.

There will always be limits to wastewater surveillance. “We’re looking at the pool of waste of an entire community, so it’s very hard to pull in information about individual infections,” says Corchis-Scott.

Wolfe also acknowledges that “we have a lot to learn about how we can best use the tools so they are useful.” But her team at WastewaterSCAN has been testing wastewater across the US for measles since May last year. And their findings are published online and shared with public health officials.

In some cases, the findings are already helping inform the response to measles. “We’ve seen public health departments act on this data,” says Wolfe. Some have issued alerts, or increased vaccination efforts in those areas, for example. “[We’re at] a point now where we really see public health departments, clinicians, [and] families using that information to help keep themselves and their communities safe,” she says.

McKay says his team has stopped testing for measles because the Ontario outbreak “has been declared over.” He says testing would restart if and when a single new case of measles is confirmed in the region, but he also thinks that his research makes a strong case for maintaining a wastewater surveillance system for measles.

McKay wonders if this approach might help Canada regain its measles elimination status. “It’s sort of like [we’re] a pariah now,” he says. If his approach can help limit measles outbreaks, it could be “a nice tool for public health in Canada to [show] we’ve got our act together.”

This article first appeared in The Checkup, MIT Technology Review’s weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first, sign up here.

A startup’s ads for controversial embryo tests hit the New York City subway.

Questions surround their effects on brain health, pregnancy or long-term use.

Why personalized gene editing, genetic resurrections and embryo scoring made our list.

A small group of volunteers will receive multiple injections of the experimental treatments next month, says Unlimited Bio.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-59')">
            <div class="source">MIT Technology Review</div>
            <div class="title">“Dr. Google” had its issues. Can ChatGPT Health do better?</div>
            <div class="meta">2026-01-22</div>
        </div>
        
        <div id="content-59" style="display:none;">
            <h2>“Dr. Google” had its issues. Can ChatGPT Health do better?</h2>
            <p><strong>MIT Technology Review | 2026-01-22</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2026/01/22/1131692/dr-google-had-its-issues-can-chatgpt-health-do-better/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">For the past two decades, there’s been a clear first step for anyone who starts experiencing new medical symptoms: Look them up online. The practice was so common that it gained the pejorative moniker “Dr. Google.” But times are changing, and many medical-information seekers are now using LLMs. According to OpenAI, 230 million people ask ChatGPT health-related queries each week.

That’s the context around the launch of OpenAI’s new ChatGPT Health product, which debuted earlier this month. It landed at an inauspicious time: Two days earlier, the news website SFGate had broken the story of Sam Nelson, a teenager who died of an overdose last year after extensive conversations with ChatGPT about how best to combine various drugs. In the wake of both pieces of news, multiple journalists questioned the wisdom of relying for medical advice on a tool that could cause such extreme harm.

Though ChatGPT Health lives in a separate sidebar tab from the rest of ChatGPT, it isn’t a new model. It’s more like a wrapper that provides one of OpenAI’s preexisting models with guidance and tools it can use to provide health advice—including some that allow it to access a user’s electronic medical records and fitness app data, if granted permission. There’s no doubt that ChatGPT and other large language models can make medical mistakes, and OpenAI emphasizes that ChatGPT Health is intended as an additional support, rather than a replacement for one’s doctor. But when doctors are unavailable or unable to help, people will turn to alternatives.

Some doctors see LLMs as a boon for medical literacy. The average patient might struggle to navigate the vast landscape of online medical information—and, in particular, to distinguish high-quality sources from polished but factually dubious websites—but LLMs can do that job for them, at least in theory. Treating patients who had searched for their symptoms on Google required “a lot of attacking patient anxiety [and] reducing misinformation,” says Marc Succi, an associate professor at Harvard Medical School and a practicing radiologist. But now, he says, “you see patients with a college education, a high school education, asking questions at the level of something an early med student might ask.”

The release of ChatGPT Health, and Anthropic’s subsequent announcement of new health integrations for Claude, indicate that the AI giants are increasingly willing to acknowledge and encourage health-related uses of their models. Such uses certainly come with risks, given LLMs’ well-documented tendencies to agree with users and make up information rather than admit ignorance.

But those risks also have to be weighed against potential benefits. There’s an analogy here to autonomous vehicles: When policymakers consider whether to allow Waymo in their city, the key metric is not whether its cars are ever involved in accidents but whether they cause less harm than the status quo of relying on human drivers. If Dr. ChatGPT is an improvement over Dr. Google—and early evidence suggests it may be—it could potentially lessen the enormous burden of medical misinformation and unnecessary health anxiety that the internet has created.

Pinning down the effectiveness of a chatbot such as ChatGPT or Claude for consumer health, however, is tricky. “It’s exceedingly difficult to evaluate an open-ended chatbot,” says Danielle Bitterman, the clinical lead for data science and AI at the Mass General Brigham health-care system. Large language models score well on medical licensing examinations, but those exams use multiple-choice questions that don’t reflect how people use chatbots to look up medical information.

Sirisha Rambhatla, an assistant professor of management science and engineering at the University of Waterloo, attempted to close that gap by evaluating how GPT-4o responded to licensing exam questions when it did not have access to a list of possible answers. Medical experts who evaluated the responses scored only about half of them as entirely correct. But multiple-choice exam questions are designed to be tricky enough that the answer options don’t give them entirely away, and they’re still a pretty distant approximation for the sort of thing that a user would type into ChatGPT.

A different study, which tested GPT-4o on more realistic prompts submitted by human volunteers, found that it answered medical questions correctly about 85% of the time. When I spoke with Amulya Yadav, an associate professor at Pennsylvania State University who runs the Responsible AI for Social Emancipation Lab and led the study, he made it clear that he wasn’t personally a fan of patient-facing medical LLMs. But he freely admits that, technically speaking, they seem up to the task—after all, he says, human doctors misdiagnose patients 10% to 15% of the time. “If I look at it dispassionately, it seems that the world is gonna change, whether I like it or not,” he says.

For people seeking medical information online, Yadav says, LLMs do seem to be a better choice than Google. Succi, the radiologist, also concluded that LLMs can be a better alternative to web search when he compared GPT-4’s responses to questions about common chronic medical conditions with the information presented in Google’s knowledge panel, the information box that sometimes appears on the right side of the search results.

Since Yadav’s and Succi’s studies appeared online, in the first half of 2025, OpenAI has released multiple new versions of GPT, and it’s reasonable to expect that GPT-5.2 would perform even better than its predecessors. But the studies do have important limitations: They focus on straightforward, factual questions, and they examine only brief interactions between users and chatbots or web search tools. Some of the weaknesses of LLMs—most notably their sycophancy and tendency to hallucinate—might be more likely to rear their heads in more extensive conversations and with people who are dealing with more complex problems. Reeva Lederman, a professor at the University of Melbourne who studies technology and health, notes that patients who don’t like the diagnosis or treatment recommendations that they receive from a doctor might seek out another opinion from an LLM—and the LLM, if it’s sycophantic, might encourage them to reject their doctor’s advice.

Some studies have found that LLMs will hallucinate and exhibit sycophancy in response to health-related prompts. For example, one study showed that GPT-4 and GPT-4o will happily accept and run with incorrect drug information included in a user’s question. In another, GPT-4o frequently concocted definitions for fake syndromes and lab tests mentioned in the user’s prompt. Given the abundance of medically dubious diagnoses and treatments floating around the internet, these patterns of LLM behavior could contribute to the spread of medical misinformation, particularly if people see LLMs as trustworthy.

OpenAI has reported that the GPT-5 series of models is markedly less sycophantic and prone to hallucination than their predecessors, so the results of these studies might not apply to ChatGPT Health. The company also evaluated the model that powers ChatGPT Health on its responses to health-specific questions, using their publicly available HeathBench benchmark. HealthBench rewards models that express uncertainty when appropriate, recommend that users seek medical attention when necessary, and refrain from causing users unnecessary stress by telling them their condition is more serious that it truly is. It’s reasonable to assume that the model underlying ChatGPT Health exhibited those behaviors in testing, though Bitterman notes that some of the prompts in HealthBench were generated by LLMs, not users, which could limit how well the benchmark translates into the real world.

An LLM that avoids alarmism seems like a clear improvement over systems that have people convincing themselves they have cancer after a few minutes of browsing. And as large language models, and the products built around them, continue to develop, whatever advantage Dr. ChatGPT has over Dr. Google will likely grow. The introduction of ChatGPT Health is certainly a move in that direction: By looking through your medical records, ChatGPT can potentially gain far more context about your specific health situation than could be included in any Google search, although numerous experts have cautioned against giving ChatGPT that access for privacy reasons.

Even if ChatGPT Health and other new tools do represent a meaningful improvement over Google searches, they could still conceivably have a negative effect on health overall. Much as automated vehicles, even if they are safer than human-driven cars, might still prove a net negative if they encourage people to use public transit less, LLMs could undermine users’ health if they induce people to rely on the internet instead of human doctors, even if they do increase the quality of health information available online.

Lederman says that this outcome is plausible. In her research, she has found that members of online communities centered on health tend to put their trust in users who express themselves well, regardless of the validity of the information they are sharing. Because ChatGPT communicates like an articulate person, some people might trust it too much, potentially to the exclusion of their doctor. But LLMs are certainly no replacement for a human doctor—at least not yet.

Four ways to think about this year&#39;s reckoning.

Our AI writers make their big bets for the coming year—here are five hot trends to watch.

By studying large language models as if they were living things instead of computer programs, scientists are discovering some of their secrets for the first time.

In an exclusive interview, the AI pioneer shares his plans for his new Paris-based company, AMI Labs.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-60')">
            <div class="source">The Next Web</div>
            <div class="title">Rainbow Weather raises $5.5M to refine real-time weather forecasting</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-60" style="display:none;">
            <h2>Rainbow Weather raises $5.5M to refine real-time weather forecasting</h2>
            <p><strong>The Next Web | 2026-01-26</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/rainbow-weather-raises-5-5m-to-refine-real-time-weather-forecasting">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Warsaw, Poland 26 January 2026 – Rainbow Weather has raised $5.5 million in seed funding to push weather forecasting further into the short-term, high-precision territory it believes the industry still underserves.

The Warsaw-based climate tech startup focuses on hyperlocal, minute-by-minute forecasts, zeroing in on what happens in the next few hours rather than days out.

The round was backed by a syndicate of investors, including Yuri Gurski, founder of Flo Health, one of Europe’s best-known consumer tech unicorns.

Rainbow Weather’s core product is a mobile app that delivers four-hour precipitation forecasts calculated from the exact moment a user checks the weather.

Open the app at 3:51 am, and it forecasts conditions through 7:51am, refreshed every 10 minutes and mapped down to a one-square-kilometre grid. That level of temporal and spatial precision is what the company says sets it apart from mainstream weather apps.

The latest rumblings from the EU tech scene, a story from our wise ol&#39; founder Boris, and some questionable AI art. It&#39;s free, every week, in your inbox. Sign up now!

Most major providers, including AccuWeather, Apple Weather, and The Weather Company, still rely on approaches that either simplify cloud movement or depend on large-scale numerical models designed for longer forecasts. According to Rainbow Weather, both methods struggle when conditions change quickly.

“Many legacy forecasting providers rely on optical flow for short-term precipitation forecasting. That’s a fast but simplistic method that treats clouds as shapes in motion, without any understanding of atmospheric physics,” explained Alexander Matveenko, co-founder of Rainbow Weather. “A second category of services uses large-scale mathematical models that do incorporate physical principles, but they’re so cumbersome and slow that they can’t respond quickly to real-time weather changes.”

Rainbow Weather positions itself in between, using machine learning to fuse high-resolution data from radar, satellites, weather stations, and even smartphone barometers. By combining these sources, the company claims it can reduce the noise and bias inherent in individual datasets, then generate forecasts faster than traditional systems.

The app currently focuses on short-term precipitation, but it has expanded into tracking wildfires and hurricanes, a feature added after the Palisades fire in Los Angeles. That expansion reflects a broader ambition to become a real-time risk awareness tool, not just a rain predictor.

The new funding will be used to extend Rainbow Weather’s forecasting window from four hours to 24 hours, add more weather parameters beyond precipitation, and grow its B2B offering.

The commercial weather intelligence market is expected to grow steadily over the next decade, driven by industries that depend on precise, near-term forecasts, from logistics and agriculture to aviation and drone operations.

Rainbow Weather says it has surpassed one million installs and has launched APIs aimed at companies that “can’t afford to get weather wrong.” It has also partnered with an unnamed long-term forecasting firm, supplying near-term data to improve broader climate models.

The founding team brings a track record of exits in applied AI. CEO Yuriy Melnichek previously founded AIMatter, acquired by Google, as well as consumer apps later bought by Pinterest and Farfetch. Matveenko previously sold mapping startup MapData to Mapbox.

Alongside its commercial products, the team also runs weatherindex.ai, an open-source project that evaluates short-term precipitation forecasts from major providers in real time. The tool compares live forecasts against verified airport weather reports, using standard accuracy metrics. It’s an unusual move in an industry not known for transparent benchmarking.

For Rainbow Weather, that openness is part of the pitch. The company is betting that as climate volatility increases, users and businesses will care less about next week’s weather and more about what happens in the next hour, and whether the forecast can be trusted.

Rainbow Weather is a next-gen climate tech startup for ultra-accurate short-term forecasts founded in 2021 by Yuriy Melnichek, who previously built AIMatter (acquired by Google), a neural network-based AI platform, as well as the video creation and editing app Vochi (acquired by Pinterest), and fashion marketplace Wanna (acquired by Farfetch), and Alexander Matveenko, a founder of artificial intelligence mapping startup MapData that he sold to Mapbox in 2017.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-61')">
            <div class="source">The Next Web</div>
            <div class="title">Synthesia’s valuation jumps to $4B after $200M raise</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-61" style="display:none;">
            <h2>Synthesia’s valuation jumps to $4B after $200M raise</h2>
            <p><strong>The Next Web | 2026-01-26</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/synthesias-valuation-jumps-to-4b-after-200m-raise">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">London-based AI video startup Synthesia has raised $200 million in a Series E round, nearly doubling its valuation to around $4 billion and cementing its position as one of Europe’s most valuable AI companies.

The round was led by Google Ventures, with participation from existing investors, underscoring continued appetite for applied AI products that have already found a clear commercial use.

Synthesia builds generative AI tools that let companies create videos using AI-generated avatars instead of cameras, studios, or presenters. The technology has found a strong foothold in corporate training, internal communications, and product explainers, areas where speed, scale, and consistency often matter more than production gloss.

“Synthesia was founded on two core beliefs: first, that AI will bring the cost of content creation down to zero. And secondly, that AI video provides a better, more engaging way for organizations to communicate and learn,” said Victor Riparbelli, Synthesia’s co-founder and CEO.

Synthesia says a significant share of Fortune 100 companies now use its platform, a rare level of enterprise penetration for a European AI startup at this stage. Rather than chasing consumer virality, the company has built its business around predictable, high-value enterprise use cases, a strategy investors have increasingly rewarded over the past year.

The funding comes at a moment when enthusiasm around generative AI has shifted from experimentation to execution. Enterprises are no longer asking whether AI video works, but how reliably it can plug into existing workflows.

The latest rumblings from the EU tech scene, a story from our wise ol&#39; founder Boris, and some questionable AI art. It&#39;s free, every week, in your inbox. Sign up now!

Synthesia’s pitch is that AI-generated video should be as routine as slides or documents, created quickly, updated easily, and deployed globally without production bottlenecks.

At a $4 billion valuation, Synthesia joins a small group of European AI companies that have managed to scale beyond regional relevance.

Its rise also highlights a broader pattern: applied AI startups, focused on specific business functions rather than general-purpose models, are attracting some of the largest growth rounds in the market.

For the UK tech ecosystem, the deal is another signal that London remains a serious hub for commercial AI, even as regulatory debates continue around model safety, copyright, and synthetic media.

Synthesia has previously positioned itself as cautious about misuse, building safeguards around consent and disclosure for its avatars, a stance that may become more important as scrutiny of AI-generated content increases.

The challenge ahead is less about proving demand and more about maintaining trust and differentiation as competitors multiply.

But with deep enterprise adoption, a clear product focus, and backing from one of Silicon Valley’s most influential investors, Synthesia is entering its next phase with momentum firmly on its side.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-62')">
            <div class="source">The Next Web</div>
            <div class="title">TNW Weekly Briefing</div>
            <div class="meta">2026-01-25</div>
        </div>
        
        <div id="content-62" style="display:none;">
            <h2>TNW Weekly Briefing</h2>
            <p><strong>The Next Web | 2026-01-25</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/tnw-weekly-briefing-2">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">What: The European Commission unveiled EU Inc (“28th regime”), a single EU-wide legal company structure designed to let startups incorporate once and operate across all member states.
Who it affects: European startups & scale-ups, founders, VCs, international investors.
How: Reduces legal fragmentation, standardises corporate and investment structures, lowers friction for cross-border scaling.
Impact timing: Strategic impact now (capital & expectations), real operational impact from 2027–2028.

What: The EU proposed mandatory rules to remove and replace technology from suppliers deemed “high-risk” in telecoms and other critical networks.
Who it affects: Telecom operators, infrastructure providers, governments, Chinese tech vendors, cybersecurity supply chains.
How: Forces equipment replacement, raises capex, hardens security requirements across Europe.
Impact timing: Immediate policy impact, execution over the next few years.

What: European institutions publicly backed a strategy to reduce reliance on US technology across cloud, software, semiconductors and AI, often referred to as building a European “tech stack.”
Who it affects: US hyperscalers, European cloud & AI companies, policymakers, public procurement.
How: Shapes future regulation, funding priorities and government tech buying decisions.
Impact timing: Political and strategic impact now, regulatory and market impact medium-term.

This week wasn’t about hype:
EU Inc sets the future structure, high-risk tech phase-out enforces security now, and tech sovereignty defines Europe’s direction.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-63')">
            <div class="source">The Next Web</div>
            <div class="title">Mews raises €255M to accelerate AI and automation in hospitality</div>
            <div class="meta">2026-01-24</div>
        </div>
        
        <div id="content-63" style="display:none;">
            <h2>Mews raises €255M to accelerate AI and automation in hospitality</h2>
            <p><strong>The Next Web | 2026-01-24</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/mews-raises-e255m-to-accelerate-ai-and-automation-in-hospitality">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Amsterdam-based hospitality tech platform Mews has raised €255 million (about $300 million) in a Series D funding round as it pushes deeper into automation and AI-powered workflows for hotels around the world.

The round was led by EQT Growth with new participation from Atomico and HarbourVest Partners, alongside existing backers including Kinnevik, Battery Ventures and Tiger Global. The investment values the company at roughly $2.5 billion.

Founded in 2012 by Richard Valtr and Matt Welle, Mews builds a cloud-native “operating system” for hotels  software that ties together reservations, check-ins, housekeeping, payments and more in one platform.

Its technology is designed to replace legacy systems that many hotels still rely on, offering a more flexible, connected way to manage day-to-day operations.

The new funding will be used to expand the company’s AI and automation capabilities at the core of its product.

The latest rumblings from the EU tech scene, a story from our wise ol&#39; founder Boris, and some questionable AI art. It&#39;s free, every week, in your inbox. Sign up now!

That includes embedding agent-driven systems that can take on complex routine tasks, reduce manual work for staff and streamline how hotels handle everything from guest interactions to revenue management.

Mews says its platform already supports more than 15,000 properties in 85 countries, and in 2025 it processed nearly 42.3 million check-ins and handled nearly $20 billion in transaction volume.

The software also helped generate over $500 million in additional revenue for hoteliers through features like its Mews Spaces module.

In a statement, CEO Matt Welle said the new capital will help Mews build an operating system that handles operational complexity so hotel teams can focus on guest experience rather than juggling disparate tools.

“We are engineering an operating system that is changing how hoteliers interact with their guests,” CEO Matt Welle said, adding that the goal is to lighten the cognitive load on staff and make everyday operations smoother.

Industry observers say the round is one of the largest ever in hospitality software and reflects broader investor interest in infrastructure-level platforms that bring AI and fintech together for real-world business operations.

As hotels embrace digital transformation, technology that can automate workflows and personalise guest experiences  without adding complexity is increasingly in demand.

For Mews, the challenge now is execution: turning generous funding into tangible upgrades that deliver value for hoteliers of all sizes.

But with strong adoption, a global footprint and a growing suite of automation tools, the company is positioning itself as a central technology partner at a time when hotels are looking to modernise their operations and enhance guest satisfaction.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-64')">
            <div class="source">The Next Web</div>
            <div class="title">How Flippa Is Removing the Language Barrier from Global Deal-Making</div>
            <div class="meta">2026-01-23</div>
        </div>
        
        <div id="content-64" style="display:none;">
            <h2>How Flippa Is Removing the Language Barrier from Global Deal-Making</h2>
            <p><strong>The Next Web | 2026-01-23</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/how-flippa-is-removing-the-language-barrier-from-global-deal-making">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">For decades, access to high-quality deal flow and sophisticated M&A infrastructure has been largely designed for well-connected investors and industry giants. Small businesses and independent founders, particularly those operating outside English-speaking markets, may often find the barriers even higher. Language, geography, and limited access to networks could mean that opportunity stops at the border.

Amidst this trend, Flippa, a platform for buying and selling digital businesses, is rewriting the script and dismantling those barriers. Under the leadership of CEO Blake Hutchison, the company has connected buyers and sellers across continents, linguistic differences, and price points, closing deals from $100,000 up to $10 million. Now, with the launch of its AI-powered multi-language Deal Room, Flippa is addressing what it sees as one of the last major points of disadvantage in global business deals and M&A, calling it the “Language Tax.”

Founded in 2009, Flippa has grown into a global marketplace where entrepreneurs can buy and sell digital assets ranging from e-commerce stores and SaaS businesses to YouTube channels, online communities, and mobile applications. According to Hutchison, the platform supports users from 189 countries, attracting over 450,000 new buyers in the last two years alone. “Our internal data shows that cross-border transactions now account for approximately 85% of all deals completed on the platform,” Hutchison says. “That growth has been especially pronounced in Europe. As a highly fragmented market with high cross-border trade volume but multiple operating languages, I believe Europe often faces structural friction in cross-border dealmaking.”

He notes that European businesses are increasingly being acquired by international buyers, with US-based acquirers representing a significant share of demand. Yet, as deal volumes continue to decline, Hutchison believes that language barriers have historically slowed or derailed otherwise viable transactions.

The latest rumblings from the EU tech scene, a story from our wise ol&#39; founder Boris, and some questionable AI art. It&#39;s free, every week, in your inbox. Sign up now!

The company’s new multi-language Deal Room is designed to remove that friction entirely. Within the Deal Room, Hutchison notes that buyers and sellers can now negotiate and transact in their preferred languages. “For example, a French seller can communicate in French with an Italian or English-speaking buyer, who receives the message instantly translated into their own language,” he says, explaining how replies can be translated back in real time, while preserving the original message for verification and clarity.

Hutchison states, “Our goal is to make deal-making as efficient and approachable as possible. Whether you are a SaaS founder in Paris or an e-commerce operator in Berlin, you should be able to negotiate your exit in the language of your choice.”

Alongside the Deal Room translation tool, Flippa has also launched a fully localized French version of its platform, with Spanish scheduled to follow shortly. The expansion reflects the user demand and the reality that French and Spanish are not only widely spoken across Europe, but globally. Spanish is spoken by 550 million people globally, and is spoken widely across the US and Brazil. Similarly, French, being the 5th most widely spoken language in the world, has 321 million speakers, with 61.8% of those speakers living in parts of North Africa and Sub-Saharan Africa, significantly extending the global reach of European-founded businesses.

According to Hutchison, this shift comes as Europe’s M&A market continues to rise again, with an estimated USD412 billion in deal value, with mid-market and digital-first businesses representing one of the fastest-growing segments. Flippa’s role, according to Hutchison, has been to create infrastructure for businesses to source deals with greater reach than elite investment banks, but with a fraction of the cost.

“We often describe Flippa as the investment bank for the 99%,” Hutchison says. “The difference now is that geography and language no longer define who gets access. The demand for cross-border deals was already there. The technology simply needed to catch up.”

Flippa continues to integrate AI-driven discovery, valuation, and outreach tools through its proprietary LaurenAI engine. “The model is trained on more than 200,000 historical listings and transactions,” he explains. “The system then helps buyers identify opportunities, estimate enterprise value, and initiate conversations at scale.” It autonomously indexes the web to identify businesses across SaaS, e-commerce, apps, publishing, and next-generation media.

Human expertise remains embedded in the process, with certified brokers and M&A professionals supporting transactions once a match is made. As Hutchison puts it, “LaurenAI gives people the ability to access off-market deals and build pipelines the same way Wall Street players do, but without the barriers of capital or connections.”

He notes that entrepreneurs who may not feel confident negotiating complex deal terms in English can now access global liquidity without intermediaries or external advisors. At the same time, international buyers can gain visibility into high-quality European businesses that were previously difficult to source or engage.

As digital entrepreneurship continues to globalize, Flippa is positioning itself at the center of a more inclusive M&A ecosystem, one where language is no longer a tax on ambition and opportunities. Flippa’s multi-language Deal Room represents a structural shift in how global deal-making can be done. For founders and buyers alike, it signals a future where the next meaningful transaction can begin in any language, from anywhere in the world.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-65')">
            <div class="source">The Next Web</div>
            <div class="title">French fintech Pennylane raises €175M</div>
            <div class="meta">2026-01-23</div>
        </div>
        
        <div id="content-65" style="display:none;">
            <h2>French fintech Pennylane raises €175M</h2>
            <p><strong>The Next Web | 2026-01-23</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/french-fintech-pennylane-raises-e175m">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Paris-based fintech Pennylane has just pulled off one of Europe’s most noteworthy funding rounds of the year, announcing €175 million in new capital to accelerate its push into artificial intelligence and expand its footprint across the continent. 
The round was led by growth investor TCV, with participation from Blackstone Growth and a group of existing backers that includes Sequoia Capital, DST Global, CapitalG and Meritech Capital.

What makes this raise stand out isn’t just the size of the cheque, though €175 million is hard to ignore in a selective funding market, but the strategic timing and purpose behind it. Pennylane says it didn’t need the capital to survive; it chose to raise now to double down on AI product development and prepare for a phase of market consolidation in European financial software.

Since its founding in 2020, Pennylane has positioned itself as more than just an accounting tool. It has built what it calls a financial operating system for small and mid-sized businesses and the accountants who serve them, bringing invoicing, payments, bookkeeping, and cash-flow management into a shared platform.

That unified approach taps a persistent pain point in Europe’s SME economy, where many companies still stitch together separate systems to manage their finances.

TNW City Coworking space - Where your best work happens

A workspace designed for growth, collaboration, and endless networking opportunities in the heart of tech.

The new funds will support expanded R&D, particularly in generative AI, with early efforts already focused on building intelligent assistants that help accountants interpret data, automate routine bookkeeping, and deliver richer insights to their clients.

The company is also gearing up for regulatory shifts, including electronic invoicing mandates rolling out across several EU countries and refining localisation for key markets like Germany.

Pennylane’s latest round reportedly values the company at about $4.25 billion (€3.6 billion), reinforcing its unicorn status and standing among Europe’s higher-valued fintech startups. That valuation reflects both investor confidence and the company’s growing footprint: Pennylane is used by thousands of accounting firms and hundreds of thousands of businesses across several European markets.

This deal also underscores a broader trend in European tech: AI is moving beyond buzzy chatbots and large language models into critical business infrastructure.

Fintech tools, compliance software, and productivity platforms are increasingly weaving machine learning and automation into once manual workflows. For accountants juggling multiple clients in different jurisdictions, AI isn’t a luxury; it’s a practical way to keep up with regulatory complexity and expectations for real-time financial insights.

Strategically, Pennylane’s timing matters. European financial software is under pressure to modernise rapidly as digital tax reporting and e-invoicing standards become the norm rather than the exception.

By raising capital now, even without immediate pressure,  Pennylane is planting a flag as these shifts accelerate. The presence of heavyweight global investors like TCV and Blackstone signals that international capital still sees promise in Europe’s SaaS and AI stack.

But there’s a deeper dynamic at play. In Europe, fintech innovation often means balancing diversification with consolidation. Investors backing Pennylane now are betting that the company can serve as a common platform for both accountants and SMEs across borders, a role that gets harder as local regulatory regimes and market expectations diverge.

Generative AI, if deployed thoughtfully, could be what ties all those variations together, letting the platform adapt to local tax rules or reporting needs without keeping teams chained to repetitive work.

From Berlin to Barcelona, founders and investors alike are watching to see whether this latest bet on AI financial tooling pays off. In a funding landscape where some sectors have tightened, and valuations have been scrutinised, Pennylane’s ability to attract major global backers while maintaining founder control and avoiding unnecessary dilution signals that Europe’s fintech scene still has room to grow.

For businesses and accountants alike, the surge in capital behind AI-first tools could translate into more seamless workflows, smarter insights, and faster decision-making.

And if Pennylane’s vision plays out, it might not just be a win for one French unicorn, but a sign that European software can innovate too, not by mimicking Silicon Valley, but by solving problems that are uniquely local, and increasingly global.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-66')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">Russia withdrawing troops from airport in northeast Syria, sources say - Reuters</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-66" style="display:none;">
            <h2>Russia withdrawing troops from airport in northeast Syria, sources say - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2026-01-26</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMipgFBVV95cUxNYUFIdG5FU3V3WWxORXdTbk9nUzVGem9WVnlhNkdybDRiWldDdE5JWENUc3lqTEFkRFA4SW9XNDYxMTBPZTQ5Y3MxZ1gzMHpQWjl1cDBHdTNmdGpnem1PajM4aHJINVROOTFCZm5hTFBlNE5OT1U5U2N1VkM5TWpzWTdhTDFpS01oNlZJYWpGQ1hiTWdmODQ3VlFMVzR6Y0Uxd1B0dFVn?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-67')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">US judge to consider pause to Minnesota crackdown as Trump dispatches border czar - Reuters</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-67" style="display:none;">
            <h2>US judge to consider pause to Minnesota crackdown as Trump dispatches border czar - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2026-01-26</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiiwFBVV95cUxPalZQSWJUejczbEN4aV85UzZJdloydVprZDRVSV9YT0Z6MEs3WThSMnBZd3dfZEZjRU5yTVFWSjhyMWpyeWhWVzR4MWRkb2VraDNXdGxSWDhOYWtiUGIySHoxNjRRR3I3ZDdZR0ZnUW1kUFVETjRiXzJ5WDU2N2dXQTlPNVEtdnVWMld3?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-68')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">Nvidia invests $2 billion in CoreWeave to boost data center build-out - Reuters</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-68" style="display:none;">
            <h2>Nvidia invests $2 billion in CoreWeave to boost data center build-out - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2026-01-26</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiowFBVV95cUxQdm0xTTlhc003ZUlGaElBblY1SWl2dFBJd3lxMmtfZldNS2F0c2ctZ3k2UVhpY2tWdjE1by1mNVl1WTQ3MUJuTEFGdGo3V3J2OHZHdzhybHFXVEhkWTRzUFFiT0N2Wkg1aE52dG9JcjFQTVhaU0tLUTVZZ2RsWlBDWU8yc0pod3lCVEpla3EwbVl2Z29HRGx6WmQzMTBlVkRQdnVr?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-69')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">Russian Urals oil trades at close to widest discounts since 2022 in India, sources say - Reuters</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-69" style="display:none;">
            <h2>Russian Urals oil trades at close to widest discounts since 2022 in India, sources say - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2026-01-26</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMixwFBVV95cUxOeDZNajFhbXBIOTFmcUduR3RJX0JGT3k3dE1QMWN4dDA4V2xHeXhEaWd3WEpXQTFRRHRLbEtnMVdrOGVyMzhkTS1GMkVqb1NsNlhzcWpaQV8zcE9lS3pVWDdlNXQ5U0dUYWtpc2pTNGl5S2VGMHUybDVrck1tMUFXeC1JaTBxVEktMFVwLWIyNGxLSzl6Q1d4Qkk4RGNoQ0xIQ19YYUxVd1NReEEybnRvZmJ5Ni1iTXZ6dTFfX2VoajM4X3J4QmNV?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-70')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">EU and India to explore defence cooperation, draft document says - Reuters</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-70" style="display:none;">
            <h2>EU and India to explore defence cooperation, draft document says - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2026-01-26</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMipwFBVV95cUxQRmtWTEJuTXZ5djJlT0ExZGszRXRRMmlZNTlIOUF1OFVVMmZqb2ZwdlF6c0txYVZLUnFBQXZPUC1sZm9BLTRGMGQ0Mk1nQ0dIbHpTdXNycU85OVI5WG1LQnVpbnJPRFYzdVFXQjFQVWhKVTRsU1dOT1l4LWpJRVBhSzJNZ2ZyTWQwV3lVeFlpUEF6N3Y4VVM2N1QtczI3eXNYbnR3ejlZbw?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-71')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">Meta, TikTok, YouTube to stand trial on youth addiction claims - Reuters</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-71" style="display:none;">
            <h2>Meta, TikTok, YouTube to stand trial on youth addiction claims - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2026-01-26</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiqwFBVV95cUxPT09hMW1zdm5HWUR3YVdmbVNBb2VPaVdkQkdGa0JhT3pKYlV2N2l1NVp1Z3hIcEJuYmVpazl4cFNPa242Vnl0c0UyZ1YxbEgtdWpxMF8xYVptdlMybzRIU0hqMWozbUJBNzJQWnFoRUJlNGJhX19YSXplb1VySTNVckhqM0N1M0pad2lBaVRfMW83SmJobmJhLXoxQlBiQU1jRm13MFFEU2llU1E?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-72')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">Scientists Discover “Master Regulator” That Could Help Reverse Brain Aging at Its Source - The Debrief</div>
            <div class="meta">2026-01-20</div>
        </div>
        
        <div id="content-72" style="display:none;">
            <h2>Scientists Discover “Master Regulator” That Could Help Reverse Brain Aging at Its Source - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2026-01-20</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMirwFBVV95cUxOdWxhR3UtU1g1eFpMT1ozNjIySFBVeUpfX1ktZlN2Xy1lUGljSkpGSG10WEF0d19jOTNZMjhpcGVPQ0VuS3ZuTnV0YzFjSlRCaml3Q2ZKeHRqT09MREN3THZuM0dadXl2YnI5THhYREtFY1pjM0lfbmd2SXZuNElDaG54OWxNZXJwUHNJXzcyTHdiV2NNRnhHV2J6TmZibm9RNnczRFpsTWdkRWJtdlc0?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-73')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">James Webb Space Telescope Captures the Stunning Demise of a Star in the Helix Nebula - The Debrief</div>
            <div class="meta">2026-01-22</div>
        </div>
        
        <div id="content-73" style="display:none;">
            <h2>James Webb Space Telescope Captures the Stunning Demise of a Star in the Helix Nebula - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2026-01-22</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMirgFBVV95cUxPVXFOVjBSLVpmQ05fMFJoQVBxVDFhX3JpdWdnYXk4YzcxUENIMHIyTHkzV1dRVnNGOUkzc3QzelhJUDVYMUV0b1A1MjdLRkRnMVZYRGJSMVdHVnRVc1lnTkNuLVBrak03NmM1WG9RMTFkN3BLUGVxWHRqVTIwSmdjM2tobDd5YWFmQmNGUU8xbndVVzlWcDM2WDRld0tjemhjX2JBLUF6X0g5VHJPRVE?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-74')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">Superconductivity Breakthrough Brings Practical Use Closer than Ever, as Team Unveils "Hidden Magnetic Order in the Pseudogap" - The Debrief</div>
            <div class="meta">2026-01-21</div>
        </div>
        
        <div id="content-74" style="display:none;">
            <h2>Superconductivity Breakthrough Brings Practical Use Closer than Ever, as Team Unveils "Hidden Magnetic Order in the Pseudogap" - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2026-01-21</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMi4AFBVV95cUxPTkV1UExSZ2dMS094c25BUTQ0cmJxT21paDI2UTBhX3c5RVdaMndBQ0MxY1NVTTVLOFhEWXNfeE0yR1NFNlk3LUdTdnVDbk9WWVdKeDA1NTRqSnlHU0Q2VEJxQUtlQ0hVckRzTVM4LXJpSlcyajRfaUFpbDNXRThvX1B4SmpuQ05VTnpWNmRTdFpSRksyR0lRd2xCNVVLZThTMndETDUxTWNjWGpvNGU5RlNtN2dNZ3NfU1p5SVVKaU9xaW1HYXdfazFoS3RjTmVUMHJhU3BTWmhVWnd1Yi1vVA?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-75')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">Archaeologists: Half a Million-Year-Old Elephant Bone Hammer Wasn’t Made by Modern Humans - The Debrief</div>
            <div class="meta">2026-01-22</div>
        </div>
        
        <div id="content-75" style="display:none;">
            <h2>Archaeologists: Half a Million-Year-Old Elephant Bone Hammer Wasn’t Made by Modern Humans - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2026-01-22</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMisAFBVV95cUxPWTFUMXVQQXVoZENJdlA1Q29xUXJhZ1NwbXR1OVBIZ0VNNXdaN0VMVFF1alVxcGl1UDFaT3A2U2JfaXpSY0d6dF9CLVNwYUtqa285eTVyUHlBaXFiM0RPT283eW9kckJ2VXIwemlBa09KN2NvOFFvYUc5b2s2LTdNYTc3SGY4Q2R6azFiRUR4OVRqRGNyd1BXN3RQaUZtNUpBamlTbG9YUm5vdUt6ME1WUA?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-76')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">50,000-Year-Old Artifacts Unearthed at Controversial Archaeological Site Could Rewrite the Early Prehistory of the Americas - The Debrief</div>
            <div class="meta">2026-01-21</div>
        </div>
        
        <div id="content-76" style="display:none;">
            <h2>50,000-Year-Old Artifacts Unearthed at Controversial Archaeological Site Could Rewrite the Early Prehistory of the Americas - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2026-01-21</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMi3wFBVV95cUxPQzR6eFVORUdoblVyV2VWOVlScHR4NXQtV1Z4dUZYdzdjUjRwUnhYdm11QVBaZXF5S3NKYUE0d2hlMzZqMmc4T2pzc3AzdmRBekNOZFhYYWdfNG1LZmdpOEZuOGxaUjUyVmRTNXg0VmV3amw1WTRvSGJ4aUtENWZFMWE5NmVFaHZGYjBheHRMT0RSc255OFdscEthMm1tUG4xdEhmeFZqd1hqRENkSi10VnBnQURvemIxMlVOVGZURlJ2dlJWb3ZLRFFPZjVJRkJPeUN1RXdNLVZFMDJuT2dZ?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-77')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">Researchers Discover AI Language Models Are Mirroring the Human Brain’s Understanding of Speech - The Debrief</div>
            <div class="meta">2026-01-23</div>
        </div>
        
        <div id="content-77" style="display:none;">
            <h2>Researchers Discover AI Language Models Are Mirroring the Human Brain’s Understanding of Speech - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2026-01-23</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiugFBVV95cUxNSEtKUTZuWERFVURvaGQ3UjY5aVdEalNfeE9KSGFfLWQ1cklJSTNaM0pSanJSQzdieVBlYVZyYmhTMXRBMW1xZi0zMHRUeEtaU1N3MHFhOUtmdnBYTHpVOGVjUUc4RjVHMUUyV0NhdnZqVU8wMTR4TXVJY2NoUUJwSW5PUTg0TjlkWVJoUVg4cUpRYWk4T0VXOF9mZjhRbTJRS0hQZDRiNDhLZlZLSDg1M0ZmZ29CZks1RVE?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-78')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">OpenAI Plans to Take a Cut of Customers’ AI-Aided Discoveries - The Information</div>
            <div class="meta">2026-01-22</div>
        </div>
        
        <div id="content-78" style="display:none;">
            <h2>OpenAI Plans to Take a Cut of Customers’ AI-Aided Discoveries - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2026-01-22</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiqgFBVV95cUxPcHdxSmlWVVZxSnAtU05FazNqajZjeThEV0RvVG9SU1BGU2VmODF5QmppXzdOYnRLSnl6NmVFZk5IZ19Md3hlZjdxVGlvY3Frc2lFZGtDWkhrM2g4VjFyRmlHRnRNOTRXaFIteEVEWVR1Wk1rWFZIR0dxVXpoOTJaa21uVkpKY2NZc0hsSjhSU2x2bzEtRE80cTRGVFRaa1EzTnBwR1gwdFBwQQ?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-79')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">Behind the Sky-High Valuation of China’s AI IPOs - The Information</div>
            <div class="meta">2026-01-25</div>
        </div>
        
        <div id="content-79" style="display:none;">
            <h2>Behind the Sky-High Valuation of China’s AI IPOs - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2026-01-25</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMihwFBVV95cUxNVDBCYlp5aW11SUVISHRtb1M4S0xqQ1BQLWlESkV3TGJxXzM1c0tUYnBOa2J6NkE1am14SHBYU0RBM1RDT2pLb3NndWNkd04tZWxId2ZzWlRjdWt0ODluRkphRUtTR2VxZExGQ0JEQmprM3RZbWhlUm5jWS1EUlF6Njg3cWE4QUE?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-80')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">Anthropic Lowers Gross Margin Projection as Revenue Skyrockets - The Information</div>
            <div class="meta">2026-01-22</div>
        </div>
        
        <div id="content-80" style="display:none;">
            <h2>Anthropic Lowers Gross Margin Projection as Revenue Skyrockets - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2026-01-22</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiogFBVV95cUxOOFNsY05rYkNDRWFDVzQzVk1CdF9yaGpLbnpmelNBcW9yQkQtNVhXUVlqNTRpZElnOFl1Q3lya1ozMlV6bzh2M21MWlNBdHh5TjlOaUppMWNhWWR5TmxPYmlkaEZSMURzbGNJS0dlcXdmSEViWEFST3dnZGpFR2MxNnRBSUFJZ091T2hwXzFQdTFzbnRhUU1IYkx1TE45emlPRHc?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-81')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">Apple Developing AI Wearable Pin - The Information</div>
            <div class="meta">2026-01-21</div>
        </div>
        
        <div id="content-81" style="display:none;">
            <h2>Apple Developing AI Wearable Pin - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2026-01-21</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMifEFVX3lxTE1rTVFHak5WVzd2dHhmNnlQMjZBTVMxeW1EYzFaSm8tTmpxcEhKeEdrSlRfMWMxcWNPdDdNTXpVbWREazBqVW5TWkZaWmltazFwLWFqbURmcVkzcG1oR2ZhakVwOGZCNnh1b0NsR1dsRWVpdjBSdU9kU1BOS1o?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-82')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">AI Videos Nearly Indistinguishable From Real Videos, Runway Finds - The Information</div>
            <div class="meta">2026-01-21</div>
        </div>
        
        <div id="content-82" style="display:none;">
            <h2>AI Videos Nearly Indistinguishable From Real Videos, Runway Finds - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2026-01-21</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMisgFBVV95cUxNQ3QtWTRac0xISlVaUnZldWl3WG5PSFEzNmdLdzl4R2Vna3RfLVg4R3hrc202cGd6N3I4X2ZmYzRyUlhHQlduWGItN2hrSlpqNFc3OE1LT1BmeTNaZUNyMHVOSVAxTVZaTmZQbW9sMW95cDdsd1NyN1BpWFhFeDdrc1docDl5clNteUtmdjlxclN0WndtUVhDVWlEZTh4aVJLRjVReldNcUN5ajVLeTdjTjNR?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-83')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">Yelp to Buy AI Agent Startup for $300 Million - The Information</div>
            <div class="meta">2026-01-21</div>
        </div>
        
        <div id="content-83" style="display:none;">
            <h2>Yelp to Buy AI Agent Startup for $300 Million - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2026-01-21</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMihAFBVV95cUxOU2pKNlJoY0JxcTVHVVUzR05BcDdWcVFJX2NqTkdGRk9LeGZHSXRoNUpNN3pMeDktcFl1RnV3Yjlrc0MxT1p1dHpxWF9NdDlzVGhhUXlISG5RR2NCb2NTbERLUWU2b1FOXzJoUWlmTjc4eVFwazRYenpHZXlFRmRlVUtudGc?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        </div>

        <div id="reader-modal">
            <div id="close-btn" class="control-btn" onclick="closeModal()">X</div>
            
            <div id="scroll-controls">
                <button class="scroll-btn" onclick="scrollPage(-1)">&#9650;</button> <button class="scroll-btn" onclick="scrollPage(1)">&#9660;</button>  </div>

            <div id="modal-inner"></div>
        </div>

        <script>
            // 1. RANDOMIZE ORDER
            const list = document.getElementById('feed-list');
            const cards = Array.from(document.querySelectorAll('.card'));
            cards.sort(() => Math.random() - 0.5);
            cards.forEach(card => list.appendChild(card));

            // 2. DARK MODE
            const btn = document.getElementById('theme-toggle');
            btn.addEventListener('click', () => document.body.classList.toggle('dark-mode'));

            // 3. MODAL & SCROLL LOGIC
            const modal = document.getElementById('reader-modal');
            const modalInner = document.getElementById('modal-inner');

            function openModal(contentId) {
                const content = document.getElementById(contentId).innerHTML;
                modalInner.innerHTML = content;
                modal.style.display = 'block';
                document.body.style.overflow = 'hidden'; 
            }

            function closeModal() {
                modal.style.display = 'none';
                document.body.style.overflow = 'auto';
            }

            function scrollPage(direction) {
                // Scroll by 80% of the screen height to keep context
                const scrollAmount = window.innerHeight * 0.8;
                modal.scrollBy(0, direction * scrollAmount);
            }
        </script>
    </body>
    </html>
    