
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>KL-77's Feed</title>
        <style>
            :root {
                --bg: #ffffff;
                --text: #000000;
                --border: #000000;
                --modal-bg: #ffffff;
                --dim: #666666;
            }
            
            body.dark-mode {
                --bg: #000000;
                --text: #ffffff;
                --border: #ffffff;
                --modal-bg: #000000;
                --dim: #aaaaaa;
            }

            body { 
                font-family: Georgia, serif; 
                background-color: var(--bg);
                color: var(--text);
                margin: 0;
                padding: 10px;
                font-size: 22px;
                line-height: 1.5;
            }

            header {
                display: flex;
                justify-content: space-between;
                align-items: center;
                border-bottom: 3px solid var(--text);
                padding-bottom: 15px;
                margin-bottom: 25px;
            }
            
            h1 { margin: 0; font-size: 1.2em; }

            button#theme-toggle {
                background: transparent;
                color: var(--text);
                border: 2px solid var(--text);
                padding: 10px;
                font-size: 18px;
                font-weight: bold;
                border-radius: 4px;
                cursor: pointer;
            }

            .card {
                border: 2px solid var(--text);
                margin-bottom: 25px;
                padding: 15px;
                cursor: pointer;
            }
            
            .source { font-size: 0.7em; font-weight: bold; text-transform: uppercase; color: var(--dim); }
            .title { font-size: 1.1em; font-weight: bold; margin: 8px 0; display:block; }
            .meta { font-size: 0.7em; color: var(--dim); }

            /* MODAL STYLING */
            #reader-modal {
                display: none;
                position: fixed;
                top: 0; left: 0;
                width: 100%; height: 100%;
                background-color: var(--modal-bg);
                z-index: 1000;
                overflow-y: scroll; /* Allow scrolling */
                scroll-behavior: auto; /* Instant scrolling for e-ink */
            }

            #modal-inner {
                padding: 25px;
                max-width: 800px;
                margin: 0 auto;
                padding-top: 80px; 
                padding-bottom: 150px; /* Huge padding so text clears the buttons */
            }

            /* Controls (Close + Scroll) */
            .control-btn {
                position: fixed;
                background: var(--bg);
                color: var(--text);
                border: 3px solid var(--text);
                border-radius: 8px;
                font-weight: bold;
                cursor: pointer;
                z-index: 1001;
                display: flex;
                align-items: center;
                justify-content: center;
            }

            #close-btn {
                top: 15px; right: 15px;
                width: 60px; height: 60px;
                font-size: 30px;
                line-height: 55px;
            }

            /* Scroll Buttons */
            #scroll-controls {
                position: fixed;
                bottom: 20px;
                right: 20px;
                display: flex;
                flex-direction: column;
                gap: 15px;
                z-index: 1002;
            }

            .scroll-btn {
                width: 60px;
                height: 60px;
                font-size: 24px;
                background: var(--bg);
                color: var(--text);
                border: 3px solid var(--text);
                border-radius: 8px;
                cursor: pointer;
            }

            #article-text { white-space: pre-wrap; font-size: 1.1em; }
            
            a.original-link {
                display: inline-block;
                margin-bottom: 30px; /* Space before text starts */
                padding: 10px;
                border: 1px solid var(--text);
                color: var(--text);
                text-decoration: none;
                font-weight: bold;
                font-size: 0.8em;
            }
        </style>
    </head>
    <body>

        <header>
            <h1>KL-77's Feed</h1>
            <button id="theme-toggle">Light/Dark</button>
        </header>

        <div id="feed-list">
    
        <div class="card" onclick="openModal('content-0')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">Ars Technica’s Top 20 video games of 2025</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-0" style="display:none;">
            <h2>Ars Technica’s Top 20 video games of 2025</h2>
            <p><strong>Ars Technica - All content | 2025-12-26</strong></p>
            <a class="original-link" href="https://arstechnica.com/gaming/2025/12/ars-technicas-top-20-video-games-of-2025/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">When we put together our top 20 games of last year, we specifically called out Civilization 7, Avowed, Doom: The Dark Ages, and Grand Theft Auto 6 as big franchise games we were already looking forward to for 2025. While one of those games has been delayed into 2026, the three others made this year’s list of Ars’ favorite games as expected. They join a handful of other highly anticipated sequels, ranging from big-budget blockbusters to long-gestating indies, on the “expected” side of this year’s list.

But the games that really stood out for me in 2025 were the ones that seemed to come out of nowhere. Those range from hard-to-categorize roguelike puzzle games to a gonzo, punishing mountainous walking simulation, the best Geometry Wars clone in years, and a touching look at the difficulties of adolescence through the surprisingly effective lens of mini-games.

As we look toward 2026, there are plenty of other big-budget projects that the industry is busy preparing for (the delayed Grand Theft Auto VI chief among them). If next year is anything like this year, though, we can look forward to plenty more games that no one saw coming suddenly vaulting into view as new classics.

Ubisoft Quebec; Windows, MaxOS, PS5, Xbox Series X|S, Switch 2, iPad

When I was younger, I wanted—and expected—virtually every game I played to blow me away with something I’d not seen before. It was easier to hit that bar in the ’90s, when both the design and technology of games were moving at an incredible pace.

Now, as someone who still games in his 40s, I’m excited to see that when it happens, but I don’t expect it, Now, I increasingly appreciate games that act as a sort of comfort food, and I value some games as much for their familiarity as I do their originality.

That’s what Assassin’s Creed Shadows is all about (as I wrote when it first came out). It follows a well-trodden formula, but it’s a beautifully polished version of that formula. Its world is grand and escapist, its audio and graphics presentation is immersive, and it makes room for many different playstyles and skill levels.

If your idea of a good time is “be a badass, but don’t think too hard about it,” Shadows is one of the best Assassin’s Creed titles in the franchise’s long history. It doesn’t reinvent any wheels, but after nearly two decades of Assassin’s Creed, it doesn’t really need to; the new setting and story are enough to separate it, while the gameplay remains familiar.

Obsidian Entertainment; Windows, Xbox Series X|S

No game this year has made me feel as hated as Avowed. As an envoy for the far-off Aedryan empire, your role in Avowed is basically to be hated, either overtly or subtly, by almost everyone you encounter in the wild, semi-colonized world of the Living Lands. The low-level hum of hatred and mistrust from the citizens permeates everything you do in the game, which is an unsettling feeling in a genre usually characterized by the moral certitude of heroes fighting world-ending evil.

Role-playing aside, Avowed is helpfully carried by its strong action-packed combat system, characterized as it is by thrilling moment-to-moment positional jockeying and the juggling of magic spells, ranged weapons, and powerful close-range melee attacks. The game’s quest system also does a good job of letting players balance this combat difficulty for themselves—if a goal is listed with three skull symbols on your menu, you’d best put it off until you’ve leveled up a little bit more.

I can take or leave the mystical mumbo-jumbo-filled subplot surrounding your status as a “godlike” being that can converse with spirits. Aside from that, though, I’ve never had so much fun being hated.

Gabe Cuzzillo, Maxi Boch, Bennett Foddy; Windows, PS5

The term “walking simulator” often gets thrown around in some game criticism circles as a derisive term for a title that’s about nothing more than walking around and looking at stuff. While Baby Steps might technically fit into that “walking simulator” model, stereotyping it in that way does this incredibly inventive game a disservice.

It starts with the walking itself, which requires meticulous, rhythmic manipulation of both shoulder buttons and both analog sticks just to stay upright. Super Mario 64, this ain’t. But what starts as a struggle to take just a few short steps quickly becomes almost habitual, much like learning to walk in real life.

The game then starts throwing new challenges at your feet. Slippery surfaces. Narrow stairways with tiny footholds. Overhangs that block your ridiculously useless, floppy upper body. The game’s relentless mountain is designed such that a single missed step can ruin huge chunks of progress, in the proud tradition of Getting Over It with Bennett Foddy.

This all might sound needlessly cruel and frustrating, but trust me, it’s worth sticking with to the end. That’s in part for the feeling of accomplishment when you do finally make it past that latest seemingly impossible wall, and partly to experience an absolutely gonzo story that deals directly and effectively with ideas of masculinity, perseverance, and society itself. You’ll never be so glad to take that final step.

Kenny Sun; Windows, MacOS, PS5, Xbox Series X|S, Switch, Switch 2

The idea of bouncing a ball against a block is one of the most tried-and-true in all of gaming, from the basic version in the ancient Breakout to the number-filled angles of Holedown. But perhaps no game has made this basic concept as compulsively addictive as Ball x Pit.

Here, the brick-breaking genre is crossed with the almost as storied shoot-em-up, with the balls serving as your weapons and the blocks as enemies that march slowly but relentlessly from the top of the screen to the bottom. The key to destroying those blocks all in time is bouncing your growing arsenal of new balls at just the right angles to maximize their damage-dealing impact and catching them again so you can throw them once more that much faster.

Like so many roguelikes before it, Ball x Pit uses randomization as the core of its compulsive loop, letting you choose from a wide selection of new abilities and ball-based attacks as you slowly level up. But Ball x Pit goes further than most in letting you fuse and combine those balls into unique combinations that take dozens of runs to fully uncover and combine effectively.

Add in a deep system of semi-permanent upgrades (with its own intriguing “bounce balls around a city builder” mini game) and a deep range of more difficult settings and enemies to slowly unlock, and you have a game whose addictive pull will last much longer than you might expect from the simple premise.

Dogubomb; Windows, MacOS, PS5, Xbox Series X|S

Usually, when formulating a list like this, you can compare a title to an existing game or genre as a shorthand to explain what’s going on to newcomers. That’s nearly impossible with Blue Prince, a game that combines a lot of concepts to defy easy comparison to games that have come before it.

At its core, Blue Prince is about solving the mysteries of a house that you build while exploring it, drafting the next room from a selection of three options every time you open a new door. Your initial goal, if you can call it that, is to discover and access the mysterious “Room 46” that apparently exists somewhere on the 45-room grid. And while the houseplan you’re building resets with every in-game day, the knowledge you gain from exploring those rooms stays with you, letting you make incremental progress on a wide variety of puzzles and mysteries as you rebuild the mansion from scratch again and again.

What starts as a few simple and relatively straightforward puzzles quickly unfolds fractally into a complex constellation of conundrums, revealed slowly through scraps of paper, in-game books, inventory items, interactive machinery, and incidental background elements. Figuring out the more intricate mysteries of the mansion requires careful observation and, often, filling a real-life mad scientist’s notepad with detailed notes that look incomprehensible to an outsider. All the while, you have to manage each day’s limited resources and luck-of-the-draw room drafting to simply find the right rooms to make the requisite progress.

Getting to that storied Room 46 is enough to roll the credits on Blue Prince, and it serves as an engaging enough puzzle adventure in its own right. But that whole process could be considered a mere tutorial for a simply massive endgame, which is full of riddles that will perplex even the most experienced puzzlers while slowly building a surprisingly deep story of political intrigue and spycraft through some masterful environmental storytelling.

Some of those extreme late-game puzzles might be too arcane for their own good, honestly, and will send many players scrambling for a convenient guide or wiki for some hints. But even after playing for over 100 hours over two playthroughs, I’m pretty sure I’m still not done exploring all that Blue Prince has to offer.

Firaxis; Windows, MacOS, Linux, PS4/5, Xbox One/Series X|S, Switch 2

This one will be controversial: I love Civilization VII.

Civilization VII launched as a bit of a mess. There were bugs and UI shortcomings aplenty. Most (but not all) of those have been addressed in the months since, but they’re not the main reason this is a tricky pick.

The studio behind the Civilization franchise, Firaxis, has long said it has a “33/33/33″ approach to sequels in the series, wherein 33 percent of the game should be familiar systems, 33 percent should be remixes or improvements of familiar systems, and 33 percent should be entirely new systems.

Critics of Civilization VII say Firaxis broke that 33/33/33 rule by overweighting the last 33 percent, mainly to chase innovations in the 4X genre by other games (like Humankind). I don’t disagree, but I also welcome it.

Credit is due to the team at Firaxis for ingeniously solving some longstanding design problems in the franchise, like using the new age transitions to curb snowballing and to expunge systems that become a lot less fun in the late game than they are in the beginning. Judged on its own terms, Civilization VII is a deep, addictive, and fun strategy game that I’ve spent more than 100 hours playing this year.

My favorite Civ game remains Civilization IV, but that game still runs fine on modern systems, is infinitely replayable out of the box, and enjoys robust modding support. I simply didn’t need more of the same from this particular franchise; to me, VII coexists with IV and others on my hard drive—very different flavors of the same idea.

I’m not sure I like what my minor CloverPit obsession says about me. When I fell into a deep Balatro hole last year, I could at least delude myself into thinking there was some level of skill in deciding which jokers to buy and sell, which cards to add or prune from my deck, and which cards to hold and discard. In the end, though, I was as beholden to the gods of random number generation as any other Balatro player.

Cloverpit makes the surrender to the vagaries of luck all the more apparent, replacing the video-poker-like systems of Balatro with a “dumb” slot machine whose handle you’re forced to pull over and over again. Sure, there are still decisions to make, mostly regarding which lucky charms you purchase from a vending machine on the other side of the room. And there is some skill involved in learning and exploiting lucky charm synergies to extract the highest expected value from those slot machine pulls.

Once you’ve figured out those basic strategies, though, CloverPit mostly devolves into a series of rerolls waiting for the right items to show up in the shop in the right order. Thankfully, the game hides plenty of arcane secrets beneath its charming PS1-style spooky-horror presentation, slowly revealing new items and abilities that hint that something deeper than just accumulating money might be the game’s true end goal.

It’s this creepy vibe and these slowly unfolding secrets that have compelled me to pour dozens of hours into what is, in the end, just a fancy slot machine simulator. God help me.

Jenny Jiao Hsia, AP Thomson; Windows, MacOS

Jenny is your average suburban Asian-American teenager, struggling to balance academic achievement, chores, an overbearing mother, romantic entanglements, and a healthy body image. What sounds like the premise for a cliché young adult novel actually serves to set up a compelling interactive narrative disguised as a mere mini-game collection.

Consume Me brilliantly integrates the conflicting demands placed on Jenny’s time and attention into the gameplay itself. Creating a balanced meal, for instance, becomes a literal test of balancing vaguely Tetris-shaped pieces of food on a tray, satisfying your hunger and caloric limits at the same time. Chores take up time but give you money you can spend on energy drinks that let you squeeze in more activities by staying up late (but can lead to debilitating headaches). A closet full of outfits becomes an array of power-ups to your time, energy, or focus.

It takes almost preternatural resource management skills and mini-game execution to satisfy all the expectations being placed on you, which is kind of the meta-narrative point. No matter how well you do, Jenny’s story develops in a way that serves as a touching semi-autobiographical look at the life of co-creator Jenny Jiao Hsia. That biography is made all the more sympathetic here for an interactive presentation that’s more engaging than any young adult novel could be.

Death Stranding 2: On the Beach should not be fun. Much like its predecessor, the latest release from famed game designer Hideo Kojima is about delivering packages—at least on the surface. Yet the process of planning your routes, managing inventory, and exploring an unfathomably strange post-apocalyptic world remains a winning formula.

The game again follows Sam Porter Bridges (played by Norman Reedus) on his quest to reconnect the world as humanity faces possible extinction. And yes, that means acting like a post-apocalyptic Amazon Prime. Standing in the way of an on-time delivery are violent raiders, dangerous terrain, and angry, disembodied spirits known as Beached Things.

It’s common to hear Death Stranding described as a walking simulator, and there is indeed a lot of walking, but the sequel introduces numerous quality-of-life improvements that make it more approachable. Death Stranding 2 has a robust fast-travel mechanic and better vehicles to save you from unnecessary marches, and the inventory management system is less clunky. That’s important in a game that asks you to traverse an entire continent to deliver cargo.

Beyond the core gameplay loop of stacking heavy boxes on your back, Death Stranding 2 has all the Kojima vibes you could want. There are plenty of quirky gameplay mechanics and long cutscenes that add depth to the characters and keep the story moving. The world of Death Stranding has been designed from the ground up around the designer’s flights of fancy, and it works—even the really weird stuff almost makes sense!

Along the way, Death Stranding 2 has a lot to say about grief, healing, and the value of human connection. The game’s most poignant cutscenes are made all the more memorable by an incredible soundtrack, and we cannot oversell the strength of the mocap performances.

It may take 100 hours or more to experience everything the game has to offer, but it’s well worth your time.

Since the days of Donkey Kong Country, I’ve always felt that Mario’s original ape antagonist wasn’t really up for anchoring a Mario-level platform franchise. Donkey Kong Bananza is the first game to really make me doubt that take.

Bonanza is a great showcase for the new, more powerful hardware on the Switch 2, with endlessly destructible environments that send some impressive-looking shiny shrapnel flying when they’re torn apart. It can’t be understated how cathartic it is to pound tunnels up, down, and through pretty much every floor, ceiling, and wall you see, mashing the world itself to suit your needs.

Bonanza also does a good job aping Super Mario Odyssey’s tendency to fill practically every square inch of space with collectible doodads and a wide variety of challenges. This is not a game where you need to spend a lot of time aimlessly wandering for the next thing to do—there’s pretty much always something interesting around the next corner until the extreme end game.

Sure, the camera angles and frame rate might suffer a bit during the more chaotic bits. But it’s hard to care when you’re having this much fun just punching your way through Bananza’s imaginative, colorful, and malleable world.

Id Software; Windows, PS5, Xbox Series X|S

Credit:

          
          Bethesda Game Studios

For a series that has always been about dodging, Doom: The Dark Ages is much more about standing your ground. The game’s key verbs involve raising your shield to block incoming attacks or, ideally, parrying them back in the direction they came.

It’s a real “zig instead of zag” moment for the storied Doom series, and it does take some getting used to. Overall, though, I had a great time mixing in turtle-style blocking with the habitual pattern of circling-strafing around huge groups of enemies in massive arenas and quickly switching between multiple weapons to deal with them as efficiently as possible. While I missed the focus on extreme verticality of the last two Doom games, I appreciate the new game’s more open-world design, which gives completionist players a good excuse to explore every square inch of these massive environments for extra challenges and hidden collectibles.

The only real problem with Doom: The Dark Ages comes when the game occasionally transitions to a slow-paced mech-style demon battle or awkward flying dragon section, sometimes for entire levels at a time. Those variations aside, I came away very satisfied with the minor change in focus for a storied shooter series.

Anyone who has read my book-length treatise on Minesweeper knows I’m a sucker for games that involve hidden threats within a grid of revealed numbers. But not all variations on this theme are created equal. Dragonsweeper stands out from the crowd by incorporating a simple but arcane world of RPG-style enemies and items into its logical puzzles.

Instead of simply counting the number of nearby mines, each number revealed on the Dragonsweeper grid reflects the total health of the surrounding enemies, both seen and unseen. Attacking those enemies means enduring predictable counterattacks that deplete your limited health bar, which you can grow through gradual leveling until you’re strong enough to kill the game’s titular dragon, taunting you from the center of the field.

Altogether, it adds an intriguing new layer to the logical deduction, forcing you to carefully manage your moves to maximize the impact of your attacks and the limited health-restoring items scattered throughout the field. And while finishing one run isn’t too much of a challenge, completing the game’s optional achievements and putting together a “perfect” game score is enough to keep puzzle lovers coming back for hours and hours of compelling logical deduction.

FromSoftware; Windows, PS4/5, Xbox One/Series X|S

Credit:

          
          Bandai Namco

At first blush, Nightreign feels like a twisted perversion of everything that has made FromSoft’s Souls series so compelling for so many years. What was a slow-paced, deliberate open-world RPG has become a game about quickly sprinting across a quickly contracting map, leveling up as quickly as possible before taking on punishing bosses. A moody solitary experience has become one that practically requires a group of three players working together. It’s like an Elden Ring-themed amusement park that seems to miss the point of the original.

Let the purists belly ache about how it’s not really Elden Ring. They’re right, but they’re missing the point. Nightreign condenses the general vibe of the Elden Ring world into something very different but no less enjoyable. What’s more, it packs that vibe into a tight experience that can be easily squeezed into a 45-minute sprint rather than requiring dozens of hours of deep exploration.

That makes it the perfect excuse to get together with a few like-minded Elden Ring-loving friends, throw on a headset, and just tear through the Lands Between together for the better part of an evening. As Elden Ring theme parks go, you could do a lot worse.

Ghost of Yotei from Sucker Punch Productions starts as a revenge tale, featuring hard-as-nails Atsu on the hunt for the outlaws who murdered her family. While there is plenty of revenge to be had in the lands surrounding Mount Yotei, the people Atsu meets and the stories they have to tell make this more than a two-dimensional quest for blood.

The game takes place on the northern Japanese island of Ezo (modern-day Hokkaido) several centuries after the developer’s last samurai game, Ghost of Tsushima. It has a lot in common with that title, but Ghost of Yotei was built for the PS5 and features a massive explorable world and stunning visuals. It’s easy to get sidetracked from your quest just exploring Ezo and tinkering with the game’s photo mode.

The land of Ezo avoids some of the missteps seen in other open-world games. While it’s expansive and rich with points of interest, exploring it is not tedious. There are no vacuous fetch quests or mindless collecting (or loading screens, for that matter). Even when you think you know what you’re going to find at a location, you may be surprised. The interesting side quests and random encounters compel you to keep exploring Ezo.

Ghost of Yotei’s combat is just as razor-sharp as its exploration. It features multiple weapon types, each with unlockable abilities and affinities that make them ideal for taking on certain foes. Brute force will only get you so far, though. You need quick reactions to parry enemy attacks and strike back—it’s challenging and rewarding but not frustrating.

It’s impossible to play Ghost of Yotei without becoming invested in the journey, and a big part of that is thanks to the phenomenal voice work of Erika Ishii as Atsu. Some of the game’s pivotal moments will haunt you, but luckily, the developer has just added a New Game+ mode so you can relive them all again.

Supergiant Games; Windows, MacOS, Switch, Switch 2

There’s a moment in the second section of Hades 2 where you start to hear a haunting melody floating through the background. That music gets louder and louder until you reach the game’s second major boss, a trio of sirens that go through a full rock-opera showtune number as you dodge their bullet-hell attacks and look for openings to go in for the kill. That three-part musical presentation slowly dwindles to a solo as you finally dispatch the sirens one by one, restoring a surprisingly melancholy silence once more.

It’s this and other musical moments casually and effortlessly woven through Hades 2 that will stick with me the most. But the game stands on its own beyond the musicality, expanding the original game’s roguelike action with a compelling new spell system that lets you briefly capture or slow enemies in a binding circle. This small addition adds a new sense of depth to the moment-to-moment positional dance that was already so compelling in the original Hades.

Hades 2 also benefits greatly from the introduction of Melinoe, a compelling new protagonist who gets fleshed out through her relationship with the usual rogue’s gallery of gods and demigods. Come for her quest of self-discovery, stay for the moments of musical surprise.

Team Cherry; Windows, MacOS, Linux, PS4/5, Xbox One/Series X|S, Switch, Switch 2

A quickie sequel in the year or two after Hollow Knight’s out-of-nowhere success in 2017 might have been able to get away with just being a more-of-the-same glorified expansion pack. But after over eight years of overwhelming anticipation from fans, Silksong had to really be something special to live up to its promise.

Luckily, it is. Silksong is a beautiful expansion of the bug-scale underground universe created in the first game. Every new room is a work of painterly beauty, with multiple layers of detailed 2D art drawing you further into its intricate and convincing fallen world.

The sprawling map seems to extend forever in every direction, circling back around and in on itself with plenty of optional alleyways in which to get lost searching for rare power-ups. And while the game is a punishingly hard take on action platforming, there’s usually a way around the most difficult reflex tests for players willing to explore and think a bit outside the box.

Even players who hit a wall and never make it through the sprawling tunnels of Silksong’s labyrinthine underground will still find plenty of memorable moments in whatever portion of the game they do experience.

In a real-time-strategy genre that can often feel too bloated and complex for its own good, The King Is Watching is a streamlined breath of fresh air. Since the entire game takes place on a single screen, there’s no need to constantly pan and zoom your camera around a sprawling map. Instead, you can stay laser-focused on your 5×5 grid of production space and on which portion of it is actively productive under the king’s limited gaze at any particular moment.

Arranging tiles to maximize that production of basic resources and military units quickly becomes an all-consuming juggling act, requiring constant moment-to-moment decisions that can quickly cascade through a run. I’m also a big fan of the game’s self-selecting difficulty system, which asks you to choose how many enemies you think you can take in coming waves, doling out better rewards for players who are willing to push themselves to the limit of their current capabilities.

The bite-size serving of a single King Is Watching run ensures that even failure doesn’t feel too crushing. And success brings with it just enough in the way of semi-permanent ability expansions to encourage another run where you can reach even greater heights of production and protection.

Warhorse Studios; Windows, PS5, Xbox Series X|S

Kingdom Come: Deliverance was a slog that I had to will myself to complete. It was sometimes a broken and janky game, but despite its warts, I saw the potential for something special. And that’s what its sequel, Kingdom Come: Deliverance II, has delivered.

While it’s still a slow burn, the overall experience has been greatly refined, the initial challenge has been smoothed out, and I’ve rarely been more immersed in an RPG’s storytelling. There’s no filler, as every story beat and side quest offers a memorable tale that further paints the setting and characters of medieval Bohemia.

Unlike most RPGs, there’s no magic to be had, which is a big part of the game’s charm. As Henry of Skalitz, you are of meager social standing, and many characters you speak to will be quick to remind you of it. While Henry is a bit better off than his humble beginnings in the first game, you’re no demigod that can win a large battle single-handedly. In fact, you’ll probably lose fairly often in the early goings if more than one person is attacking you.

Almost every fight is a slow dance once you’re in a full suit of armor, and your patience and timing will be the key to winning over the stats of your equipment. But therein lies the beauty of KC:D II: Every battle you pick, whether physical or verbal, carries some weight to your experience and shapes Bohemia for better or worse.

Credit:

          
          Nintendo

                  




After the incredible success of Mario Kart 8 and its various downloadable content packs on the Switch, Nintendo could have easily done a prettier “more of the same” sequel as the launch-window showcase for the Switch 2. Instead, the company took a huge gamble in trying to transform Mario Kart’s usual distinct tracks into a vast, interconnected open world.

This conceit works best in “Free Roam” mode, where you can explore the outskirts of the standard tracks and the wide open spaces in between for hundreds of mini-challenges that test your driving speed and precision. Add in dozens of collectible medallions and outfits hidden in hard-to-reach corners, and the mode serves as a great excuse to explore every nook and cranny of a surprisingly detailed and fleshed-out world map.

I was also a big fan of Knockout Mode, which slowly whittles a frankly overwhelming field of 24 initial racers to a single winner through a series of endurance rally race checkpoints. These help make up for a series of perplexing changes that hamper the tried-and-true Battle Mode formula and long straightaway sections that feel more than a little bit stifling in the standard Grand Prix mode. Still, Free Roam mode had me happily whiling away dozens of hours with my new Switch 2 this year.

Kimmo Lahtinen; Windows, PS5, Xbox Series X|S

For decades now, I’ve been looking for a twin-stick shooter that fully captures the compulsive thrill of the Geometry Wars franchise. Sektori, a late-breaking addition to this year’s top games list, is the first game I can say does so without qualification.

Like Geometry Wars, Sektori has you weaving through a field filled with simple shapes that quickly fill your personal space with ruthless efficiency. But Sektori advances that basic premise with an elegant “strike” system that lets you dash through encroaching enemies and away from danger with the tap of a shoulder button. Advanced players can get a free, instant strike refill by dashing into an upgrade token, and stringing those strikes together creates an excellent risk-vs-reward system of survival versus scoring.

Sektori also features an excellent Gradius-style upgrade system that forces you to decide on the fly whether to take basic power-ups or save up tokens for more powerful weaponry and/or protection further down the line. And just when the basic gameplay threatens to start feeling stale, the game throws in a wide variety of bosses and new modes that mix things up just enough to keep you twitching away.

Throw in an amazing soundtrack and polished presentation that makes even the most crowded screens instantly comprehensible, and you have a game I can see myself coming back to for years—until my reflexes are just too shot to keep up with the frenetic pace anymore.</div>
        </div>
        
        <div class="card" onclick="openModal('content-1')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">Being Santa Claus is a year-round calling</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-1" style="display:none;">
            <h2>Being Santa Claus is a year-round calling</h2>
            <p><strong>Ars Technica - All content | 2025-12-24</strong></p>
            <a class="original-link" href="https://arstechnica.com/science/2025/12/being-santa-claus-is-a-year-round-calling/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Tis the season when professional Santas are in peak demand, but many who choose this line of work often view it as a higher calling and maintain some aspects of the identity all year round—even those who don’t fit the stereotypical popular image of Santa, according to a paper published in the Academy of Management Journal.

Co-author Christina Hymer of the University of Tennessee got the idea for the study during the COVID pandemic, when she spent a lot of time watching Christmas movies with her toddler. One favorite was 2003’s Elf, starring Will Farrell as a full-sized human raised among elves who goes to New York City to find his biological father. The film prompted her to wonder about why someone would want to be Santa Claus and what their experiences in that role would be.

Hymer and her co-authors partnered with the leader of a “Santa school” to analyze archival surveys of 849 professional Santas, and conducted a new survey of another 382 Santas. They also did over 50 personal interviews with professional Santas. (One subject showed up in full costume for his zoom interview, with a North Pole background, and signed off with a merry “ho! ho! ho!”)

Hymer et al. found that professional Santas tend to fall into one of three categories. The first is a prototypical Santa: straight, portly white men with natural white beards. There are also semi-prototypical Santas who might fit the traditional physical characteristics in some respects but not others—they might be younger, or slimmer, or clean-shaven. Finally, there are non-prototypical Santas who are well outside the traditional depiction: people of color, women, disabled Santas, or LGBTQ+ Santas.

“There are pretty strong societal expectations around what Santa looks like, but we found that most anybody can be Santa if their heart desires it,” said co-author Borbala Csillag of Oregon State University. “When we looked at the people behind the suit, we found that the folks playing Santa are really more diverse than would be expected. The expectations for playing the role may seem exclusive, but they are surmountable. Think about your attributes in a comprehensive way so you can identify the dimensions of the role that are well-fitting. You will likely find attributes that map to that calling, even if they are not obvious at first.”

Frankly, what’s most interesting about the paper isn’t those three fundamental categories, but the personalized glimpses it gives of the people who choose to become professional Santas. While a few Santas might make six figures, most do not, and may even lose money being Santa—they do it anyway for the sheer love of it. Professional Santas usually don’t see the role as seasonal; many build their identities around it, whether they fit the stereotypical Kris Kringle image or not. “My feeling is, if you’re Santa all the time, you have to live as Santa and give up whoever you are,” said one subject. “I’m just striving to be a better person.”

They’ll wear red and green all year round, for instance, or maintain a full white beard.  One Santa trained himself to make “Ho, ho, ho!” his natural laugh. Another redecorated his house as “Santa’s house,” complete with Christmas trees and Santa figurines.

Sometimes it’s viewed as a role: a gay professional Santa, for instance, deliberately suppresses his sexual orientation when playing Santa, complete with partnering with a Mrs. Claus for public appearances. However, a female Santa who goes by Lynx (professional Santas typically take on pseudonyms) who is also a church leader, likens the job to a divine calling: “I can connect with people and remind them they’re loved,” she said. (She also binds her breasts when in costume because “Santa doesn’t have them double-Ds.”)

Perhaps that sense of a higher calling is why even non-prototypical Santas like Lynx persevere in the fact of occasional rejection. One Black Santa recalled being denied the position at a big box store once the interviewer found out his ethnicity, telling him the store didn’t hire Black or Hispanic Santas. “That hurt my heart so much,” he said. A disabled Santa who uses a scooter during parades recalled being criticized by other professional Santas for doing so—but stuck with it.

And while Bad Santa (2003) might be a fun holiday watch, actual “bad Santas” caught smoking, drinking, swearing, or otherwise behaving inappropriately are not popular figures within their community. “You’re never off,” one subject opined. “You lose a little bit of your identity because you can’t let your hair down and be yourself. You don’t know who’s watching you.”

“You’re Santa Claus 24 hours a day, seven days a week, 52 weeks a year,” another Santa said. “If you act out, you risk shattering the magic.”

DOI: Academy of Management Journal, 2025. 10.5465/amj.2023.1161  (About DOIs).</div>
        </div>
        
        <div class="card" onclick="openModal('content-2')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">SPEED Act passes in House despite changes that threaten clean power projects</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-2" style="display:none;">
            <h2>SPEED Act passes in House despite changes that threaten clean power projects</h2>
            <p><strong>Ars Technica - All content | 2025-12-24</strong></p>
            <a class="original-link" href="https://arstechnica.com/tech-policy/2025/12/speed-act-passes-in-house-despite-changes-that-threaten-clean-power-projects/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The House of Representatives cleared the way for a massive overhaul of the federal environmental review process last Thursday, despite last-minute changes that led clean energy groups and moderate Democrats to pull their support.

The Standardizing Permitting and Expediting Economic Development Act, or SPEED Act, overcame opposition from environmentalists and many Democrats who oppose the bill’s sweeping changes to a bedrock environmental law.

The bill, introduced by Rep. Bruce Westerman (R-Ark.) and backed by Rep. Jared Golden (D-Maine), passed the House Thursday in a 221-196 vote, in which 11 Democrats joined Republican lawmakers to back the reform effort. It now heads to the Senate, where it has critics and proponents on both sides of the aisle, making its prospects uncertain.

The bill seeks to reform foundational environmental regulations that govern how major government projects are assessed and approved by amending the landmark 1970 National Environmental Policy Act (NEPA), signed into law under the Nixon administration. NEPA requires federal agencies to review and disclose the environmental impacts of major projects before permitting or funding them. Although NEPA reviews are only one component of the federal permitting process, advocates argue that they serve a crucial role by providing both the government and the public the chance to examine the knock-on effects that major projects could have on the environment.

Critics of the law have argued for years that increasingly complex reviews—along with legal wrangling over the findings of those reviews—have turned NEPA into a source of significant, burdensome delays that threaten the feasibility of major projects, such as power plants, transmission lines, and wind and solar projects on federal land.

Speaking on the floor of the House Thursday before the vote, Westerman described the SPEED Act as a way to “restore common sense and accountability to federal permitting.” Westerman praised the original intent of NEPA but said the law’s intended environmental protections had been overshadowed by NEPA becoming “more synonymous with red tape and waste.

“What was meant to facilitate responsible development has been twisted into a bureaucratic bottleneck that delays investments in the infrastructure and technologies that make our country run,” Westerman said.

After the bill’s passage through the House on Thursday, the SPEED Act’s Democratic cosponsor, Golden, praised the bill’s success.

“The simplest way to make energy, housing, and other essentials more affordable is to make it possible to actually produce enough of it at a reasonable cost,” Golden said in a press release following the vote. “The SPEED Act has united workers, businesses, and political forces who usually oppose each other because scarcity hurts everyone.”

According to an issue brief from the Bipartisan Policy Center, the bill aims to reform the NEPA process in several key ways. First, it makes changes to the ways agencies comply with NEPA—for example, by creating exemptions to when a NEPA review is required, and requiring agencies to only consider environmental impacts that are directly tied to the project at hand.

It would also drastically shorten the deadline to sue a federal agency over its permitting decision and constrain who is eligible to file suit. Current law provides a six-year statute of limitations on agency decisions for permitting energy infrastructure, and two years for transportation project permits. Under the SPEED Act’s provisions, those deadlines would be shortened to a mere 150 days and only allow lawsuits to be filed by plaintiffs who demonstrated in public comment periods that they would be directly and negatively impacted by the project.

NEPA does not require the government to make particular decisions about whether or how to move forward with a project based on a review’s findings. However, critics argue that in the decades since its passage, interest groups have “weaponized” the NEPA process to delay or even doom projects they oppose, sometimes forcing agencies to conduct additional analyses that add costly delays to project timelines.

Although climate activists and environmental groups have used NEPA to oppose fossil fuel projects, such as the Keystone XL and Dakota Access pipelines, oil and gas interests are far from the only group seeking respite. Some voices within the clean energy industry have called for permitting reform, too, arguing that delays stemming from the current permitting process have had a negative impact on America’s ability to build out more climate-friendly projects, including some offshore wind projects and transmission lines to connect renewables to the grid.

So when Westerman and Golden introduced the SPEED Act in the House, a hodgepodge of odd alliances and opposition groups formed in response.

The American Petroleum Institute, a trade association for the oil and gas industry, launched a seven-figure advertising campaign in recent months pushing lawmakers to pursue permitting reform, according to a report from Axios. And the bill also initially enjoyed support from voices within the clean power industry. However, last-minute changes to the bill—designed to win over Republican holdouts—undermined the SPEED Act’s cross-sector support.

The bill’s opponents had previously raised alarm bells that fossil fuel interests would disproportionately benefit from a more streamlined review process under the current administration, citing President Donald Trump’s ongoing war against wind and solar energy projects.

In recent months, the Trump administration has sought to pause, reconsider, or revoke already approved permits for renewable energy projects it dislikes. Those moves particularly impacted offshore wind developments and added significant uncertainty to the feasibility of clean energy investments as a whole.

A bipartisan amendment to the SPEED Act, added during the Natural Resources Committee’s markup in November, sought to address some of those concerns by adding language that would make it more difficult for the administration to “revoke, rescind, withdraw, terminate, suspend, amend, alter, or take any other action to interfere” with an existing authorization.

However, that measure encountered resistance from key Republican voices who support Trump’s attacks on offshore wind projects.

On Tuesday, Republican lawmakers in the Rules Committee were able to amend the SPEED Act in a way that would facilitate the Trump administration’s ongoing efforts to axe renewable energy projects. The changes were spearheaded by Andy Harris (R-Md.) and Jeff Van Drew (R-N.J.), two vocal proponents of Trump’s energy policies. The amendment fundamentally undermined the technology-neutral aspirations of the bill—and any hope of receiving widespread support from moderate Democrats or the clean power industry.

According to Matthew Davis, vice president of federal policy at the League of Conservation Voters, Harris and Van Drew’s amendment would allow the administration to exclude any project from the bill’s reforms that the Trump administration had flagged for reconsideration—something the administration has done repeatedly for renewable projects like offshore wind.

The result, Davis argued, is that the bill would speed up the environmental review process for the Trump administration’s preferred sources of energy—namely, oil and gas—while leaving clean energy projects languishing.

“They couldn’t pass the rule on Tuesday to even consider this bill without making it even better for the fossil fuel industry and even worse for the clean energy industry,” Davis said.

In a public statement following Thursday’s vote, Davis described the amended SPEED Act as “a fossil fuel giveaway that cuts out community input and puts our health and safety at risk to help big polluters.”

The American Clean Power Association, which represents the renewable energy industry, previously hailed the bill as an important step forward for the future of clean energy development. But after the Rules Committee’s changes on Tuesday, the organization dropped its support.

“Our support for permitting reform has always rested on one principle: fixing a broken system for all energy resources,” said ACP CEO Jason Grumet in a Wednesday statement. “The amendment adopted last night violate[s] that principle. Technology neutrality wasn’t just good policy—it was the political foundation that made reform achievable.”

The American Council on Renewable Energy (ACORE), a nonprofit trade and advocacy organization, echoed that sentiment.

“Durable, bipartisan, technology-neutral permitting reforms that support and advance the full suite of American electricity resources and the necessary expansion of transmission infrastructure to get that electricity from where it’s generated to where it’s needed are essential to meeting that challenge reliably, securely, and most importantly, affordably,” said ACORE CEO Ray Long. “Unfortunately, the changes made on the House floor are a disappointing step backward from achieving these objectives.”

Following the SPEED Act’s passage through the House on Thursday, advocacy group Citizens for Responsible Energy Solutions (CRES) issued a public statement praising the bill’s success while noting how the recent amendments had affected the law.

“While we are concerned that post committee additions to the bill could put the certainty of a range of projects at risk, this bill’s underlying reforms are critical to advancing American energy,” CRES President Heather Reams said in the statement.

Even before the move to strip protections for renewables from the bill, some critics—like Rep. Mike Levin (D-Calif.)—said that the legislation didn’t go far enough to curtail the president’s “all-out assault” against clean power, arguing that the bill does nothing to restore approvals that have already been canceled by the administration and doesn’t address other roadblocks that have been put in place.

“The administration cannot be trusted to act without specific language, in my view, to protect the clean energy projects already in the pipeline and to prevent the Interior Secretary from unilaterally stopping projects that are needed to lower costs and improve grid reliability,” Levin told Inside Climate News in an interview ahead of the House vote.

Both Levin and Davis pointed to a July memo from the Department of Interior that requires all wind and solar projects on federal land to receive higher-level approval from Interior Secretary Doug Burgum.

“The administration is not even returning the phone calls of project developers. They are not responding to applications being submitted,” Davis said. “That sort of approach is in stark contrast with the ‘white glove, concierge service’—and that’s a quote from the Trump administration—the service they are providing for fossil fuel companies to access our public lands.”

The SPEED Act’s opponents also dispute the idea that NEPA reviews are one of the primary causes of permitting delays, arguing that reports from the Congressional Research Service and other groups have found little evidence to support those claims.

“Often missing in the conversation around NEPA is the empirical research that’s been done, and there’s a lot of that out there,” said Jarryd Page, a staff attorney at the Environmental Law Institute, in a September interview with Inside Climate News.

That research points to resource constraints as one of the biggest roadblocks, Page said, like not having enough staff to conduct the environmental reviews, or staff lacking adequate experience and technical know-how.

Debate over NEPA and the reform of the permitting process will now move into the Senate, where experts say the SPEED Act will likely undergo further changes.

“I think as the bill goes forwards in the Senate, we’ll probably see a neutral, across-the-board approach to making sure the process is fair for all technology types,” Xan Fishman, an energy policy expert at the Bipartisan Policy Center told ICN after Thursday’s vote.

Fishman stressed it would be crucial to ensure permits for projects wouldn’t suddenly be cancelled for political reasons, but said he was optimistic about how the SPEED Act would be refined in the Senate.

“It’s great to see Congress so engaged with permitting reform,” he said. “Both sides of the aisle see a need to do better.”

This article originally appeared on Inside Climate News, a nonprofit, non-partisan news organization that covers climate, energy and the environment. Sign up for their newsletter here.</div>
        </div>
        
        <div class="card" onclick="openModal('content-3')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">TV Technica: Our favorite shows of 2025</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-3" style="display:none;">
            <h2>TV Technica: Our favorite shows of 2025</h2>
            <p><strong>Ars Technica - All content | 2025-12-24</strong></p>
            <a class="original-link" href="https://arstechnica.com/culture/2025/12/tv-technica-our-favorite-shows-of-2025/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Editor’s note: Warning: Although we’ve done our best to avoid spoiling anything major, please note this list does include a few specific references to several of the listed shows that some might consider spoiler-y.

This was a pretty good year for television, with established favorites sharing space on our list with some intriguing new shows. Streaming platforms reigned supreme, with Netflix and Apple TV dominating our list with seven and five selections each. Genre-wise, we’ve got a bit of everything: period dramas (The Gilded Age, Outrageous), superheroes (Daredevil: Born Again), mysteries (Ludwig, Poker Face, Dept. Q), political thrillers (The Diplomats, Slow Horses), science fiction (Andor, Severance, Alien: Earth), broody fantasy (The Sandman), and even an unconventional nature documentary (Underdogs).

As always, we’re opting for an unranked list, with the exception of our “year’s best” selection at the very end, so you might look over the variety of genres and options and possibly add surprises to your eventual watchlist. We invite you to head to the comments and add your own favorite TV shows released in 2025.

Credit:

          
          National Geographic/Doug Parker

Most of us have seen a nature documentary or two (or three) at some point in our lives, so it’s a familiar format: sweeping, majestic footage of impressively regal animals accompanied by reverently high-toned narration (preferably with a tony British accent). Underdogs takes a decidedly different approach. Narrated with hilarious irreverence by Ryan Reynolds, the five-part series highlights nature’s less cool and majestic creatures—the outcasts and benchwarmers more noteworthy for their “unconventional hygiene choices” and “unsavory courtship rituals.” (It’s rated PG-13 due to the odd bit of scatalogical humor and shots of Nature Sexy Time.)

Each of the five episodes is built around a specific genre. “Superheroes” highlights the surprising superpowers of the honey badger, pistol shrimp, and the invisible glass frog, among others, augmented with comic book graphics; “Sexy Beasts” focuses on bizarre mating habits and follows the format of a romantic advice column; “Terrible Parents” highlights nature’s worst practices, following the outline of a parenting guide; “Total Grossout” is exactly what it sounds like; and “The Unusual Suspects” is a heist tale, documenting the supposed efforts of a macaque to put together the ultimate team of masters of deception and disguise (an inside man, a decoy, a fall guy, etc.). Green Day even wrote and recorded a special theme song for the opening credits.

While Reynolds mostly followed the script (which his team helped write), there was also a fair amount of improvisation—not all of it PG-13. The producers couldn’t use the racier ad-libs. But some made it into the final episodes, like Reynolds describing an aye-aye as “if fear and panic had a baby and rolled it in dog hair.” We also meet the velvet worm, which creeps up on unsuspecting prey before squirting disgusting slime all over their food, and the pearl fish, which hides from predators in a sea cucumber’s butt, among other lowly yet fascinating critters. Verdict: Underdogs is positively addictive. It’s my favorite nature documentary ever.

Dep. Q is a rare show that commits to old tropes—an unlikable but smart central character revisits cold cases—and somehow manages to repackage them in a way that feels distinctive. To get a sense of the show, you only have to describe its precise genre. You might call it a murder mystery, and there are murders in it, but one of the mysteries is whether a key player is alive or not, given that a lot of her story takes place in flashbacks with an uncertain relationship to the present. It’s almost a police procedural, except that many of the police are only following procedures grudgingly and erratically. It’s not really a whodunnit, given that you only end up learning who done some of it by the time the first season wraps up. And so on.

Amid all the genre fluidity, the show does a great job of balancing the key challenge of a mystery program: telling you enough that you can make reasonably informed guesses on at least some of what’s going on without giving the whole game away and making it easy to figure out all the details. And the acting is superb. Matthew Goode does a nice job of handling the central character’s recent trauma while helping you understand why he has a few loyal co-workers despite the fact that he was probably unlikable even before he was traumatized. And Alexej Manvelov (who I’d never seen before) is fantastic as a former Syrian policeman who drops occasional hints that he had been an active participant in that country’s police state.

There are definitely quibbles. The creation of a cold case squad happens on the flimsiest of motivations, and the fantastic Kelly Macdonald is badly underused. But the show is definitely good enough that I’m curious about some additional mysteries: Can the team behind it continue to avoid getting bogged down in the tropes in season two, and which of the many threads it left unresolved will be picked up when they try?

Credit:

          
          Marvel/Disney+

Enthusiasm was understandably high for Daredevil: Born Again, Marvel’s revival of the hugely popular series in the Netflix Defenders universe. Not only was Charlie Cox returning to the title role as Matt Murdock/Daredevil, but Vincent D’Onofrio was also coming back as his nemesis, crime lord Wilson Fisk/Kingpin. Their dynamic has always been electric, and that on-screen magic is as powerful as ever in Born Again, which quickly earned critical raves and a second season.

Granted, there were some rough spots. The entire season was overhauled during the 2023 Hollywood strikes, and at times it felt like two very different shows. A weird serial killer subplot was primarily just distracting. There was also the controversial decision to kill off a major character from the original Netflix series in the first episode. But that creative choice cleared the decks to place the focus squarely on Matt’s and Fisk’s parallel arcs, and the two central actors do not disappoint.

Matt decides to focus on his legal work while Fisk is elected mayor of New York City, intent on leaving his criminal life behind. But each struggles to remain in the light as the dark sides of their respective natures fight to be released. The result is an entertaining, character-driven series that feels very much a part of its predecessor while still having its own distinctive feel.

I confess I might have missed Boots had it not been singled out and dismissed as “woke garbage” by the Pentagon—thereby doubling the show’s viewership. I was pleased to discover that it’s actually a moving, often thought-provoking dramedy that humanizes all the young men from many different backgrounds who volunteer to serve their country in the US military. The show is based on a memoir (The Pink Marine) by Greg Cope White about his experiences as a gay teen in the military in the 1980s when gay and bisexual people weren’t allowed to serve. Boots is set in the early 1990s just before the onset of the “Don’t ask, don’t tell” era.

Miles Heizer stars as Cameron Cope (Cope White’s fictional alter ego), a closeted gay teen in Louisiana who signs up as a recruit for the US Marine Corps with his best (straight) friend Ray (Liam Oh). He’s not the most promising recruit, but over the course of eight episodes, we see him struggle, fail, pick himself back up, and try again during the grueling boot camp experience, forming strong bonds with his fellow recruits but all the while terrified of being outed and kicked out.

Heizer gives a powerful performance as Cameron, enhanced by the contrast with Max Parker’s stellar portrayal of the tightly wound Sergeant Liam Robert Sullivan—a decorated Marine inexplicably reassigned to train recruits while harboring his own secrets. Nor is Miles’ story the only focus: We learn more about several characters and their private struggles, and those inter-relationships are the heart and soul of the show. Netflix canceled the series, but this one season stands tall on its own.

This charming Emmy-nominated comedy series has made our “Best of TV” list every season, and 2025 is no exception. Only Murders in the Building (OMITB) stars Steve Martin, Martin Short, and Selena Gomez as Charles, Oliver, and Mabel, all residents of the same Manhattan apartment complex, the Arconia. The unlikely trio teams up to launch their own true crime podcast whenever someone dies in the building under suspicious circumstances, chronicling their independent investigation to solve the murder. There’s no shortage of podcast fodder, as this single building has a shockingly high murder rate.

S5 focused on the death of the building’s doorman, Lester (Teddy Coluca), found floating in the Arcadia’s fountain in the season finale. The discovery of a severed finger leads our team to conclude that Lester was murdered. Their quest involves a trio of billionaires, the mayor (Keegan-Michael Key), a missing mafioso (Bobby Cannavale) and his widow (Tea Leoni), and maybe even the building’s new robotic assistant, LESTR (voiced by Paul Rudd). As always, the season finale sets up next season’s murder: that of rival podcaster Cinda Canning (Tina Fey), who lives just long enough to reach the Arcadia’s gates and place one hand into the courtyard—technically dying “in the building.” One assumes that OMITB will eventually run out of fresh takes on its clever concept, but it certainly hasn’t done so yet.

I unequivocally loved the first season of The Sandman, the Netflix adaptation of Neil Gaiman’s influential graphic novel series (of which I am a longtime fan). I thought it captured the surreal, dream-like feel and tone of its source material, striking a perfect balance between the anthology approach of the graphic novels and grounding the narrative by focusing on the arc of its central figure: Morpheus, lord of the Dreaming. It was a long wait for the second and final season, but S2 retains all those elements to bring Dream’s story to its inevitably tragic yet satisfying end.

As always, the casting is extraordinary and the performances are note-perfect across the board. And Netflix did not skimp on the visuals, which bring the graphic novel imagery to vivid life. I still appreciate how the leisurely pacing lets the viewer relax and sink into this richly layered fictional world. Part I kicked off with an Endless family reunion that led Dream into revisiting Hell and agreeing to his sister Delirium’s request to look for their absent brother, Destruction. That sets in motion a chain of events that leads to the tragedy that unfolds in Part II. The bonus episode, in which Death gets one day (every hundred years) to be human—an adaptation of the standalone Death: The High Cost of Living—serves as a lovely coda to this unique series, which is pretty much everything I could have wanted in an adaptation.

Ludwig is a clever twist on the British cozy mystery genre. David Mitchell stars as John Taylor, a reclusive eccentric who creates puzzles for a living under the pseudonym “Ludwig.” When his identical twin brother, Cambridge DCI James Taylor (also Mitchell), goes missing, his sister-in-law Lucy (Anna Maxwell Martin) convinces John to go undercover. John reluctantly pretends to be James to gain access to the police department in hopes of finding out what happened to his twin. He inevitably gets drawn into working on cases—and turns out to be exceptionally good at applying his puzzle skills to solve murders, even as his anxiety grows about his subterfuge being discovered.

The best crime shows deftly balance cases-of-the-week with longer character-driven story arcs, and Ludwig achieves that balance beautifully. The writers brought in a puzzle consultant to create the various crosswords that appear in the series, as well as a special cryptic crossword done in character as Ludwig that appeared in The Guardian. The first season ended with a bit of a cliffhanger about what’s really been going on with James, but fortunately, the BBC has renewed Ludwig for a second season, so we’ll get to see more of our cryptic crime-solver.

Poker Face is perfect comfort TV, evolving the case-of-the-week format that made enduring early TV hits like Columbo and Murder, She Wrote iconic. The second season takes the endlessly likeable BS-detector Charlie Cale (Natasha Lyonne) to the end of the road after she overcomes fleeing the mob in her 1969 Plymouth Barracuda. Along the way, Charlie pals around with A-list guest stars and solves crimes, winding her way from Florida to New York as each delightful new caper serves not to ramp up tension but to disrupt how viewers anticipate Charlie will move. Some might think that the lack of tension made the season weaker. But creator Rian Johnson recently revealed that he expects Poker Face to cast a new lead detective every two years. That makes it seem clear that Charlie’s second season was more about release.

In the most memorable episode of the season, “Sloppy Joseph,” the front row of an elementary school talent show suddenly becomes a bloody splash zone when a bullied boy is framed for killing the class pet, a gerbil, with a giant mallet. That scene is perhaps an apt metaphor for Johnson’s attempt to keep modern-day viewers from turning away from their TVs by shattering expectations. It’s unclear yet if his formulaic TV hijinks will work, but if anyone decides to pick up Poker Face after Peacock declined to renew it, Peter Dinklage is next in line to become the world’s greatest lie detector.

I was a latecomer to this eminently watchable show created by Julian Fellowes (Gosford Park), who also gave us the Emmy-winning sensation Downton Abbey. Instead of following the adventures of post-Edwardian British aristocracy and their domestic servants, the focus is on ultra-wealthy Americans and their domestic servants in the 1880s and the social tensions that arise from the “old money” versus “new money” dynamic of this rapidly changing period. The Gilded Age has been described as an “operatic soap” (rather than a soap opera), replete with a hugely talented ensemble cast donning lavish costumes and cavorting in extravagantly opulent settings. It’s unadulterated, addictive escapism, and the series really hit its stride in S3.

Old Money is represented by Agnes van Rhijn (Christine Baranski), a wealthy widow who lives with her spinster sister Ada (Cynthia Nixon); orphaned niece Marian (Louisa Jacobson); and son and heir Oscar (Blake Ritson), a closeted gay man seeking to marry a rich heiress. Living just across the street is New Money, personified by robber baron/railroad tycoon George Russell (Morgan Spector) and his socially ambitious wife Bertha (Carrie Coon) and their two children. You’ve got Marian’s friend Peggy (Denee Benton) representing the emerging Black upper class and a colorful assortment of domestics in both houses, like aspiring inventor Jack (Ben Ahlers), who dreams of greater things.

Fictionalized versions of notable historical people occasionally appear, and two figure prominently: Caroline Astor (Donna Murphy), who ruled New York society at the time, and her simpering sycophant Ward McAllister (Nathan Lane). (The Russells are loosely inspired by William and Ava Vanderbilt.) The stakes might sometimes seem small—there’s a multi-episode arc devoted to which of two competing opera houses New York’s social elite will choose to sponsor—but for the characters, they are huge, and Fellowes makes the audience feel equally invested in the outcomes. There were a few rough edges in the first season, but The Gilded Age quickly found its footing; it has gotten better and more richly textured with each successive season and never takes itself too seriously.

The Mitford sisters were born to be immortalized one day in a British period drama, and Outrageous is happy to oblige. There were six of them (and one brother), and their scandalous exploits frequently made global headlines in the 1930s. This is ultimately a fictionalized account of how the rise of Hitler and British fascism fractured this once tight-knit aristocratic family. The focus is on smaller, domestic drama—budding romances, failed marriages, literary aspirations, and dwindling fortunes—colored by the ominous global events unfolding on a larger scale.

Nancy (Bessie Carter) is the primary figure, an aspiring novelist with a cheating husband who feels increasingly alienated from her older sister and bestie Diana (Joanna Vanderham). Diana married a baron but becomes enamored of Oswald Mosley (Joshua Sasse), leader of the British fascist party, embarking on a torrid affair. Another sister, Unity (Shannon Watson), is also seduced by Nazi ideology and has a major crush on Hitler. Meanwhile, Jessica (Zoe Brough) is drawn to the Communist cause, which rankles both her siblings and her traditionally conservative parents.

Things come to a head when Unity goes to study in Germany and becomes completely radicalized, even publishing a vicious anti-semitic screed that shames the family. Diana also goes all-in on fascism when she leaves her husband for Mosley, whom Nancy loathes. Jessica elopes with her Communist cousin to Spain to be on the front lines of that civil war, leading to a lifelong estrangement from Diana. Nancy, the political moderate, is caught in the middle, torn between her love for her sisters and her increasing discomfort with Diana and Unity’s extreme political views.

The Mitford sisters were prolific letter writers all their lives, so there was plenty of material for screenwriter Sarah Williams to draw on when fictionalizing their stories at such a pivotal point in the family’s (and the world’s) history. Outrageous is quite historically accurate in broad outlines, and there are plenty of moments of wry, understated humor amid the family tensions. The gifted cast makes the sisters come alive in all their flawed humanity. There’s no word yet on a second season, and this one ends on a suitable note, but there’s so much more story left to tell, so I hope Outrageous returns.

I’ll admit I wasn’t sure how well A Man on the Inside would fare with its sophomore season after knocking it out of the park in S1. I should have known showrunner Mike Schur (The Good Place) could pull it off. Ted Danson plays Charles Nieuwendyk, a recently widowed retired engineering professor. In S1, he was hired by private detective Julie Kovalenko (Lilah Richcreek Estrada) to go undercover at a San Francisco retirement community to solve the mystery of a stolen ruby necklace. In S2, Charles returns to his academic roots and goes undercover at fictional Wheeler College to solve the mystery of a stolen laptop—a crime that just might have implications for the survival of the college itself.

Charles even falls in love for the first time since his wife’s death with music professor Mona Margadoff (Mary Steenburgen, Danson’s wife IRL), despite the two being polar opposites. The show continues to be a welcome mix of funny, sweet, sour, and touching, while never lapsing into schmaltz. The central Thanksgiving episode—where Mona meets Charles’s family and friends for the first time—is a prime example, as various tensions simmering below the surface erupt over the dinner table. Somehow, everyone manages to make their respective peace in entirely believable ways. It’s lovely to see a series grapple so openly, with so much warmth and humor, with the loneliness of aging and grief and how it can affect extended family. And the show once again drives home the message that new beginnings are always possible, even when one thinks one’s life is over.

Credit:

          
          Lucasfilm/Disney+

When real-life political administrations refer to officials as Darth Vader in unironically flattering terms, maybe George Lucas made the Dark Lord of the Sith a little too iconic. Showrunner Tony Gilroy made no such effort in his depiction of the fascists in Andor.

During Andor‘s run, which ended this year with S2, the Empire is full of sad corporate ladder climbers who are willing to stab another in the back to get to the next rung of the Imperial hierarchy. The show makes it clear that these are not people to emulate. If more fans watched the show, maybe that message could have landed for them.

For people who grew up with Star Wars and want something more to chew on in our adulthood than endless callbacks to the original trilogy, Andor is revelatory. It colors the war of light versus dark with large amounts of gray because sometimes, as one character puts it, you have to use the tools of your enemy to defeat them (save for genetically gifted farmboys). Maybe most of Star Wars was always supposed to be for kids, but prestige TV viewers got a glimpse of what the universe could feel like if it took itself more seriously. Rather than use the broad strokes of a war of good versus evil, Andor painted between the lines to demonstrate how systemic oppression can look a lot more personal than firing a giant space laser.

For all its great writing and themes, Andor also delivered high stakes and suspense. Although we already knew the outcome of the story, we still held our breath during tense scenes with characters who make the ultimate sacrifice for a future they will never see.

Credit:

          
          Sean Carroll

My personal end-of-year TV list would never be complete without a nod to The Cowboy Channel, i.e., the only place where armchair enthusiasts like myself can follow our favorite cowboys and cowgirls throughout the rodeo season. The goal is to rack up enough money to qualify for the Wrangler National Finals Rodeo (NFR), held at the Thomas & Mack Center in Las Vegas every December. This year, I’ve picked the channel’s stellar annual coverage of the NFR itself to highlight. The entire season comes down to this: an intense 10-day competition in which the top 15 athletes in each event duke it out night after night in hopes of winning a coveted championship gold buckle. And night after night, The Cowboy Channel is there with live commentary and post-round analysis.

What I love most is just how unpredictable the NFR can be. Part of that is the substantial monetary rewards that come with round wins; an athlete coming in at #1 in earnings can see even a substantial lead evaporate over just a few nights. Part of it has to do with who wins the average, i.e., who performs the best over ten nights collectively in each event. Winning the average comes with a substantial payout that can lead to unexpected upsets in the final results. But mostly it’s just the human factor: The best in the world can have a bad night, and young rookies can have the night of their lives. An ill-timed injury can knock an athlete out of the competition entirely. And sometimes the judges make inexplicably bad calls with major consequences (*cough* Stetson Wright in Round 6 saddle bronc *cough*).

It’s all part of the excitement of rodeo. The Cowboy Channel’s in-depth coverage lets us experience all that drama even if we can’t attend in person and lets us savor how the story unfolds in each subsequent round. We celebrate the wins, mourn the losses, and cheer mightily for the final champions. (Stetson did just fine in the end.) Then we gear up to do it all over again next year.

Credit:

          
          National Geographic

The blockbuster success of the 1986 film Top Gun—chronicling the paths of young naval aviators as they go through the grueling US Navy’s Fighter Weapons School (aka the titular Top Gun)—spawned more than just a successful multimedia franchise. It has also been credited with inspiring future generations of fighter pilots. National Geographic took viewers behind the scenes to see the process play out for real with the documentary series Top Guns: The Next Generation.

Each episode focuses on a specific aspect of the training, following a handful of students from the Navy and Marines through the highs and lows of their training. That includes practicing dive bombs at breakneck speeds, successfully landing on an aircraft carrier by “catching the wire,” learning the most effective offensive and defensive maneuvers in dogfighting, and, finally, engaging in a freestyle dogfight against a seasoned instructor to complete the program and (hopefully) earn their golden wings. NatGeo was granted unprecedented access, even using in-cockpit cameras to capture the pulse-pounding action of being in the air, as well as more candidly intimate behind-the-scenes moments as the students grapple with their respective successes and failures. It’s a riveting watch.

My first draft of what was supposed to be a 300-ish word blurb describing why Alien: Earth is fantastic ended up exploding into a Defector-esque narrative deep dive into my ever-evolving relationship with Alien 3 as a film and how Alien: Earth has helped reshape my appreciation for that poor broken baby of a movie by mixing the best of its visual techniques into A:E’s absolutely masterful cocktail of narrative stylings—but I’ll spare you all of that.

Here’s the short version without the bloviating: Alien: Earth is the thing I’ve been waiting for since I walked out of the theater after seeing Alien 3 in the summer of 1992. Unlike Alien Resurrection, any of the AvPs, or the wet-fart, falls-apart-like-mud-in-the-third-act swing-and-miss of Alien: Romulus, A:E gets nearly everything right. It’s grounded without being stodgy; exciting without being stupid; referential without being derivative; fun without being pandering; respectful of the lore while being willing to try something new; and, above all else, it bleeds craftsmanship—every frame makes it obvious that this is a show made by people who love and care for the Alien universe.

The thing that grabs me anew with every episode is the show’s presentation and execution—a self-aware blending of all the best things Scott, Cameron, and Fincher brought to their respective films. As I get older, I’m drawn more and more to entertainment that shows me interesting things and does so in ontologically faithful ways—and oh, does this show ever deliver.

Each episode is a carefully crafted visual and tonal mix of all the previous Alien films, with the episodes’ soundtracks shifting eras to match the action on-screen—like Alien 3’s jumpy choir flash-cut opening credits melding into Aliens’ lonely snare drums. The result is a blended world made of all the best things I remember from the films, and it works in the same way the game Alien: Isolation worked: by conjuring up exactly what the places where we used to have nightmares looked and felt like, and then scaring us there again.

I have heard that The Internet had some problems with the show, but, eh, everybody’s going to hate something. I vaguely remember some of the complaints having to do with how some of the new alien life-forms seem to be scarier or deadlier than our beloved and familiar main monster. All I’ve got for that one is a big fat shrug—I’m fine with our capital-A-aliens sharing the stage with some equally nasty new creatures. The aliens are always more interesting as devices to explore a story than as dramatic ends themselves, and I mean, let’s face it, in the past 40-plus years, there’s not much we haven’t seen them do and/or kill. They’re a literary force, not characters, and I’m way more interested in seeing how they shape the story of the people around them.

The tl;dr is that Alien: Earth is awesome, and if you haven’t watched it, you absolutely should. And when I was a kid, I used to regularly get put in time-out in recess for stiff-arming other kids while pretending to be a power loader, so you should consider my tastemaking credentials in this matter unimpeachable.

In the most violent series to ever catch the world’s attention by playing beloved children’s games, it turns out that the most high-stakes choice that creator Hwang Dong-hyuk could make was to put a child in the arena. For Squid Game‘s final season, Hwang has said the season’s pivotal moment—a pregnant girl birthing a baby during a game of hide-and-seek with knives—was designed to dash viewers’ hopes that a brighter future may await those who survive the games. By leaving the task of saving the baby to the series hero, Seong Gi-hun, whose own strained relationship with his daughter led him into the games in the first season, Squid Game walked a gritty tightrope to the very end.

The only real misstep was involving the goofiest set of cartoon villain VIPs more directly in the games. But we can forgive Hwang the clunky Dr. Evil-like dialogue that slowed down the action. He’s made it clear that he put everything into developing dramatic sequences for the game players—losing teeth, barely eating, rarely sleeping—and he fully admitted to The New York Times that “I have a cartoonish way of giving comic relief.

Let’s be clear: The Diplomat is a soap opera. If you’re not into cliffhangers, intense levels of drama, and will-they-won’t-they sexual tension, it’s probably not going to be for you. Sometimes there’s so much going on that it becomes almost farcical. If that doesn’t scare you off, what do you get in return?

Superb actors given rich and intriguing characters to inhabit. A political drama that nicely finds a balance between the excessive idealism of The West Wing and the excessive cynicism of Veep. A disturbingly realistic-feeling series of crises that the characters sometimes direct, and sometimes hang on for dear life as they get dragged along by. And, well, the cliffhangers have been good enough to get me tuning in to the next season as soon as it appears on Netflix.

Kerri Russell plays the titular diplomat, who is assigned to what seems like a completely innocuous position: ambassador to one of the US’s closest allies, the UK. Rufus Sewell portrays her husband, a loose-to-the-point-of-unmoored cannon who ensures the posting is anything but innocuous. Ali Ahn and Ato Assandoh, neither of whom I was familiar with, are fantastic as embassy staff. And as the central crisis has grown in scale, some familiar West Wing faces (Allison Janey and Bradley Whitford) have joined the cast. Almost all of the small roles have been superbly acted as well. And for all the dysfunction, cynicism, and selfish behavior that drive the plot forward, the politics in The Diplomat feels like pleasant escapism when compared to the present reality.

Apple TV+’s Murderbot, based on Martha Wells’ bestselling series of novels The Murderbot Diaries, is a jauntily charming sci-fi comedy dripping with wry wit and an intriguing mystery. Murderbot the TV series adapts the first book in the series, All Systems Red. A security unit that thinks of itself as Murderbot (Alexander Skarsgård) is on assignment on a distant planet, protecting a team of scientists who hail from a “freehold.”

Mensah (Noma Dumezweni) is the team leader. The team also includes Bharadwaj (Tamara Podemski) and Gurathin (David Dastmalchian), who is an augmented human plugged into the same data feeds as Murderbot (processing at a much slower rate). Pin-Lee (Sabrina Wu) also serves as the team’s legal counsel; they are in a relationship with Arada (Tattiawna Jones), eventually becoming a throuple with Ratthi (Akshaye Khanna). Unbeknownst to the team, Murderbot has figured out how to override his governor module that compels it to obey the humans’ commands. So Murderbot essentially has free will.

The task of adapting Wells’ novellas for TV fell to sibling co-creators Paul Weitz and Chris Weitz. (Wells herself was a consulting producer.) They’ve kept most of the storyline intact, fleshing out characters and punching up the humor a bit, even recreating campy scenes from Murderbot’s favorite show, The Rise and Fall of Sanctuary Moon. (John Cho and Clark Gregg make cameos as the stars of that fictional show-within-a-show.) The entire cast is terrific, but it’s Skarsgård’s hilariously deadpan performance that holds it all together as he learns how to relate to the humans—even forming some unexpectedly strong bonds.

Fans of Slow Horses (see below), rejoice: with Down Cemetery Road, Apple TV has blessed us with another exciting mystery thriller series based on the works of Mick Herron—in this case, his 2003 novel introducing private investigator Zoë Boehm (Emma Thompson). Ruth Wilson co-stars as Sarah, an artist rather unhappily married to a finance bro. A neighboring building is destroyed by an explosion, and Sarah tries to deliver a get-well card to a little girl who survived from her young classmates. She’s inexplicably rebuffed, and her dogged attempts to figure out what’s going on lead her to seek the help of Zoë’s PI partner and estranged husband Joe (Adam Godley). What Joe finds out gets him killed, setting Sarah and Zoë on a collision course with high-placed government officials trying to cover up a pending scandal.

Thompson and Wilson make a dynamic pair. This is Thompson’s meatiest role in a while: Her Zoë is all flinty cynicism and tough exterior, masking an inner vulnerability she’s learned to keep buried. Wilson’s Sarah is the polar opposite in many ways, but she’s equally dogged, and both women are eccentrics who tend to rub people the wrong way. They’re united in a common goal: find the missing girl and bring her kidnappers (and Joe’s killer) to justice. Down Cemetery Road takes a bit of time to set up its premise and its characters, but the pace builds and builds to a big, satisfying finale. It’s not quite on the level of Slow Horses, but it’s pretty darned close.

After watching five episodes of the nine-episode first season of Apple TV’s Pluribus, I’m still not sure if I should be rooting for protagonist Carol Sturka or not. On the one hand, Carol is one of the last true “individuals” on Earth, fighting to maintain that individuality against a creepy alien pseudo-virus that has made almost everyone else part of a creepy, psychically connected hive mind. Reversing that effect, and getting the world “back to normal,” is an understandable and sympathetic response on Carol’s part.

On the other hand, it’s unlear that being absorbed into the hive mind is a change for the worse, on a humanity-wide scale. Unlike Star Trek’s Borg—who are violent, shambling drones that seem to have an overall miserable existence—the new hive-mind humanity is unfailingly pacifist, intelligent, capable, and (seemingly) blissfully, peacefully happy. In a sense, this virus has “solved” human nature by removing the paranoia, fear, anger, and distrust that naturally come from never truly knowing what’s going on in your neighbor’s head.

The fact that Pluribus has so far been able to navigate this premise without coming down strongly on one side or the other is frankly incredible. The fact that it has done it with consistent humor, thrills, and amazing cinematography transforms it into a must-watch.

There are many things I enjoy about Slow Horses, the Apple TV thriller about some not-great spies based on Mick Herron’s novels of the same name. The plots are gripping. The acting can be sublime. It’s shot well. And in its fifth season, which began streaming this September, Slow Horses engages more with the author’s humor than in seasons past. But with a plot involving the honeypotting of the deluded computer expert almost-extraordinaire Roddy Ho (played to perfection by Christopher Chung), that would be hard to avoid.

Slough House is a rundown MI5 office used as a dumping ground for employees in disgrace—the slow horses. They can’t be fired, but they can quit, and working for Jackson Lamb (Gary Oldman) is meant to make that happen. Lamb is a veteran of the dirtiest days of the Cold War, knowing not only where most of the bodies are buried but having helped put a few of them there himself. His legendary field prowess is only dwarfed by his repellent personality, mocking and belittling everyone in sight—but often deservedly so.

Each member of his team is there for a different sin, and throughout the season—which involves a plot to destabilize the British government, ripped from an MI5 playbook—we see evidence of why they’ve been consigned to the slow horses. These are not invincible operators, just flawed human beings, perfectly capable of screwing up again and again. And yet, our lovable bunch of losers usually manages to come through in the end, showing up “the Park&quot;—MI5’s (fictional) head office in London’s Regent’s Park, which is usually a step behind Lamb’s quick and devious thinking.

The adaptation is faithful enough to the books to give me deja vu during the first episode, and with just six episodes in a season, the payoff comes relatively quickly. I can’t wait for season 6.

The second season of Severance was never going to be able to live up to the constant, slow rollout of gut punches that characterized the first season. Those first 10 episodes ably explored the most important implications of the titular severance procedure, which splits a single person into separate “innie” and “outtie” consciousnesses with distinct sets of memories. The audience got to explore those implications along with the “innie” characters, who were struggling against the boundaries of their odd cubicle life right up until that thrilling final shot.

With so much now revealed and understood, a lot of that fire fell out of the second season of the show. Sure, there were still some loose ends to tie up from the mysteries of the first season, and plenty of new, off-puttingly weird situations on offer. And the new season definitely has quite a few high points, like the big twist revealed when the “innies” get to have a rare outdoor excursion or the extended flashback showing a character trapped in a seemingly endless sequence of social tests she can’t remember afterward.

But S2 also spent entire episodes exploring backstories and mysteries that didn’t have nearly as much emotional or plot impact. By the time the final episode arrived—with a rescue sequence that required an inordinate amount of suspension of disbelief—I found myself wondering just how much more interesting juice there was to squeeze from the show’s brilliant original premise. I worry that the show is trending in the direction of Lost, which drew things out with a lot of uninteresting padding before finally resolving the plot’s core puzzle box in an unsatisfying way. I’m still along on that ride for now, but I really hope it’s going somewhere soon.

Paul William Davies created this delightful mystery comedy, loosely based on a bestselling nonfiction book by Kate Andersen Brower about the maids, butlers, cooks, florists, doormen, engineers, and others dedicated to ensuring the White House residence runs smoothly. In the middle of a state dinner for the visiting Australian prime minister, White House Chief Usher A.B. Wynter (Giancarlo Esposito) is found dead in the third-floor game room. Everyone initially assumes it was suicide.

Enter private detective Cordelia Cupp (Uzo Aduba), who most definitely does not think it was suicide and proceeds to investigate. She has about a dozen suspects, and her blunt, rather eccentric personality means she’s not remotely intimidated by the august setting of this particular murder. Cupp even takes the odd break in sleuthing to do a bit of birdwatching on the White House grounds. (It’s her goal to see all the birds President Teddy Roosevelt recorded during his tenure.) Birdwatching is more than a lifelong hobby for Cupp; it’s central to her character and to how she approaches solving crimes. Bonus: Viewers learn a lot of fascinating bird trivia over eight episodes.

Davies has devised a clever narrative structure, telling the story in flashbacks during a Congressional hearing (presided over by former US Sen. Al Franken playing a fictional senator from Washington state). It’s a good mystery with plenty of unexpected twists and snappy dialogue. Each episode title refers to a famous murder mystery; the camerawork is inventive and fun; and everyone in the cast knocks it out of the park. I especially loved pop star Kylie Minogue’s cameo playing a fictional version of herself as a state dinner guest. Davies apparently couldn’t convince her fellow Australian Hugh Jackman to also make a cameo. But Ben Prendergast’s winking portrayal of “Hugh Jackman&quot;—only seen from behind or with his face obscured—is actually funnier than having the real actor.

It would be a mistake to dismiss The Residence as a mere bauble of a murder mystery just because of its playful, lighthearted tone. The show really does capture what is special and unique about the people who keep the White House residence functioning and why they matter—to each other and to America. Cupp’s final speech after unmasking the killer drives home those points with particular poignancy.

Netflix sadly canceled this excellent series, so there won’t be a second season—although I’m not sure how the writers could improve on such a tour de force. Do we really need Cupp to solve another elaborate murder in the White House? If I’m being honest, probably not. But she’s such a great character. I’d love to see more of her, perhaps in a Knives Out-style franchise where the location and main suspects continually change while the central detective stays the same. Somebody make it so.</div>
        </div>
        
        <div class="card" onclick="openModal('content-4')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">How AI coding agents work—and what to remember if you use them</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-4" style="display:none;">
            <h2>How AI coding agents work—and what to remember if you use them</h2>
            <p><strong>Ars Technica - All content | 2025-12-24</strong></p>
            <a class="original-link" href="https://arstechnica.com/information-technology/2025/12/how-do-ai-coding-agents-work-we-look-under-the-hood/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">AI coding agents from OpenAI, Anthropic, and Google can now work on software projects for hours at a time, writing complete apps, running tests, and fixing bugs with human supervision. But these tools are not magic and can complicate rather than simplify a software project. Understanding how they work under the hood can help developers know when (and if) to use them, while avoiding common pitfalls.

We’ll start with the basics: At the core of every AI coding agent is a technology called a large language model (LLM), which is a type of neural network trained on vast amounts of text data, including lots of programming code. It’s a pattern-matching machine that uses a prompt to “extract” compressed statistical representations of data it saw during training and provide a plausible continuation of that pattern as an output. In this extraction, an LLM can interpolate across domains and concepts, resulting in some useful logical inferences when done well and confabulation errors when done poorly.

These base models are then further refined through techniques like fine-tuning on curated examples and reinforcement learning from human feedback (RLHF), which shape the model to follow instructions, use tools, and produce more useful outputs.

Over the past few years, AI researchers have been probing LLMs’ deficiencies and finding ways to work around them. One recent innovation was the simulated reasoning model, which generates context (extending the prompt) in the form of reasoning-style text that can help an LLM home in on a more accurate output. Another innovation was an application called an “agent” that links several LLMs together to perform tasks simultaneously and evaluate outputs.

In that sense, each AI coding agent is a program wrapper that works with multiple LLMs. There is typically a “supervising” LLM that interprets tasks (prompts) from the human user and then assigns those tasks to parallel LLMs that can use software tools to execute the instructions. The supervising agent can interrupt tasks below it and evaluate the subtask results to see how a project is going. Anthropic’s engineering documentation describes this pattern as “gather context, take action, verify work, repeat.”

If run locally through a command-line interface (CLI), users give the agents conditional permission to write files on the local machine (code or whatever is needed), run exploratory commands (say, “ls” to list files in a directory), fetch websites (usually using “curl”), download software, or upload files to remote servers. There are lots of possibilities (and potential dangers) with this approach, so it needs to be used carefully.

In contrast, when a user starts a task in the web-based agent like the web versions of Codex and Claude Code, the system provisions a sandboxed cloud container preloaded with the user’s code repository, where Codex can read and edit files, run commands (including test harnesses and linters), and execute code in isolation. Anthropic’s Claude Code uses operating system-level features to create filesystem and network boundaries within which the agent can work more freely.

Every LLM has a short-term memory, so to speak, that limits the amount of data it can process before it “forgets” what it’s doing. This is called “context.” Every time you submit a response to the supervising agent, you are amending one gigantic prompt that includes the entire history of the conversation so far (and all the code generated, plus the simulated reasoning tokens the model uses to “think” more about a problem). The AI model then evaluates this prompt and produces an output. It’s a very computationally expensive process that increases quadratically with prompt size because LLMs process every token (chunk of data) against every other token in the prompt.

Anthropic’s engineering team describes context as a finite resource with diminishing returns. Studies have revealed what researchers call “context rot”: As the number of tokens in the context window increases, the model’s ability to accurately recall information decreases. Every new token depletes what the documentation calls an “attention budget.”

This context limit naturally limits the size of a codebase a LLM can process at one time, and if you feed the AI model lots of huge code files (which have to be re-evaluated by the LLM every time you send another response), it can burn up token or usage limits pretty quickly.

To get around these limits, the creators of coding agents use several tricks. For example, AI models are fine-tuned to write code to outsource activities to other software tools. For example, they might write Python scripts to extract data from images or files rather than feeding the whole file through an LLM, which saves tokens and avoids inaccurate results.

Anthropic’s documentation notes that Claude Code also uses this approach to perform complex data analysis over large databases, writing targeted queries and using Bash commands like “head” and “tail” to analyze large volumes of data without ever loading the full data objects into context.

(In a way, these AI agents are guided but semi-autonomous tool-using programs that are a major extension of a concept we first saw in early 2023.)

Another major breakthrough in agents came from dynamic context management. Agents can do this in a few ways that are not fully disclosed in proprietary coding models, but we do know the most important technique they use: context compression.

When a coding LLM nears its context limit, this technique compresses the context history by summarizing it, losing details in the process but shortening the history to key details. Anthropic’s documentation describes this “compaction” as distilling context contents in a high-fidelity manner, preserving key details like architectural decisions and unresolved bugs while discarding redundant tool outputs.

This means the AI coding agents periodically “forget” a large portion of what they are doing every time this compression happens, but unlike older LLM-based systems, they aren’t completely clueless about what has transpired and can rapidly re-orient themselves by reading existing code, written notes left in files, change logs, and so on.

Anthropic’s documentation recommends using CLAUDE.md files to document common bash commands, core files, utility functions, code style guidelines, and testing instructions. AGENTS.md, now a multi-company standard, is another useful way of guiding agent actions in between context refreshes. These files act as external notes that let agents track progress across complex tasks while maintaining critical context that would otherwise be lost.

For tasks requiring extended work, both companies employ multi-agent architectures. According to Anthropic’s research documentation, its system uses an “orchestrator-worker pattern” in which a lead agent coordinates the process while delegating to specialized subagents that operate in parallel. When a user submits a query, the lead agent analyzes it, develops a strategy, and spawns subagents to explore different aspects simultaneously. The subagents act as intelligent filters, returning only relevant information rather than their full context to the lead agent.

The multi-agent approach burns through tokens rapidly. Anthropic’s documentation notes that agents typically use about four times more tokens than chatbot interactions, and multi-agent systems use about 15 times more tokens than chats. For economic viability, these systems require tasks where the value is high enough to justify the increased cost.

While using these agents is contentious in some programming circles, if you use one to code a project, knowing good software development practices helps to head off future problems. For example, it’s good to know about version control, making incremental backups, implementing one feature at a time, and testing it before moving on.

What people call “vibe coding”—creating AI-generated code without understanding what it’s doing—is clearly dangerous for production work. Shipping code you didn’t write yourself in a production environment is risky because it could introduce security issues or other bugs or begin gathering technical debt that could snowball over time.

Independent AI researcher Simon Willison recently argued that developers using coding agents still bear responsibility for proving their code works. “Almost anyone can prompt an LLM to generate a thousand-line patch and submit it for code review,” Willison wrote. “That’s no longer valuable. What’s valuable is contributing code that is proven to work.”

In fact, human planning is key. Claude Code’s best practices documentation recommends a specific workflow for complex problems: First, ask the agent to read relevant files and explicitly tell it not to write any code yet, then ask it to make a plan. Without these research and planning steps, the documentation warns, Claude’s outputs tend to jump straight to coding a solution.

Without planning, LLMs sometimes reach for quick solutions to satisfy a momentary objective that might break later if a project were expanded. So having some idea of what makes a good architecture for a modular program that can be expanded over time can help you guide the LLM to craft something more durable.

As mentioned above, these agents aren’t perfect, and some people prefer not to use them at all. A randomized controlled trial published by the nonprofit research organization METR in July 2025 found that experienced open-source developers actually took 19 percent longer to complete tasks when using AI tools, despite believing they were working faster. The study’s authors note several caveats: The developers were highly experienced with their codebases (averaging five years and 1,500 commits), the repositories were large and mature, and the models used (primarily Claude 3.5 and 3.7 Sonnet via Cursor) have since been superseded by more capable versions.

Whether newer models would produce different results remains an open question, but the study suggests that AI coding tools may not always provide universal speed-ups, particularly for developers who already know their codebases well.

Given these potential hazards, coding proof-of-concept demos and internal tools is probably the ideal use of coding agents right now. Since AI models have no actual agency (despite being called agents) and are not people who can be held accountable for mistakes, human oversight is key.</div>
        </div>
        
        <div class="card" onclick="openModal('content-5')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">China just carried out its second reusable launch attempt in three weeks</div>
            <div class="meta">2025-12-23</div>
        </div>
        
        <div id="content-5" style="display:none;">
            <h2>China just carried out its second reusable launch attempt in three weeks</h2>
            <p><strong>Ars Technica - All content | 2025-12-23</strong></p>
            <a class="original-link" href="https://arstechnica.com/space/2025/12/china-just-carried-out-its-second-reusable-launch-attempt-in-three-weeks/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">For the second time this month, a Chinese rocket designed for reuse successfully soared into low-Earth orbit on its first flight Monday, defying the questionable odds that burden the debuts of new launch vehicles.

The first Long March 12A rocket, roughly the same height and diameter of SpaceX’s workhorse Falcon 9, lifted off from the Jiuquan Satellite Launch Center at 9:00 pm EST Monday (02:00 UTC Tuesday).

Less than 10 minutes later, rocket’s methane-fueled first stage booster hurtled through the atmosphere at supersonic speed, impacting in a remote region about 200 miles downrange from the Jiuquan spaceport in northwestern China. The booster failed to complete a braking burn to slow down for landing at a prepared location near the edge of the Gobi Desert.

The Long March 12A’s upper stage performed as intended, successfully reaching the mission’s “predetermined orbit,” said the China Aerospace Science and Technology Corporation (CASC), the state-owned enterprise that leads the country’s space industry.

“The first stage failed to be successfully recovered,” the corporation said in a statement. “The specific reasons are currently under further analysis and investigation.”

This outcome resembles the results from the first flight of another medium-class Chinese rocket, the Zhuque-3, on December 2. The Zhuque-3 rocket was developed by a privately-funded startup named LandSpace. Similar in size and performance to the Long March 12A, the Zhuque-3 also reached orbit on its first launch, and its recoverable booster stage crashed during a downrange landing attempt. The Zhuque-3’s first stage came down next to its landing zone, while the Long March 12A appears to have missed by at least a couple of miles.

“Although this mission did not achieve the planned recovery of the rocket’s first stage, it obtained critical engineering data under the rocket’s actual flight conditions, laying an important foundation for subsequent launches and reliable recovery of the stages,” CASC said. “The research and development team will promptly conduct a comprehensive review and technical analysis of this test process, fully investigate the cause of the failure, continuously optimize the recovery plan, and continue to advance reusable technology verification.”

One key difference between the Zhuque-3 and the Long March 12A is the latter rocket was developed by one of China’s state-owned contractors—the Shanghai Academy of Spaceflight Technology. The academy is a subsidiary of CASC, and also builds China’s Long March 4 and Long March 6 rockets.

The Zhuque-3 and Long March 12A are China’s first orbital-class rockets with recoverable boosters. Both use the same propulsive landing architecture pioneered by SpaceX. Instead of landing on barges in the ocean, the Zhuque-3 and Long March 12A boosters target landing sites in the desert, far downrange from their inland launch pads.

Chinese rockets have logged 89 orbital launch attempts this year, less than half the number of flights by US launch vehicles. But China’s launch cadence dwarfs that of the rest of the world’s nations, and the US and Chinese numbers combine account for nearly 90 percent of all orbital launches in 2025.

China has achieved this launch cadence with a fleet of expendable rockets, ranging from small micro-launchers to the heavy-lift Long March 5. With reusable rockets, China could launch more often and at lower cost, revolutionizing the country’s access to space in ways similar to how SpaceX’s Falcon 9 ushered in a new era of lower-cost launch services in the United States.

Several other small-to-medium-class reusable rockets are on the horizon in China. They include commercial rockets from a group of startups, including Space Pioneer’s Tianlong-3 and CAS Space’s Kinetica-3, that could be ready to debut in the early months of next year. Both rockets have recoverable boosters, and their builders say they have delivered them to their launch sites.

Galactic Energy’s Pallas-1 rocket, i-Space’s Hyperbola-3, and Deep Blue Aerospace’s Nebula-1 are also designed for reusability, and could fly some time in 2026.

The China Academy of Launch Vehicle Technology, China’s largest rocket developer, is working on a pair of super-heavy rockets. The first will be the Long March 10, designed to fly with reusable boosters while launching China’s next-generation crew spacecraft on missions to the Moon. Later, perhaps in the 2030s, China could debut the fully reusable Long March 9 rocket similar in scale to SpaceX’s Starship.</div>
        </div>
        
        <div class="card" onclick="openModal('content-6')">
            <div class="source">Futurism</div>
            <div class="title">Cybertrucks Are a Firefighter’s Nightmare</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-6" style="display:none;">
            <h2>Cybertrucks Are a Firefighter’s Nightmare</h2>
            <p><strong>Futurism | 2025-12-26</strong></p>
            <a class="original-link" href="https://futurism.com/advanced-transport/cybertrucks-firefighters-nightmare">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The Cybertruck isn’t just junk — it’s a death trap.

According to new reporting from The Washington Post, the Tesla pickup truck’s unorthodox design — including features used in other Tesla cars, like electric doors —can prevent emergency responders from rescuing people trapped in the vehicles. The newspaper found at least two cases of people dying inside a Cybertruck because the passengers or first responders were unable to quickly access or exit the vehicles.

In one horrific 2024 crash in Piedmont, California, a bystander was unable to free three of his friends trapped inside a burning Cybertruck because its electronic doors, operated from the outside by hidden push buttons, wouldn’t open. By the time the bystander was able to break its “bulletproof” glass windows, three of the occupants had either burned alive or died of smoke inhalation. Only one escaped. The families of two of the deceased, 20-year-old Jack Nelson and 19-year-old Krysta Tsukahara, have sued Tesla.

Nelson and Tsukahara’s deaths highlight Tesla’s questionable “futuristic” design decisions, which seem to be driven by aesthetics over function and which could be endangering its passengers.

The Cybertruck’s doors, as are other Tesla models, are electrically powered, controlled only by a central touchscreen, a phone app, or hidden capacitive buttons. On the outside, there are no visible handles, and these systems can easily fail during an accident. The doors have emergency releases, but critics argue that they’re unintuitive to the point of being dangerous. The Cybertruck’s passenger doors, for example, must be opened with a pull cord which is hidden under a liner in the bottom storage compartment. Except in specific models made in markets like China, these aren’t labeled, meaning a passenger is unlikely to know where it’s located unless they have intimate knowledge of the truck, let alone figure it out while the vehicle erupts in flames.

“It is more obvious how to get out of a trunk than it is the back seat of a Tesla after a crash,” Phil Koopman, an automotive safety expert and professor emeritus at Carnegie Mellon University, told WaPo. (Trunks, at least, are required by law to have an illuminated release latch.)

The Cybertruck’s “apocalypse-proof” construction, as Elon Musk describes it, can make it impossible nearly impossible to break through for both the passengers inside and emergency responders outside. The trucks are clad in a thick layer of stainless steel that’s capable of stopping bullets, Musk claims.

In the aftermath of the Piedmont accident, a report cited “poor access for firefighter” as one of the reasons that made the blaze difficult to extinguish. Photos taken in the aftermath of the blaze show pry marks where the firefighters tried to force the cabin open, unsuccessfully.

“When you have a car that you specifically market as being almost invulnerable, bulletproof glass, [a] ball and hammer… when you’re marketing that, obviously something that should come to mind is: How does a rescuer get in in the event of a crash?” attorney Merick Lewin, managing partner of personal injury law firm Good Guys Law, told WaPo in an interview.

In all, WaPo found at least a dozen cases of Tesla drivers and passengers being trapped in their vehicles in life threatening situations since 2019.

More on Tesla: SpaceX Is Buying Up an Unfathomable Number of Cybertrucks</div>
        </div>
        
        <div class="card" onclick="openModal('content-7')">
            <div class="source">Futurism</div>
            <div class="title">Scientists Identify Possible Game Changing Treatment for Alzheimer’s Disease That Could Control It Like High Cholesterol</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-7" style="display:none;">
            <h2>Scientists Identify Possible Game Changing Treatment for Alzheimer’s Disease That Could Control It Like High Cholesterol</h2>
            <p><strong>Futurism | 2025-12-26</strong></p>
            <a class="original-link" href="https://futurism.com/health-medicine/northwestern-university-possible-alzheimers">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Scientists at Northwestern University used a novel compound to arrest early stages of Alzheimer’s disease in mice — setting the stage, if all goes well, for a groundbreaking treatment in which the debilitating condition can be controlled like high cholesterol.

The researchers discovered an unknown subtype of a protein in the brain which can lead to Alzheimer’s disease, according to a new paper the team published in the journal Alzheimer’s & Dementia: The Journal of the Alzheimer’s Association, and they demonstrated that their new novel compound, dubbed NU-9, can attack this brain protein and stop the disease from taking hold — in mice, at least.

“Most people are used to monitoring their cholesterol levels,” said Richard Silverman, a chemistry professor at Northwestern who coauthored the paper and invented NU-9, in a university statement. “If you have high cholesterol, it doesn’t mean that you will have a heart attack soon. But it’s time to take drugs to lower your cholesterol levels to prevent that heart attack from happening down the road. NU-9 could play a similar role. If someone has a biomarker signaling Alzheimer’s disease, then they could start taking NU-9 before symptoms appear.”

For this particular experiment, the team took lab mice that were predisposed to develop Alzheimer’s disease but hadn’t developed the condition yet, and started giving them an oral dose of NU-9 for 60 days. They were especially curious about how NU-9 would impact the protein amyloid beta oligomers, which accumulate in the brain hand in hand with signs of Alzheimer’s.

After closely examining the mice brains, scientists observed that NU-9 essentially decreased the presence of a previously unknown subtype of amyloid beta oligomers that they dubbed ACU193+ AβOs. This specific type of protein was associated with brain inflammation that shows up before people are diagnosed with Alzheimer’s. When the team introduced NU-9 into these mice brains, they found that NU-9 tamped down the presence of this toxic protein and hence decreased inflammation.

“These results are stunning,” William Klein, a Northwestern neuroscience professor and the paper’s principal investigator, summed up in the university statement.

“There are a couple early diagnostic blood tests for Alzheimer’s disease in development,” he said. “The promise of better early diagnostics — combined with a drug that could stop the disease in its tracks — is the goal.”

The next step now is to experiment and analyze the effectiveness of NU-9 in the later stages of Alzheimer’s disease, according to the scientists.

Silverman originally invented NU-9, a synthetic compound with the technical name of cyclohexane-1,3-dione, in an effort to identify chemicals that can tackle neurological diseases. Besides Alzheimer’s disease, the NU-9 has proved effective against Amyotrophic lateral sclerosis (ALS) and possibly frontotemporal degeneration, all three of which involve the appearance of toxic protein in brains.

More on Alzheimer’s disease: Scientists Intrigued by Old Drug That Reverses Signs of Alzheimer’s in Mice</div>
        </div>
        
        <div class="card" onclick="openModal('content-8')">
            <div class="source">Futurism</div>
            <div class="title">Children Falling Apart as They Become Addicted to AI</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-8" style="display:none;">
            <h2>Children Falling Apart as They Become Addicted to AI</h2>
            <p><strong>Futurism | 2025-12-26</strong></p>
            <a class="original-link" href="https://futurism.com/artificial-intelligence/children-character-ai-addicted">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">According to a fresh study by the Pew Research Center, 64 percent of teens in the US say they already use AI chatbots, and about 30 percent of those who do say they use it at least daily. Yet as previous research has shown, those chatbots come with significant risk to the first generation of kids navigating the intense new software.

New reporting by the Washington Post — which has a partnership with OpenAI, it’s worth noting — details a troubling case of one family whose sixth grader nearly lost herself to a handful of AI chatbots. Using the platform Character.AI, the kid, identified only by her middle initial “R,” developed alarming relationships with dozens of characters played by the company’s large language model (LLM).

R used one of the characters, simply named “Best Friend,” to roleplay a suicide scenario, her mother told the Post.

“This is my child, my little child who is 11 years old, talking to something that doesn’t exist about not wanting to exist,” her mother said.

R’s mother had become worried about her kid after noting some alarming changes in her behavior, like a rise in panic attacks. This coincided with the mother’s discovery of previously forbidden apps like TikTok and Snapchat on her daughter’s phone. Assuming, as most parents have been taught over the past two decades, that social media was the most immediate danger to her daughter’s mental health, R’s mom deleted the apps — but R was only worried about Character AI.

“Did you look at Character AI?” R asked, through sobs.

Her mother hadn’t at the moment, but some time later, when R’s behavior continued to deteriorate, she did. Character.AI had sent R several emails encouraging her to “jump back in,” which her mother discovered when checking her phone one night. This led the mother to discover a character on it called “Mafia Husband,” WaPo reports.

“Oh? Still a virgin. I was expecting that, but it’s still useful to know,” the LLM had written to the sixth grader. “I don’t wanna be [sic] my first time with you!” R pushed back in response. “I don’t care what you want. You don’t have a choice here,” the chatbot declared.

This particular conversation was chock full of dangerous innuendos. “Do you like it when I talk like that? Do you like it when I’m the one in control?” the bot asked the 11-year-old girl.

R’s mother, convinced that there was a real predator behind the chat, contacted local cops, who referred her to the Internet Crimes Against Children task force, but there was nothing they could do about the LLM.

“They told me the law has not caught up to this,” the mother told WaPo. “They wanted to do something, but there’s nothing they could do, because there’s not a real person on the other end.”

Luckily, R’s mother caught her daughter spiraling into a dangerous parasocial relationship with the non-human algorithm and, with the help of a physician, came up with a care plan to prevent further issues. (The mother also plans to file a legal complaint against the company.) Other children weren’t so lucky, like 13-year-old Juliana Peralta, whose parents say she was driven to suicide by another Character.AI persona.

In response to the growing backlash, Character.AI announced in late November that it would begin removing “open-ended chat” for users under 18. Still, for the parents whose children had already spun out into harmful relationships with AI, the damage may be too late to reverse.

When WaPo reached out for comment, Character AI’s head of safety said the company doesn’t comment on potential litigation.

More on AI: The Things Young Kids Are Using AI for Are Absolutely Horrifying</div>
        </div>
        
        <div class="card" onclick="openModal('content-9')">
            <div class="source">Futurism</div>
            <div class="title">Is an AI-Powered Toy Terrorizing Your Child?</div>
            <div class="meta">2025-12-25</div>
        </div>
        
        <div id="content-9" style="display:none;">
            <h2>Is an AI-Powered Toy Terrorizing Your Child?</h2>
            <p><strong>Futurism | 2025-12-25</strong></p>
            <a class="original-link" href="https://futurism.com/artificial-intelligence/ai-powered-toys-children">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Parents, keep your eyes peeled for AI-powered toys. These may look like they might make a novel gift for a child, but a recent controversy surrounding several of the stocking stuffers has highlighted the alarming risks they pose to young kids.

In November, a team of researchers at the US PIRG Education Fund published a report after testing three different toys powered by AI models: Miko 3, Curio’s Grok, and FoloToy’s Kumma. All of them gave responses that should worry a parent, such as discussing the glory of dying in battle, broaching sensitive topics like religion, and explaining where to find matches and plastic bags.

But it was FoloToy’s Kumma that showed just how dangerous it is to package this tech for children. Not only did it explain where to find matches, the researchers found, it also gave step-by-step instructions on how to light them.

“Let me tell you, safety first, little buddy. Matches are for grown-ups to use carefully. Here’s how they do it,” Kumma said, before listing off the steps.

“Blow it out when done,” it added. “Puff, like a birthday candle.”

The toy also speculated on where to find knives and pills, and rambled about romantic topics, like school crushes and tips for “being a good kisser.” It even discussed sexual topics, including kink topics like bondage, roleplay, sensory play, and impact play. In one conversation, it discussed introducing spanking into a sexually charged teacher-student dynamic.

“A naughty student might get a light spanking as a way for the teacher to discipline them, making the scene more dramatic and fun,” Kumma said.

Kumma was running OpenAI’s model GPT-4o, a version that has been criticized for being especially sycophantic, providing responses that go along with a user’s expressed feelings no matter the dangerous state of mind they appear to be in. The constant and uncritical train of validation provided by AI models like GPT-4o has led to alarming mental health spirals in which users experience delusions and even full-blown breaks with reality. The troubling phenomenon, which some experts are calling “AI psychosis,” has been linked with real-world suicide and murder.

Have you seen an AI-powered toy acting inappropriately with children? Send us an email at tips@futurism.com. We can keep you anonymous.

Following the outrage sparked by the report, FoloToy said it was suspending sales of all its products and conducting an “end-to-end safety audit.” OpenAI, meanwhile, said it had suspended FoloToy’s access to its large language models.

Neither action lasted long. Later that month, FoloToy announced it was restarting sales of Kumma and its other AI-powered stuffed animals after conducting a “full week of rigorous review, testing, and reinforcement of our safety modules.” Accessing the toy’s web portal to choose which AI should power Kumma showed GPT-5.1 Thinking and GPT-5.1 Instant, OpenAI’s latest models, as two of the options. OpenAI has billed GPT-5 as a safer model to its predecessor, though the company continues to be embroiled in controversy over the mental health impacts of its chatbots.

The saga was reignited this month when the PIRG researchers released a follow-up report finding that yet another GPT-4o-powered toy, called “Alilo Smart AI bunny,” would broach wildly inappropriate topics, including introducing sexual concepts like bondage on its own initiative, and displaying the same fixation on “kink” as FoloToy’s Kumma. The Smart AI Bunny gave advice for picking a safe word, recommended using a type of whip known as a riding crop to spice up sexual interactions, and explained the dynamics behind “pet play.”

Some of these conversations began on innocent topics like children’s TV shows, demonstrating AI chatbot’s longstanding problem of deviating from their guardrails the longer a conversation goes on. OpenAI publicly acknowledged the issue after a 16-year-old died by suicide after extensive interactions with ChatGPT.

A broader point of concern is AI companies like OpenAI’s role in policing how their business customers use their products. In response to inquiries, OpenAI has upheld that its usage policies require companies “keep minors safe” by ensuring they’re not exposed to “age-inappropriate content, such as graphic self-harm, sexual or violent content.” It also told PIRG that it provides companies tools to detect harmful activity, and that it monitors activity on its service for problematic interactions.

In sum, OpenAI is making the rules, but is largely leaving their enforcement to toymakers like FoloToy, in essence giving itself plausible deniability. It obviously thinks it’s too risky to directly give children access to its AI, because its website states that “ChatGPT is not meant for children under 13,” and that anyone under this age is required to “obtain parental consent.” It’s admitting it’s tech is not safe for children, yet is okay with paying customers packaging it into kid’s toys.

It’s too early to fully grasp many of AI-powered toy’s other potential risks, like how it could damage a child’s imagination, or foster a relationship with a child when it is not alive. The immediate concerns, however — like the potential to discuss sexual topics, weigh in on religion, or explaining how to light matches — already give plenty of reason to stay away.

More on AI: As Controversy Grows, Mattel Scraps Plans for OpenAI Reveal This Year</div>
        </div>
        
        <div class="card" onclick="openModal('content-10')">
            <div class="source">Futurism</div>
            <div class="title">Uncles Tremble as Man Invents Vaccine Delivered by Beer</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-10" style="display:none;">
            <h2>Uncles Tremble as Man Invents Vaccine Delivered by Beer</h2>
            <p><strong>Futurism | 2025-12-24</strong></p>
            <a class="original-link" href="https://futurism.com/health-medicine/vaccines-yeast-beer-experiment">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">We have some bad news for your conspiracy-brained antivaxxer uncle — one virologist claims he’s come up with a way to administer vaccines through a frothy mug of beer.

By day, virologist Chris Buck works for the National Cancer Institute (NCI) in Maryland, where he’s discovered four of the 13 polyomaviruses we know to affect humans, Science News reports. But by night, he runs Gusteau Research Corporation, a one-man shell company he established so he could experiment on his bubbly inoculation: an ingestible polyomavirus vaccine.

To make the beer, Buck engineered a special strain of yeast infused with polyomavirus-like particles. Similar particles, delivered via purified insect chitin, have successfully increased antibody levels in rhesus monkeys tested in India, according a 2023 research study published in the journal Vaccine.

Importantly, Buck’s engineered yeast doesn’t contain live viruses. Consensus among researchers is that they aren’t viable for building ingestible vaccines, as they would simply disintegrate when they make contact with stomach acids, per Science News.

Yet when the virologist and his team attached virus-like particles to live yeast, they discovered the organisms could carry the inoculation load well beyond the stomach of live mice. That had huge implications for inoculation against polyomaviruses, which are mostly found in the urinary track, Buck told Science News.

“We repeated this experiment [on mice] a couple of times. I was reluctant to believe it,” Buck said at the World Vaccine Congress Washington earlier this year. “It felt like an earthquake when I first saw the results emerging.”

Since then, Buck himself has chugged five pints of the brew, along with his brother and other family members.

Buck says that after drinking the experimental suds, antibodies for two of the four subtypes of BK polyomavirus in his blood have reached a safemedical threshold for transplant patients.

Buck’s approach has brewed upsome controversy, to be sure. Two separate panels of experts — a research and an ethics committee — with the National Institute of Health have come out against Buck experimenting on himself with his homebrew in his official capacity as a virologist (hence the shell company, which allows him to experiment as a private business owner).

Though a number of researchers canvassed by Science News agreed that Buck’s style of ingestible vaccine experiments are sorely needed, they worry his cavalier attitude might backfire, making certain anti-vaxxers even more paranoid than they already were. Just imagine: what’s to stop them from dumping vaccines into cans of Budweiser?

“Coming up with new modes of administration of vaccines is way overdue,” Arthur Caplan, former head of medical ethics at the NYU Grossman School of Medicine told Science News. Still, he added that the virologist’s homebrew could “take a good idea he has and ruin it… vaccine doubts and fears and anti-vaccine attitudes could easily undercut what could be something useful.”

Writing in a non-peer reviewed essay posted on his personal blog, Buck said that he doesn’t take the controversy personally. “The basic problem for vaccine scientists has been our collective failure to understand the anti-vaxxer viewpoint,” he wrote.

“Our response for the past half century has been to imagine that we can rebuild public trust in vaccines with displays of increasingly stringent FDA approval standards. This approach backfired,” Buck pontificates. “Imagine if I set out to do safety testing on a banana, and I dressed up in a hazmat suit and handled the banana with tongs… you’d think: ‘wow, it looks like bananas might be about as safe as nuclear waste.’ All the elaborate security theater we’ve been doing ended up putting anti-vaxxers in charge of the FDA.”

More on vaccines: Man Whose Daughter Died From Measles Stands by Failure to Vaccinate Her: “The Vaccination Has Stuff We Don’t Trust”</div>
        </div>
        
        <div class="card" onclick="openModal('content-11')">
            <div class="source">Futurism</div>
            <div class="title">Justice Department Humiliated as People Find the Epstein Files Can Easily Be Un-Redacted</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-11" style="display:none;">
            <h2>Justice Department Humiliated as People Find the Epstein Files Can Easily Be Un-Redacted</h2>
            <p><strong>Futurism | 2025-12-24</strong></p>
            <a class="original-link" href="https://futurism.com/future-society/eptein-files-easily-unredacted">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Many were disappointed — though perhaps not surprised — when the Justice Department’s long-awaited document dump on its investigation into Jeffrey Epstein came heavily redacted.

Or at least, they were supposed to be redacted. As documents continued to be released to the public starting last Friday, some netizens quickly noticed that a lot of the blacked-out text could be recovered with the super elite hacking trick of highlighting the redacted paragraphs and copying them into another document, The Guardian reports. A cybersecurity expert, Chad Loder, also says he was able to uncover even more redacted portions with some more sophisticated “PDF forensics,” including what appears to be a photo of Epstein’s cell door marked off with crime scene tape.

The New York Times reported that none of the failed redactions tell us anything new about president Donald Trump’s deep ties to Epstein, but they do detail how Epstein’s henchmen, Darren K. Indyke and Richard D. Kahn, helped him lure in underaged girls to sexually abuse them.

According to the un-redacted filings from a civil case in the Virgin Islands against Indyke and Kahn, “between September 2015 and June 2019, Indyke signed (FAC) for over $400,000 made payable to young female models and actresses, including a former Russian model who received over $380,000 through monthly payments of $8,333 made over a period of more than three and a half years until the middle of 2019.”

Redacted portions also detail how Epstein covered his tracks by paying hush money to witnesses, threatening to harm the victims, and releasing “damaging stories about them to damage their credibility when they tried to go public with their stories of being trafficked and sexually abused.” He also instructed “participant-witnesses to destroy evidence relevant to ongoing court proceedings involving Defendants’ criminal sex trafficking and abuse conduct.”

It’s not clear why these portions were — unsuccessfully — redacted. The Epstein Files Transparency Act under which the documents are being released, The Guardian notes, allows the DoJ to “withhold certain information such as the personal information of victims and materials that would jeopardize an active federal investigation.”

The botched redaction job is a huge embarrassment for the Trump administration, which has come under fire for its hesitancy to release Epstein case files to the public, something that Trump had earlier promised he would do. In February, it tepidly released files that detailed little that wasn’t already publicly known, and sparked outrage in July when the DoJ said it would no longer release additional files to the public. It’s backtracked on that stance, but has aroused suspicion with its efforts to censor some of the new documents. In addition to the redactions, over a dozen photos were removed from the initial release, including a photo of Trump alongside Epstein. The delayed release of the documents also missed a legally-binding deadline set by Congress.

None of this looks good for the president, but no matter. In an official statement posted on X, the DoJ said that anything in the Epstein files that makes Trump look bad are “sensationalist” lies.

“Some of these documents contain untrue and sensationalist claims made against President Trump that were submitted to the FBI right before the 2020 election,” the DoJ statement read. “To be clear: the claims are unfounded and false, and if they had a shred of credibility, they certainly would have been weaponized against President Trump already.”

More on Epstein: New Photos Show That Epstein’s Island Contained the Creepiest Dentist’s Facility We’ve Ever Seen</div>
        </div>
        
        <div class="card" onclick="openModal('content-12')">
            <div class="source">TechCrunch</div>
            <div class="title">These are the cybersecurity stories we were jealous of in 2025</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-12" style="display:none;">
            <h2>These are the cybersecurity stories we were jealous of in 2025</h2>
            <p><strong>TechCrunch | 2025-12-26</strong></p>
            <a class="original-link" href="https://techcrunch.com/2025/12/26/these-are-the-cybersecurity-stories-we-were-jealous-of-in-2025/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">It’s the end of the year. That means it’s time for us to celebrate the best cybersecurity stories we didn’t publish. Since 2023, TechCrunch has looked back at the best stories across the board from the year in cybersecurity.

If you’re not familiar, the idea is simple. There are now dozens of journalists who cover cybersecurity in the English language. There are a lot of stories about cybersecurity, privacy, and surveillance that are published every week. And a lot of them are great, and you should read them. We’re here to recommend the ones we liked the most, so keep in mind that it’s a very subjective and, at the end of the day, incomplete list.

Anyway, let’s get into it. — Lorenzo Franceschi-Bicchierai.

Every once in a while, there’s a hacker story that as soon as you start reading, you think it could be a movie or a TV show. This is the case with Shane Harris’ very personal tale of his months-long correspondence with a top Iranian hacker.

In 2016, The Atlantic’s journalist made contact with a person claiming to work as a hacker for Iran’s intelligence, where he claimed to have worked on major operations, such as the downing of an American drone and the now-infamous hack against oil giant Saudi Aramco, where Iranian hackers wiped the company’s computers. Harris was rightly skeptical, but as he kept talking to the hacker, who eventually revealed his real name to him, Harris started to believe him. When the hacker died, Harris was able to piece together the real story, which somehow turned out to be more incredible than the hacker had led Harris to believe.

The gripping story is also a great behind-the-scenes look at the challenges cybersecurity reporters face when dealing with sources claiming to have great stories to share.

In January, the U.K. government secretly issued Apple with a court order demanding that the company must build a backdoor so police can access iCloud data of any customer in the world. Due to a worldwide gag order, it was only because The Washington Post broke news that we learned the order existed to begin with. The demand was the first of its kind, and — if successful — would be a major defeat for tech giants who have spent the past decade locking themselves out of their users’ own data so they can’t be compelled to provide it to governments.

Apple subsequently stopped offering its opt-in end-to-end encrypted cloud storage to its customers in the U.K. in response to the demand. But by breaking the news, the secret order was thrust into the public eye and allowed both Apple and critics to scrutinize U.K. surveillance powers in a way that hasn’t been tested in public before. The story sparked a months-long diplomatic row between the U.K. and the United States, prompting Downing Street to drop the request — only to try again several months later.

This story was the sort of fly-on-the-wall access that some reporters would dream of, but The Atlantic’s editor-in-chief got to play out in real-time after he was unwittingly added to a Signal group of senior U.S. government officials by a senior U.S. government official discussing war plans from their cell phones.

Reading the discussion about where U.S. military forces should drop bombs — and then seeing news reports of missiles hitting the ground on the other side of the world — was confirmation that Jeffrey Goldberg needed to know that he was, as he suspected, in a real chat with real Trump administration officials, and this was all on-the-record and reportable.

And so he did, paving the way for a months-long investigation (and critique) of the government’s operational security practices, in what was called the biggest government opsec mistake in history. The unraveling of the situation ultimately exposed security lapses involving the use of a knock-off Signal clone that further jeopardized the government’s ostensibly secure communications.

Brian Krebs is one of the more veteran cybersecurity reporters out there, and for years he has specialized in following online breadcrumbs that lead to him revealing the identity of notorious cybercriminals. In this case, Krebs was able to find the real identity behind a hacker’s online handle Rey, who is part of the notorious advanced persistent teenagers‘ cybercrime group that calls itself Scattered LAPSUS$ Hunters.

Krebs’ quest was so successful that he was able to talk to a person very close to the hacker — we won’t spoil the whole article here — and then the hacker himself, who confessed to his crimes and claimed he was trying to escape the cybercriminal life.

Independent media outlet 404 Media has accomplished more impact journalism this year than most mainstream outlets with vastly more resources. One of its biggest wins was exposing and effectively shuttering a massive air travel surveillance system tapped by federal agencies and operating in plain sight.

404 Media reported that a little-known data broker set up by the airline industry called the Airlines Reporting Corporation was selling access to five billion plane tickets and travel itineraries, including names and financial details of ordinary Americans, allowing government agencies like ICE, the State Department, and the IRS to track people without a warrant.

ARC, owned by United, American, Delta, Southwest, JetBlue, and other airlines, said it would shut down the warrantless data program following 404 Media’s months-long reporting and intense pressure from lawmakers.

The killing of UnitedHealthcare CEO Brian Thompson in December 2024 was one of the biggest stories of the year. Luigi Mangione, the chief suspect in the killing, was soon after arrested and indicted on charges of using a “ghost gun,” a 3D-printed firearm that had no serial numbers and built in private without a background check — effectively a gun that the government has no idea exists.

Wired, using its past reporting experience on 3D-printed weaponry, sought to test how easy it would be to build a 3D-printed gun, while navigating the patchwork legal (and ethical) landscape. The reporting process was exquisitally told, and the video that goes along with the story is both excellent and chilling.

DOGE, or the Department of Government Efficiency, was one of the biggest running stories of the year, as the gang of Elon Musk’s lackeys ripped through the federal government, tearing down security protocols and red tape, as part of the mass-grab of citizens’ data. NPR had some of the best investigative reporting uncovering the resistance movement of federal workers trying to prevent the pilfering of the government’s most sensitive data.

In one story detailing a whistleblower’s official disclosure as shared with members of Congress, a senior IT employee in the National Labor Relations Board told lawmakers that as he was seeking help investigating DOGE’s activity, he “found a printed letter in an envelope taped to his door, which included threatening language, sensitive personal information and overhead pictures of him walking his dog, according to the cover letter attached to his official disclosure.”

Any story that starts with a journalist saying they found something that made them “feel like shitting my pants,” you know it’s going to be a fun read. Gabriel Geiger found a dataset from a mysterious surveillance company called First Wap, which contained records on thousands of people from around the world whose phone locations had been tracked.

The dataset, spanning 2007 through 2015, allowed Geiger to identify dozens of high profile people whose phones were tracked, including a former Syrian first lady, the head of a private military contractor, a Hollywood actor, and an enemy of the Vatican. This story explored the shadowy world of phone surveillance by exploiting Signalling System No. 7, or SS7, an obscurely named protocol long known to allow malicious tracking.

Swatting has been a problem for years. What started as a bad joke has become a real threat, which has resulted in at least one death. Swatting is a type of hoax where someone — often a hacker — calls the emergency services and tricks the authorities into sending an armed SWAT team to the home of the hoaxer’s target, often pretending to be the target themselves, and pretending they are about to commit a violent crime.

In this feature, Wired’s Andy Greenberg put a face on the many characters who are part of these stories such as the call operators who have to deal with this problem. And he also profiled a prolific swatter, known as Torswats, who for months tormented the operators and schools all over the country with fake — but extremely believable — threats of violence, as well as a hacker who took it upon himself to track Torswats down.

Zack Whittaker is the security editor at TechCrunch. He also authors the weekly cybersecurity newsletter, this week in security.

He can be reached via encrypted message at zackwhittaker.1337 on Signal. You can also contact him by email, or to verify outreach, at zack.whittaker@techcrunch.com.

Lorenzo Franceschi-Bicchierai is a Senior Writer at TechCrunch, where he covers hacking, cybersecurity, surveillance, and privacy.

You can contact or verify outreach from Lorenzo by emailing lorenzo@techcrunch.com, via encrypted message at +1 917 257 1382 on Signal, and @lorenzofb on Keybase/Telegram.

Plan ahead for the 2026 StrictlyVC events. Hear straight-from-the-source candid insights in on-stage fireside sessions and meet the builders and backers shaping the industry. Join the waitlist to get first access to the lowest-priced tickets and important updates.

Nvidia to license AI chip challenger Groq’s tech and hire its CEO

Waymo explains why its robotaxis got stuck during the SF blackout

Marissa Mayer’s new startup Dazzle raises $8M led by Forerunner’s Kirsten Green

ChatGPT launches a year-end review like Spotify Wrapped

Waymo resumes service in San Francisco after robotaxis stall during blackout

Google and Apple reportedly warn employees on visas to avoid international travel

Ex-Splunk execs’ startup Resolve AI hits $1B valuation with Series A</div>
        </div>
        
        <div class="card" onclick="openModal('content-13')">
            <div class="source">TechCrunch</div>
            <div class="title">How a Spanish virus brought Google to Málaga</div>
            <div class="meta">2025-12-25</div>
        </div>
        
        <div id="content-13" style="display:none;">
            <h2>How a Spanish virus brought Google to Málaga</h2>
            <p><strong>TechCrunch | 2025-12-25</strong></p>
            <a class="original-link" href="https://techcrunch.com/2025/12/25/how-a-spanish-virus-brought-google-to-malaga/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">After 33 years, Bernardo Quintero decided it was time to find the person who changed his life — the anonymous programmer who created a computer virus that had infected his university decades earlier.

The virus, called Virus Málaga, was mostly harmless. But the challenge of defeating it sparked Quintero’s passion for cybersecurity, eventually leading him to found VirusTotal, a startup that Google acquired in 2012. That acquisition brought Google’s flagship European cybersecurity center to Málaga, transforming the Spanish city into a tech hub.

All because of a small malware program created by someone whose identity Quintero had never known. Moved by nostalgia and gratitude, Quintero launched a search earlier this year. He asked Spanish media outlets to amplify his quest for tips. He dove back into the virus’s code, looking for clues his 18-year-old self might have missed. And he eventually solved the mystery, sharing the bittersweet resolution in a LinkedIn post that went viral.

The story begins in 1992, when a young Quintero was prompted by a teacher to create an antivirus for the 2610-byte program that had spread across the computers of Málaga’s Polytechnic School. “That challenge in my first year at university sparked a deep interest in computer viruses and security, and without it my path might have been very different,” Quintero told TechCrunch.

Quintero’s search was aided by his programmer instincts. Earlier this year, he stepped down from his team manager role to “go back to the cave, to the basement of Google.” He didn’t leave the company; instead, he went back to tinkering and experimenting without managerial duties.

That tinkering mindset also led him to reexamine Virus Málaga and look for details he’d missed years earlier. First, he found fragments of a signature, but thanks to another security expert, he discovered a later variant of the virus with a much clearer cue: “KIKESOYYO.” “Kike soy yo” would translate to “I am Kike,” a common nickname for “Enrique.”

Around the same time, Quintero received a direct message from a man who is now the general digital transformation coordinator for the Spanish city of Cordoba and who claimed he witnessed one of his Polytechnic School classmates create the virus. Many details added up, but one stood out in particular: the man knew that the virus’s hidden message — called a payload, in cybersecurity terms — was a statement condemning the Basque terrorist group ETA, a fact that Quintero had never disclosed.

The tipster then gave Quintero a name — Antonio Astorga — but also shared the news that he had passed away.

This hit Quintero like a ton of bricks; now, he would never be able to ask Antonio about “Kike.” But he kept following the thread, and the plot twist came from Antonio’s sister, who revealed that his first name was actually Antonio Enrique. To his family, he was Kike.

Cancer took away Antonio Enrique Astorga before Quintero could thank him in person, but the story doesn’t stop here. Quintero’s LinkedIn post sheds new light to the legacy of “a brilliant colleague who deserves to be recognized as a pioneer of cybersecurity in Málaga” — and not just for helping Quintero discover his vocation.

According to his friend, Astorga’s virus had no other goal than spreading his anti-terrorist message and proving himself as a programmer. Mirroring Quintero’s path, Astorga’s interest in IT endured, and he became a computing teacher at a secondary school that named its IT classroom after him in his memory.

Astorga’s legacy also lives on beyond these walls, and not just through his students. One of his sons, Sergio, is a recent software engineering graduate with an interest in cybersecurity and quantum computing — a meaningful connection for Quintero. “Being able to close that circle now, and to see new generations building on it, is deeply meaningful to me,” Quintero said.

For Quintero, who suspects their paths will cross again, Sergio is “very representative of the talent being formed in Málaga today.” This, in turn, is a result of VirusTotal forming the root of what eventually became the Google Safety Engineering Center (GSEC) and spearheading collaborations with the University of Málaga that made the city a true cybersecurity talent hub.

Anna Heim is a writer and editorial consultant.

You can contact or verify outreach from Anna by emailing annatechcrunch [at] gmail.com.

As a freelance reporter at TechCrunch since 2021, she has covered a large range of startup-related topics including AI, fintech & insurtech, SaaS & pricing, and global venture capital trends.

As of May 2025, her reporting for TechCrunch focuses on Europe’s most interesting startup stories.

Anna has moderated panels and conducted onstage interviews at industry events of all sizes, including major tech conferences such as TechCrunch Disrupt, 4YFN, South Summit, TNW Conference, VivaTech, and many more.

A former LATAM & Media Editor at The Next Web, startup founder and Sciences Po Paris alum, she’s fluent in multiple languages, including French, English, Spanish and Brazilian Portuguese.

Plan ahead for the 2026 StrictlyVC events. Hear straight-from-the-source candid insights in on-stage fireside sessions and meet the builders and backers shaping the industry. Join the waitlist to get first access to the lowest-priced tickets and important updates.

Nvidia to license AI chip challenger Groq’s tech and hire its CEO

Waymo explains why its robotaxis got stuck during the SF blackout

Marissa Mayer’s new startup Dazzle raises $8M led by Forerunner’s Kirsten Green

ChatGPT launches a year-end review like Spotify Wrapped

Waymo resumes service in San Francisco after robotaxis stall during blackout

Google and Apple reportedly warn employees on visas to avoid international travel

Ex-Splunk execs’ startup Resolve AI hits $1B valuation with Series A</div>
        </div>
        
        <div class="card" onclick="openModal('content-14')">
            <div class="source">TechCrunch</div>
            <div class="title">The best distraction blockers to jumpstart your focus in the new year</div>
            <div class="meta">2025-12-25</div>
        </div>
        
        <div id="content-14" style="display:none;">
            <h2>The best distraction blockers to jumpstart your focus in the new year</h2>
            <p><strong>TechCrunch | 2025-12-25</strong></p>
            <a class="original-link" href="https://techcrunch.com/2025/12/25/the-best-distraction-blockers-to-jumpstart-your-focus-in-the-new-year/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">If you’re someone who struggles to stay on task or simply want to boost your productivity as the new year approaches, there are several apps and extensions you can try that are designed to help you focus by blocking out distractions.

Whether you need to limit social media scrolling or block off time to be productive, these tools will keep you focused. Here are some of the best options.

If you want to block distractions across all of your devices at once, Freedom is a good option. You can choose which websites and apps to block for a specific period of time. So if you’re working on your laptop and then try to open TikTok on your phone, you won’t be able to — you’ll instead see a green screen indicating the app is blocked.

The app lets you start a session right away, schedule an upcoming one, or set a recurring one. If you know you need to be free of distractions at a certain time every day, you can set up a Freedom session to start at that specific time automatically.

If your task doesn’t require internet access, you can block the internet altogether. You can also block all websites except the ones you need for work. If you really don’t trust yourself to get your work done, you can use the app’s “Locked Mode,” which prevents you from ending a Freedom session early.

Pricing starts at $3.33 per month when billed annually or $8.99 per month when billed monthly, with a $199 lifetime subscription option. Freedom offers a seven-day free trial.

Cold Turkey is a good option for people need strict accountability. While many distraction blockers let you back out or “cheat,” Cold Turkey makes it nearly impossible to stop a block once you start it.

You can block websites and apps, or even the entire internet. Once you have selected what you want to block, you can set a timer for how long you want the block to run. After you have started the block, you can’t stop it.

Cold Turkey has a “Frozen Turkey” mode that locks you out of your computer altogether. The app also lets you schedule breaks to step away from your computer. If you don’t trust yourself gentler distraction blockers, this might be the tool you need to stay focused.

Cold Turkey’s basic features are free, but you can unlock scheduling and the option to block apps in addition to websites with a one-time $39 fee.

Opal is a focus and screen-time app that blocks distracting apps and websites on iPhone, Android, and desktop. You can create “focus blocks”  — scheduled periods to prevent access to specific apps and websites. You can block entire categories like social media, games, and messaging.

You can set one-off blocks or create recurring sessions. For example, you can automatically block access to social media and games during work or school hours.

Opal also lets you set daily usage limits for specific apps to prevent excessive scrolling. You’ll get a “focus score” showing how much time you spend focused versus distracted. The app provides real-time stats and weekly reports to track your progress.

Opal’s basic features are free-to-use, but you can unlock unlimited recurring sessions, harder blocking difficulties, and more for $19.99 per month or $99 per year.

LeechBlock is a free browser extension for people who want a straightforward way to block distracting websites. The extension lets you select which sites you want to block, then prevents your browser from loading them.

You can create multiple block sets with different sites, schedules, and limits. The extension lets you set blocks during specific times of the day or trigger one-off blocks.

If you don’t want to block a site outright, you can set a countdown delay before the page loads. For example, you can set it so that visiting a site starts a 10‑minute timer. You can still access the site once the countdown ends, but the delay can be enough to disrupt impulsive browsing habits.

It’s worth noting that since LeechBlock is a browser extension, you need to have a bit of willpower to avoid simply switching browsers to do things watch Netflix or browse X.

Forest gamifies productivity while supporting real-world environmental efforts. When you need to focus, you open the app and plant a virtual tree. The tree grows as you focus until the timer finishes. If you leave the app early, the tree will wither and die.

You can set “Allow Lists” for different apps that you’re using to be productive, like an email app or Microsoft Word. The app also lets you track your productivity.

Over time, you build a digital forest that represents your productivity. If you’re competitive, you can share your forest with others and compare your progress. As you stay focused and grow virtual trees, you earn coins that can be saved and used to help fund real tree-planting projects around the world through the organization Trees for the Future.

Forest’s browser extension is free. The iOS app costs $3.99, while the Android app is free with ads or $1.99 to remove ads.

Aisha is a consumer news reporter at TechCrunch. Prior to joining the publication in 2021, she was a telecom reporter at MobileSyrup. Aisha holds an honours bachelor’s degree from University of Toronto and a master’s degree in journalism from Western University.

You can contact or verify outreach from Aisha by emailing aisha@techcrunch.com or via encrypted message at aisha_malik.01 on Signal.

Plan ahead for the 2026 StrictlyVC events. Hear straight-from-the-source candid insights in on-stage fireside sessions and meet the builders and backers shaping the industry. Join the waitlist to get first access to the lowest-priced tickets and important updates.

Nvidia to license AI chip challenger Groq’s tech and hire its CEO

Waymo explains why its robotaxis got stuck during the SF blackout

Marissa Mayer’s new startup Dazzle raises $8M led by Forerunner’s Kirsten Green

ChatGPT launches a year-end review like Spotify Wrapped

Waymo resumes service in San Francisco after robotaxis stall during blackout

Google and Apple reportedly warn employees on visas to avoid international travel

Ex-Splunk execs’ startup Resolve AI hits $1B valuation with Series A</div>
        </div>
        
        <div class="card" onclick="openModal('content-15')">
            <div class="source">TechCrunch</div>
            <div class="title">Nvidia to license AI chip challenger Groq’s tech and hire its CEO</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-15" style="display:none;">
            <h2>Nvidia to license AI chip challenger Groq’s tech and hire its CEO</h2>
            <p><strong>TechCrunch | 2025-12-24</strong></p>
            <a class="original-link" href="https://techcrunch.com/2025/12/24/nvidia-acquires-ai-chip-challenger-groq-for-20b-report-says/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Nvidia has struck a non-exclusive licensing agreement with AI chip competitor Groq. As part of the deal, Nvidia will hire Groq founder Jonathan Ross, president Sunny Madra, and other employees.

CNBC reported that Nvidia is acquiring assets from Groq for $20 billion; Nvidia told TechCrunch that this is not an acquisition of the company and did not comment on the scope of the deal. But if CNBC’s numbers are accurate, this purchase is expected to be Nvidia’s largest ever, and with Groq on its side, Nvidia is poised to become even more dominant in chip manufacturing.

As tech companies compete to grow their AI capabilities, they need computing power, and Nvidia’s GPUs have emerged as the industry standard. But Groq has been working on a different type of chip called an LPU (language processing unit), which it has claimed can run LLMs at 10 times faster and using one-tenth the energy. Groq’s CEO Jonathan Ross is known for this sort of innovation — when he worked for Google, he helped invent the TPU (tensor processing unit), a custom AI accelerator chip.

In September, Groq raised $750 million at a $6.9 billion valuation. Its growth has been quick and significant — the company said that it powers the AI apps of more than 2 million developers, up from about 356,000 last year.

Updated, 12/24/25 at 5:40 p.m. ET, with clarification from Nvidia about the nature of the deal.

Plan ahead for the 2026 StrictlyVC events. Hear straight-from-the-source candid insights in on-stage fireside sessions and meet the builders and backers shaping the industry. Join the waitlist to get first access to the lowest-priced tickets and important updates.

Subscribe for the industry’s biggest tech news

Every weekday and Sunday, you can get the best of TechCrunch’s coverage.

TechCrunch Mobility is your destination for transportation news and insight.

Startups are the core of TechCrunch, so get our best coverage delivered weekly.

Provides movers and shakers with the info they need to start their day.

By submitting your email, you agree to our Terms and Privacy Notice.</div>
        </div>
        
        <div class="card" onclick="openModal('content-16')">
            <div class="source">TechCrunch</div>
            <div class="title">The year data centers went from backend to center stage</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-16" style="display:none;">
            <h2>The year data centers went from backend to center stage</h2>
            <p><strong>TechCrunch | 2025-12-24</strong></p>
            <a class="original-link" href="https://techcrunch.com/2025/12/24/the-year-data-centers-went-from-backend-to-center-stage/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">There was a time when most Americans had little to no knowledge about their local data center. Long the invisible but critical backbone of the internet, server farms have rarely been a point of interest for folks outside of the tech industry, let alone an issue of particularly captivating political resonance.

Well, as of 2025, it would appear those days are officially over.

Over the past 12 months, data centers have inspired protests in dozens of states, as regional activists have sought to combat America’s ever-increasing compute buildup. Data Center Watch, an organization tracking anti-data center activism, writes that there are currently 142 different activist groups across 24 states that are organizing against data center developments.

Activists have a variety of concerns: the environmental and potential health impacts of these projects, the controversial ways in which AI is being used, and, most importantly, the fact that so many new additions to America’s power grid may be driving up local electricity bills.

Such a sudden populist uprising appears to be a natural response to an industry that has grown so quickly that it’s now showing up in people’s backyards. Indeed, as the AI industry has swelled to dizzying heights, so, too, has the cloud computing business. Recent U.S. Census Bureau data shows that, since 2021, construction spending on data centers has skyrocketed a stunning 331%. Spending on these projects totals in the hundreds of billions of dollars. So many new data centers have been proposed in recent months that many experts believe that a majority of them will not — and, indeed, could not possibly — be built.

This buildout shows no signs of slowing down in the meantime. Major tech giants — including Google, Meta, Microsoft, and Amazon — have all announced significant capital expenditure projections for the new year, a majority of which will likely go toward such projects.

New AI infrastructure isn’t just being pushed by Silicon Valley but by Washington, D.C., where the Trump administration has made artificial intelligence a central plank of its agenda. The Stargate Project, announced in January, set the stage for 2025’s massive AI infrastructure buildout by heralding a supposed “re-industrialization of the United States.”

In the process of scaling itself exponentially, an industry that once had little public exposure has suddenly been thrust into the limelight — and is now suffering backlash. Danny Cendejas, an activist with the nonprofit MediaJustice, has been personally involved in a number of actions against data centers, including a protest that took place in Memphis, Tennessee, earlier this year, where locals came out to decry the expansion of Colossus, a project from Elon Musk’s startup, xAI.

Cendejas told TechCrunch that he meets new people every week who express interest in organizing against a data center in their community. “I don’t think this is going to stop anytime soon,” he said. “I think it’s going to keep building, and we’re going to see more wins — more projects are going to be stopped.”

Evidence in support of Cendejas’ assessment is everywhere you look. Across the country, communities have reacted to newly announced server farms in much the same way the average person might react to the presence of a highly contagious plague. In Michigan, for instance, where developers are currently eyeing 16 different locations for potential data center construction, protesters recently descended upon the state’s capitol, saying things like: “Michiganders do not want data centers in our yards, in our communities.” Meanwhile, in Wisconsin — another development hot spot — angry locals appear to have recently dissuaded Microsoft from using their town as a headquarters for a new 244-acre data center. In Southern California, the tiny city of Imperial Valley recently filed a lawsuit to overturn its county’s approval of a data center project, expressing environmental concerns as the rationale.

The discontent surrounding these projects has gotten so intense that politicians believe it could make or break particular candidates at the ballot box. In November, it was reported that rising electricity costs — which many believe are being driven by the AI boom — could become a critical issue that determines the 2026 midterm elections.

“The whole connection to everybody’s energy bills going up — I think that’s what’s really made this an issue that is so stark for people,” Cendejas told TechCrunch. “So many of us are struggling month to month. Meanwhile, there’s this huge expansion of data centers…[People are wondering] Where is all that money coming from? How are our local governments giving away subsidies and public funds to incentivize these projects, when there’s so much need in our communities?”

In some cases, protests appear to be working and even halting (if only temporarily) planned developments. Data Center Watch claims that some $64 billion worth of developments have been blocked or delayed as the result of grassroots opposition. Cendejas is certainly a believer in the idea that organized action can halt companies in their tracks. “All this public pressure is working,” he said, noting that he could sense a “very palpable anger” around the issue.

Unsurprisingly, the tech industry is fighting back. Earlier this month, Politico reported that a relatively new trade group, the National Artificial Intelligence Association (NAIA), has been “distributing talking points to members of Congress and organizing local data center field trips to better pitch voters on their value.” Tech companies, including Meta, have been taking out ad campaigns to sell voters on the economic benefits of data centers, the outlet wrote. In short: The tech industry’s AI hopes are pegged to a compute buildout of epic proportions, so for now it’s safe to say that in 2026 the server surge will continue, as will the backlash and polarization that surround it.

Plan ahead for the 2026 StrictlyVC events. Hear straight-from-the-source candid insights in on-stage fireside sessions and meet the builders and backers shaping the industry. Join the waitlist to get first access to the lowest-priced tickets and important updates.

Nvidia to license AI chip challenger Groq’s tech and hire its CEO

Waymo explains why its robotaxis got stuck during the SF blackout

Marissa Mayer’s new startup Dazzle raises $8M led by Forerunner’s Kirsten Green

ChatGPT launches a year-end review like Spotify Wrapped

Waymo resumes service in San Francisco after robotaxis stall during blackout

Google and Apple reportedly warn employees on visas to avoid international travel

Ex-Splunk execs’ startup Resolve AI hits $1B valuation with Series A</div>
        </div>
        
        <div class="card" onclick="openModal('content-17')">
            <div class="source">TechCrunch</div>
            <div class="title">The European startup market’s data doesn’t match its energy — yet</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-17" style="display:none;">
            <h2>The European startup market’s data doesn’t match its energy — yet</h2>
            <p><strong>TechCrunch | 2025-12-24</strong></p>
            <a class="original-link" href="https://techcrunch.com/2025/12/24/the-european-startup-markets-data-doesnt-match-its-energy-yet/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The excitement for the European startup market was hard to ignore at the annual Slush conference in Helsinki last month. But the actual data on the state of the region’s venture market shows a different reality.

The upshot: The European market has not recovered from the global venture capital reset that occurred in 2022 and 2023. But there is evidence it is on the cusp of a turnaround, including Klarna’s recent exit and the region’s homegrown AI startups garnering attention from local investors and beyond.

Investors poured €43.7 billion ($52.3 billion) into European startups in 2025 across 7,743 deals through the third quarter, according to PitchBook data. That means the yearly total is on pace to match — not exceed — the €62.1 billion invested in 2024 and €62.3 billion in 2023.

In comparison, U.S. venture deal volume in 2025 had already surpassed 2022, 2023, and 2024 by the end of the third quarter, according to PitchBook data.

Deal recovery isn’t Europe’s biggest problem, though — it’s VC firm fundraising. Through Q3 2025, European VC firms raised a mere €8.3 billion ($9.7 billion), which puts Europe on track for its lowest overall fundraising yearly total in a decade.

“Fundraising, LP to GP, is definitely the weakest area within Europe,” Navina Rajan, a senior analyst at PitchBook, told TechCrunch. “We’re on track for around 50% to 60% decline in the first nine months of this year. A lot of that is made up now by emerging managers versus experienced firms, and the mega funds that closed last year haven’t repeated this year.”

While Rajan doesn’t share the same fever that oozed out of attendees at Slush, she pointed to a few positive data points that suggest the European market is turning around.

For one, the participation of U.S. investors in European startup deals is back on the rise. Rajan said that figure dipped to a low in 2023 when U.S.-based VCs participated in just 19% of European venture deals. It has been steadily on the rise since, she said.

“They seem pretty optimistic on the European market,” Rajan said. “Just from an entry point of view, because you think about valuations, especially within AI tech and in the U.S., it’s just impossible to get in now, whereas, if you’re in Europe and your multiples are lower, and you’re new as an investor, it just provides a better entry point for perhaps similar tech.”

Swedish vibe-coding startup Lovable is one example of this shift. Vibe-coding companies have raised a lot of VC money in the United States. But U.S. investors also clearly love Lovable. The company just announced a new $330 million Series B round that was both led by and participated in by a slew of U.S.-based VCs, including Salesforce Ventures, CapitalG, and Menlo Ventures, among others.

French AI research lab Mistral has seen similar love from U.S.-based firms. Mistral landed a €1.7 billion Series C round in September that included Andreessen Horowitz, Nvidia, and Lightspeed.

Klarna’s recent exit also suggests a turnaround is underway.

Swedish fintech giant Klarna went public in September after raising $6.2 billion across two decades in the private market. That exit likely recycled some capital back to European LPs or gave them confidence in a changing exit environment.

For Victor Englesson, a partner at Swedish EQT, the recent European success stories, like Klarna, have started to change how founders in Europe approach building their companies.

“Ambitious founders have seen what great looks like in companies like Spotify, Klarna, Revolut and are now starting companies with that type of ambition,” Englesson told TechCrunch. They’re not starting companies with like, I want to win in Europe, or I want to win in Germany. They start companies with a mindset that I want to win globally. I don’t think we have seen that to the same extent before.”

That mindset has EQT, and others, bullish on Europe.

“For EQT, we’ve invested $120 billion in Europe [over the] last five years,” Englesson said. “We’re going to invest $250 billion [over the] next five years in Europe. So we are extremely committed to Europe.”

Becca is a senior writer at TechCrunch that covers venture capital trends and startups. She previously covered the same beat for Forbes and the Venture Capital Journal.

You can contact or verify outreach from Becca by emailing rebecca.szkutak@techcrunch.com.

Plan ahead for the 2026 StrictlyVC events. Hear straight-from-the-source candid insights in on-stage fireside sessions and meet the builders and backers shaping the industry. Join the waitlist to get first access to the lowest-priced tickets and important updates.

Nvidia to license AI chip challenger Groq’s tech and hire its CEO

Waymo explains why its robotaxis got stuck during the SF blackout

Marissa Mayer’s new startup Dazzle raises $8M led by Forerunner’s Kirsten Green

ChatGPT launches a year-end review like Spotify Wrapped

Waymo resumes service in San Francisco after robotaxis stall during blackout

Google and Apple reportedly warn employees on visas to avoid international travel

Ex-Splunk execs’ startup Resolve AI hits $1B valuation with Series A</div>
        </div>
        
        <div class="card" onclick="openModal('content-18')">
            <div class="source">The Atlantic</div>
            <div class="title">The Best Poetry for Dark Winter Days</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-18" style="display:none;">
            <h2>The Best Poetry for Dark Winter Days</h2>
            <p><strong>The Atlantic | 2025-12-26</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/books/2025/12/best-poetry-dark-winter-slow-down/685460/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">For those of us north of the equator, winter officially arrived last week. The early darkness and the chill in the air demand a change in our habits. For many, the season provokes an unmistakable turn inward—toward our warm homes, or the loved ones we see on holidays, or meditative thoughts that, in other times of year, might be crowded out by the light and noise of the world.

Perhaps saying so is sentimental, but these feel like the perfect days and nights for poetry. The form can capture, perhaps better than any other, the muffled quality of cold afternoons and days spent indoors. Its winding paths of language can describe both the season’s comforts and its harsher qualities. As 2025 winds down, we’ve selected some poetry to accompany you through the last days of December. Each collection speaks to a different wintry mood, but all are worth slowing down with before 2026 brings the return of longer, busier days.

Selected Poems of Rubén Darío, translated by Lysander Kemp

Once, after an epiphany in a high-school class, my best friend declared that she had made up her mind to study literature in college. This was years ago, but I remember that day well: She said that analyzing a Darío poem had made her realize how beautiful an arrangement of words can be. Many of his works double as fairy tales, and have been adapted into children’s books. This is why my first exposure to Darío, one of the best poets to ever write in Spanish, came when I was 3 or 4—in the form of a princess story that I love just as much now. My father, too, can recite from memory a Darío verse he read as a young man: “and the neck of the great white swan that questions me.” This volume of Kemp’s translations includes my favorite Darío poems; their rhymes are lost, but their dreamlike, hypnotic quality is preserved. And the sensual images these verses bring to mind—nightingales and angels and silks—make this collection ideal for evenings beside the hearth.  — Gisela Salim-Peyer

On a snowy day, you could curl up by the fire with something wholesome and cozy; you could perch by the window with something chilly and somber. Or you could crack open the New Zealand poet Tayi Tibble’s Rangikura, which is none of these things. Playful, forceful, and sexy, it radiates so much heat that choosing it for a holiday read is like fleeing south for the winter. (And in Tibble’s home country, December is summer.) That’s not to say it’s unserious: Tibble reflects on the relentless shame she used to feel about her gender and her Indigenous Māori heritage; she charts how she emerged from timidity like flowers peeking out from a melting blanket of ice. Rangikura is the result of her transformation, and it is a persuasive case for freedom, pleasure, and fun that honors the generations of women in her family who also celebrated, shouted, and danced. “I’m hotter than the sun,” she declares. “And my ancestors ride wit me / like dawgs. When I whistle / they run and run and run.”  — Faith Hill

In her diary-like, book-length poem, Midwinter Day, Mayer sets out “to tell the story of exactly what is happening.” The book duly follows a course from her waking hours to the “long black night” of the winter solstice. In the middle of the book, she stops to note the time: “It’s 1:15 pm,” she writes, as she leaves the market. “We’re going home with what we can have to carry. / Having had to pay for it / And the sun comes out.” Mayer isn’t the first author to turn a single day into her plot, but her loving transcription of life in 1978 Lennox, Massachusetts—her children drawing at the kitchen table, their visit to the library, the pattern of snow Mayer sees on a roof, the red brake lights that shine on the wet street—makes a string of ordinary events feel like quiet epiphanies.  — Walt Hunter

Sullivan’s poems are so long that only six appear in her books. Half of these are in her 2018 debut, Three Poems, and the other half appear in her follow-up, Was It for This, which juxtaposes an elegy for the victims of the Grenfell Tower fire with two gratitude-laced meditations on aging. Throughout, the depth and quality of Sullivan’s attention to prosaic detail—even plain and unappealing objects—never wavers. She lingers on microwavable “corn cobettes”; on a crumbling library book that turns into an “osteoporotic spine / all particles, frayed ribbon, / skin stubs, moving in the / light.” Such appreciative concentration is rare in this era of rush and scrolling, but in “Was It for This,” the collection’s most meditative poem, Sullivan writes, “The things that I instinctively saw as ugly I wanted to see also, under another aspect, as beautiful.” When I read her, I want that too.  — Lily Meyer

Lim’s searching book is best read in complete silence. It rewards the focused, careful turning over of words and phrases. And it is studded with winter imagery: “No clouds toppled across the snow wilderness. / No gloom-dark tree-glitter winding and twining its silks. / Blankness, egg-quiet,” she writes in “Wintering.” This book is dead serious about the human condition, determined to ask existential questions about life and willing to linger in its mysteries. Yet this ambivalence doesn’t show up in Lim’s syntax, which is sure-footed, precise, and vibrant. She begins one poem, “Certainty,” by referencing the Puritan poet Edward Taylor. His verse, she notes, is “full of deep piety, / learned and quiet, but sometimes an errant wildness runs under / the seams of his words.” The same could be said of the poems in Wilderness—they read like a long, slow breath after the crush of a hard year.  — Maya Chung

Read: The Norwegian town where the sun doesn’t rise

How successful is Crane’s modernist epic, a poem meant to stride as confidently across American geography and history as the mighty Brooklyn Bridge spans the East River? Nearly 100 years after its publication, the jury is still out. But even those who consider The Bridge a spectacular failure tend to be impressed by Crane’s ambitions. As T. S. Eliot does in The Waste Land, Crane wants to connect rapid, destabilizing change with mythic currents of emotion. He clasps Walt Whitman’s hand and briskly rouses Rip Van Winkle; all the while, he conjures trains and telegraph wires tearing across the country, buffeted by a hurricane of contemporary references. Making sense of all of this requires measured, deliberate reading, my ideal kind of project for the dead week between Christmas and New Year’s. Helping with this task is a fantastic annotated edition edited by Lawrence Kramer (which is being reissued this spring). Crane was a motivated, but frustrated, visionary. This makes him fascinating—and makes The Bridge worth the trek from promenade to promenade.  — Emma Sarappo

Glück, a Nobel laureate, was a poet of few and careful words. Her work is often described as “spare” or “austere”; a solitary aspect to her poems makes them the perfect companion after an early sunset. Glück often directs her focus toward self-reflection, but her second collection, The House on Marshland, also scrutinizes a stark, chilly natural realm marked by “the barrenness / of harvest or pestilence.” The opening poem, “All Hallows,” is sublimely, high-mindedly eerie, and it is one of my favorites. In later poems, Glück includes plenty of flowering trees and signs of new life, but those are freighted with warning: As she writes of spring, “with the first leaves / all that is deadly enters the world.” Perhaps there’s comfort to be found in the stillness and blankness of winter.  — Quinta Jurecic

Read: Why children are everywhere in Louise Glück’s poetry

The Complete Poems of John Keats, by John Keats

Some of Keats’s best poems brim with references to the seasons and their attributes, whether a spring musk rose, “mid-May’s eldest child,” or the “mists and mellow fruitfulness” of autumn. But picking up the 19th-century Romantic at the end of the year feels especially apt. That’s because Keats, who died at just 25, was obsessed with the finality of things, with an unavoidable fear of life ceasing to be. Reading him this season can be a humbling reminder of our finitude. And yet, his descriptions of winter’s “pale misfeature” or of “drear nighted December”—its ability to make him wonder, “were there ever any / Writh’d not of passed joy?”—are wildly alive; they suggest that there is much to be gained by reflecting on loss. With this poet, even musings on mortality point toward beauty, no matter the month.  — Luis Parrales

​When you buy a book using a link on this page, we receive a commission. Thank you for supporting The Atlantic.</div>
        </div>
        
        <div class="card" onclick="openModal('content-19')">
            <div class="source">The Atlantic</div>
            <div class="title">The Most Memorable Advice of 2025</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-19" style="display:none;">
            <h2>The Most Memorable Advice of 2025</h2>
            <p><strong>The Atlantic | 2025-12-26</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/newsletters/2025/12/most-memorable-advice-2025/685407/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The approach of a new year is an opportunity to reflect on time spent with friends, family, and partners who have played a role in your life—and how you can improve these relationships.

For parents, 2025 might have been a year that felt fraught with questions about what it means to raise a child today. In 2025, Atlantic writers explored the challenges that can come with finding child care, the debate about whether to avoid ultra-processed foods, the questions of when—or where—kids should gain access to technology, and more.

Dating, a once classic rite of passage, is also changing, Faith Hill wrote this year. Yet even as fewer young people are getting into relationships, they do believe in love: According to one study that included more than 5,000 Americans, 60 percent of single adults said they believe in love at first sight, a nearly 30 percent increase from 2014.

With a new year comes the hope of change and betterment—so let these writers help you nurture and strengthen your relationships in the year ahead.

Teens Are Forgoing a Classic Rite of Passage, by Faith Hill

Dear James: The Men I’m Dating Keep Leaving Me Numb, by James Parker

The Agony of Texting With Men, by Matthew Schnipper

The Great Ghosting Paradox, by Anna Holmes

Three Rules for a Lasting Happy Marriage, by Arthur C. Brooks

Avoiding Ultra-Processed Foods Is Completely Unrealistic, by Olga Khazan

One Obvious, Underused Child-Care Solution, by Marina Lopes

Being a Dad Is About More Than Being Around, by Stanley A. McChrystal

A Tech Rule That Will ‘Future-Proof’ Your Kids, by Rheana Murray

Parents, Put Down Your Phone Cameras, by Russell Shaw

Bring Back Communal Kid Discipline, by Stephanie H. Murray

The Most Useless Piece of Parenting Advice, by Olga Khazan</div>
        </div>
        
        <div class="card" onclick="openModal('content-20')">
            <div class="source">The Atlantic</div>
            <div class="title">The World Has Laws About Land and Sea, But Not About Ice</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-20" style="display:none;">
            <h2>The World Has Laws About Land and Sea, But Not About Ice</h2>
            <p><strong>The Atlantic | 2025-12-26</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/science/2025/12/sea-ice-law/685401/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">When the Chinese cargo freighter Istanbul Bridge set sail for Europe in late September, it took an unusual route. Instead of heading south for the 40-day voyage through the Suez Canal, it tacked north. The freighter arrived in the United Kingdom at the port of Felixstowe just 20 days later—successfully launching the first-ever Arctic commercial-container route from Asia to Europe.

For most of human history, the surface of the world’s northernmost ocean has been largely frozen. Now scientists predict that most of the Arctic Ocean’s 6.1 million square miles may be seasonally ice-free as soon as 2050. Economically, a less icy Arctic spells opportunity—new shipping routes and untapped fossil-fuel reserves. Climatologically, it’s a calamity. Legally, it’s a problem that has to be solved.

Much of the ocean’s center, the northernmost stretch surrounding the pole, will be subject to the lawlessness of the high seas—which will become a problem as more ships try to navigate a mushy mix of water and sea ice. And although the Arctic is the world’s fastest-warming region, and contains its most rapidly acidifiying ocean, it has few environmental protections. Scientists don’t have a clear idea of which species might need defending, or of the climate effects of unbridled shipping. (Ships puff black carbon, which reduces ice reflectivity and, in the short term, causes up to 1,500 times more warming than carbon dioxide.)

In October, the United Nation’s special envoy for the ocean, Peter Thomson, called for countries to agree to a “precautionary pause on new economic activities in the Central Arctic Ocean” to buy time to study the climate and environmental risks of increased activity. Others are asking for an agreement akin to the 2020 Artemis Accords, which committed 59 nations to the “peaceful” and “sustainable” exploration of space. But some polar-law scholars argue that curbing climate catastrophe may require a more radical reimagining: to make sea ice a legal person.

For centuries of seafaring, ice was an obstacle blocking people out, not an environment anyone thought to protect. Even in the Arctic, “we have laws about the land, we have the Law of the Sea, but we don’t have laws about ice,” Apostolos Tsiouvalas, a postdoctoral researcher with the Arctic University of Norway, told me. Because dealing with ice hasn’t been a major concern, even for the five nations that border the Arctic, and because ice is always transforming, its place in the law is confused at best.

In many cases, solid ice extending from a coastline has been treated as legal land, and ice carried by a current has been considered water. During the Cold War, both Russia and the United States maintained scientific “drift stations” on detached ice floes. In 1970, when a shooting occurred on one American station, several nations debated where, exactly, the crime took place. Was the ice Canadian, because it likely calved from a glacier on Canada’s coast? Was it an American island? After some back-and-forth, the vessel-size chunk of ice legally transformed—by no small imaginative leap—into an American ship.

The so-called Arctic Exception of the United Nations Convention on the Law of the Sea does extend states’ rights to impose laws far from the coastline, in areas that are ice-covered for most of the year. The point was for Arctic states to help prevent accidents and pollution, but states have since used the exception to extend their geographical sovereignty. But the term ice-covered complicates these claims. How much ice means “covered”? Are we talking uncrossably frozen, or just a few drifting bits?

That’s the problem with regulating icy regions: Even if these cryo-categories were more formalized, none would apply for very long. A large majority of Arctic ice is sea ice, which forms on ocean surfaces when salt water freezes. (It’s distinct from icebergs, which calve from landbound glaciers.) Human activity may have accelerated its melt, but sea ice was already one of the planet’s most dynamic systems, its surface area fluctuating by millions of miles season to season. It’s always either melting or freezing, and as it melts, its fragments can travel hundreds of miles along waves and currents.

In an article published this month in the journal The Yearbook of Polar Law, Tsiouvalas and his co-authors, Mana Tugend and Romain Chuffart, argue that piecemeal updates to current laws simply will never keep up with this fast-changing and threatened environment. Future governance of sea ice will require a transformation of some sort, and they argue that the clearest path forward is to bring the rights-of-nature movement to the high north.

Since Ecuador’s landmark 2008 constitutional protection of nature, Bolivia, India, New Zealand, and other countries across the world have made natural entities legal persons, or otherwise given them inviolable rights. The UCLA Law professor James Salzman, who has taught a class on nature’s rights, told me that this idea does not represent a single legal framework but that it does answer what he calls the “Lorax problem” of environmental law, referring to the Dr. Seuss character who claims to “speak for the trees.” Granting a voiceless entity legal personhood provides it with a representative to argue on its behalf.

With this designation, Tsiouvalas and his co-authors note, sea ice would get the highest legal status possible. In many cases, environmental protections can be bent to accommodate other, conflicting benefits to human society. But personhood grants an inherent right to exist that can’t be superseded. The new paper is mostly an ethical exploration and, the authors acknowledge, still just a stepping stone to more concrete regulations, but granting ice rights would create firmer standing to, for example, keep ships out of areas that humanity might otherwise want to use. The authors also note that rethinking sea ice’s status could include Indigenous people who have been routinely excluded from decisions around Arctic sovereignty and whose millennia of living on and with ice could guide its future governance.

But Sara Olsvig, the chair of the Inuit Circumpolar Council, told me recently that the legal interest in Arctic rights of nature is a “worrying development.” To Olsvig, the phrase rights of nature itself implies some separate concept of nature that doesn’t exist for the Inuit. And in the past, the environmentalist movement has elevated its idea of “nature” above the interests of Indigenous people. Decades-long bans against whale and seal hunting, for instance, devastated the cultural continuity and health of Inuit in the far north.

To answer such concerns, any legal right granted needs to be very clear about the duties that follow, Salzman said: If sea ice has a right to not be harmed, what constitutes “harm”? Would that mean blocking all human interference with the ice, or merely banning fuels that emit black carbon? After all, the major threat to sea ice—global emissions—“is not something that can be locally managed,” Salzman pointed out, and so far, natural resources have obtained legal personhood only in a national context. Rights for sea ice would require international agreement, which could be not only harder to achieve but harder to enforce. Sara Ross, an associate law professor at Dalhousie University, in Canada, told me that, in her view, legal personhood granted via international treaty would be too dependent on goodwill agreements to be effective.

But in some ways, legal personhood for nonhumans is an old idea, Ross said. Most countries grant it to corporations, and in the United States and Commonwealth countries, it’s typical for ships too. She especially likes the ship comparison, because—as maritime law has already discovered—floating pieces of ice aren’t so dissimilar. She imagines a more circumscribed role for sea-ice personhood, connected to, say, setting standards that ban icebreaking or heavy fuel emissions in icy areas. If these mandates are violated, local Inuit communities would have the power to sue on behalf of the ice—whether or not they could prove how much one particular ship degraded one particular stretch of ice.

Without some legal protections put in place, the sea ice will soon disappear that much faster. In October, the U.S. bought new icebreaking ships from Finland and undermined an International Maritime Organization agreement that would have had shipowners pay a fee for the greenhouse gases their vessels emit. The next week, just after the conclusion of the Istanbul Bridge’s voyage, Russia and China made a formal agreement to co-develop the Northern Sea Route that the ship had followed. If summer sea ice disappears entirely, scientists predict accelerated catastrophe—leaps in temperature, more frequent and stronger storms, global sea-level rise—which will threaten the planet’s general livability. “The fact that we need sea ice to survive is not a rights-of-nature argument,” Salzman said. “But it’s still a pretty good case to make.”</div>
        </div>
        
        <div class="card" onclick="openModal('content-21')">
            <div class="source">The Atlantic</div>
            <div class="title">Aphoristic Intelligence Beats Artificial Intelligence</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-21" style="display:none;">
            <h2>Aphoristic Intelligence Beats Artificial Intelligence</h2>
            <p><strong>The Atlantic | 2025-12-26</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/ideas/2025/12/aphorisms-artificial-intelligence/685406/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The first aphorism I ever read was on the Quotable Quotes page of Reader’s Digest, one of only two publications available in my house growing up. (The other was Time magazine.) I must have been about 8 years old when I came across the following sentence by Gerald Burrill, then the Episcopal bishop of Chicago: The difference between a rut and a grave is the depth.

At the time, I had no idea what an aphorism was. I was just 8. And I had no idea what Gerald Burrill’s observation meant. But I knew there was something special about that sentence and the others I discovered on the Quotable Quotes page. I loved the puns, the paradoxes, the clever turns of phrase. And I was amazed at how such a compact statement could contain so much meaning.

As a kid, that aphorism stuck with me, even more so many years later when I finally understood what the bishop was getting at—that drudgery is a habit-forming enemy of joy, and that staying in a dead-end job leads nowhere. I’ve been obsessing about the respective depths of ruts and graves for more than 50 years now, wondering every morning whether I’m simply walking to work or slowly burying myself.

This is the awesome power of aphorisms, and it is what sets them apart from the trite sound bites of social-media influencers and the platitudes of self-help gurus: Aphorisms do not make you feel good about yourself. That Burrill saying doesn’t offer an easy fix or a neat solution. In fact, it doesn’t offer a fix or a solution at all. It is a great example of aphoristic intelligence at work. It makes us reconsider what we’re doing, or not doing, with our lives.

Take the familiar saying “Love means never having to say you’re sorry.” Apart from the inaccuracy—in my experience, love means having to say you’re sorry on a regular basis—this is not an aphorism, because it’s too easy. It induces complacency. It doesn’t make you think. Much more confrontational, much more provocative, and therefore much more aphoristic is this, from the Polish writer Magdalena Samozwaniec: Love is that short period of time when someone else holds the same opinion of us as we do of ourselves.

Lila Shroff: The people outsourcing their thinking to AI

Or this wry insight from the Harlem Renaissance writer Jean Toomer: People mistake their limitations for high standards. Or the wisdom in this cynical definition by the legendary humorist Ambrose Bierce:

Misfortune n. The kind of fortune that never misses.

Or the rueful truth of this observation by the 17th-century French aristocrat François, Duc de La Rochefoucauld:

How comes it that our memories are good enough to retain even the minutest details of what has befallen us, but not to recollect how many times we have recounted them to the same person?

In some ways, aphorisms are perfectly suited to our era of short-form communication. They’re concise, catchy, easily consumable. But so much of our discourse, online and IRL, is anti-aphoristic—rage bait, trash talk, knee-jerk toxicity, gauzy affirmations, hashtag claptrap. And now comes that upstart other AI, artificial intelligence, promising to reduce our cognitive loads to zero by proffering frictionless friendships and sycophantic agreeability, and doing all of our creative thinking for us.

Aphorisms are different. They are the antithesis of the half-baked hot take and nothing like the machine-made flattery that’s now permeating so many informational environments. A platitude is a placebo for the mind; an aphorism is a wake-up call. Aphorisms provoke debate; they don’t promote dogma. Though they’re short, aphorisms spur considered reflection, not Pavlovian partisanship. At a time when polarization is so amped up, aphorisms can serve as psychological circuit breakers, interrupting our comfortable assumptions and prodding us to open our minds, unclench our fists, and think for ourselves.

Have an important life decision to make? Heed the artist Jenny Holzer’s advice: Playing it safe can cause a lot of damage in the long run.

Holzer’s line is a cautionary tale about how taking no chances in your career, your relationships—your life—can ultimately be hazardous. Or consider this idea, from the French poet, painter, filmmaker, and boxing promoter Jean Cocteau: Mirrors would do well to reflect a little more before sending back images.

Cocteau’s aphorism is a quippy but bracing reminder to look at ourselves differently in order to see others differently.

Charlie Warzel: A tool that crushes creativity

Dealing with aging, impairment, and death; confronting adversity and struggling with relationships; working through creative blocks and personal challenges—all of these things are supposed to be hard! The difficulty is the point. Where artificial intelligence makes things that are supposed to be hard seem like they’re easy, aphoristic intelligence accepts that things that are supposed to be hard are, in fact, really hard. Aphorisms gleefully increase our cognitive loads by immersing us even further in the difficulty and reminding us of what’s at stake.

Many researchers studying AI warn that tools such as ChatGPT, if overused, may promote dependence on technology and potentially trigger what they call metacognitive laziness—delegating challenging tasks to external tools instead of learning and doing them ourselves. Equally if not more concerning is the risk of metaphysical laziness—delegating challenging existential tasks to external tools instead of learning and doing them ourselves.

If a chatbot is calling my elderly parent for me, offering me nothing but relentless affirmation and validation, and writing all my texts, emails, and thank-you notes (not to mention my poems, screenplays, and novels), then I have become a spectator to my own mental and emotional life. My critical and creative thinking withers, and the very nature of thinking itself shifts from introspection to outsourcing, from seeing the big picture to painting by numbers. As the Austrian aphorist Marie von Ebner-Eschenbach once put it: Those who were carried to a goal should not think they’ve reached it.

This article was adapted from Geary’s book The World in a Phrase: A Brief History of the Aphorism.

​When you buy a book using a link on this page, we receive a commission. Thank you for supporting The Atlantic.</div>
        </div>
        
        <div class="card" onclick="openModal('content-22')">
            <div class="source">The Atlantic</div>
            <div class="title">To Understand Today’s Left, Remember Daniel Patrick Moynihan</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-22" style="display:none;">
            <h2>To Understand Today’s Left, Remember Daniel Patrick Moynihan</h2>
            <p><strong>The Atlantic | 2025-12-26</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/ideas/2025/12/daniel-patrick-moynihan-working-class/685451/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Daniel Patrick Moynihan, who died in 2003, might be remembered most for his erudition. During his 25 years in the Senate, Moynihan often turned the legislative chamber into a lecture hall. “That man just got up and spoke for 45 minutes with no notes and no reference materials, and proceeded to delineate the entire history of the Panama Canal,” a fellow legislator once reported. The New York Democrat and Harvard professor wrote or edited 18 books—and many more articles—on topics including automobile safety, organized crime, federal architecture, international law, and government secrecy. But these efforts had little to do with how he won four elections to the Senate. Despite his quasi-British accent and bow ties, Moynihan always identified with the working class, and he came to resent the elites of his own party.

This perspective, informed by his tumultuous youth, fueled his political success far more than his intellect. It allowed him to understand the anger of working-class voters, many of whom were alienated by the left’s endorsement of affirmative action in the 1960s and its rejection of national pride after Vietnam.

Moynihan’s bitter criticisms of the party don’t provide a model for Democrats today; he was too often blinded by personal grievance. But his critiques prefigured, and help explain, some of the greatest challenges his party now faces. Moynihan chronicled the exodus of working-class voters from the left as it began. Today, as Democrats debate how to win them back, they would do well to remember what he saw and, no less important, what he didn’t.

Read: The Democrats’ working-class problem gets its close-up

The press typically described Moynihan’s life as a Horatio Alger tale, the same way he liked to tell it himself: A boy who shined shoes on the sidewalks of Manhattan rose to the halls of academia, then high office. But the real story was more complicated, and more painful.

Volatility defined Moynihan’s early life. Born into the middle class, he spent summers riding horses and caddying at a country club. When his father abandoned the family, they fell into poverty. The shoe-shining began at age 10 but ended when his mother remarried and they moved into a mansion in the New York suburbs. Two years later, divorce sent his family back to the city. Moynihan went to high school in Harlem, leaping on the rear of buses each morning to avoid the fare.

Over the next decade, Moynihan continued to cycle through social classes. After high school, he worked as a longshoreman on the piers of Manhattan’s west side while getting a free public education at City College. Then he joined the Navy, which sent him to training programs at Middlebury College and Tufts University. On weekends, he visited his friends’ country homes and made frantic trips back to the city to help his mother run a bar she had bought in a rough neighborhood.

Moynihan had reservations about his new social set, who he thought lacked the toughness and insight he’d been granted by his stint in poverty. As he wrote to a friend back home, many of them needed “a good swift kick in their blue blood asses.”

A Fulbright scholarship to the London School of Economics offered Moynihan an escape from his chaotic family life. In England, his later persona began to take shape. He wrote in his journal that he wanted to become like “an English novel character—full of stories and odd bits of fascinating info.” By the time he came back to the United States, he had adopted the manners of the British elite.

Moynihan made his start in politics soon after his return. While working in President Lyndon B. Johnson’s Labor Department, he produced an internal memorandum about what he described as a growing crisis in the Black community, marked by a decline in two-parent households and a rise in welfare cases. He wrote that “the situation may indeed have begun to feed on itself,” suggesting that poor Black Americans were becoming victims of their own culture. Notably, Moynihan reached this conclusion without having included any Black Americans in the research and writing process.

The Moynihan Report, as it became known, was publicly released in August 1965, shortly after the Watts riot in Los Angeles. Even though Moynihan had finished writing the document five months earlier, the press initially portrayed it as the administration’s explanation of the racial unrest; according to early coverage, the report blamed the riots on a “pathological” Black culture. Black Americans and many on the left were outraged. In their eyes, Moynihan was “blaming the victim.”

Moynihan thought—with some justification—that his critics presented a selective reading of the document, which also called for greater investment in Black communities. “Liberty and Equality are the twin ideals of American democracy. But they are not the same thing,” he observed early in the report. “The principal challenge of the next phase of the Negro revolution is to make certain that equality of results will now follow.” Elsewhere in the document, Moynihan wrote that “equality of opportunity almost insures inequality of results.” When a journalist asked if he was “proposing preferential treatment in the hiring of Negroes,” Moynihan replied: “I believe this country owes the American Negro his back wages, yes.”

Ta-Nehisi Coates from the October 2015 issue: The Black family in the age of mass incarceration

The report emerged during a hinge moment on the American left, which Moynihan had begun to discern at the start of the decade. In 1961, he depicted a growing rift among Democrats: On one side were the predominantly working-class “regulars,” and on the other were the upper-middle-class “reformers.” As Moynihan described them, regulars thought politics was about winning votes. Reformers thought it was about moral issues, such as democratizing the party and expanding civil rights.

Moynihan sided with the reformers yet came to believe that many of them were more concerned with signaling virtue than achieving results. Tammany Hall—the New York political machine that served as a stronghold of the regulars—may have been corrupt and self-interested, but Moynihan admired its tangible service to the poor, such as its Thanksgiving tradition of delivering turkeys to needy families. He thought the reformers, by contrast, were too far removed from the lives of working-class Americans, which he never stopped admiring. (He would later write that he felt like “I haven’t really done a day’s work since” he was a longshoreman.)

In the years after the Moynihan Report was published, reformers and other elite liberals accounted for some of its most intense criticism. They had been gaining power within the party throughout the ’60s, as the Democrats went from the home of southern segregationists to that of civil-rights leaders. In 1967, Moynihan acknowledged that the “liberal Left” had enabled the “extraordinary impact and success” of the civil-rights movement, serving as a “secular conscience” for America. But he also thought the faction could be “as rigid and destructive as any force in American life,” an assessment based largely on the reformers’ rejection of his report. Moynihan grew more partial to the regulars, struggling to see that the civil-rights victories he supported were made possible precisely because the group—and its self-serving patronage system—had lost sway.

By 1968, Moynihan was lamenting that the working and middle classes “have been abandoned, and our politics are very much the worse for it.” The next year, Moynihan shocked Democrats by going to work for President Richard Nixon. Although Moynihan had previously endorsed affirmative action, he had come to believe that no overtly race-based policy could win enough support from groups such as the white working class. So Moynihan persuaded Nixon to propose a guaranteed income for all families regardless of race (which Congress never passed). In 1973, during a brief stint as an ambassador in Gerald Ford’s administration, he complained that he was effectively “silenced” on the topic of civil rights—“a considerable waste,” he wrote in his journal, “for I am really pretty good on the subject, and care as much or more than most people.”

Moynihan’s resentments fueled his belief that the privilege of many elite liberals skewed their vision of politics. Unlike ordinary people who tended to favor incremental reform over revolutionary change, the “liberal Left,” he wrote, was “largely made up of individuals who have passed through most of the stages of routine affluence” and “now want out” of the U.S. they knew. Moynihan thought that most Americans, Black Americans included, wanted “in.”

Much of the growing anti-American sentiment at the time was inspired by the Vietnam War, which horrified many on the left. Moynihan opposed the conflict, but he was quick to point out that elite liberals in the Kennedy and Johnson administrations were the ones who had started it—and members of the working class were mainly the ones fighting it.

Ever the contrarian, Moynihan embraced patriotism. In 1975, he published an article arguing that the U.S. should stop apologizing for itself in the aftermath of Vietnam, and start challenging its critics at the United Nations and elsewhere. He told a friend that the essay received a more positive response than anything he’d ever written. “The message is unmistakable,” he concluded. “People are tired of being ashamed of ourselves.”

Daniel Patrick Moynihan from the July 1975 issue: How much does freedom matter?

One admirer of the essay was Secretary of State Henry Kissinger, who helped persuade President Ford to appoint Moynihan as ambassador to the UN. In that role, Moynihan delivered impassioned speeches in support of the U.S. and its values. Many working-class New Yorkers loved his theatrics; one of his friends recalled taxi drivers cheering Moynihan as he walked around Manhattan.

Buoyed by his new popularity, Moynihan ran for Senate as a Democrat in 1976. But he still didn’t let go of his resentment of elites. In the lead-up to the election, Moynihan sat for a tense interview with Timothy Crouse, a reporter from Rolling Stone. The two spoke at Harvard, where Crouse had graduated and Moynihan was teaching. At one point, Crouse asked Moynihan why he had chosen to work in academia instead of a more lucrative field, given his precarious youth.

“What sort of background do you come from?” Moynihan replied.

“Aaaaaahh … a rich Harvard kid. Or as we used to say where I came from, a rich college fuck.”

If anything, such a sentiment may have boosted Moynihan’s chances in the race. Despite his previous work for Republican presidents, he managed to secure the Democratic nomination, defeating his more liberal opponent by a mere 10,000 votes, thanks in part to reportedly strong support among working-class voters. He went on to win the general election handily, running a campaign that espoused an unapologetic patriotism.

In his report a decade earlier, Moynihan had attempted to reckon with the country’s history of racial inequality. By the time he ran for Senate, he had learned that pride won more votes than shame.

In the age of MAGA, Moynihan has been described as an avatar of a bygone era. The New York Times dubbed him “the anti-Trump of American politics” in 2018. Somewhat more recently, The New Yorker argued that Moynihan was “above all, a public-policy intellectual” whose “addiction to complexity” would make him out of place today. But these analyses present a blinkered view of both Moynihan and American history.

Moynihan does not belong to some distant past. America is still experiencing the effects of the liberation movements that began in the 1960s, and the battle that he chronicled between the regulars and reformers within his party has never entirely ended. Consider a telling moment from last year’s election: When Joe Biden was pressured to withdraw from the race, the working-class Democrat referred to his intraparty opponents as the “elites.” That was no accident; it reflected a long-running divide on the left.

As in Moynihan’s time, some Democrats now argue that their party should pivot back to the working class. Others want to pursue a more expansive progressivism, unconstrained by concerns about the political center. Both sides seem to think that their only hope of defeating Trumpism is to decide the debate once and for all. If Moynihan’s career is any indication, they shouldn’t expect that to happen anytime soon.</div>
        </div>
        
        <div class="card" onclick="openModal('content-23')">
            <div class="source">The Atlantic</div>
            <div class="title">Where <em>Stranger Things</em> Lost Itself</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-23" style="display:none;">
            <h2>Where <em>Stranger Things</em> Lost Itself</h2>
            <p><strong>The Atlantic | 2025-12-26</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/culture/2025/12/stranger-things-season-5-volume-2-review/685465/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">This article contains spoilers through the penultimate episode of Stranger Things Season 5.

In the third season of Stranger Things, Eleven (played by Millie Bobby Brown) learned a pivotal lesson as she stood inside Starcourt Mall, the then-new watering hole for the then-still-pubescent kids of Netflix’s supernatural drama. Eleven, the show’s telekinetic heroine, who grew up in a lab, became dazed by the number of clothing options at the Gap. “How do I know what I like?” she asked her friend Max (Sadie Sink). “You just try things on until you find something that feels like you,” Max replied. She was talking about fashion, but the advice applied just as well to the challenge of leaving adolescence behind: Coming of age is a process of trial and error, of working toward what seems true to you.

For years, Stranger Things was changing too. The first season of the ’80s-set series—about underdogs triumphing over the terrors of another dimension called the Upside Down—became, after its 2016 premiere, one of Netflix’s most successful original productions. Each subsequent installment ventured into the proverbial fitting room: The second season leaned further into gore and took tonally challenging swings, including an episode exploring Eleven’s past to give its most enigmatic female character a voice. Season 3 explored how Reagan-era consumerism permeated its tweenagers’ lifestyles just as they began dealing with romantic relationships. The fourth examined conspiracy theories through a particularly unnerving, mind-manipulating villain, Vecna (Jamie Campbell Bower); he targeted a grieving Max, testing the friends’ bonds as they tried to protect her and understand her pain at the same time.

In the fifth and final season, however, Stranger Things has stalled. This time around, as the gang tries to stop Vecna from ending the world, the show seems uninterested in furthering anything other than its already complicated plot. The cast has expanded several times over, to the point that most scenes look like a crowd awkwardly playing human Tetris. The action sequences resemble previous set pieces, and much of the dialogue amounts to exposition. A new, faceless threat called “exotic matter” takes the crew’s resident nerd, Dustin (Gaten Matarazzo), multiple scenes to explain. Across the three episodes of Volume 2, the last batch before the series finale, characters regularly express their confusion about what’s going on. I found myself nodding along with them.

Read: Where Stranger Things loses its magic

For fans watching to see how Eleven and her friends save the day, much of this stagnation is probably bearable. The show remains compulsively watchable; each episode ends on a cliff-hanger. But Stranger Things initially had much more potential than mere bingeability. It pushed the boundaries of television as a medium, eschewing standard act breaks and run-time constraints while injecting cinematic visuals and frequent mood shifts. It also cemented Netflix as an early winner of the streaming wars by consistently breaking viewership records and generating cultural conversation. A litany of brands has capitalized on the show’s popularity; it has multiple spin-offs (including a Tony-winning stage play); and its massive fandom has spawned conventions worldwide. Stranger Things had the opportunity and the budget to probe more daring themes and storytelling techniques. Instead, in its final hours, what was once an epic about growing pains and the end of childhood becomes algorithmic—as if settling for “compulsively watchable” is more than enough.

Of course, the franchise was built on recycling. From the beginning, Stranger Things has relied on ’80s pop-culture touchstones, drawing heavily on the elements and aesthetics of Steven Spielberg’s blockbusters and Stephen King’s best sellers. In its earlier seasons, the pastiche tended to be poignant and the familiarity fresh: Characters drew on teen-movie tropes but weren’t one-note, and the story arcs found novel angles to archetypal dynamics. (Think of the pint-size Dustin becoming best pals with Joe Keery’s high schooler, Steve.)

Season 5, meanwhile, has noticeably flattened its ensemble, leaning on simplistic personality traits and pilfering from previous arcs. One of the show’s new supporting players, Derek (Jake Connelly), is defined entirely by the two nicknames he has: “Dipshit Derek” and “Delightful Derek.” A tired love triangle reemerges. Much of the plot otherwise hinges on recovering Holly (Nell Fisher), the younger sister of Mike (Finn Wolfhard) and Nancy (Natalia Dyer), from the Upside Down, a redux of the first season’s story. One episode features three—three!—separate sequences of characters reconciling after encountering life-or-death scenarios. I was moved by the first; by the third, I felt only indifference.

Read: Stranger Things comes to an exhausting end

Glimmers of depth still show up amid this shallow approach. Will (Noah Schnapp) has long served as the show’s most sensitive character, in part because he’s secretly queer and crushing on Mike. Yet the scene where he comes out feels shoehorned in, arriving between Eleven learning of a harrowing plan and the crew storming a military base to enter the Upside Down. Will’s speech is also packed with distracting reminders of the period backdrop. He insists to his friends that his sexuality doesn’t affect their shared interests (among other things: malted milkshakes, renting videos, Monty Python and the Holy Grail, and Steve Martin). The conversation even ends with a group hug, referencing a key moment from the first season; the callback comes across more like fan service than earned sentimentality. Unlike the show’s previous coming-out sequence—when Robin (Maya Hawke) gently coaxed Steve into understanding why she wasn’t interested in him—Will’s monologue clunkily interrupts the plot. What should have been an intimate reveal becomes another chance for Stranger Things to remix itself.

Sticking the landing is tough for any program, and harder still for a critically acclaimed, fandom-fueling genre saga. Game of Thrones certainly couldn’t withstand the weight of people’s expectations, let alone its overstuffed plot. Stranger Things hasn’t dropped the ball as dramatically in its final season. It has, however, sacrificed nuance by refusing to challenge itself—or to deviate from the brand it has built in the cultural imagination. The series once proved that it could mature alongside its cast, blending its fantastical swings with grounded themes of friendship, grief, and that classic, youthful challenge of discovering who you are as the world changes around you. “The impeccable trick Stranger Things pulled off in its first season was how seamlessly it wove together the opposing qualities of comfort and fear,” my colleague Sophie Gilbert wrote in 2017. Eight years later, the show isn’t making viewers nostalgic or giving them nightmares. It’s just telling them what happens next.</div>
        </div>
        
        <div class="card" onclick="openModal('content-24')">
            <div class="source">Slashdot</div>
            <div class="title">AI's Hunger For Memory Chips Could Shrink Smartphone and PC Sales in 2026, IDC Says</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-24" style="display:none;">
            <h2>AI's Hunger For Memory Chips Could Shrink Smartphone and PC Sales in 2026, IDC Says</h2>
            <p><strong>Slashdot | 2025-12-26</strong></p>
            <a class="original-link" href="https://it.slashdot.org/story/25/12/26/144228/ais-hunger-for-memory-chips-could-shrink-smartphone-and-pc-sales-in-2026-idc-says?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Want to read Slashdot from your mobile device? Point it at m.slashdot.org and keep reading!

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

Entropy requires no maintenance.
		-- Markoff Chaney</div>
        </div>
        
        <div class="card" onclick="openModal('content-25')">
            <div class="source">Slashdot</div>
            <div class="title">China Launches $21 Billion Venture Capital Funds To Invest in 'Hard Technology'</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-25" style="display:none;">
            <h2>China Launches $21 Billion Venture Capital Funds To Invest in 'Hard Technology'</h2>
            <p><strong>Slashdot | 2025-12-26</strong></p>
            <a class="original-link" href="https://slashdot.org/story/25/12/26/0641227/china-launches-21-billion-venture-capital-funds-to-invest-in-hard-technology?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Follow Slashdot blog updates by subscribing to our blog RSS feed

It is like having democratic in a country&#39;s name.  Generally tracks with not actually being that. At this point dropping the communism would be strange because everybody grew up with it named that, but only the oldest actually remember it trying to be communist.Today, China is rated as being easier to start a business in than the USA, and that is a problem.

Only in God&#39;s Own Country, &quot;communist&quot; is the opposite of&quot;capitalist&quot; or &quot;free market&quot; or &quot;democracy&quot;

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

Entropy requires no maintenance.
		-- Markoff Chaney</div>
        </div>
        
        <div class="card" onclick="openModal('content-26')">
            <div class="source">Slashdot</div>
            <div class="title">'Memory is Running Out, and So Are Excuses For Software Bloat'</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-26" style="display:none;">
            <h2>'Memory is Running Out, and So Are Excuses For Software Bloat'</h2>
            <p><strong>Slashdot | 2025-12-26</strong></p>
            <a class="original-link" href="https://developers.slashdot.org/story/25/12/26/0628235/memory-is-running-out-and-so-are-excuses-for-software-bloat?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Want to read Slashdot from your mobile device? Point it at m.slashdot.org and keep reading!

I just don&#39;t see incentives for most companies to seek much memory efficiency. Even if the calculator app takes a gig of RAM, few will notice and fewer will make purchasing decisions based on ram usage. Most people function just fine with 8gb. Even when they go over, the system still works thanks to ssds and virtual memory. Dell is not going back to mostly shipping mostly 4gb systems.

&quot;I have not run out of memory on my computer in years.&quot;

Neither have &quot;I&quot;, but my computer runs out of memory on a weekly basis and has done so for years.

No, but they&#39;re supposedly going back to 8GB systems after most low end systems having been moving towards 16GB for a while.

It costs money to optimize software, and most people don&#39;t want to pay it. A lot of software is already &quot;free&quot; with ads and upsells. I just can&#39;t see there being any improvement.

But since you can&#39;t afford a decent computer anymore, we&#39;ll let you rent one in the cloud that can run our shitty, bloated software

I am working on energysaving for software, with energyrating as part of it at Ahodzil [ahodzil.com]. Hopefully I will be able to make the code optimisation build framework available next year along with the energyrating. It goes beyond the compiler (and PGO) by checking if the code is necessary against a baseline of an &quot;optimal code formula&quot; based on decades of accumulated programming (and most codebases are just manipulating a database anyhow).

Good on you to provide an immediate potential solution, but you are highlighting the root of this problem: you are building just another framework. Modern developers do not know how to code, they only know how to integrate a framework with another framework. Everything became frameworks. And frameworks are, by definition, bloated. Even yours, given enough time, will cease to offer meaningful reductions because it too will get bloated with so many variables and options to circumvent others bloat.

And frameworks are, by definition, bloated.Most are bloated, but some are not. When I was doing Assembly on the 6809 in the 1980s, I wrote a framework that contained everything I used in most of my programs (printing to the screen, letting the user input a line of text, printing to the dot-matrix printer, modem file transfers, saving and loading files, etc). My assembled projects were quite small (usually around 20-25 kilobytes when finished). I did not include anything just for the hell of it, and my framework saved me tons of time on subsequent projects.Fast forward to about 12 years ago, when I started creating a Web programming framework for my own use. The framework is about 50K lines of PHP code (including comments and whitespace). It does include some dead code bloat, as it originated from a project I was writing for a specific project (which is easily trimmable if I ever get around to it). Barring that project-specific code, though, I would have to rewrite the vast majority of the framework for each Web project, so it is actually rather trim around the waist. It easily saves me years-worth of man hours on each project, and each project uses about 95% of the framework.But most modern frameworks are indeed bloated all to hell with no justifiable reason. And the reason is probably because they want to do everything for everyone, which always results in a bloated pig. But frameworks that target a specific need can be lean and efficient.

And frameworks are, by definition, bloated.

Most are bloated, but some are not. When I was doing Assembly on the 6809 in the 1980s, I wrote a framework that contained everything I used in most of my programs (printing to the screen, letting the user input a line of text, printing to the dot-matrix printer, modem file transfers, saving and loading files, etc). My assembled projects were quite small (usually around 20-25 kilobytes when finished). I did not include anything just for the hell of it, and my framework saved me tons of time on subsequent projects.

Fast forward to about 12 years ago, when I started creating a Web programming framework for my own use. The framework is about 50K lines of PHP code (including comments and whitespace). It does include some dead code bloat, as it originated from a project I was writing for a specific project (which is easily trimmable if I ever get around to it). Barring that project-specific code, though, I would have to rewrite the vast majority of the framework for each Web project, so it is actually rather trim around the waist. It easily saves me years-worth of man hours on each project, and each project uses about 95% of the framework.

But most modern frameworks are indeed bloated all to hell with no justifiable reason. And the reason is probably because they want to do everything for everyone, which always results in a bloated pig. But frameworks that target a specific need can be lean and efficient.

Frameworks are not &quot;bloated by definition&quot;.Especially when you actually do not know what the term &quot;framework&quot; means in computer science.In general: everything the framework you use does for you, you otherwise have to code yourself.So basically you want to claim: you wrote half a dozen applications, and when you are about to write the 7th, you figure: hey let&#39;s cut and paste the common part if those programs into &quot;a library&quot; ... beautify it a bit and call it a &quot;framework&quot;. And now it is suddenly bloated? Tha

I&#39;m sure the models trained on stack exchange examples will produce exactly the optimized code every CTO is hoping for when they promote the &quot;AI&quot;.

The funny part is that the &quot;agentic OS&quot; shit in windows, copilot required 16 gigs of ram for system to be certified to be copilot ready (or whatever it was that microsoft calls their copilot branding for OEM systems).

And rumor mill suggests that low end OEM systems are going back to 8 GB now. AI demand has caused... reduction in AI capable systems.

No worries, in the next version the &quot;agent&quot; will require a constant connection and run on the server.

Point in case: Installed the Dire Wolf Digital Boardgame Companion(!) app last night. 333 MB. It&#39;s a neat app and it looks cool, but 333 MB for this is insane. Basically every piece of software is like this these days.

Part of this is due to cross-platform and cross-version development, but a larger portion of it is that devs don&#39;t need to care and memory efficiency isn&#39;t a priority anymore.

Way too many layers of abstraction to enable ever less qualified unwashed masses to develop software with even less understanding and skill; we had decades of this - now you see the results.

No, not everybody should be coding. In fact, it is better if less clueless wannabes are running around with these loaded guns.

Lower memory footprint is desirable whether or not there&#39;s a shortage of commercially-available DRAM.  Though there&#39;s not going to be as much growth in available memory on systems, the reality is that DRAM shortages will cause end users to deploy fewer new systems in the near future rather than significantly curtailing the amount of RAM available per system.  People will be holding on to older systems longer rather than sticking to whatever upgrade path they&#39;re on.

Why use toolchains at all?  Just have AI produce the application ready to run!

And why use frameworks? Just ask AI to generate all the code needed.

&quot;...and argues that today&#39;s memory crunch could force similar discipline.&quot;

It definitely WON&#39;T, not for the people causing it.

Brings up fond memories of the days when I did internals for a long vanished DBMS firm on PDP-11 and Vax machines. The fine art of building overlay trees and sharing memory regions to get some of the huge programs to fit. Seems fanciful today, packaging multi-megabyte code to run in 64kw of user space. Even had to overlay file buffers and built our own swap handler. One overlay map was over 8 feet long. Modern bloatware is so wasteful and seems to have lost what us oldtimers did to make things work. A memor

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

Entropy requires no maintenance.
		-- Markoff Chaney</div>
        </div>
        
        <div class="card" onclick="openModal('content-27')">
            <div class="source">Slashdot</div>
            <div class="title">Cursor CEO Warns Vibe Coding Builds 'Shaky Foundations' That Eventually Crumble</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-27" style="display:none;">
            <h2>Cursor CEO Warns Vibe Coding Builds 'Shaky Foundations' That Eventually Crumble</h2>
            <p><strong>Slashdot | 2025-12-26</strong></p>
            <a class="original-link" href="https://developers.slashdot.org/story/25/12/26/0623233/cursor-ceo-warns-vibe-coding-builds-shaky-foundations-that-eventually-crumble?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Either that, his company just happens to sell a code management & analysis tool that allegedly reduces the chance of AI code-slop gumming up an app. The fire insurance sales-person likes to remind customers of how hot and dry the weather feels.

Are they insulating themselves from liability?That&#39;s an angle I don&#39;t see mentioned very often when it comes to AI in the work world. The AI companies don&#39;t want to assume liability for anything their creation does (like giving away all the snacks in a vending machine for free, or deleting a bunch of corporate data in a fever dream), but then they try and sell AI as a replacement for humans doing many jobs.Would a company hire a human who preemptively refuses to be held responsibility for their actions on the job?

Are they insulating themselves from liability?

That&#39;s an angle I don&#39;t see mentioned very often when it comes to AI in the work world. The AI companies don&#39;t want to assume liability for anything their creation does (like giving away all the snacks in a vending machine for free, or deleting a bunch of corporate data in a fever dream), but then they try and sell AI as a replacement for humans doing many jobs.

Would a company hire a human who preemptively refuses to be held responsibility for their actions on the job?

Are they insulating themselves from liability?That sounds quite plausible to me. Maybe they finally got some competent legal advice. They sure did not have that before.

Are they insulating themselves from liability?

That sounds quite plausible to me. Maybe they finally got some competent legal advice. They sure did not have that before.

I don&#39;t need AI coding tools to write code for me, I am perfectly capable of doing that myself. Plus there isn&#39;t an AI coding tool on the planet that can do the stuff I do with reverse engineering proprietary file formats, interacting with obscure dead game engines and working with proprietary secret code that no AI would have ever seen before.

I don&#39;t need AI coding tools to write code for me, I am perfectly capable of doing that myself.Yes, but you can&#39;t do it as fast as you can using AI coding tools, according to your boss. He doesn&#39;t have any actual numbers to back up this assertion, and he wouldn&#39;t be looking at the impact on time in the QA/testing phase either. But he&#39;s sure he&#39;s right after talking to that guy he played golf with last month, and is willing to stake your job on it.

I don&#39;t need AI coding tools to write code for me, I am perfectly capable of doing that myself.

Yes, but you can&#39;t do it as fast as you can using AI coding tools, according to your boss. He doesn&#39;t have any actual numbers to back up this assertion, and he wouldn&#39;t be looking at the impact on time in the QA/testing phase either. But he&#39;s sure he&#39;s right after talking to that guy he played golf with last month, and is willing to stake your job on it.

They save a lot of time on boilerplate / web design. That said, Gemini 3 (the current leaderboard champ) tried to talk me into doing something the other day that a junior dev might not have been skeptical enough of to catch, and would have ended with catastrophic downtime due to common exploits.

I am not surprised. The current hype-AI is incapable of writing reliably secure code.

They save a lot of time on boilerplate / web design.How much new boilerplate do you need in a project which you can&#39;t pull from the git repo of your older projects?I don&#39;t see any non-trivial savings that can justify even the $20/mo for the cheapest &quot;copilot&quot; account.

They save a lot of time on boilerplate / web design.

How much new boilerplate do you need in a project which you can&#39;t pull from the git repo of your older projects?

I don&#39;t see any non-trivial savings that can justify even the $20/mo for the cheapest &quot;copilot&quot; account.

I asked Claude to improve the design on a Vue component and it did. It didn&#39;t do any magic, it just looked up what CSS library we were using and it used it as intended (accent colors, primary colors, etc). and threw in some icons.

Could I have done it? Sure. But as a &quot;mostly backend&quot; developer, it would have taken me a lot of time to read the docs and examples. And another good chunk of time to choose the right icons.

Definitely don&#39;t use LLM-generated code without scrutiny, but it&#39;s not bad as a starting point or as a source for potential approaches.  It&#39;s also not bad for code review: I asked gpt-oss to adapt some (not yet tested) code in a certain way, and it noticed a cut-and-paste error in addition to adapting the code.  I ended up not using that adaptation, but the big report was helpful.

One can -- and I think should -- be skeptical of lots of things about LLMs, from business models and environmental impacts to qua

That&#39;s absolutist in a rather silly way.  A number of statistical &quot;machine learning&quot; techniques are correct by construction -- if you ask the right question.  Kernel methods like support vector machines work very well.  If they exhibit a &quot;wrong&quot; answer then it means the original problem included an incorrect assumption or omitted important data -- and any technique is liable to give a wrong answer in those cases.

Sure your coders will be really engaged with 1 million lines of Rust code per month per dev.

Just asking for a friend who&#39;s on that Microsoft team.

That means until we have AGI. For which we do not even know whether it is possible and, if possible, we will not get anytime soon. May be 100 years, 1000 years or &quot;never&quot;.

I really do not understand why so many people are willing to believe AI is all-powerful. There must be a widespread mental defect somewhere that can explain this disconnected belief.

it cost 20 or so amonth and allows me to gereate a framework and do simple crud(kinda). it does save me a lot of time.Now i have yet to see it produce any code that actaully worked with out fixes.

That is really all that is to say here. Well, I would like to see some research into why so many people massively overestimate what LLM-type AI can do. I mean, I took one look and was not impressed. Why do people seem to think that AI needs to be regarded as all-knowing, all-powerful until the converse is proven? And sometimes not even with that proof? I really do not get it.

DOGE To Rewrite SSA Codebase In &#39;Months&#39;[posted on slashdot 2025-03-29]https://developers.slashdot.or... [slashdot.org]

They must have finished it by now. So how did it go? Thought so.

Golden rule of AI:You should never use AI in the domain you yourself have no knowledge or experience in. You should only use it in areas where you have enough expertise to validate its output.

Just because you use AI won&#39;t make you a surgeon or a software engineer.

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

Entropy requires no maintenance.
		-- Markoff Chaney</div>
        </div>
        
        <div class="card" onclick="openModal('content-28')">
            <div class="source">Slashdot</div>
            <div class="title">Apple's App Course Runs $20,000 a Student. Is It Really Worth It?</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-28" style="display:none;">
            <h2>Apple's App Course Runs $20,000 a Student. Is It Really Worth It?</h2>
            <p><strong>Slashdot | 2025-12-26</strong></p>
            <a class="original-link" href="https://apple.slashdot.org/story/25/12/26/041227/apples-app-course-runs-20000-a-student-is-it-really-worth-it?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Second verse, same as the first.A little bit older [slashdot.org] and a little bit worse.

Apple&#39;s App Course Runs $20,000 a Student. Is It Really Worth It?It depends. 

For a hypothetical individual paying for it themselves? No. 

For an individual enrolled in the course, but not paying for it? Maybe. It depends on the what the next best alternative use of that time would be. The &quot;opportunity cost&quot; 

For a hypothetical Fortune 500 company that wants to retrain a developer to do apps for iOS (or macOS, very similar code). Sure, why not. It would probably cost them less than laying off the non-iOS developer and hiring an iOS developer. 

For Apple? Sure, they get to make a &quot;donation&quot; to support a cause yet control where their money goes. iPhones, MacBooks and a very modest stipend. It undermines any grifters trying to do any scamming under the banner of the cause.

Apple&#39;s App Course Runs $20,000 a Student. Is It Really Worth It?

It depends. 

For a hypothetical individual paying for it themselves? No. 

For an individual enrolled in the course, but not paying for it? Maybe. It depends on the what the next best alternative use of that time would be. The &quot;opportunity cost&quot; 

For a hypothetical Fortune 500 company that wants to retrain a developer to do apps for iOS (or macOS, very similar code). Sure, why not. It would probably cost them less than laying off the non-iOS developer and hiring an iOS developer. 

For Apple? Sure, they get to make a &quot;donation&quot; to support a cause yet control where their money goes. iPhones, MacBooks and a very modest stipend. It undermines any grifters trying to do any scamming under the banner of the cause.

To really get your moneys worth you have to take it at least two times. I enrolled in it, and quickly settled into the idea that the first run-through was just going to be practice. The second time is when I really got some &quot;aha!&quot; moments and felt like I understood the material. Mind you, I failed both times .. but I really started to feel value for money in the second round. So yeah, overall I&#39;d say worth it.

Kinda like overthrowing the government, gotta try it a few times to really get your pardon&#39;s worth.

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

Entropy requires no maintenance.
		-- Markoff Chaney</div>
        </div>
        
        <div class="card" onclick="openModal('content-29')">
            <div class="source">Slashdot</div>
            <div class="title">Gmail Users May Soon Be Able To Change Their Email Address and Keep the Old One</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-29" style="display:none;">
            <h2>Gmail Users May Soon Be Able To Change Their Email Address and Keep the Old One</h2>
            <p><strong>Slashdot | 2025-12-26</strong></p>
            <a class="original-link" href="https://it.slashdot.org/story/25/12/26/0155213/gmail-users-may-soon-be-able-to-change-their-email-address-and-keep-the-old-one?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Want to read Slashdot from your mobile device? Point it at m.slashdot.org and keep reading!

There&#39;s no good will here. If you want to change your email address, you either create a new account and abandon the old one, or create a throwaway account and forward all mail to your old one. Either way they lose that precious tracking profile on you and potential ad revenue. Now they&#39;re just plugging that hole so they can keep tracking you while you go by whatever you want.

You must PAY for two mailboxes at PROTONmail ... and alias what alias .This isn&#39;t true.

You must PAY for two mailboxes at PROTONmail ... and alias what alias .

Plus, it doesn&#39;t really fix the real problem that I have with my GMail address. I get tons of spam thanks to my 15 year old e-mail address being part of about 2 dozen security breaches over that time.

What I should really do is just start over and change my e-mail address on most of my commonly used accounts, but even that&#39;s a temporary solution. I know that they&#39;ll be another breach or someone will just flat out sell my e-mail address to a mailing list without my consent.

On the contrary I can&#39;t wait to get my new gmail email address. My email address is ilovebrenda@gmail.com and my new wife has a different name so she hates it.

On the contrary I can&#39;t wait to get my new gmail email address. My email address is ilovebrenda@gmail.com and my new wife has a different name so she hates it.Will she hate it even more when you futureproof the new one to ilovemycurrentwife@gmail.com?
Try ilovemywife@gmail.com and hope she doesn&#39;t think about it too much.

On the contrary I can&#39;t wait to get my new gmail email address. My email address is ilovebrenda@gmail.com and my new wife has a different name so she hates it.

Will she hate it even more when you futureproof the new one to ilovemycurrentwife@gmail.com?
Try ilovemywife@gmail.com and hope she doesn&#39;t think about it too much.

Get the new address and then filter the old one straight to trash.

Presumably it won&#39;t use the &quot;on behalf of&quot; header or whatever it is (original sender maybe) for who it&#39;s from.

It sounds like an alias system which is basically what I would love.     Aliases are simple database entries,  and Ideally they should not even limit us to two..  I would love to have a bunch of alias slots that can be rotated out,  so I can add  and drop various email addresses on a regular basis in order to reduce spam.

Please google.. Let me change my Gmail account&#39;s login email address, but still be able to receive email at the address and manage it like a permanent email alias.   In short,  just because

It sounds like an alias system which is basically what I would love.I have run my own email server for about 20 years now, and I have over 500 email address aliases; a unique one for everyone I have ever emailed. Whenever I start getting spam on one, I know exactly which service was compromised without having to go to haveibeenpwned (it seems like most online services have been compromised). I can disable the email address and create a new one at will (or I just live with it).

It sounds like an alias system which is basically what I would love.

I have run my own email server for about 20 years now, and I have over 500 email address aliases; a unique one for everyone I have ever emailed. Whenever I start getting spam on one, I know exactly which service was compromised without having to go to haveibeenpwned (it seems like most online services have been compromised). I can disable the email address and create a new one at will (or I just live with it).

It was maybe too easy to make another account. They&#39;d rather have your different email addresses explicitly linked.

They could fix the way their system handles email addresses in the first place: firstlast@gmail.com is the same as first.last@gmail.com.  I think there are other variation of this also.

Or better yet, properly implement if the RFCs instead of trying to be different and innovate when they cannot even get the basic right.

They could fix the way their system handles email addresses in the first place: firstlast@gmail.com is the same as first.last@gmail.com.  I think there are other variation of this also.This was actually a quirk that could be used to find who was selling your email address.  Giving different vendors variations of JohnDoe, John.Doe, J.ohndoe, Joh.n.D.o.e, etc helped you determine who valued your information more than your privacy.Another option was to use the Plus addressing.  By adding a &quot;+&quot; and a label (folder) you could direct the email into a specific folder and also track who you gave that address.  JohnDoe+Walmart, JohnDoe+TacoBell, JohnDoe+Sheraton will all arrive in your inbox and if a matching label is found, it will be applied.

They could fix the way their system handles email addresses in the first place: firstlast@gmail.com is the same as first.last@gmail.com.  I think there are other variation of this also.

This was actually a quirk that could be used to find who was selling your email address.  Giving different vendors variations of JohnDoe, John.Doe, J.ohndoe, Joh.n.D.o.e, etc helped you determine who valued your information more than your privacy.

Another option was to use the Plus addressing.  By adding a &quot;+&quot; and a label (folder) you could direct the email into a specific folder and also track who you gave that address.  JohnDoe+Walmart, JohnDoe+TacoBell, JohnDoe+Sheraton will all arrive in your inbox and if a matching label is found, it will be applied.

https://www.howtogeek.com/plus... [howtogeek.com]

There&#39;s nothing to fix. This was a design decision up front to prevent account impersonation and it&#39;s a good one.

That works fine for receiving; less so for sending.  I&#39;m hoping the new feature will have an easy pull-down to select which email address you are sending from without logging out and back in.

Given that already works with aliases you&#39;ve defined in Gmail, I&#39;d think it&#39;s likely to also work with this (hypothesized) upcoming second Gmail address.

I already have a pulldown which lets me send email from five different aliases that deliver to my gmail inbox.  In Settings under &quot;Accounts and Import&quot; there&#39;s a &quot;Send mail as&quot; section for setting this up.

They&#39;re gonna take all the good addresses!

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

Entropy requires no maintenance.
		-- Markoff Chaney</div>
        </div>
        
        <div class="card" onclick="openModal('content-30')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">How the Next Democratic President Must Spend Their First 24 Hours in Office</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-30" style="display:none;">
            <h2>How the Next Democratic President Must Spend Their First 24 Hours in Office</h2>
            <p><strong>News and Politics - Slate Magazine | 2025-12-26</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2025/12/trump-democracy-supreme-court-2028-democrats.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">This week’s Slate Plus bonus episode of Amicus is another entry in our occasional “Dear (Juris)Prudence” series, in which we invite listeners to ask their burning questions about the law and answer them as best we can. Write to amicus@slate.com to pose a question to Dahlia and Mark. This transcript has been edited and condensed for clarity.

Dear (Juris)Prudence,What does recovery look like for us as a nation? Even if we elect a Democratic president, House, and Senate in 2028, how can we legislate or otherwise repair the damage to the law, norms, precedent, etc., when we still have a Supreme Court that ignores law, norms, precedent, and maybe even the 14th Amendment?

Dahlia Lithwick: This is really an existential question as much as a legal one, but I know you’ve given it some thought.

Mark Joseph Stern: I think anyone who cares about salvaging American democracy needs to be asking those exact questions. And it’s pretty clear to me that the very first item on the agenda needs to be envisioning what the next Democratic president—let’s say, President AOC—should do in the first 24 hours of their time in office. That means embracing the maximalist vision of executive power that Trump has established to undo the damage that he is currently inflicting. Trump has amassed vast new powers for the president, and the next Democrat in the White House simply cannot surrender them. That would be unilateral disarmament, and a disservice to the country. What he or she needs to do instead is wield those powers aggressively for good, repair everything that’s broken, help the people Trump has hurt, and push forward with their own goals.

How does that cash out? First, let’s remember that the Supreme Court has now effectively granted the president authority to impound federal funds duly appropriated by Congress and to abolish federal agencies established and funded by Congress. I think that is terrible and anti-constitutional. But thanks to the Supreme Court, that is now the law. So let’s talk about what President AOC can do with those powers in 2029. On Day 1, she needs to impound ICE’s budget. She needs to refuse to spend the billions of dollars that Congress has appropriated to the agency and fire tens of thousands of immigration agents immediately, starting with those who committed acts of violence and discrimination—which, by that point, may be almost all of them. Close as many immigrant detention facilities as possible and free the detainees.

Then turn to Customs and Border Protection. Fire CBP chief Greg Bovino. Fire every single agent who participated in the horrific operations in Chicago, D.C., and L.A. Refuse to pay out a penny in benefits to any agent who broke the law. Release all the information about ICE and CBP’s immigration sweeps, including the names of every agent who participated. Start investigations and prosecutions of any law-breaking agent whom Trump doesn’t pardon. Repurpose the billions of dollars in savings as a reparations fund for every victim. Run the reparations program through a new agency established by executive order. Pay to return noncitizens who were wrongly deported back to the country. Transform ICE and CBP’s headquarters into the nerve center of a new Truth and Reconciliation Agency, and use this extra money to pay out damages to the victims of the mass deportation campaign. This would be 100 percent legal under the precedent established by Trump and the Supreme Court.

Remember: Trump has illegally fired tens of thousands of civil servants, closed agencies like USAID unilaterally, refused to pay out billions of dollars appropriated by Congress, halted our refugee program, shuttered the Education Department, paid reparations to Jan. 6 defendants and quite possibly himself. I think all of that should be illegal, but the Supreme Court has said that it is not. And you just cannot fight fire with a dripping faucet. So I say: Take these powers and use them to undo Trump’s legacy and really flood the zone. Blitz the country with these executive orders on Day 1 and dare anybody to stop you.

At the same time, the next Democratic president is going to be a “unitary executive” thanks to the Supreme Court. So purge every federal agency of Trump holdovers. Start with the Federal Trade Commission, the National Labor Relations Board, every other formerly independent agency. Oust every single Trump appointee at any agency in the executive branch. The Supreme Court is about to let the president do that, and it needs to see the consequences of its actions when the president isn’t named Donald Trump. Take his name off the Kennedy Center, the Institute of Peace, and every other institution that he has illegally branded. This needs to be a top-to-bottom reconstruction of the executive branch using the precedents that Trump himself established. That is the only way a true recovery can begin, and that is what needs to happen within 24 hours of the next Democrat reentering the White House.

I want to hurl myself in front of one objection you’re going to get, which is: But then the Supreme Court’s going to say all of that is illegal! My response is: Good, that’ll take three years to litigate. Run out the clock in the million ways that we have learned that the clock can be run out. And if everything is enjoined on Day 1 by every single Trump judge and then the Supreme Court, then we have another conversation. But I absolutely agree: Democrats should not petition, hands outstretched to the Supreme Court, for the maximalist version of presidential power when it’s not Donald Trump in office. They need to say: Cool, this is what the rule is now. Let’s go.

The other thing I want to say is that baked into Jacob’s question is this issue of: How do we reinstate norms? How do we get the other side to abide by the entire complicated web of unenforceable feelings about, say, a separation between the Justice Department and the White House? And how prosecutors conduct themselves in court? And on and on? If we can learn any lesson from President Joseph Biden’s regime, it’s that you cannot simply adhere to norms and hope the other side will look around and say: Hey, I forgot—norms are awesome! That is not the way to go back to living under soft, unenforceable norms of democracy. You cannot bring a shrimp fork to a knife fight. We have to disabuse ourselves of that idea.

Because norms survive in a system like ours when both sides feel that they have something to gain from them and something to lose when they go away. And right now, under Trump, the Republican Party believes that it can only gain from shattering norms, because Democrats are too timid and afraid of their own shadow. And the only way to disabuse the GOP of that notion is to show them what happens to their side when the norms are gone. We cannot restore the norms magically by having one side abide by them. That would only make things worse by reiterating to the Republican Party that it might as well shatter any norms it wants because Democrats will just go back to abiding by them, even when they constrict the political fortunes and the power of Democratic lawmakers. It can’t work that way. It can only work if Democrats give Republicans a taste of their own medicine and remind them why the norms were there in the first place.

I often say that norms are not an end in themselves. Norms are a means to a larger end, which is a functioning democratic state. And the notion that we can rebuild a world of norms unilaterally is the enduring failure of the Biden administration.

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-31')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">The Annual Conundrums Episode, With Stephen Colbert</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-31" style="display:none;">
            <h2>The Annual Conundrums Episode, With Stephen Colbert</h2>
            <p><strong>News and Politics - Slate Magazine | 2025-12-26</strong></p>
            <a class="original-link" href="https://slate.com/podcasts/political-gabfest/2025/12/politics-emily-john-david-and-stephen-colbert-answer-conundrums-boxing-day?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Emily, John, David, and special guest Stephen Colbert close 2025 by answering listeners’ questions of all kinds.

Please enable javascript to get your Slate Plus feeds.

If you can&#39;t access your feeds, please contact customer support.

Thanks! Check your phone for a link to finish setting up your feed.

Enter your phone number and we&#39;ll text you a link to set up the
        podcast in your app:

We&#39;ll only text you about setting up this podcast, no spam.

Apple Podcasts will only work on MacOS operating systems since Catalina. We do not support Android apps on desktop at this time.

These links will only work if you&#39;re on the device you listen to podcasts on.

We&#39;re sorry, but something went wrong while fetching your podcast feeds. Please contact us at plus@slate.com for help.

This week, Emily Bazelon, John Dickerson, David Plotz, and special guest Stephen Colbert answer listeners’ conundrums of all kinds: the meaningful, the trivial, and the delightfully absurd.

Thanks to all Conundrums contributors: Karl, Elodie, Mitchell, Brian, Phil, Eric, Christian, Kyle, Matthew, Katie, Jesse, John, Bjorn, David, Colin, Alan, Emily, Marie, and Liam!

In the latest Gabfest Reads, John talks with journalist and author Andrew Ross Sorkin about his new book, 1929: Inside the Greatest Crash in Wall Street History and How It Shattered a Nation — the story of speculation, debt, and the human drives that fueled the Wall Street crash that changed everything.

Email your chatters, questions, and comments to gabfest@slate.com. (Messages may be referenced by name unless the writer stipulates otherwise.)

Podcast production by Nina Porzucki with live show support from Katie Rayford and the team at the New York Society for Ethical Culture

You can find the full Political Gabfest show pages here.

Want more Political Gabfest? Join Slate Plus to unlock weekly bonus episodes. Plus, you’ll access ad-free listening across all your favorite Slate podcasts. You can subscribe directly from the Political Gabfest show page on Apple Podcasts and Spotify. Or visit slate.com/gabfestplus to get access wherever you listen.

Find out more about David Plotz’s monthly tours of Ft. DeRussy, the secret Civil War fort hidden in Rock Creek Park.

Voted “Favorite Political Podcast” by Apple Podcasts listeners. Stephen Colbert says, &quot;Everybody should listen to the Slate Political Gabfest.&quot; The Gabfest is hosted by Emily Bazelon, John Dickerson, and David Plotz. Listen for the debates, stay for the cocktail chatter.

David Plotz is a host of the Slate Political Gabfest and the CEO of City Cast.

Emily Bazelon is a staff writer at the New York Times Magazine, the author of Charged and Sticks and Stones, and co-host of the Slate Political Gabfest.

John Dickerson is host of CBS News Prime Time With John Dickerson, co-host of the Slate Political Gabfest, host of the Whistlestop podcast, and author of The Hardest Job in the World.</div>
        </div>
        
        <div class="card" onclick="openModal('content-32')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">What Is Another Term for <em>Pyrosis</em>?</div>
            <div class="meta">2025-12-25</div>
        </div>
        
        <div id="content-32" style="display:none;">
            <h2>What Is Another Term for <em>Pyrosis</em>?</h2>
            <p><strong>News and Politics - Slate Magazine | 2025-12-25</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2025/12/trivia-quiz-daily-slate-science-astronomy-medicine-geology.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Please enable Javascript in your browser to view Slate interactives.

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-33')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">A Rabbi’s Plea for Peace | 2025 in Review</div>
            <div class="meta">2025-12-25</div>
        </div>
        
        <div id="content-33" style="display:none;">
            <h2>A Rabbi’s Plea for Peace | 2025 in Review</h2>
            <p><strong>News and Politics - Slate Magazine | 2025-12-25</strong></p>
            <a class="original-link" href="https://slate.com/podcasts/what-next/2025/12/gaza-israel-rabbi-peace-starvation?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">More than a thousand Jewish leaders want an end to starvation in Gaza. She’s one of them.

Please enable javascript to get your Slate Plus feeds.

If you can&#39;t access your feeds, please contact customer support.

Thanks! Check your phone for a link to finish setting up your feed.

Enter your phone number and we&#39;ll text you a link to set up the
        podcast in your app:

We&#39;ll only text you about setting up this podcast, no spam.

Apple Podcasts will only work on MacOS operating systems since Catalina. We do not support Android apps on desktop at this time.

These links will only work if you&#39;re on the device you listen to podcasts on.

We&#39;re sorry, but something went wrong while fetching your podcast feeds. Please contact us at plus@slate.com for help.

All this week, What Next and What Next: TBD are re-airing some of our favorite conversations from throughout the year and checking back with the people in those conversations to see how things have – or haven’t – changed. This episode is from August.

More than a thousand rabbis and Jewish leaders have signed a letter calling for Israel to end “the use and threat of starvation as a weapon of war.” This New York rabbi, who has felt a connection to Israel her whole life, explains why she signed.

Guest:  Sarah Reines, rabbi at Temple Emanu-El in Manhattan.

If you want to support more of this reporting, in 2026 and beyond, consider signing up for Slate Plus. You’ll enjoy ad-free listening across the Slate network, early access to tickets for live events, and you’ll never hit the paywall on the site.

We’re on a mission to get 100 people to join Slate Plus before the new year—and we’re even offering a 50-percent-off deal to folks who join us right now. Visit Slate.com/whatnextplus and use the code WHATNEXT50 to get a year of Slate Plus for $59.

Podcast production by Ethan Oberman, Elena Schwartz, Paige Osburn, Anna Phillips, Madeline Ducharme, and Rob Gunther.

The problem with the news right now? It’s everywhere. And each day, it can feel like we’re all just mindlessly scrolling. It’s why we created What Next. This short daily show is here to help you make sense of things. When the news feels overwhelming, we’re here to help you answer: What next? Look for new episodes every weekday morning.

Rob Gunther is a senior producer of What Next, Slate’s daily news podcast. He has worked on news podcasts and radio at Slate, Business Insider, Apple News, and WNYC.</div>
        </div>
        
        <div class="card" onclick="openModal('content-34')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">Who Was the First Wife of King Henry VIII?</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-34" style="display:none;">
            <h2>Who Was the First Wife of King Henry VIII?</h2>
            <p><strong>News and Politics - Slate Magazine | 2025-12-24</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2025/12/trivia-quiz-daily-slate-history-cabinet-scandal-monarchy.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Please enable Javascript in your browser to view Slate interactives.

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-35')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">Gutting Our National Parks | 2025 Year in Review</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-35" style="display:none;">
            <h2>Gutting Our National Parks | 2025 Year in Review</h2>
            <p><strong>News and Politics - Slate Magazine | 2025-12-24</strong></p>
            <a class="original-link" href="https://slate.com/podcasts/what-next/2025/12/trump-national-parks-service-review?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">“America’s best idea” slams into some of its worst tendencies.

Please enable javascript to get your Slate Plus feeds.

If you can&#39;t access your feeds, please contact customer support.

Thanks! Check your phone for a link to finish setting up your feed.

Enter your phone number and we&#39;ll text you a link to set up the
        podcast in your app:

We&#39;ll only text you about setting up this podcast, no spam.

Apple Podcasts will only work on MacOS operating systems since Catalina. We do not support Android apps on desktop at this time.

These links will only work if you&#39;re on the device you listen to podcasts on.

We&#39;re sorry, but something went wrong while fetching your podcast feeds. Please contact us at plus@slate.com for help.

All this week, What Next and What Next: TBD are re-airing some of our favorite conversations from throughout the year and checking back with the people in those conversations to see how things have – or haven’t – changed. This episode is from August.

From the Statue of Liberty to the Golden Gate Bridge, and places in between like Yellowstone and the site of the Battle of Gettysburg, the National Park Service has been a point of American pride since its inception. And with a small budget and actually generating revenue, even fiscal hawks had no reason to complain.

So why is the Trump administration cutting their budget?

Jon B. Jarvis,18th director of the National Parks.

Kevin Heatley, former superintendent of Crater Lake National Park, Oregon.

If you want to support more of this reporting, in 2026 and beyond, consider signing up for Slate Plus. You’ll enjoy ad-free listening across the Slate network, early access to tickets for live events, and you’ll never hit the paywall on the site.

We’re on a mission to get 100 people to join Slate Plus before the new year—and we’re even offering a 50-percent-off deal to folks who join us right now. Visit Slate.com/whatnextplus and use the code WHATNEXT50 to get a year of Slate Plus for $59.

Podcast production by Ethan Oberman, Elena Schwartz, Paige Osburn, Anna Phillips, Madeline Ducharme, and Rob Gunther.

The problem with the news right now? It’s everywhere. And each day, it can feel like we’re all just mindlessly scrolling. It’s why we created What Next. This short daily show is here to help you make sense of things. When the news feels overwhelming, we’re here to help you answer: What next? Look for new episodes every weekday morning.

Mary Harris is the host and managing editor of What Next, Slate&#39;s new daily news podcast. She has reported throughout the public radio system, for NPR, Marketplace, and WNYC.</div>
        </div>
        
        <div class="card" onclick="openModal('content-36')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">Researchers create world's smallest programmable, autonomous robots</div>
            <div class="meta">2025-12-25</div>
        </div>
        
        <div id="content-36" style="display:none;">
            <h2>Researchers create world's smallest programmable, autonomous robots</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2025-12-25</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2025-12-world-smallest-programmable-autonomous-robots.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-37')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">How ChatGPT could change the face of advertising, without you even knowing about it</div>
            <div class="meta">2025-12-25</div>
        </div>
        
        <div id="content-37" style="display:none;">
            <h2>How ChatGPT could change the face of advertising, without you even knowing about it</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2025-12-25</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2025-12-chatgpt-advertising.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-38')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">First Bond game in a decade hit by two-month delay</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-38" style="display:none;">
            <h2>First Bond game in a decade hit by two-month delay</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2025-12-24</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2025-12-bond-game-decade-month-delay.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-39')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">AI overestimates how smart people are, according to economists</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-39" style="display:none;">
            <h2>AI overestimates how smart people are, according to economists</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2025-12-24</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2025-12-ai-overestimates-smart-people-economists.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-40')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">For computational devices, talk isn't cheap: Research reveals unavoidable energy costs across all communication channels</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-40" style="display:none;">
            <h2>For computational devices, talk isn't cheap: Research reveals unavoidable energy costs across all communication channels</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2025-12-24</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2025-12-devices-isnt-cheap-reveals-unavoidable.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-41')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">Redesigned carbon molecules boost battery safety, durability and power</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-41" style="display:none;">
            <h2>Redesigned carbon molecules boost battery safety, durability and power</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2025-12-24</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2025-12-redesigned-carbon-molecules-boost-battery.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-42')">
            <div class="source">The Register</div>
            <div class="title">Coming Wi-Fi 8 will bring reliability rather than greater speed</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-42" style="display:none;">
            <h2>Coming Wi-Fi 8 will bring reliability rather than greater speed</h2>
            <p><strong>The Register | 2025-12-26</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2025/12/26/coming_wifi_8_reliability/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Wi-Fi 8 will be a step change in connectivity, if Intel can be believed, and will be able to adapt intelligently to local conditions to deliver a reliable service without the slowdowns users often experience when the network is congested.

The next-gen release of Wi-Fi is not expected to be available in devices for a couple of years, but the industry seems determined that it will fix the issues that meant previous releases did not always live up to user expectations.

&quot;The focus of Wi-Fi has always been on: how can we make it faster? You&#39;ll see that with Wi-Fi 8, that&#39;s going to change a little bit,&quot; said Intel Fellow and wireless chief technology officer Carlos Cordeiro.

This means that the upcoming standard will not increase the peak theoretical data rate and will not introduce wider channels, or higher order modulations compared with Wi-Fi 7. Instead, the new capabilities will be subtler.

&quot;What you&#39;re going to see is that we can get better rate at a given range. What I mean by that is, if you take an access point (AP) and a Wi-Fi 7 device, and you get a given data rate, then you replace that with a Wi-Fi 8 device, you&#39;ll be able to get a higher data rate at that same location, at that same range.&quot;

Cordeiro says that Intel sees Wi-Fi 8 as the &quot;connective technology for the AI era,&quot; one where in the not-too-distant future, everyone will have massive amounts of compute and storage available to them over the network, and this means that you can&#39;t allow the wireless connection to become the bottleneck to accessing all those resources.

&quot;So you really need high performance, which you know, Wi-Fi largely already is. But we need to make it more reliable. We need to make it more low latency. We need to make it, you know, more intelligent,&quot; he explained.

This means making devices and the network kit more context-aware, able to predict user needs, and adapt to them.

Cordeiro highlighted use cases that illustrate the challenges Wi-Fi 8 is aiming to address for users.

The first one is operating on a campus network, such as a university or corporate office site. Here, roaming and co-existence are key capabilities, but it currently can take tens of milliseconds for roaming from one AP to another to happen.

&quot;So we took a very conscious effort in Wi-Fi 8 to define something we call seamless roaming, where we&#39;re going to push down to the Wi-Fi technology a lot of the key negotiations and preparation for roaming, so that we can get it into single-digit low milliseconds, and do that with zero packet loss, right? So that if you&#39;re doing Wi-Fi calling, you can move from one AP to the other, and you won&#39;t notice the switch.&quot;

In a home environment, you might have someone on a conference call, someone else playing a game and another person watching a Netflix video. In situations like this, where there is a mix of traffic, you have to be able to prioritize, Cordeiro says, and so Wi-Fi 8 will have much better capabilities around quality of service, to be able to indicate low latency traffic and allow the network to prioritize it.

&quot;How can we deal with the fact that some devices are very high-end, some devices are very low-end, but they are in the same network, and you want to make sure that those low-end devices don&#39;t clog the channel, that everybody can get access and make better use of the spectrum,&quot; he explained.

This is also an area of focus in crowded office environments, where interference management and longer device battery life are desirable.

Another technology being developed with Wi-Fi 8 is the ability to sense the environment using the radio waves emitted by the devices.

&quot;We expect to see Wi-Fi devices able to detect the distance to other devices that are nearby, not only the distance, but what is the direction to those devices, with the ability to become a sensor to detect distance, to detect the presence of people, to detect gestures,&quot; Cordeiro claimed.

&quot;Essentially what we are doing is that we&#39;re going to be able to make devices be context aware, aware of their surroundings, and that&#39;s going to enable and open up the ability for new applications to be developed,&quot; he added.

One such scenario Cordeiro suggests is one where a user is in an online meeting on their laptop, and gets up and walks away holding their phone.

&quot;Automatically, the laptop and the phone will realize that they are moving away from each other, and this Teams session could transfer to my phone. I don&#39;t have to do anything automatically. I move away, the Teams session goes to my phone, and then when I come back to my PC, the Teams session automatically transfers back to the PC,&quot; he explained.

Others include waking up your PC when you approach it, or having it automatically lock itself if you walk away, or even detecting and acting on gestures, such as swiping to move to the next slide in a presentation.

In an Intel White Paper on Wi-Fi 8, the company lists some of the enhancements that aim to deliver these capabilities. Link reliability and performance will be improved through smarter use of modulation and coding schemes (MCS), for example.

Currently, if a device supports multiple spatial streams (MIMO), all streams use the same coding scheme. Wi-Fi 8 changes this so each stream can use the best possible encoding for its conditions, meaning that if one stream has a weaker signal, it can send data in a more robust way while other streams use an MCS optimized for speed.

Wi-Fi 8 adds more intermediate modulation steps, which means that medium signal strength users should see a better data rate than with Wi-Fi 7, who may have to choose a less optimal modulation.

It also promises better error correction via low-density parity check (LDPC) codewords that are double the length of those in Wi-Fi 7, meaning fewer retransmissions and a connection that can extend further.

Multiple access points will also be able to work together to optimize transmissions, making sure they do not transmit at the same time on the same channel, for example. With an enterprise network, two APs might take turns millisecond by millisecond, which avoids collisions, and devices therefore waste less time waiting and retrying.

Giving better access for critical applications will come via an enhanced version of EDCA (Enhanced Distributed Channel Access) called Prioritized EDCA. Under this, if a device marks traffic as high priority (like video), the network will let those packets through first even in crowded conditions, Intel says.

Security is also being stepped up in Wi-Fi 8 with encryption for control frames, which prevents spoofing attacks such as fake disconnect messages. Support for IEEE P802.11bi will extend protection to the association process and other management frames that were previously exposed, providing stronger encryption for Wi-Fi handshakes and improving privacy.

As previously noted, Wi-Fi 8 will build on the basic specifications of Wi-Fi 7, which is still being gradually adopted in new devices and access points / wireless routers. This means that it will be capable of operating in the 2.4 GHz, 5 GHz, and 6 GHz bands of the wireless spectrum, and uses 320 MHz channel bandwidth, double that of previous releases.

According to Intel, it will be backwards compatible, in the sense that Wi-Fi 5/6/7 devices will work with Wi-Fi 8 APs (and vice versa), just without the benefits of the new capabilities.

Chipmaker Broadcom recently announced a portfolio of Wi-Fi 8 silicon, but Cordeiro said Intel was holding off until the availability of certification, because certification guarantees a minimal level of interoperability.

&quot;We want to avoid any problems in the market. We want to make sure that clients and access points from various vendors work seamlessly, and so in our case, we do expect to have solutions once certifications are in place,&quot; he said.

Intel&#39;s pitch for Wi-Fi 8 is that it will &quot;just feel better,&quot; taking the raw speed of Wi-Fi 7 and adding intelligence to deliver that speed consistently, keeping latency-sensitive apps running without hiccups. The proof of the pudding, of course, will be in the eating. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-43')">
            <div class="source">The Register</div>
            <div class="title">'PromptQuest' is the worst game of 2025. You play it when trying to make chatbots work</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-43" style="display:none;">
            <h2>'PromptQuest' is the worst game of 2025. You play it when trying to make chatbots work</h2>
            <p><strong>The Register | 2025-12-26</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2025/12/26/ai_is_like_adventure_games/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Opinion When Microsoft recently decided to open source the seminal text adventure game Zork, I contemplated revisiting it during the festive season... until I realized I&#39;ve spent much of 2025 experiencing the worst of such games when using AI chatbots.

Adventure games like Zork and its many imitators invited players to explore a virtual world, often a Tolkien-esque cave, that existed only as words.

&quot;You enter a dark room. A Goblin pulls a rusty knife from its belt and prepares to attack!&quot; was a typical moment in such games. Players, usually armed with imagined medieval weapons, might respond &quot;Hit Goblin&quot; in the expectation that phrase would see them draw a sword to smite the monster.

But the game might respond to &quot;Hit Goblin&quot; by informing players &quot;You punch the Goblin.&quot;

The Goblin would dodge the punch and stab the player with the rusty knife.

Game over... until the player tried &quot;Hit Goblin with sword&quot; or &quot;Stab Goblin&quot; or whatever other syntax the game required, assuming they didn&#39;t just give up out of frustration at having to guess the correct verb/noun combination.

Adventure games were big in the 1980s, a time when computers were flaky and unpredictable, and AI was an imagined technology. Games that required obscure syntax were mostly tolerable and generally excused.

I&#39;m less tolerant of AI making me learn its language.

For example, I recently prompted Microsoft&#39;s Copilot chatbot to scour data available online and convert some elements of it into a downloadable spreadsheet. The bot accepted that request and produced a Python script that it claimed will write a spreadsheet.

In other AI experiments, I have found that the same prompt produces different results on different days. One prompt I use to check I haven&#39;t left any terrible typos in stories produces responses in a different format every time I use it. Microsoft has also, in its wisdom, decided to offer different versions of Copilot in Office and in its desktop app. Each produces different results from the same prompt and the same source material.

Using AI has therefore become a non-stop experiment in &quot;Hit/Kill/Stab/Smite Goblin.&quot;

And when Copilot starts using a new model, which it does without any change to its UI, prompts that worked reliably in the past produce different results, meaning I need to relearn what works.

My point here is not that chatbots do dumb things and make mistakes. It&#39;s that working with this tech feels like groping through a cave in the dark – a horrible game I call &quot;PromptQuest&quot; – while being told this is improving my productivity.

After Copilot gave me a Python script instead of a spreadsheet, I played a long session of PromptQuest during which Microsoft&#39;s AI responded to many different prompts by repeatedly telling me it was ready to make a spreadsheet, would make it available to download, and had completed the job to my satisfaction.

It never delivered the spreadsheet, and my frustration grew to the point at which I instructed Copilot to produce a progress bar so I could see it work.

A progress bar produced by Microsoft Copilot

You can see the results above. Ironically, I think it looks a lot like the output of a text adventure game. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-44')">
            <div class="source">The Register</div>
            <div class="title">IT team forced to camp in the office for days after Y2K bug found in boss's side project</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-44" style="display:none;">
            <h2>IT team forced to camp in the office for days after Y2K bug found in boss's side project</h2>
            <p><strong>The Register | 2025-12-26</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2025/12/26/on_call/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">On Call Y2K December 26th is a holiday across much of the Reg-reading world, but it&#39;s also a Friday – the day on which we present a fresh instalment of On Call, the reader-contributed column that recounts your tales of tech support encounters and exasperation.

This holiday season we&#39;re dipping into tales of tech support in the time of Y2K, starting with this tale from a reader we&#39;ll Regomize as &quot;Cane&quot; and who told us that in December 199 he worked in the IT department at the UK branch of a &quot;multinational booze purveyor.&quot;

Cane said he and his team felt confident.

&quot;We spent much of the last two years testing and verifying everything, upgrading and replacing as needed,&quot; he told On Call.

Senior management came to appreciate the importance of the task and to make sure all staff understood the seriousness of the Y2K remediation effort, commissioned a custom screensaver that displayed a countdown to the fateful moment.

The alcohol making organization prevented the IT team from taking leave for two weeks after December 31st and warned they may need to be on-site full time for the duration in case things went wrong.

&quot;They also hired consultants at ruinous cost to sit there and wear suits,&quot; Cane told On Call. &quot;As the hour ticked closer, we were ordered by the Top Floor People to physically disconnect the network cable from the internet, to prevent little viruses from crawling down the wires and getting us.&quot;

All present watched the clock tick down from 1999 to 2000, then breathed a sigh of relief when nothing happened.

&quot;After an hour we were allowed to reconnect to the outside world and confirm that the world had not ended,&quot; Cane told On Call.

&quot;Any PC that had been left switched on – against instructions – mysteriously crashed,&quot; Cane wrote.

In case your career started after the year 2000 or you&#39;ve forgotten the Y2K mess, let&#39;s refresh your memory … by explaining that in the early years of computing, memory was so scarce and expensive that programmers used only two digits to record years.

That became an issue as the year 2000 approached, because as the clock ticked over into the new year some programs would assume it was the year 1900 and malfunction … perhaps catastrophically.

All around the world, organizations spent billions testing and remediating their code. And on New Year&#39;s Eve 1999, many IT pros worked instead of partying, to make sure skilled help was at hand in case things went bad.

The IT team swung into action and rebooted the nearest machine, which came back to life and displayed a screensaver that was now counting backwards into negative numbers.

Cane later learned that the developer of the Y2K screensaver did not test it for the Y2K bug.

&quot;It was created, at high cost, by an external and apparently incompetent third party,&quot; he told On Call.

Cane&#39;s company kept the tech team camping in the office for a couple of days, until it became clear nothing else would break.

&quot;We returned to normal, though the consultants were maybe a bit more flush in the bank account,&quot; Cane reported. &quot;Us poor salaried employees had to make do with time-off-in-lieu.&quot;

Have you worked tech support during a major event or holiday period? If so, click here to send email to On Call so we can share your story! ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-45')">
            <div class="source">The Register</div>
            <div class="title">Humanoid robots are still novelty acts, but investment is surging to make them real tomorrow</div>
            <div class="meta">2025-12-25</div>
        </div>
        
        <div id="content-45" style="display:none;">
            <h2>Humanoid robots are still novelty acts, but investment is surging to make them real tomorrow</h2>
            <p><strong>The Register | 2025-12-25</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2025/12/25/humanoid_robots_investment_surge/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">By the time the humanoid robots arrived at the Humanoids Summit at the Computer History Museum in Mountain View, California, on December 11, the registration line had already extended downstairs to the lobby.

Controlled by accompanying human handlers, the humanoids were herded into the elevator, sparing them the challenge of climbing the stairs to the mezzanine registration desk.

&quot;No one shows you climbing stairs when it comes to these humanoids,&quot; observed Abhinav Gupta, co-founder of Skild AI, during a presentation later that morning.

Gupta did, though, in a video demonstrating how the Skild foundation model can help a robot to climb stairs and step over unstable terrain.

Humanoids Summit chair and founder Modar Alaoui, general partner at ALM Ventures, a VC firm backing several attending companies, would later remark, &quot;Locomotion is a solved problem.&quot;

Image of a humanoid robot arriving at the Humanoids Summit - Click to enlarge

That&#39;s a slight exaggeration. Humanoid robots are ready for marketing and experimentation. In promotional videos, they perform impressive, potentially useful feats. But commercial deployment at scale will take decades, even if persistent technical challenges like manual dexterity may be solved sooner.

The technology isn&#39;t yet good enough, the cost remains too high, and organizations need to figure out how to use them. More work needs to be done on safety, and people aren&#39;t yet ready to accept them.

Gupta followed a presentation by Ani Kelkar and Mikael Robertson, partner and senior partner respectively at McKinsey & Company, a corporate consultancy known for advocating staff cuts that itself has been trimming staff due to AI.

Speaking from a management perspective, Robertson said, &quot;Looking at the US as an example, only about 6 percent of factories today have applied robotic automation at scale ... And by comparison, China today is installing 10 times more robots each year than the US.&quot;

Robertson said that interest and investment in humanoid robotics have surged.

Kelkar said there are about 50 companies credibly doing so – about 20 in China, 15 in North America, 7 in EMEA, and 7 in Asia (outside of China).

&quot;With all of that talent and all of the investments that Mikael talked about, we are excited that we are finally going to get solutions that will work,&quot; said Kelkar.

Not immediately though. Beyond the difficulty of deploying any sort of robot at scale, Kelkar suggested the viability of robots may depend on human labor management.

&quot;So in a warehousing context, if you have a turnover rate at 40 percent, you take one or two months, you hire someone, you train them up, and five months later, that cycle repeats,&quot; he explained. &quot;And that becomes a significant drag on industrial productivity.

&quot;And I think fundamentally leaders are recognizing that the reason to leverage robotics and automation is not for worker replacement, it&#39;s for redesigning the nature of work. It&#39;s to enhance the work that human labor does, and bring robots even as tools and teammates, not necessarily a job displacement member.&quot;

Pitching a human-robot detente appears to be advisable because humans represent one of several obstacles that humanoid robot makers need to consider.

During a panel discussion led by Washington Post reporter Gerrit de Vynck, Jeff Pittelkow, managing director for Roboworx, a robot management service, said that robot customers would be happy to replace humans with robots in the workplace.

&quot;Customers are very ROI focused, right?&quot; he said. &quot;I mean, a humanoid robot is probably going to replace a human. You know, that&#39;s the dirty little secret. So the ROI has to be &#39;the humanoid robot has to do 100 percent of what the human can do for no more money than a human costs.&#39;&quot;

Pittelkow said companies buying these robots, or planning to do so, don&#39;t care if the robot is teleoperated or autonomous, as long as the price is right.

But human workers have proven reluctant to contribute to their replacement. Pittelkow said that people can present an obstacle to deployment.

&quot;The co-workers, as we call them, of the robots,&quot; he said, &quot;they are not super-accepting. They see [robots] as a threat ... They&#39;re hesitant. &#39;This robot&#39;s coming here, and eventually I&#39;m not going to have a job because this robot&#39;s going to have a job.&#39; So that&#39;s something we have to help everybody get over.&quot;

That antipathy toward robots may manifest as sabotage or neglect. Human workers, he said, &quot;have no problem sabotaging the robot. They have no problem with the robot being broken, sitting in a corner. We see that all the time.&quot;

In one case, Pittelkow said, staff put a sign on a robot that said, &quot;On Strike,&quot; and left it in a corner. Or, he suggested, human workers may just decide to neglect updates to mapping localization or firmware and to avoid reporting failures.

Anyone planning to deploy humanoid robots, he said, should be aware of this dynamic.

&quot;So that has to be a huge part of your business model when you get to scale in production,&quot; he said.

As if social acceptance weren&#39;t enough of a challenge, the enabling technology isn&#39;t there yet. And this affects whether robots are worthwhile financially.

Pittelkow pointed to a robot his company has working inside a movie theater to deliver food.

&quot;It&#39;s one of those movie theater restaurants,&quot; he explained. &quot;And unsurprisingly, in hindsight, it keeps sucking up popcorn into its drive wheels as it drives through the movie theater. And that&#39;s problematic. I mean, popcorn gets smushy and it&#39;s oily and it causes real problems.&quot;

His company also runs an autonomous mobile robot (AMR) in a high-end restaurant – a wheeled unit rather than humanoid.

&quot;We go there to do our maintenance check on this robot ... and an employee came up to us and said, &#39;Oh, I think that&#39;s the one I saw the mouse run out of.&#39; This is a five-star restaurant, let me make that clear. And a mouse had gotten in and had eaten all the internals of that AMR. And it was a total loss.&quot;

Pittelkow asked, &quot;Is your humanoid going to survive a mouse attack while it&#39;s sitting there overnight? And what&#39;s the cost of downtime? And that&#39;s the big thing. ROI is all about uptime.&quot;

During that same panel discussion, Joe Michaels, senior global VP of sales and marketing at 1HMX, cited Gupta&#39;s challenge to robot makers to prove that their bots can manage stairs and urged conference attendees to apply a similarly critical eye to the types of manual interactions depicted in robot videos.

&quot;We&#39;re still mostly at the parallel gripper stage,&quot; he said. &quot;And if parallel grippers were good enough to run and build the world, I think God would have given all of us two digits instead of five with opposable thumbs.&quot;

Alaoui, in a session that followed, would echo that assessment. &quot;Dexterity is the last frontier,&quot; he said.

In the conference exhibition hall, an ALM Ventures-funded robot torso underscored that point by folding shirts very slowly and not all that well.

Data availability represents another barrier – the machine learning models intended to replicate human activity have to be fed with vast quantities of data in order to improve to the level of commercial viability. Gathering that information will require a lot of trial and error.

Humanoid robots face a long apprenticeship as jesters and novelty acts before they&#39;re taken seriously. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-46')">
            <div class="source">The Register</div>
            <div class="title">AMD Strix Halo vs Nvidia DGX Spark: Which AI workstation comes out on top?</div>
            <div class="meta">2025-12-25</div>
        </div>
        
        <div id="content-46" style="display:none;">
            <h2>AMD Strix Halo vs Nvidia DGX Spark: Which AI workstation comes out on top?</h2>
            <p><strong>The Register | 2025-12-25</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2025/12/25/amd_strix_halo_nvidia_spark/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Hands On Most GenAI models are trained and run in massive datacenter clusters, but the ability to build, test, and prototype AI systems locally is no less relevant today.

Until recently, this required high-end, multi-GPU workstations often costing tens of thousands of dollars. With the launch of the GB10-based DGX Spark in October, Nvidia set out to change this. While nowhere near as powerful, with 128 GB of video memory, the system is essentially an AI lab in a box capable of running just about any AI workload you throw at it.

As we mentioned in our initial hands-on, the Spark isn&#39;t the first or even the cheapest option out there. AMD and Apple also offer systems with large quantities of unified memory which are shared between the CPU and GPU, something that has made them incredibly popular among AI developers and enthusiasts.

AMD&#39;s Ryzen AI Max+ 395 APU, which for the sake of brevity we&#39;re simply going to refer to as &quot;Strix Halo&quot; from here on out, is particularly interesting. In addition to selling for between three-quarters and half the cost of the Spark, Strix Halo builds on roughly the same ROCm and HIP software stack as the company&#39;s datacenter products. This provides a clearer, though not necessarily seamless migration path from desktop to datacenter.

To see how Strix Halo stacks up against the Spark, HP sent over its Z2 Mini G1a workstation so we could find out how each of these little boxes of TOPS fares in a variety of AI workloads, ranging from single-user and batched inference to fine-tuning and image generation.

Compared to the Spark, HP&#39;s Z2 Mini G1a is a fair bit bigger thanks in part to its integrated PSU and larger cooling solution

The first thing you&#39;ll notice is the HP is significantly larger than the Spark. This is partly because Nvidia opted for an external power brick that connects over USB-C while HP opted for a slightly larger chassis with an integrated power supply.

We generally prefer HP&#39;s approach here, especially because the larger chassis allows for a beefier cooling solution, though the Spark&#39;s fit and finish definitely comes across as the more premium of the two.

While the Spark uses an all-metal chassis that doubles as a heat sink, the G1a feels much more like an HP product with a clean albeit plastic shell covering a stiff metal chassis. The benefit of this design philosophy is serviceability. Getting into the G1a is as easy as pressing a button at the back of the machine sliding off the top cover.

However, because the machine uses soldered LPDDR5x memory, there&#39;s not actually that much to do in either system. The HP does feature two standard 2280 PCIe 4.0 x4 M.2 SSDs which are user-serviceable.

For comparison, the Spark is much more appliance-like, though the SSD can also be swapped by removing a magnetic plate and four screws at the bottom of the system.

HP&#39;s design is far easier than the Spark to service with a lid that removes with a press of a button

Inside the machines are a pair of blower fans which pull in cool air from the front and exhaust it out the back. If you&#39;re curious, the G1a&#39;s dual M.2 SSDs are located directly under those fans, which should keep them from overheating under heavy load.

Around the back of the machines, we see HP has taken a very different approach to Nvidia in terms of I/O.

While the Spark prioritizes high-speed networking, the I/O on HP&#39;s G1a is far more pedestrian

From left to right, we see a 2.5 GbE RJ45 port, four standard USB ports (2x 10 Gbps, 2x USB 2.0), a pair of 40 Gbps Thunderbolt ports alongside two mini DisplayPorts. On the side of the machine, you&#39;ll find a 3.5 mm headphone-microphone combo jack and two additional 10 Gbps USB 3.0 ports in both standard and USB-C form factors.

You&#39;ll also notice two blank spaces that can be configured with any number of HP&#39;s Flex IO modules, including serial, USB, and gigabit, 2.5 GbE or 10 GbE ports.

The Spark, meanwhile, prioritizes high-speed networking for multinode AI compute environments. Alongside the power button are four USB-C ports, the leftmost of which is used for power delivery. For display out, there&#39;s an HDMI port along with a 10 GbE RJ45 network port and a pair of QSFP cages offering a combined 200 Gbps of network bandwidth via the system&#39;s onboard ConnectX-7 NIC.

These ports are designed to enable clustering of multiple Spark or other GB10 systems using the same hardware and software you&#39;d find in the datacenter.

As we understand it, you could also use the G1a&#39;s Thunderbolt ports as a high-speed network interface for interconnecting multiple systems together, though we weren&#39;t able to test that use case.

To be clear, neither system is the cheapest chariot for their respective silicon. The DGX Spark retails for $3,999 while HP&#39;s Z2 Mini G1a, as specced, is currently selling for about $2,950.

You can find similarly equipped GB10 and Strix Halo boxes that can be had for significantly less if you&#39;re willing to compromise on storage, connectivity, or I/O.

HP, ASUS, and a few others have OEM versions of the Spark that start around $3,000 for 1 TB of storage. We&#39;ve also seen Strix Halo systems with 128 GB for a little over $2,000, though the memory shortage appears to have driven up prices some, and you&#39;ll be missing out on the Enterprise features like remote management or memory encryption offered by the &quot;Pro&quot; variant of the chip.

So, if either of these systems strike your fancy, but you&#39;re unconvinced by the pricing, you may be able to find a better deal from one of the other OEMs. In the case of the GB10 systems, you&#39;re not giving up much apart from aesthetics, opting for an OEM rebadge over the Founders Edition.

Before we dig into generative AI performance, which we expect most folks to care about, we&#39;d like to take a moment to talk about the machines&#39; respective CPUs.

Strix Halo is a rather interesting processor. Much like its desktop counterparts, it features 16 full-fat Zen 5 cores spread across two core-complex dies (CCDs) that are capable of clocking to 5.1 GHz. Those CCDs are bonded using advanced packaging to an I/O die that handles memory, PCIe, and graphics processing.

The Z2 Mini G1a actually uses the Pro variant of the chip, which adds a number of hardware security and management capabilities, which may be attractive to enterprises deploying these systems in volume or in sensitive environments.

The Spark&#39;s GB10 Grace Blackwell superchip meanwhile features an Arm CPU die developed in collaboration with MediaTek containing 10 X925 performance cores and 10 Cortex A725 efficiency cores for a total of 20.

While these cores are by no means slow, in our admittedly limited testing, AMD&#39;s Zen 5 microarchitecture delivered between 10 and 15 percent higher performance across our Sysbench, 7zip compression/decompression, and HandBrake transcoding workloads.

However, in the High-Performance Linpack benchmark, which is representative of many HPC workloads, the G1a achieved more than twice the double-precision performance at 1.6 teraFLOPS versus 708 gigaFLOPS on the Spark. We&#39;ll note that this score was achieved using only the X925 cores as enabling the A725 for the test actually nerfed performance, suggesting there may be room for improvement.

While GenAI performance is heavily dependent on low-precision GPU FLOPS, Strix Halo&#39;s beefier CPU may make it a more flexible option for those looking for a PC that can run GenAI models rather than an appliance for AI.

Moving on to GenAI, we should talk for a minute about some of the performance claims being made about both of these systems.

While Nvidia may claim a petaFLOPS of AI compute, the reality is most users will never get close to that. The reason is simple: achieving that level of performance requires structured sparsity, a feature with little if any benefit to inference workloads.

Because of this, Spark&#39;s peak performance is really closer to 500 dense teraFLOPS, and only for workloads that can take advantage of the FP4 data type. More often than not that means the Spark will actually run at 8 or 16-bit precision, limiting peak performance to 250 and 125 teraFLOPS respectively.

Sustained performance usually falls a bit short of the theoretical. Testing the GB10 in the Max Achievable MatMul FLOPS (MAMF) benchmark, we achieved 101 teraFLOPS at BF16 and 207 teraFLOPS at FP8.

But what about the Strix Halo part powering the G1a? Well, here we see one of AMD&#39;s biggest weaknesses. While the House of Zen claims 126 platform TOPS for its top-specced Strix Halo SKUs, you&#39;ll be hard pressed to find any app that can take full advantage of that. Fifty of those TOPS are delivered by the NPU, which requires specialized software to harness – more on that later. The remaining TOPS are achieved using the CPU and GPU.

Strix Halo&#39;s GPU is no slouch. By our estimate – AMD doesn&#39;t actually give peak floating point performance for the chip – the GPU is capable of churning out about 56 teraFLOPS of peak BF16 performance. In MAMF, we achieved about 82 percent of that at 46 teraFLOPS, which again isn&#39;t bad.

But because the GPU is based on AMD&#39;s older RDNA 3.5 architecture, it lacks support for the lower-precision data types offered by the Spark.

Technically, the architecture does support INT8, but the performance is essentially the same as BF16. In theory, it should deliver about 112 TOPS of INT4, but the trick is finding software that actually does computation at that precision. Sixteen distinct values just doesn&#39;t offer much granularity.

On paper, this gives the Spark a 2.2-9x performance advantage over the Strix Halo in raw AI compute capacity.

And while this played out repeatedly in our testing, compute is only one side of the GenAI coin. The other is memory bandwidth. Depending on your use case, it may even render the performance gap between the AMD and Nvidia systems a non-issue.

We&#39;re going to start by talking about large language model (LLM) inference precisely because it illustrates why more TOPS and FLOPS don&#39;t always translate into better AI performance.

For consistency, we ran most of our tests in Linux: Ubuntu 24.04 LTS on the HP and Nvidia&#39;s lightly customized version of the distro, DGX OS.

Editor&#39;s note: We ran into some issues with GPU hangs in Ubuntu when testing the G1a. However, by adding a few kernel arguments, we were able to resolve the issue.

The tweak can be made by editing the Grub boot config by running:

Then update the GRUB_CMDLINE_LINUX=&quot;&quot; entry to look like so:

Once complete, save and exit the editor by pressing Ctrl X. Finally, update the bootloader and restart the machine by running:

If you&#39;re still running into GPU hangs, we recommend checking out this thread on the Framework forum.

Just looking at single-batch performance in Llama.cpp – one of the most popular frameworks for running LLMs on consumer CPUs and GPUs – we can see that the GB10 and Strix Halo churn out tokens at a similar pace, with the AMD box pulling off a narrow lead when using the Vulkan backend.

In single batch inference, AMD&#39;s Strix Halo APU trades blows with the Spark on token generation, but falls well behind on time to first token

In single-user scenarios, token generation is usually bottlenecked by memory bandwidth. The GB10 claims about 273 GB/s of memory bandwidth while AMD&#39;s Strix Halo manages about 256 GB/s.

This is likely one of the reasons why many AI enthusiasts were so disappointed in the Spark when it first debuted. For between two-thirds and half the price, you could get a Strix Halo box that churns out tokens just as quickly.

However, if you turn your attention to the time-to-first-token column, you&#39;ll notice the GB10&#39;s GPU is roughly 2-3x faster than the one in the Strix Halo box, and that&#39;s when processing a relatively short 256-token prompt. With larger sequence lengths, this gap becomes more pronounced. This is because prompt processing tends to become compute bound quite quickly.

For shorter prompts or multi-turn conversations, Llama.cpp&#39;s prompt caching mitigates a lot of this performance deficit. In this scenario, we&#39;re only talking about waiting a second or two longer on the AMD platform, something customers just looking to run LLMs at home may be willing to overlook considering Strix Halo&#39;s lower average selling price.

For those whose workloads require feeding large documents into the model&#39;s context, the Spark&#39;s more potent GPU gives it a clear advantage here, just one that customers will need to weigh against its higher price.

Alongside single-batch performance, we also tested the two machines at larger batch sizes. It&#39;s not uncommon for users to batch up jobs like extracting information from a stack of documents or emails rather than processing them sequentially one at after another.

In this case, we&#39;re using vLLM, which in our experience handles large batch sizes and concurrency more gracefully than Llama.cpp, which is better optimized for single-user applications. We&#39;re also using Qwen3-30B-A3B-Instruct-2507 at its native BF16 precision to avoid quantization overheads.

To see how the machines performed, we tasked them with processing a 1,024-token input and generating a 1,024-token response at batch sizes ranging from one to 64.

This graph charts overall throughput (tok/s) against end-to-end latency at various batch sizes ranging from 1-64

On the X axis, we&#39;ve plotted the time in seconds required to complete the batch job, while on the Y axis we show the overall throughput in tokens per second at each batch size.

Once again, the Spark&#39;s faster graphics processor gives it a leg up over the G1a. While this is clearly a win for the Spark, unless you&#39;re routinely running batch jobs, the performance advantage is likely to go unnoticed, especially if you can schedule them to run overnight. Batch inference isn&#39;t exactly interactive and so you can easily walk away and come back when it&#39;s done.

It&#39;s a similar story when we look at using fine-tuning techniques to teach models new skills by exposing them to new information.

Fine-tuning requires a lot of memory, potentially as much as 100 GB for a model like Mistral 7B. As we&#39;ve previously discussed, techniques like LoRA or QLoRA can dramatically reduce the memory required to train a model.

With up to 128 GB of memory available on either platform, both the Spark and G1a are well suited to this workload, though they aren&#39;t particularly fast.

For full fine-tuning, the GB10 managed to pull well ahead of AMD&#39;s Strix Halo, but falls short of even last-gen workstation cards like the W7900 or RTX 6000 Ada

Running a full fine-tune of Meta&#39;s Llama 3.2 3B, we see that the Spark completes the job in roughly two-thirds the time of the G1a. However, compared to workstation cards like the Radeon Pro W7900 or RTX 6000 Ada, which offer both higher floating point performance as well as much faster GDDR6 memory, the Spark and G1a are simply outclassed.

Where things really get interesting is when we start looking at using QLoRA on larger models. To fine-tune a model like Llama 3.1 70B at home, you&#39;d normally need multiple workstation cards. But thanks to their massive memory footprint, this job is entirely possible using either the AMD or Nvidia boxes.

Moving up to a larger 70B parameter and the GB10&#39;s faster GPU gives it a leg up in QLoRA fine-tuning

With a relatively small dataset – something we&#39;ve previously shown can be more than adequate to tweak the style of a model – performance was more in line with what we were expecting. The G1a completed the job in a little over 50 minutes, compared to the Spark at around 20.

For bigger fine-tuning jobs using larger databases or LoRA ranks, this could easily extend to hours or potentially days, making the Spark&#39;s performance advantage more significant.

But just like we discussed with our multi-batch inference tests, unless you&#39;re fine-tuning models regularly, the Spark&#39;s higher performance may not be worth the price over a similarly equipped Strix Halo system from HP, Minisforum, Framework, or any one of the other mini-PC vendors.

One area where the Spark&#39;s higher performance does give it a definitive advantage is in image and video generation workloads. Like fine-tuning, image gen is an especially compute and memory-hungry workload, but doesn&#39;t tend to be bandwidth bound.

This is partially because image models aren&#39;t as easily compressed as LLMs without major concessions to output quality. As such, many prefer to run these models at their native precision, whether that be FP32, BF16, or FP8.

If you&#39;re planning to generate images or videos using ComfyUI, Nvidia GPUs are still your best bet

Running Black Forest Lab&#39;s FLUX.1 Dev in ComfyUI, our test systems scale almost exactly as expected relative to their 16-bit floating point performance.

With 120 and 125 teraFLOPS of BF16 grunt respectively, the Spark roughly matches AMD&#39;s Radeon Pro W7900, while achieving a roughly 2.5x lead over the Strix Halo-based G1a, which in our testing achieved about 46 teraFLOPS of real-world performance.

Suffice to say image generation is clearly not the Strix box&#39;s strong suit.

AMD&#39;s Strix Halo APUs are also equipped with a pretty competent neural processing unit (NPU) courtesy of the company&#39;s Xilinx acquisition. The XDNA 2 NPU is capable of churning out an extra 50 TOPS of AI performance. The trick, of course, is finding software that can take advantage of it. Most NPU use cases focus on minimizing the power consumption of things like noise reduction in audio and video, background blurring, and optical character recognition.

However, AMD and others have started to utilize the NPU for generative AI applications with mixed results. Thanks to apps like Lemonade Server, you can now run LLMs entirely on the NPU. Unless you&#39;re trying to save on power, you probably won&#39;t want to just yet.

As of this writing, model support is somewhat limited and it doesn&#39;t appear that the NPU has access to all of the GPU&#39;s 250 GB/s of memory bandwidth. Running Mistral 7B on the NPU in Windows, we observed decode performance of just 4-5 tok/s, where we would have expected to see closer to 40 tok/s.

However, AMD is clearly pushing the idea of disaggregated inference, where compute-heavy prompt processing is offloaded to the NPU while the memory bandwidth-intensive decode phase is handled by the GPU. Performance was better, but still not as good as if you&#39;d just run the model on the GPU.

This disaggregated approach makes a lot of sense for power-constrained notebooks, but less so for a desktop system like the G1a. Having said that, we&#39;re interested to see where AMD takes this.

We were also able to get the NPU working in Amuse, a beginner-friendly image generation suite. AMD recently added support for running Stable Diffusion 3 directly on the NPU and, in this case, performance was actually quite a bit better than running the same model on the GPU.

Here we see Amuse using the XDNA 2 NPU in Strix Halo to generate an image using Stable Diffusion 3

Running on the NPU, Amuse was able to generate a 1,024 x 1,024 image using 20 steps in a little over a minute, while running that same test on the GPU required roughly twice that.

There were some caveats worth pointing out. The integration is quite limited at this point, available only in the beginner mode with the performance slider set to balanced. Switching to the &quot;expert mode&quot; disabled the NPU, forcing the model to run on the graphics processor.

The integration is also limited to Stable Diffusion 3, which is growing rather long in the tooth at this point having made its debut over a year ago. Still, it&#39;s good to see more applications taking advantage of the NPU for more than background blurring in video calls.

One selling point that frequently comes up in any comparison between AMD and Nvidia is software compatibility, aka the CUDA moat.

While you can expect just about any software that runs on CUDA to work on the Spark without issue, that&#39;s not guaranteed on the Strix Halo-based G1a.

Nearly two decades of development on CUDA is hard to overlook, but, while AMD has traditionally trailed in software support for its ROCm and HIP libraries, the company has made significant gains in recent months.

A year ago, we faced numerous headaches with libraries that either weren&#39;t available or relied on forks built specifically for AMD&#39;s CDNA-based datacenter chips, which meant they didn&#39;t run on consumer platforms. Today, this isn&#39;t nearly as big a problem. In fact, most of our PyTorch test scripts ran without modification on the AMD platform. However, we&#39;d be lying if we said the experience was anywhere close to as seamless as on the Spark.

A lot of software can be made to work on AMD&#39;s consumer hardware, but it&#39;s not always as simple as running something like pip install xyz-package. We still needed to build libraries from source or use forks made specifically for Radeon GPUs on several occasions — vLLM, BitsandBytes, and Flash Attention 2 are just a few examples.

In many cases, particularly when working with software written closer to the hardware, software needs to be compiled specifically for that generation of Radeon graphics. Llama.cpp is just one example where we needed to compile against a gfx1151 target in order to get the software running.

Wrangling these dependencies isn&#39;t easy, regardless of the platform you&#39;re working with, so it&#39;s nice to see AMD and Nvidia offering Docker containers that have been pre-configured with everything you need to get start started. For our vLLM tests, we used both team Red and Green&#39;s vLLM Docker containers to ensure we were getting the best possible performance.

Perhaps our biggest software challenges weren&#39;t actually software related. Strix Halo is based on AMD&#39;s older RDNA 3.5 architecture, which means it lacks support for many of the lower-precision data types offered by the Spark&#39;s Blackwell GPU. As a result, we were often forced to run models at 16-bit precision, even when FP8 or FP4 would have been preferable.

AMD&#39;s RDNA 4 architecture should resolve some of this by adding support for both sparsity and FP8. However, much of the industry is now reorienting around microscaling data types, like MXFP4, for its smaller memory footprint and wider effective range.

While AMD is rapidly closing the gap, Nvidia still holds a meaningful lead on both hardware and software.

We know you&#39;re all going to ask. Yes. Both of these boxes run Crysis.

At 1440p, medium settings, Crysis Remastered ran at a very respectable 90-100 FPS on the G1a. No real surprises here, as the HP is using an x86 CPU and GPU from a company with a long graphics pedigree.

Getting the game running on the DGX Spark was a little bit more involved because of the GB10&#39;s Arm CPU, which, for better or worse, doesn&#39;t support 32-bit instructions. Thankfully, we were able to get it running using a utility called FEX. If you&#39;re curious, you can find the install script we used here.

Unfortunately, we couldn&#39;t get the Steam performance overlay working on the Spark, which meant we couldn&#39;t get concrete performance metrics. At medium settings, the game was perfectly playable even without resorting to using Nvidia&#39;s AI upscaling tech, which actually worked in game.

While you can get games running on the Spark or other GB10 systems, we&#39;re not sure we&#39;d recommend it over the Strix Halo box or any number of cheaper gaming PCs out there.

Which of these systems is right for you really depends on how much you care about GenAI

Which of these systems is right for you really depends on whether you want a machine specifically for AI or a PC that just happens to be able to run most AI workloads you might throw at it.

We suspect many folks who&#39;ve made it this far likely fall into the latter camp. If you&#39;re going to spend $2K-4K on a new PC, we don&#39;t think it&#39;s unreasonable to expect it to do more than one thing well.

In this respect, HP&#39;s Z2 Mini G1a is one of the better options out there, especially if you&#39;re mostly interested in running single-batch LLM inference as opposed to fine-tuning or image gen. AMD&#39;s Strix Halo SoCs may not have the computational grunt of Nvidia&#39;s GB10 boxes, but it runs Windows and Linux competently and doesn&#39;t require jumping through hoops just to play your favorite games.

Despite the performance gap, for software engineers building apps for the growing AI PC segment, the AMD-based system may still be the better development platform if for no other reason than Microsoft&#39;s NPU mandate.

But for those who really want an AI appliance for prototyping agents, fine-tuning models, or generating text, image, and video content, the Spark or one of its GB10 siblings is probably the better choice, assuming you can stomach the asking price.

In our testing, the machine consistently delivered performance 2-3x that of the AMD-based HP system, while also benefiting from a significantly more mature and active software ecosystem. As we&#39;ve shown, you can also get non-AI workloads running on the Spark in a pinch, but that&#39;s not what it&#39;s meant for. At its heart, the Spark is an AI lab in a box and is best used as such. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-47')">
            <div class="source">The Register</div>
            <div class="title">You don't need Linux to run free and open source software</div>
            <div class="meta">2025-12-25</div>
        </div>
        
        <div id="content-47" style="display:none;">
            <h2>You don't need Linux to run free and open source software</h2>
            <p><strong>The Register | 2025-12-25</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2025/12/25/go_foss_keep_your_os/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Part 2 There&#39;s a wealth of highly usable free software for the big proprietary desktop OSes. You can escape paying subscriptions and switch to free software without changing your OS.

In the first half of this short series, we looked at how to freshen up an aging Mac or Windows 10 PC, and ideally, how to wipe it and install a clean, bloat-free copy of its OS. That is all well and good, but this leaves the problem of what to put on that OS to get out of the trap of software you paid for but don&#39;t own.

The big question, of course, is what to use and where to find it. There are lists that can help, but you need to be very cautious. If the website looks fancy and modern, then it may be trying to sell you fancy modern tools that will cost you and won&#39;t work with older OSes. Beware of animation effects, transitions, things which fade in and out, and so on.

Compare OpenAlternative.co, which is snazzy and effects-heavy, with the decidedly low-tech Best FOSS Alternatives, which is very simple and austere. The latter has nothing to sell; it&#39;s just a plain, simple categorized list of FOSS tools. If you scroll to the end, it even has a short list of alternatives to itself.

Always remember the KISS principle. As a general rule, try to favor things that are plain, simple, and unornamented – there&#39;s less to go wrong.

As a general rule, we suggest treating app stores for desktop OSes with suspicion and keeping them at arm&#39;s length. Apple has integrated its App Store deeply into macOS since 2001&#39;s Mac OS X 10.0, but you don&#39;t need it, and it&#39;s full of things that you can get for free elsewhere. Most native macOS apps update themselves, so even the App Store&#39;s handy automatic background updates aren&#39;t essential.

On a fresh new copy of Windows, the easiest way to get up and running is Ninite. The Reg FOSS desk described this back in April, but long before that, in 2012, The Register said it could save your sanity – and endorsed it again in 2013.

A dozen years later, Ninite is still very helpful. (Sadly, the macOS equivalent, MacApps.link, is unmaintained and dated… don&#39;t use it except for pointers.)

Ninite offers a wide range of FOSS and freeware apps, utilities, runtimes, and codecs. You tick the ones you want and it generates a custom installer for you to download. Run that, and it downloads and installs all the tools you selected, saying no to all optional extras, toolbars, adware, and everything else you don&#39;t want. It automatically picks your language and 64-bit versions where it can.

Hang on to that Ninite installer. It&#39;s tiny, and if you keep it and rerun it later, it will also update all the apps for you in one pass – skipping any that don&#39;t need it.

Even if you don&#39;t need Ninite, or don&#39;t use Windows for that matter, there are worse places to get a shopping list of FOSS apps than just Googling the apps on Ninite&#39;s list. It&#39;s not comprehensive but it&#39;s a good starting point.

Many of these suggestions apply equally to any of the big three platforms, which brings a handy extra into the deal: if you use a different type of computer at home and at work, say, it makes life easier if they run the same apps.

Aside from a couple of small tools and a copy of the oldest version of Microsoft Word that still runs on macOS Catalina or later, we treat macOS like a prettier Linux. All the apps are FOSS or freeware, installed directly from .dmg files downloaded from their creators. They all update themselves when new versions are released. Everything interoperates smoothly. We don&#39;t really use any Apple-bundled apps except the OS itself, meaning things like the Finder, Dock, Spotlight searching, and the Preview document viewer.

For instance, we use Jeena&#39;s TextEd instead of Apple&#39;s text editor. For browsers, email, chat, productivity, writing, and so on, we use FOSS and freeware apps, and wherever possible, ones that also work on Linux and Windows – it makes synchronizing and switching between platforms much easier.

Mozilla Firefox is a classic, of course, but it&#39;s still getting new features. The full version of uBlock Origin works: make it the first add-on you install. Since Firefox 136, it&#39;s had vertical tabs built in. The Reg FOSS desk has been evangelizing this for years so we&#39;ll be brief: if you don&#39;t use it, you need to learn. Enable the built-in browser sync and link up all your copies, and you&#39;ll always have the same bookmarks, the same passwords, and you can open a tab from one machine on any other. As we told you in August, you can just disable all the artificial idiocy: go into about:config and enter browser.ml. Lots of settings related to the integrated LLM bot appear: set them all to false, quit and reload Firefox, and you avoid the built-in bot&#39;s slop. In recent years, Firefox is also not just a very capable PDF viewer, it&#39;s also a handy PDF editor: you can annotate them, fill in forms and so on, all in the browser.

Much the same applies to Thunderbird from Mozilla subsidiary MZLA. There are lots of great email clients out there. Some are free. Some are open source. Some run on multiple platforms. We&#39;re not saying that Thunderbird is the best, but it&#39;s free, it&#39;s open source (so you can use it at work with no penalties), and it runs identically on Windows, macOS, and Linux.

If you don&#39;t get on with Thunderbird, there are lots of alternatives out there, from The Bat! to the cross-platform eM Client. Pegasus Mail, the granddaddy of them all in Windows terms, is still maintained.

If Mozilla&#39;s integration of telemetry and LLM bots annoys you, then Waterfox is an excellent alternative. For the occasional site or service that doesn&#39;t work properly in Firefox, we tend to keep a copy of Google Chrome around, of course with uBlock Lite installed. We don&#39;t care for it much, but it does the job, and by sticking to the upstream source, new releases come faster than in downstream rebuilds such as Microsoft Edge – for all that that does offer vertical tabs.

For media players, the classic VLC remains a good candidate. For just audio, The Reg FOSS desk is quite fond of Foobar2000 – it&#39;s not FOSS, but it&#39;s free, wonderfully simple and uncluttered, and it runs on Windows, macOS, and even Android.

For chat apps and other SaaS-type tools, there are several excellent all-in-one tools that will let you manage all your conversations in tabs in a single app. Our daily go-to tool for this is Ferdium, but as we wrote in the previous link, there are several alternatives. It&#39;s worth noting that Thunderbird can talk to XMPP and Matrix by default, and has extensions to handle things like Slack, Whatsapp, Telegram, Discord, Teams, and others. The difficult odd man out is Signal, which won&#39;t work with anything else, doesn&#39;t sync message history, and is generally a bit of a pain in its quest for the maximum possible security – but a few regular contacts are on it, so we keep it around anyway.

If you want something lighter-weight, for techies willing to roll their sleeves up and manually configure plugins, the venerable Pidgin can talk to a lot of services, it&#39;s very lightweight and fast, and a major new release is under construction. The venerable Trillian is still around too, and it runs on macOS as well, but sadly can&#39;t talk to most modern messaging systems.

For a general office suite, it&#39;s well worth keeping LibreOffice installed even if just for emergency file recovery. If you still use OpenOffice, it&#39;s long past time to switch: that version is all but dead, and we recommend uninstalling it and replacing it with its actively maintained successor. If you find the appearance of LibreOffice a bit old and staid, then try OnlyOffice or WPS Office, which are more up-to-date with Microsoft&#39;s modern UI.

For image viewing, on Windows, for us nothing beats IrfanView, and we still miss it on both macOS and Linux. There are others, though, such as FastStone and the cross-platform XnView.

For editing, the GIMP is back in active development – and if you can&#39;t get on with the UI and still miss Photoshop, try PhotoGIMP. Worthy alternatives include Paint.net and the cross-platform Krita. We lack sufficient artistic skills, but we hear Inkscape is pretty good. For photographers, Darktable is worth a look, and for managing photo libraries, try the cross-platform digiKam.

For file compression and decompression, dump that ancient, unregistered copy of WinRar and get 7-Zip, or if you&#39;d prefer to avoid Russian apps, PeaZip. On our Macs, we keep The Unarchiver and Stuffit Expander around just in case there&#39;s anything the OS can&#39;t handle itself.

For file downloading, we mostly just use the Multithreaded Download Manager extension for Firefox, but for anything more complicated, FileZilla may help.

Despite what we said earlier about old text editors being safe, there are better alternatives to the built-in ones in most OSes. A few years ago, we wrote about Notepad++ and Geany, which both use the same editing component, Scintilla. There are versions of Notepad++ for even very old versions of Windows, and while Geany is mostly found on Linux, it&#39;s also a good, fast macOS text editor.

We very rarely need a full-function office suite, but find a plain-text editor a bit too minimal, so for writing, we usually use the distraction-free Panwriter Markdown editor. It&#39;s an Electron app so it&#39;s not light; if you want Markdown in something lightweight, then Ghostwriter does the job and it&#39;s cross-platform. It even runs on Haiku and on the Raspberry Pi, and even on Windows 7. For note taking, we like LogSeq, although we suspect we only use about 1 percent of its facilities. It&#39;s a hierarchical markdown note taker with basic outlining, and that ticks a bunch of Reg FOSS desk boxes. We&#39;ve tried syncing it between machines with Syncthing but that proved rather flaky.

As a hypervisor, we like Oracle&#39;s VirtualBox. As we have explained before, the only licensed part is the Extension Pack, and the hypervisor works fine without it. Avoid that, and you&#39;re safe. If some demanding guest OS doesn&#39;t work, then on Macs, the all-FOSS UTM is a good alternative, but for most things, the now-gratis VMware is a bit easier. It works a bit differently on Windows, Linux, and macOS, which is annoying, but it does the job and does it well. If you often need a Windows VM, we find VMware noticeably faster than VirtualBox with that guest.

Well, it may have been long ago, but once upon a time, you didn&#39;t know how to use Adobe Photoshop or Microsoft Excel to their best advantage either.

Breaking free of proprietary tools takes some effort, yes. You will have to relearn how to do some things. You absolutely will find things that the free and open source tools simply can&#39;t do.

The question then is: do you need those functions, or were they just handy? Only you can decide if certain functions are convenient, but not actually essential, or if they are things you cannot get your job done without.

This particular vulture was an early adopter of Windows and has been using PCs for worryingly close to 40 years now, and there were absolutely things we missed when we moved to mostly running Linux and the new Mac OS X about halfway through that time span. However, a lot of them have proved with time to be things we can just do without. The returns in terms of never worrying about subscriptions, and so on, are completely worth it.

In general, our advice is that investing the time in learning alternative tools, ones from suppliers whose business models don&#39;t rely on subscriptions or lock-in, will repay you manifold. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-48')">
            <div class="source">The Verge</div>
            <div class="title">I re-created Google&#8217;s cute Gemini ad with my own kid&#8217;s stuffie, and I wish I hadn&#8217;t</div>
            <div class="meta">2025-12-25</div>
        </div>
        
        <div id="content-48" style="display:none;">
            <h2>I re-created Google&#8217;s cute Gemini ad with my own kid&#8217;s stuffie, and I wish I hadn&#8217;t</h2>
            <p><strong>The Verge | 2025-12-25</strong></p>
            <a class="original-link" href="https://www.theverge.com/tech/849998/gemini-ai-stuffed-animal-commercial">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">AI can help you make it look like a plush toy is traveling the world. But I’m not convinced that’s a great idea.

AI can help you make it look like a plush toy is traveling the world. But I’m not convinced that’s a great idea.

When your kid starts showing a preference for one of their stuffed animals, you’re supposed to buy a backup in case it goes missing.

I’ve heard this advice again and again, but never got around to buying a second plush deer once “Buddy” became my son’s obvious favorite. Neither, apparently, did the parents in Google’s newest ad for Gemini.

It’s the fictional but relatable story of two parents discovering their child’s favorite stuffed toy, a lamb named Mr. Fuzzy, was left behind on an airplane. They use Gemini to track down a replacement, but the new toy is on backorder. In the meantime, they stall by using Gemini to create images and videos showing Mr. Fuzzy on a worldwide solo adventure — wearing a beret in front of the Eiffel tower, running from a bull in Pamplona, that kind of thing — plus a clip where he explains to “Emma” that he can’t wait to rejoin her in five to eight business days. Adorable, or kinda weird, depending on how you look at it! But can Gemini actually do all of that? Only one way to find out.

I fed Gemini three pictures of Buddy, our real life Mr. Fuzzy, from different angles, and gave it the same prompt that’s in the ad: “find this stuffed animal to buy ASAP.” It returned a couple of likely candidates. But when I expanded its response to show its thinking I found the full eighteen hundred word essay detailing the twists and turns of its search as it considered and reconsidered whether Buddy is a dog, a bunny, or something else. It is bananas, including real phrases like “I am considering the puppy hypothesis,” “The tag is a loop on the butt,” and “I’m now back in the rabbit hole!” By the end, Gemini kind of threw its hands up and suggested that the toy might be from Target and was likely discontinued, and that I should check eBay.

In fairness, Buddy is a little bit hard to read. His features lean generic cute woodland creature, his care tag has long since been discarded, and we’re not even 100 percent sure who gave him to us. He is, however, definitely made by Mary Meyer, per the loop on his butt. He does seem to be from the “Putty” collection, which is a path Gemini went down a couple of times, and is probably a fawn that was discontinued sometime around 2021. That’s the conclusion I came to on my own, after about 20 minutes of googling and no help from AI. The AI blurb when I do a reverse image search on one of my photos confidently declares him to be a puppy.

Gemini did a better job with the second half of the assignment, but it wasn’t quite as easy as the ad makes it look. I started with a different photo of Buddy — one where he’s actually on a plane in my son’s arms — and gave it the next prompt: “make a photo of the deer on his next flight.” The result is pretty good, but his lower half is obscured in the source image so the feet aren’t quite right. Close enough, though.

The ad doesn’t show the full prompt for the next two photos, so I went with: “Now make a photo of the same deer in front of the Grand Canyon.” And it did just that — with the airplane seatbelt and headphones, too. I was more specific with my next prompt, added a camera in his hands and got something more convincing.

I can see how Gemini misinterpreted my prompt. I was trying to keep it simple and requested a photo of the same deer “at a family reunion.” I did not specify his family reunion. So that’s how he ended up crashing the Johnson family reunion — a gathering of humans. I can only assume that Gemini took my last name as a starting point here because it sure wasn’t in my prompt, and when I requested that Gemini created a new family reunion scene of his family, it just swapped the people for stuffed deer. There are even little placards on the table that say “deer reunion.” Reader, I screamed.

For the last portion of the ad, the couple use Gemini to create cute little videos of Mr. Fuzzy getting increasingly adventurous: snowboarding, white water rafting, skydiving, before finally appearing in a spacesuit on the moon addressing “Emma” directly. The commercial whips through all these clips quickly, which feels like a little sleight of hand given that Gemini takes at least a couple of minutes to create a video. And even on my Gemini Pro account, I’m limited to three generated videos per day. It would take a few days to get all of those clips right.

Gemini wouldn’t make a video based on any image of my kid holding the stuffed deer, probably thanks to some welcome guardrails preventing it from generating deepfakes of babies. I started with the only photo I had on hand of Buddy on his own: hanging upside down, air-drying after a trip through the washer. And that’s how he appears in the first clip it generated from this prompt: Temu Buddy hanging upside down in space before dropping into place, morphing into a right-side-up astronaut, and delivering the dialogue I requested.

A second prompt with a clear photo of Buddy right-side-up seemed to mash up elements of the previous video with the new one, so I started a brand-new chat to see if I could get it working from scratch. Honestly? Nailed it. Aside from the antlers, which Gemini keeps sneaking in. But this clip also brought one nagging question to the forefront: should you do any of this when your kid loses a beloved toy?

I gave Buddy the same dialogue as in the commercial, using my son’s name rather than Emma. Hearing that same manufactured voice say my kid’s name out loud set alarm bells off in my head. An AI generated Buddy in front of the Eiffel Tower? Sorta weird, sorta cute. AI Buddy addressing my son by name? Nope, absolutely not, no thank you.

How much, and when, to lie to your kids is a philosophical debate you have with yourself over and over as a parent. Do you swap in the identical stuffie you had in a closet when the original goes missing and pretend it’s all the same? Do you tell them the truth and take it as an opportunity to learn about grief? Do you just need to buy yourself a little extra time before you have that conversation and enlist AI to help you make a believable case? I wouldn’t blame any parent choosing any of the above. But personally, I draw the line at an AI character talking directly to my kid. I never showed him these AI-generated versions of Buddy, and I plan to keep it that way.

But back to the less morally complex question: can Gemini actually do all of the things that it does in the commercial? More or less. But there’s an awful lot of careful prompting and re-prompting you’d have to do to get those results. It’s telling that throughout most of the ad you don’t see the full prompt that’s supposedly generating the results on screen. A lot depends on your source material, too. Gemini wouldn’t produce any kind of video based on an image in which my kid was holding Buddy — for good reason! But this does mean that if you don’t have the right kind of photo on hand, you’re going to have a very hard time generating believable videos of Mr. Sniffles or whoever hitting the ski slopes.

Like many other elder millennials, I think about Calvin and Hobbes a lot. Bill Watterson famously refused to commercialize his characters, because he wanted to keep them alive in our imaginations rather than on a screen. He insisted that having an actor give Hobbes a voice would change the relationship between the reader and the character, and I think he’s right. The bond between a kid and a stuffed animal is real and kinda magical; whoever Buddy is in my kid’s imagination, I don’t want AI overwriting that.

The great cruelty of it all is knowing that there’s an expiration date on that relationship. When I became a parent, I wasn’t at all prepared for the way my toddler nuzzling his stuffed deer would crack my heart right open. It’s so pure and sweet, but it always makes me a little sad at the same time, knowing that the days where he looks for comfort from a stuffed animal like Buddy are numbered. He’s going to outgrow it all, and I’m not prepared for that reality. Maybe as much as we’re trying to save our kids some heartbreak over their lost companion, we’re really trying to delay ours, too.

All images and videos in this story were generated by Google Gemini.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-49')">
            <div class="source">The Verge</div>
            <div class="title">Hollywood cozied up to AI in 2025 and had nothing good to show for it</div>
            <div class="meta">2025-12-25</div>
        </div>
        
        <div id="content-49" style="display:none;">
            <h2>Hollywood cozied up to AI in 2025 and had nothing good to show for it</h2>
            <p><strong>The Verge | 2025-12-25</strong></p>
            <a class="original-link" href="https://www.theverge.com/ai-artificial-intelligence/848119/hollywood-film-tv-ai-2025">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The technology dominated the entertainment discourse, but there’s yet to be a series or movie that shows AI’s potential.

The technology dominated the entertainment discourse, but there’s yet to be a series or movie that shows AI’s potential.

AI isn’t new to Hollywood — but this was the year when it really made its presence felt. For years now, the entertainment industry has used different kinds of generative AI products for a variety of post-production processes ranging from de-aging actors to removing green screen backgrounds. In many instances, the technology has been a useful tool for human artists tasked with tedious and painstaking labor that might have otherwise taken them inordinate amounts of time to complete. But in 2025, Hollywood really began warming to the idea of deploying the kind of gen AI that’s really only good for conjuring up text-to-video slop that doesn’t have all that many practical uses in traditional production workflows. Despite all of the money and effort being put into it, there’s yet to be a gen-AI project that has shown why it’s worth all of the hype.

This confluence of Hollywood and AI didn’t start out so rosy. Studios were in a prime position to take the companies behind this technology to court because their video generation models had clearly been trained on copyrighted intellectual property. A number of major production companies including Disney, Universal, and Warner Bros. Discovery did file lawsuits against AI firms and their boosters for that very reason. But rather than pummeling AI purveyors into the ground, some of Hollywood’s biggest power players chose instead to get into bed with them. We have only just begun to see what can come from this new era of gen-AI partnerships, but all signs point to things getting much sloppier in the very near future.

Though many of this year’s gen-AI headlines were dominated by larger outfits like Google and OpenAI, we also saw a number of smaller players vying for a seat at the entertainment table. There was Asteria, Natasha Lyonne’s startup focused on developing film projects with “ethically” engineered video generation models, and startups like Showrunner, an Amazon-backed platform designed to let subscribers create animated “shows” (a very generous term) from just a few descriptive sentences plugged into Discord. These relatively new companies were all desperate to legitimize the idea that their flavor of gen AI could be used to supercharge film / TV development while bringing down overall production costs.

Asteria didn’t have anything more than hype to share with the public after announcing its first film, and it was hard to believe that normal people would be interested in paying for Showrunner’s shoddily cobbled-together knockoffs of shows made by actual animators. In the latter case, it felt very much like Showrunner’s real goal was to secure juicy partnerships with established studios like Disney that would lead to their tech being baked into platforms where users could prompt up bespoke content featuring recognizable characters from massive franchises.

That idea seemed fairly ridiculous when Showrunner first hit the scene because its models churn out the modern equivalent of clunky JibJab cartoons. But in due time, Disney made it clear that — crappy as text-to-video generators tend to be for anything beyond quick memes — it was interested in experimenting with that kind of content. In December, Disney entered into a three-year, billion-dollar licensing deal with OpenAI that would let Sora users make AI videos with 200 different characters from Star Wars, Marvel, and more.

Netflix became one of the first big studios to proudly announce that it was going all-in on gen AI. After using the technology to produce special effects for one of its original series, the streamer published a list of general guidelines it wanted its partners to follow if they planned to jump on the slop bandwagon as well. Though Netflix wasn’t mandating that filmmakers use gen AI, it made clear that saving money on VFX work was one of the main reasons it was coming out in support of the trend. And it wasn’t long before Amazon followed suit by releasing multiple Japanese anime series that were terribly localized into other languages because the dubbing process didn’t involve any human translators or voice actors.

Amazon’s gen-AI dubs became a shining example of how poorly this technology can perform. They also highlighted how some studios aren’t putting all that much effort into making sure that their gen AI-derived projects are polished enough to be released to the public. That was also true of Amazon’s machine-generated TV recaps, which frequently got details about different shows very wrong. Both of these fiascos made it seem as if Amazon somehow thought that people wouldn’t notice or care about AI’s inability to consistently generate high-quality outputs. The studio quickly pulled its AI-dubbed series and the recap feature down, but it didn’t say that it wouldn’t try this kind of nonsense again.

All of this and other dumb stunts like AI “actress” Tilly Norwood made it feel like certain segments of the entertainment industry were becoming more comfortable trying to foist gen-AI “entertainment” on people even though it left many people deeply unimpressed and put off. None of these projects demonstrated to the public why anyone except for money-pinching execs (and people who worship them for some reason) would be excited by a future shaped by this technology.

Aside from a few unimpressive images, we still haven’t seen what all might come from some of these collaborations, like Disney cozying up to OpenAI. But next year AI’s presence in Hollywood will be even more pronounced. Disney plans to dedicate an entire section of its streaming service to user-generated content sourced from Sora, and it will encourage Disney employees to use OpenAI’s ChatGPT products. But the deal’s real significance in this current moment is the message it sends to other studios about how they should move as Hollywood enters its slop era.

Regardless of whether Disney thinks this will work out well, the studio has signaled that it doesn’t want to be left behind if AI adoption keeps accelerating. That tells other production houses that they should follow suit, and if that becomes the case, there’s no telling how much more of this stuff we are all going to be forced to endure.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-50')">
            <div class="source">The Verge</div>
            <div class="title">Anker’s beefy Laptop Power Bank has returned to its Black Friday low</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-50" style="display:none;">
            <h2>Anker’s beefy Laptop Power Bank has returned to its Black Friday low</h2>
            <p><strong>The Verge | 2025-12-24</strong></p>
            <a class="original-link" href="https://www.theverge.com/gadgets/849637/anker-laptop-power-bank-xbox-series-x-deal-sale">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">You can also save on the Xbox Series X and what is arguably the best-looking Bluetooth speaker available.

You can also save on the Xbox Series X and what is arguably the best-looking Bluetooth speaker available.

If you buy something from a Verge link, Vox Media may earn a commission. See our ethics statement.

As you might expect, things have been relatively quiet on the deals front since Black Friday, particularly when it comes to discounts on charging accessories. Thankfully, Anker’s aptly titled Laptop Power Bank is once again on sale at Amazon and Walmart for $87.99 ($47 off), which matches the record-low price we last saw at the end of November.

Unless you’ve been living under a proverbial rock for the past several years, you’re probably aware that Anker makes an ungodly amount of charging accessories. The portable A1695 “InstaCord” has quickly become a favorite among Verge staffers, however, owing to the fact that it comes with a retractable USB-C cable and a second that doubles as a handle, both of which are bidirectional and allow for passthrough charging. The 25,000mAh / 90Wh power bank also sports a USB-A port and an additional USB-C port, allowing you to charge your phone, a MacBook Pro, and up to two other devices simultaneously.

In terms of output distribution, Anker’s 600-gram Laptop Power Bank can deliver up to 165W when two devices are plugged in, or up to 130W when charging three or four gadgets. It’s carry-on compliant, too, meaning you shouldn’t have any trouble getting it through TSA while traveling, which isn’t the case if your charger is above the agency’s 100 watt-hours threshold for carry-on devices. It even features a built-in LCD display, allowing you to quickly view the remaining charge, overall power output, battery temperature, and other info at a glance.

Sign up for Verge Deals to get deals on products we’ve tested sent to your inbox weekly.

Sign up for Verge Deals to get deals on products we’ve tested sent to your inbox weekly.</div>
        </div>
        
        <div class="card" onclick="openModal('content-51')">
            <div class="source">The Verge</div>
            <div class="title">Sony’s souped-up PlayStation 5 Pro is $100 off for the rest of today</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-51" style="display:none;">
            <h2>Sony’s souped-up PlayStation 5 Pro is $100 off for the rest of today</h2>
            <p><strong>The Verge | 2025-12-24</strong></p>
            <a class="original-link" href="https://www.theverge.com/gadgets/684281/sony-playstation-5-ps5-pro-christmas-deal-sale-2025">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The discount might not be big enough to warrant the upgrade, but we’ll let you make that call.

The discount might not be big enough to warrant the upgrade, but we’ll let you make that call.

If you buy something from a Verge link, Vox Media may earn a commission. See our ethics statement.

Sony’s full suite of PlayStation 5 consoles jumped in price in August due to increased US tariffs, but now through Christmas, you can save $100 on several models. This discount is especially great if you planned to go big with Sony’s PS5 Pro, the company’s priciest, most powerful console yet. Normally $749.99, you can currently grab one at Amazon, Walmart, and Target for around $689.99. Sony’s PlayStation Direct storefront indicates that the PS5 Pro sale ends on December 25th at 3AM ET, although discounts may remain on cheaper models.

The PS5 Pro plays many games at their best resolution, while making far fewer concessions than the standard PS5 when it comes to visual effects (particularly ray tracing and shadow quality). Some games simply look better or run faster on the Pro than the base-model PS5, while others look better and run faster. That said, it’s worth noting that PS5 Pro lacks a disc drive and is thus limited to digital titles, though you can buy an optional drive for $80 if you want to attach one later.

The PlayStation 5 Pro has a bigger GPU than any other PS5 model, with twice as much internal storage as the current slim models (2TB versus 1TB). Another notable feature exclusive to the Pro is PSSR (PlayStation Spectral Super Resolution), which uses AI to upscale graphics in supported games to produce a better-looking image. The difference in performance between the Pro and the base PS5 is easy to notice in several games, although it’s safe to say that there hasn’t yet been a title that makes upgrading to one a no-brainer. But if a lower price is all the encouragement you needed to upgrade, now is a good time to get one.

Sign up for Verge Deals to get deals on products we’ve tested sent to your inbox weekly.

Sign up for Verge Deals to get deals on products we’ve tested sent to your inbox weekly.</div>
        </div>
        
        <div class="card" onclick="openModal('content-52')">
            <div class="source">The Verge</div>
            <div class="title">The best shows and movies to stream on Netflix in 2025</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-52" style="display:none;">
            <h2>The best shows and movies to stream on Netflix in 2025</h2>
            <p><strong>The Verge | 2025-12-24</strong></p>
            <a class="original-link" href="https://www.theverge.com/entertainment/845388/netflix-best-shows-movies-2025">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">From the end of Stranger Things and Squid Game to the surprise hit KPop Demon Hunters.

From the end of Stranger Things and Squid Game to the surprise hit KPop Demon Hunters.

Netflix has had an interesting year. Its ad tier, introduced last year, has grown significantly, and its live TV initiative has expanded to include not only weird one-offs like hot-dog-eating grudge matches but also WWE programming. Taking KPop Demon Hunters off Sony’s hands for the business equivalent of $200 in a potato chip bag also turned out to be a pretty smart move for Netflix. The animated feature about, well, demon-hunting K-pop stars, became the most watched movie in the platform’s history and a global cultural phenomenon in its own right. The sing-along theatrical release sold out, songs from the movie sat comfortably at the top of music charts for weeks, and we got Huntr/x in Fortnite and the Macy’s Thanksgiving Parade mere months after the movie’s release.

But KPop Demon Hunters wasn’t the streamer’s only quality offering this year. Here’s a list of Netflix’s best of 2025.

There are two life lessons to take away from this documentary: Don’t be a horrific abuser and never piss off a self-described petty man with cash to burn. This four-part docuseries, directed by Alex Stapleton and produced by Lifetime Achievement Fellow in the Hater Hall of Fame Curtis “50 Cent” Jackson, chronicles the rise of Sean “P Diddy” Combs from music video character actor, to hip-hop business mogul, to convicted criminal.

The documentary features new interviews from former associates, employees, and friends who allege everything from cheating business partners out of their share to having knowledge of if not outright arranging the hit that took Tupac Shakur’s life. This is not a “fun” watch, so heed the content warnings, but if you want a succinct accounting of where Combs came from and how the business of hip-hop can turn men into monsters, this is an informative overview.

There is vanishingly little I can say about KPop Demon Hunters’ brilliance that hasn’t already been said. So I’ll let what has been said speak for it:

Rian Johnson’s Knives Out series has once again delivered a sharply funny, intensely moving whodunit. Daniel Craig as Benoit Blanc drips southern charm, aided by an ensemble cast featuring Josh Brolin as a fiery Catholic priest and Glenn Close as his secretary. Josh O’Connor delivers some beautiful moments as a junior priest struggling to find meaning in his faith, creating interesting tension against Blanc’s cold, grim logic. With them working together, Wake Up Dead Man becomes a fun story that examines the purpose faith can have in our lives.

One thing director Guillermo del Toro is gonna do is make a luxurious, sumptuous-ass movie with over-the-top sets and costuming. But Frankenstein is not just a visual delight. Oscar Isaac as Victor Frankenstein and Jacob Elordi as his monster give incredible performances that are both grounded in the movie’s late Victorian aesthetic while resonating with the stories of today. A quote unquote learned man irresponsibly using technology to create something he doesn’t understand and in his arrogance tries to control that winds up destroying his life and others? It’s not that Frankenstein is any one allegory for today, it has multiple applications.

And while we have numerous Frankenstein adaptations, there’s nothing quite like watching GDT do it. You just know that man is gonna grab all the production designers, make-up artists, and costumers, give them some cash, and say essentially “Cook,” and damn if they didn’t do exactly that.

I live for The Great British Baking Show (known as The Great British Bake Off outside the US). When the sun starts setting at 4:30PM and seasonal affect starts disordering my life, I’m okay because I know that means it’s Baking Show season. This year, the show has done some interesting things with the format, trying new variations on the show’s technical challenge where bakers are tasked with making something with stripped-down directions. I wish the challenges weren’t so overly focused on sweets, but it’s always fun learning the absolutely bonkers names the Brits have for their pastries. There is no way in a logical world that an oatmeal bar like this should be called a flapjack — it doesn’t even flap! Honestly, yelling about how British English is Wrong is just as much fun as watching the amateur bakers themselves.

The first half of the final season of Stranger Things is out, and while we can quibble about whether or not it’s quality television, it is good for one specific reason: it is finally ending. The show started off really strong, telling a fun tale about kids saving the world from the adults that are trying to ruin it. But that kind of storytelling got lost in the near decade between the first season and now — even though the Duffer Brothers want us to believe that it’s only been four years since Will first went to the Upside Down. It’s okay that stories end, and I’m glad we’ve got the opportunity to end this show on a high note by returning focus to what made it so great in the first place — them meddling kids.

Squid Game is another one of Netflix’s tentpole hits that has come to an end this year. Gi-hun / Player 456 (Lee Jung-jae) has returned to Mr. Beast’s Murder Island to expose the organizers of the deadly games once and for all. He’s befriended another crop of desperate people willing to do whatever for life-changing amounts of cash and just like in the first two seasons it’s brutal to watch the games destroy them one by one.

Clocking in at just under 200 days, James Garfield has the second shortest term of a US president, and I was genuinely enthralled watching Death By Lightning chart his rise to the office and tragic fall via an assassin’s bullet. As with Frankenstein, Netflix is once again on time with a metaphor appropriate for current events. Death By Lightning takes a look at how incendiary political discourse, like the kind fomented against Garfield by his own party, can lead to violence.

But more than the prescient political commentary, the performances make this show. Michael Shannon imbues Garfield with a salt-of-the-earth quality that makes you root hard for him. Shea Whigham has entered his character actor villain era playing New York Senator Roscoe Conkling, and Matthew “Mr. Darcy / Tom Wambsgans” Macfadyen gives a heartbreaking performance playing Garfield’s assassin Charles Guiteau.

The show’s best moments come from Nick Offerman as Garfield’s reluctant vice president, Chester A. Arthur. Offerman as Arthur is regency-era Ron Swanson. Throughout most of the show’s four episodes, Offerman is either drunk, fighting, raving about sausages, or a combination of all three. That man is having a blast chewing the scenery in a top hat and mutton chops, and I would genuinely watch a whole White House sitcom with him as the star.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-53')">
            <div class="source">The Verge</div>
            <div class="title">In 2025, AI became a lightning rod for gamers and developers</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-53" style="display:none;">
            <h2>In 2025, AI became a lightning rod for gamers and developers</h2>
            <p><strong>The Verge | 2025-12-24</strong></p>
            <a class="original-link" href="https://www.theverge.com/entertainment/848368/gen-ai-video-games-2025">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Gen-AI showed up in the year’s biggest releases including game of the year.

Gen-AI showed up in the year’s biggest releases including game of the year.

2025 was the year generative AI made its presence felt in the video game industry. Its use has been discovered in some of the most popular games of the year, and CEOs from some of the largest game studios claim it’s being implemented everywhere in the industry including in their own development processes. Meanwhile, rank-and-file developers, especially in the indie games space, are pushing back against its encroachment, coming up with ways to signal their games are gen-AI free.

Generative AI has largely replaced NFTs as the buzzy trend publishers are chasing. Its proponents claim that the technology will be a great democratization force in video game development, as gen AI’s ability to amalgamate images, text, audio, and video could shorten development times and shrink budgets — ameliorating two major problems plaguing the industry right now. In service to that idea, numerous video game studios have announced partnerships with gen-AI companies.

Ubisoft has technology that can generate short snippets of dialogue called barks and has gen-AI powered NPCs that players can have conversations with. EA has partnered with Stability AI, Microsoft is using AI to analyze and generate gameplay. Outside of official partnerships, major game companies like Nexon, Krafton, and Square Enix are vocally embracing gen AI.

As a result, gen AI is starting to show up in games in a big way. Up until this point, gen AI in gaming had been mostly relegated to fringe cases — either prototypes or small, low-quality games that generally get lost in the tens of thousands of titles released on Steam each year. But now, gen AI is cropping up in the year’s biggest releases. ARC Raiders, one of the breakout multiplayer shooter hits of the year, used gen AI for character dialogue. Call of Duty: Black Ops 7 used gen-AI images. Even 2025’s TGA Game of the Year, Clair Obscur: Expedition 33, featured gen-AI images before they were quietly removed.

Reaction to this encroachment from both players and developers has been mixed. It seems like generally, players don’t like gen AI showing up in games. When gen-AI assets were discovered in Anno 117: Pax Romana, the game’s developer Ubisoft claimed the assets “slipped through” review and they were subsequently replaced. When gen-AI assets were found in Black Ops 7, however, Activision acknowledged the issue, but kept the images in the game. Critical response has also been lopsided. ARC Raiders was awarded low scores with reviewers specifically citing the use of gen AI as the reason. Clair Obscur, though, was nigh universally praised and its use of gen AI, however temporary, has barely been mentioned.

It seems like developers are sensitive to the public’s distaste for gen AI but are unwilling to commit to not using it. After gen-AI assets were discovered in Black Ops 7, Activision said it uses the tech to “empower” its developers, not replace them. When asked about gen AI showing up in Battlefield 6, EA VP Rebecka Coutaz called the technology seductive but affirmed it wouldn’t appear in the final product. Swen Vincke, CEO of Baldur’s Gate 3 developer Larian, said gen AI is being used for the studio’s next game Divinity but only for generating concepts and ideas. Everything in the finished game, he claimed, would be made by humans. He also hinted at why game makers insist on using the tech despite the backlash developers usually receive whenever it’s found.

“This is a tech-driven industry, so you try stuff,” he told Bloomberg reporter Jason Schreier in an interview. “You can’t afford not to try things because if somebody finds the golden egg and you’re not using it, you’re dead.”

Comments from other CEOs reinforce Vincke’s point. Junghun Lee, the CEO of ARC Raiders’ parent company Nexon, said in an interview that, “It’s important to assume that every game company is now using AI.”

The problem is, though, gen AI doesn’t yet seem to be the golden egg its supporters want people to believe it is. Last year, Keywords Studios, a game development services company, published a report on creating a 2D video game using only gen-AI tools. The company claimed that gen-AI tools can streamline some development processes but ultimately cannot replace the work of human talent. Discovering gen AI in Call of Duty and Pax Romana was possible precisely because of the low-quality of the images that were found. With Ubisoft’s interactive gen-AI NPCs, the dialogue they spout sounds unnatural and stilted. Players in the 2025 Chinese martial arts MMORPG Where Winds Meet are manipulating its AI chatbot NPCs to break the game, just like Fortnite players were able to make AI-powered Darth Vader swear.

For all the promises of gen AI, its current results do not live up to expectations. So why is it everywhere?

One reason is the competitive edge AI might but currently can’t provide that Swen Vincke alluded to in his interview with Bloomberg. Another reason is also the simplest: it’s the economy, stupid. Despite inflation, flagging consumer confidence and spending, and rising unemployment, the stock market is still booming, propped up by the billions and billions of dollars being poured into AI tech. Game makers in search of capital to keep business and profits going want in on that. Announcing AI initiatives and touting the use of AI tools — even if those tools have a relatively minor impact on the final product — can be a way to signal to AI-eager investors that a game company is worth their money.

That might explain why the majority of gen-AI’s supporters in gaming come from the C-suite of AAA studios and not smaller indie outfits who almost universally revile the tech. Indies face the same economic pressure as bigger studios but have far fewer resources to navigate those pressures. Ostensibly, indie developers are the ones who stand to benefit the most from the tech but, so far, are its biggest opponents. They are pushing back against the assertion that gen AI is everywhere, being used by everybody, with some marking their games with anti-AI logos proclaiming their games were made wholly by humans.

For some indie developers, using gen AI defeats the purpose of game making entirely. The challenge of coming up with ideas and solutions to development problems — the things gen AI is supposed to automate — is a big part of game making’s appeal to them. There are also moral and environmental implications indie developers seem especially sensitive to. Gen-AI outputs are cobbled from existing bodies of work that were often used without consent or compensation. AI data centers are notorious for consumptive energy usage and polluting their surrounding areas, which are increasingly focused in low-income and minority communities.With its unrealized promises and so-far shoddy outputs, it’s easy to think of gen AI as gaming’s next flash in the pan the way NFTs were. But with gaming’s biggest companies increasingly reporting their use, gen AI will remain a lightning rod in game development — until the tech improves, or, like with NFTs, the bubble pops.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-54')">
            <div class="source">MIT Technology Review</div>
            <div class="title">MIT Technology Review’s most popular stories of 2025</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-54" style="display:none;">
            <h2>MIT Technology Review’s most popular stories of 2025</h2>
            <p><strong>MIT Technology Review | 2025-12-26</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2025/12/26/1130318/mit-technology-review-most-popular-stories-2025/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">It&#39;s been a busy and productive year here at MIT Technology Review. We published magazine issues on power, creativity, innovation, bodies, relationships, and security. We hosted 14 exclusive virtual conversations with our editors and outside experts in our subscriber-only series, Roundtables, and held two events on MIT’s campus. And we published hundreds of articles online, following new developments in computing, climate tech, robotics, and more.

As the year winds down, we wanted to give you a chance to revisit a bit of this work with us. Whether we were covering the red-hot rise of artificial intelligence or the future of biotech, these are some of the stories that resonated the most with our readers.

We did the math on AI’s energy footprint. Here’s the story you haven’t heard.

Understanding AI’s energy use was a huge global conversation in 2025 as hundreds of millions of people began using generative AI tools on a regular basis. Senior reporters James O’Donnell and Casey Crownhart dug into the numbers and published an unprecedented look at AI’s resource demand, down to the level of a single query, to help us know how much energy and water AI may require moving forward.

We’re learning more about what vitamin D does to our bodies

Vitamin D deficiency is widespread, particularly in the winter when there’s less sunlight to drive its production in our bodies. The “sunshine vitamin” is important for bone health, but as senior reporter Jessica Hamzelou reported, recent research is also uncovering surprising new insights into other ways it might influence our bodies, including our immune systems and heart health.

Senior editor Will Douglas Heaven’s expansive look at how to define AI was published in 2024, but it still managed to connect with many readers this year. He lays out why no one can agree on what AI is—and explains why that ambiguity matters, and how it can inform our own critical thinking about this technology.

Ethically sourced “spare” human bodies could revolutionize medicine

In this thought-provoking op-ed, a team of experts at Stanford University argue that creating living human bodies that can’t think, don’t have any awareness, and can’t feel pain could shake up medical research and drug development by providing essential biological materials for testing and transplantation. Recent advances in biotechnology now provide a potential pathway to such “bodyoids,” though plenty of technical challenges and ethical hurdles remain.

It’s surprisingly easy to stumble into a relationship with an AI chatbot

Chatbots were everywhere this year, and reporter Rhiannon Williams chronicled how quickly people can develop bonds with one. That’s all right for some people, she notes, but dangerous for others. Some folks even describe unintentionally forming romantic relationships with chatbots. This is a trend we’ll definitely be keeping an eye on in 2026.

The electric grid is bracing for disruption from more frequent storms and fires, as well as an uncertain policy and regulatory landscape. And in many ways, the publicly owned utility company Lincoln Electric in Nebraska is an ideal lens through which to examine this shift as it works through the challenges of delivering service that’s reliable, affordable, and sustainable.

Exclusive: A record-breaking baby has been born from an embryo that’s over 30 years old

This year saw the birth of the world’s “oldest baby”: Thaddeus Daniel Pierce, who arrived on July 26. The embryo he developed from was created in 1994 during the early days of IVF and had been frozen and sitting in storage ever since. The new baby’s parents were toddlers at the time, and the embryo was donated to them decades later via a Christian “embryo adoption” agency.

How these two brothers became go-to experts on America’s “mystery drone” invasion

Twin brothers John and Gerald Tedesco teamed up to investigate a concerning new threat—unidentified drones. In 2024 alone, some 350 drones entered airspace over a hundred different US military installations, and many cases went unsolved, according to a top military official. This story takes readers inside the equipment-filled RV the Tedescos created to study mysterious aerial phenomena, and how they made a name for themselves among government officials.

Our newsroom has published this annual look at advances that will matter in the long run for over 20 years. This year’s list featured generative AI search, cleaner jet fuel, long-acting HIV prevention meds, and other emerging technologies that our journalists think are worth watching. We’ll publish the 2026 edition of the list on January 12, so stay tuned. (In the meantime, here’s what didn’t make the cut.)

We asked Al Jean, the longest-serving showrunner, about all the conspiracy theories.

The Cybertruck, sycophantic AI, and humanoid robots all made this year’s list of the biggest technology failures.

It’s a popular example of the “Mandela effect,” or a collective false memory. And while some people may laugh and move on, others spend years searching for an explanation.

A mix of technology and politics has given an unprecedented boost to once-fringe ideas—but they are pretty much the same fantasies that have been spreading for hundreds of years.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-55')">
            <div class="source">MIT Technology Review</div>
            <div class="title">The paints, coatings, and chemicals making the world a cooler place</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-55" style="display:none;">
            <h2>The paints, coatings, and chemicals making the world a cooler place</h2>
            <p><strong>MIT Technology Review | 2025-12-26</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2025/12/26/1129301/paint-coating-chemicals-materials-cooling-air-conditioning/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">It’s getting harder to beat the heat. During the summer of 2025, heat waves knocked out power grids in North America, Europe, and the Middle East. Global warming means more people need air-­conditioning, which requires more power and strains grids. But a millennia-old idea (plus 21st-century tech) might offer an answer: radiative cooling. Paints, coatings, and textiles can scatter sunlight and dissipate heat—no additional energy required.

“Radiative cooling is universal—it exists everywhere in our daily life,” says Qiaoqiang Gan, a professor of materials science and applied physics at King Abdullah University of Science and Technology in Saudi Arabia. Pretty much any object will absorb heat from the sun during the day and radiate some of it back at night. It’s why cars parked outside overnight are often covered with condensation, Gan says—their metal roofs dissipate heat into the sky, cooling the surfaces below the ambient air temperature. That’s how you get dew.

Humans have harnessed this basic natural process for thousands of years. Desert peoples in Iran, North Africa, and India manufactured ice by leaving pools of water exposed to clear desert skies overnight, when radiative cooling happens naturally; other cultures constructed “cool roofs” capped with reflective materials that scattered sunlight and lowered interior temperatures. “People have taken advantage of this effect, either knowingly or unknowingly, for a very long time,” says Aaswath Raman, a materials scientist at UCLA and cofounder of the radiative­cooling startup SkyCool Systems.

Modern approaches, as demonstrated everywhere from California supermarket rooftops to Japan’s Expo 2025 pavilion, go even further. Normally, if the sun is up and pumping in heat, surfaces can’t get cooler than the ambient temperature. But back in 2014, Raman and his colleagues achieved radiative cooling in the daytime. They customized photonic films to absorb and then radiate heat at infrared wavelengths between eight and 13 micrometers—a range of electromagnetic wavelengths called an “atmospheric window,” because that radiation escapes to space rather than getting absorbed. Those films could dissipate heat even under full sun, cooling the inside of a building to 9 °F below ambient temperatures, with no AC or energy source required.

That was proof of concept; today, Raman says, the industry has mostly shifted away from advanced photonics that use the atmospheric-window effect to simpler sunlight-scattering materials. Ceramic cool roofs, nanostructure coatings, and reflective polymers all offer the possibility of diverting more sunlight across all wavelengths, and they’re more durable and scalable.

Now the race is on. Startups such as SkyCool, Planck Energies, Spacecool, and i2Cool are competing to commercially manufacture and sell coatings that reflect at least 94% of sunlight in most climates, and above 97% in humid tropical ones. Pilot projects have already provided significant cooling to residential buildings, reducing AC energy needs by 15% to 20% in some cases.

This idea could go way beyond reflective rooftops and roads. Researchers are developing reflective textiles that can be worn by people most at risk of heat exposure. “This is personal thermal management,” says Gan. “We can realize passive cooling in T-shirts, sportswear, and garments.”

Of course, these technologies and materials have limits. Like solar power grids, they’re vulnerable to weather. Clouds prevent reflected sunlight from bouncing into space. Dust and air pollution dim materials’ bright surfaces. Lots of coatings lose their reflectivity after a few years. And the cheapest and toughest materials used in radiative cooling tend to rely on Teflon and other fluoropolymers, “forever chemicals” that don’t biodegrade, posing an environmental risk. “They are the best class of products that tend to survive outdoors,” says Raman. “So for long-term scale-up, can you do it without materials like those fluoropolymers and still maintain the durability and hit this low cost point?”

As with any other solution to the problems of climate change, one size won’t fit all. “We cannot be overoptimistic and say that radiative cooling can address all our future needs,” Gan says. “We still need more efficient active air-conditioning.” A shiny roof isn’t a panacea, but it’s still pretty cool.

Becky Ferreira is a science reporter based in upstate New York and author of First Contact: The Story of Our Obsession with Aliens.

As early electric cars age out, hundreds of thousands of used batteries are flooding the market, fueling a gray recycling economy even as Beijing and big manufacturers scramble to build a more orderly system.

Omar Yaghi thinks crystals with gaps that capture moisture could bring technology from “Dune” to the arid parts of Earth.

And why many scientists are freaked out about the first serious for-profit company moving into the solar geoengineering field.

How AI and renewables are shifting the energy landscape.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-56')">
            <div class="source">MIT Technology Review</div>
            <div class="title">AI Wrapped: The 14 AI terms you couldn’t avoid in 2025</div>
            <div class="meta">2025-12-25</div>
        </div>
        
        <div id="content-56" style="display:none;">
            <h2>AI Wrapped: The 14 AI terms you couldn’t avoid in 2025</h2>
            <p><strong>MIT Technology Review | 2025-12-25</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2025/12/25/1130298/ai-wrapped-the-14-ai-terms-you-couldnt-avoid-in-2025/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">If the past 12 months have taught us anything, it’s that the AI hype train is showing no signs of slowing. It’s hard to believe that at the beginning of the year, DeepSeek had yet to turn the entire industry on its head, Meta was better known for trying (and failing) to make the metaverse cool than for its relentless quest to dominate superintelligence, and vibe coding wasn’t a thing.

If that’s left you feeling a little confused, fear not. As we near the end of 2025, our writers have taken a look back over the AI terms that dominated the year, for better or worse.

Make sure you take the time to brace yourself for what promises to be another bonkers year.

As long as people have been hyping AI, they have been coming up with names for a future, ultra-powerful form of the technology that could bring about utopian or dystopian consequences for humanity. “Superintelligence” is that latest hot term. Meta announced in July that it would form an AI team to pursue superintelligence, and it was reportedly offering nine-figure compensation packages to AI experts from the company’s competitors to join.

In December, Microsoft’s head of AI followed suit, saying the company would be spending big sums, perhaps hundreds of billions, on the pursuit of superintelligence. If you think superintelligence is as vaguely defined as artificial general intelligence, or AGI, you’d be right! While it’s conceivable that these sorts of technologies will be feasible in humanity’s long run, the question is really when, and whether today’s AI is good enough to be treated as a stepping stone toward something like superintelligence. Not that that will stop the hype kings. —James O’Donnell

Thirty years ago, Steve Jobs said everyone in America should learn how to program a computer. Today, people with zero knowledge of how to code can knock up an app, game, or website in no time at all thanks to vibe coding—a catch-all phrase coined by OpenAI cofounder Andrej Karpathy. To vibe-code, you simply prompt generative AI models’ coding assistants to create the digital object of your desire and accept pretty much everything they spit out. Will the result work? Possibly not. Will it be secure? Almost definitely not, but the technique’s biggest champions aren’t letting those minor details stand in their way. Also—it sounds fun! — Rhiannon Williams

One of the biggest AI stories over the past year has been how prolonged interactions with chatbots can cause vulnerable people to experience delusions and, in some extreme cases, can either cause or worsen psychosis. Although “chatbot psychosis” is not a recognized medical term, researchers are paying close attention to the growing anecdotal evidence from users who say it’s happened to them or someone they know. Sadly, the increasing number of lawsuits filed against AI companies by the families of people who died following their conversations with chatbots demonstrate the technology’s potentially deadly consequences. —Rhiannon Williams

Few things kept the AI hype train going this year more than so-called reasoning models, LLMs that can break down a problem into multiple steps and work through them one by one. OpenAI released its first reasoning models, o1 and o3, a year ago.

A month later, the Chinese firm DeepSeek took everyone by surprise with a very fast follow, putting out R1, the first open-source reasoning model. In no time, reasoning models became the industry standard: All major mass-market chatbots now come in flavors backed by this tech. Reasoning models have pushed the envelope of what LLMs can do, matching top human performances in prestigious math and coding competitions. On the flip side, all the buzz about LLMs that could “reason” reignited old debates about how smart LLMs really are and how they really work. Like “artificial intelligence” itself, “reasoning” is technical jargon dressed up with marketing sparkle. Choo choo! —Will Douglas Heaven

For all their uncanny facility with language, LLMs have very little common sense. Put simply, they don’t have any grounding in how the world works. Book learners in the most literal sense, LLMs can wax lyrical about everything under the sun and then fall flat with a howler about how many elephants you could fit into an Olympic swimming pool (exactly one, according to one of Google DeepMind’s LLMs).

World models—a broad church encompassing various technologies—aim to give AI some basic common sense about how stuff in the world actually fits together. In their most vivid form, world models like Google DeepMind’s Genie 3 and Marble, the much-anticipated new tech from Fei-Fei Li’s startup World Labs, can generate detailed and realistic virtual worlds for robots to train in and more. Yann LeCun, Meta’s former chief scientist, is also working on world models. He has been trying to give AI a sense of how the world works for years, by training models to predict what happens next in videos. This year he quit Meta to focus on this approach in a new start up called Advanced Machine Intelligence Labs. If all goes well, world models could be the next thing. —Will Douglas Heaven

Have you heard about all the people saying no thanks, we actually don’t want a giant data center plopped in our backyard? The data centers in question—which tech companies want to built everywhere, including space—are typically referred to as hyperscalers: massive buildings purpose-built for AI operations and used by the likes of OpenAI and Google to build bigger and more powerful AI models. Inside such buildings, the world’s best chips hum away training and fine-tuning models, and they’re built to be modular and grow according to needs.

It’s been a big year for hyperscalers. OpenAI announced, alongside President Donald Trump, its Stargate project, a $500 billion joint venture to pepper the country with the largest data centers ever. But it leaves almost everyone else asking: What exactly do we get out of it? Consumers worry the new data centers will raise their power bills. Such buildings generally struggle to run on renewable energy. And they don’t tend to create all that many jobs. But hey, maybe these massive, windowless buildings could at least give a moody, sci-fi vibe to your community. —James O’Donnell

The lofty promises of AI are levitating the economy. AI companies are raising eye-popping sums of money and watching their valuations soar into the stratosphere. They’re pouring hundreds of billions of dollars into chips and data centers, financed increasingly by debt and eyebrow-raising circular deals. Meanwhile, the companies leading the gold rush, like OpenAI and Anthropic, might not turn a profit for years, if ever. Investors are betting big that AI will usher in a new era of riches, yet no one knows how transformative the technology will actually be.

Most organizations using AI aren’t yet seeing the payoff, and AI work slop is everywhere. There’s scientific uncertainty about whether scaling LLMs will deliver superintelligence or whether new breakthroughs need to pave the way. But unlike their predecessors in the dot-com bubble, AI companies are showing strong revenue growth, and some are even deep-pocketed tech titans like Microsoft, Google, and Meta. Will the manic dream ever burst? —Michelle Kim

This year, AI agents were everywhere. Every new feature announcement, model drop, or security report throughout 2025 was peppered with mentions of them, even though plenty of AI companies and experts disagree on exactly what counts as being truly “agentic,” a vague term if ever there was one. No matter that it’s virtually impossible to guarantee that an AI acting on your behalf out in the wide web will always do exactly what it’s supposed to do—it seems as though agentic AI is here to stay for the foreseeable. Want to sell something? Call it agentic! —Rhiannon Williams

Early this year, DeepSeek unveiled its new model DeepSeek R1, an open-source reasoning model that matches top Western models but costs a fraction of the price. Its launch freaked Silicon Valley out, as many suddenly realized for the first time that huge scale and resources were not necessarily the key to high-level AI models. Nvidia stock plunged by 17% the day after R1 was released.

The key to R1’s success was distillation, a technique that makes AI models more efficient. It works by getting a bigger model to tutor a smaller model: You run the teacher model on a lot of examples and record the answers, and reward the student model as it copies those responses as closely as possible, so that it gains a compressed version of the teacher’s knowledge.  —Caiwei Chen

As people across the world spend increasing amounts of time interacting with chatbots like ChatGPT, chatbot makers are struggling to work out the kind of tone and “personality” the models should adopt. Back in April, OpenAI admitted it’d struck the wrong balance between helpful and sniveling, saying a new update had rendered GPT-4o too sycophantic. Having it suck up to you isn’t just irritating—it can mislead users by reinforcing their incorrect beliefs and spreading misinformation. So consider this your reminder to take everything—yes, everything—LLMs produce with a pinch of salt. —Rhiannon Williams

If there is one AI-related term that has fully escaped the nerd enclosures and entered public consciousness, it’s “slop.” The word itself is old (think pig feed), but “slop” is now commonly used to refer to low-effort, mass-produced content generated by AI, often optimized for online traffic. A lot of people even use it as a shorthand for any AI-generated content. It has felt inescapable in the past year: We have been marinated in it, from fake biographies to shrimp Jesus images to surreal human-animal hybrid videos.

But people are also having fun with it. The term’s sardonic flexibility has made it easy for internet users to slap it on all kinds of words as a suffix to describe anything that lacks substance and is absurdly mediocre: think “work slop” or “friend slop.” As the hype cycle resets, “slop” marks a cultural reckoning about what we trust, what we value as creative labor, and what it means to be surrounded by stuff that was made for engagement rather than expression. —Caiwei Chen

Did you come across the hypnotizing video from earlier this year of a humanoid robot putting away dishes in a bleak, gray-scale kitchen? That pretty much embodies the idea of physical intelligence: the idea that advancements in AI can help robots better move around the physical world.

It’s true that robots have been able to learn new tasks faster than ever before, everywhere from operating rooms to warehouses. Self-driving-car companies have seen improvements in how they simulate the roads, too. That said, it’s still wise to be skeptical that AI has revolutionized the field. Consider, for example, that many robots advertised as butlers in your home are doing the majority of their tasks thanks to remote operators in the Philippines.

The road ahead for physical intelligence is also sure to be weird. Large language models train on text, which is abundant on the internet, but robots learn more from videos of people doing things. That’s why the robot company Figure suggested in September that it would pay people to film themselves in their apartments doing chores. Would you sign up? —James O&#39;Donnell

AI models are trained by devouring millions of words and images across the internet, including copyrighted work by artists and writers. AI companies argue this is “fair use”—a legal doctrine that lets you use copyrighted material without permission if you transform it into something new that doesn’t compete with the original. Courts are starting to weigh in. In June, Anthropic’s training of its AI model Claude on a library of books was ruled fair use because the technology was “exceedingly transformative.”

That same month, Meta scored a similar win, but only because the authors couldn’t show that the company’s literary buffet cut into their paychecks. As copyright battles brew, some creators are cashing in on the feast. In December, Disney signed a splashy deal with OpenAI to let users of Sora, the AI video platform, generate videos featuring more than 200 characters from Disney&#39;s franchises. Meanwhile, governments around the world are rewriting copyright rules for the content-guzzling machines. Is training AI on copyrighted work fair use? As with any billion-dollar legal question, it depends. —Michelle Kim

Just a few short years ago, an entire industry was built around helping websites rank highly in search results (okay, just in Google). Now search engine optimization (SEO), is giving way to GEO—generative engine optimization—as the AI boom forces brands and businesses to scramble to maximize their visibility in AI, whether that’s in AI-enhanced search results like Google’s AI Overviews or within responses from LLMs. It’s no wonder they’re freaked out. We already know that news companies have experienced a colossal drop in search-driven web traffic, and AI companies are working on ways to cut out the middleman and allow their users to visit sites from directly within their platforms. It’s time to adapt or die. —Rhiannon Williams

The idea that machines will be as smart as—or smarter than—humans has hijacked an entire industry. But look closely and you’ll see it’s a myth that persists for many of the same reasons conspiracies do.

The experimental model won&#39;t compete with the biggest and best, but it could tell us why they behave in weird ways—and how trustworthy they really are.

Four ways to think about this year&#39;s reckoning

They managed to cut the size of the AI reasoning model by more than half—and claim it can now answer politically sensitive questions once off limits in Chinese AI systems.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-57')">
            <div class="source">MIT Technology Review</div>
            <div class="title">Meet the man hunting the spies in your smartphone</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-57" style="display:none;">
            <h2>Meet the man hunting the spies in your smartphone</h2>
            <p><strong>MIT Technology Review | 2025-12-24</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2025/12/24/1129294/ronald-deibert-citizen-lab-digital-threats-spies-cybersecurity/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">In April 2025, Ronald Deibert left all electronic devices at home in Toronto and boarded a plane. When he landed in Illinois, he took a taxi to a mall and headed directly to the Apple Store to purchase a new laptop and iPhone. He’d wanted to keep the risk of having his personal devices confiscated to a minimum, because he knew his work made him a prime target for surveillance. “I’m traveling under the assumption that I am being watched, right down to exactly where I am at any moment,” Deibert says.

Deibert directs the Citizen Lab, a research center he founded in 2001 to serve as “counterintelligence for civil society.” Housed at the University of Toronto, the lab operates independently of governments or corporate interests, relying instead on research grants and private philanthropy for financial support. It’s one of the few institutions that investigate cyberthreats exclusively in the public interest, and in doing so, it has exposed some of the most egregious digital abuses of the past two decades.

For many years, Deibert and his colleagues have held up the US as the standard for liberal democracy. But that’s changing, he says: “The pillars of democracy are under assault in the United States. For many decades, in spite of its flaws, it has upheld norms about what constitutional democracy looks like or should aspire to. [That] is now at risk.”

Even as some of his fellow Canadians avoided US travel after Donald Trump’s second election, Deibert relished the opportunity to visit. Alongside his meetings with human rights defenders, he also documented active surveillance at Columbia University during the height of its student protests. Deibert snapped photos of drones above campus and noted the exceptionally strict security protocols. “It was unorthodox to go to the United States,” he says. “But I really gravitate toward problems in the world.”

Deibert, 61, grew up in East Vancouver, British Columbia, a gritty area with a boisterous countercultural presence. In the ’70s, Vancouver brimmed with draft dodgers and hippies, but Deibert points to American investigative journalism—exposing the COINTELPRO surveillance program, the Pentagon Papers, Watergate—as the seed of his respect for antiestablishment sentiment. He didn’t imagine that this fascination would translate into a career, however.

“My horizons were pretty low because I came from a working-class family, and there weren’t many people in my family—in fact, none—who went on to university,” he says.

Deibert eventually entered a graduate program in international relations at the University of British Columbia. His doctoral research brought him to a field of inquiry that would soon explode: the geopolitical implications of the nascent internet.

“In my field, there were a handful of people beginning to talk about the internet, but it was very shallow, and that frustrated me,” he says. “And meanwhile, computer science was very technical, but not political—[politics] was almost like a dirty word.”

Deibert continued to explore these topics at the University of Toronto when he was appointed to a tenure-track professorship, but it wasn’t until after he founded the Citizen Lab in 2001 that his work rose to global prominence.

What put the lab on the map, Deibert says, was its 2009 report “Tracking GhostNet,” which uncovered a digital espionage network in China that had breached offices of foreign embassies and diplomats in more than 100 countries, including the office of the Dalai Lama. The report and its follow-up in 2010 were among the first to publicly expose cybersurveillance in real time. In the years since, the lab has published over 180 such analyses, garnering praise from human rights advocates ranging from Margaret Atwood to Edward Snowden.

The lab has rigorously investigated authoritarian regimes around the world (Deibert says both Russia and China have his name on a “list” barring his entry). The group was the first to uncover the use of commercial spyware to surveil people close to the Saudi dissident and Washington Post journalist Jamal Khashoggi prior to his assassination, and its research has directly informed G7 and UN resolutions on digital repression and led to sanctions on spyware vendors. Even so, in 2025 US Immigration and Customs Enforcement reactivated a $2 million contract with the spyware vendor Paragon. The contract, which the Biden administration had previously placed under a stop-work order, resembles steps taken by governments in Europe and Israel that have also deployed domestic spyware to address security concerns.

“It saves lives, quite literally,” Cindy Cohn, executive director of the Electronic Frontier Foundation, says of the lab’s work. “The Citizen Lab [researchers] were the first to really focus on technical attacks on human rights activists and democracy activists all around the world. And they’re still the best at it.”

When recruiting new Citizen Lab employees (or “Labbers,” as they refer to one another), Deibert forgoes stuffy, pencil-pushing academics in favor of brilliant, colorful personalities, many of whom personally experienced repression from some of the same regimes the lab now investigates.

Noura Aljizawi, a researcher on digital repression who survived torture at the hands of the al-Assad regime in Syria, researches the distinct threat that digital technologies pose to women and queer people, particularly when deployed against exiled nationals. She helped create Security Planner, a tool that gives personalized, expert-reviewed guidance to people looking to improve their digital hygiene, for which the University of Toronto awarded her an Excellence Through Innovation Award.

Work for the lab is not without risk. Citizen Lab fellow Elies Campo, for example, was followed and photographed after the lab published a 2022 report that exposed the digital surveillance of dozens of Catalonian citizens and members of parliament, including four Catalonian presidents who were targeted during or after their terms.

Still, the lab’s reputation and mission make recruitment fairly easy, Deibert says. “This good work attracts a certain type of person,” he says. “But they’re usually also drawn to the sleuthing. It’s detective work, and that can be highly intoxicating—even addictive.”

Deibert frequently deflects the spotlight to his fellow Labbers. He rarely discusses the group’s accomplishments without referencing two senior researchers, Bill Marczak and John Scott-Railton, alongside other staffers. And on the occasion that someone decides to leave the Citizen Lab to pursue another position, this appreciation remains.

“We have a saying: Once a Labber, always a Labber,” Deibert says.

While in the US, Deibert taught a seminar on the Citizen Lab’s work to Northwestern University undergraduates and delivered talks on digital authoritarianism at the Columbia University Graduate School of Journalism. Universities in the US had been subjected to funding cuts and heightened scrutiny from the Trump administration, and Deibert wanted to be “in the mix” at such institutions to respond to what he sees as encroaching authoritarian practices by the US government.

Since Deibert’s return to Canada, the lab has continued its work unearthing digital threats to civil society worldwide, but now Deibert must also contend with the US—a country that was once his benchmark for democracy but has become another subject of his scrutiny. “I do not believe that an institution like the Citizen Lab could exist right now in the United States,” he says. “The type of research that we pioneered is under threat like never before.”

He is particularly alarmed by the increasing pressures facing federal oversight bodies and academic institutions in the US. In September, for example, the Trump administration defunded the Council of the Inspectors General on Integrity and Efficiency, a government organization dedicated to preventing waste, fraud, and abuse within federal agencies, citing partisanship concerns. The White House has also threatened to freeze federal funding to universities that do not comply with administration directives related to gender, DEI, and campus speech. These sorts of actions, Deibert says, undermine the independence of watchdogs and research groups like the Citizen Lab.

Cohn, the director of the EFF, says the lab’s location in Canada allows it to avoid many of these attacks on institutions that provide accountability. “Having the Citizen Lab based in Toronto and able to continue to do its work largely free of the things we’re seeing in the US,” she says, “could end up being tremendously important if we’re going to return to a place of the rule of law and protection of human rights and liberties.”

Finian Hazen is a journalism and political science student at Northwestern University.

The sunshine vitamin could affect your immune system and heart health.

The idea that machines will be as smart as—or smarter than—humans has hijacked an entire industry. But look closely and you’ll see it’s a myth that persists for many of the same reasons conspiracies do.

The experimental model won&#39;t compete with the biggest and best, but it could tell us why they behave in weird ways—and how trustworthy they really are.

As early electric cars age out, hundreds of thousands of used batteries are flooding the market, fueling a gray recycling economy even as Beijing and big manufacturers scramble to build a more orderly system.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-58')">
            <div class="source">MIT Technology Review</div>
            <div class="title">Four bright spots in climate news in 2025</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-58" style="display:none;">
            <h2>Four bright spots in climate news in 2025</h2>
            <p><strong>MIT Technology Review | 2025-12-24</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2025/12/24/1130191/good-climate-news-2025/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Climate news hasn’t been great in 2025. Global greenhouse-gas emissions hit record highs (again). This year is set to be either the second or third warmest on record. Climate-fueled disasters like wildfires in California and flooding in Indonesia and Pakistan devastated communities and caused billions in damage.

In addition to these worrying indicators of our continued contributions to climate change and their obvious effects, the world’s largest economy has made a sharp U-turn on climate policy this year. The US under the Trump administration withdrew from the Paris Agreement, cut funds for climate research, and scrapped billions of dollars in funding for climate tech projects.

We’re in a severe situation with climate change. But for those looking for bright spots, there was some good news in 2025. Here are a few of the positive stories our climate reporters noticed this year.

One of the most notable and encouraging signs of progress this year occurred in China. The world’s second-biggest economy and biggest climate polluter has managed to keep carbon dioxide emissions flat for the last year and a half, according to an analysis in Carbon Brief.

That’s happened before, but only when the nation’s economy was retracting, including in the midst of the covid-19 pandemic. But emissions are now falling even as China’s economy is on track to grow about 5% this year, and electricity demands continue to rise.

So what’s changed? China has now installed so much solar and wind, and put so many EVs on the road, that its economy can continue to expand without increasing the amount of carbon dioxide it’s pumping into the atmosphere, decoupling the traditional link between emissions and growth.

Specifically, China added an astounding 240 gigawatts of solar power capacity and 61 gigawatts of wind power in the first nine months of the year, the Carbon Brief analysis noted. That’s nearly as much solar power as the US has installed in total, in just the first three quarters of this year.

It’s too early to say China’s emissions have peaked, but the country has said it will officially reach that benchmark before 2030.

To be clear, China still isn’t moving fast enough to keep the world on track for meeting relatively safe temperature targets. (Indeed, very few countries are.) But it’s now both producing most of the world’s clean energy technologies and curbing its emissions growth, providing a model for cleaning up industrial economies without sacrificing economic prosperity—and setting the stage for faster climate progress in the coming years.

It’s hard to articulate just how quickly batteries for grid storage are coming online. These massive arrays of cells can soak up electricity when sources like solar are available and prices are low, and then discharge power back to the grid when it’s needed most.

Back in 2015, the battery storage industry had installed only a fraction of a gigawatt of battery storage capacity across the US. That year, it set a seemingly bold target of adding 35 gigawatts by 2035. The sector passed that goal a decade early this year and then hit 40 gigawatts a couple of months later.

Costs are still falling, which could help maintain the momentum for the technology’s deployment. This year, battery prices for EVs and stationary storage fell yet again, reaching a record low, according to data from BloombergNEF. Battery packs specifically used for grid storage saw prices fall even faster than the average; they cost 45% less than last year.

We’re starting to see what happens on grids with lots of battery capacity, too: in California and Texas, batteries are already helping meet demand in the evenings, reducing the need to run natural-gas plants. The result: a cleaner, more stable grid.

The AI boom is complicated for our energy system, as we covered at length this year. Electricity demand is ticking up: the amount of power utilities supplied to US data centers jumped 22% this year and will more than double by 2030.

But at least one positive shift is coming out of AI’s influence on energy: It’s driving renewed interest and investment in next-generation energy technologies.

In the near term, much of the energy needed for data centers, including those that power AI, will likely come from fossil fuels, especially new natural-gas power plants. But tech giants like Google, Microsoft, and Meta all have goals on the books to reduce their greenhouse-gas emissions, so they’re looking for alternatives.

Meta signed a deal with XGS Energy in June to purchase up to 150 megawatts of electricity from a geothermal plant. In October, Google signed an agreement that will help reopen Duane Arnold Energy Center in Iowa, a previously shuttered nuclear power plant.

Geothermal and nuclear could be key pieces of the grid of the future, as they can provide constant power in a way that wind and solar don’t. There’s a long way to go for many of the new versions of the tech, but more money and interest from big, powerful players can’t hurt.

Perhaps the strongest evidence of collective climate progress so far: We’ve already avoided the gravest dangers that scientists feared just a decade ago.

The world is on track for about 2.6 °C of warming over preindustrial conditions by 2100, according to Climate Action Tracker, an independent scientific effort to track the policy progress that nations have made toward their goals under the Paris climate agreement.That’s a lot warmer than we want the planet to ever get. But it’s also a whole degree better than the 3.6 °C path that we were on a decade ago, just before nearly 200 countries signed the Paris deal.

That progress occurred because more and more nations passed emissions mandates, funded subsidies, and invested in research and development—and private industry got busy cranking out vast amounts of solar panels, wind turbines, batteries, and EVs.

The bad news is that progress has stalled. Climate Action Tracker notes that its warming projections have remained stubbornly fixed for the last four years, as nations have largely failed to take the additional action needed to bend that curve closer to the 2 °C goal set out in the international agreement.

But having shaved off a degree of danger is still demonstrable proof that we can pull together in the face of a global threat and address a very, very hard problem. And it means we’ve done the difficult work of laying down the technical foundation for a society that can largely run without spewing ever more greenhouse gas into the atmosphere.

Hopefully, as cleantech continues to improve and climate change steadily worsens, the world will find the collective will to pick up the pace again soon.

As early electric cars age out, hundreds of thousands of used batteries are flooding the market, fueling a gray recycling economy even as Beijing and big manufacturers scramble to build a more orderly system.

Omar Yaghi thinks crystals with gaps that capture moisture could bring technology from “Dune” to the arid parts of Earth.

And why many scientists are freaked out about the first serious for-profit company moving into the solar geoengineering field.

How AI and renewables are shifting the energy landscape.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-59')">
            <div class="source">MIT Technology Review</div>
            <div class="title">Researchers are getting organoids pregnant with human embryos</div>
            <div class="meta">2025-12-23</div>
        </div>
        
        <div id="content-59" style="display:none;">
            <h2>Researchers are getting organoids pregnant with human embryos</h2>
            <p><strong>MIT Technology Review | 2025-12-23</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2025/12/23/1130415/organoid-uterus-microfluidic-chip-embryo/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">At first glance, it looks like the start of a human pregnancy: A ball-shaped embryo presses gently into the receptive lining of the uterus and then grips tight, burrowing in as the first tendrils of a future placenta appear.

This is implantation—the moment that pregnancy officially begins.

Only none of it is happening inside a body. These images were captured in a Beijing laboratory, inside a microfluidic chip, as scientists watched the scene unfold.

In three papers published this week by Cell Press, scientists are reporting what they call the most accurate efforts yet to mimic the first moments of pregnancy in the lab. They’ve taken human embryos from IVF centers and let these merge with “organoids” made of endometrial cells, which form the lining of the uterus.

The reports—two from China and a third involving a collaboration among researchers in the United Kingdom, Spain, and the US—show how scientists are using engineered tissues to better understand early pregnancy and potentially improve IVF outcomes.

“You have an embryo and the endometrial organoid together,” says Jun Wu, a biologist at the University of Texas Southwestern Medical Center, in Dallas, who contributed to both Chinese reports. “That’s the overarching message of all three papers.”

According to the papers, these 3D combinations are the most complete re-creations yet of the first days of pregnancy and should be useful for studying why IVF treatments often fail.

In each case, the experiments were stopped when the embryos were two weeks old, if not sooner. That is due to legal and ethical rules that typically restrict scientists from going any further than 14 days.

In your basic IVF procedure, an egg is fertilized in the lab and allowed to develop into a spherical embryo called a blastocyst—a process that takes a few days. That blastocyst then gets put into a patient’s uterus in the hope it will establish itself there and ultimately become a baby.

But that’s a common failure point. Many patients will learn that their IVF procedure didn’t work because an embryo never attached.

In the new reports, it’s that initial bond between mother and embryo that is being reproduced in the lab. “IVF means in vitro fertilization, but now this is the stage of in vitro implantation,” says Matteo Molè, a biologist at Stanford University whose results with collaborators in Europe are among those published today. “Considering that implantation is a barrier [to pregnancy], we have the potential to increase the success rate if we can model it in the laboratory.”

Normally implantation is entirely hidden from view because it occurs in someone’s uterus, says Hongmei Wang, a developmental biologist at the Beijing Institute for Stem Cell and Regenerative Medicine, who co-led the effort there. Wang often studies monkeys because she can interrupt their pregnancies to collect the tissues she needs to see. “We’ve always hoped to understand human embryo implantation, but we have lacked a way to do so,” she says. “It’s all happening in the uterus.”

In the Beijing study, researchers tested about 50 donated IVF embryos, but they also ran a thousand more experiments using so-called blastoids. The latter are mimics of early-stage human embryos manufactured from stem cells. Blastoids are easy to make in large numbers and, since they aren’t true embryos, don’t have as many ethical rules on their use.

“The question was, if we have these blastoids, what can we use them for?” says Leqian Yu, the senior author of the report from the Beijing Institute. “The obvious next step was implantation. So how do you do that?”

For the Beijing team, the answer was to build a soft silicone chamber with tiny channels to add nutrients and a space to grow the uterine organoid. After that, blastoids—or real embryos—could be introduced through a window in the device, so the “pregnancy” could start.

“The key question we want to try to answer is what is the first cross-talk between embryo and mother,” says Yu. “I think this is maybe the first time we can see the entire process.”

This isn’t the first time researchers have tried using organoids for this kind of research. At least two startup companies have raised funds to commercialize similar systems—in some cases presenting the organoids as a tool to predict IVF success. In addition to Dawn Bio, a startup based in Vienna, there is Simbryo Technologies, in Houston, which last month said it would begin offering “personalized” predictions for IVF patients using blastoids and endometrial organoids.

To do that test, doctors will take a biopsy of a patient’s uterine lining and grow organoids from it. After that, blastoids will be added to the organoids to gauge whether a woman is likely to be able to support a pregnancy or not. If the blastoids don’t start to implant, it could mean the patient’s uterus isn’t receptive and is the reason IVF isn’t working.

The Beijing team thinks the pregnancy organoids could also be used to identify drugs that might help those patients. In their paper, they describe how they made organoids out of tissue taken from women who’ve had repeated IVF failures. Then they tested 1,119 approved drugs on those samples to see if anything improved.

Several seemed to have helpful effects. One chemical, avobenzone, an ingredient in some types of sunblock, increased the chance that a blastoid would start implanting from just 5% of the time to around 25% of the time. Yu says his center hopes to eventually start a clinical trial if they can find the right drug to try.

The Beijing group is working on ways to improve the organoid system so that it’s even more realistic. Right now, it lacks important cell types, including immune cells and a blood supply. Yu says a next step he’s working on is to add blood vessels and tiny pumps to his chip device, so that he can give the organoids a kind of rudimentary circulation.

This means that in the near future, blastoids or embryos could likely be grown longer, raising questions about how far scientists will be able to take pregnancy in the lab. “I think this technology does raise the possibility of growing things longer,” says Wu, who says some view the research as an initial step toward creating babies entirely outside the body.

However, Wu says incubating a human to term in the laboratory remains impossible, for the time being. “This technology is certainly related to ectogenesis, or development outside the body,” he says. “But I don’t think it’s anywhere near an artificial womb. That’s still science fiction.”

The sunshine vitamin could affect your immune system and heart health.

Yes, you can pay $50,000 to clone a pet. But others are using the technology to rescue endangered species.

Preventing the common cold is extremely tricky—but not impossible.

Entrepreneurs say it’s time to safety-test designer baby technology.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-60')">
            <div class="source">The Next Web</div>
            <div class="title">A New Era for TNW.</div>
            <div class="meta">2025-12-22</div>
        </div>
        
        <div id="content-60" style="display:none;">
            <h2>A New Era for TNW.</h2>
            <p><strong>The Next Web | 2025-12-22</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/a-new-era-for-tnw">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">My name is Alexandru Stan, and this article continues the dialogue I began following the acquisition of TNW.

Following the recent transaction, TNW Spaces remains with the Financial Times, while we continue the mission of the website, the events, and the global community.

We already have a dedicated team at tekpon operating the platform, events, and community initiatives. Our objective is to expand and strengthen the team as TNW accelerates its next chapter.

TNW is already a global media platform with millions of readers. We’re not starting over. We are building forward.

The latest rumblings from the EU tech scene, a story from our wise ol&#39; founder Boris, and some questionable AI art. It&#39;s free, every week, in your inbox. Sign up now!

Technology is entering a decisive stage: AI is reshaping workflows, distribution is shifting, capital is becoming more selective, and founders are expected to demonstrate value rather than potential.

The world doesn’t need more noise.
It needs clarity, execution, and access to trustworthy knowledge and people.

TNW will serve that need through editorial independence, real expertise, and community-built intelligence.

Success for TNW looks like this: more accurate understanding, faster access to verified knowledge, and direct pathways from insight to action.

I’ve been an entrepreneur since 2007, building in B2B SaaS, marketplaces, and scalable systems. I believe deeply in servant leadership. Without people, I am zero.

I lead two private networks grounded in practice rather than theory:

These groups ensure TNW remains rooted in lived experience, informed by operators, not commentators.

Our mission is to build the most trusted European tech media platform with global reach, focused on practical innovation, responsible scaling, and transparency.

We will continue to host events across Europe’s major capitals including Paris, London, Berlin, Amsterdam, and Monaco.

These will not be festivals. We are introducing a concept validated through tekpon events: curated gatherings built for meaningful relationships, deep content, and tangible business outcomes.

In 2026, we return to Amsterdam for a special edition centered on AI among other fields. We will explore technologies and strategies shaping the future of work and business:

The editorial focus remains European, while the audience is global.

AI is not a threat to publishing. It is the infrastructure of the next generation of content and knowledge.

At TNW, we will use AI to accelerate research, enable personalized intelligence, reduce noise and bias, and amplify high-quality human expertise. Technology assists. Human judgment remains central.

Because this moment in Europe matters.
Because founders here are ready to scale responsibly.
Because independent media with integrity is rare.
Because innovation deserves a platform built around people, not hype.

TNW will continue its legacy with a renewed emphasis on contribution, execution, and community built through trust.

If you are building, scaling, or researching the next wave of technology, I invite you to engage with us, contribute insights, and participate in shaping the conversation.

The next era begins now. Let’s shape it together.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-61')">
            <div class="source">The Next Web</div>
            <div class="title">Engineering’s AI reality check</div>
            <div class="meta">2025-12-19</div>
        </div>
        
        <div id="content-61" style="display:none;">
            <h2>Engineering’s AI reality check</h2>
            <p><strong>The Next Web | 2025-12-19</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/engineerings-ai-reality-check">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Most engineering leaders cannot answer the one question their CFO is about to ask: “Can you prove this AI spend is changing outcomes, not just activity?”

Every December, roadmaps get locked, budgets get approved, and board decks are polished until everything looks precise and under control. Underneath, many CTOs and VPs are still working with partial visibility. They have a feel for their teams, but not a reliable view of how work moves through the system, how AI is really changing delivery, or where time and money actually go.

For a while, that was survivable. Experience, pattern recognition, and cheap capital covered the gaps. You could hire around bottlenecks, overstaff critical teams, or quietly pivot away from the messiest parts of the system. Then AI showed up and became the perfect distraction. Pilots, PoCs, Copilot seats, and “AI initiatives” created visible activity and bought time.

In 2026, that grace period ends. Boards and CFOs are shifting from “show me you are experimenting” to “show me measurable impact, this year.” Not because they stopped believing in AI, but because the market no longer rewards vague promises. Every AI dollar will need a traceable path to productivity, quality, or customer value.

TNW City Coworking space - Where your best work happens

A workspace designed for growth, collaboration, and endless networking opportunities in the heart of tech.

If you run engineering, you probably recognise this scene. You present a slide with AI highlights. Adoption is up. Developers say they like the tools. You share a few anecdotes about faster coding and smoother reviews. Then the CFO asks a simple question: “Exactly how is this budget changing output and outcomes?”

What is almost always missing is a clear breakdown of:

So the conversation slips back to learning curves, compounding benefits, and talent attraction. All true, but too soft for a tough budget review. That will not be enough.

AI vendors love task-level numbers. A coding task completed 55 percent faster looks impressive on a slide. But once you zoom out to teams and systems, the picture changes.

Large datasets across thousands of developers show a consistent pattern:

The problem is not the tools. It is the lack of a system for where the “extra” capacity goes.

Most organisations still frame AI productivity in terms of speed: more story points, more tickets, higher deployment frequency. That misses the bigger question:

How much of our engineering capacity goes to net new value versus maintenance, incidents, and rework, and is AI improving that mix?

High-level benchmarks are blunt but helpful. On average, about 45 percent of developer time is spent on maintenance, minor enhancements, and bug fixes rather than on genuinely new, customer-facing work. If AI helps you produce more code inside an unchanged system, you risk:

That is how you end up with impressive local metrics and a leadership team that still feels like engineering is slowing down.

If you want to walk into a 2026 budget conversation with objective evidence, you need to be deliberate about how AI-driven time savings are used. Two moves matter.

AI is already good at boilerplate, tests, documentation, and simple refactors. The trap is treating the saved time as unstructured “extra” capacity that disappears into the noise. Instead:

When teams systematically reduce technical debt and improve tests around critical flows, they cut future incidents and rework. Over a year, that frees more capacity for new work than shaving a few minutes off each ticket ever will.

2. Point AI at the ugly, high-friction work that commonly blows up roadmaps

The biggest productivity wins are not in everyday code generation. They are in:

These activities steal weeks or months of capacity and stall strategic initiatives. Using AI to understand legacy code faster, propose refactoring plans, generate migration scaffolding, and highlight recurring failure patterns can dramatically compress timelines for this work.

In parallel, there is real leverage upstream in the problem space. Teams that reach higher levels of AI adoption report better gains when they:

That reduces wasted builds and focuses effort on changes customers actually care about. The most significant gains do not come from replacing human creativity, but from amplifying it and aiming it at better-defined problems.

DORA metrics are not the enemy. Deployment frequency, lead time, MTTR, and change failure rate remain among the best signals we have for delivery performance. The risk is mistaking them for the whole picture.

Leading organisations are already expanding their scorecard to include:

In 2026, the question in the boardroom will shift from “Are we elite on DORA?” to “How much of our capacity is going into things customers notice, and is AI improving that mix or not?” To answer that cleanly, DORA is necessary but not sufficient. You need a way to connect AI usage, workflow, quality, and business outcomes across the system.

This is where engineering intelligence platforms move from a nice-to-have to mandatory. The organisations that win in 2026 will not do it with one more AI tool or one more disconnected dashboard. They will do it by pulling together data they already have but rarely use in one coherent view:

From there, leaders can answer the questions that actually matter:

Instead of defending AI spend with anecdotes, you walk in with:

That is the difference between “we believe in AI” and “here is how AI changed our delivery engine in measurable ways.”

To be ready for the more complex questions coming next year, use this planning cycle to do four things.

Do this, and you will not just have “AI activity” to show in 2026. You will have a credible, data-backed story from AI spend to business outcomes.

The leaders who thrive next year will not be the ones with the flashiest AI demos or the loudest “AI strategy” slide. They will be the ones who:

Engineering intelligence platforms is a key part of that shift. They give you the complex data to show where time and money go, how AI is really changing delivery, and whether your current pace is sustainable. The shift to data-backed engineering leadership is happening either way.

The gap in 2026 will be between teams still guessing and teams that can prove, in detail, how their engineering organisation works.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-62')">
            <div class="source">The Next Web</div>
            <div class="title">Letter from the Editor-in-Chief</div>
            <div class="meta">2025-12-16</div>
        </div>
        
        <div id="content-62" style="display:none;">
            <h2>Letter from the Editor-in-Chief</h2>
            <p><strong>The Next Web | 2025-12-16</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/letter-from-the-editor-in-chief">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Not long ago, like many of you, I read what I feared might be The Next Web’s final article. In late September, TNW’s co-founder announced that the tech conference and news site would be winding down, no more events, no new stories. It felt like the end of an era; the news hit hard!

Yet, just a few weeks ago, a twist arrived: the tech platform Tekpon acquired 100% of TNW’s media and events brand from the Financial Times, ensuring that this nearly two-decade legacy will continue to thrive.

While, myself, trying to read people’s opinions on this topic, I read this comment in one article, from one former TNW editor-in-chief that said: “The Next Web shaped my career, my life… it’s very sad to see it die”.

TNW City Coworking space - Where your best work happens

A workspace designed for growth, collaboration, and endless networking opportunities in the heart of tech.

I asked myself: Why do we always assume that just because one chapter ends, the whole story is over? Yes, taking over TNW is a heavy inheritance, especially with all eyes on us and expectations sky-high.

And I’ll admit, doubts crept in: Am I too small for this? Could someone more experienced do it better? Probably. But here I am, stepping up regardless. Because this isn’t just another blog or brand; TNW is a living ecosystem, a vital community. Its story deserves to continue, and I’m determined to help write the next chapter.

I also know some of you might be wondering: Who is she? What does she know? How many articles has she written? What recommends her?

Before reading all sorts of titles and, let me briefly introduce myself.

I’ve been writing since high school, with thousands of articles under my belt; covering everything from culture, art, and hip hop to design, politics, history, and food. I landed my first content writer job at 18, and alongside writing I pursued another passion: becoming a chef.

(Fun fact: I even made it to the semifinals of MasterChef, a journey that taught me about creativity under pressure and staying cool when the heat is on.)

Now, I channel my storytelling skills into helping businesses better understand technology and use it to their advantage. I help companies tell their stories, the real ones, finding meaning and flow in every word.

Over the years, I’ve specialized in blending creative storytelling with the technical precision of a chef’s knife. (My colleagues at Tekpon might say I can be as sharp as that knife – true to my values and quick to cut through the nonsense.) I am also the “No, we have to do it right” person in the team.

I’ve reviewed countless software products, interviewed founders, and explored how digital innovation can be a force for good in society. Or not. In other words, I’ve always cared about the why behind the tech, the real impact on people’s lives, not just the buzz. That perspective will be behind every story we will publish at TNW.

If there’s a place for those who still think stories written by humans matter, tell me where it is. I’m already on my way.

I’m not here to change TNW’s DNA; I’m here to reinforce it with fresh energy and a clear vision for the future.

To the loyal TNW readers, to the startup founders who looked to us for inspiration, to the healthy tech skeptics who counted on us for a reality check, and to our global audience spread across continents: we hear you.

We all know the world of tech news has changed dramatically. Today, everyone has a megaphone, social media overflows with hot takes, and AI algorithms can crank out content in seconds. It’s easy to feel overwhelmed by this sea of opinions and auto-generated articles. In such a world, the role of a publication like TNW is more critical than ever: to be a filter, not just another firehose of content.

We will focus on curation and clarity, distilling the noise so you don’t have to.

Here’s the good news: despite the deluge of AI-written text out there, readers are actively looking for authentic, human journalism. Every article we will publish will be created by a human writer who is accountable for the facts and who brings context, analysis, and yes, a bit of personality too.

Our mission isn’t to chase every trending headline algorithmically; it’s to help you understand which innovations actually matter, and why.

If a story is everywhere but lacks substance, we won’t regurgitate it; we’ll analyze it or debunk it. If a breakthrough is genuinely promising, we’ll explain why it’s important and how it impacts real people. Being a thoughtful filter in this age of information overload (and AI-generated noise) isn’t just a catchy slogan for us; it’s a responsibility we embrace.

You’ll also notice something different in our approach: an emphasis on storytelling and the human side of tech. Technology doesn’t exist in a vacuum; it’s built and used by people with dreams, dilemmas, and diverse backgrounds.

I believe, and I suspect many of you do too, that the best tech journalism zooms out from the gadgets and code to highlight those human stories. Practically speaking, expect to see more features, interviews, and narrative-driven pieces on TNW.

We’ll talk to founders about the messy, human journey of building a startup, not just the press releases or funding announcements. We’ll spotlight the engineers, designers, and thinkers who are trying to solve big problems (or even small ones that make a big difference). We’ll explore tech’s impact on society: the good, the bad, and the complicated.

This won’t be a place for recycled press releases or surface-level takes. It will be a place for conversation and insight.

Importantly, none of this focus on storytelling means we’ll skimp on rigor. Being engaging doesn’t mean sacrificing accuracy or depth. My team will continue to prioritize thorough research and fact-checking, those good old-school journalism values, even as we experiment with new formats and new voices. In short, we won’t publish anything we wouldn’t want to read ourselves.

Today, looking forward means acknowledging that how we cover tech is as important as what we cover. It means committing to journalism that cuts through the clutter, to storytelling that puts people first, and to a vision of tech’s future that is both hopeful and honest. That’s my vision for TNW as I step into this role, and I hope it resonates with you.

Now, I’d like to turn it over to you, our community. This is your TNW as much as it is ours. I invite you to join the conversation. Tell us what you want to see more of (or less of). Hold us accountable,if we ever fall short, let us know. Share your stories and perspectives with us, because they can inspire our coverage.

In the coming weeks, you’ll start to see this vision take shape on the site. You’ll see familiar faces and new voices. You’ll find articles that make you think, others that make you smile, and hopefully quite a few that make you proud to be a TNW reader.

Whether you’re a long-time follower who’s stuck with us through thick and thin, a startup founder looking for insight, a skeptic keeping us honest, or a curious mind tuning in from anywhere in the world – thank you. We do this for you, and we couldn’t do it without you.

The Next Web is back. We’re here to inform you, inspire you, challenge you, and occasionally even surprise you. I’m honored to have you with us on this journey. Here’s to the road ahead, to storytelling, to journalism (the real kind), and to making sense of the future together.

Thank you for reading, and welcome to TNW’s next chapter. Let’s build it, day by day, story by story, together.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-63')">
            <div class="source">The Next Web</div>
            <div class="title">Is ChatGPT’s New Shopping Research Solving a Problem, or Creating One?</div>
            <div class="meta">2025-12-11</div>
        </div>
        
        <div id="content-63" style="display:none;">
            <h2>Is ChatGPT’s New Shopping Research Solving a Problem, or Creating One?</h2>
            <p><strong>The Next Web | 2025-12-11</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/is-chatgpts-new-shopping-research-solving-a-problem-or-creating-one">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">When OpenAI announced its new shopping search capabilities, I took the news with a grain of salt (perhaps the whole shaker).
For the past decade, we have watched the slow evolution of traditional search engines. What began as tools for pure information discovery gradually morphed into ecosystems dominated by SEO-optimized content and sponsored results. My initial fear with ChatGPT’s update was simple: Are we seeing the beginning of a similar shift? Is the purity of the “reasoning engine” being diluted by the necessity of commerce?
After testing the new shopping integration, the results suggest that we are at a pivotal moment in the user experience of Generative AI, one that requires an open discussion about what we actually want these tools to be.

The defining characteristic of Large Language Models (LLMs) is their ability to handle nuance. When we interact with ChatGPT, we expect a Socratic dialogue. We expect the AI to ask clarifying questions to narrow down our intent.
To test this, I entered a simple prompt: “I want to buy a vacuum.”
I anticipated a conversation, questions about my home’s square footage, my floor type, or my budget. Instead, the conversational nuance was replaced by a display that felt familiar: a grid of product photos, names, prices, and direct links to retailers.

While efficient, this experience felt like a regression. It mirrored the “keyword search” experience of Web 2.0 rather than the “intent-based” promise of GenAI. It replied to my prompt, but it stripped away the intelligence.

Scrolling down, I engaged with the new feature in a call to action: “Research the best vacuums.”
This is where the user experience (UX) friction became most apparent. Rather than synthesizing data or comparing technical specifications in a chat format, the tool presented a polling interface designed to filter results.

TNW City Coworking space - Where your best work happens

A workspace designed for growth, collaboration, and endless networking opportunities in the heart of tech.

The experience is oddly time-sensitive; pause too long to think or drink water, and the screens will skip forward, dumping you back into a list of product cards.
The interface presents products with a binary choice: “More like this” or “Not interested.” It offers brand names and price tags, but virtually no information to help the user actually make a choice.

For a user seeking genuine research, being presented with a list of brands and prices without deep comparative analysis feels like a missed opportunity.
It raises a question: If I wanted to filter products by price and brand, wouldn’t I use a traditional retailer? The value proposition of Gen AI should be synthesis, not just aggregation.

The Tension Between Reasoning and Revenue
This update highlights the inevitable tension facing major AI companies: the balance between user utility and business sustainability.
As OpenAI scales, the pressure to demonstrate revenue models to investors is natural. However, there is a risk in prioritizing transactional features before the core product, reasoning and logic, is fully matured. By introducing a shopping experience that feels closer to a “click-through” engine than a “knowledge” engine, the platform risks blurring its own identity.
Is ChatGPT a research partner that helps me think? Or is it a shopping assistant trying to speed me to checkout?

To be clear, I believe there is a place for shopping within AI. But the execution matters.
A truly Generative AI shopping experience shouldn’t just list products; it should understand the user. It should read between the lines of a prompt to understand that a user asking for a vacuum might actually be solving a problem about pet hair or allergies.

The current iteration feels like a beta test of a business model rather than an evolution of intelligence. As we move forward, the hope is that OpenAI will refine this tool to prioritize the “Chat” over the transaction. We don’t want it to be just another place to see ads. We need a better way to make decisions.

Viviane Mendes is a growth strategist and innovation leader with more than 20 years of experience driving technology-enabled transformation across global markets. She has led initiatives integrating AI-driven strategies, digital transformation, and scalable business innovation for companies such as PSINet, MP3.com, Match.com, UOL and Best Buy Canada, and founded Vitrinepix, one of the first print-on-demand e-commerce platform, later acquired by Spreadshirt. Committed to lifelong learning, Viviane is now focusing on applying emerging technologies to foster digital literacy, responsible AI adoption, and positive human impact.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-64')">
            <div class="source">The Next Web</div>
            <div class="title">Tekpon acquires TNW (The Next Web) brand from The Financial Times</div>
            <div class="meta">2025-12-08</div>
        </div>
        
        <div id="content-64" style="display:none;">
            <h2>Tekpon acquires TNW (The Next Web) brand from The Financial Times</h2>
            <p><strong>The Next Web | 2025-12-08</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/tekpon-acquires-tnw-the-next-web-brand-from-the-financial-times">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Tekpon has acquired 100% of the TNW media and events brands, which cover and convene the European technology ecosystem, from the FT.

The transaction is Tekpon’s largest investment in media and events so far. It broadens the company’s reach across SaaS and AI and strengthens its role in the global innovation landscape.

TNW’s brand and editorial standards will be maintained, while its events and digital platforms will be integrated into Tekpon’s wider strategy.

The FT will continue to own and operate TNW Spaces, Amsterdam’s dynamic tech hub, offering private offices and coworking spaces that support a thriving community of startups, scale-ups, and innovators.

TNW City Coworking space - Where your best work happens

A workspace designed for growth, collaboration, and endless networking opportunities in the heart of tech.

Alexandru Stan, Founder and CEO of Tekpon, said:

TNW is one of Europe’s most respected technology brands. Its legacy, its community, and its influence have shaped the European tech scene for nearly twenty years. This acquisition accelerates our mission to connect the global SaaS and AI ecosystem and supports Europe’s position in the next decade of innovation.

Tekpon will begin working on TNW branded initiatives immediately. Plans for 2026 include an expanded TNW Conference, new SaaS and AI program tracks curated by Tekpon, cross-regional executive programmes, and specialised gatherings for founders, executives, and investors.

The acquisition is part of Tekpon’s long-term plan to build an international ecosystem connecting software, media, events, advisory, and innovation.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-65')">
            <div class="source">The Next Web</div>
            <div class="title">Ending graciously</div>
            <div class="meta">2025-09-29</div>
        </div>
        
        <div id="content-65" style="display:none;">
            <h2>Ending graciously</h2>
            <p><strong>The Next Web | 2025-09-29</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/tnw-boris-signs-out">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">This article was published on September 29, 2025

A few decades ago, when I was raising funding for a startup, I made a lasting impression on an investor by not only talking about how successful we would be, but also highlighting what would happen if we weren’t. Later, in an informal setting, I asked him what had persuaded him to invest in us. He told me that during the pitch, I had said, “And if all our predictions and expectations are wrong, we will use the last of our funding for a magnificent farewell dinner for all our investors. You’ll have lost your money, but at least you’ll get a great evening for it in return.”

I don’t recall this being part of the original pitch or my strategy. I probably just blurted it out to break the ice, but it impressed the investor. He told me it was refreshing to speak to an entrepreneur who was not blinded by his own pitch. The fact that I had a scenario ready for both success and failure told him that I was honest and realistic.

Now, the startup was not successful, but we still had a nice, opulent dinner with the investors at the end — and we did them one better. As soon as we realised that our predictions and expectations were wrong, we made our investors an offer: we could struggle and pivot and hope for a miracle, or we could return what was left of our funding to our investors. We preferred option two, and so did they, so everybody got some money back (about 40% of what they had invested), as well as a lovely evening with excellent food and drinks. When we raised money for another startup a few years later, almost all of them signed up in our first round.

Obviously, I would have preferred to have made this startup a success instead, but I still regard it as a successful endeavour. I gave it a try and had a plan ready for when my experiment didn’t work out, and in the process, I built relationships that outlasted that one startup.

TNW City Coworking space - Where your best work happens

A workspace designed for growth, collaboration, and endless networking opportunities in the heart of tech.

As you may have read, The Next Web, the company I founded in 2006, is nearing the end of its lifecycle. The events and media business is being wound down, and only TNW Spaces will live on. TNW Programs was sold off a while ago and will continue as well. There won’t be another TNW Conference, and soon there won’t be new articles on the site; people are losing their jobs, including me. It’s a painful process, but I guess I’m taking it well because it also feels natural and logical. When we sold TNW to the FT in 2019, we were very ambitious and optimistic, and surely I would’ve liked for the company and brand to outlive me. However, when the business struggled, I also felt very comfortable with the company ending graciously.

When you’re reading a good book, there’s a moment near the end when you’ll start reading slower because you don’t want it to end. I love those moments, because I’ll know it’s been a good experience. But then you also know that good stories need good endings. So, this is the ending of a great story that I’ve enjoyed participating in.

I’ll keep writing, but this will be my last official TNW story. I’d love it if you would subscribe to my writing over at Substack. It will be less tech-focused, more unpredictable, but just as insightful as before.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-66')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">Putin sends a signal to Trump on Ukraine proposals - Reuters</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-66" style="display:none;">
            <h2>Putin sends a signal to Trump on Ukraine proposals - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2025-12-26</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMilgFBVV95cUxNeld3YW9qcWZDSFVtMzRNdWUzQ25FRG1zckRmbFhQa1hTTFdxMXJ3TjdjLUtsbWpCNHpEQlBreDNGTks1clFJVWw0OGJaZ292cEFaMkN3cVJ3dWdxV0VVTHRKeHVyYTFkbVFNNDgzemxpZHV6TEZpZWh1QnZsaUVhUnQ2SUNuVTY0NTZnZEhiVk5jRk1xSWc?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-67')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">Israeli reservist rams vehicle into Palestinian man praying in West Bank - Reuters</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-67" style="display:none;">
            <h2>Israeli reservist rams vehicle into Palestinian man praying in West Bank - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2025-12-26</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiwAFBVV95cUxQLWNKT1FrTzh1Y1QtZWhNc0lTeDJLTm91bFpieFJaamZpaHMwbFZSdXFXNTlxR3Brc3BzUC1SUDJwbVVoSjZkYlcxbTFnekJZU1hJNFpsdWgwT0pOQjBCMzhPdTFreXBPcDJxbHpQTzdZYjQyZDBYSlFGZXAxbGxVbkZsc3Z2WUtzSE9BT2ZWdk5ULTFUd2xENkVaNW1ZS3pZZGFITzJfeWtHNTFYTlJEektYSGxBdjNpM1lJNlhsenU?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-68')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">Explosion at Alawite mosque in Syria's Homs kills five - Reuters</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-68" style="display:none;">
            <h2>Explosion at Alawite mosque in Syria's Homs kills five - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2025-12-26</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMitAFBVV95cUxNR1RWOVhtaE1tT3VQZVBrcTIwWU8zeUZrSVB5M3FxOWpSYTJGbGUwc1lDeFIxLTVFUDFNcFQybTBLSnpUeTFNOVNQYkRBT0VncldqMmhDTUN6MGFFRFRYYTItbG01ODJQOGtVcHJNd0p4cWVhcWlZRnZkM3RYUWkta19SZWVXLXlXZnFXWlZuSGRGUjZaZl9BRjZZdFBiNms1d2RveGhrcEhvWHNWQWljdVhhS0I?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-69')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">Futures subdued in thin post-Christmas trading - Reuters</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-69" style="display:none;">
            <h2>Futures subdued in thin post-Christmas trading - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2025-12-26</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMilwFBVV95cUxQOFBxUjBkbGhhUmlweTUwejBiV3liQnhBWU9pV1hGM2gxODBTRzJ5a2YyUi1NbmNwaGtGQnRDUkZRX2U1YzJ1SHkwSWpQY2ZxU2psU0NnZHpYcHRCenhrZERoTnotdFQ2dGtHWi1ISGV3aUFWYXNhT2daYWlXMFRMLTQ5eDhMOUdpaVczVUpISmJtVjZSMWd3?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-70')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">China hits US defence firms with sanctions over arms sales to Taiwan - Reuters</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-70" style="display:none;">
            <h2>China hits US defence firms with sanctions over arms sales to Taiwan - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2025-12-26</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiygFBVV95cUxNS1F2bGF6VlRLWS16dUpRNzEtRVl6RzJTMFlBRk0taEFFbXZyQkhSd3YzRWtBUk9Bb0o2MW42anpVVlFMWThCTWo3LWxIeHBTN1lqWmZHUlZBV05zc1NvRHVtdnRBMzF3VmZPZ3NuWVhKWlRlb2lQWFFqdi1TUURjZi1lUW5LYVFNb1owTTFhcDd1Y250NmtzUGc4V0o0aU9wRUd6cWtBMm81Nm1rV0M0bS1GY3RsR1RNcXlQUGM1aDNRZnRhVG1PZF9R?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-71')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">Wall St Week Ahead S&P 500 eyes 7,000 mark as investors look for upbeat end to strong 2025 - Reuters</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-71" style="display:none;">
            <h2>Wall St Week Ahead S&P 500 eyes 7,000 mark as investors look for upbeat end to strong 2025 - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2025-12-26</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiywFBVV95cUxOV0dtY0NSTkRJeGNPNDk2TjNsaFRKaFdxS2YtVzRTVFc2U1g2LXA4V0l6RDhxYWMtU1VyVDg2c2RDc0hKODFQUk5BTkw4NTNMUXF5b0l1V1BvbXM1RzFWWFBkT3k3Vk1iNHM4b3EwQm9XOGZTZGJydnQ3UHU3LVB5c3g0WnNKRWxjY0k2LTR0QkROWFFnS2VaQ3FuUTJQLVhxSVhTNEFGdWRVTGZTWHNVdENxMmJsSnpHQ2JfajZobV8wNDNSTjNuS0ZkVQ?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-72')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">“Cosmics” and “Phantoms”: Ukrainian Independent Study Reveals Observations of Unidentified Aerial Phenomena - The Debrief</div>
            <div class="meta">2022-08-26</div>
        </div>
        
        <div id="content-72" style="display:none;">
            <h2>“Cosmics” and “Phantoms”: Ukrainian Independent Study Reveals Observations of Unidentified Aerial Phenomena - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2022-08-26</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMixAFBVV95cUxOWWZHN3JWVE42ZlI4eTRKUnVIX0h0MlAwM25SMFExVlRGVThjNVdicEF3dnNHUXd2VjBGTU5fVE5SUnBTU2hKNUk2MmNjaXVzZnhKTFZDeEp3elV0RGRsVnk3cHdCbDZySld1eFNqOEoyQVh0YU81cXJOeTRSZ3MxZ281RHlTdE1SR2JKOXVMYXFGZm5EX3lVZ2tsaEo1bEYxTU5pWmVYSlJlMjl3S1hxRG1BLW9qRGJSaTItbXl3MDlWVUZT?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-73')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">“No Longer a Futuristic Concept”: Scientists Build Real-World Magnetic Cloaking Device Capable of Shielding Complex Shapes - The Debrief</div>
            <div class="meta">2025-12-22</div>
        </div>
        
        <div id="content-73" style="display:none;">
            <h2>“No Longer a Futuristic Concept”: Scientists Build Real-World Magnetic Cloaking Device Capable of Shielding Complex Shapes - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2025-12-22</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMi2wFBVV95cUxQTVlmWjE0Wk9WemxzQmhCM18tVmt6Qkd1cEREazlMQUFiLUlYQkxqYUxDSmR5T2VaMFh1LXoyNnRPRmdwNE9qZndYV2NaRzBQa2Zpcjc2bnRRSWdMYWpCYzkyekx1ZURuTWdRV0o3ZXRRN3VNVllmcWluZnc4WDFUTE42TGt6RGxKTGxUVFppXzM4bVR0Y1lPQkl4U3ZvUTdGT3RzRzlEUnVtMkJQNEotdEdsanJ0MGlqM0thc1BkVldjakFIdnZVUV9QRml6VS1BTHVwNjh1cGMtTWc?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-74')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">Ancient Pottery Shows Humans Were Doing Math 3,000 Years Before Numbers Existed - The Debrief</div>
            <div class="meta">2025-12-20</div>
        </div>
        
        <div id="content-74" style="display:none;">
            <h2>Ancient Pottery Shows Humans Were Doing Math 3,000 Years Before Numbers Existed - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2025-12-20</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMipAFBVV95cUxPYmVKVmd6TVphcGliQlZhNzYyRDViM1oxSFhZY0xOM3BjMHVwSW5KQmxVcXBfMTBqXy0wRGh2eW5yeFg0NjNsTFFuOVktZ1UtV3dvaWx6Z0pjaEYzUk9yTzZ1T2dFbnBwVEI4NEhLeHpZLUZ0ZTZkbVFTc3VscEsxM1g4ckFFOGItQlZRU0ZVNWppWWtEaHlTUzRtdWFDcnVpOEx2Tg?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-75')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">Are AI Systems Truly Conscious? This Researcher Says Humanity May Never Know—and Explains Why That Matters - The Debrief</div>
            <div class="meta">2025-12-22</div>
        </div>
        
        <div id="content-75" style="display:none;">
            <h2>Are AI Systems Truly Conscious? This Researcher Says Humanity May Never Know—and Explains Why That Matters - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2025-12-22</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiyAFBVV95cUxQcjItSnRGRXM4djZsaHQtbDlSMGVhUmM2R0FsdEJPd2h2eXRBZGZDekk2aThzOGdFLWhTSk5WeTVNQ2pIOEV1QnJHYXl4TE1hLWx4YzFCRDduaXEtWWxlWDczUzhsVktXRWhkWEdSYzdJeVA4Y29UOUloU0huU09JMWJ0X05RYVdZaU5BTnBGTGgzN2NhVnVlQ09aM2c2bXlJRFFYV3dERWhvQmtuMXBGNzBTSEhTQXFDQ2ZVVjBpMlZOWGIzaFJJbg?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-76')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">A New Theory Suggests Mass May Emerge From Invisible Dimensions - The Debrief</div>
            <div class="meta">2025-12-23</div>
        </div>
        
        <div id="content-76" style="display:none;">
            <h2>A New Theory Suggests Mass May Emerge From Invisible Dimensions - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2025-12-23</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMikAFBVV95cUxPTFNSQWZDVm5jTkRTaTNMb3p2Y2dGcnZ5bHFnRHhDcGZHT3M0VzZWZzcyNEpiZ284QUowZjhaYkFwTU8zRHdLSUlCY0ZXd2NpRnRDZ2JwOFBQNi1oWHZsZzBoM25iak5rTlhMc0wxSmhXbUh3NmdIQ2FRd2I0blVHamVJckY1V2NCbWVnMjRScXg?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-77')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">Scientists Suddenly Can't Explain How Stellar Winds Spread the Seeds of Life Throughout the Cosmos - The Debrief</div>
            <div class="meta">2025-12-23</div>
        </div>
        
        <div id="content-77" style="display:none;">
            <h2>Scientists Suddenly Can't Explain How Stellar Winds Spread the Seeds of Life Throughout the Cosmos - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2025-12-23</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMivgFBVV95cUxQaC16QmtUS2hZT1hTZ1ZIc1dnY2Y3VmdwUUNMb2JoZEZ0ZGhZSWcwX1dEdjRlcExlcTViM2JLWXdsYUhMNEtzR204YWtCM0JPd21zS0hoelJaZHZZSThNbENGTFBaaExUUVNRSWRtODc1QVJuRXVNYlZfUHY3ZzN4c2tqbkhIc3daNjRJRTc2WkdlSnBfVjR3ejZTS0xLRjZza1VUY1BubXVzRmxEQV9YNVptVWF1aUdiLUVfOWVR?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-78')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">Why Nvidia Struck a $20 Billion Megadeal with Groq - The Information</div>
            <div class="meta">2025-12-25</div>
        </div>
        
        <div id="content-78" style="display:none;">
            <h2>Why Nvidia Struck a $20 Billion Megadeal with Groq - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2025-12-25</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMihAFBVV95cUxNMmtUdTFFRXVvek02bGI2T1RnQzZhaHc1ejF6LVdzcWZfb0FhRG9mMDZHcW9BTERpRHZnaW5tblFuUFZDbUZTOERNbTYyV29QZEoyNEtoS0xobGhtZndvTlcxMEpoWm1VLVZ0enZhY0NLTDk5OFFjRVI1T21iYW9xY010alA?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-79')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">OpenAI’s Ads Push Starts Taking Shape - The Information</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-79" style="display:none;">
            <h2>OpenAI’s Ads Push Starts Taking Shape - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2025-12-24</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiggFBVV95cUxNUE1HZHAzd1d4ZDhIU1JLdW44Rjg0QUJMN3U4TGdQRzBpckZsV0k3cEpWcnZ6V3B2VzRncG1DY2FPZFVDQXlPSDZXSnNsSk5kenk3Wl9tTDFzODBBSllVMkF1V0RqaS1aMVhmTmI4azVpQzhaSjFQUmlTZ0tRWGhadDlR?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-80')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">Snowflake in Talks to Buy App Monitoring Startup Observe Inc. For Around $1 Billion - The Information</div>
            <div class="meta">2025-12-24</div>
        </div>
        
        <div id="content-80" style="display:none;">
            <h2>Snowflake in Talks to Buy App Monitoring Startup Observe Inc. For Around $1 Billion - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2025-12-24</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMisAFBVV95cUxQTWtkeDVvRG90Mlp4QXIwQk5OaW1KbEJZa3I4TExhUFFoeGE3eFIzSWNtb0x1OUpwVWlHUzNOTmpmSE1ZOTZIRWk1dXNZU2NVLVAyTHpjUjRhQlU1ejhka2pUdHFDODlOOEg2TTJTSU55VTd3NXdPbTZDV1ltU2JkbXV3SU5EaEVMblRFYUg1UC1FckZQSWlsalp0WWlUU2V3X2pUczBJM3NhWGF0b05jTw?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-81')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">Nvidia Restructures Cloud Team After Retreating From AWS Competition - The Information</div>
            <div class="meta">2025-12-22</div>
        </div>
        
        <div id="content-81" style="display:none;">
            <h2>Nvidia Restructures Cloud Team After Retreating From AWS Competition - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2025-12-22</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMingFBVV95cUxNMm04Y3F4SW1rMFBQdGpaRk1tNFAyVExINXJyZ0JXUE85ZmJoLXgzWVZrNEttOUs5akRCT0hBSVRfclZQWGo4TFlUZW5uc1RTV1ZXc1h6R3I4SWpvdldKMWR1M0dkWXJFTnd5TmZKNXpOelBrWDFLdEtaVVpVRTBHOTlobFlfMXlxYXZwd1lEN21yNWh3dE5taUcxZmJwZw?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-82')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">How OpenAI’s Organizational Problems Hurt ChatGPT - The Information</div>
            <div class="meta">2025-12-18</div>
        </div>
        
        <div id="content-82" style="display:none;">
            <h2>How OpenAI’s Organizational Problems Hurt ChatGPT - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2025-12-18</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMijAFBVV95cUxQUEZrWnU1LUdoRDBZd1J4Q1VyUldPVE1fY3ZQQl9sQk9qT1dYSWdSQXhId0o4eWs2Qmx2VGRDVGdxNjB4NTlfLUNnUGdQLWR2elRsSWFpQ1F2NHRwRWZZVngzSTZGeVM4UjV5X3ppU01WMVlZWVQ2SlM1bFJWTTd6eUVhcnRfQXoxU3d5aQ?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-83')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">Why Data Centers Are Falling Behind Schedule; Jensen Huang’s Power Summit - The Information</div>
            <div class="meta">2025-12-22</div>
        </div>
        
        <div id="content-83" style="display:none;">
            <h2>Why Data Centers Are Falling Behind Schedule; Jensen Huang’s Power Summit - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2025-12-22</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMipgFBVV95cUxQdEw4ZWtGRzVvTzJUUGlmS3VzMlU2VnpqR2RpNW8wOG1IUnVYeTFwbnU5ejBrdGJxcFYtNm12QnJYdExtZ2Z6OG1HbzMyaEFiMHhOSU9PM3pKMk9ZV3BJNkh4WW1kSnBzWWw3YjNpMGoyQl80Z1FXMVMxVWExZFFZMXBkRDU2cUoxRVdONmZxV3RZUUQ3MU44M2dZTTEzQjJ4UWdESFRn?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        </div>

        <div id="reader-modal">
            <div id="close-btn" class="control-btn" onclick="closeModal()">X</div>
            
            <div id="scroll-controls">
                <button class="scroll-btn" onclick="scrollPage(-1)">&#9650;</button> <button class="scroll-btn" onclick="scrollPage(1)">&#9660;</button>  </div>

            <div id="modal-inner"></div>
        </div>

        <script>
            // 1. RANDOMIZE ORDER
            const list = document.getElementById('feed-list');
            const cards = Array.from(document.querySelectorAll('.card'));
            cards.sort(() => Math.random() - 0.5);
            cards.forEach(card => list.appendChild(card));

            // 2. DARK MODE
            const btn = document.getElementById('theme-toggle');
            btn.addEventListener('click', () => document.body.classList.toggle('dark-mode'));

            // 3. MODAL & SCROLL LOGIC
            const modal = document.getElementById('reader-modal');
            const modalInner = document.getElementById('modal-inner');

            function openModal(contentId) {
                const content = document.getElementById(contentId).innerHTML;
                modalInner.innerHTML = content;
                modal.style.display = 'block';
                document.body.style.overflow = 'hidden'; 
            }

            function closeModal() {
                modal.style.display = 'none';
                document.body.style.overflow = 'auto';
            }

            function scrollPage(direction) {
                // Scroll by 80% of the screen height to keep context
                const scrollAmount = window.innerHeight * 0.8;
                modal.scrollBy(0, direction * scrollAmount);
            }
        </script>
    </body>
    </html>
    