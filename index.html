
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>KL-77's Feed</title>
        <style>
            :root {
                --bg: #ffffff;
                --text: #000000;
                --border: #000000;
                --modal-bg: #ffffff;
                --dim: #666666;
            }
            
            body.dark-mode {
                --bg: #000000;
                --text: #ffffff;
                --border: #ffffff;
                --modal-bg: #000000;
                --dim: #aaaaaa;
            }

            body { 
                font-family: Georgia, serif; 
                background-color: var(--bg);
                color: var(--text);
                margin: 0;
                padding: 10px;
                font-size: 22px;
                line-height: 1.5;
            }

            header {
                display: flex;
                justify-content: space-between;
                align-items: center;
                border-bottom: 3px solid var(--text);
                padding-bottom: 15px;
                margin-bottom: 25px;
            }
            
            h1 { margin: 0; font-size: 1.2em; }

            button#theme-toggle {
                background: transparent;
                color: var(--text);
                border: 2px solid var(--text);
                padding: 10px;
                font-size: 18px;
                font-weight: bold;
                border-radius: 4px;
                cursor: pointer;
            }

            .card {
                border: 2px solid var(--text);
                margin-bottom: 25px;
                padding: 15px;
                cursor: pointer;
            }
            
            .source { font-size: 0.7em; font-weight: bold; text-transform: uppercase; color: var(--dim); }
            .title { font-size: 1.1em; font-weight: bold; margin: 8px 0; display:block; }
            .meta { font-size: 0.7em; color: var(--dim); }

            /* MODAL STYLING */
            #reader-modal {
                display: none;
                position: fixed;
                top: 0; left: 0;
                width: 100%; height: 100%;
                background-color: var(--modal-bg);
                z-index: 1000;
                overflow-y: scroll; /* Allow scrolling */
                scroll-behavior: auto; /* Instant scrolling for e-ink */
            }

            #modal-inner {
                padding: 25px;
                max-width: 800px;
                margin: 0 auto;
                padding-top: 80px; 
                padding-bottom: 150px; /* Huge padding so text clears the buttons */
            }

            /* Controls (Close + Scroll) */
            .control-btn {
                position: fixed;
                background: var(--bg);
                color: var(--text);
                border: 3px solid var(--text);
                border-radius: 8px;
                font-weight: bold;
                cursor: pointer;
                z-index: 1001;
                display: flex;
                align-items: center;
                justify-content: center;
            }

            #close-btn {
                top: 15px; right: 15px;
                width: 60px; height: 60px;
                font-size: 30px;
                line-height: 55px;
            }

            /* Scroll Buttons */
            #scroll-controls {
                position: fixed;
                bottom: 20px;
                right: 20px;
                display: flex;
                flex-direction: column;
                gap: 15px;
                z-index: 1002;
            }

            .scroll-btn {
                width: 60px;
                height: 60px;
                font-size: 24px;
                background: var(--bg);
                color: var(--text);
                border: 3px solid var(--text);
                border-radius: 8px;
                cursor: pointer;
            }

            #article-text { white-space: pre-wrap; font-size: 1.1em; }
            
            a.original-link {
                display: inline-block;
                margin-bottom: 30px; /* Space before text starts */
                padding: 10px;
                border: 1px solid var(--text);
                color: var(--text);
                text-decoration: none;
                font-weight: bold;
                font-size: 0.8em;
            }
        </style>
    </head>
    <body>

        <header>
            <h1>KL-77's Feed</h1>
            <button id="theme-toggle">Light/Dark</button>
        </header>

        <div id="feed-list">
    
        <div class="card" onclick="openModal('content-0')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">OpenAI spills technical details about how its AI coding agent works</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-0" style="display:none;">
            <h2>OpenAI spills technical details about how its AI coding agent works</h2>
            <p><strong>Ars Technica - All content | 2026-01-26</strong></p>
            <a class="original-link" href="https://arstechnica.com/ai/2026/01/openai-spills-technical-details-about-how-its-ai-coding-agent-works/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">On Friday, OpenAI engineer Michael Bolin published a detailed technical breakdown of how the company’s Codex CLI coding agent works internally, offering developers insight into AI coding tools that can write code, run tests, and fix bugs with human supervision. It complements our article in December on how AI agents work by filling in technical details on how OpenAI implements its “agentic loop.”

AI coding agents are having something of a “ChatGPT moment,” where Claude Code with Opus 4.5 and Codex with GPT-5.2 have reached a new level of usefulness for rapidly coding up prototypes, interfaces, and churning out boilerplate code. The timing of OpenAI’s post details the design philosophy behind Codex just as AI agents are becoming more practical tools for everyday work.

These tools aren’t perfect and remain controversial for some software developers. While OpenAI has previously told Ars Technica that it uses Codex as a coding tool to help develop the Codex product itself, we also discovered, through hands-on experience, that these tools can be astonishingly fast at simple tasks but remain brittle beyond their training data and require human oversight for production work. The rough framework of a project tends to come fast and feels magical, but filling in the details involves tedious debugging and workarounds for limitations the agent cannot overcome on its own.

Bolin’s post doesn’t shy away from these engineering challenges. He discusses the inefficiency of quadratic prompt growth, performance issues caused by cache misses, and bugs the team discovered (like MCP tools being enumerated inconsistently) that they had to fix.

The level of technical detail is somewhat unusual for OpenAI, which has not published similar breakdowns of how other products like ChatGPT work internally, for example (there’s a lot going on under that hood we’d like to know). But we’ve already seen how OpenAI treats Codex differently during our interview with them in December, noting that programming tasks seem ideally suited for large language models.

It’s worth noting that both OpenAI and Anthropic open-source their coding CLI clients on GitHub, allowing developers to examine the implementation directly, whereas they don’t do the same for ChatGPT or the Claude web interface.

Bolin’s post focuses on what he calls “the agent loop,” which is the core logic that orchestrates interactions between the user, the AI model, and the software tools the model invokes to perform coding work.

As we wrote in December, at the center of every AI agent is a repeating cycle. The agent takes input from the user and prepares a textual prompt for the model. The model then generates a response, which either produces a final answer for the user or requests a tool call (such as running a shell command or reading a file). If the model requests a tool call, the agent executes it, appends the output to the original prompt, and queries the model again. This process repeats until the model stops requesting tools and instead produces an assistant message for the user.

That looping process has to start somewhere, and Bolin’s post reveals how Codex constructs the initial prompt sent to OpenAI’s Responses API, which handles model inference. The prompt is built from several components, each with an assigned role that determines its priority: system, developer, user, or assistant.

The instructions field comes from either a user-specified configuration file or base instructions bundled with the CLI. The tools field defines what functions the model can call, including shell commands, planning tools, web search capabilities, and any custom tools provided through Model Context Protocol (MCP) servers. The input field contains a series of items that describe the sandbox permissions, optional developer instructions, environment context like the current working directory, and finally the user’s actual message.

As conversations continue, each new turn includes the complete history of previous messages and tool calls. This means the prompt grows with every interaction, which has performance implications. According to the post, because Codex does not use an optional “previous_response_id” parameter that would allow the API to reference stored conversation state, every request is fully stateless (that is, it sends the entire conversation history with each API call rather than the server retrieving it from memory). Bolin says this design choice simplifies things for API providers and makes it easier to support customers who opt into “Zero Data Retention,” where OpenAI does not store user data.

The quadratic growth of prompts over a conversation is inefficient, but Bolin explains that prompt caching mitigates this issue somewhat. Cache hits only work for exact prefix matches within a prompt, which means Codex must carefully avoid operations that could cause cache misses. Changing the available tools, switching models, or modifying the sandbox configuration mid-conversation can all invalidate the cache and hurt performance.

The ever-growing prompt length is directly related to the context window, which limits how much text the AI model can process in a single inference call. Bolin writes that Codex automatically compacts conversations when token counts exceed a threshold, just as Claude Code does. Earlier versions of Codex required manual compaction via a slash command, but the current system uses a specialized API endpoint that compresses context while preserving summarized portions of the model’s “understanding” of what happened through an encrypted content item.

Bolin says that future posts in his series will cover the CLI’s architecture, tool implementation details, and Codex’s sandboxing model.</div>
        </div>
        
        <div class="card" onclick="openModal('content-1')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">Doctors face-palm as RFK Jr.’s top vaccine advisor questions need for polio shot</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-1" style="display:none;">
            <h2>Doctors face-palm as RFK Jr.’s top vaccine advisor questions need for polio shot</h2>
            <p><strong>Ars Technica - All content | 2026-01-26</strong></p>
            <a class="original-link" href="https://arstechnica.com/science/2026/01/do-we-really-need-polio-shots-deep-thoughts-by-rfk-jr-advisor-get-dragged/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The chair of a federal vaccine advisory panel under anti-vaccine Health Secretary Robert F. Kennedy Jr. made his stance clear on vaccines in a podcast last week—and that stance was so alarming that the American Medical Association was compelled to respond with a scathing statement.

Kirk Milhoan, who was named chair of the Advisory Committee on Immunization Practices for the Centers for Disease Control and Prevention in December, appeared on the aptly named podcast “Why Should I Trust You.” In the hour-long interview, Milhoan made a wide range of comments that have concerned medical experts and raised eyebrows.

Early into the discussion, Milhoan, a pediatric cardiologist, declared, “I don’t like established science,” and that “science is what I observe.” He lambasted the evidence-based methodology that previous ACIP panels used to carefully and transparently craft vaccine policy.

While arguing that he was not anti-vaccine, he said he was merely focused on safety and made false claims about vaccine risks, a common trope among anti-vaccine activists. He falsely linked vaccines to allergies, asthma, and eczema and repeated a claim, without evidence, that COVID-19 vaccines killed children. When pressed by the podcast hosts, he revealed that he put the risk of vaccine side effects on the same footing as the risks from the diseases the shots prevent—despite the fact that disease risks are often orders of magnitude larger than the tiny risks from vaccines.

In response to pushback from the hosts, Milhoan objected to the idea that the measles and polio vaccines reduced the spread of those diseases. He went further, questioning the need for those vaccines as well as routine vaccinations, generally.

“I think also as you look at polio, we need to not be afraid to consider that we are in a different time now than we were then,” he said, referring to the time before the first polio vaccines were developed in the 1950s. “Our sanitation is different. Our risk of disease is different. And so those all play into the evaluation of whether this is worthwhile of taking a risk for a vaccine or not.”

He then pondered out loud what would happen if people stopped getting vaccinated. “If we take away all of the herd immunity, then does that switch, does that teeter-totter switch in a different direction?” he asked.

In a statement, AMA Trustee Sandra Adamson Fryhofer blasted the question. “This is not a theoretical debate—it is a dangerous step backward,” she said. “Vaccines have saved millions of lives and virtually eliminated devastating diseases like polio in the United States. There is no cure for polio. When vaccination rates fall, paralysis, lifelong disability, and death return. The science on this is settled.”

Fryhofer also took aim at Milhoan’s repeated argument that the focus of vaccination policy should move from population-level health to individual autonomy. Moving away from routine immunizations, which include discussions between clinicians and patients, “does not increase freedom—it increases suffering,” she said, adding that the weakening of recommendations “will cost lives.”

Overall, Milhoan’s comments only further erode the relevance of ACIP and federal vaccine policy among the medical community and states. According to a KFF policy brief, 27 states and Washington, DC, have already announced they will not follow current CDC vaccine recommendations, which Kennedy dramatically overhauled earlier this month without even consulting the ACIP. Instead, the majority of states are relying on previous recommendations or recommendations made within states or by medical organizations.

On Monday, the American Academy of Pediatrics announced the 2026 update to its childhood and adolescent vaccine schedule, which it has held up as an alternative to the CDC’s schedule and has been widely embraced by pediatricians. In the announcement, AAP noted that 12 other medical organizations have endorsed the schedule, including the AMA, the American Academy of Family Physicians, the American College of Obstetricians and Gynecologists, the Infectious Diseases Society of America, and the Pediatric Infectious Diseases Society.

The AAP’s updated recommendations are largely the same as the schedule from last year, but it is significantly different from the CDC’s recommendations, which “depart from longstanding medical evidence and no longer offer the optimal way to prevent illnesses in children,” the AAP said.

“The AAP will continue to provide recommendations for immunizations that are rooted in science and are in the best interest of the health of infants, children and adolescents of this country,” AAP President Andrew Racine said in the announcement.</div>
        </div>
        
        <div class="card" onclick="openModal('content-2')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">Why has Microsoft been routing example.com traffic to a company in Japan?</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-2" style="display:none;">
            <h2>Why has Microsoft been routing example.com traffic to a company in Japan?</h2>
            <p><strong>Ars Technica - All content | 2026-01-26</strong></p>
            <a class="original-link" href="https://arstechnica.com/information-technology/2026/01/odd-anomaly-caused-microsofts-network-to-mishandle-example-com-traffic/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">From the Department of Bizarre Anomalies: Microsoft has suppressed an unexplained anomaly on its network that was routing traffic destined to example.com—a domain reserved for testing purposes—to a maker of electronics cables located in Japan.

Under the RFC2606—an official standard maintained by the Internet Engineering Task Force—example.com isn’t obtainable by any party. Instead it resolves to IP addresses assigned to Internet Assiged Names Authority. The designation is intended to prevent third parties from being bombarded with traffic when developers, penetration testers, and others need a domain for testing or discussing technical issues. Instead of naming an Internet-routable domain, they are to choose example.com or two others, example.net and example.org.

Output from the terminal command cURL shows that devices inside Azure and other Microsoft networks have been routing some traffic to subdomains of sei.co.jp, a domain belonging to Sumitomo Electric. Most of the resulting text is exactly what’s expected. The exception is the JSON-based response. Here’s the JSON output from Friday:

Similarly, results when adding a new account for test@example.com in Outlook looked like this:

In both cases, the results show that Microsoft was routing email traffic to two sei.co.jp subdomains: imapgms.jnet.sei.co.jp and smtpgms.jnet.sei.co.jp. The behavior was the result of Microsoft’s autodiscover service.

“I’m admittedly not an expert in Microsoft’s internal workings, but this appears to be a simple misconfiguration,” Michael Taggart, a senior cybersecurity researcher at UCLA Health, said. “The result is that anyone who tries to set up an Outlook account on an example.com domain might accidentally send test credentials to those sei.co.jp subdomains.”

When asked early Friday afternoon why Microsoft was doing this, a representative had no answer and asked for more time. By Monday morning, the improper routing was no longer occurring, but the representative still had no answer.

Update: in an email sent after this post went live, the representative confirmed that Microsoft has “updated the service to no longer provide suggested server information for example.com.” As already reported here, the behavior only affected people configuring email accounts through the Outlook autoconfiguration feature. The representative added that Microsoft is investigating.

The new JSON response suggested that, as of Monday morning, Microsoft hadn’t fixed the endpoint routing traffic to the Sumitomo Electric servers. Instead, the JSON response no longer occurs. Where the output was occurring on Friday, the command now simply sits and hangs for 10 or 20 seconds and then terminates with a not found error. This behavior can be seen in the following output:

“It looks like they may have outright removed the endpoint that validates the email, because I’m seeing ‘not found’ errors,” said Dan Tentler, founder of Phobos Group. As denoted by ENOTFOUND, the error “suggests that [Microsoft admins] just ripped out whatever this thing was.”

It’s unclear how Sumitomo Electric’s domain would have found itself part of this mess. Microsoft last year said the Japanese company’s parent company, Sumitomo Corp., was deploying Microsoft 365 Copilot, but that still doesn’t explain why a subsidiary’s domain was added to Microsoft’s network configuration.

Questions sent to Microsoft include: How are autodiscover records added at Microsoft; was the routing intentional; and how long has the behavior been occurring? (Tinyapps.org, which noted the odd routing behavior earlier this month, said it lasted five years.) There doesn’t appear to be anything nefarious about the improper routing, and as long as people inside Microsoft’s network weren’t sending live credentials in tests, there was no danger posed.

There’s still reason for concern. In 2024, Microsoft revealed that one of its admins had assigned administrative privileges to a test account on the company network and then forgot about it. Russia-state hackers seized on the gaffe to gain initial access to Microsoft’s system. They went on to root through the network and monitor top executives’ email for two months. The routing misconfiguration for example.com raises the question: What other possibly more severe errors lurk on the network?</div>
        </div>
        
        <div class="card" onclick="openModal('content-3')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">Apple's AirTag 2 is easier to find thanks to new chip</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-3" style="display:none;">
            <h2>Apple's AirTag 2 is easier to find thanks to new chip</h2>
            <p><strong>Ars Technica - All content | 2026-01-26</strong></p>
            <a class="original-link" href="https://arstechnica.com/gadgets/2026/01/apple-introduces-new-airtag-with-better-range-and-a-louder-speaker/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Apple is introducing a new version of its AirTag tracking device—simply dubbed “the new AirTag&quot;—and claims it offers substantial improvements thanks to a new Bluetooth chip.

The original AirTag came out five years ago now, and it became popular in a variety of contexts. There were some problems, though—there was real concern about unwanted tracking and stalking with the devices, based on real stories of it being used for that. The company gradually introduced new features and protections against that, getting it to a much better place.

This new version is focused on making the device more effective in general. Thanks to the inclusion of the second-generation Ultra Wideband chip (the same one found in other recently released Apple devices like the iPhone 17), Apple says the new AirTag can work with the Precision Finding feature in the Find My app to direct users to the AirTag (and whatever lost item it’s stored with or attached to) from up to 50 percent farther away.

Additionally, the speaker in the AirTag is now 50 percent louder, Apple says. These two things together address some user complaints that, as useful as an AirTag can be in ideal circumstances, sometimes it is frustrating trying to get things just right to find something. It won’t eliminate all edge cases, but it ought to help.

Apple used this announcement to also talk up some of the features of the AirTag, including the encryption that it says prevents anyone but the AirTag owner from using it, and an arrangement with airlines where users can temporarily give airlines the ability to use Apple’s network to find a specific AirTag to locate lost luggage and the like.

To be clear, the new AirTag doesn’t introduce any major new features that aren’t already offered in the previous generation—this is just an update to the device’s accuracy, volume, and range.

The price remains unchanged, at $29 for one AirTag or $99 for a pack of four. The new model is available for order on Apple’s website now and will hit physical stores later this week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-4')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">“Wildly irresponsible”: DOT's use of AI to draft safety rules sparks concerns</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-4" style="display:none;">
            <h2>“Wildly irresponsible”: DOT's use of AI to draft safety rules sparks concerns</h2>
            <p><strong>Ars Technica - All content | 2026-01-26</strong></p>
            <a class="original-link" href="https://arstechnica.com/tech-policy/2026/01/wildly-irresponsible-dots-use-of-ai-to-draft-safety-rules-sparks-concerns/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The US Department of Transportation apparently thinks it’s a good idea to use artificial intelligence to draft rules impacting the safety of airplanes, cars, and pipelines, a ProPublica investigation revealed Monday.

It could be a problem if DOT becomes the first agency to use AI to draft rules, ProPublica pointed out, since AI is known to confidently get things wrong and hallucinate fabricated information. Staffers fear that any failure to catch AI errors could result in flawed laws, leading to lawsuits, injuries, or even deaths in the transportation system.

But the DOT’s top lawyer, Gregory Zerzan, isn’t worried about that, December meeting notes revealed, because the point isn’t for AI to be perfect. It’s for AI to help speed up the rulemaking process, so that rules that take weeks or months to draft can instead be written within 30 days. According to Zerzan, DOT’s preferred tool, Google Gemini, can draft rules in under 30 minutes.

“We don’t need the perfect rule on XYZ,” Zerzan told DOT staffers at the meeting. “We don’t even need a very good rule on XYZ. We want good enough.”

ProPublica spoke to experts and granted six DOT staffers anonymity to discuss their concerns about DOT’s use of Google Gemini to draft rules.

Some experts who monitor AI use in government told ProPublica that DOT could save time using Gemini as a research assistant “with plenty of supervision and transparency.” For example, at a presentation, DOT staffers were told that “most of what goes into the preambles of DOT regulatory documents is just ‘word salad,’” and “Gemini can do word salad.”

However, staffers told ProPublica they felt “deeply skeptical” that Gemini was up to the task. They emphasized that DOT rulemaking is “intricate work” requiring sometimes decades of “expertise in the subject at hand as well as in existing statutes, regulations, and case law.” Likely unsettling staffers further, ProPublica noted that a demonstration of Gemini’s rule-drafting produced a document missing key text, which a staffer would then have to fill in. Additionally, the DOT’s move comes after a year of AI hallucinations scrambling courts, with many lawyers fined and even judges admitting they can be fooled by fabricated information.

Any errors in the rules could have serious consequences. These rules “touch virtually every facet of transportation safety,” keeping “airplanes in the sky,” preventing “gas pipelines from exploding,” and stopping “freight trains carrying toxic chemicals from skidding off the rails,” ProPublica reported.

“It seems wildly irresponsible,” one staffer said.

Despite staffers’ concerns, DOT appears to be racing forward with the plan, ProPublica reported. The department has already used Gemini to draft a “still-unpublished Federal Aviation Administration rule, according to a DOT staffer briefed on the matter.”

Donald Trump has urged federal agencies to adopt AI at a rapid pace, but nowhere in his orders has the president pushed for AI to draft laws, ProPublica noted.

However, Trump is “very excited” about the DOT initiative, Zerzan told staffers at the meeting, suggesting that Trump sees DOT as the “point of the spear” and expects other agencies to follow its lead.

At DOT, Trump likely hopes to see many rules quickly updated to modernize airways and roadways. In a report highlighting the Office of Science and Technology Policy’s biggest “wins” in 2025, the White House credited DOT with “replacing decades-old rules with flexible, innovation-friendly frameworks,” including fast-tracking rules to allow for more automated vehicles on the roads.

Right now, DOT expects that Gemini can be relied on to “handle 80 to 90 percent of the work of writing regulations,” ProPublica reported. Eventually all federal workers who rely on AI tools like Gemini to draft rules “would fall back into merely an oversight role, monitoring ‘AI-to-AI interactions,’” ProPublica reported.

Google did not respond to Ars’ request to comment on this use case for Gemini, which could spread across government under Trump’s direction.

Instead, the tech giant posted a blog on Monday, pitching Gemini for government more broadly, promising federal workers that AI would help with “creative problem-solving to the most critical aspects of their work.”

Google has been competing with AI rivals for government contracts, undercutting OpenAI and Anthropic’s $1 deals by offering a year of access to Gemini for $0.47.

The DOT contract seems important to Google. In a December blog, the company celebrated that DOT was “the first cabinet-level agency to fully transition its workforce away from legacy providers to Google Workspace with Gemini.”

At that time, Google suggested this move would help DOT “ensure the United States has the safest, most efficient, and modern transportation system in the world.”

Immediately, Google encouraged other federal leaders to launch their own efforts using Gemini.

“We are committed to supporting the DOT’s digital transformation and stand ready to help other federal leaders across the government adopt this blueprint for their own mission successes,” Google’s blog said.

DOT did not immediately respond to Ars’ request for comment.</div>
        </div>
        
        <div class="card" onclick="openModal('content-5')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">How to encrypt your PC's disk without giving the keys to Microsoft</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-5" style="display:none;">
            <h2>How to encrypt your PC's disk without giving the keys to Microsoft</h2>
            <p><strong>Ars Technica - All content | 2026-01-26</strong></p>
            <a class="original-link" href="https://arstechnica.com/gadgets/2026/01/how-to-encrypt-your-pcs-disk-without-giving-the-keys-to-microsoft/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">In early 2025, Forbes reports, investigators at the FBI served Microsoft with a warrant seeking the BitLocker encryption recovery keys for several laptops it believed held evidence of fraud in Guam’s COVID-19 unemployment assistance program. And Microsoft complied with the FBI’s request.

BitLocker is the name of the full-disk encryption technology that has been part of Windows for nearly two decades. Though initially only available to owners of the Pro editions of Windows who turned it on manually, during the Windows 8 era Microsoft began using BitLocker to encrypt local disks automatically for all Windows 11 Home and Pro PCs that signed in with a Microsoft account. Using BitLocker in this way also uploads a recovery key for your device to Microsoft’s servers—this makes it possible to unlock your disk so you don’t lose data if something goes wrong with your system, or if you install a CPU upgrade or some other hardware change that breaks BitLocker. But it also (apparently) makes it possible for Microsoft to unlock your disk, too.

A Microsoft rep said that the company handled “around 20” similar BitLocker recovery key requests from government authorities per year, and that these requests often fail because users haven’t stored their recovery keys on Microsoft’s servers. Microsoft and other tech companies have generally refused requests to install universal encryption backdoors for law enforcement purposes, and some companies (like Apple) claim to store device encryption keys using another layer of encryption that renders the keys inaccessible to the company.

But storing your device’s recovery keys in someone else’s cloud can still represent a privacy and security risk, especially at a time when the US government has become more interested in targeting journalists and the Trump administration’s political opponents.

If you want to encrypt your Windows PC’s disk but you don’t want to store your recovery key with Microsoft, you do have options. We’ll recap the requirements, as well as the steps you’ll need to take.

Before we begin: Disk encryption is one of the handful of differences between the Home and Pro versions of Windows.

Both the Home and Pro versions of Windows support disk encryption, but only the Pro versions give users full control over the process. The Home version of Windows only supports disk encryption when logged in with a Microsoft account and will only offer to store your encryption key on Microsoft’s servers.

To access the full version of BitLocker and back up your own recovery key, you’ll need to upgrade to the Pro version of Windows. Microsoft offers its own first-party upgrade option through the Microsoft Store for a one-time fee of $99, but it’s also possible to bring your own product key and upgrade yourself. This Macworld-affiliated listing from StackCommerce claims to be an official Microsoft partner and is offering a Windows 11 Pro key for just $10, though your mileage with third-party key resellers may vary.

However you get it, once you have a valid key, open Settings, then System, then Activation, click upgrade your edition of Windows, click change product key, and then enter your Windows 11 Pro key (Windows 10 Pro keys should also work, if you already have one). Luckily, changing Windows editions doesn’t require anything more disruptive than a system restart. You won’t need to reinstall Windows, and you shouldn’t lose any of your installed apps or data.

And once you’ve upgraded a PC to Windows 11 Pro once, you should be able to reinstall and activate Windows 11 Pro on that system again any time you want without having to re-enter your product key. Keep the product key stored somewhere, though, just in case you do need to use it for a reinstall, or if you ever need to re-activate Windows after a hardware upgrade.

Once you’ve got Windows 11 Pro set up, it’s time to either encrypt or re-encrypt your disk.

If you’ve signed in with a Microsoft account, your disk is likely already encrypted, and the key is likely already stored on Microsoft’s servers. If this is the case, this process will actually involve fully unencrypting and re-encrypting your drive, which can take an hour or two depending on the speed of your PC and the size of your drive.

Here’s how to check your current encryption status and the steps to follow if you’ve already got a key backed up with Microsoft:

Once your disk is re-encrypted, your PC should work just as it did before. The actual encryption technology hasn’t changed at all—all we’ve done is change where the recovery key is saved.

This does put the burden on the user if and when it comes time to use your recovery key. You’ll have to remember where you put it and not get it mixed up with any other recovery keys you’ve stored for other PCs or old Windows installations. But for anyone concerned about Microsoft giving their device’s encryption keys to the government or anyone else with a valid subpoena, the extra hassle may be worth it in exchange for the added privacy and peace of mind.</div>
        </div>
        
        <div class="card" onclick="openModal('content-6')">
            <div class="source">Futurism</div>
            <div class="title">Tesla Kills Autopilot After Storm of Criticism, Paywalls Basic Features</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-6" style="display:none;">
            <h2>Tesla Kills Autopilot After Storm of Criticism, Paywalls Basic Features</h2>
            <p><strong>Futurism | 2026-01-26</strong></p>
            <a class="original-link" href="https://futurism.com/future-society/tesla-kills-autopilot-criticism">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The concept for Tesla’s driver-assistance system, Autopilot, has been around for well over a decade. Elon Musk’s EV maker has long used the term to describe features like advanced cruise control and auto-steer, all the while admitting that drivers still need to be able to take over at any time.

But in light of plummeting sales and shrinking profits, Tesla has killed the feature in the United States and Canada for good. It’s a major reversal after over a decade of Musk making yearly — and flat-out wrong — predictions of achieving fully autonomous, or Level 5, driving “next year.”

Autopilot has also been caught up in several high-profile investigations by federal regulators, following hundreds of crashes and dozens of deaths involving the feature. The EV maker has also faced a litany of lawsuits over the software, including a $329 million wrongful death settlement last year.

To raise much-needed revenue now that car sales have taken a major hit, the company has instead paywalled most of the basic features. Starting on February 14, Tesla owners will need to shell out a steep $99 a month to enable features like autosteer or advanced lane keep assist, something the vehicles were previously capable of without a subscription. (Traffic Aware Cruise Control, however, will remain standard, even without a subscription.)

The timing is suspect, to say the least. As Ars Technica points out, a court ruled in December that Tesla deceived its customers by implying that its “Autopilot” branding amounts to “deceptive marketing,” giving the company a mere 60 days to fix any misleading claims or be banned from selling cars in California, one of its biggest markets.

The start of the subscription service almost perfectly aligns with that deadline, although it remains unclear what exactly motivated the company to kill Autopilot. Another major motivating factor may be Musk’s $1 trillion pay package, which requires the company to reach 10 million active subscriptions to its driver assistance software.

Tesla’s branding for the features has been especially confusing as of late, differentiating between Autopilot and “Full Self-Driving” (FSD), a highly controversial and easily fooled add-on package that also still requires the driver to stay engaged at all times, despite its misleading name.

As of February 14, owners will only be able to either pay $99 a month for an FSD subscription — or live with the fact that their vehicles’ driver assistance capabilities will be considerably reined in. Before that date, users can still shell out a steep $8,000 to permanently unlock FSD.

Musk has boasted that it’s an incredible value add — and one that’s going to become even more expensive as time goes on.

“I should also mention that the $99/month for supervised FSD will rise as FSD’s capabilities improve,” Musk warned in a January 22 tweet. “The massive value jump is when you can be on your phone or sleeping for the entire ride (unsupervised FSD).”

When such an “unsupervised” version of FSD will materialize remains a mystery. However, given Musk’s track record of making predictions about the tech, such a future may still be many years out — if it ever materializes.

More on Autopilot: Tesla Admits That Its Cars May Never Fully Drive Themselves</div>
        </div>
        
        <div class="card" onclick="openModal('content-7')">
            <div class="source">Futurism</div>
            <div class="title">Earth’s Lower Orbit Could Rapidly Collapse, Scientists Warn</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-7" style="display:none;">
            <h2>Earth’s Lower Orbit Could Rapidly Collapse, Scientists Warn</h2>
            <p><strong>Futurism | 2026-01-26</strong></p>
            <a class="original-link" href="https://futurism.com/space/earths-lower-orbit-rapidly-collapse">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">If you thought humanity already had its hands full with climate change, think again.

With satellites and space junk increasingly cluttering our planet’s low Earth orbit, a team of scientists warn that this entire region could suddenly collapse into a destructive maelstrom of swirling debris, posing a threat to any spacecraft that dares to venture up there, and hurling dangerous missiles of space junk down onto our planet below.

Their study, which is yet-to-be-peer reviewed, builds on a theoretical scenario first laid out by NASA scientist Donald Kessler, which describes how just a few accidental collisions between satellites could quickly cascade into a vicious cycle in which the resulting debris causes even more smash-ups, and thus even more debris. At worst, the ensuing vortex of dangerous debris could trap us on our planet and set back spaceflight for decades.

With more satellites being launched into low Earth orbit than ever, this scenario — dubbed Kessler syndrome — is starting to be considered as a serious possibility. Elon Musk’s SpaceX alone maintains a “megaconstellation” of over 9,000 expendable satellites, with Amazon set to follow suit with its own megaconstellation and China working on yet another.

Kessler originally envisioned this orbital catastrophe unfolding over many years. But the new work adds a grim twist to the mix. What if a Kessler syndrome type scenario was suddenly kicked off by a violent solar storm? These outbursts by the Sun blast the Earth with electromagnetic waves that can disrupt electrical grids and communications. In theory, a powerful enough one could cut off our contact with satellites and fry their navigation systems, leaving them with no means to stay on course.

It’s a concerning possibility. With all that stuff up there, SpaceX’s expendable satellites have to constantly perform maneuvers to avoid hitting each other and other objects, with over 300,000 of these maneuvers performed last year.

Investigating this possibility, the researchers created a new metric called the CRASH clock, which measures how long it would take a catastrophic collision to occur if the satellites lose navigation in a crisis like a solar storm.

The gist is that things would go south very quickly. The researchers calculated that satellites may be having a “close approach,” or pass within one kilometer of each other, once every 36 seconds in low Earth orbit — an uncomfortably close distance in space.

Factoring that in, they put the CRASH clock at just 5.5 days, meaning that humanity would have very little time to intervene if this solar storm did occur. On the other hand, if we were struck by a solar event of this magnitude — like the infamous Carrington Event in 1859, which took out the planet’s burgeoning telegraph infrastructure and today would likely cause blackouts the world over— we would probably have more immediate concerns to worry about.

More on space: Experts Warn That There’s Something Wrong With the Moon Rocket NASA Is About to Launch With Astronauts Aboard</div>
        </div>
        
        <div class="card" onclick="openModal('content-8')">
            <div class="source">Futurism</div>
            <div class="title">Trump Forgets the Word for “Alzheimer’s” While Insisting His Memory Is Fine</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-8" style="display:none;">
            <h2>Trump Forgets the Word for “Alzheimer’s” While Insisting His Memory Is Fine</h2>
            <p><strong>Futurism | 2026-01-26</strong></p>
            <a class="original-link" href="https://futurism.com/health-medicine/trump-forgets-word-alzheimers">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Experts have long questioned president Donald Trump’s claims of having a clean bill of health. He has been spotted with swollen ankles and dark bruises on both of his hands, which experts argue could be a sign that he’s receiving frequent intravenous treatments.

His mental acuity has also been called into question, with critics pointing to his slurred speech, nonsensical rants, and lapses in memory.

Case in point, in a recently published interview with New York Magazine, Trump struggled to recall the name of Alzheimer’s disease — a particularly dark blunder, considering the condition is characterized by progressive memory loss, and Trump has a family history of it.

When discussing his father, Fred Trump, he struggled to remember what the disease was called.

“He had one problem. At a certain age, about 86, 87, he started getting… what do they call it?” he pondered during the video.

White House press secretary Karoline Leavitt came to his rescue.

“Like an Alzheimer’s thing,” the president continued. “Well, I don’t have it.”

When asked if the disease is “something you think about at all,” Trump was vehement in his denial, but once again struggled to sound coherent.

“No, I don’t think about it at all,” he said. “You know why? Because whatever it is, my attitude is whatever.”

Swirling questions about Trump’s cognitive condition have clearly frustrated the 79-year-old. During baffling remarks from the Oval Office earlier this month, made after signing a bipartisan Whole Milk for Healthy Kids Act, Trump boasted that a penchant for dairy had allowed him to “ace” all of his cognitive tests.

“I’ve aced every one of them because I drink milk,” he said.

He also boasted about passing cognitive tests on January 2 and December 9, suggesting that his neurological condition has been evaluated frequently in recent months. (He’s discussed the topic for years now, claiming to have achieved a top score on the Montreal Cognitive Assessment (MoCA), a 30-point cognitive screening tool to detect cognitive impairment, back in 2018.)

Also concerning is his family history. Fred Trump died at the age of 93 in 1999, after struggling with the disease for almost a decade.

Adding to Trump’s optics conundrum around his health, his top staff often defends his physical and mental health in terms so strong that it can be unintentionally comical.

Leavitt, for instance, insisted to NY Mag that the “Marine sentries who stand outside the Oval Office, they had to request more staff and bring up more Marines because the president is in the Oval Office so much.”

“They’ve never had to do that before,” she said. “They had to request more guys to stand by the door because they are running out of men to fill the shifts.”

“He’s working harder now than he did in his entire life,” she told the magazine. “Even in real estate when he was on top of the world in New York.”

More on Trump’s health: Trump’s Other Hand Is Also Now Showing a Grisly Mark</div>
        </div>
        
        <div class="card" onclick="openModal('content-9')">
            <div class="source">Futurism</div>
            <div class="title">Scientists Investigating 2,000-Year-Old Artifact That Appears to Be a Battery</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-9" style="display:none;">
            <h2>Scientists Investigating 2,000-Year-Old Artifact That Appears to Be a Battery</h2>
            <p><strong>Futurism | 2026-01-26</strong></p>
            <a class="original-link" href="https://futurism.com/future-society/scientists-ancient-artifiact-battery">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">A 2,000 year old battery, or just a very interesting pot?

This is the debate that’s been swirling over the fragments of a puzzling artifact discovered in Iraq nearly a century ago. Dubbed the “Baghdad battery,” it’s believed to have originally been a clay jar housing a copper vessel, at the center of which was an iron rod. This arrangement, either by coincidence or design, could’ve allowed it to function as a primitive galvanic cell, some archaeologists argue — a primitive energy storage device pioneered in the Western world by Alessandro Volta, after whom the “volt” was named.

These are tough claims to bear out, not least of all because the original artifact has been lost since the US’s invasion of Iraq in 2003. As such, archaeologists have had to rely on reconstructing the strange vessel based on records to try to tease out its origins.

Now a new study highlighted by Chemistry World purports that the Baghdad battery wasn’t just a battery, but one that was capable of outputting much more power than once believed.

“If this artefact were truly a battery — and I could be wrong of course — then my experiment shows the most effective and convenient way it could have been used as one,” the author, independent researcher Alexander Bazes, told the outlet.

Skeptics argue that the artifact, in its suspected arrangement, would’ve outputted too puny an amount of power to have intentionally been a battery.

Bazes’s reconstruction argues otherwise. His experiments suggests that the clay jar’s porous exterior acted like a separator between an electrolyte, perhaps lye, and air, which connected with the copper vessel to create an outer cell. Meanwhile, the iron rod inside the copper vessel acted as an inner cell, creating an electrical series that could’ve produced 1.4 volts of electricity — approximately the same voltage of a modern AA battery.

Still, Bazes doesn’t buy the argument purported by some fringe archaeologists that the battery’s copper vessel would’ve been used to electroplate jewelry, or coat them in a thin layer of metal. Instead, he argues the Baghdad battery may have been used to “ritually corrode” prayers written on paper, as witnessing the corrosion would’ve been seen as “visual evidence of an energetic influence having passed through their prayer,” Bazes wrote in the study.

Or maybe it wasn’t a battery at all, counters University of Pennsylvania archaeologist William Hafford, who has extensively researched the artifact. In reality, it was likely a sacred jar for storing prayers, he told Chemistry World, noting that other magic items like it have been found buried nearby, including a similar clay jar with ten copper vessels, which is obviously too many to form a battery. The iron rod that supposedly acted as an electrode for the inner battery cell were really just iron nails that were part of the magical ritual.

“You would drop the prayer through the neck of the jar, seal it with bitumen and then bury it with a ritual,” Hafford told the outlet. “They were usually buried in the ground because you were giving them to the chthonic deities.”

More on archaeology: Divers Intrigued by Huge Underwater Structure</div>
        </div>
        
        <div class="card" onclick="openModal('content-10')">
            <div class="source">Futurism</div>
            <div class="title">Entire City Buried by Epic Snow</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-10" style="display:none;">
            <h2>Entire City Buried by Epic Snow</h2>
            <p><strong>Futurism | 2026-01-26</strong></p>
            <a class="original-link" href="https://futurism.com/science-energy/city-buried-snow-kamchatka">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">As much of North America is still recovering from a devastating winter storm over the weekend, other parts of the globe have already been through much worse.

Consider the Kamchatka Peninsula, a Russian territory that reaches into the Pacific Ocean north-east of Japan, which has been battling with record amounts of snow this winter. On January 16 alone, a small city on the peninsula’s southern coast, called Petropavlovsk-Kamchatskiy, experienced a baffling five and a half feet of snow, effectively burying local residents and their cars completely. Some areas saw more than six and a half feet in just the first half of January.

One video that went viral on social media last week shows a local resident jumping out of his window several stories up, only to land in a deep blanket of snow below. A time-lapse recorded by a CCTV camera shows entire cars being buried in a matter of hours, forcing residents to shovel narrow channels just to get down the block.

According to the Russian state-operated news agency RIA Novosti, it was the most snowfall in the peninsula the Kamchatka hydrometeorology department has seen in about 60 years. Satellite images highlighted by NASA show the peninsula being buried by snow, turning it into a white snowball that can easily be spotted from space.

Yet as the New York Times reports, AI-generated videos have added to the confusion, showing unrealistic apocalyptic scenes. One fake clip, for instance, shows residents sliding down massive ramps of snow that reach the top of ten-story apartment blocks.

Petropavlovsk-Kamchatsky local Andrey Stepanchuk told the NYT that many of the videos circulating online were not real, describing the situation as “nothing catastrophic.”

Apart from record amounts of snow, the region had to deal with other kinds of natural disasters as well. After all, per NASA, it’s the most volcanically active region in the entire world.

Case in point, Kamchatka was struck by a magnitude 8.8 earthquake last summer, the sixth largest on record since 1900. Just weeks later, the Krasheninnikov volcano near the east coast erupted for the first time in “at least 400 years.”

In short, Kamchatka’s experiences with the brute force of Mother Nature really put the latest snowstorm blanketing much of the United States and Canada into perspective.

More on snow: Meteorologist Warns That Winter Storm Means Trees Are About to Start Exploding</div>
        </div>
        
        <div class="card" onclick="openModal('content-11')">
            <div class="source">Futurism</div>
            <div class="title">AI Is Causing Cultural Stagnation, Researchers Find</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-11" style="display:none;">
            <h2>AI Is Causing Cultural Stagnation, Researchers Find</h2>
            <p><strong>Futurism | 2026-01-26</strong></p>
            <a class="original-link" href="https://futurism.com/artificial-intelligence/ai-cultural-stagnation">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Generative AI relies on a massive body of training material, primarily made up of human-authored content haphazardly scraped from the internet.

Scientists are still trying to better understand what will happen when these AI models run out of that content and have to rely on synthetic, AI-generated data instead, closing a potentially dangerous loop. Studies have found that AI models start cannibalizing this AI-generated data, which can eventually turn their neural networks into mush. As the AI iterates on recycled content, it starts to spit out increasingly bland and often mangled outputs.

There’s also the question of what will happen to human culture as AI systems digest and produce AI content ad infinitum. As AI executives promise that their models are capable enough to replace creative jobs, what will future models be trained on?

In an insightful new study published in the journal Patterns this month, an international team of researchers found that a text-to-image generator, when linked up with an image-to-text system and instructed to iterate over and over again, eventually converges on “very generic-looking images” they dubbed “visual elevator music.”

“This finding reveals that, even without additional training, autonomous AI feedback loops naturally drift toward common attractors,” they wrote. “Human-AI collaboration, rather than fully autonomous creation, may be essential to preserve variety and surprise in the increasingly machine-generated creative landscape.”

As Rutgers University professor of computer science Ahmed Elgammal writes in an essay about the work for The Conversation, it’s yet another piece of evidence that generative AI may already be inducing a state of “cultural stagnation.”

The recent study shows that “generative AI systems themselves tend toward homogenization when used autonomously and repeatedly,” he argued. “They even suggest that AI systems are currently operating in this way by default.”

“The convergence to a set of bland, stock images happened without retraining,” Elgammal added. “No new data was added. Nothing was learned. The collapse emerged purely from repeated use.”

It’s a particularly alarming predicament considering the tidal wave of AI slop drowning out human-made content on the internet. While proponents of AI argue that humans will always be the “final arbiter of creative decisions,” per Elgammal, algorithms are already starting to float AI-generated content to the top, a homogenization that could greatly hamper creativity.

“The risk is not only that future models might train on AI-generated content, but that AI-mediated culture is already being filtered in ways that favor the familiar, the describable and the conventional,” the researcher wrote.

It remains to be seen to what degree existing creative outlets, from photography to theater, will be affected by the advent of generative AI, or whether they can coexist peacefully.

Nonetheless, it’s an alarming trend that needs to be addressed. Elgammal argued that to stop this process of cultural stagnation, AI models need to be encouraged or incentivized to “deviate from the norms.”

“If generative AI is to enrich culture rather than flatten it, I think systems need to be designed in ways that resist convergence toward statistically average outputs,” he concluded. “The study makes one thing clear: Absent these interventions, generative AI will continue to drift toward mediocre and uninspired content.”

More on generative AI: San Diego Comic Con Quietly Bans AI Art</div>
        </div>
        
        <div class="card" onclick="openModal('content-12')">
            <div class="source">TechCrunch</div>
            <div class="title">South Korea’s Edenlux set for U.S. debut of eye-strain wellness device</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-12" style="display:none;">
            <h2>South Korea’s Edenlux set for U.S. debut of eye-strain wellness device</h2>
            <p><strong>TechCrunch | 2026-01-27</strong></p>
            <a class="original-link" href="https://techcrunch.com/2026/01/26/south-koreas-edenlux-set-for-u-s-debut-of-eye-strain-wellness-device/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">People around the world now spend hours a day on their smartphones. On average, daily smartphone use exceeds three hours, and for many adults, total screen time climbs to six hours or more, according to research. This constant close-up screen exposure has been linked to a growing list of eye-health issues, including dry and irritated eyes, eye fatigue, blurred vision, headaches, and the worsening of nearsightedness, per reports.

Edenlux, a South Korea–headquartered startup, has developed technology to address eye and ear health issues caused by screen-heavy digital lifestyles.

The company’s mission is personal. Edenlux founder and CEO Sungyong Park knows first-hand what it feels like to lose control of your eyesight. While serving as a military physician, Park received a muscle relaxant injection for severe neck stiffness. It triggered a rare side effect: temporary paralysis of the eye muscles responsible for focusing. Doctors told him there was little to do but wait.

Park didn’t wait. He imported specialized ophthalmic equipment and began retraining his eye muscles himself. Over time, his vision gradually returned. That experience reshaped his understanding of eye health, leading Park, a medical doctor turned entrepreneur, to develop technology to help people protect and restore their vision in a screen-heavy world.

Now, Edenlux is preparing to launch its second wellness device, Eyeary, a daily visual recovery tool aimed at the U.S. market, with a planned Indiegogo launch around the end of March. Unlike medical devices, Edenlux’s products fall under the FDA’s wellness category, allowing them to be described for vision training and general eye health. (The company opted to launch on Indiegogo rather than seek investor funding, Park said, citing sufficient cash reserves to support operations for several years.)

The company’s first product, Otus, launched in 2022 in South Korea, Singapore, Japan, and Taiwan. The bulky, VR-style device uses lenses to contract and relax the ciliary muscle. Otus has generated $10 million in cumulative revenue, and Edenlux says Eyeary is designed to be faster and easier to use.

“With Otus, users typically took about 12 months to reduce their dependence on reading glasses. Eyeary could shorten that to around six months,” Park claimed.

Eyeary is also a design leap, he added. It looks like normal glasses, is lighter and more comfortable and the lens system includes 144 diopter focal points, allowing for finer focus adjustments and more precise eye-muscle training. (Otus has five diopter focal points) The device pairs with a mobile app via Bluetooth, collecting usage data and feeding it to Edenlux’s servers. The company analyzes datasets across age, gender, and vision profiles, using AI to predict improvement timelines and customize training programs.

Prolonged screen time can overwork the ciliary muscle, which controls the lens inside the eye. “When people are young, the muscle is strong enough to focus,” Park said. “But constant smartphone use keeps it contracted, and over time, it can weaken, leading to fatigue and vision problems.”

Edenlux has developed a suite of products targeting specific eye conditions, including Otus and Eyeary for visual recovery, Tearmore for dry eye, Lux-S for strabismus, Lumia for myopia prevention, and Heary for auditory recovery. Tearmore, Lux-S, Lumia, and Heary are expected to roll out in Asia, Park said.

Park sees companies like Oura Ring as peers. Both collect human data and provide insights via software, on a subscription model. But while Oura focuses on heart rate and sleep, Edenlux targets vision and hearing health.

Its target customers include all individuals who regularly use smartphones and earphones. “We aim to address the root causes of eye and hearing problems from digital device overuse,” Park said.

Edenlux raised $39 million in its Series A round in 2020 and $60 million in Series B funding in 2022. The company recently established a U.S. subsidiary in Dallas, Texas, where its devices will undergo final assembly.

While Edenlux currently develops and manufactures in-house, it’s exploring partnerships with major tech firms like Apple or Samsung, aiming to integrate its vision-protecting technology with smartphones.

Combining firsthand insight, advanced science, and hardware devices, Edenlux believes that eye health in the digital age is more than a wellness trend – it’s an emerging area in consumer technology.

Kate Park is a reporter at TechCrunch, with a focus on technology, startups and venture capital in Asia. She previously was a financial journalist at Mergermarket covering M&A, private equity and venture capital.

Tickets are live at the lowest rates of the year. Save up to $680 on your pass — and if you’re among the first 500 registrants, score a +1 pass at 50% off.Meet investors. Discover your next portfolio company. Hear from 250+ tech leaders, dive into 200+ sessions, and explore 300+ startups building what’s next. Don’t miss these one-time savings.

TikTok users freak out over app’s ‘immigration status’ collection — here’s what it means

Researchers say Russian government hackers were behind attempted Poland power outage

Microsoft gave FBI a set of BitLocker encryption keys to unlock suspects’ laptops: Reports

Capital One acquires Brex for a steep discount to its peak valuation, but early believers are laughing all the way to the bank

Not to be outdone by OpenAI, Apple is reportedly developing an AI wearable

Lemonade launches an insurance product for Tesla Full Self-Driving customers

Anthropic’s CEO stuns Davos with Nvidia criticism</div>
        </div>
        
        <div class="card" onclick="openModal('content-13')">
            <div class="source">TechCrunch</div>
            <div class="title">Qualcomm backs SpotDraft to scale on-device contract AI with valuation doubling toward $400M</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-13" style="display:none;">
            <h2>Qualcomm backs SpotDraft to scale on-device contract AI with valuation doubling toward $400M</h2>
            <p><strong>TechCrunch | 2026-01-27</strong></p>
            <a class="original-link" href="https://techcrunch.com/2026/01/26/qualcomm-backs-spotdraft-to-scale-on-device-contract-ai-with-valuation-doubling-toward-400m/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">As demand grows for privacy-first enterprise AI that can run without sending sensitive data to the cloud, SpotDraft has raised $8 million from Qualcomm Ventures in a strategic Series B extension to scale its on-device contract review tech for regulated legal workflows.

The extension values SpotDraft at around $380 million, the startup told TechCrunch, nearly double its $190 million post-money valuation following its $56 million Series B in February of last year.

Across regulated sectors, enterprises have moved quickly to test generative AI, but privacy, security, and data governance concerns continue to slow adoption for sensitive workflows — especially in legal, where contracts can include privileged information, intellectual property, pricing, and deal terms. Industry research has consistently flagged data security and privacy as key barriers to wider GenAI deployment in professional services, pushing vendors like SpotDraft to pursue architectures that keep core contract intelligence on the user’s device rather than routing it through the cloud.

At Qualcomm’s Snapdragon Summit 2025, SpotDraft demonstrated its VerifAI workflow running end-to-end on Snapdragon X Elite-powered laptops, executing contract review and edits offline while keeping the document on the local machine. SpotDraft said internet connectivity is still required for login, licensing, and collaboration features, but contract review, risk scoring, and redlining can run fully offline without sending documents to the cloud.

SpotDraft sees legal as an early proving ground for on-device enterprise AI, arguing that sensitive contracts often cannot be routed through external cloud models due to privacy, security, and compliance constraints.

“The future of how enterprise AI is going to be — right now, there’s got to be AI that is close to the document, which is privacy critical, latency sensitive, [and] legally sensitive, and those are the things that will move on device,” said Shashank Bijapur (pictured above, left), co-founder and CEO of SpotDraft, in an interview.

SpotDraft says VerifAI’s on-device capability extends beyond simply generating summaries, with the tool designed to apply playbooks and recommendations directly inside Microsoft Word, the way legal teams already work. “VerifAI will compare a contract against your guidelines, your playbooks, your prior policies,” said Madhav Bhagat (pictured above, right), co-founder and CTO of SpotDraft.

Bijapur told TechCrunch that the demand for on-device AI is emerging most clearly in tightly regulated sectors, including defense and pharma, where internal security reviews and data residency requirements can slow or block the use of cloud-based AI tools for sensitive documents.

On-device models have rapidly closed the gap with cloud-based systems, both in output quality and response times, Bhagat said. “Now we’ve come to a place where, in terms of eval, we are seeing as little as 5% difference between the frontier models, and some of these fine-tuned on device models,” he said, adding that speeds on newer chips are now “one-third of what we get in the cloud.”

Since its launch in 2017, SpotDraft said it has reached more than 700 customers, up from around 400 in February last year, and counts Apollo.io, Panasonic, Zeplin, and Whatfix among its users. The company said adoption is rising on its contract lifecycle management platform, with customers now processing over 1 million contracts annually, contract volumes growing 173% year-over-year, and nearly 50,000 monthly active users. It also expects 100% year-over-year revenue growth in 2026, after growing 169% in 2024 and posting a similar growth rate in 2025, though it did not share specific revenue figures.

SpotDraft plans to use the new capital to deepen its product and AI capabilities and expand its enterprise presence across the Americas, the EMEA region (Europe, Middle East, and Africa), and India, Bijapur said, adding that Qualcomm’s involvement extends beyond financing into joint development and go-to-market efforts for on-device deployments. The startup’s on-device workflow is currently available to a limited set of customers, and the founders expect it to expand more broadly as compatible AI PC hardware becomes more widely available.

“SpotDraft’s ability to deploy their proprietary models securely on-device using Snapdragon platforms represents a meaningful advancement for a privacy-critical industry,” said Quinn Li, senior vice president, Qualcomm Technologies, and global head of Qualcomm Ventures.

Bengaluru- and New York-based SpotDraft said it has a team of 300-plus employees, including 15–20 in the U.S., where COO Akshay Verma is based, and four to five in the UK, with the rest of the workforce in Bengaluru.

To date, the startup has raised $92 million, including the latest Qualcomm Ventures investment. Its earlier investors include Vertex Growth Singapore, Trident Growth Partners, Xeed VC, Arkam Ventures, and Prosus Ventures.

Jagmeet covers startups, tech policy-related updates, and all other major tech-centric developments from India for TechCrunch. He previously worked as a principal correspondent at NDTV.

You can contact or verify outreach from Jagmeet by emailing mail@journalistjagmeet.com.

Tickets are live at the lowest rates of the year. Save up to $680 on your pass — and if you’re among the first 500 registrants, score a +1 pass at 50% off.Meet investors. Discover your next portfolio company. Hear from 250+ tech leaders, dive into 200+ sessions, and explore 300+ startups building what’s next. Don’t miss these one-time savings.

TikTok users freak out over app’s ‘immigration status’ collection — here’s what it means

Researchers say Russian government hackers were behind attempted Poland power outage

Microsoft gave FBI a set of BitLocker encryption keys to unlock suspects’ laptops: Reports

Capital One acquires Brex for a steep discount to its peak valuation, but early believers are laughing all the way to the bank

Not to be outdone by OpenAI, Apple is reportedly developing an AI wearable

Lemonade launches an insurance product for Tesla Full Self-Driving customers

Anthropic’s CEO stuns Davos with Nvidia criticism</div>
        </div>
        
        <div class="card" onclick="openModal('content-14')">
            <div class="source">TechCrunch</div>
            <div class="title">Google pays $68M to settle claims its voice assistant spied on users</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-14" style="display:none;">
            <h2>Google pays $68M to settle claims its voice assistant spied on users</h2>
            <p><strong>TechCrunch | 2026-01-27</strong></p>
            <a class="original-link" href="https://techcrunch.com/2026/01/26/google-pays-68-million-to-settle-claims-its-voice-assistant-spied-on-users/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Google agreed to pay $68 million to settle claims its voice assistant illegally spied on users to, among other things, serve them advertisements, Reuters reports.

Google did not admit wrongdoing in the settlement of the class-action case, which accused the firm of “unlawful and intentional interception and recording of individuals’ confidential communications without their consent and subsequent unauthorized disclosure of those communications to third parties.” The suit further claimed that “information gleaned from these recordings was wrongly transmitted to third parties for targeted advertising and for other purposes.”

The case centered on “false accepts,” wherein Google Assistant is alleged to have activated and recorded the user’s communications even if they had not intentionally prompted it to do so with a wake word. TechCrunch reached out to Google for comment.

Americans have long suspected that their devices inappropriately spy on them. Those suspicions have led, increasingly, to claims of legal wrongdoing. In 2021, Apple agreed to pay $95 million to settle claims its voice assistant, Siri, had recorded their conversations without a prompt from users.

Google, like other tech giants, has faced other privacy-related litigation in recent years. Last year, the company agreed to pay $1.4 billion to the state of Texas to settle two lawsuits that claimed it had violated the state’s data privacy laws.

Tickets are live at the lowest rates of the year. Save up to $680 on your pass — and if you’re among the first 500 registrants, score a +1 pass at 50% off.Meet investors. Discover your next portfolio company. Hear from 250+ tech leaders, dive into 200+ sessions, and explore 300+ startups building what’s next. Don’t miss these one-time savings.

Subscribe for the industry’s biggest tech news

Every weekday and Sunday, you can get the best of TechCrunch’s coverage.

TechCrunch Mobility is your destination for transportation news and insight.

Startups are the core of TechCrunch, so get our best coverage delivered weekly.

Provides movers and shakers with the info they need to start their day.

By submitting your email, you agree to our Terms and Privacy Notice.</div>
        </div>
        
        <div class="card" onclick="openModal('content-15')">
            <div class="source">TechCrunch</div>
            <div class="title">AI chip startup Ricursive hits $4B valuation two months after launch</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-15" style="display:none;">
            <h2>AI chip startup Ricursive hits $4B valuation two months after launch</h2>
            <p><strong>TechCrunch | 2026-01-27</strong></p>
            <a class="original-link" href="https://techcrunch.com/2026/01/26/ai-chip-startup-ricursive-hits-4b-valuation-two-months-after-launch/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Ricursive Intelligence, a startup building an AI system to design and automatically improve AI chips, has raised $300 million at a $4 billion valuation. The company said Monday the round was led by Lightspeed.

Ricursive says the system will be able to create its own silicon substrate layer and speed up AI chip improvements. Rinse and repeat to get to AGI, the founders say.

The Series A comes just two months since the company formally launched with a seed investment led by Sequoia. It has raised $335 million total, reports The New York Times.

Ricursive was founded by former Google researchers CEO Anna Goldie and CTO Azalia Mirhoseini. Their work on a novel reinforcement learning method for designing chip layouts, called AlphaChip, has been used in four generations of Google’s TPU chip, the startup says.

DST Global, Nvidia’s venture capital arm NVentures, Felicis Ventures, 49 Palms Ventures, and Radical AI are also investors.

Ricursive is not to be confused with the similarly named startup Recursive, reportedly founded by well-known natural language processing neural networks researcher Richard Socher. That Recursive is also in talks to raise a giant round at a $4 billion valuation, Bloomberg reported last week. And it is also working on AI systems that improve themselves.

And these two are not the only new startups working on the concept. As TechCrunch previously reported, Naveen Rao’s new AI hardware startup, named Unconventional AI, is also working on an intelligent substrate. In December it raised a $475 million seed round at a $4.5 billion valuation led by Andreessen Horowitz and Lightspeed Ventures, with participation from Lux Capital and DCVC.

Tickets are live at the lowest rates of the year. Save up to $680 on your pass — and if you’re among the first 500 registrants, score a +1 pass at 50% off.Meet investors. Discover your next portfolio company. Hear from 250+ tech leaders, dive into 200+ sessions, and explore 300+ startups building what’s next. Don’t miss these one-time savings.

Subscribe for the industry’s biggest tech news

Every weekday and Sunday, you can get the best of TechCrunch’s coverage.

TechCrunch Mobility is your destination for transportation news and insight.

Startups are the core of TechCrunch, so get our best coverage delivered weekly.

Provides movers and shakers with the info they need to start their day.

By submitting your email, you agree to our Terms and Privacy Notice.</div>
        </div>
        
        <div class="card" onclick="openModal('content-16')">
            <div class="source">TechCrunch</div>
            <div class="title">Meta to test premium subscriptions on Instagram, Facebook, and WhatsApp</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-16" style="display:none;">
            <h2>Meta to test premium subscriptions on Instagram, Facebook, and WhatsApp</h2>
            <p><strong>TechCrunch | 2026-01-26</strong></p>
            <a class="original-link" href="https://techcrunch.com/2026/01/26/meta-to-test-premium-subscriptions-on-instagram-facebook-and-whatsapp/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Meta plans to test new subscriptions that give people access to exclusive features on it apps, the company told TechCrunch on Monday. The tech giant said the new subscriptions will unlock more productivity and creativity, along with expanded AI capabilities.

In the coming months, Meta said it will offer a premium experience on Instagram, Facebook, and WhatsApp that gives users access to special features and more control over how they share and connect, while keeping the core experiences free. Meta doesn’t appear to be locked into one strategy, noting that it will test a variety of subscription features and bundles, and that each app subscription will have a distinct set of exclusive features.

Meta also shared that it plans to scale Manus, an AI agent it recently acquired for a reported $2 billion, as part of its subscription plans.

Meta is taking a two-fold approach to Manus. The company is going to integrate Manus into Meta products, while continuing to sell standalone subscriptions to businesses. Meta has already been spotted working on adding a shortcut to Manus AI on Instagram, according to a screenshot shared by reverse engineer Alessandro Paluzzi, who often finds unreleased features while they’re still under development.

Additionally, Meta plans to test subscriptions for AI features, such as Vibes video generation. Vibes is Meta’s AI-powered short-form video experience built into the Meta AI app that lets people create and remix AI-generated videos. Although Vibes has been free since its launch last year, Meta now plans to offer freemium access to Vibes video creation, with the option to subscribe to unlock additional video creation opportunities each month.

While it’s unknown what the paid features on WhatsApp and Facebook will look like, Paluzzi notes that the new subscription on Instagram will let users create unlimited audience lists, the ability to see a list of followers who don’t follow you back, and the option to view a Story without the poster seeing that you viewed it.

It’s worth noting that the new subscriptions will be separate from Meta Verified. The tech giant says it’s going to use what it learned from Meta Verified to evolve its subscription business to include more offerings it thinks everyday users, creators, and businesses will want.

Meta Verified is aimed at content creators and businesses, as it comes with a verified badge, 24/7 direct support, impersonation protections, search optimization, exclusive stickers, and more. While these features aren’t aimed at everyday users or non-creators, the new subscriptions will be designed for a broader audience.

The launch of additional subscriptions will allow Meta to generate more revenue; however, many users may be deterred by subscription fatigue. With so many paid services competing for monthly spending, Meta will have to offer a compelling product to get users to sign up for yet another subscription.

Snap has proven there is a market for social media subscriptions, as its Snapchat+ offering continues to be a revenue driver. Snapchat+, which starts at $3.99 per month for exclusive features, has topped 16 million subscribers, more than doubling since early 2024.

Meta says it plans to listen to its community of users and gather feedback as it starts rolling out the subscriptions in the coming months.

Aisha is a consumer news reporter at TechCrunch. Prior to joining the publication in 2021, she was a telecom reporter at MobileSyrup. Aisha holds an honours bachelor’s degree from University of Toronto and a master’s degree in journalism from Western University.

You can contact or verify outreach from Aisha by emailing aisha@techcrunch.com or via encrypted message at aisha_malik.01 on Signal.

Tickets are live at the lowest rates of the year. Save up to $680 on your pass — and if you’re among the first 500 registrants, score a +1 pass at 50% off.Meet investors. Discover your next portfolio company. Hear from 250+ tech leaders, dive into 200+ sessions, and explore 300+ startups building what’s next. Don’t miss these one-time savings.

TikTok users freak out over app’s ‘immigration status’ collection — here’s what it means

Researchers say Russian government hackers were behind attempted Poland power outage

Microsoft gave FBI a set of BitLocker encryption keys to unlock suspects’ laptops: Reports

Capital One acquires Brex for a steep discount to its peak valuation, but early believers are laughing all the way to the bank

Not to be outdone by OpenAI, Apple is reportedly developing an AI wearable

Lemonade launches an insurance product for Tesla Full Self-Driving customers

Anthropic’s CEO stuns Davos with Nvidia criticism</div>
        </div>
        
        <div class="card" onclick="openModal('content-17')">
            <div class="source">TechCrunch</div>
            <div class="title">Some international attendees are skipping 2026 GDC due to safety fears and growing ICE presence</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-17" style="display:none;">
            <h2>Some international attendees are skipping 2026 GDC due to safety fears and growing ICE presence</h2>
            <p><strong>TechCrunch | 2026-01-26</strong></p>
            <a class="original-link" href="https://techcrunch.com/2026/01/26/some-international-attendees-are-skipping-2026-gdc-due-to-safety-fears-and-growing-ice-presence/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The 2026 Game Developers Conference is shaping up to be a little less international this year if commentary on social media platforms like LinkedIn is an indicator.

Many members of the international games industry have announced they will skip the event, mainly over concerns about safety, tougher U.S. immigration rules, and a stronger immigration and Customs Enforcement presence. Developers, past GDC attendees, and other industry professionals have taken to platforms like LinkedIn to publicly voice their concerns.

ICE activity in numerous U.S. cities as well as the recent fatal shootings in Minneapolis involving ICE agents have compounded concerns. Renee Nicole Good was killed on January 7, and ICU nurse Alex Pretti lost his life on January 24. Many travelers also said they’re worried about unpredictable border checks and safety concerns.

As one person put it, “It’s not worth taking the risk of going.” Another chimed in: “The U.S. is just a very problematic location for an international event.”

GDC, now rebranded as the “GDC Festival of Gaming,” is scheduled to take place in San Francisco from March 9 to 13.

Others cited general concerns over safety as well as cost as factors in their decision not to attend. Some indie developers and small studios have said the costs, which include hotel, food, travel, and the ticket price, are just too high.

In response to these concerns, GDC president Nina Brown told Mobilegamer.biz, that the “safety of our community is always our top priority.” In a statement, Brown said the GDC works closely with “local officials and legal experts to monitor U.S. policy changes” and to provide the most up-to-date guidance. Brown also advised international attendees to start their visa applications early and consult with their embassies regarding any special requirements.

​Brown also outlined several safety measures, including that GDC offers a 24/7 safety hotline, safety training for event staff, and security escorts upon request. San Francisco’s Safety Community Ambassadors program will also be present, providing additional support to attendees throughout the event.

TechCrunch has also reached out to GDC for comment and will update this article if the organization responds.

On the cost front, GDC has introduced a simpler, more affordable ticketing system to make the event more accessible to smaller developers and indie studios. The new Festival Pass replaces the previous All-Access pass and is 45% cheaper, with pricing starting at $649 and providing access to all main event programming.

Lauren covers media, streaming, apps and platforms at TechCrunch.

You can contact or verify outreach from Lauren by emailing laurenf.techcrunch@gmail.com or via encrypted message at laurenforris22.25 on Signal.

Tickets are live at the lowest rates of the year. Save up to $680 on your pass — and if you’re among the first 500 registrants, score a +1 pass at 50% off.Meet investors. Discover your next portfolio company. Hear from 250+ tech leaders, dive into 200+ sessions, and explore 300+ startups building what’s next. Don’t miss these one-time savings.

TikTok users freak out over app’s ‘immigration status’ collection — here’s what it means

Researchers say Russian government hackers were behind attempted Poland power outage

Microsoft gave FBI a set of BitLocker encryption keys to unlock suspects’ laptops: Reports

Capital One acquires Brex for a steep discount to its peak valuation, but early believers are laughing all the way to the bank

Not to be outdone by OpenAI, Apple is reportedly developing an AI wearable

Lemonade launches an insurance product for Tesla Full Self-Driving customers

Anthropic’s CEO stuns Davos with Nvidia criticism</div>
        </div>
        
        <div class="card" onclick="openModal('content-18')">
            <div class="source">The Atlantic</div>
            <div class="title">Minnesota Proved MAGA Wrong</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-18" style="display:none;">
            <h2>Minnesota Proved MAGA Wrong</h2>
            <p><strong>The Atlantic | 2026-01-27</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/ideas/2026/01/the-neighbors-defending-minnesota-from-ice/685769/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">It took only a few minutes before everyone in the church knew that another person had been shot. I was sitting with Trygve Olsen, a big man in a wool hat and puffy vest, who lifted his phone to show me a text with the news. It was his 50th birthday, and one of the coldest days of the year. I asked him whether he was doing anything special to celebrate. “What should I be doing?” he replied. “Should I sit at home and open presents? This is where I’m supposed to be.”

He had come to Iglesia Cristiana La Viña Burnsville, about 15 miles south of the Twin Cities, to pick up food for families who are too afraid to go out—some have barely left home since federal immigration agents deployed to Minnesota two months ago. The church was filled with pallets of frozen meat and vegetables, diapers, fruit, and toilet paper. Outside, a man wearing a leather biker vest bearing the insignia of the Latin American Motorcycle Association, his blond beard flecked with ice crystals, directed a line of cars through the snow.

The man who had been shot—fatally, we later learned—was Alex Pretti, an ICU nurse who had been recording agents outside a donut shop. Officials at the Department of Homeland Security claimed that he had threatened agents with a gun; videos of the shooting show him holding only his phone when he is pushed down by masked federal agents and beaten, his licensed sidearm removed from its holster by one agent before another unloads several shots into his back. Pretti’s death was a reminder—if anyone in Minnesota still needed one—that people had reason to be hiding, and that those trying to help them, protect them, or protest on their behalf had reason to be scared.

The church has a mostly Hispanic and working-class flock. Its pastor, Miguel Aviles, who goes by Pastor Miguel, told me that it had sent out about 2,000 packages of food since the federal agents had arrived. Many of the people in hiding, he said, “have asylum cases pending. They already have work permits and stuff, but some of them are legal residents and still they’re afraid to go out. Because of their skin color, they are afraid to go out.”

Federal agents have arrested about 3,000 people in the state, but they have released the names of only about 240 of those detained, leaving unclear how many of the larger number have committed any crimes. Many more thousands of people have been affected by the arrests and the fear they have instilled. Minneapolis Public Radio estimates that in school districts “with widespread federal activity, as many as 20 to 40 percent of students have been absent in recent weeks.”

I don’t know what the feds expected when they surged into Minnesota. In late November, The New York Times reported on a public-benefit fraud scheme in the state that was executed mainly by people of Somali descent. Federal prosecutors under the Biden administration had already indicted dozens of people, but after the Times story broke, President Trump began ranting about Somalis, whom he referred to as “garbage”; declared that he didn’t want Somali immigrants in the country; and announced that he was sending thousands of armed federal immigration agents to Minneapolis. This weekend, he posted on social media that the agents were there because of “massive monetary fraud.” The real reason may be that a majority of Minnesotans did not vote for him. Trump has said that “I won Minnesota three times, and I didn’t get credit for it. That’s a crooked state.” He has never won Minnesota.

Perhaps the Trump-administration officials had hoped that a few rabble-rousers would get violent, justifying the kind of crackdown he seems to fantasize about. Maybe they had assumed that they would find only a caricature of “the resistance”—people who seethed about Trump online but would be unwilling to do anything to defend themselves against him.

Instead, what they discovered in the frozen North was something different: a real resistance, broad and organized and overwhelmingly nonviolent, the kind of movement that emerges only under sustained attacks by an oppressive state. Tens of thousands of volunteers—at the very least—are risking their safety to defend their neighbors and their freedom. They aren’t looking for attention or likes on social media. Unless they are killed by federal agents, as Pretti and Renee Good were, other activists do not even necessarily know their names. Many use a handle or code name out of fear of government retaliation. Their concerns are justified: A number of people working as volunteers or observers told me that they had been trailed home by ICE agents, and some of their communications have already been infiltrated, screenshotted, and posted online, forcing them to use new text chains and code names. One urgent question among observers, as the videos of Pretti’s killing spread, was what his handle might have been.

Olsen had originally used the handle “Redbear” in communicating with me, but later said I could name him. He had agreed to let me ride along while he did his deliveries. As he loaded up his truck with supplies, he wore just a long-sleeved red shirt and vest, apparently unfazed by the Minnesota cold.

“This is my first occupation,” Olsen said as I climbed into the truck. “Welcome to the underground, I guess.”

The number of Minnesotans resisting the federal occupation is so large that relatively few could be characterized as career activists. They are ordinary Americans—people with jobs, moms and dads, friends and neighbors. They can be divided into roughly three groups.

The largest is the protesters, who show up at events such as Friday’s march in downtown Minneapolis, and at the airport, where deportation flights take off. Many protesters have faced tear gas and pepper spray, and below-zero temperatures—during the Twin Cities march on Friday, I couldn’t take notes; the ink in my pens had frozen.

Then there are the people who load up their car with food, toiletries, and school supplies from churches or schools to take to families in hiding. They also help families who cannot work meet their rent or mortgage payments. In addition to driving around with Olsen, I rode along with a Twin Cities mom of young kids named Amanda as she did deliveries (she asked me to use only her first name). Riding in her small car—her back row was taken up by three child seats and a smattering of stray toys—she told me that she’d gotten involved after more than 100 students at her kids’ elementary school simply stopped coming in. Parents got organized to provide the families with food, to shepherd their kids to school, and to arrange playdates for those stuck inside.

Amanda’s father and husband are immigrants, she said, and she speaks Spanish. “I can be a conduit between those who want to help and those who need help,” she told me. She calls each family before knocking on the door, so they don’t have to worry that they are being tricked by ICE. At one home, a woman asked us to go around back because a suspicious vehicle was idling out front. At another home, a little girl in pigtails beamed as Amanda handed her a Target bag full of school supplies.

Finally, there’s those most at risk of coming into violent contact with federal agents, a group that’s come to be popularly known as ICE Watch, although the designation is unofficial—as far as I can tell, you’re in ICE Watch if you watch ICE. These are the whistle-wielding pedestrians and drivers calling themselves “observers” or “commuters” who patrol for federal agents (usually identifiable by their SUVs with out-of-state plates) and alert the neighborhood to their presence. Pretti and Good, the two Minneapolis residents killed by federal agents, fit in this category.

Trump-administration officials and MAGA influencers have repeatedly called these activists “violent” and said they are involved in “riots.” But the resistance in Minnesota is largely characterized by a conscious, strategic absence of physical confrontation. Activists have made the decision to emphasize protection, aid, and observation. When matters escalate, it is usually the choice of the federal agents. Of the three homicides in Minneapolis this year, two were committed by federal agents.

“There’s been an incredible, incredible response from the community. I’ve seen our neighbors go straight from allies to family—more than family—checking in on each other, offering food and rides for kids and all kinds of support, alerting each other if there’s ICE or any kind of danger,” Malika Dahir, a local activist of Somali descent, told me.

If the Minnesota resistance has an overarching ideology, you could call it “neighborism”—a commitment to protecting the people around you, no matter who they are or where they came from. The contrast with the philosophy guiding the Trump administration couldn’t be more extreme. Vice President Vance has said that “it is totally reasonable and acceptable for American citizens to look at their next-door neighbors and say, ‘I want to live next to people who I have something in common with. I don’t want to live next to four families of strangers.’” Minnesotans are insisting that their neighbors are their neighbors whether they were born in Minneapolis or Mogadishu. That is, arguably, a deeply Christian philosophy, one apparently loathed by some of the most powerful Christians in America.

On Wednesday, I met with two volunteers who went by the handles “Green Bean” and “Cobalt.” They picked me up in the parking lot of a Target, not far from where Good was killed two weeks earlier. Cobalt works in tech but has recently been spending more time on patrol than at her day job. Green Bean is a biologist, but she told me the grant that had been funding her work hadn’t been renewed under the Trump administration. Neither of them had imagined doing what they were doing now. “I’m supposed to be creeping around in the woods looking at insects,” Green Bean said.

Most commuters work in pairs—a co-pilot listens in on a dispatcher who provides the locations of ICE encounters and can run plates through a database of cars that federal agents have used in the past. Green Bean explained what happens when they identify an ICE vehicle. (Both ICE and Border Patrol are in Minneapolis, but everyone just calls them ICE.) The commuters will follow the agents, honking loudly, until they leave the neighborhood or stop and get out.

The commuters—as my colleague Robert Worth reported—do not have a centralized leadership but have been trained by local activist groups that have experience from past protests against police killings, and recent immigration-enforcement sweeps in L.A. and Chicago. The observers are taught to conscientiously follow the law, including traffic rules, and to try to avoid physical confrontation with federal agents.

If the agents detain someone, the observers will try to get that person’s name so they can inform the family. But ICE prefers to make arrests—which the ICE Watchers call “abductions”—quietly. More often than not, Green Bean said, when these volunteers draw attention, the agents will “leave rather than dig in.” She added, “They are huge pussies, I will be honest.”

As we cruised through the Powderhorn neighborhood, practically every business had an ICE OUT sign in the window. Graffiti trashing ICE was everywhere, as were posters of Good labeled AMERICAN MOM KILLED BY ICE. Listening to the dispatcher, Cobalt relayed directions to Green Bean about the locations of ICE vehicles, commuters who had been boxed in or threatened by agents, and possible “abductions.”

About 30 minutes into the patrol, Green Bean saw a white Jeep Wagoneer with out-of-state plates and read out the numbers. “Confirmed ICE,” Cobalt said, and we began following the Wagoneer as it drove through the neighborhood. Another car of commuters joined us, making as much noise as possible.

After about 10 minutes, the Wagoneer got onto the highway. Green Bean followed until we could be sure that it wasn’t doubling back to the neighborhood, and then we turned around.

Most encounters with ICE end like that. But sometimes situations deteriorate—as with Good, who was killed while doing a version of what Green Bean and Cobalt were now doing. The task is stressful for the observers, who understand that even minor encounters can turn deadly.

The next day, I drove around with another pair of commuters who went by “Judy” and “Lime.” Both told me they were anti-Zionist Jews who had been involved in pro-Palestinian and Black Lives Matter protests. Lime’s day job is with an abortion-rights organization, and Judy is a rabbi. “I did protective presence in the West Bank,” Lime told me, referring to a form of protest in which activists try to deter settler violence by simply being present in Palestinian communities. “This is very similar.”

About an hour into our drive, we came across an ICE truck. Judy started blaring the horn, and I heard her mutter to herself: “We’re just driving, we’re just driving, which is legal. I hate this.” I asked them both if they were scared. “I do not feel scared, but I probably should,” Lime said.

Judy said she had been out on patrol days after Good was killed, and had gotten boxed in and yelled at by federal agents. “It was very scary,” Judy told me. “Murdering someone definitely works as an intimidation tactic. You just have no idea what is going to happen.” She said that ICE agents had taken a picture of her license plate and then later showed up at her house, leaning out of their car to take another picture—making it clear to Judy that they knew who she was.

Green Bean had told me the same thing—that agents had come to her house, followed her when she left, and then blocked her vehicle and screamed at her to “stop fucking following us. This is your last warning.” Green Bean was able to laugh while retelling this. “I just stared at them until they left,” she said.

We drove past Good’s memorial. Tributes to her—flowers and letters—were still there, covered in a light powder of snow. We didn’t yet know at the time that residents would soon set up another memorial, for Pretti.

The broad nature of the civil resistance in Minnesota should not lead anyone to believe that no one there supports what ICE is doing. Plenty of people do. Trump came close to winning the state in 2024, and many people here, especially outside the Twin Cities, believe the administration’s rhetoric about targeting “the worst of the worst,” despite what the actual statistics reveal.

“You don’t have to go too far south” to find places where Minnesotans “welcome ICE into their restaurants and bars and sort of love what they do,” Tom Jenkins, the lead pastor of Mount Cavalry Lutheran Church in suburban Eagan, which is also helping with food drives, told me. “A lot of people are still cheering ICE on because they don’t think that whatever people are telling them or showing them is real.”

Although most of the coverage has understandably focused on the cities, suburban residents told me that they had seen operations all over the state. “There are mobile homes not far from where I live,” Jenkins said. Agents “were there every day, you know: 10, 15, 20 agents working the bus stops and bus drop-offs.” He added: “They’re all over.”

Even among those involved in opposing ICE in Minnesota, people have a range of political views. The nonviolent nature of the movement, and the focus on caring for neighbors, has drawn in volunteers with many different perspectives on immigration, including people who might have been supportive if the Trump administration’s claims of a targeted effort to deport violent criminals had been sincere.

“One of the things that I believe, and I know most of the Latino community agrees, is that we want the bad people out. We want the criminals out,” Pastor Miguel, who immigrated from Mexico 30 years ago, told me. “All of us came here looking for a better life for us and for our children. So when we have criminals, rapists—when we have people who have done horrible things in our streets, in our communities—we are afraid of them. We don’t want them here.”

The problem is that federal agents are not going after just criminals. Growing distraught, Pastor Miguel said that one of the men who helped organize the food drive, a close friend of his who he believed had legal status, had been picked up by federal agents the day before I visited.

“I just—I didn’t have words,” he said. “And yet I cannot crumble; I cannot fall. Because all these families also need us.”

Two days after Pretti was killed, my colleague Nick Miroff broke the news that Gregory Bovino, the Border Patrol official who had led the operation in Minneapolis, would be leaving the city and replaced by Trump’s border czar, Tom Homan. Bovino, strutting around in body armor or his distinctive long coat, seemed to relish his role as a villain to his critics, encouraging aggressive tactics by federal agents and sometimes engaging in them himself. The day I accompanied Green Bean and Cobalt, Bovino fumbled with a gas canister before throwing it into a sparse crowd of protesters.

Bovino’s departure seemed an admission that Minnesotans aren’t the only Americans who won’t tolerate more deaths at the hands of federal agents. The people of Minnesota have forced the Trump administration into a strategic retreat—one inflicted not as rioters or insurgents, but as neighbors.

After Friday’s protest, when thousands marched in frigid downtown Minneapolis, chanting, “No Trump, no troops, Twin Cities ain’t licking boots!” I spoke with a young protester named Ethan McFarland, who told me that his parents are immigrants from Uganda. He had recently asked his mother to show him her immigration papers, in case she got picked up. This kind of state oppression, he said, is exactly what his mother was “trying to get away from” when she came to the United States.

McFarland’s remarks reminded me of something Stephen Miller, the Trump adviser, had written: “Migrants and their descendants recreate the conditions, and terrors, of their broken homelands.” In Minnesota, the opposite was happening. The “conditions and terrors” of immigrants’ “broken homelands” weren’t being re-created by immigrants. They were being re-created by people like Miller. The immigrants simply have the experience to recognize them.

The federal surge into Minneapolis reflects a series of mistaken MAGA assumptions. The first is the belief that diverse communities aren’t possible: “Social bonds form among people who have something in common,” Vance said in a speech last July. “If you stop importing millions of foreigners into the country, you allow social cohesion to form naturally.” Vance’s remarks are the antithesis to the neighborism of the Twin Cities, whose people do not share the narcissism of being capable of loving only those who are exactly like them.

A second MAGA assumption is that the left is insincere in its values, and that principles of inclusion and unity are superficial forms of virtue signaling. White liberals might put a sign in their front yard saying IMMIGRANTS WELCOME, but they will abandon those immigrants at the first sensation of sustained pressure.

And in Trump’s defense, this has turned out to be true of many liberals in positions of power—university administrators, attorneys at white-shoe law firms, political leaders. But it is not true of millions of ordinary Americans, who have poured into the streets in protest, spoken out against the administration, and, in Minnesota, resisted armed men in masks at the cost of their own life.

The MAGA faith in liberal weakness has been paired with the conviction that real men—Trump’s men—are conversely strong. Consider Miller’s bizarre meltdown while addressing Memphis police in October. “The gangbangers that you deal with—they think that they’re ruthless? They have no idea how ruthless we are. They think they’re tough? They have no idea how tough we are,” Miller said. “They think they’re hard-core? We are so much more hard-core than they are.” Around this time, Miller moved his family onto a military base—for safety reasons.

The federal agents sent to Minnesota wear body armor and masks, and bear long guns and sidearms. But their skittishness and brutality are qualities associated with fear, not resolve. It takes far more courage to stare down the barrel of a gun while you’re armed with only a whistle and a phone than it does to point a gun at an unarmed protester.

Every social theory undergirding Trumpism has been broken on the steel of Minnesotan resolve. The multiracial community in Minneapolis was supposed to shatter. It did not. It held until Bovino was forced out of the Twin Cities with his long coat between his legs.

The secret fear of the morally depraved is that virtue is actually common, and that they’re the ones who are alone. In Minnesota, all of the ideological cornerstones of MAGA have been proved false at once. Minnesotans, not the armed thugs of ICE and the Border Patrol, are brave. Minnesotans have shown that their community is socially cohesive—because of its diversity and not in spite of it. Minnesotans have found and loved one another in a world atomized by social media, where empty men have tried to fill their lonely soul with lies about their own inherent superiority. Minnesotans have preserved everything worthwhile about “Western civilization,” while armed brutes try to tear it down by force.

No matter how many more armed men Trump sends to impose his will on the people of Minnesota, all he can do is accentuate their valor. No application of armed violence can make the men with guns as heroic as the people who choose to stand in their path with empty hands in defense of their neighbors. These agents, and the president who sent them, are no one’s heroes, no one’s saviors—just men with guns who have to hide their faces to shoot a mom in the face, and a nurse in the back.</div>
        </div>
        
        <div class="card" onclick="openModal('content-19')">
            <div class="source">The Atlantic</div>
            <div class="title">Greg Bovino Loses His Job</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-19" style="display:none;">
            <h2>Greg Bovino Loses His Job</h2>
            <p><strong>The Atlantic | 2026-01-26</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/politics/2026/01/greg-bovino-demoted-minneapolis-border-patrol/685770/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Gregory Bovino has been removed from his role as Border Patrol “commander at large” and will return to his former job in El Centro, California, where he is expected to retire soon, according to a DHS official and two people with knowledge of the change.

Bovino’s sudden demotion is the clearest sign yet that the Trump administration is reconsidering its most aggressive tactics after the killing Saturday of 37-year-old Alex Pretti by Border Patrol agents under Bovino’s command.

Earlier today, President Trump appeared to signal in a series of social-media posts a tactical shift in the administration’s mass-deportation campaign. Trump wrote that he spoke with Minnesota Governor Tim Walz—whom the White House has blamed for inciting violence—and the two men are now on “a similar wavelength.” Tom Homan, the former ICE chief whom Trump has designated “border czar,” will head to Minnesota to assume command of the federal mobilization there, Trump said.

Homeland Security Secretary Kristi Noem and her close adviser Corey Lewandowski, who were Bovino’s biggest backers at DHS, are also at risk of losing their jobs, two of the people told me.

Read: The hype man of Trump’s mass deportations

For the past seven months, Bovino has been the public face of a traveling immigration crackdown on cities governed by Democrats. Noem and other Trump officials gave Bovino the “commander” title and sent him and his masked border agents to Chicago, Charlotte, New Orleans, and then Minneapolis. Bovino became a MAGA social-media star as he traveled the country with his own film crew and used social media to hit back at Democratic politicians and random critics online. Veteran ICE and CBP officials grew more and more uneasy as Bovino worked outside his agency’s chain of command and appeared to relish his role as a political actor.

In Minneapolis, the Trump administration used Bovino as its lead spokesperson, scheduling daily press conferences where he defended agents’ rough tactics and cast blame on protesters and local officials. Border Patrol commanders typically avoid engaging in political arguments with elected officials.

Bovino’s fall comes two days after Border Patrol agents in Minneapolis fatally shot Pretti, an intensive-care nurse who worked with veterans. Hours after the shooting, Bovino appeared at a press conference and echoed statements by the Department of Homeland Security alleging Pretti sought to “massacre” the federal agents. Bovino repeatedly claimed that Border Patrol agents, not Pretti, were the victims.

Videos of the encounter showed no evidence for his claims. Pretti, who was licensed to carry a concealed weapon, did not draw a firearm or attack the agents. The videos show one agent disarming Pretti in the moments just before another agent shot him in the back.

DHS and U.S. Customs and Border Protection officials did not immediately respond to questions about Bovino’s departure from Minnesota and his current role. Asked about Bovino and Noem, a White House spokesperson referred to Press Secretary Karoline Leavitt’s statement today that Noem has the president’s “utmost confidence and trust.”

In another post, Trump said he also spoke with Minneapolis Mayor Jacob Frey. “Lots of progress is being made!” the president wrote. “Tom Homan will be meeting with him tomorrow in order to continue the discussion.”</div>
        </div>
        
        <div class="card" onclick="openModal('content-20')">
            <div class="source">The Atlantic</div>
            <div class="title">What the Administration Is Signaling to Federal Agents After Minnesota</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-20" style="display:none;">
            <h2>What the Administration Is Signaling to Federal Agents After Minnesota</h2>
            <p><strong>The Atlantic | 2026-01-26</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/newsletters/2026/01/trump-minnesota-shootings-ice-border-patrol/685771/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">This is an edition of The Atlantic Daily, a newsletter that guides you through the biggest stories of the day, helps you discover new ideas, and recommends the best in culture. Sign up for it here.

Perhaps the most disturbing part of the Trump administration’s immigration operation in Minnesota is not just that agents of the state are killing peacefully protesting citizens on the streets. It’s that they’re doing it with the expectation of impunity, backed by top government officials who are brazenly lying about what happened.

The response from President Trump, Homeland Security Secretary Kristi Noem, and other officials has sent a clear message: When immigration agents kill peaceful protesters, the government will defend them unconditionally, no matter if clear video evidence contradicts its version of events. It will resist investigating shootings, and it will do everything it can to block probes by other authorities. Vice President Vance has even claimed that federal agents have “absolute immunity” for their actions. This approach all but guarantees more killings.

The culture of impunity runs from the bottom to the top. It includes the federal agents who shot Alex Pretti, a 37-year-old ICU nurse, multiple times in Minneapolis on Saturday morning, despite videos that appear to show that the agents had already removed his holstered gun, and despite knowing that many bystanders were filming. (If this is what Border Patrol feels comfortable doing on camera, one can only guess how they might act in private.) It also encompasses the administration officials who offered false accounts immediately, without bothering to wait for the facts.

Videos show Pretti filming officers before being pepper-sprayed and tackled by multiple officers, who then shot him while he was on the ground. Yet the Homeland Security secretary accused Pretti of “domestic terrorism” and said that he’d “attacked” agents, a claim that FBI Director Kash Patel repeated. Noem also said that Pretti had been “brandishing” a gun. (He had been legally carrying a concealed weapon, a right that the administration has previously celebrated.) Deputy Attorney General Todd Blanche argued that because Pretti was shouting and had “a phone right up to ICE’s face,” he was not protesting peacefully. The Trump aide Stephen Miller labeled him an “assassin,” and the Border Patrol commander Greg Bovino said that Pretti “wanted to do maximum damage and massacre law enforcement.” No known evidence backs any of this up, and videos show that much of it is provably false.

When law-enforcement officers shoot civilians, it is common—if unsavory—for government officials to defend them. The Trump administration has gone far beyond this. Fatal shootings are almost always subject to investigation. After an ICE agent killed Renee Good earlier this month, Blanche (who once was Trump’s personal lawyer) said that the FBI would not launch a civil-rights investigation into the shooting. Instead, MS NOW reported, the Justice Department instructed the FBI to seek a search warrant to investigate Good for possible criminal liability. A federal magistrate rejected the warrant, which is unusual—except that, as the magistrate noted, Good is dead and could not legally be considered a suspect. An FBI agent resigned after she was allegedly pressured to stop pursuing a civil-rights inquiry into the ICE officer, Jonathan Ross, who’d shot Good.

Something similar started to play out immediately after Pretti’s death. Federal agencies seem unsure what, if any, investigation is occurring, according to The Washington Post, although White House Press Secretary Karoline Leavitt said today that DHS and CBP are investigating the Pretti shooting, including reviewing body-cam footage. Federal agents refused to give even “the most basic information” to Minneapolis police at the scene, Chief Brian O’Hara said yesterday, and they initially blocked the Minnesota Bureau of Criminal Apprehension, the state’s criminal-investigation office, from accessing the crime scene. The state then went to court and obtained an order from a (Trump-appointed) federal judge blocking the destruction of evidence. That such a move was even necessary is astonishing.

A state-level agency like the BCA has nowhere near the resources or expertise that federal agencies do, and local investigators face legal hurdles when investigating federal agents. Yet administration officials have so clearly declared their position with lies and prejudicial statements that any federal investigation would be suspect from the start—another example of how Trump’s politicization of the Justice Department has undermined its ability to do its job.

Compared with the aftermath of Good’s shooting, more Republicans are expressing concerns about the operation in Minneapolis and Pretti’s killing. Even Trump has vacillated somewhat. He blamed Democrats for Pretti’s death but was noncommittal in a conversation with The Wall Street Journal about whether the agents involved had acted appropriately, in contrast to his quick blaming of Good for her own death. He has since conceded that ICE agents may have made a “mistake” in her case. Vance has also backtracked some, abandoning his claims of “absolute immunity.” (Law-enforcement officers are entitled to what’s known as “qualified immunity,” or protection from liability unless breaking clear legal or constitutional boundaries.)

Even as Republicans grow wary, they have tried to blame Trump’s aides rather than the president himself; Oklahoma Governor Kevin Stitt, for example, lamented that the president was “getting bad advice.” But the culture of impunity proceeds directly from Trump. He has enthusiastically embraced the idea that the federal government should serve his personal whims. He argued that investigations into himself, even for overt offenses such as taking home boxes of sensitive documents, were improper. And he has made clear that when people act to assist him, whether they are aides or January 6 rioters, he will use his clemency powers to protect them from consequences.

Trump has spent years dehumanizing immigrants, exhorting law enforcement to treat suspects more roughly, and attacking the rule of law. The killings in Minnesota aren’t the collateral damage of Trump’s approach to governance. They’re a direct result.

Here are three new stories from The Atlantic:

Anyone who thinks the contemplative life amounts to a form of quietism or a retreat from the world’s suffering should spend some time shadowing Joan Halifax, the Zen priest and anthropologist. I’d been curious about Halifax for years, ever since I heard about an annual trek that she leads through the mountains of Nepal, bringing a cadre of doctors and dentists to remote mountain villages with little access to health care.

Each summer over the course of two weeks or so, this Nomads Clinic covers more than 100 miles on foot and horseback, at altitudes of nearly 18,000 feet. These “medical mountaineers,” as they’ve been called, all volunteers, sleep in tents, often in freezing temperatures. But after some 40 annual trips to Nepal—Halifax is normally based in Santa Fe—she recently decided it was time to hang it up.

Watch. Last Saturday’s “Weekend Update” segment (streaming on Peacock) explains how Saturday Night Live benefits from making pop culture a little bit cringe, Michael Tedder writes.

Read. Before her murder made her a true-crime obsession, Elizabeth Short was a real person. Black Dahlia tries to separate truth from myth in the infamous case, Sarah Weinman writes.

Last Wednesday, covering President Trump’s speech at the World Economic Forum, I remarked, “Perhaps the Germans have a word for the experience of watching your country’s leader embarrass himself and the country on the global stage.” Several Germanophone readers wrote in to tell me that, in fact, they do—or at least one that partly captures the feeling. Fremdscham is a term for vicarious embarrassment, a sort of inverse of schadenfreude. I’m going to have to add this one to my vocabulary. Now, if we can only find a way to shoehorn presidential presence into it!

Rafaela Jinich contributed to this newsletter.

When you buy a book using a link in this newsletter, we receive a commission. Thank you for supporting The Atlantic.</div>
        </div>
        
        <div class="card" onclick="openModal('content-21')">
            <div class="source">The Atlantic</div>
            <div class="title">ICE Is Failing the Legitimacy Test</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-21" style="display:none;">
            <h2>ICE Is Failing the Legitimacy Test</h2>
            <p><strong>The Atlantic | 2026-01-26</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/ideas/2026/01/policing-open-carry-minnesota-pretti/685767/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Carrying a concealed handgun in public is now commonplace in much of the country. For many, this is not only a prudent act of personal safety, but an expression of liberty and a bulwark against government overreach. At the same time, America&#39;s law-enforcement officers insist they must exercise vigilance while patrolling dangerous streets. When officers make a split-second decision to shoot someone who is carrying a gun, many political leaders, especially on the right, believe they need to be given deference because their lives were at risk.

The tension between these two ideas is acute, putting law enforcement and citizens on a potentially catastrophic collision course. One such collision took place in Minnesota on Saturday. It was fatal for the citizen. And it was potentially delegitimizing for law enforcement. A broader crisis of government legitimacy is imminent in the absence of a change in direction by the Trump administration.

Judging from the video evidence and news reports, this is what seems to have taken place: The Minneapolis nurse Alex Pretti carried his loaded, concealed 9-mm handgun to a protest against the ICE agents.  He had no criminal record, and a permit to carry the gun. Holding only a phone when an agent moved in to make an arrest, he was pepper-sprayed and thrown to the ground. Then, as federal agents wrestled him into submission, Pretti’s coat rode up and his holstered gun came into view. It set off panicked screams of “Gun!” among the agents. One of them reached in and removed the pistol from Pretti’s waistband; another then drew his own pistol and shot Pretti in the back. Pretti died in the street never having touched his gun. He had been disarmed before the first shot was even fired.

In response to this tragedy, the president of the United States wrote on social media: “LET OUR ICE PATRIOTS DO THEIR JOB!”

But surely doing their job well must include respecting the people they serve. For true Second Amendment advocates, Pretti’s decision to bring a gun to a protest in no way excuses his killing. A protester with a gun, they believe, is not courting his own demise. To these advocates, under the Second Amendment, there is no wrong time and place for a citizen to be armed; it is a right that “shall not be infringed.” Some states prohibit guns at protests, but Minnesota is not one of them. As of 2025, more than 20 million Americans held a concealed carry permit. And 29 states have adopted Constitutional Carry, meaning a permit is not required.

Robert F. Worth: Welcome to the American winter

None of this is to say that policing an armed society is easy. It requires highly trained, well-led officers who can navigate incidents including routine calls and crimes in progress with discipline and restraint. It also requires a commitment to transparency—and to accountability, when police wrongly shoot a person exercising their right to carry a gun. In this regard, ICE and the federal government have failed dismally.

ICE agents are poorly screened and quickly hired. They spend just 47 days in their training academy, a shorter duration than nearly all law enforcement organizations; Minnesota, for example, requires about double the training for its police officers at 1,050 hours. In the field, they are saddled with quotas for how many people they must apprehend. That leads to desperate measures and poor decisions. Many of these agents wear masks to conceal their identity and project an air of menace. They regularly flout their own body-camera policy, which their agency is seeking to roll back. They have been instructed to use force to enter homes without the judicial warrant the Constitution requires. They perform poorly at crowd control, resorting to tear gas and pepper spray with an alarming frequency.

Compounding these problems, the federal government has vilified the men and women shot by ICE agents, including U.S. citizens; refused to conduct transparent investigations; and contemptuously blocked state agencies from doing so. Federal officials have declared ICE’s killings lawful and justified over social media without any pretense of a formal review, making statements that are cruel, derogatory, misleading, or simply false. People who want the government to account for what it has done are told to go pound sand.

A particularly vivid example of this dynamic occurred three weeks ago, when an ICE agent, also in Minneapolis, killed Renee Good as she tried to drive away from him. The agency argued that a car on the move is a lethal threat, so an officer who steps in front of a car can shoot a driver who doesn’t stop. The New York City Police Department prohibited shooting at moving vehicles in 1972, and most major cities tightly regulate the practice. Professional police agencies have learned that shooting the driver doesn’t stop the car or make the officer any safer; the best bet is to get out of the way. Rather than explain this contradiction, ICE dismissed criticism, immediately declared Good’s killing necessary and lawful, labeled her a domestic terrorist and the officer a hero, and shut down efforts to investigate the incident. Then the Department of Justice ordered federal prosecutors and the FBI to investigate Good’s family for ties to left-wing radicals, leading several prosecutors to resign. This is not the behavior of government officials who can plausibly argue that they have a legitimate right to use force against citizens.

Contrary to the administration’s feverish claims, the protesters in Minneapolis are not “woke” leftist domestic terrorists confronting responsible law-enforcement officers to foment an insurrection. As best we can tell, among the cast of activists are citizens of every class, ideology, and race, standing up for basic decency and constitutional liberties. One of our mothers-in-law regularly demonstrates against ICE, and she hasn’t protested anything since the Vietnam War. In the face of the dangers posed by armed, masked men who have been reassured by the president that they will receive immunity for their actions—both legally incorrect and a bad idea—these citizens are putting themselves on the line to say that what is happening is inconsistent with America’s most fundamental values.

There is a lot of overlap between the elected officials who exhort Americans to carry guns wherever they like, and the ones who tend to stand by law-enforcement officers who use lethal force. These positions are not always contradictory, but in this situation they are flatly incompatible. If elected officials are going to stump for the Second Amendment, and at the same time refuse to hold a federal agency accountable for killing an American exercising that very right, the country is at risk of losing any right to protest. And the federal government is calling into question its legitimacy.</div>
        </div>
        
        <div class="card" onclick="openModal('content-22')">
            <div class="source">The Atlantic</div>
            <div class="title">The Worst Thing About the Black Dahlia Case</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-22" style="display:none;">
            <h2>The Worst Thing About the Black Dahlia Case</h2>
            <p><strong>The Atlantic | 2026-01-26</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/books/2026/01/woman-who-became-black-dahlia/685739/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Elizabeth Short liked to wander. Sometimes this wandering was merely in her mind, watching movies and dreaming of a life far beyond her hometown of Medford, Massachusetts. Many times, it was physical; she’d land in a new city—Miami, Jacksonville, Chicago, Long Beach, San Diego, Los Angeles—and explore its streets on foot. Sometimes her travels revolved around family, as when she tracked down her long-lost father and lived with him for a time—until he cast her out. On January 9, 1947, Short, who was 22, told a gentleman friend to drop her off at the Biltmore Hotel in downtown Los Angeles, where her sister was supposedly waiting. She was never seen alive again.

A contemporary version of Elizabeth—dreamy, elusive, independent, and canny—might be called a flaneuse, someone curious about the world. But we’ll never know what kind of life she would have led; by the time her bisected body was found in a vacant lot, six days after she left the Biltmore, Elizabeth had ceased to be a person. From then on, she became “The Black Dahlia,” an archetype, a myth, a riddle that countless people have attempted to solve in books, films, television shows, podcasts, websites, internet-message boards, and social-media posts.

“After we are dead, the pretense that we may be protected against the world’s careless malice is abandoned,” Janet Malcolm wrote in her book The Silent Woman. She was referring to the poet and novelist Sylvia Plath, another beautiful young woman who died too soon, after which her life and words became grist for the biographical mill. But Malcolm’s words apply equally, even eerily, to the afterlife of Short—one of America’s most famous murder victims, and certainly among the most persistent subjects of the true-crime industrial complex.

From the moment Short’s killing became headline news, sensation was the prime directive. With every new lead, confession, and suspect, the actual Elizabeth receded further. It didn’t help that she was an enigmatic character in life, prone to embellishment and even lies. She recounted tales of woe to paramours only to ask them for money, exaggerated her prospects in missives to her mother, told friends about a dead husband and a child who probably didn’t exist—all without letting on about her actual precarious straits. Short avoided the spotlight, but over the nearly 80 years since her death, it has wholly consumed her.

This kind of flattening happens all too often with murder victims, particularly young women and girls who die at the hands of a serial killer, usually male. (Never mind that more marginalized women, especially women of color, are less likely to merit any attention at all.) In Short’s case, the flattening is particularly egregious, because the inchoate facts of her life are shoehorned into the obsessions of amateur sleuths who continue to get those facts wrong.

Read: A provocative argument about what creates serial killers

William J. Mann’s new book, Black Dahlia: Murder, Monsters, and Madness in Midcentury Hollywood, attempts a different approach: to weave the fragments we have into a narrative whole that prioritizes Short, in all of her contradictions, and tries to debunk decades’ worth of accumulated myths. Although Mann’s effort stands apart from the overlong run of books about the case, it, too, is undercut by the need to name a likely suspect, playing into the true-crime imperative it aims to leave behind.

Mann begins Black Dahlia in late July 1946, several months before Short’s murder and not long after her arrival in Long Beach, California. Over the ensuing period, Short befriends women and dates men; wears sophisticated clothing, ankle-strapped high heels, and flowers in her hair; and comes across as “a very modest girl who never cursed or acted sexy,” in the words of one friend. The reader comes to understand why fascination has proved more appealing than facts: We know very little about her life. Short defied norms and customs. She seemed innocent in the ways of men but savvy enough to keep her dates at a respectful distance. The two women who knew her best during this time, Marjorie Graham and Anne Toth, whom Mann renders more fully than any author before him, still had trouble understanding what made Short tick.

Mann starts the story, however, from the vantage point of Tod Faulkner, who says he first spotted Short in a two-piece bathing suit, walking alone toward the beach, and saw her again several more times that summer. Faulkner was 11 at the time, and says he never forgot her. Yet after growing up to become a journalist, he was the one who immortalized the erroneous middle name “Ann,” in a 1971 article for the Los Angeles Times. Faulkner’s error would propagate in numerous articles, books, and films before being codified in the 1975 TV movie Who Is the Black Dahlia?, which starred Lucie Arnaz (the daughter of Lucille Ball and Desi Arnaz) as Short. Already we have the conflict between truth and myth, and we’re only on page four.

From there, Mann situates the known facts about the last few months of Short’s life in postwar Los Angeles, whose rising murder rate led to an even sharper spike in fear. From 1945 to 1946, “while the homicide rate for men grew by 26.8 percent, the number of women murdered in that same period shot up by 52.9 percent,” Mann points out. Over the next few years, the increase in violent deaths of women, seemingly at the hands of strangers, was reflected in the growing genre of film noir and in novels including Dorothy B. Hughes’s In a Lonely Place, which was published less than a year after Short’s murder.

Fear also sold newspapers, as any tabloid journalist at the time could tell you. And tell people they did, particularly in the early days and weeks after Short’s death, when the tiniest new detail about the “Black Dahlia” investigation—even, or especially, if that detail wasn’t true—could boost circulation. Mann calls out many instances of “sexing up the news” (a phrase he uses multiple times): the description of the block where Short’s body was discovered as a “lover’s lane”; invented testimony from witnesses and family members (including Short’s grieving mother, Phoebe); exaggerations in the memoirs of the L.A. newspaper editors Agness Underwood and Jimmy Richardson, early chroniclers—and shapers—of the murder narrative.

The errors and suppositions would multiply over the decades—most of them cataloged by the former L.A. Times reporter and historian Larry Harnisch. Was Short a sex worker? Blame John Gregory Dunne’s otherwise terrific 1977 novel, True Confessions, which gave its Short stand-in the moniker “The Virgin Tramp” along with a past career in pornography. (Without True Confessions, James Ellroy probably wouldn’t have written his own The Black Dahlia novel in 1987, which led to a 2006 film adaptation.) Did she have sexual dysfunction? That’s an invention of a former Examiner reporter, Will Fowler, bolstered by John Gilmore in his supposedly nonfiction 1994 account, Severed, which includes information from a detective, “Herman Willis,” who doesn’t seem to have existed.

False suspects also proliferated. Was George Hodel the killer? So his son Steve Hodel keeps insisting, first in his 2003 book, Black Dahlia Avenger, then in a later book that also puts George forward as the Zodiac Killer (oy). Janice Knowlton, too, believed that her father murdered Elizabeth: Read about it in Daddy Was the Black Dahlia Killer. Piu Eatwell’s Black Dahlia, Red Rose initially convinced me that Leslie Dillon was the culprit, but Mann’s account definitively rules Dillon out. Eli Frankel’s Sisters in Death, published just last year, strains (and, to my mind, fails) to connect Short to an unsolved murder in Kansas City. And a new podcast hosted by Michael Connelly, Killer in the Code, also tries to connect the Black Dahlia and the Zodiac Killer, with the help of a “cold-case consultant” who bases his “smoking gun” on a deathbed sketch that better resembles fan art.

Shiftiness, con artistry, and even violence toward women don’t add up to hard, incriminating evidence. Mann, too, succumbs to the temptation, perhaps reluctantly; he spends precious pages explaining why one of Elizabeth’s Long Beach boyfriends, a military veteran named Marvin Margolis who died in 1993—the same suspect in Connelly’s podcast—can’t be ruled out as the killer. (The original detectives crossed him off the list early in the investigation.) Even Mann seems dissatisfied when he mulls the prospect that a stranger killed Short: “She was simply a vulnerable young woman who came face-to-face with someone with severe and violent psychopathology who decided, either on impulse or deliberation, to kill her, to use her body to express rage and resentment at the world.”

After so much time has passed, no one is likely to be satisfied with any identification of Short’s killer. If the lead detective, Harry Hansen, is to be believed, the Los Angeles Police Department never once interviewed the actual killer despite interrogating scores of suspects—including all of those mentioned in prior books, and now Mann’s. Any outcome would likely resemble the identification last September, via investigative genetic genealogy, of the man responsible for the 1991 quadruple homicide in Austin, Texas, known as the “Yogurt Shop Murders.” In that case, pinning down the murderer didn’t erase the 34 years of anguish and damage sustained by the girls’ families and the young men wrongfully convicted—including one who had been on death row. After decades of pain and exploitation, solving the case feels like an anticlimax.

“Solving” the Black Dahlia case, most likely through genetic genealogy, may bring an answer, but it would only generate many more questions. Harnisch, the historian, who knows more about the case than almost anybody (and has a credible theory relegated to a footnote in Mann’s book), put it best in a 2020 interview: “This is a story that fades to conjecture. This is a story without an ending.”

Look past the need for narrative and there, out on the horizon, is Elizabeth Short, walking down a California boulevard, trying to create a better story for herself. She didn’t have to remain forever a girl wounded by her father’s rejection, too proud to admit the truth about her life to her mother and sisters, yet resourceful enough to survive, for a time, in a world that couldn’t care less. Her luck ran out, and we don’t know why, or who killed her. But the brutality of Short’s death shouldn’t supersede her life any more than myth should overshadow a larger truth: that her murder will never truly make any sense.

​When you buy a book using a link on this page, we receive a commission. Thank you for supporting The Atlantic.</div>
        </div>
        
        <div class="card" onclick="openModal('content-23')">
            <div class="source">The Atlantic</div>
            <div class="title">How to Have a ‘Don’t-Know Mind’</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-23" style="display:none;">
            <h2>How to Have a ‘Don’t-Know Mind’</h2>
            <p><strong>The Atlantic | 2026-01-26</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/science/2026/01/consciousness-journey-zen-meditation/685647/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Anyone who thinks the contemplative life amounts to a form of quietism or a retreat from the world’s suffering should spend some time shadowing Joan Halifax, the Zen priest and anthropologist. I’d been curious about Halifax for years, ever since I heard about an annual trek that she leads through the mountains of Nepal, bringing a cadre of doctors and dentists to remote mountain villages with little access to health care.

Each summer over the course of two weeks or so, this Nomads Clinic covers more than 100 miles on foot and horseback, at altitudes of nearly 18,000 feet. These “medical mountaineers,” as they’ve been called,  all volunteers, sleep in tents, often in freezing temperatures. But after some 40 annual trips to Nepal—Halifax is normally based in Santa Fe—she recently decided it was time to hang it up. She had just turned 80.

In addition to bringing medical care to remote mountain villages half a world away, Halifax has ministered to the dying in hospice, worked with the homeless in New Mexico, cared for prisoners on death row, and led countless protests for peace. I don’t know if Halifax has shed the last remnants of her ego—she would say she hasn’t—but the selflessness she manifests in the conduct of her life is something to behold, a reminder of what the exploration of human consciousness can lead a person to do and be. This, too, is a Buddhist principle—that overcoming one’s own small self should lead to greater compassion for others, and that the suffering alleviated when we transcend the ego is not only our own.

For more than 30 years, Halifax has been the abbot at Upaya Zen Center, the retreat she founded in Santa Fe in 1990. I’ve had the chance to meet her a couple of times; once, we appeared together on a panel to talk about psychedelics. Halifax was married to the pioneering Czech psychiatrist Stanislav Grof for several years in the 1970s. Working together, they gave transformative doses of LSD to the dying. For a period of time, Halifax regularly took large doses of LSD herself. Her first psychedelic trip, while wandering the streets of Paris in 1968, showed her “that there was beauty behind the beauty I perceived, and that mind was both in here and out there. I was dumbstruck.”

I could relate. After years of curiosity about psychoactive plants, my own experimentation with mushrooms and LSD in recent years fundamentally changed the way I understand the mysteries of consciousness and the self. So in 2024, I emailed Halifax to see if I might pay a visit to Upaya. My idea was to spend a week or so in residence, meditating with the aspiring monks, performing monkish chores, interviewing Halifax, and seeing if I could make a little more progress untying the knot of self. “Upaya is a factory for the deconstruction of selves,” she had told me. I was curious to find out how that worked.

Read: Psychedelics open your brain. You might not like what falls in.

But Roshi Joan, as everyone calls her, had other plans for me. She decided I should spend a day or two at Upaya and then accompany her up to “the refuge,” an off-the-grid compound of tiny houses and huts stretched out across a broad hammock of meadow at 9,400 feet in the Sangre de Cristo Mountains, north of Santa Fe. Whenever she’s not traveling or running conferences or teaching, Halifax retreats to these mountains, where she meditates and hikes and paints and writes and doesn’t have to play the role of abbot. She dispatches students to the refuge when she deems them in need of a period of monastic solitude—for years at a time, in some cases.

“After you’ve acclimated to the altitude, we’ll drive up to the refuge,” she said by email before my arrival in Santa Fe. “You can stay in the cave.” This was not put in the form of a question.

Halifax explained that even though it had neither plumbing nor electricity nor an internet connection, this was “a five-star cave” and I would be comfortable—or, more likely, I’d be uncomfortable in a spiritually productive way. I’m not much of a camper but decided I might as well put myself in her hands to see what the experience would yield.

The first thing you notice about Joan Halifax is her undiminished beauty—the shining blue eyes and the easy smile and the generous sweep of white hair. That she’s 83 is hard to believe. She moves through Upaya’s little village of low-slung adobes and tended gardens with a graceful authority. Yet abbot is a role that, these days, she’s more than happy to trade for the solitude and freedom of the refuge.

The refuge is at the end of a 25-mile-long rutted dirt road that climbs through a shadowy forest of pine and spruce, punctuated by the sparkle of the occasional stream or meadow. Though it was well into June, spring was still unfolding at this altitude, the meadow grasses and spruce tips bright green and the groves of ivory-trunked aspen just leafing out. After we unloaded our SUV at the main house, where we would gather for meals (and connect to the outside world, as the house has a satellite internet connection), Halifax escorted me to my lodgings, a hike of half a mile along a path through meadows lined with aspen trees, their new leaves fluttering gently. Along the way, she identified the scat of elk, deer, and bears.

The cave was a 12-by-15-foot cell dug into a south-facing hillside and lined with brown stucco; it was windowless except for a sliding glass door overlooking the meadow. In one corner stood a spartan single bed, in the other a small woodstove. Between them, against the back wall, a meditation cushion sat on a raised platform, beneath an embroidered fabric depicting a Buddhist figure I didn’t recognize. I pictured myself seated cross-legged on the platform, like one of those levitating yogis in a New Yorker cartoon. The room also had a small sink fed by a five-gallon jug of water suspended above it, a two-burner camp stove, some shelving for clothes and books, and a car battery hooked up to a small solar panel outside. This produced just enough juice to power a reading light and charge a phone, though with no cell service or internet connection, what was the point?

What was the point? Why did Roshi Joan want me here rather than at Upaya or the main house, with its creature comforts? (And why did she keep putting off our interview?) I came to suspect she had decided that the questions I had for her—questions regarding Buddhist ideas about the self and consciousness and her own path from psychedelics to Zen—were best approached obliquely, perhaps by way of firsthand experience rather than words; that I should answer them myself. When I’d told her what I was working on, she had diagnosed me as hopelessly stuck in my head. Better to spend several days alone with myself meditating and navigating these hills than in the more familiar landscape of concepts, something to which I should have known a Zen priest would be allergic. When we finally did sit down for our interview, in the main house on the morning of the third day, Roshi Joan began by saying, somewhat cryptically, that she had “divested from meaning.” Okay.

It took me a while to realize that for Halifax, the practice of Buddhism was everything and theories were of little use or consequence. It was only through doing that she had learned her most enduring life lessons, whether that meant sitting with death-row inmates who taught her how powerlessness ferments into anger, or ministering to people in their last days and hours. “You learn to be nimble toward whatever is arising, because there’s no one death,” she said, “and if you cling to expectations, you will experience futility.” It was here, in doing the work, that Buddhist ideas about impermanence, conditioning, and dependent arising became flesh.

I took the hint. When I asked Halifax about herself or about Buddhist philosophy, she often ducked my questions or directed me elsewhere, so during one of our daily walks, I instead asked her to describe exactly how her factory for the deconstruction of selves operated.

People come on silent retreat for a week or two at a time and spend most of their days sitting in the Zendo—the meditation hall—facing a wall or tracing walking meditations on the gravel paths that meander through Upaya’s gardens. (I’d witnessed this glacial parade of earnest zombies.) I asked if novices received any guidance or technique. Not much, she said. Students are instructed about posture, and beginners are told to follow the breath, which “unifies body, mind, and space.” As Halifax has written, zazen, or sitting, “is not a mental exercise, a thing you do with your mind.” Rather, “it is about being radically open to things just as they are, not grasping at or rejecting phenomena, but simply being present and at ease with moment-to-moment uncertainty and groundlessness” and “letting openness or not-knowing deconstruct our version of reality. It is the method of non-method.” Just sitting, upright—that, apparently, is all there is to zazen.

“Zen is the hardest school,” Halifax explained, “because there is so little support.” But at Upaya, she told me, “there is the jungle gym of structure”—the strict rules and rituals and routines that govern life on retreat.

“There’s a certain point at about day three where you can feel the whole room go poof,” she said. “And everyone realizes we’re now in one body, one mind.” I asked her how this transformation was achieved. “We don’t say we’re deconstructing the self, but that is what we’re doing,” she told me. “Living in silence means you can’t start a conversation, so there’s no opportunity for self-presentation. Then there are the rituals that organize the day. These draw people into the group and relieve them of having to make decisions. Rituals take the place of a certain amount of volition.” It hadn’t occurred to me that ritual and silence could serve as tools to change consciousness and breach the hard shell of self.

Arthur C. Brooks: Five teachings of the Dalai Lama I try to live by

But it is the agony of meditating for hours at a time that finally breaks down the ego. I asked her what people meditate about. “Mostly they ruminate and plan,” she said. “They do that until they can’t stand the thought of themselves any longer. You’re just sitting there for hours on end, and the entertainment value of watching the same reruns all day long diminishes over time. Pretty soon, it becomes unsustainable; they’re exhausted and uncomfortable, and that’s when they drop in.”

To “drop in,” Halifax explained, is to enter a state of being completely present in time and space, experiencing “the sense field”—the world as it appears to our senses prior to thought—without conceptualizing, and surrendering the sense of a separate self. The recipe was simpler (and much less appetizing) than I would have imagined: To transcend the self, force yourself to be alone with it long enough to get so bored and exhausted that you are happy to let it go.

Halifax, who did anthropological fieldwork in Africa, thinks of the Zen retreat as an initiation ceremony, or rite of passage, and like most such rites, it involves the metaphorical death of the ego followed by rejoining the group. She regards the psychedelic trip as another rite of initiation, but “it’s a shortcut,” and one she’d rather her students not take. I wondered if this helped explain why she preferred that I stay at the refuge rather than mingle with her students at Upaya. Perhaps she thought contact with me would undermine the process by encouraging them to take the psychedelic shortcut.

“There is a lot gained when we give up the self,” she noted. “We break out of rumination. We discover we’re part of something larger, and we learn it feels good to care for others.” When I asked Halifax if she had succeeded in exorcising her own self, she allowed that she can be self-righteous at times. “There is moral injury, moral outrage, moral apathy—all of them are products of either a sense of superiority or inferiority,” she said. “So they’re all ego-based.”

I came to understand that Roshi Joan had sent me to the cave because there were no words or ideas she could offer that would teach me as much as simply being completely alone with myself in the middle of these mountains, with no phone or any other screens (and no toilet). Her idea, I eventually saw, was to pose a kind of experiential koan for me to puzzle and, perhaps, to help me unlearn some of the things I thought I had learned about consciousness and the self.

Cave life quickly stripped down to the bare essentials: collecting, splitting, and stacking wood; building fires; hauling water; digging pits in the woods; sweeping the floor and threshold; and, for hours each day, meditating on the platform. I’ve meditated for several years now, but never as easily or as deeply or as strangely as I did in my little cave. It may have been the silence, which felt bottomless, or the certainty that I would not be interrupted or distracted. Even the air there felt different, as if the absence of the electromagnetic waves that normally surround and pass through us made it easier to empty the mind of its usual detritus. I found I could sit for hours at a time, something I’d never managed to do before.

It helped that there was nothing else I needed to do, except maybe brew a cup of tea or sweep the cave again. Somehow, these seemed like particularly cave-appropriate activities. I fell into a routine so elemental and repetitive that it began to feel like ritual. The only snafu came the first time I attempted to use my hand-dug pit toilet and, failing to position myself properly, managed to pee into my sneaker. Now I was a shoeless monk. Which also seemed cave-appropriate.

One morning, I decided to try a meditation I’d learned from my time with the Nepalese French Buddhist monk Matthieu Ricard, who has written extensively on the self as an illusion. To see this, he suggested I explore the rooms of my mind, one by one, as if searching for a thief—what he called “the thief of self.” Looking within, I found all sorts of mental stuff but, as Ricard had predicted, none of it qualified as a self. Rather, I witnessed a parade of unbidden, free-floating perceptions, feelings, images, sensations, and thoughts, but I could locate no thinker of these thoughts or perceiver of these perceptions.

The longer I sat, the stranger these appearances became, as the space of my awareness became an empty stage. Picture a circus ring where all kinds of images might suddenly and inexplicably appear out of nowhere. Why is there now a bank of three old-timey telephone booths with men inside making calls? And what’s this hammer suddenly coming down on a knee?! Or that automatic glass door swinging open for no one? These stray images were then blasted away by a blazing sun that completely filled the space of awareness before transforming itself into a gigantic eyeball—a sighted sun with a black circle of iris. Could this be the anarchic mind that emerges when the ego relinquishes its hold?

Maybe, and yet these dreamy, hypnagogic images were more curious than frightening, probably because it was easy enough to chase them away, to change the mental channel, simply by willing it. So then who, or what, did the chasing? The source of that will, that inchoate “I,” might have escaped introspective detection, yet it could still make things happen or stop happening. The self might well be illusory, I decided, but no more so than color or any other construct of the mind. Put another way, the self can be both illusory and real, or real enough.

Initially, I found I was talking to myself out loud, trying to fill the vast space of silence, which made it feel as though I had doubled my self rather than eliminated it—given it a little company. “Should I brew a cup of tea? Put another log on the fire?” I would ask. And I would answer: “Sure,” or “Good idea.” But after a day or two, I fell in love with the silence, and the voices stopped. I found the handful of chores completely absorbing, as if nothing in the world mattered as much as splitting firewood, fully occupying my attention and leaving no remainder of thought, self-consciousness, or anticipation. The distance between living and meditating had narrowed to a sliver. When I described the satisfactions of my routine to Roshi Joan during one of our hikes, she smiled: “That’s the sacredness of the everyday.”

Something was happening to my sense of self, and it seemed to have everything to do with what was happening to my sense of time. I had never given much thought to the relationship between self and time, but it explains a lot. When the self is deprived of time past (memory) and future (anticipation), it melts away. Absorbed in meditation, or in my chores, or in watching a small herd of elk graze in the meadow below at sunset, I could feel my time horizon shrink. The feeling was unfamiliar, since my usual mental coordinates place me somewhere in the proximate future, a locus of anticipation and, all too often, unfocused worry. But now, for longer and longer stretches, I was simply here, being, with no thought of the past or the future.

To my surprise, these moments of simple and more or less self-less consciousness did not occur when my eyes were closed—in fact, the darkness sent me zooming off to all kinds of strange places. No, now it was when my eyes were open that the stream of thought stilled and pooled, and not only on the meditation platform; it could happen when I was moving around the cave doing chores or hiking in the woods. The miraculous everyday fact of consciousness loomed larger than “the hard problem” of how a brain produces subjective experience.

Had I “dropped in”? There were moments when all I experienced was what Roshi Joan had called the “sense field.” This happened especially upon opening my eyes in meditation, but it was never very long before I slipped back into reflection and then the inevitable jotting-down of notes, and all at once I was back in the self-world. To stay in that state of unthinking presence was like walking a tightrope only to suddenly look down, panic, and come plunging back to Earth.

Except once, when I managed to look not down but up. I had woken up in the middle of the night and stepped outside into the cold night air. There was a new moon, and the only light in the world was that of the stars, which were out in force, brighter and more numerous than I’d ever seen them, but also strangely different. Instead of dotting the same black scrim, like pinholes in a two-dimensional theater backdrop, the stars were scattered through space at dramatically varying distances, a vast swarm of them filling every last corner of an even vaster, more numinous, and emphatically three-dimensional darkness. Even stranger, the negative space between the stars had flipped to positive, forming a soft, almost palpable blackness that embraced the stars and reached all the way to Earth, enveloping it and me in the same intergalactic blanket. For the first time, I could see—no, could feel—that the stars and I shared the same infinite space.

Adam Frank: The truth physics can no longer ignore

My brain’s usual priors, predictions, and inferences about the night sky had broken down, it seemed, allowing me to see more of the galaxy and space itself than I ever had. There was hugely more of it and less of me, rendered infinitesimal in the presence of this immensity. I felt as though every previous experience I’d had of the night sky had been filtered through some idea or model or expectation and so had been something less than completely conscious. And I understood that this state—abstracted, distracted—had been my default. A line in a poem by Jorie Graham came to me:

This is what is wrong: we, only we, the humans, can retreat from ourselves and

Only we, the humans. Yes! What other animal can afford to be anything less than completely conscious?

This moment of being fully, freshly present to the universe stopped me cold and made me wonder if all my hard thinking about consciousness had missed something crucial about it. The more I focused the narrow beam of my attention on what consciousness is and what it does and how it came to be, the less of it I was actually experiencing—whatever it was. My time in the cave and, now, beneath this night sky showed me the price of my impatience with the mystery.

“Always keep a don’t-know mind,” Roshi Joan had said to me. Sometimes not knowing opens us to possibilities that knowing, or trying to know, or thinking we already know, closes off. In the years since I had embarked on this inquiry, desperate to know, I had narrowed the aperture of my awareness, sacrificing this, the glory of the night sky, for a keen intellectual focus. But as my days of solitude in these mountains had shown me, that wider circle of light, that numinous lantern of awareness, is still available to us, so long as we can break the spell of self and its distractions. Consciousness is a miracle, truly, and remains the deepest of mysteries, yes, but it is also so very simple that it can fit into a sentence: I open my eyes and a world appears.

This essay was adapted from Michael Pollan’s book, A World Appears: A Journey Into Consciousness, published next month.

​When you buy a book using a link on this page, we receive a commission. Thank you for supporting The Atlantic.</div>
        </div>
        
        <div class="card" onclick="openModal('content-24')">
            <div class="source">Slashdot</div>
            <div class="title">Lawsuit Alleges That WhatsApp Has No End-to-End Encryption</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-24" style="display:none;">
            <h2>Lawsuit Alleges That WhatsApp Has No End-to-End Encryption</h2>
            <p><strong>Slashdot | 2026-01-27</strong></p>
            <a class="original-link" href="https://it.slashdot.org/story/26/01/27/0550249/lawsuit-alleges-that-whatsapp-has-no-end-to-end-encryption?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Catch up on stories from the past week (and beyond) at the Slashdot story archive

Gee, what would lead anyone think they were capable of doing such a thing?

The backdoor was probably mandated by the feddy gov.

>&quot;The lawsuit does not provide any technical details to back up the rather sensational claims.&quot;

That is an inherent problem with closed code and closed platforms.  They can claim anything they want and there isn&#39;t much way we can verify their claims.  I admit, this story seems really sensational (a little hard to believe), but it is plausible.

Also, there can be word-trickery here.  It is possible things can be claimed to be &quot;end-to-end encrypted&quot; and yet still have ways for the mothership to decrypt anything at will (by having intentional secret holes/weaknesses, by storing your or another key, or a method they can pull the key from your device through their own control over the app, or by having master keys present at the start).  I think that would be a misuse of the term &quot;end-to-end encryption&quot;, yet term use/definitions mutate all the time.  Anyway this can backfire spectacularly if discovered and lead to a lot of legal issues- if they had denied law enforcement/courts access in the past with the excuse that they can&#39;t decrypt it and then it is discovered they could.

>&quot;Otherwise it would be end-to-middle-to-end encryption, wouldn&#39;t it?&quot;

Nope, that would imply it is being decrypted and then re-encrypted in the middle.  That doesn&#39;t have to happen.  It would still have stayed encrypted from one end (sender) to the other end (receiver).  The middle can just store the message and decrypt it later, if needed, if they have access to the keys (now or later) or a weakness/backdoor.

Meta, calls the claims &quot;false and absurd.&quot; 
Meta also says they routinely see false claims and speculation like this in lots of users&#39; WhatsApp messages - and none are true. ;-)

Meta, calls the claims &quot;false and absurd.&quot;

Meta also says they routinely see false claims and speculation like this in lots of users&#39; WhatsApp messages - and none are true. ;-)

When E2EE was first rolled out, a message appeared in each chat saying that communications were now secure. I always wondered how they managed to distribute the keys without Facebook ever gaining access to them. I long suspected that they might secretly keep a copy of the keys, perhaps obtained during the key distribution process itself. Now those suspicions are gone

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

Whenever a system becomes completely defined, some damn fool discovers
something which either abolishes the system or expands it beyond recognition.</div>
        </div>
        
        <div class="card" onclick="openModal('content-25')">
            <div class="source">Slashdot</div>
            <div class="title">China Hacked Downing Street Phones For Years</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-25" style="display:none;">
            <h2>China Hacked Downing Street Phones For Years</h2>
            <p><strong>Slashdot | 2026-01-27</strong></p>
            <a class="original-link" href="https://news.slashdot.org/story/26/01/27/0138225/china-hacked-downing-street-phones-for-years?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Please create an account to participate in the Slashdot moderation system

It&#39;s weird to see a global espionage saga and say, &quot;well that&#39;s dumb. I am not a wizard with nation state resources, but I could so that on a casual weekend.&quot; Their security sucks so much that my grandson could probably accidentally do that while settling up a game server.

The difference is the western countries admit when they get hacked.  (Not sure if the US still counts - will find out in 2028).

China?  Russia?  Iraq?  If someone is lucky, they just fire the General responsible for security.  If not lucky, they fall out of a forty story building.  And the press says it was an accident.

But they never admit what happened - because they are terrified of letting the common folk find out how bad they are at their job.

Yup, GCHQ doesnt have a massive budget for no reason.  The NSA doesnt put its huge budget into a savings account for a rainy day.  The CIA cant even operate on US soil...

If China is doing this and getting away with it, my issue is not with China but with my countries intelligence services not countering it properly.

As a Five Eyes (FVEY) member, there are security implications for the US and other members. So it&#39;s not some trivial matter to ignore.

Given how Trump is behaving towards the UK (tarifs) and Canada (tarifs and 51st state comments) right now I suspect that alliance might well be fraying at the edges anyway.

End result China&#39;s IQ reduces by 10 points listening to limey blabber.

Never trust anyone with the self-aggrandising job title &#39;Chief Mouser&#39;.

They&#39;ve likely been feeding the Chinese bogus crap for years knowing the phones were being tapped.

And Liz &quot;Bested by head of lettuce&quot; Truss.

You do realise they&#39;re not directly responsible for the security apparatus, right?

You know it will be run by Fujitsu, Capita, or Palantir, so of course their private data will be safe and secure, if over budget by an order of magnitude.

What about them? Any different from a tesla, except that they are better and cheaper?

https://militarnyi.com/en/news... [militarnyi.com]

Tesla also collects all kinds of data, and despite their &quot;opt-out&quot; claims, you can&#39;t fully opt out except by disabling their networking with an axe.

What is a &quot;most honourable order of the bath&quot;? I assume it isn&#39;t something given you in the Hogwash school of magic.

In 2014, a couple of months after he stepped down as Director of Public Prosecutions (and more than a year before he became an MP).

Sure makes you wonder why the UK has approved that sketchy new embassy China wants to build, complete with underground rooms a few meters away from comm lines:

https://www.telegraph.co.uk/ne... [telegraph.co.uk]

Looking at it the other way - those tunnels make it easy for us to spy on them.

Always good to have your take on virtually every story these days cut and pasted some cretinous poster who thinks they&#39;re being clever.

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

Whenever a system becomes completely defined, some damn fool discovers
something which either abolishes the system or expands it beyond recognition.</div>
        </div>
        
        <div class="card" onclick="openModal('content-26')">
            <div class="source">Slashdot</div>
            <div class="title">Reddit Lawyers Force Founder to Redact 'WallStreetBets' From Miami Event</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-26" style="display:none;">
            <h2>Reddit Lawyers Force Founder to Redact 'WallStreetBets' From Miami Event</h2>
            <p><strong>Slashdot | 2026-01-27</strong></p>
            <a class="original-link" href="https://tech.slashdot.org/story/26/01/27/0147238/reddit-lawyers-force-founder-to-redact-wallstreetbets-from-miami-event?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Want to read Slashdot from your mobile device? Point it at m.slashdot.org and keep reading!

The people who built/run the Nebula online streaming video to shy away from this sort of thing are probably feeling pretty good about themselves right now. Youtube video creators are probably sweating bullets right now. A lot of people &quot;invested&quot; in youtube channels over the years, according to this, youtube owns the IP (or at least, branding) of channels like Mr. Beast, Veratasium, etc etc

Social structures are all about fucking over the little guy.  Best of luck starting a new community platform without big money backing, and even then, best of luck.

So Reddit wants to own everything good created by their users but avoid any responsibility for anything bad created by their users via section 230.

Bad ruling by the court.  They should be required to take the bad with the good or not get to control any of it.  We know they&#39;d take option 2 if the court has made a better ruling.

The rich fucking over the poor is much older than that term you use.

And recently Rogozinsky lost this case.  This establishes the trademark WallStreetBets as owned by Reddit (for the uses for which they filed), and given that, they can control use of the trademark.  By, for example, banning its use by others for whatever reason - the reason doesn&#39;t matter, as they own the trademark.

What I think it specifically unusual about this is that Reddit didn&#39;t create this intellectual property, nor did anyone employed by them.  So it is hard to even understand on what basis the have standing to claim the copyright above the person who actually coined the name.

The reason might be somewhere in the legal gobbledygook we all have to read & sign when registering an account with Reddit.  Aside from specifically assigning away these rights, it&#39;s hard to imagine the basis for just grabbing them from the actual creator.

But I haven&#39;t tracked down nor read the actual case, so that is just speculation.

The trademark filings & other info for these marks can be found here:

- https://tsdr.uspto.gov/#caseNu... [uspto.gov]

- https://tsdr.uspto.gov/#caseNu... [uspto.gov]

Creation established copyright as per the Berne convention,  social media site ToS notwithstanding... which doesn&#39;t matter here.

The trademark of &#39;WallStreetBets&#39; was established by using it commercially, which happened the moment Reddit inserted ad content as someone surfed the subreddit.

Which sucks, is unfair, etc... but also American law.

It&#39;s not every day you see somebody use the courts to pound a blunt screwdriver into their own nuts. I hope the lawyers are OK.

Does anybody truly give a damn about reddit drama?

The law is about screwing you over, which to the law is perfectly reasonable.

Is anyone going to explain (please please) what WallStreetBets is all about ?

I suppose I could just scroll on by, but it&#39;s nice when posters add some meaning to their stories.

Or how to scare away your most loyal user base.

Anybody who is loyal to reddit deserves the deep rogering they&#39;re about to receive.  Reddit is a turd palace filled with turds.

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

Whenever a system becomes completely defined, some damn fool discovers
something which either abolishes the system or expands it beyond recognition.</div>
        </div>
        
        <div class="card" onclick="openModal('content-27')">
            <div class="source">Slashdot</div>
            <div class="title">Apple Launches AirTag 2 With Improved Range, Louder Speaker</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-27" style="display:none;">
            <h2>Apple Launches AirTag 2 With Improved Range, Louder Speaker</h2>
            <p><strong>Slashdot | 2026-01-27</strong></p>
            <a class="original-link" href="https://apple.slashdot.org/story/26/01/27/0047225/apple-launches-airtag-2-with-improved-range-louder-speaker?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Follow Slashdot blog updates by subscribing to our blog RSS feed

This is merely tracker. Do you actually expect the item to sprout arms and legs and act as a physical protector and apprehend the thief? If do, your comprehension about things is sorely deficient.Do you comprehend there may be use cases beyond your limited guesswork? For example, I&#39;m traveling. Car is at the airpot. Each day I check if it&#39;s still there. If it moves I can report things to the police within a day of its movement, rather than a week or more later when I return home. That can be the difference between a car broken into and joy rided and a car stripped for parts.

This is merely tracker. Do you actually expect the item to sprout arms and legs and act as a physical protector and apprehend the thief? If do, your comprehension about things is sorely deficient.

Do you comprehend there may be use cases beyond your limited guesswork? For example, I&#39;m traveling. Car is at the airpot. Each day I check if it&#39;s still there. If it moves I can report things to the police within a day of its movement, rather than a week or more later when I return home. That can be the difference between a car broken into and joy rided and a car stripped for parts.

And the new louder speaker will make it 50% more likely the thieves will find it. Thanks Apple!

Really? You think thieves are hanging around random boxes waiting for somebody to trigger a tag so they can select one to open?

No, really. Please. Go ahead and use case this. Draw the lines.

What boxes? We were talking about using an AirTag to track a stolen car. Ask your doctor if sanity is right for you!

Your phone can already keep track of where you left your car.

Your phone can already keep track of where you left your car.My phone and the car don&#39;t talk. I used to drop a pin but the air tag is easier and more reliable.

Your phone can already keep track of where you left your car.

My phone and the car don&#39;t talk. I used to drop a pin but the air tag is easier and more reliable.

Still no hole so you can actually attach it to something.

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

Whenever a system becomes completely defined, some damn fool discovers
something which either abolishes the system or expands it beyond recognition.</div>
        </div>
        
        <div class="card" onclick="openModal('content-28')">
            <div class="source">Slashdot</div>
            <div class="title">TikTok Alternative 'Skylight' Soars To 380K+ Users After TikTok US Deal Finalized</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-28" style="display:none;">
            <h2>TikTok Alternative 'Skylight' Soars To 380K+ Users After TikTok US Deal Finalized</h2>
            <p><strong>Slashdot | 2026-01-27</strong></p>
            <a class="original-link" href="https://tech.slashdot.org/story/26/01/27/0036229/tiktok-alternative-skylight-soars-to-380k-users-after-tiktok-us-deal-finalized?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Slashdot is powered by your submissions, so send in your scoop

Someone says &quot;authoritarianism is bad&quot;, and you assume that they&#39;re talking about Trump. Weird.

BlueSky/SkyLight are decentralized platforms owned by public benefit corporations.TikTok is still owned by ByteDance which is at least CCP-adjacent (arguably bad), but the US implementation of its algorithm is now controlled by  a group of Great American Patriots and Investors, the Biggest in the World  [truthsocial.com] (arguably worse).

These social media sites are all lost money. They come and go.

Linux showed the blueprint when it toppled Microsoft, now this generations task is to do the same to social media.

Well if it&#39;s open source I hope they beat UpScrolled that the TikTok users are apparently also fleeing to today:

https://www.engadget.com/socia... [engadget.com]

[ Okay, so I&#39;m an old fart and not the target audience... ]

Relaxing after work with my 3 screens. Anything without a web interface is a non starter.

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

Whenever a system becomes completely defined, some damn fool discovers
something which either abolishes the system or expands it beyond recognition.</div>
        </div>
        
        <div class="card" onclick="openModal('content-29')">
            <div class="source">Slashdot</div>
            <div class="title">Microsoft's Latest AI Chip Claims Performance Edge Over Amazon and Google</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-29" style="display:none;">
            <h2>Microsoft's Latest AI Chip Claims Performance Edge Over Amazon and Google</h2>
            <p><strong>Slashdot | 2026-01-27</strong></p>
            <a class="original-link" href="https://hardware.slashdot.org/story/26/01/26/2244208/microsofts-latest-ai-chip-claims-performance-edge-over-amazon-and-google?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Follow Slashdot blog updates by subscribing to our blog RSS feed

At least that seems to be the most common reaction.

Yeah, it&#39;s like Microsoft and all the FAANG companies are playing a game no one cares about but them. Meanwhile, NVidia is happy to sell them booster packs for their decks.

Why have a lowly slop bucket when we can have the MS Slopcrete Sprayer!    But remember,  Satya the Slopmonger  cries when you say &quot;AI Slop&quot;

&quot;Mmmm, slop, is there anything it can&#39;t write?&quot;  -- Home Simpson

It&#39;s part of the larger trend among cloud giants to build their own custom silicon for AI rather than rely solely on Nvidia.And they are all made by Taiwan Semiconductor Manufacturing Co. (TSMC) .Meanwhile, from chips to ships for no particular reason, China has over 200X the shipbuilding capacity of the US at around 23 million tons.  Which coincidentally is about the same as the US in 1942 or 1943.

It&#39;s part of the larger trend among cloud giants to build their own custom silicon for AI rather than rely solely on Nvidia.

And they are all made by Taiwan Semiconductor Manufacturing Co. (TSMC) .Meanwhile, from chips to ships for no particular reason, China has over 200X the shipbuilding capacity of the US at around 23 million tons.  Which coincidentally is about the same as the US in 1942 or 1943.

So it enshitifies faster than the competition. Got it.

Only fools (and there are many in the AI hype machine ecosystem) do not understand that the next gen Amazon, Google, and nVidia chips will end up better than these Microsoft chips.  Each generation gets better than the previous generation.

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.

Whenever a system becomes completely defined, some damn fool discovers
something which either abolishes the system or expands it beyond recognition.</div>
        </div>
        
        <div class="card" onclick="openModal('content-30')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">How the Supreme Court Made Alex Pretti’s Killing More Likely</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-30" style="display:none;">
            <h2>How the Supreme Court Made Alex Pretti’s Killing More Likely</h2>
            <p><strong>News and Politics - Slate Magazine | 2026-01-26</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2026/01/supreme-court-alex-pretti-killing-qualified-immunity.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Sign up for the Slatest to get the most insightful analysis, criticism, and advice out there, delivered to your inbox daily.

Immigration and Customs Enforcement and Customs and Border Protection agents have now killed two U.S. citizens in Minnesota under the made-up banner of “absolute immunity” for federal law enforcement officials, regardless of what they do or how they do it. The notion of immunity for state actors in American law goes back decades, and much of what we are seeing on the ground now in terms of violent immigration enforcement has its antecedents in long-standing and deeply flawed American ideas about good guys versus bad guys and who bears the burden of law enforcement run amok. On this week’s Amicus podcast, as the nation struggles to process the executions of Renee Good and Alex Pretti, Dahlia Lithwick was joined by Alex Reinert, the Max Freund Professor of Litigation and Advocacy at Cardozo School of Law. Their conversation has been edited and condensed for clarity.

Dahlia Lithwick: ICE agents, like all federal agents, are protected by qualified immunity, and that protects them from lawsuits for constitutional violations committed in the course of duty. And we’ve had that for a long time. Help us understand this foundational idea that for the most part, law enforcement officers cannot be held liable for their actions when they violate your rights. How did we get here?

Alex Reinert: Really, there are two foundational ideas in play in these cases involving federal officials. One is what I’m about to talk about, which is qualified immunity, and a second is something called Bivens doctrine, which is a common law doctrine that used to allow people to sue federal officials for constitutional violations. Let’s start with qualified immunity, which is not long-standing in the sense that it’s really a modern introduction to the law of constitutional torts. It was introduced by the Supreme Court in 1967 in the context of a Freedom Riders case. That was the context in which a lawsuit was brought against state and local officials, and the Supreme Court basically said: We think, even though Congress didn’t spell it out in detail in a statute that gave you the right to sue these officials, and even though Congress didn’t say anything about an immunity doctrine, we think this common law doctrine that may have existed in 1871 should be incorporated into our constitutional tort regime. Fast-forward to 1982, which is where we got a case called Harlow v. Fitzgerald. In that case the Supreme Court said: We also think there should be an immunity doctrine that applies to federal officials.

What it means in practice is that any officer—whether state, local, or federal—who violates the Constitution won’t be held liable unless there is some prior case that makes it clear, from a court’s perspective, that the officer’s conduct was obviously a violation of the Constitution.

So qualified immunity is only really used, or it really only has an impact, when an officer is violating the Constitution. If officers don’t violate the Constitution, they don’t need the protection of qualified immunity. It’s only when officers violate the Constitution that they are able to obtain the protection of qualified immunity.

On its face, if you explained it to somebody and said that we should only hold officers liable when they were on reasonable notice of the unlawfulness of their conduct, people might look at it and think that makes sense. In practice, it has been applied in the widest range of circumstances where most people would say: How is it possible? How is it possible that somebody could get immunity when, for instance, they’re ordered by their supervisor not to fire a shot and they fire six shots and kill someone? When they are executing a search warrant and they decide to steal about $200,000 worth of valuables and a court says, Well, there’s qualified immunity because there wasn’t a prior case in point saying that when you’re executing a search warrant, you can’t steal money? Those are the kinds of cases in which qualified immunity comes into play.

It’s probably shocking to the ordinary person that in this country, a country purported to be governed by the rule of law, and where the Constitution is thought of as foundational, it turns out that violations of the Constitution by our highest-level officers and officials aren’t remediable because of this doctrine of qualified immunity.

Explain Bivens doctrine now, to set the table for what follows.

This is the other part of what is a perverse design of our constitutional scheme. Bivens is special because it applies only to federal officials. When state and local officials violate our rights, there’s a statute that goes all the way back to Reconstruction enacted in 1871 that allows us to sue state and local officials for violations of our constitutional rights. Qualified immunity still applies, but at least there’s a right to sue. There is no similar statute when federal officials violate the Constitution.

In 1971, in a case by the name of Bivens, the Supreme Court said: We think that we are going to find a right to sue in the Fourth Amendment, for Fourth Amendment violations when federal officials violate someone’s rights. Over the course of the next 10 years, the Supreme Court expanded that doctrine to include Eighth Amendment violations, and claims for sex discrimination. During the 1970s, lower courts were also rapidly expanding the Bivens doctrine.

All that changed in 1980. From 1980 on, the Supreme Court said: We are not going to entertain Bivens actions. And the court has given us a variety of reasons to the point where today, when the Supreme Court hears a Bivens claim, it basically says: We’re not sure that this court would even recognize the right to sue federal officials for constitutional violations. We’re certainly not going to extend that right to sue beyond the narrow category of the three cases in which the Bivens right was recognized in the 1970s. Furthermore, we’re going to confine those categories very narrowly.

I come back to this principle that we have a Constitution that is supposed to be meaningful in this country and it’s supposed to govern the conduct of all of our officers. It’s perverse that we have a federal Constitution that means less for federal officials than it does for state and local officials. We have a federal Constitution that is harder to enforce against federal officials than almost anyone else. That’s really a product of the Bivens doctrine.

And the last piece of this that I think is really important, just historically, for people to understand is that this wasn’t the model of remediation we had in the 19th century. You could sue federal officers in the 19th century when they violated your rights. It was not a unique occurrence. It was accepted that this was a way for people to obtain remedies. It also was accepted that it was a way to test the legality of executive conduct, of the policies and conduct of federal officials. Now we live in this world in which there are so many barriers to that kind of accountability, to those tests for legality.

That’s just a bad way to design courts. We want to learn from our mistakes. We want law to be able to develop if it should. It’s also bad, obviously, for people who are bringing these kinds of claims. I also think  it’s bad for policing. We want police to do their job consistent with the Constitution. Having answers to the question of when they violate rights and when they don’t should be, and is, important to them. So we’re losing all these opportunities in these cases to develop the law in ways that I think should help everyone.

Last week the AP reported a whistleblower complaint that showed that in violation of long-standing Fourth Amendment principles, ICE is taking the position that they can just enter folks’ homes without a judicial warrant. They can just use an administrative warrant. The whistleblower complaint alleges that the secret memo outlining this policy, signed by acting deputy ICE Director Todd Lyons, says, “although the U.S. Department of Homeland Security has not historically relied on administrative warrants alone to arrest aliens subject to final orders of removal in their place of residence, the DHS Office of General Counsel has recently determined that the U.S. Constitution, the INA, and the immigration regulations do not prohibit relying on administrative warrants for this purpose.”

I think it is extremely concerning and also an untenable interpretation of the Fourth Amendment. The Supreme Court hasn’t addressed this question, but the whole premise of the warrant requirement is that there should be some independent adjudicator—someone outside the executive branch—to decide whether or not there is a justification for invading the sanctity of someone’s home. Administrative warrants don’t provide that; judicial warrants do. That doesn’t mean judicial warrants are perfect, but they are at least outside the executive branch. It’s important from a separation-of-powers perspective, of course, and it’s important from an institutional design perspective. We already have so much about the immigration system over which the executive has so much authority: the appointment of immigration judges, all of these policy memos. So to fold the power to issue warrants, and act on warrants, into the executive in this way is just an extreme power grab. And the line about use of force gets us back to what we were talking about with Bivens and qualified immunity, which is when the officers use force in those circumstances, when they go overboard in their use of force—as inevitably some will—what kinds of remedies will there be? Those will be few and far between.

It reminds me of Justice Kavanaugh’s concurrence in Noem v. Vasquez-Perdomo, where he says, essentially, People are talking about use of force, but this case isn’t about use of force. If there is a use of force, then people should be able to go to court and sue. He says all that in his concurrence, but at the same time we know that Justice Kavanaugh is one of the justices who has led the charge for undermining the Bivens remedy. It’s exactly what the Supreme Court does in so many contexts in the civil rights world. They’ll say: We’re not going to give you this remedy here, but don’t worry. There’s all these other ways you can enforce your rights. And then when they’re over there in the other box, they say: Well, we’re not going to allow you to enforce your rights here because there’s something else over here. Pam Karlan calls it a shell game and it works like this: When I’m over here, I’m going to say, Don’t worry about me limiting your rights because there’s some other way for you to enforce them. And then I’m just going to undermine your means of enforcing them in that other part of the jurisprudence. So it is troubling to the extreme that ICE officers are going to be acting on this authority.

Since 2020, and the murder of George Floyd and the flash of recognition that police reform was past due, there has been a significant public silence. As a consequence, in that silence, we have to grapple with that which makes us very uncomfortable. By “we” I mean a culture that has turned a blind eye to a lot of these issues and is suddenly startled by the ways police immunity and impunity have been weaponized for immigration enforcement. So help us think through reform in ways that are conducive to meaningful accountability and conducive to having a civic life that doesn’t include masked officers pepper-spraying or shooting somebody who’s already restrained on the ground. How do we think in a bigger, more generous way about getting to where we want to be?

I guess I would think about it in at least two different ways. The first is part of the reason there’s resistance to increasing accountability, particularly for our policing apparatus. It has to do with the sense that it’s a hard job. And it’s a job that at some level, most people think we need people to do. And what do we do when something that people see as really important, that’s also hard, what do we do when that imposes costs? When that imposes costs on people who did nothing wrong, who are left traumatized, maybe dead, seriously injured? I’ve always thought that the problem with a lot of the doctrine we’ve been talking about is it leaves those costs on the people who suffered them. It leaves those costs directly on the people who suffered them. But if we allow it, if we think there’s something good that comes out of policing, if we think it creates some value for the public at large, why should the costs be borne solely by the people who suffered most significantly as a result of it? So that’s one piece of it that always resonates with me about why some of the doctrine we’ve been talking about is so wrong.

For a while, or at least for I don’t know how long of a moment after the murder of George Floyd, there was a conversation. I would go to demonstrations and I’d see signs that said “End qualified immunity.” There was a way in which the doctrine that previously mostly lawyers knew about or scholars were talking about and mostly other people didn’t know about, that doctrine came into the public consciousness and became important. I think there is still some of that going on. I think there is still some momentum for that.

When we think about accountability, we usually think about accountability for an individual, an individual who behaved in some unlawful way. It makes sense to think about accountability that way. But the problems we’re talking about are systemic. That doesn’t mean there aren’t some individuals, the so-called bad apples, who no matter what kind of training we have, no matter what way we approach hiring, no matter what kind of supervision we provide, there are some people who may just act egregiously because they can, because they have a badge. But I think for the most part, the problems we’re talking about are systemic. And if the problems are systemic, then talking about accountability for individuals isn’t necessarily the right frame. I think we need to approach solutions to the problem systemically. And those solutions are as much about: Who ends up paying the damages for the people who suffer? Should it be the individual officer or should it be the departments that employ them? As a matter of practice, it’s always the departments who employ them. So we need to find a way for those agencies to learn better from the kinds of misconduct that their officers enter into. But it’s also about the legal regime that we set up to allow people to sue and what kinds of things they sue for, the way we allow people, really limit the ability of people, to bring so-called injunctive relief and systemic reform of departments.

So if we think about accountability more broadly, and we think about the problems we’ve been talking about, through a systemic lens, it’s not so much about the individual officer. It’s about creating a legal regime that allows us to get answers to the questions of how people were mistreated, whether the way in which they were mistreated was unlawful, and making sure that we can build systems so that it doesn’t keep happening. Because right now we’re in a world where it is happening over and over again and it seems like there are very few tools in our toolbox to prevent the reoccurrence.

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-31')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">Are Democrats Going to Vote for More Money for ICE?</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-31" style="display:none;">
            <h2>Are Democrats Going to Vote for More Money for ICE?</h2>
            <p><strong>News and Politics - Slate Magazine | 2026-01-26</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2026/01/ice-funding-and-alex-pretti-will-democrats-shut-down-the-government.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Sign up for the Slatest to get the most insightful analysis, criticism, and advice out there, delivered to your inbox daily.

Early Saturday morning, it appeared as if enough Senate Democrats were willing to fund the Department of Homeland Security and its deportation machine, if that’s what it took to keep the rest of the government open.

The House had passed funding for the DHS late last week, with seven centrist Democrats joining nearly all Republicans to get it over the line. The Senate was to take it up this week alongside a handful of other funding bills. It was expected that, as with the House vote, enough Democrats would hold their noses and support it, even if it meant absorbing blowback from a furious Democratic base that has been dusting off the largely dormant “Abolish ICE” slogan. Democratic negotiators felt that approving full-year, carefully negotiated spending bills and reasserting Congress’ power of the purse over a freewheeling executive branch was the priority of the moment.

“There is much more we must do to rein in DHS, which I will continue to press for,” Sen. Patty Murray, the top Democrat on the Senate Appropriations Committee, said in a statement last Tuesday, once the deal was released. She listed some pittances she had secured in the DHS bill, such as more money for body cameras for Immigrations and Customs Enforcement. She knew, though, that wouldn’t ease any anger within the base. Ultimately, she leveled.

“But the hard truth,” she added, “is that Democrats must win political power to enact the kind of accountability we need.”

All of this changed on Saturday in Minneapolis, when Border Patrol agents killed 37-year-old observer Alex Pretti. All of this changed when videos showed Pretti subdued, being pepper-sprayed and then shot, over and over again, without brandishing the firearm that he was permitted to carry. All of this changed when, as after the killing of Renee Good, White House adviser Stephen Miller and DHS Secretary Kristi Noem absurdly described Pretti as a “domestic terrorist” or “assassin.” After Pretti’s killing and the administration’s eyesight-defying remorselessness over what happened, there was no way Senate Democrats could put their fingerprints on a bill to fund the administration’s deportation machine.

“I will NOT support the DHS bill as it stands,” Patty Murray said Saturday.

She was hardly the only one. Democrats who’ve previously broken from the pack to join Republicans in advancing government funding bills, like Sens. Tim Kaine, Catherine Cortez Masto, Angus King, and Jacky Rosen, all said the same. On the House side, meanwhile, one Democrat who had voted for the DHS funding bill, New York Rep. Tom Suozzi, offered a mea culpa on social media, saying that he had “long been critical of ICE’s unlawful behavior and I must do a better job demonstrating that.”

Senate Democratic Leader Chuck Schumer put a bow on Democrats’ new posture Saturday night: Democrats would filibuster DHS funding without changes. And it didn’t sound like there was much handwringing about it.

Does this make a partial government shutdown, after funding lapses after Jan. 30, inevitable? Let’s say much more likely. The situation is complicated for reasons including, but not limited to, the weather.

The funding bill the Senate will be voting on does not just cover DHS. It combines half a dozen bills that the House has passed in January funding everything from the Pentagon to the State Department to the departments of Health and Human Services, Transportation, Education, Labor, and more. Although this package includes only half of the 12 yearly appropriations bills, the specific departments it includes—especially Defense and HHS—comprise a comfortable majority of annual spending.

Senate Democrats are calling on their Republican counterparts, in Schumer’s words, to “work with Democrats to advance the other five funding bills while we work to rewrite the DHS bill.” In other words, to strip DHS funding from the package, pass everything else, and then allow for more time to negotiate the DHS budget.

Would Republicans be willing to do this? They typically don’t take orders from Democrats. But Republican leaders, just as much as Democratic ones, don’t want appropriators’ delicate work on the biggest funding bills to get sent to an incinerator of fury. The New York Times reported Saturday that “recognizing the depth of Democratic rage,” Senate Republicans “immediately began examining whether they could separate the homeland security funding from the rest of the package and preserve the bulk of what had been a bipartisan deal to fund a large chunk of the government.” Maine Sen. Susan Collins, the chair of the Appropriations Committee, said her committee was “exploring all options.”

If—if—leaders in the Senate reach an agreement to amend the package, then there’s another problem: The House is on recess this week, and House Republicans’ leaders wouldn’t be particularly enthused about summoning members to Washington to revote on a package amended at Democrats’ request. Plus, a substantial portion of the continental United States is buried under a sheet of ice and snow, conditions that aren’t conducive to travel.

It’s important to note that a lapse in DHS funding wouldn’t impede deportation operations much. As Patty Murray repeatedly said when she was trying to push the deal through, ICE is sitting on substantial funds that were made available to it in Republicans’ party-line megabill last year.

Murray is still saying that, posting on Sunday that “Americans must be eyes wide open that blocking the DHS funding bill will not shut down ICE. ICE is now sitting on a massive slush fund it can tap, whether or not we pass a funding bill.”

“But,” she added, “we all saw another American shot and killed in broad daylight.” They’re not about to bless it with their votes.

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-32')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">“Oh, Shit, That Was Alex”: What It’s Like to Discover That Your Friend and Colleague Was Killed by Federal Agents</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-32" style="display:none;">
            <h2>“Oh, Shit, That Was Alex”: What It’s Like to Discover That Your Friend and Colleague Was Killed by Federal Agents</h2>
            <p><strong>News and Politics - Slate Magazine | 2026-01-26</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2026/01/ice-cbp-alex-pretti-icu-nurse-video-kind-guy.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Sign up for the Slatest to get the most insightful analysis, criticism, and advice out there, delivered to your inbox daily.

On Saturday, Alex Pretti was pushed to the ground and fatally shot by federal agents. Video shows that, moments before, Pretti was holding a cellphone in one hand and had his other hand up. Pretti was 37 and worked as an ICU nurse at a VA hospital. He enjoyed biking and had a dog named Joule.

Later that day, What Next’s Mary Harris spoke to Dimitri Drekonja, a colleague and friend of Pretti’s, who remembers him as “a kind guy” who modeled cooperation and who, right out of school, took one of the hardest jobs available to nurses. Their conversation has been edited and condensed for clarity.

Mary Harris: How did you learn about what happened?

Dimitri Drekonja: We were at [my son’s ski] race in the morning, and one of the other parents said, “Did you hear there was another shooting?” It sort of filtered through: “It sounds like another shooting.” “Another person died.” And there was a lot of sort of like, “This is just heavy.” “Awful.”

And then we got back from the race, and on a group chat, someone said, “ICE executed Alex Pretti.” [Editor’s note: It later became clear that the officers were with Customs and Border Protection.] It was from our group that we had had when we had first hired him to be study staff on our research project. It was like, What? You have to be kidding me.

I had seen one of the videos. [In it,] you can’t see the defined definitions of someone’s face and recognize them. But once the name was out there and I saw the build, the facial hair, it’s like, Oh, shit, that was Alex.

People have asked, “Are you surprised that he was protesting?” And, in all honesty, no one can be surprised that anyone in Minneapolis is protesting. We see 80-year-olds out protesting. We see kids out protesting. The city is pretty, pretty pissed off about what is happening, and people are out there doing their civic duty of being out there peacefully protesting.

Have you been able to watch the videos? I can’t stop myself watching the videos.

I don’t know how you watch someone you know—

I have not sought them out. I mean, my wife has shown me some, like, “Oh, God, with this new view you can see …” I’ve seen a few that way. It’s awful.

You posted on social media that you were feeling white-hot rage. What do you do with that feeling in this moment?

Right now, delay going to dinner with friends because I don’t feel terribly sociable. I’ve been really appreciative of people who have been reaching out to say, “Hey, sorry to hear—sounds like Alex was a great guy. This is hard.”

I think other people are enraged. I think the worst thing right now would be to have random violence. I’ve been really proud of Minneapolis—the scope and scale of the protests, the fact that they have been peaceful.

The administration has said your friend must have been trying to kill officers. Is there something you want to tell people who may have that belief about Alex?

The thing that I would say is that I have known Alex for years. I’ve known him to be a kind guy, a guy quick with a laugh, a joke, willing to help. He has never shared a conspiracy theory or shared anger at a group or been unpatriotic. I mean, he is the kind of guy that you would want as your neighbor and your friend. I would be thrilled if he were to move into the house next door.

We have a shared interest in mountain biking. We were planning on going out together. I was always the one who was having to say, “No, sorry, my kid has a race this week. Can’t do it.” But we liked the same trail systems, and we talked about riding them.

I have observed him clinically. He is fabulous, he gives great assessments, he’s enthusiastic, he is smart, and I will just say that anybody going into the ICU fresh out of nursing school—you’re gonna deal with very sick patients. A [large] percent of the patients in the ICU will die, and you’ll have to deal with grieving, upset families. You’ll have to use all your skills to try to keep that person alive. To do that right out of nursing school is impressive.

Sometimes medicine is a hierarchical place. He was not like that, and I loved that. I would run into him, and he would say, “Hey, Dimitri, how’s it going? It’s good to see you again.” I love that he had that informal relationship. I love it was modeled for trainees who worked with us. Like, yeah, this is how you do it: You’re colleagues, you’re friendly, you are nice to each other, and you work well together.

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-33')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">What Word Refers to Someone Who Has Supposedly Returned From the Dead?</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-33" style="display:none;">
            <h2>What Word Refers to Someone Who Has Supposedly Returned From the Dead?</h2>
            <p><strong>News and Politics - Slate Magazine | 2026-01-26</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2026/01/trivia-quiz-daily-slate-vocabulary-definitions-bible-synonyms.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Please enable Javascript in your browser to view Slate interactives.

Slate Crossword: Genre-Defying Film That Received a Record-Breaking 16 Oscar Nominations (Seven Letters)

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-34')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">Everyone Saw CBP Kill Alex Pretti</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-34" style="display:none;">
            <h2>Everyone Saw CBP Kill Alex Pretti</h2>
            <p><strong>News and Politics - Slate Magazine | 2026-01-26</strong></p>
            <a class="original-link" href="https://slate.com/podcasts/what-next/2026/01/why-dhs-is-refusing-to-investigate-the-killing-of-alex-pretti?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Another person is dead in Minneapolis. Will anyone see justice?

Please enable javascript to get your Slate Plus feeds.

If you can&#39;t access your feeds, please contact customer support.

Thanks! Check your phone for a link to finish setting up your feed.

Enter your phone number and we&#39;ll text you a link to set up the
        podcast in your app:

We&#39;ll only text you about setting up this podcast, no spam.

Apple Podcasts will only work on MacOS operating systems since Catalina. We do not support Android apps on desktop at this time.

These links will only work if you&#39;re on the device you listen to podcasts on.

We&#39;re sorry, but something went wrong while fetching your podcast feeds. Please contact us at plus@slate.com for help.

Once again, federal agents have shot and killed a legal observer in Minneapolis. Once again, the shooting is on video. And once again, the Trump Administration has closed ranks around the officers. But could the fallout from Alex Pretti’s death be different? And Minnesotans want to know – when will the feds finally leave?

Guest: Will Stancil, lawyer and observer in Minneapolis

Want more What Next? Subscribe to Slate Plus to access ad-free listening to the whole What Next family and across all your favorite Slate podcasts. Subscribe today on Apple Podcasts by clicking “Try Free” at the top of our show page. Sign up now at slate.com/whatnextplus to get access wherever you listen.

Podcast production by Elena Schwartz, Paige Osburn, Anna Phillips, Madeline Ducharme and Rob Gunther.

The problem with the news right now? It’s everywhere. And each day, it can feel like we’re all just mindlessly scrolling. It’s why we created What Next. This short daily show is here to help you make sense of things. When the news feels overwhelming, we’re here to help you answer: What next? Look for new episodes every weekday morning.

Mary Harris is the host and managing editor of What Next, Slate&#39;s new daily news podcast. She has reported throughout the public radio system, for NPR, Marketplace, and WNYC.</div>
        </div>
        
        <div class="card" onclick="openModal('content-35')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">Don’t Let Them Tell You That Was Self-Defense</div>
            <div class="meta">2026-01-25</div>
        </div>
        
        <div id="content-35" style="display:none;">
            <h2>Don’t Let Them Tell You That Was Self-Defense</h2>
            <p><strong>News and Politics - Slate Magazine | 2026-01-25</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2026/01/alex-pretti-execution-lie-self-defense-myths.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Sign up for the Slatest to get the most insightful analysis, criticism, and advice out there, delivered to your inbox daily.

Early Saturday morning in downtown Minneapolis, 37-year-old Alex Pretti was killed by federal agents in full public view. Within hours, Immigration and Customs Enforcement and Customs and Border Protection officials released a familiar statement: An agent, they said, had acted in lawful self-defense against an armed and violent agitator. According to this narrative, Pretti instigated the violence that led to his death. A multitude of videos filmed by witnesses from multiple angles show this to be a lie.

They show Alex Pretti holding up his phone, filming as masked ICE and CBP agents shove demonstrators and pepper-spray the crowd. They show an agent shoving a woman in the street. They show Pretti stepping forward, without striking anyone or reaching for a weapon, attempting to shield the woman from the agent’s blows. They show an agent spraying Pretti directly in the face with chemical irritant. They show Pretti being tackled to the ground. They show six or seven agents piling on top of him, striking him while he lies immobilized. And they show one agent removing Pretti’s licensed handgun—which he was carrying in compliance with state law—from his waistband.

Then, while he remains pinned to the pavement, helpless beneath a mass of armed bodies, gunshots ring out. Agents scatter, and one of them appears to clap. Pretti does not get up. This is not self-defense. It is much more akin to an execution.

Pretti was a licensed, law-abiding gun owner and registered nurse who worked at a veterans hospital.

The sequence of events matters, not only because it starkly contradicts the official account but because it exposes how the language of self-defense has been distorted to the point that it now functions as a near-automatic exoneration for state violence. When authorities invoke “self-defense” today, they rarely describe a factual necessity. They are deploying a rhetorical shield with deep historical roots and devastating contemporary consequences.

Just weeks earlier, on Jan. 7, Renee Good was shot three times and killed by an ICE agent as she attempted to flee in her car. In that case, too, officials framed the killing as justified and necessary, as self-defense rather than aggression. In that case, too, video evidence and eyewitness accounts—including an agent muttering “Fucking bitch” after the shooting—raised serious questions about the agents’ alleged “fear for their lives.” There is little to suggest that lethal force was unavoidable in this case, and yet Donald Trump’s Department of Justice is refusing to investigate the killing as a homicide. Instead, it is investigating Good’s widow. The pattern should be clear: Use an empty claim of self-defense to vindicate the shooter, then frame the victim as the perpetrator.

What we are witnessing is not a series of isolated tragedies. We have reached the logical end point of a political and legal culture that has long distorted claims of vulnerability, of “reasonable fear,” in the service of power, conflating aggressive, state-sanctioned violence with necessary self-protection.

From the nation’s founding, claims of self-defense have been used to justify extraordinary brutality. Systematic colonial violence against Indigenous nations was routinely rationalized as necessary to the protection of settler families and communities. Entire Indigenous communities were eradicated under the guise of lawful defense, with Indigenous resistance labeled “Savage Wars,” as a confrontation among equals rather than a genocidal onslaught.

After the Civil War, the Ku Klux Klan organized itself “to maintain forever the supremacy of the white race.” At the center of its mission lay the claim that white society required urgent protection from formerly enslaved people. Their founding documents emphasized “the sacred duty of protecting [white] womanhood” from sexual violence, with violence as necessary.

This mandate of protection congealed into widespread racial terror, claiming the lives of thousands of Black men, women, and children between Reconstruction and the mid-20th century. The Equal Justice Initiative estimates that 4,400 lynchings took place during this time period, which was also characterized by legalized segregation, mass disenfranchisement, economic coercion, and sexual violence perpetrated against Black women. And yet, when anti-lynching bills appeared before Congress—again and again—white leaders defended ritualized, spectacular acts of racial terror as a regrettable but necessary response to generally false claims of sexual violence by Black men against white women.

This “rape-lynch” mythology “that Negro men rape white women” was a “threadbare lie,” as journalist Ida B. Wells painstakingly documented in 1892, and she was almost murdered for speaking the truth. But truth was never the point. The claim of self-defense functioned as a form of camouflage to shroud the economic, political, and social project of keeping Black Americans subordinate under a blanket of legitimacy. It worked because enough people were willing to accept it, to pretend that racial terror was necessary to (white) public safety.

A similarly pernicious logic has insulated law enforcement from legal accountability for generations. Police violence, no matter how extreme, is routinely reframed as a defensive reaction to a threat rather than aggression. “The officer feared for his life.” “The suspect was reaching … for something.” “The situation escalated quickly, and the officer had no choice but to shoot.” The language is reflexive, ritualized, and remarkably effective. It is baked into our nation’s DNA to frame the victims of state-sanctioned violence as perpetrators.

In recent decades, that logic has been codified into law and expanded to select citizens through “Stand Your Ground” laws and permissive gun regulations that collapse the distinction between defense and dominance. These laws encourage armed confrontation while removing the legal duty to retreat or de-escalate. They transform subjective fear into legal justification while inviting ordinary citizens to imagine themselves as lone sentinels in a hostile world, as heroic “good guys with guns,” and as “armed citizens” exercising their Second Amendment rights. The laws reward those who act on that fantasy with legal immunity.

But only when they are acting in the service of repressive power. By all accounts, including the video evidence, Alex Pretti was a law-abiding good guy with a gun, who stepped in to protect an unarmed woman from an assault. He did not draw his weapon, nor did he attack the agents who disarmed him before shooting him multiple times while he was pinned to the ground.

What is new today is not the twisted rhetoric of self-defense but its escalation, and its targets. Masked federal agents, many of them poorly trained, now patrol public streets with military-grade weapons and broad discretionary authority. They detain, assault, and, increasingly, kill people based on vague or erroneous claims of public safety. They do so while invoking the same exonerating language that has long enabled state violence.

For generations, public state violence has been normalized precisely because it was disproportionately inflicted on nonwhite people, immigrants, low-income and other marginalized individuals. Many learned to look away or to justify this violence as the necessary price of “law and order.” Part of race and class privilege was the capacity to see such violence as a regrettable but necessary byproduct of maintaining order and keeping “us” safe.

We are now witnessing—some of us in incredulous horror—what happens when a society confuses authority with innocence and violence with virtue. We have built legal doctrines that reward escalation. We have granted weapons to institutions without demanding restraint. We have taught ourselves that “good guys” with guns will keep us safe from “bad guys.” Maybe now we are learning that the boundary separating the two was never clear in the first place.

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-36')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">Geothermal energy has the potential to reshape global power supply</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-36" style="display:none;">
            <h2>Geothermal energy has the potential to reshape global power supply</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2026-01-27</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2026-01-geothermal-energy-potential-reshape-global.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-37')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">How to include fossil fuel communities in Canada's clean energy transition</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-37" style="display:none;">
            <h2>How to include fossil fuel communities in Canada's clean energy transition</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2026-01-26</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2026-01-fossil-fuel-communities-canada-energy.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-38')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">Artificial metacognition: Giving an AI the ability to 'think' about its 'thinking'</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-38" style="display:none;">
            <h2>Artificial metacognition: Giving an AI the ability to 'think' about its 'thinking'</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2026-01-26</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2026-01-artificial-metacognition-ai-ability.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-39')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">Elastic metasurface can capture multiple frequencies at once</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-39" style="display:none;">
            <h2>Elastic metasurface can capture multiple frequencies at once</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2026-01-26</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2026-01-elastic-metasurface-capture-multiple-frequencies.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-40')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">Self-powered electronics: Organic semiconductors achieve both light emission and energy harvesting</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-40" style="display:none;">
            <h2>Self-powered electronics: Organic semiconductors achieve both light emission and energy harvesting</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2026-01-26</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2026-01-powered-electronics-semiconductors-emission-energy.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-41')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">Optimizing wastewater use for green hydrogen production: AI unlocks clean energy potential</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-41" style="display:none;">
            <h2>Optimizing wastewater use for green hydrogen production: AI unlocks clean energy potential</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2026-01-26</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2026-01-optimizing-wastewater-green-hydrogen-production.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-42')">
            <div class="source">The Register</div>
            <div class="title">Crossrail? More like Borkrail...</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-42" style="display:none;">
            <h2>Crossrail? More like Borkrail...</h2>
            <p><strong>The Register | 2026-01-27</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2026/01/27/crossrail_more_like_borkrail/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Bork!Bork!Bork! London&#39;s Elizabeth Line is the latest thing in urban development (at least as far as the UK is concerned). So it seems appropriate that its borks should be similarly up to date, and its emoticons rotated so the intent cannot be mistaken.

Sent in by an eagle-eyed Register reader, today&#39;s entry in the pantheon of bork was snapped at London&#39;s Paddington station, where a passenger can enjoy the delights of the UK&#39;s national rail network, as well as take a trip on a variety of London underground lines (aka the &quot;Tube&quot;) including the District, Metropolitan, and the increasingly inaccurately named Circle.

And no, the Elizabeth Line is in town, taking visitors from East to West and back again on trains with astonishingly uncomfortable seats and a bladder-bursting lack of toilet facilities.

And, it appears, some very unhappy information screens.

By our reckoning, that looks like a recent Windows 10 blue-screen-of-death, where Microsoft has attempted to hide what has befallen the device in question behind a sad emoticon and the friendly text &quot;Your PC ran into a problem.&quot;

Elizabeth line information screen BSOD - Click to enlarge

Something running into something else is never a thing a passenger wants to see on public transport, and we suspect that something has gone badly wrong behind the scenes. The stop code IRQL_NOT_LESS_OR_EQUAL usually happens when a process stomps over memory to which it should have access. Windows responds to such antics in time-honored fashion… by halting abruptly with a stop error.

However, look a little closer, and it seems there might be something more to this error. Aside from the fact that the user is being directed to http://windows.com/stopcode rather than something starting with https, several characters have been replaced with blocks, suggesting that a video driver or some video hardware is playing up.

Our reader, a former Vulture, didn&#39;t hang around to find out what happened if and when that percentage counter reached 100. After all, it takes a very special kind of nerd to hang around a station watching borked information signs.

However, we were saddened to see that for London&#39;s Elizabeth Line at least, that that cockroach of public transport, Windows 2000, appears to have been squashed once and for all. Had it endured a little longer, we&#39;re sure that the old thing would have kept on running or spared customers a cutesy emoticon where a hard-core technical error really belongs. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-43')">
            <div class="source">The Register</div>
            <div class="title">Vibe coding may be hazardous to open source</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-43" style="display:none;">
            <h2>Vibe coding may be hazardous to open source</h2>
            <p><strong>The Register | 2026-01-26</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2026/01/26/vibe_coding_hazardous_open_source/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Tailwind Labs CEO Adam Wathan recently blamed AI for forcing him to lay off three workers.

Tailwind Labs oversees the development of the open source Tailwind CSS framework. And according to Wathan, AI coding tools came between the company and its customers, reducing traffic to the website, which in turn hit product exposure.

&quot;Traffic to our docs is down about 40 percent from early 2023 despite Tailwind being more popular than ever,&quot; he wrote in a GitHub Issues post earlier this month. &quot;The docs are the only way people find out about our commercial products, and without customers we can&#39;t afford to maintain the framework.&quot;

A recent pre-print paper cites the situation at Tailwind Labs as evidence that the increasing adoption of AI coding tools represents a breaking change for the open source community.

The paper, titled Vibe Coding Kills Open Source, was written by Miklós Koren (Central European University, KRTK, CEPR and CESifo), Gábor Békés (Central European University, KRTK, and CEPR), Julian Hinz (Bielefeld University and Kiel Institute for the World Economy), and Aaron Lohmann (Kiel Institute for the World Economy).

Essentially, the paper argues that AI tools install open source dependencies in a way that comes between software developers and project maintainers, undermining interactions that potentially return value to those doing the work of software maintenance.

&quot;Vibe coding raises productivity by lowering the cost of using and building on existing code, but it also weakens the user engagement through which many maintainers earn returns,&quot; the authors argue. &quot;When OSS is monetized only through direct user engagement, greater adoption of vibe coding lowers entry and sharing, reduces the availability and quality of OSS, and reduces welfare despite higher productivity.&quot;

Co-author Koren, a professor of economics at Central European University in Vienna, Austria, told The Register in an email that evidence of AI tools weakening engagement with the open source community is mostly circumstantial.

&quot;There is a documented decline in Stack Overflow questions after the launch of ChatGPT; and it is faster than in countries where ChatGPT was not accessible,&quot; he said. &quot;There are many similar anecdotes circulating on social media. In fact, we started working on the paper before Tailwind&#39;s case became publicized.&quot;

Koren said the paper&#39;s findings represent an extrapolation about what he and his co-authors know given an economic model of the open source software ecosystem.

&quot;We know that developers have adopted vibe coding very fast,&quot; he said. &quot;[Anthropic CEO] Dario Amodei has famously said at the Axios AI+ Summit in September 2025 that &#39;70, 80, 90 percent of the code written in Anthropic is written by Claude.&#39; So users of vibe coding find it easy to switch to this mode of building software. This implies that human attention towards producers of OSS is shrinking.&quot;

The impact of that attention shift is not measured only in terms of revenue. Rather, it&#39;s assessed as an amalgamation of the rewards available to open source developers, such as community recognition, reputation, and job prospects, Koren said, pointing to a recent paper [PDF] that found &quot;only about 0.1 percent of the total value created by OSS developers is captured by them.&quot;

Koren said that the impact of the adoption of AI tools differs depending on the size and governance of the project.

&quot;High-quality projects can still thrive,&quot; he said. &quot;OSS developers need visibility of their project to gather useful feedback from users, recruit new developers and maintainers, and to garner kudos from the community. We don&#39;t think that large OSS projects will disappear overnight. But it will be harder to get beyond the &#39;cold start problem&#39; and get an otherwise promising project off the ground. Or maintainers of marginally successful projects may lose their motivation and stop contributing. The proverbial &#39;random person in Nebraska&#39; may give up.&quot;

Koren said this is a systematic issue that needs industry collective action.

&quot;Traditionally, OSS work is not directly compensated by users not because they don&#39;t value OSS, but because of the frictions involved,&quot; he explained. &quot;I may use dozens of libraries for any given project. I will not look up each individual maintainer and give them a fraction of a cent. There are ongoing funding drives at GitHub or npm, but these do not solve the problem because they still need the user to pay attention and to open their wallet.&quot;

But AI companies could help, Koren argues, noting that most LLM inference is done by a handful of large providers like OpenAI, Anthropic, or third-party providers like OpenRouter and Groq.

&quot;Metering the usage of each OSS library would be technically simple to do,&quot; he said. &quot;This could serve as the basis for a revenue-sharing deal. Much like Spotify pays artists based on playtime, OSS developers could share some of the LLM revenue based on actual usage.&quot;

Armin Ronacher, creator of Flask and an experienced open source developer, told The Register in an email that while AI has altered open source, he&#39;s reserving judgment.

&quot;AI is definitely changing a lot about the dynamics of open source,&quot; Ronacher said. &quot;In particular, it makes code cheaper and it changes the associated calculations. Open source right now sees a lot more low-quality contributions, but on the other hand, it might strengthen some key projects where trust comes from strong maintainers with a track record.

&quot;I think it&#39;s too early to say where this will land. This is a massive shift and we will see the effects in a few years. It will take some rewiring and it&#39;s very hard to come to conclusions until it all settles again.

&quot;In general I don&#39;t try to think much about alarmism on any of this right now. All the energy put into meta discussions right now seems wasted until we find a new normal.&quot; ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-44')">
            <div class="source">The Register</div>
            <div class="title">AWS's inevitable destiny: becoming the next Lumen</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-44" style="display:none;">
            <h2>AWS's inevitable destiny: becoming the next Lumen</h2>
            <p><strong>The Register | 2026-01-26</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2026/01/26/aws_destiny_lumen_corey_quinn/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">For a decade, AWS&#39;s position on multi-cloud was clear: don&#39;t.

Multi-cloud meant a lowest-common-denominator architecture. Multi-cloud meant giving up the managed services, the security integrations, the features that justified the lock-in. Multi-cloud was for that indecisive tranche of companies that couldn&#39;t commit. And until 2019, mentioning other clouds at all was forbidden at AWS conferences.

Then in November 2025, AWS launched AWS Interconnect with Google Cloud as a launch partner, with Microsoft Azure joining in 2026. Just a bit of jiggery-pokery in the console to connect your VPC to a competitor&#39;s network, and boom: the thing they spent years telling you was a mistake is now productized and fully managed. AWS didn&#39;t change its mind, so much as get told by about 84 percent of its customers to shut up and get with the times.

AWS has a tell: it markets hardest wherever it&#39;s losing.

Each time, the pattern holds. The louder the marketing, the weaker the position.

Here&#39;s the thing: Azure and Google aren&#39;t AWS&#39;s real problem.

The real problem is that developers don&#39;t choose AWS anymore (because honestly, given a choice between AWS and a vendor who thinks deeply about developer experience, who would?). They choose Vercel, or Netlify, or whatever their AI coding assistant suggests when they type &quot;deploy this.&quot; Heck, I have Strong Opinions about this and even I get tired of wrestling with Claude Code&#39;s biases; just make the container work already.

These platforms run on AWS Lambda under the hood. The serverless functions, the edge compute, the CDN — they&#39;re AWS infrastructure, abstracted into invisibility. Users never see it, never need an AWS account, never learn what a VPC is. Why would they?

One platform comparison put it bluntly: &quot;In 2026, most developers no longer ask &#39;How do I deploy this?&#39; They ask &#39;Which button do I click to ship to prod?&#39;&quot;

I don&#39;t put my infrastructure on AWS. I put it wherever the tool I&#39;m using wants to put it. Cursor suggests Vercel? Fine. Claude wants Netlify? Sure. The LLM is making the infrastructure decision now, and it&#39;s not optimizing for &quot;which cloud provider has the best managed Kafka offering.&quot; Vercel charges a 15-20 percent premium over raw AWS pricing. Customers pay it gladly for faster deployments. The margin accrues to the abstraction layer. AWS gets the commodity revenue underneath.

Quick: name a Tier 1 internet backbone provider.

If you said Lumen, Cogent, Telia, or NTT, congratulations — you&#39;re in the tiny minority of people who think about this. These companies own the undersea cables connecting continents and operate the networks that carry 99 percent of international internet traffic. Nobody thinks about them.

Because all the interesting stuff rides on top of them. And the margins follow the interesting stuff.

AWS is on that path. Today they&#39;re running 33-39 percent operating margins — genuinely impressive, making AWS the engine that funds Amazon&#39;s everything else. But they&#39;re also losing roughly 2 percent market share annually to Azure and Google, and that&#39;s just the competition they can see.

The competition they can&#39;t see is the abstraction layer that makes them irrelevant to the people actually building software. Every developer who ships via Vercel without knowing what region their Lambda runs in is a developer who will never care about AWS&#39;s 347 services. Every AI coding assistant that defaults to &quot;deploy to Netlify&quot; is training the next generation to treat cloud providers like plumbing.

AWS spent 2024 promising an AI future that 95 percent of enterprises aren&#39;t seeing ROI on, according to MIT&#39;s &quot;GenAI Divide&quot; study. They spent 2025 quietly accepting the multi-cloud reality they&#39;d fought for a decade. Now they&#39;re hoping you forgot.

Meanwhile, the October 2025 us-east-1 outage took down Snapchat, Fortnite, Ring doorbells, McDonald&#39;s mobile ordering, and Britain&#39;s tax website for fifteen hours (six and a half million Downdetector reports). It was the third major outage in five years from their oldest region. The institutional knowledge keeps walking out the door, and it shows.

But none of that matters if developers stop choosing AWS directly. In a world where nobody consciously selects their cloud provider, the only time AWS will have any relevance is when they fail. Outages become the brand.

AWS&#39;s destiny isn&#39;t to lose to Azure or Google. It&#39;s to win the infrastructure war and lose the relevance war. To become the next Lumen — the backbone nobody knows they&#39;re using, while the companies on top capture the margins and the mindshare.

The cables matter. But nobody&#39;s writing blog posts about them. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-45')">
            <div class="source">The Register</div>
            <div class="title">Canva among ~100 targets of ShinyHunters Okta identity-theft campaign</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-45" style="display:none;">
            <h2>Canva among ~100 targets of ShinyHunters Okta identity-theft campaign</h2>
            <p><strong>The Register | 2026-01-26</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2026/01/26/shinyhunters_okta_sso_campaign/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">ShinyHunters has targeted around 100 organizations in its latest Okta single sign-on (SSO) credential stealing campaign, according to researchers and the criminal group itself.

In a Monday report, Silent Push researchers said the identity-theft operation set its sights on more than 100 Okta SSO accounts across &quot;high-value enterprises.&quot; The cyber threat hunters also listed all of the companies across which they have &quot;detected active targeting or infrastructure preparation directed at your domain&quot; in the last 30 days.

We are not going to list all of the names - head over to the Silent Push blog to check out the organizations, which span multiple industries - but the technology and software firms include Atlassian, AppLovin, Canva, Epic Games, Genesys, HubSpot, Iron Mountain, RingCentral, and ZoomInfo.

To be clear: this doesn&#39;t mean any of these companies have been breached. &quot;We have no intel to share on any specific attacks and are unable to confirm if any have been successful,&quot; Silent Push senior threat researcher Zach Edwards told The Register. &quot;We do believe the orgs we&#39;ve listed on our public blog have been targeted.&quot;

ShinyHunters would not confirm how many companies it has breached using their Okta SSO credentials, nor say how many have been targeted in the campaign, but did tell The Register that 100 was &quot;close.&quot;

Google&#39;s Mandiant team also confirmed on Monday that it&#39;s &quot;tracking a new, ongoing ShinyHunters-branded campaign.&quot; It uses &quot;evolved&quot; voice-phishing techniques to &quot;compromise SSO credentials from victim organizations, and enroll threat actor controlled devices into victim MFA solutions,&quot; Mandiant Consulting CTO Charles Carmakal told The Register.

&quot;This is an active and ongoing campaign. After gaining initial access, these actors pivot into SaaS environments to exfiltrate sensitive data,&quot; he continued. &quot;An actor that identifies as ShinyHunters has approached some of the victim organizations with an extortion demand.&quot;

Carmakal added that while these identity attacks are not caused by a security flaw in the products or infrastructure, Mandiant &quot;strongly&quot; recommends organizations use phishing-resistant multi-factor authentication (MFA), such as FIDO2 security keys (like YubiKeys) or passkeys.

&quot;These protections are resistant to social engineering attacks in ways that push-based or SMS authentication are not,&quot; he said. &quot;Administrators should also implement strict app authorization policies and monitor logs for anomalous API activity or unauthorized device enrollments.&quot;

This latest ShinyHunters campaign came to light last week after Okta issued an alert about criminals voice-phishing for SSO credentials and using those to target organizations&#39; accounts. Okta declined to comment beyond its Thursday blog.

On Friday, ShinyHunters told The Register that it was behind the campaign, and said it had gained access to Crunchbase and Betterment by voice-phishing their Okta single sign-on codes. The criminals also leaked what they claimed to be more than 20 million records belonging to Betterment and 2 million belonging to Crunchbase. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-46')">
            <div class="source">The Register</div>
            <div class="title">How one developer used Claude to build a memory-safe extension of C</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-46" style="display:none;">
            <h2>How one developer used Claude to build a memory-safe extension of C</h2>
            <p><strong>The Register | 2026-01-26</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2026/01/26/trapc_claude_c_memory_safe_robin_rowe/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">feature TrapC, a memory-safe version of the C programming language, is almost ready for testing.

&quot;We&#39;re almost there,&quot; Robin Rowe told The Register in a phone interview. &quot;It almost works.&quot;

We caught up with Rowe, a computer science professor and entrepreneur, amid debugging efforts that had kept him up until four in the morning. The long-awaited TrapC website has appeared.

&quot;My work building TrapC has taken two parallel paths,&quot; Rowe explains in his initial post. &quot;A TrapC interpreter called itrapc and a separate compiler called trapc. I had wanted to make a software release by 1 January 2026, but too many bugs. I only reached code complete this month and am now on the painstaking and sleepless process of debugging. When I have something stable that mostly works I will make a release. Sorry to make you wait a little longer. Aiming for Q1 2026.&quot;

Back in November 2024, Rowe explained that he was working on TrapC. At the time, the public and private sector had undertaken a campaign to promote memory-safe software development as a way to reduce exposure to serious vulnerabilities.

Memory safety provides a way of ensuring that memory-related bugs like out-of-bounds reads/writes and use-after-free don&#39;t happen. In large codebases, like Chromium and Windows, most of the security vulnerabilities follow from memory bugs. As that message has been repeated in recent years, memory safety has become an imperative, evangelized by the likes of Google and Microsoft, and more recently by authorities in the US and elsewhere.

For at least the past ten years, there&#39;s been a rising chorus of voices calling for the adoption of memory-safe programming languages and techniques. This has meant encouraging developers to avoid languages like C and C++ where feasible, and to adopt languages like C#, Go, Java, Python, Swift, and Rust, instead, particularly for new projects.

To remain relevant, the C and C++ communities have tried to address those concerns with projects like TrapC, FilC, Mini-C, Safe C++, and C++ Profiles. There&#39;s also a C to Rust conversion project under development at DARPA called TRACTOR – TRanslating All C TO Rust.

But progress has been slow and those writing in C and C++ haven&#39;t found a widely accepted approach. The C++ standards committee recently rejected the Safe C++ proposal. And Rowe said he doubted TRACTOR would have anything to show this year.

Meanwhile, the clock is ticking. Microsoft engineer Galen Hunt last month said, &quot;My goal is to eliminate every line of C and C++ from Microsoft by 2030. Our strategy is to combine AI and algorithms to rewrite Microsoft&#39;s largest codebases.&quot;

&quot;There are some efforts to port C code by hand to Rust,&quot; said Rowe. &quot;But there&#39;re some real challenges to doing that because there are some idioms in C that cannot be expressed in Rust.

&quot;Rust is much more type safe than C is. And so if you have a void pointer, what does that mean in Rust? There&#39;s no translation for it. And that&#39;s how TrapC is fundamentally different because it actually remembers what that void pointer actually is.&quot;

Rowe said he expects TRACTOR will eventually be able to accomplish C to Rust translation using AI. But he said he thinks it&#39;s better to just build the necessary tooling into the C compiler, so you don&#39;t have to rely on some external tool that rewrites your code in an unfamiliar language.

Rowe has been using AI tools himself and has been teaching others to do so. This past semester, he taught AI Cybersecurity Programmer Analyst (PCO471) at Community College of Baltimore County – Linux administration using vibe coding in bash with no prerequisites. And starting in February, he&#39;s teaching C++ Programming with Generative AI (PCO472) – vibe coding in C++.

Rowe said programming has fundamentally changed as a result of AI tools. &quot;I think this is sort of the same type of discussion as when C came in and people said, &#39;Well, I&#39;m happy in assembly.&#39; There will still be people doing it the old way. But because vibe programming is so much more efficient on time when done correctly, there&#39;s gonna be no choice. You just won&#39;t be competitive if you&#39;re not vibe programming.&quot;

Then he shifted gears, slightly. &quot;But I have to walk that back a little bit because the reason I was up until four in the morning is I had vibe programming working on the Trap C compiler. And it took a fundamentally wrong design turn. And I didn&#39;t detect that it had made a design mistake. I had told it how I wanted to approach it. But somehow it misunderstood me or it forgot or something happened and I forgot to check. And so I spent hours doodling around in the debugger and trying to understand why code was acting weird before I finally looked at it and said, &#39;wait a minute, this isn&#39;t even the right design.&#39;&quot;

Rowe said a similar situation crops up in pair programming, where you&#39;ve told someone to do something and they didn&#39;t do it, and you don&#39;t realize that until later.

&quot;[C++ creator] Bjarne Stroustrup famously said that the most important thing in software design is to be clear about what you&#39;re trying to build,&quot; Rowe said. &quot;And vibe [programming] just puts that on steroids. Now we not only have to be ourselves clear, but we have to communicate it clearly to an LLM.&quot;

Rowe argues that developers have to be encouraged to try AI tools and to make mistakes. He recounted how during his AI Cybersecurity Programmer Analyst course, his students expressed interest in doing more hands-on work in lieu of lectures.

&quot;So I said, &#39;I&#39;ve got real servers on the internet that are my companies. I&#39;ll give you root,&#39;&quot; he recalled. &quot;I&#39;ll set loose students who know nothing on my own servers and hope for the best and we&#39;ll see how this goes. And the reaction was panic. I couldn&#39;t get past the timidity cliff.&quot;

Rowe said that what he learned from that exchange was that they didn&#39;t want their own hands-on, they wanted to watch him work.

&quot;I said to them, &#39;But guys, this is like learning to play the piano. You can&#39;t learn to play the piano by watching me. Yeah, you guys have to practice. And it&#39;s gonna be embarrassing at first. You know, you&#39;re gonna play a lot of bad notes and sound terrible. You have to get over that situation&#39;.&quot;

That&#39;s a scenario playing out in various companies where AI tools remain underutilized, for various reasons, including lack of training, security concerns, lack of utility, and poor tool design.

Rowe has traveled often to China to speak at the China Association of Higher Education conference. In December, he said, he was interviewed on China News Television about how China&#39;s plan for AI compares with America&#39;s.

In an email he explained, &quot;I said, &#39;China&#39;s AI-Plus plan calls for efficient AI on devices everywhere, from farm to factory to city, while the White House plan calls for building 500-billion-dollar cloud data centers ... using chips that will, inevitably, seem obsolete within two years.&#39;&quot;

Rowe argues China&#39;s approach will prevail and that the US has taken the wrong turn by focusing on centralized cloud datacenters to run LLMs. Within two years, he said, we&#39;ll have AI models we can run locally on our phones, with no need for network access for most tasks. Apple and Huawei, he said, are likely to be the winners in this scenario.

Rowe pointed to China&#39;s DeepSeek as an example. While it may not be quite as good as the leading US commercial models, he said, it runs with far less power.

&quot;This is a very Moore&#39;s Law type of strategy,&quot; he said. &quot;I remember when I had a Navy supercomputer in 1994. That was an amazing technology. But in 1995, Cray went bankrupt. There weren&#39;t enough buyers for it, even though it was an amazing device.

&quot;And now I&#39;ve got an iPhone that&#39;s in my pocket. That runs on a battery. It doesn&#39;t have a whole room devoted to it and exotic cooling and all kinds of stuff. And it&#39;s more powerful than that [the Cray from 1994]. So as a long-term strategy, you know, going toward the device makes a lot more sense, because that half-trillion dollar data center is going to be on my iPhone eventually.&quot;

Rowe also said that on the recommendation of a friend from his time at the AT&T DIRECTV Innovation Lab, he tried running Deepseek at a time when Claude wasn&#39;t available. Deepseek, he said, was able to find a bug that Claude couldn&#39;t.

&quot;Surprisingly, the bug was in code Claude had generated, that I had cut-and-pasted carelessly,&quot; he said. &quot;With hindsight it was a silly code mistake I should have caught, but was in an &#39;else&#39; branch outside where I was looking. I&#39;d not expected or intended to have Claude make any change to that block of code. And because the code was valid but the logic wrong, the compiler didn&#39;t catch it.&quot;

But the bug was obvious, he said, as soon as Deepseek pointed it out. He added, &quot;I&#39;m paying $200/year for Claude. Deepseek is free.&quot; ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-47')">
            <div class="source">The Register</div>
            <div class="title">Microsoft's Maia 200 promises Blackwell levels of performance for two-thirds the power</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-47" style="display:none;">
            <h2>Microsoft's Maia 200 promises Blackwell levels of performance for two-thirds the power</h2>
            <p><strong>The Register | 2026-01-26</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2026/01/26/microsoft_maia_200/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Microsoft on Monday unveiled a new in-house AI accelerator to rival Nvidia&#39;s Blackwell GPUs.

Fabbed on TSMC&#39;s N3 process node, Redmond&#39;s second-gen Maia 200 accelerator packs 144 billion transistors capable of churning out a collective 10 petaFLOPS of FP4 performance.

That puts the chip in direct contention with Nvidia&#39;s first-generation Blackwell GPUs, like the B200 — at least in terms of inference.

According to Scott Guthrie, EVP of cloud and AI at Microsoft, the chip has been &quot;specifically optimized for inferencing very large models, including both reasoning and chain of thought.&quot;

Compared to training, inference is much more sensitive to memory bandwidth. For each token (think words or punctuation) generated, the entirety of the model&#39;s active weights needs to be streamed from memory. Because of this, memory bandwidth puts an upper bound on how interactive — that&#39;s how many tokens per second per user — a system can generate.

To address this, Maia 200 has been equipped with 216GB of high-speed memory spread across what appears to be six HBM3e stacks, good for a claimed 7TB/s of bandwidth.

To put that in perspective, Nvidia&#39;s B200 GPUs offer between 180 GB and 192 GB of HBM3e with up to 8 TB/s of bandwidth each. More recent iterations of Blackwell increase this to 288 GB but bandwidth remains the same.

Microsoft is also keen to point out just how much more cost- and power-efficient Maia 200 is than competing accelerators.

&quot;Maia is 30 percent cheaper than any other AI silicon on the market today,&quot; Guthrie said in a promotional video.

At 750 watts, the chip uses considerably less power than either Nvidia&#39;s chips, which can chew through more than 1,200 watts each. This is low enough that Microsoft says Maia can be deployed in either air- or liquid-cooled datacenters.

However, it&#39;s important to remember that Maia is an inference chip. So while it may compare favorably to Nvidia&#39;s older Blackwell parts, it&#39;s not nearly as versatile.

Diving into the chip&#39;s speeds and feeds, we see Microsoft has made some significant concessions in order to maximize performance per watt.

The chip&#39;s tile tensor unit (TTU), which Microsoft calls a tensor core, supports only FP8, FP6, and FP4 datatypes in hardware. So while we still see a 2x jump in FLOPS from FP8 to FP4, workloads requiring 16- or 32-bit precision incur a stiff performance penalty, as they have to be computed on the chip&#39;s tile vector processors (TVPs).

Here&#39;s a quick rundown of the Maia 200&#39;s speeds and feeds - Click to enlarge

The good news is most LLM inference is now done at lower precisions than BF16. In fact, it&#39;s not uncommon for model weights to be stored in a 4-bit block floating point precision like NVFP4 or MXFP4, while the actual activations and KV caches (the model&#39;s short-term memory) are computed at a higher precision like MXFP8 in order to maintain accuracy.

Nonetheless, Microsoft isn&#39;t lying about this chip being an inference accelerator. Despite some advancements in ultra-low precision training, most GenAI models are still trained at higher precisions, with BF16 still the most common.

All of this is to say, while Maia 200 may be Microsoft&#39;s most competitive AI chip to date, don&#39;t expect Redmond to cut back its Nvidia GPU orders any time soon, especially with Rubin promised to deliver a 5x uplift in inference performance compared to either Blackwell or Maia 200 launching later this year.

Maia 200 doesn&#39;t just deliver more performance and memory than last-gen, it&#39;s also designed to scale to support massive multi-trillion parameter models.

Each Maia 200 is equipped with 2.8 TB/s of bidirectional bandwidth (1.4 TB/s in each direction), which enables it to pool its compute and memory resources across clusters of up to 6,144 chips. That works out to 61 exaFLOPS of AI compute and 1.3 petabytes of HBM3e.

This is achieved using an integrated Ethernet network on chip (NoC), which by our estimates either has 56 200 Gbps or 112 100 Gbps SerDes each. Running atop this is Microsoft&#39;s own AI transport layer protocol.

As strange as this might sound at a time when Nvidia is pushing NVLink Fusion and AMD UALink, it&#39;s not the first time we&#39;ve seen Ethernet used this way. AMD is tunneling UALink over Ethernet on its MI455X series chips, and you may recall that Intel used Ethernet for chip-to-chip communications on its Gaudi family of AI accelerators.

As for Microsoft&#39;s scale-up topology, the cloud giant says it&#39;s using a two-tier scale-up domain, which involves Ethernet packet switches. To us this sounds like a two-layer fat tree topology normally associated with scale-out networks.

To avoid performance bottlenecks in larger clusters, Microsoft can dynamically partition the Maia 200&#39;s 272 MB of SRAM into cluster level (CSRAM) and tile-level (TSRAM) pools.

The CSRAM pool functions as a buffer for collective communications, avoiding unnecessary data transfers between the speedy on chip memory and HBM. The TSRAM, meanwhile, serves as a cache for intermediary matrix multiplication operations and attention kernels.

We&#39;ve reached out to Microsoft for clarification on both its scale-up topology; we&#39;ll let you know if we hear anything back.

In any case, Microsoft&#39;s networking is clearly designed to ensure it can run even the largest frontier models for its customers, and that includes OpenAI&#39;s GPT-5.2.

Maia 200 is already running in Microsoft&#39;s Central region in Des Moines, Iowa, with plans to bring it to its West 3 region in Phoenix and other locations in the near future.

Alongside the new chips, Microsoft has also launched an SDK in preview to provide prospective customers the tools they need to start integrating the chip into their workflows – sign up to request access here. The company says the chip will support both PyTorch and Triton kernels, which should lower the barrier to adoption. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-48')">
            <div class="source">The Verge</div>
            <div class="title">TikTok is still down, here are all the latest updates</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-48" style="display:none;">
            <h2>TikTok is still down, here are all the latest updates</h2>
            <p><strong>The Verge | 2026-01-27</strong></p>
            <a class="original-link" href="https://www.theverge.com/news/868379/tiktok-us-trump-oracle-broken-rumors-power-outage">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">More than a day after TikTok’s issues began, TikTok USDS says the problems are the result of a power outage at a data center and subsequent cascading systems failure.

Starting early Sunday morning, TikTok’s now under new ownership US arm started breaking down just a couple of days after Oracle & Co took the reins. Its For You page algorithm is suddenly unreliable, while features like comments are failing to load or loading slowly, and publishing new videos seems nearly impossible for many people.

Rumors of censorship targeting anti-ICE protesting or attempting to block discussion of Jeffrey Epstein appear to be misguided (even the governor of California is resharing misinformation now), with problems blocking traffic to all kinds of videos and messages on the service through Monday night.

Read on below for the latest updates about the ongoing TikTok problems.

TikTok’s US service crashed early Sunday morning, and as of late Monday night, it still hasn’t fully recovered.

After finally announcing the problem started with a power outage at an unnamed partner’s data center, TikTok USDS followed up with an updated statement saying, “While the network has been recovered, the outage caused a cascading systems failure that we’ve been working to resolve together with our data center partner,” and listing some of the bugs users are experiencing. There’s still no ETA for a full fix.

Despite claims floating around social media, the truth is a bit more complicated, not least by the fact that TikTok in the US is still largely down, about a day and a half after its data center power outage problems started.

While tweets from random users, the governor of California, and PopBase claimed TikTok US DMs now censor “Epstein,” testing it from our end showed that its messaging feature bans many innocuous single-word messages, like “test.” Using the convicted sex offender’s name in a sentence, however, goes through unbanned.

TikTok says a power outage is causing ongoing issues and outages that started in the US early Sunday morning. In an email to The Verge, TikTok USDS spokesperson Jamie Favazza pointed to a statement posted to the joint venture’s newly-created X account, which says the company has been “working to restore our services following a power outage at a U.S. data center impacting TikTok and other apps we operate.”

On Sunday, many US users, including some of us here at The Verge, reported not being able to upload videos to TikTok or see most new videos, including new videos uploaded successfully by users from outside the US. Others said that their algorithm appeared to “reset,” though it’s unclear if that’s linked to the power outage, too.

TikTok has suffered from extensive problems on its first weekend after completing a transaction that changed the ownership of its US arm. According to Downdetector, the issues initially spiked in the early hours of Sunday morning, but many users, including editors here at The Verge, are still reporting errors.

On Monday morning, TikTok USDS head of communications Jamie Favazza responded to our inquiries, pointing to a post on a newly-created X account for the US joint venture that said its current issues are the result of a data center power outage.

Whether this is just a regular outage or a result of this week’s changes in management, reports tracked on Downdetector and Reddit confirm many people are having trouble loading TikTok right now.

If the mobile app loads, it’s not consistently showing comments or other features, and the algorithm managing the For You page doesn’t feel like it’s working correctly.

Update, January 26th: TikTok is still having problems in the US, which it says are connected to a data center power outage.

TikTok is officially under new ownership in the US, and that could spell big changes for the video-sharing app. On January 22nd, ByteDance – TikTok’s Chinese parent company — and a group of investors closed a $14 billion deal to spin off the platform’s US operations, introducing a new slate of American executives.

The Silver Lake investment firm, Abu Dhabi’s MGX, and the cloud giant Oracle will each have 15 percent stakes in the new TikTok US Data Security (USDS) Joint Venture LLC. ByteDance will still hold a 19.9 percent stake in the company, in line with the divest-or-ban law that went into effect last year — though the deal was pushed through with help from President Donald Trump in persistent disregard of the law.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-49')">
            <div class="source">The Verge</div>
            <div class="title">X faces EU investigation over Grok’s sexualized deepfakes</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-49" style="display:none;">
            <h2>X faces EU investigation over Grok’s sexualized deepfakes</h2>
            <p><strong>The Verge | 2026-01-26</strong></p>
            <a class="original-link" href="https://www.theverge.com/news/868239/x-grok-sexualized-deepfakes-eu-investigation">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The EU will look into whether Elon Musk’s platform ‘properly assessed and mitigated risks’ associated with Grok’s image editing tools.

The EU will look into whether Elon Musk’s platform ‘properly assessed and mitigated risks’ associated with Grok’s image editing tools.

X is facing an investigation from the European Commission over the sexualized deepfakes generated by its Grok AI chatbot. In its announcement, the Commission says it will evaluate whether X “properly assessed and mitigated risks” associated with Grok’s image-generating capabilities in the EU, as reported earlier by The New York Times.

Advocacy groups and lawmakers from around the world have raised the alarm on Grok’s AI image editing feature after it began complying with requests to generate sexualized images of women and minors on the platform. X later paywalled the ability to edit images in public replies to posts, but everyone can still generate images using Grok’s chatbot interface inside X.

The EU Commission will evaluate whether X violated the Digital Services Act, a set of rules that hold large online platforms legally accountable for the content posted to them. It’s also extending a broader 2023 investigation into X, which will now examine the platform’s Grok-powered recommendation system (The EU already fined X $140 million over “deceptive” blue checkmarks in connection with this probe).

“Sexual deepfakes of women and children are a violent, unacceptable form of degradation,” Henna Virkkunen, the EU Commission’s executive vice president for tech sovereignty, security, and democracy, says in the press release. “With this investigation, we will determine whether X has met its legal obligations under the DSA, or whether it treated rights of European citizens – including those of women and children – as collateral damage of its service.”

X could face fines of up to 6 percent of its annual global revenue if it’s once again found in violation of the DSA.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-50')">
            <div class="source">The Verge</div>
            <div class="title">The best Bluetooth trackers for Apple and Android phones</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-50" style="display:none;">
            <h2>The best Bluetooth trackers for Apple and Android phones</h2>
            <p><strong>The Verge | 2026-01-26</strong></p>
            <a class="original-link" href="https://www.theverge.com/23769840/best-bluetooth-trackers">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">For those of us who don’t ever seem to know where our keys or wallets have gone.

For those of us who don’t ever seem to know where our keys or wallets have gone.

If you buy something from a Verge link, Vox Media may earn a commission. See our ethics statement.

Some people rarely lose things. Wallets are always exactly where they’re supposed to be, keys never go missing, and remotes never slip between the couch cushions. And then there’s the rest of us — the folks who can’t ever seem to find the thing that was right there a few seconds ago. For us, there are Bluetooth trackers.

Bluetooth trackers have been around for a long time, and they all generally work the same way. You stick the tracker onto an object, pair it with your phone, and then, when you lose said object, you can go into an app and ring the tracker. But these days, Bluetooth trackers can do a lot more. Some have ultra-wideband chips that enable precision tracking, so you can find exactly where in a room your item is. Increasingly, trackers also tap into large networks — like Apple’s and Google’s — making it easier to locate lost items outside the home. Many will notify you if they detect you’ve left the device behind or come with QR codes that link to your contact information so people can easily return lost devices.

Bluetooth trackers are meant to find lost items. To test that, we lose items — both organically (some of us really do misplace wallets and keys daily) and in more controlled test environments. For the latter, one example is testing how these trackers perform in office environments or in multi-story houses. Sometimes, we also enlist the help of family and friends to “hide” objects to evaluate precision finding features. We’ll also enlist help to simulate and evaluate unwanted tracking alerts. In our testing, we’re also looking to assess factors like Bluetooth and network (ie., Find My, Tile, etc.) range, battery life, and how loud chimes / alerts are.

Are you limited to Bluetooth range, or can you make use of wider networks like Apple’s Find My, Google’s Find Hub network, or Amazon Sidewalk? Is it hard to hear the tracker when you ring it?

A technology that lets you track small objects can be abused to track people without their consent. Tracker companies know this, and an increasing number now come with anti-stalking features. These features may never prevent abuse 100 percent of the time, but we investigate whether these features were crafted with care, how well the company educates users about them, and if the company is proactive about updating them according to feedback from experts.

Do you need to pay a subscription fee to get all available features? If so, is it worth the moolah?

Most Bluetooth trackers last at least a year, but not all of them allow you to replace the battery. That means you have to buy a whole new tracker when the battery dies. I prefer the ability to replace batteries whenever possible.

These features are incredibly handy but also have the potential for misuse. Take AirTags. When Apple launched the trackers, it hadn’t anticipated they’d be used to track people or stolen items — but that’s exactly what happened. It’s since beefed up its anti-stalking features, and companies like Tile have also followed suit. Apple and Google have launched a standard that enables unwanted tracking alerts across both Android and iOS devices — and major players like Tile, Samsung, and Chipolo are on board. But until this standard is up and running, it pays to be aware of each tracker’s current approach when you’re deciding the best option for you.

As a consummate Loser of Things, I’ve tested my fair share of Bluetooth trackers on wallets, keys, and luggage. Here’s what I’d recommend if you, too, have a hard time finding things.

Apple’s AirTags can help you find your lost items with their ultra wideband technology. You’ll get the best compatibility with an iPhone, though Apple released an Android app that can detect an AirTag’s location and notify you if one seems to be following you.

When Apple launched AirTags in 2021, it really did shake up the category. That’s because AirTags are equipped with Apple’s Ultra Wideband (UWB) chip and tap into Apple’s vast Find My network. That’s a potent combo. And even though you can now get third-party accessories that work with the Find My network — including the Pebblebee trackers featured later in this guide — AirTags are still the best, thanks to UWB.

Basically, UWB enables precision tracking while Find My compatibility expands range far, far beyond Bluetooth’s limitations. With precision tracking, all you have to do is open the Find My app, tap “Find,” and you should see an arrow pointing you in the exact direction you need to go to find your item. Using the Find My network also means that so long as there’s an Apple device nearby, a lost AirTag can ping its location to Apple’s iCloud servers without notifying the owners of those other devices. And there are over a billion Apple products out there.

That accuracy is super convenient. My keys fell out of my pocket while running once, and I didn’t notice until my phone pinged me to say my keys were no longer with me. While I wasn’t able to use the precision tracking outdoors, I could see the last reported location in the Find My app. Twenty minutes had already passed, but I was still able to find my keys. I haven’t had that degree of success with any other item tracker.

However, this accuracy is a double-edged sword. In 2022, I ran a test to see whether I could track a friend and my spouse (with their consent) in real time. And I could, to a disturbing degree. While Apple’s unwanted tracking prevention measures worked, there were also inherent flaws. (You can read about our testing in full here.) However, Apple has since improved unwanted tracking alerts by shortening the time before you’re notified an unknown AirTag is in your vicinity, making chimes louder, and creating a separate app that lets Android users scan for unknown AirTags. Apple also now informs users during setup that unwanted tracking is a crime and that AirTags are “intended solely to track items that belong to you.”

Apple has also added more ways to share AirTag locations with trusted people. iOS 17 introduced AirTag sharing, which means shared items won’t trigger unwanted tracking alerts. As of iOS 18.2, you can also share the location of a lost AirTag with other people via a temporary link. So if an airline loses your luggage, you can send them a link to an interactive map showing your item’s last known location. (Apple is partnering with more than 15 airlines for this particular use case.)

The only thing I really don’t like about AirTags is that they aren’t truly $29. They’re $29, plus the cost of any accessory needed to attach them to the item you want to track. For example, you’ll need a holder to attach it to your keys or luggage. Thankfully, there’s a robust third-party accessory market, so you don’t have to pay Apple’s prices if you don’t want to. The fact that you can easily replace the battery with a regular CR2032 coin cell battery helps take the sting out, too. I’ve done it for two of my AirTags, and it’s much, much cheaper than buying two new ones.

All that being said, it’s worth noting that Apple just announced a new AirTag that costs $29 and still lacks a lanyard hole, meaning you’ll still need an accessory to attach it to anything. We’ll be testing it soon, but the key updates include a second-gen UWB chip for improved Precision Finding, helping you locate items from “50 percent farther away” using haptic, visual, and audio signals. It also features an upgraded Bluetooth chip that further expands its tracking range, along with an updated speaker that’s supposedly twice as loud.

The Tile Pro is the company’s loudest Bluetooth tracker and has the widest range at 400 feet. It also has a user-replaceable battery, unlike other Tiles.

More and more trackers now support both Google’s and Apple’s Find My networks, but Tile’s trackers — especially the $34.99 Tile Pro — are still our top recommendation for Android users or mixed iOS / Android households. Functionally, the platform-agnostic trackers can do just about anything an AirTag can. Like AirTags, Tile devices can tap into a larger network — in this case, the Tile Network and Amazon Sidewalk — to help you find your devices outside of your phone’s Bluetooth range. While this network isn’t as expansive as Apple’s or Google’s, Amazon Sidewalk’s coverage has improved significantly. When we tested Google’s Find Hub-compatible trackers — including the Chipolo Pop, Pebblebee Clip 5, and the Moto Tag — we found that Tile still did better at tracking items outside the home.

Unfortunately, Tile still can’t do true real-time tracking, and it still doesn’t offer a tracker with UWB, so it lacks the AirTag’s precision tracking. The company announced one back in 2021, but we’re still waiting, partly because Apple is effectively blocking UWB compatibility for third parties in iOS and because Tile’s priorities shifted once it was acquired by Life360.

In 2024, Google finally launched its Find My Device network, which was later renamed Find Hub. It works similarly to Apple’s Find My network: you’ll be able to share trackers with family members, and there are also unwanted tracking alerts.

Initially, the network lagged behind Apple’s, but it’s starting to catch up. After several weeks of testing Find Hub-compatible trackers — specifically the Chipolo Pop, Pebblebee Clip 5, and Moto Tag — in April, we found the network had improved significantly over the past year or so, especially in busy areas. Still, it’s clear Google prioritized privacy over precision.

Google is making some progress, though. In May, Google added UWB support for more precise tracking with Motorola’s Moto Tag and, eventually, other compatible phones and trackers. Google also rolled out satellite connectivity to Pixel 9 phones and newer devices in August, with the ability to share tracker locations with airline staff coming soon.

That said, Life360’s acquisition has brought some meaningful upgrades. Pressing a Tile button three times now sends an SOS alert to emergency contacts through Life360. You can also add others to your Circle so they can view and ring nearby Tiles on a shared Life360 map. More recently, Tile trackers have become fully integrated into Life360, letting users manage their trackers directly within the Life360 app. This merger unlocked a few premium features for free, including push alerts for forgotten items and two-day location history.

Still, most of the good stuff — like 30-day location history, unlimited sharing with friends and family, free replacements for damaged Tiles, and up to $100 reimbursement for lost items — sits behind a $29.99/year subscription. Fortunately, Tile offers new members a one-year trial, and a single subscription covers all your devices. You also still get a lot of core functionality without paying: you can find your Tile via Bluetooth, view its last known location on a map, ring your phone from the Tile, and share access with one other person for free.

Tile also stands out for its versatility. While AirTags come in a single puck-like design, Tile offers four distinct form factors to suit different needs. The card-shaped Tile Slim ($29.99), for example, is the best option if you’re constantly losing your wallet. The square Tile Mate ($24.99) comes with a hole so you can stick it on a key ring or carabiner, and is probably the most versatile. The $24.99 Tile Sticker, meanwhile, is a small disc that comes with a sticky backing so you can put it on remotes, pet collars, and anything else you can stick it on.

The best Tile will depend on what you’re looking to track. My personal favorite, however, is the $34.99 Tile Pro, which is shaped like a key fob, is larger than the Mate, and can also be attached to other items. Of the four, it has the longest Bluetooth range at 500 feet and the loudest ring. It’s also the only one that has a replaceable one-year CR2032 battery.

Last but not least, Tile may actually be better than AirTags for tracking stolen items. The company rolled out an anti-theft feature in 2023, which renders Tile devices invisible to unwanted tracking detection in the event someone steals your item. Just know that to use it, Tile requires you to submit a government ID for verification, agree to Tile working with law enforcement without a subpoena, and consent to a $1 million fine if you misuse this feature. For anti-stalking measures, Tile also has a “Scan and Secure” feature, which allows you to use the Tile app to scan for unknown Tile devices in your vicinity. While better than nothing, it’s a flawed measure, as it requires the potential victim to proactively scan their surroundings.

The Pebblebee Clip 5 supports Apple’s Find My and Google’s Find Hub networks, but also has a 500-foot Bluetooth range, LEDs that flash to help you locate it, and a rechargeable battery that lasts up to 12 months on a single charge.

If you’re looking for an AirTag or Tile alternative, the $34.99 Pebblebee Clip 5 is an excellent choice. It’s one of a growing number of trackers that support both Apple’s Find My and Google’s Find Hub networks, which is a major improvement over its predecessor. Setup is seamless for iOS and Android users, but because Pebblebee’s app doesn’t handle tracking, features like geofencing and safe locations depend on which network you choose. Apple’s Find My, for instance, supports “left behind” alerts and safe locations; Google’s Find Hub still lacks an equivalent.

The thing I like best about the Pebblebee Clip 5 is its rechargeable battery. It can last up to a year on a single charge, though you may get longer than that depending on your usage. It features a USB-C port, and Pebblebee advertises a Bluetooth range of up to 500 feet, which is 100 feet more than the Tile Pro, our pick for Android users. Additionally, the Clip 5 features a blinking LED strip that’s noticeably brighter than prior models and a significantly louder ringtone, making lost items easier to find, even in dark or noisy environments.

You can still use Pebblebee’s app to set voice tags, ask Amazon Alexa or Google Assistant for help, or double-tap the tracker to ring your phone. While the Clip 5 is larger than an AirTag, it also includes a snap-on key ring, so you don’t need to pay for an extra accessory just to attach it to your belongings. It’s also rated IP66 for dust and water resistance, making it slightly more durable than earlier Pebblebee trackers. ~ Sheena Vasani, Commerce Writer

The Pebblebee Card 5 has a rechargeable battery that lasts up to 18 months and supports wireless charging. It works with Apple’s Find My and Google’s Find Hub, but you can also use the Pebblebee app for voice tagging.

You could try stuffing an AirTag into a bifold wallet and hope it stays put — or opt for a Find My–compatible alternative that’s actually designed for wallets, like the $34.99 Pebblebee Card 5. It plays nicely with both Apple’s Find My and Google’s Find Hub networks, giving you cross-platform flexibility and the benefits of each, all with a super loud ringtone. It doesn’t offer precision tracking because it lacks UWB, but it makes up for it with said ringtones. It also supports unwanted tracking alerts as part of the Find My network.

The Card 5 stands out for its sleek design and wireless charging. At just 1.8mm thick, it’s one of the thinnest trackers you can buy and measures about the size of a credit card, meaning you can easily slip it into an overstuffed wallet packed to the brim with receipts, gift cards, and cash. The same can’t always be said of Tile’s wallet tracker, which is nearly twice as thick. What’s more, the Card 5 lasts up to 18 months on a single charge and supports wireless charging, so you don’t have to worry about replacing any batteries.

Unsurprisingly, the Card 5 shares many of the same strengths as the Pebblebee Clip 5, including support for the Pebblebee app and voice tagging. You also get a range of up to 500 feet, an IP66 rating for dust and water resistance, and a built-in button you can press to help locate your phone. ~ Sheena Vasani, Commerce Writer

The $29 Chipolo Pop offers a similar form factor to Apple’s AirTag in a lighter, more colorful package with a hole for a keychain or lanyard, a louder beep, and compatibility with both Apple’s Find My and Google’s Find Hub networks (though only one at a time). You can even use the Pop as a remote camera shutter and press the built-in button twice to find your lost phone. Unlike Chipolo’s other trackers, it boasts a wider 300-foot Bluetooth range, a more robust IP55 rating for water and dust resistance, and includes a user-replaceable battery that can last up to a year.

In my testing, tracking was accurate on both Apple’s and Google’s networks in most cases, Google’s struggled to track items outside my home as reliably as the Tile. And without UWB, the Pop couldn’t match the AirTag’s pinpoint precision. Still, the Chipolo app provides Android users with reliable out-of-range alerts and left-behind notifications — something Pebblebee and Moto Tag’s trackers lack —which, in my experience, triggered even faster than the AirTag and Tile.

If you’re willing to spend an extra $10, the $39 Chipolo Loop is very similar to the Chipolo Pop, with many of the same strengths and weaknesses. However, it charges via USB-C and includes a built-in silicone ring that’s easy to attach to keys, bags, and other items. You also get a more durable IP67 rating and an extra 100 feet of Bluetooth range — up to 400 feet total. Just note you’ll have to supply your own USB-C cable. ~ Sheena Vasani, Commerce Writer

If you’re a Samsung Galaxy phone user, the $29.99 Samsung SmartTag2 gets you UWB tracking and can tap into the Galaxy Find network, which operates similarly to Apple’s Find My network. It’s a great AirTag alternative but isn’t our overall pick for Android because it’s limited to Samsung Galaxy users. But for Samsung users, the latest SmartTag2 includes an improved Compass View, longer battery life, and a better app experience. It also has a newer, oblong design with a larger key ring than the original SmartTag.

Motorola’s $29.99 Moto Tag is the first tracker on Google’s Find Hub network to offer ultra wideband for locating lost items on phones equipped with a UWB chip, which is a feature Google only recently enabled via a firmware update. Like Apple’s AirTag, it can guide you directly to your missing item via directional cues in the Find Hub app. It worked well in my testing, helping me find the exact location of nearby items in my small apartment, though Apple’s AirTag was occasionally more precise when tracking objects farther away or through walls. The Moto Tag was also less effective than Tile’s trackers at locating items outside my home.

Still, if you want a tracker to find things around the house, the Moto Tag is a solid pick. It also fits most AirTag accessories, carries an IP67 rating for dust and water resistance, and uses a replaceable CR2032 battery that lasts up to a year. It can ring your misplaced phone, too, and doubles as a remote shutter for Motorola phones. ~ Sheena Vasani, Commerce Writer

The rechargeable Chipolo Card is also a good tracker for wallets. Priced at $39, it works with either Apple’s Find My or Google’s Find Hub network and carries an IP67 rating for dust and water resistance. It supports Qi wireless charging, unlike the Chipolo Loop, and features a slim design that slips neatly into your wallet. It also offers a 400-foot Bluetooth range — a bit less than the Pebblebee Card 5 — and lasts about six months per charge. Overall, it’s a solid choice if you want something simple, even if it lacks the QR code found on some competing trackers. ~ Sheena Vasani, Commerce Writer

Eufy’s rechargeable $34.99 SmartTrack Card E30 is another good option for wallets, one that offers the same Find My network benefits as the aforementioned Pebblebee Card 5. On the back, there’s also a QR code — similar to the ones Tile uses — that helps good Samaritans return your item to you. Like the Pebblebee’s newest offerings, you can share it with multiple people if you set it up via the Eufy Security app. The bummer here is that it doesn’t work with Android and lacks UWB.

Update, January 26th: Adjusted pricing / availability and added the Pebblebee Clip 5, Pebblebee Card 5, and Chipolo Card to our list of recommendations. We also mentioned Apple’s latest AirTag and removed a pair of former Chipolo picks.

Sign up for Verge Deals to get deals on products we’ve tested sent to your inbox weekly.</div>
        </div>
        
        <div class="card" onclick="openModal('content-51')">
            <div class="source">The Verge</div>
            <div class="title">OpenAI’s president is a Trump mega-donor</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-51" style="display:none;">
            <h2>OpenAI’s president is a Trump mega-donor</h2>
            <p><strong>The Verge | 2026-01-26</strong></p>
            <a class="original-link" href="https://www.theverge.com/ai-artificial-intelligence/867947/openai-president-greg-brockman-trump-super-pac">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Greg Brockman said he started “getting involved politically” in 2025.

Greg Brockman said he started “getting involved politically” in 2025.

OpenAI’s co-founder and longtime president, Greg Brockman, didn’t just make a run-of-the-mill donation to the main pro-Trump super PAC — together, he and his wife Anna’s September 2025 donations equaled the largest of them all, totaling $25 million to “MAGA Inc.,” per a recent filing. The Brockmans’ donations made up nearly one-fourth of the six-month fundraising cycle.

It’s the latest in a string of examples of tech executives cozying up to President Trump’s administration, happening as the administration pushes to aggressively back the AI industry and defang state-level regulations that companies like OpenAI have largely opposed. OpenAI did not immediately respond to a request for comment.

Brockman’s multimillion-dollar donation isn’t the only example of him spending big, under his own name, on lobbying efforts that have their sights set on dismantling potential AI industry regulation. The pro-AI super PAC “Leading the Future,” of which Brockman is a significant backer, has bought ads targeting New York State Assemblymember Alex Bores — a cosponsor of New York’s RAISE Act, which was watered down at the last minute after coordinated lobbying efforts.

Though news of the Brockmans’ donations first broke earlier this month, it’s seen a resurgence in online discussion after the recent death of Alex Pretti in Minneapolis, where federal officers have fatally shot two people during an anti-immigrant crackdown. Tech workers from across the industry, including multiple employees at OpenAI, have signed a letter calling for their CEOs to cancel all contracts with Immigration and Customs Enforcement (ICE) and publicly condemn the department’s actions. “When Trump threatened to send the national guard to San Francisco in October, tech industry leaders called the White House,” the petition’s website states. “It worked: Trump backed down. Today we’re calling on our CEOs to pick up the phone again.”

However, since Trump’s inauguration, tech leader after tech leader has donated to his inauguration fund, flocked to Mar-a-Lago to meet with him, or attended White House dinners by his side. In return, they’ve gotten an administration eager to roll back consumer protections and tech regulation. Trump’s AI Action Plan resurrected a failed Republican attempt to bar states from passing AI regulations, to tech leaders’ delight. The new provision states that “AI is far too important to smother in bureaucracy at this early stage” and that the government “should not allow AI-related Federal funding to be directed toward states with burdensome AI regulations that waste these funds,” though it should also “not interfere with states’ rights to pass prudent laws that are not unduly restrictive to innovation.” Targets of the moratorium include SB 53, the landmark AI transparency bill California Gov. Gavin Newsom signed in September despite many tech companies lobbying against it, including OpenAI.

In 2019, Brockman co-wrote a blog post about how hard it is to “change powerful systems … once they’ve been deployed,” and that it’s “important to address AGI’s safety and policy risks before it is created.” Six years later, his posts have shifted in tone, highlighting the importance of “approach[ing] emerging technology with a growth-focused mindset.” In a New Year’s Eve post on X, Brockman wrote that “this year, my wife Anna and I started getting involved politically, including through political contributions, reflecting support for policies that advance American innovation and constructive dialogue between government and the technology sector.” He added that “it’s been great to see the president’s and his administration’s willingness to engage directly with the AI community.”

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-52')">
            <div class="source">The Verge</div>
            <div class="title">Google will settle its Assistant spying lawsuit for $68 million</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-52" style="display:none;">
            <h2>Google will settle its Assistant spying lawsuit for $68 million</h2>
            <p><strong>The Verge | 2026-01-26</strong></p>
            <a class="original-link" href="https://www.theverge.com/news/868078/google-assistant-lawsuit-settlement">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The class-action was spurred by a 2019 report about human contractors listening to recordings made when devices like Pixel phones or Google Home speakers were triggered inadvertently.

The class-action was spurred by a 2019 report about human contractors listening to recordings made when devices like Pixel phones or Google Home speakers were triggered inadvertently.

Google could owe you some money, now that it’s moving to settle a class-action lawsuit over how it handled recordings captured when its devices were activated by something other than Google Assistant’s actual trigger word, “Ok Google.” German outlet VRT NWS’s 2019 report exposed the issue, and court filings from last Friday say the proposed settlement number is $68 million, as reported previously by Reuters.

The lawsuit accuses Google of “unlawful and intentional recording of individuals’ confidential communications without their consent,” during these “False Accepts.” VRT NWS reported that human workers who analyzed Assistant audio clips recalled hearing personal information and private conversations in instances where Google Assistant was triggered inadvertently or by someone who wasn’t supposed to be using it, like children.

The plaintiffs’ accusations had also included a claim that “information gleaned from these recordings was wrongly transmitted to third parties for targeted advertising and for other purposes,” which Google denied, and in the proposed settlement, it denies any allegations of wrongdoing.

Google, Apple, and Amazon all faced accusations of inadvertent recordings tied to trigger words for their AI helpers being shared for review by human contractors in 2019. Apple settled a similar class-action lawsuit in January 2025 for $95 million, and continued to refute rumors it used recordings to target ads. These days, Siri is in line for a generative AI upgrade, Alexa’s is rolling out, and Assistant is slowly being shoved aside in favor of Gemini.

If the settlement is approved, it will be paid out to people whose Google accounts were associated with at least one device with Google Assistant pre-installed as early as 2016, including Pixel phones, Google Home devices, Google smart speakers and smart displays, Nest Hub, and Nest Hub Max. Customers who purchased one of these devices will be eligible for a recovery payout of $18 to $56. Anyone who used Google Assistant or lived in a household with an Assistant device that illegally recorded their conversations will also be eligible for a payout of $2 to $10.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-53')">
            <div class="source">The Verge</div>
            <div class="title">Apple’s luxe AirPods Max have dropped to one of their lowest prices ever</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-53" style="display:none;">
            <h2>Apple’s luxe AirPods Max have dropped to one of their lowest prices ever</h2>
            <p><strong>The Verge | 2026-01-26</strong></p>
            <a class="original-link" href="https://www.theverge.com/gadgets/868017/apple-airpods-max-usb-c-best-buy-flash-deal-sale">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">You have until January 28th to take advantage of the deal.

You have until January 28th to take advantage of the deal.

If you buy something from a Verge link, Vox Media may earn a commission. See our ethics statement.

If you prefer over-ear headphones to earbuds and own an iPhone or another Apple device, the AirPods Max with USB-C are worth a look, especially now that you can buy them at Best Buy as part of a flash deal for $429.99 ($120 off) through tomorrow, January 27th. That’s $30 shy of their lowest price to date, and a notable deal given these over-ears don’t often drop below $449.99 outside of big sales events.

The AirPods Max stand out thanks to their premium design, which uses premium materials like aluminum, steel, and fabric that feel more high-end than plastic rivals from Sony and Bose. They’re also one of the few pairs of over-ear headphones designed to work seamlessly with Apple gadgets, thanks to features like automatic device switching and hands-free Siri access. Additionally, they can tap into Apple’s Find My network and the company’s nifty audio sharing feature, which lets two pairs of AirPods or Beats headphones listen from a single iPhone or iPad.

In terms of audio, the AirPods Max deliver well-balanced, natural sound with support for 24-bit / 48kHz lossless audio playback over USB-C, so you can listen to compatible songs with better detail and clarity. They also continue to deliver top-tier noise cancellation, support ultra-low latency audio, and feature a clear transparency mode, making them a great all-around option for Apple users.

Sign up for Verge Deals to get deals on products we’ve tested sent to your inbox weekly.

Sign up for Verge Deals to get deals on products we’ve tested sent to your inbox weekly.</div>
        </div>
        
        <div class="card" onclick="openModal('content-54')">
            <div class="source">MIT Technology Review</div>
            <div class="title">Inside OpenAI’s big play for science</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-54" style="display:none;">
            <h2>Inside OpenAI’s big play for science</h2>
            <p><strong>MIT Technology Review | 2026-01-26</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2026/01/26/1131728/inside-openais-big-play-for-science/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">In the three years since ChatGPT’s explosive debut, OpenAI’s technology has upended a remarkable range of everyday activities at home, at work, in schools—anywhere people have a browser open or a phone out, which is everywhere.

Now OpenAI is making an explicit play for scientists. In October, the firm announced that it had launched a whole new team, called OpenAI for Science, dedicated to exploring how its large language models could help scientists and tweaking its tools to support them.

The last couple of months have seen a slew of social media posts and academic publications in which mathematicians, physicists, biologists, and others have described how LLMs (and OpenAI’s GPT-5 in particular) have helped them make a discovery or nudged them toward a solution they might otherwise have missed. In part, OpenAI for Science was set up to engage with this community.

And yet OpenAI is also late to the party. Google DeepMind, the rival firm behind groundbreaking scientific models such as AlphaFold and AlphaEvolve, has had an AI-for-science team for years. (When I spoke to Google DeepMind’s CEO and cofounder Demis Hassabis in 2023 about that team, he told me: “This is the reason I started DeepMind … In fact, it’s why I’ve worked my whole career in AI.”)

So why now? How does a push into science fit with OpenAI’s wider mission? And what exactly is the firm hoping to achieve?

I put these questions to Kevin Weil, a vice president at OpenAI who leads the new OpenAI for Science team, in an exclusive interview last week.

Weil is a product guy. He joined OpenAI a couple of years ago as chief product officer after being head of product at Twitter and Instagram. But he started out as a scientist. He got two-thirds of the way through a PhD in particle physics at Stanford University before ditching academia for the Silicon Valley dream. Weil is keen to highlight his pedigree: “I thought I was going to be a physics professor for the rest of my life,” he says. “I still read math books on vacation.”

Asked how OpenAI for Science fits with the firm’s existing lineup of white-collar productivity tools or the viral video app Sora, Weil recites the company mantra: “The mission of OpenAI is to try and build artificial general intelligence and, you know, make it beneficial for all of humanity.”

Just imagine the future impact this technology could have on science he says: New medicines, new materials, new devices. “Think about it helping us understand the nature of reality, helping us think through open problems. Maybe the biggest, most positive impact we’re going to see from AGI will actually be from its ability to accelerate science.”

He adds: “With GPT-5, we saw that becoming possible.”

As Weil tells it, LLMs are now good enough to be useful scientific collaborators. They can spitball ideas, suggest novel directions to explore, and find fruitful parallels between new problems and old solutions published in obscure journals decades ago or in foreign languages.

That wasn’t the case a year or so ago. Since it announced its first so-called reasoning model—a type of LLM that can break down problems into multiple steps and work through them one by one—in December 2024, OpenAI has been pushing the envelope of what the technology can do. Reasoning models have made LLMs far better at solving math and logic problems than they used to be. “You go back a few years and we were all collectively mind-blown that the models could get an 800 on the SAT,” says Weil.

But soon LLMs were acing math competitions and solving graduate-level physics problems. Last year, OpenAI and Google DeepMind both announced that their LLMs had achieved gold-medal-level performance in the International Math Olympiad, one of the toughest math contests in the world. “These models are no longer just better than 90% of grad students,” says Weil. “They’re really at the frontier of human abilities.”

That’s a huge claim, and it comes with caveats. Still, there’s no doubt that GPT-5, which includes a reasoning model,  is a big improvement on GPT-4 when it comes to complicated problem-solving. Measured against an industry benchmark known as GPQA, which includes more than 400 multiple-choice questions that test PhD-level knowledge in biology, physics, and chemistry, GPT-4 scores 39%, well below the human-expert baseline of around 70%. According to OpenAI, GPT-5.2 (the latest update to the model, released in December) scores 92%.

The excitement is evident—and perhaps excessive. In October, senior figures at OpenAI, including Weil, boasted on X that GPT-5 had found solutions to several unsolved math problems. Mathematicians were quick to point out that in fact what GPT-5 appeared to have done was dig up existing solutions in old research papers, including at least one written in German. That was still useful, but it wasn’t the achievement OpenAI seemed to have claimed. Weil and his colleagues deleted their posts.

Now Weil is more careful. It is often enough to find answers that exist but have been forgotten, he says: “We collectively stand on the shoulders of giants, and if LLMs can kind of accumulate that knowledge so that we don’t spend time struggling on a problem that is already solved, that’s an acceleration all of its own.”

He plays down the idea that LLMs are about to come up with a game-changing new discovery. “I don’t think models are there yet,” he says. “Maybe they’ll get there. I’m optimistic that they will.”

But, he insists, that’s not the mission: “Our mission is to accelerate science. And I don’t think the bar for the acceleration of science is, like, Einstein-level reimagining of an entire field.”

For Weil, the question is this: “Does science actually happen faster because scientists plus models can do much more, and do it more quickly, than scientists alone? I think we’re already seeing that.”

In November, OpenAI published a series of anecdotal case studies contributed by scientists, both inside and outside the company, that illustrated how they had used GPT-5 and how it had helped. “Most of the cases were scientists that were already using GPT-5 directly in their research and had come to us one way or another saying, ‘Look at what I’m able to do with these tools,’” says Weil.

The key things that GPT-5 seems to be good at are finding references and connections to existing work that scientists were not aware of, which sometimes sparks new ideas; helping scientists sketch mathematical proofs; and suggesting ways for scientists to test hypotheses in the lab.

“GPT 5.2 has read substantially every paper written in the last 30 years,” says Weil. “And it understands not just the field that a particular scientist is working in; it can bring together analogies from other, unrelated fields.”

“That’s incredibly powerful,” he continues. “You can always find a human collaborator in an adjacent field, but it’s difficult to find, you know, a thousand collaborators in all thousand adjacent fields that might matter. And in addition to that, I can work with the model late at night—it doesn’t sleep—and I can ask it 10 things in parallel, which is kind of awkward to do to a human.”

Most of the scientists OpenAI reached out to back up Weil’s position.

Robert Scherrer, a professor of physics and astronomy at Vanderbilt University, only played around with ChatGPT for fun (“I used to it rewrite the theme song for Gilligan’s Island in the style of Beowulf, which it did very well,” he tells me) until his Vanderbilt colleague Alex Lupsasca, a fellow physicist who now works at OpenAI, told him that GPT-5 had helped solve a problem he’d been working on.

Lupsasca gave Scherrer access to GPT-5 Pro, OpenAI’s $200-a-month premium subscription. “It managed to solve a problem that I and my graduate student could not solve despite working on it for several months,” says Scherrer.

It’s not perfect, he says: “GTP-5 still makes dumb mistakes. Of course, I do too, but the mistakes GPT-5 makes are even dumber.” And yet it keeps getting better, he says: “If current trends continue—and that’s a big if—I suspect that all scientists will be using LLMs soon.”

Derya Unutmaz, a professor of biology at the Jackson Laboratory, a nonprofit research institute, uses GPT-5 to brainstorm ideas, summarize papers, and plan experiments in his work studying the immune system. In the case study he shared with OpenAI, Unutmaz used GPT-5 to analyze an old data set that his team had previously looked at. The model came up with fresh insights and interpretations.

“LLMs are already essential for scientists,” he says. “When you can complete analysis of data sets that used to take months, not using them is not an option anymore.”

Nikita Zhivotovskiy, a statistician at the University of California, Berkeley, says he has been using LLMs in his research since the first version of ChatGPT came out.

Like Scherrer, he finds LLMs most useful when they highlight unexpected connections between his own work and existing results he did not know about. “I believe that LLMs are becoming an essential technical tool for scientists, much like computers and the internet did before,” he says. “I expect a long-term disadvantage for those who do not use them.”

But he does not expect LLMs to make novel discoveries anytime soon. “I have seen very few genuinely fresh ideas or arguments that would be worth a publication on their own,” he says. “So far, they seem to mainly combine existing results, sometimes incorrectly, rather than produce genuinely new approaches.”

I also contacted a handful of scientists who are not connected to OpenAI.

Andy Cooper, a professor of chemistry at the University of Liverpool and director of the Leverhulme Research Centre for Functional Materials Design, is less enthusiastic. “We have not found, yet, that LLMs are fundamentally changing the way that science is done,” he says. “But our recent results suggest that they do have a place.”

Cooper is leading a project to develop a so-called AI scientist that can fully automate parts of the scientific workflow. He says that his team doesn’t use LLMs to come up with ideas. But the tech is starting to prove useful as part of a wider automated system where an LLM can help direct robots, for example.

“My guess is that LLMs might stick more in robotic workflows, at least initially, because I’m not sure that people are ready to be told what to do by an LLM,” says Cooper. “I’m certainly not.”

LLMs may be becoming more and more useful, but caution is still key. In December, Jonathan Oppenheim, a scientist who works on quantum mechanics, called out a mistake that had made its way into a scientific journal. “OpenAI leadership are promoting a paper in Physics Letters B where GPT-5 proposed the main idea—possibly the first peer-reviewed paper where an LLM generated the core contribution,” Oppenheim posted on X. “One small problem: GPT-5’s idea tests the wrong thing.”

He continued: “GPT-5 was asked for a test that detects nonlinear theories. It provided a test that detects nonlocal ones. Related-sounding, but different. It’s like asking for a COVID test, and the LLM cheerfully hands you a test for chickenpox.”

It is clear that a lot of scientists are finding innovative and intuitive ways to engage with LLMs. It is also clear that the technology makes mistakes that can be so subtle even experts miss them.

Part of the problem is the way ChatGPT can flatter you into letting down your guard. As Oppenheim put it: “A core issue is that LLMs are being trained to validate the user, while science needs tools that challenge us.” In an extreme case, one individual (who was not a scientist) was persuaded by ChatGPT into thinking for months that he’d invented a new branch of mathematics.

Of course, Weil is well aware of the problem of hallucination. But he insists that newer models are hallucinating less and less. Even so, focusing on hallucination might be missing the point, he says.

“One of my teammates here, an ex math professor, said something that stuck with me,” says Weil. “He said: ‘When I’m doing research, if I’m bouncing ideas off a colleague, I’m wrong 90% of the time and that’s kind of the point. We’re both spitballing ideas and trying to find something that works.’”

“That’s actually a desirable place to be,” says Weil. “If you say enough wrong things and then somebody stumbles on a grain of truth and then the other person seizes on it and says, ‘Oh, yeah, that’s not quite right, but what if we—’ You gradually kind of find your trail through the woods.”

This is Weil’s core vision for OpenAI for Science. GPT-5 is good, but it is not an oracle. The value of this technology is in pointing people in new directions, not coming up with definitive answers, he says.

In fact, one of the things OpenAI is now looking at is making GPT-5 dial down its confidence when it delivers a response. Instead of saying Here’s the answer, it might tell scientists: Here’s something to consider.

“That’s actually something that we are spending a bunch of time on,” says Weil. “Trying to make sure that the model has some sort of epistemological humility.”

Another thing OpenAI is looking at is how to use GPT-5 to fact-check GPT-5. It’s often the case that if you feed one of GPT-5’s answers back into the model, it will pick it apart and highlight mistakes.

“You can kind of hook the model up as its own critic,” says Weil. “Then you can get a workflow where the model is thinking and then it goes to another model, and if that model finds things that it could improve, then it passes it back to the original model and says, ‘Hey, wait a minute—this part wasn’t right, but this part was interesting. Keep it.’ It’s almost like a couple of agents working together and you only see the output once it passes the critic.”

What Weil is describing also sounds a lot like what Google DeepMind did with AlphaEvolve, a tool that wrapped the firms LLM, Gemini, inside a wider system that filtered out the good responses from the bad and fed them back in again to be improved on. Google DeepMind has used AlphaEvolve to solve several real-world problems.

OpenAI faces stiff competition from rival firms, whose own LLMs can do most, if not all, of the things it claims for its own models. If that’s the case, why should scientists use GPT-5 instead of Gemini or Anthropic’s Claude, families of models that are themselves improving every year? Ultimately, OpenAI for Science may be as much an effort to plant a flag in new territory as anything else. The real innovations are still to come.

“I think 2026 will be for science what 2025 was for software engineering,” says Weil. “At the beginning of 2025, if you were using AI to write most of your code, you were an early adopter. Whereas 12 months later, if you’re not using AI to write most of your code, you’re probably falling behind. We’re now seeing those same early flashes for science as we did for code.”

He continues: “I think that in a year, if you’re a scientist and you’re not heavily using AI, you’ll be missing an opportunity to increase the quality and pace of your thinking.”

Four ways to think about this year&#39;s reckoning.

Our AI writers make their big bets for the coming year—here are five hot trends to watch.

By studying large language models as if they were living things instead of computer programs, scientists are discovering some of their secrets for the first time.

In an exclusive interview, the AI pioneer shares his plans for his new Paris-based company, AMI Labs.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-55')">
            <div class="source">MIT Technology Review</div>
            <div class="title">Why chatbots are starting to check your age</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-55" style="display:none;">
            <h2>Why chatbots are starting to check your age</h2>
            <p><strong>MIT Technology Review | 2026-01-26</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2026/01/26/1131726/why-chatbots-are-starting-to-check-your-age/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first, sign up here.

How do tech companies check if their users are kids?

This question has taken on new urgency recently thanks to growing concern about the dangers that can arise when children talk to AI chatbots. For years Big Tech asked for birthdays (that one could make up) to avoid violating child privacy laws, but they weren’t required to moderate content accordingly. Two developments over the last week show how quickly things are changing in the US and how this issue is becoming a new battleground, even among parents and child-safety advocates.

In one corner is the Republican Party, which has supported laws passed in several states that require sites with adult content to verify users’ ages. Critics say this provides cover to block anything deemed “harmful to minors,” which could include sex education. Other states, like California, are coming after AI companies with laws to protect kids who talk to chatbots (by requiring them to verify who’s a kid). Meanwhile, President Trump is attempting to keep AI regulation a national issue rather than allowing states to make their own rules. Support for various bills in Congress is constantly in flux.

So what might happen? The debate is quickly moving away from whether age verification is necessary and toward who will be responsible for it. This responsibility is a hot potato that no company wants to hold.

In a blog post last Tuesday, OpenAI revealed that it plans to roll out automatic age prediction. In short, the company will apply a model that uses factors like the time of day, among others, to predict whether a person chatting is under 18. For those identified as teens or children, ChatGPT will apply filters to “reduce exposure” to content like graphic violence or sexual role-play. YouTube launched something similar last year.

If you support age verification but are concerned about privacy, this might sound like a win. But there&#39;s a catch. The system is not perfect, of course, so it could classify a child as an adult or vice versa. People who are wrongly labeled under 18 can verify their identity by submitting a selfie or government ID to a company called Persona.

Selfie verifications have issues: They fail more often for people of color and those with certain disabilities. Sameer Hinduja, who co-directs the Cyberbullying Research Center, says the fact that Persona will need to hold millions of government IDs and masses of biometric data is another weak point. “When those get breached, we’ve exposed massive populations all at once,” he says.

Hinduja instead advocates for device-level verification, where a parent specifies a child’s age when setting up the child’s phone for the first time. This information is then kept on the device and shared securely with apps and websites.

That’s more or less what Tim Cook, the CEO of Apple, recently lobbied US lawmakers to call for. Cook was fighting lawmakers who wanted to require app stores to verify ages, which would saddle Apple with lots of liability.

More signals of where this is all headed will come on Wednesday, when the Federal Trade Commission—the agency that would be responsible for enforcing these new laws—is holding an all-day workshop on age verification. Apple’s head of government affairs, Nick Rossi, will be there. He’ll be joined by higher-ups in child safety at Google and Meta, as well as a company that specializes in marketing to children.

The FTC has become increasingly politicized under President Trump (his firing of the sole Democratic commissioner was struck down by a federal court, a decision that is now pending review by the US Supreme Court). In July, I wrote about signals that the agency is softening its stance toward AI companies. Indeed, in December, the FTC overturned a Biden-era ruling against an AI company that allowed people to flood the internet with fake product reviews, writing that it clashed with President Trump’s AI Action Plan.

Wednesday’s workshop may shed light on how partisan the FTC’s approach to age verification will be. Red states favor laws that require porn websites to verify ages (but critics warn this could be used to block a much wider range of content). Bethany Soye, a Republican state representative who is leading an effort to pass such a bill in her state of South Dakota, is scheduled to speak at the FTC meeting. The ACLU generally opposes laws requiring IDs to visit websites and has instead advocated for an expansion of existing parental controls.

While all this gets debated, though, AI has set the world of child safety on fire. We’re dealing with increased generation of child sexual abuse material, concerns (and lawsuits) about suicides and self-harm following chatbot conversations, and troubling evidence of kids’ forming attachments to AI companions. Colliding stances on privacy, politics, free expression, and surveillance will complicate any effort to find a solution. Write to me with your thoughts.

Four ways to think about this year&#39;s reckoning.

Our AI writers make their big bets for the coming year—here are five hot trends to watch.

By studying large language models as if they were living things instead of computer programs, scientists are discovering some of their secrets for the first time.

In an exclusive interview, the AI pioneer shares his plans for his new Paris-based company, AMI Labs.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-56')">
            <div class="source">MIT Technology Review</div>
            <div class="title">The power of sound in a virtual world</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-56" style="display:none;">
            <h2>The power of sound in a virtual world</h2>
            <p><strong>MIT Technology Review | 2026-01-26</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2026/01/26/1124655/the-power-of-sound-in-a-virtual-world/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">In an era where business, education, and even casual conversations occur via screens, sound has become a differentiating factor. We obsess over lighting, camera angles, and virtual backgrounds, but how we sound can be just as critical to credibility, trust, and connection.

That’s the insight driving Erik Vaveris, vice president of product management and chief marketing officer at Shure, and Brian Scholl, director of the Perception & Cognition Laboratory at Yale University. Both see audio as more than a technical layer: It’s a human factor shaping how people perceive intelligence, trustworthiness, and authority in virtual settings.

&quot;If you&#39;re willing to take a little bit of time with your audio set up, you can really get across the full power of your message and the full power of who you are to your peers, to your employees, your boss, your suppliers, and of course, your customers,&quot; says Vaveris.

Scholl’s research shows that poor audio quality can make a speaker seem less persuasive, less hireable, and even less credible.

&quot;We know that [poor] sound doesn&#39;t reflect the people themselves, but we really just can&#39;t stop ourselves from having those impressions,&quot; says Scholl. &quot;We all understand intuitively that if we&#39;re having difficulty being understood while we&#39;re talking, then that&#39;s bad. But we sort of think that as long as you can make out the words I&#39;m saying, then that&#39;s probably all fine. And this research showed in a somewhat surprising way, to a surprising degree, that this is not so.&quot;

For organizations navigating hybrid work, training, and marketing, the stakes have become high.

Vaveris points out that the pandemic was a watershed moment for audio technology. As classrooms, boardrooms, and conferences shifted online almost overnight, demand accelerated for advanced noise suppression, echo cancellation, and AI-driven processing tools that make meetings more seamless. Today, machine learning algorithms can strip away keyboard clicks or reverberation and isolate a speaker’s voice in noisy environments. That clarity underpins the accuracy of AI meeting assistants that can step in to transcribe, summarize, and analyze discussions.

The implications across industries are rippling. Clearer audio levels the playing field for remote participants, enabling inclusive collaboration. It empowers executives and creators alike to produce broadcast-quality content from the comfort of their home office. And it offers companies new ways to build credibility with customers and employees without the costly overhead of traditional production.

Looking forward, the convergence of audio innovation and AI promises an even more dynamic landscape: from real-time captioning in your native language to audio filtering, to smarter meeting tools that capture not only what is said but how it’s said, and to technologies that disappear into the background while amplifying the human voice at the center.

&quot;There&#39;s a future out there where this technology can really be something that helps bring people together,&quot; says Vaveris. &quot;Now that we have so many years of history with the internet, we know there&#39;s usually two sides to the coin of technology, but there&#39;s definitely going to be a positive side to this, and I&#39;m really looking forward to it.

In a world increasingly mediated by screens, sound may prove to be the most powerful connector of all.

This episode of Business Lab is produced in partnership with Shure.

Megan Tatum: From MIT Technology Review, I&#39;m Megan Tatum, and this is Business Lab, the show that helps business leaders make sense of new technologies coming out of the lab and into the marketplace.This episode is produced in partnership with Shure.Our topic today is the power of sound. As our personal and professional lives become increasingly virtual, audio is emerging as an essential tool for everything from remote work to virtual conferences to virtual happy hour. While appearance is often top of mind in video conferencing and streaming, audio can be as or even more important, not only to effective communication, but potentially to brand equity for both the speaker and the company.Two words for you: crystal clear.My guests today are Erik Vaveris, VP of Product Management and Chief Marketing Officer at Shure, and Brian Scholl, Director of the Perception & Cognition Laboratory at Yale University.Welcome, Erik and Brian.

Erik Vaveris: Thank you, Megan. And hello, Brian. Thrilled to be here today.

Megan: Fantastic. Thank you both so much for being here. Erik, let&#39;s open with a bit of background. I imagine the pandemic changed the audio industry in some significant ways, given the pivot to our modern remote hybrid lifestyles. Could you talk a bit about that journey and some of the interesting audio advances that arose from that transformative shift?

Erik: Absolutely, Megan. That&#39;s an interesting thing to think about now being here in 2025. And if you put yourself back in those moments in 2020, when things were fully shut down and everything was fully remote, the importance of audio quality became immediately obvious. As people adopted Zoom or Teams or platforms like that overnight, there were a lot of technical challenges that people experienced, but the importance of how they were presenting themselves to people via their audio quality was a bit less obvious. As Brian&#39;s noted in a lot of the press that he&#39;s received for his wonderful study, we know how we look on video. We can see ourselves back on the screen, but we don&#39;t know how we sound to the people with whom we&#39;re speaking.

If a meeting participant on the other side can manage to parse the words that you&#39;re saying, they&#39;re not likely to speak up and say, &quot;Hey, I&#39;m having a little bit of trouble hearing you.&quot; They&#39;ll just let the meeting continue. And if you don&#39;t have a really strong level of audio quality, you&#39;re asking the people that you&#39;re talking to devote way too much brainpower to just determining the words that you&#39;re saying. And you&#39;re going to be fatiguing to listen to. And your message won&#39;t come across. In contrast, if you&#39;re willing to take a little bit of time with your audio set up, you can really get across the full power of your message and the full power of who you are to your peers, to your employees, your boss, your suppliers, and of course your customers. Back in 2020, this very quickly became a marketing story that we had to tell immediately.

And I have to say, it&#39;s so gratifying to see Brian&#39;s research in the news because, to me, it was like, &quot;Yes, this is what we&#39;ve been experiencing. And this is what we&#39;ve been trying to educate people about.&quot; Having the real science to back it up means a lot. But from that, development on improvements to key audio processing algorithms accelerated across the whole AV industry.

I think, Megan and Brian, you probably remember hearing loud keyboard clicking when you were on calls and meetings, or people eating potato chips and things like that back on those. But you don&#39;t hear that much today because most platforms have invested in AI-trained algorithms to remove undesirable noises. And I know we&#39;re going to talk more about that later on.

But the other thing that happened, thankfully, was that as we got into the late spring and summer of 2020, was that educational institutions, especially universities, and also businesses realized that things were going to need to change quickly. Nothing was going to be the same. And universities realized that all classrooms were going to need hybrid capabilities for both remote students and students in the classroom. And that helped the market for professional AV equipment start to recover because we had been pretty much completely shut down in the earlier months. But that focus on hybrid meeting spaces of all types accelerated more investment and more R&D into making equipment and further developing those key audio processing algorithms for more and different types of spaces and use cases. And since then, we&#39;ve really seen a proliferation of different types of unobtrusive audio capture devices based on arrays of microphones and the supporting signal processing behind them. And right now, machine-learning-trained signal processing is really the norm. And that all accelerated, unfortunately, because of the pandemic.

Megan: Yeah. Such an interesting period of change, as you say. And Brian, what did you observe and experience in academia during that time? How did that time period affect the work at your lab?

Brian: I&#39;ll admit, Megan, I had never given a single thought to audio quality or anything like that, certainly until the pandemic hit. I was thrown into this, just like the rest of the world was. I don&#39;t believe I&#39;d ever had a single video conference with a student or with a class or anything like that before the pandemic hit. But in some ways, our experience in universities was quite extreme. I went on a Tuesday from teaching an in-person class with 300 students to being on Zoom with everyone suddenly on a Thursday. Business meetings come in all shapes and sizes. But this was quite extreme. This was a case where suddenly I&#39;m talking to hundreds and hundreds of people over Zoom. And every single one of them knows exactly what I sound like, except for me, because I&#39;m just speaking my normal voice and I have no idea how it&#39;s being translated through all the different levels of technology.

I will say, part of the general rhetoric we have about the pandemic focuses on all the negatives and the lack of personal connection and nuance and the fact that we can&#39;t see how everyone&#39;s paying attention to each other. Our experience was a bit more mixed. I&#39;ll just tell you one anecdote. Shortly after the pandemic started, I started teaching a seminar with about 20 students. And of course, this was still online. What I did is I just invited, for whatever topic we were discussing on any given day, I sent a note to whoever was the clear world leader in the study of whatever that topic was. I said, &quot;Hey, don&#39;t prepare a talk. You don&#39;t have to answer any questions. But just come join us on Zoom and just participate in the conversation. The students will have read some of your work.&quot;

Every single one of them said, &quot;Let me check my schedule. Oh, I&#39;m stuck at home for a year. Sure. I&#39;d be happy to do that.&quot; And that was quite a positive. The students got to meet a who&#39;s who of cognitive science from this experience. And it&#39;s true that there were all these technological difficulties, but that would never, ever have happened if we were teaching the class in real life. That would&#39;ve just been way too much travel and airfare and hotel and scheduling and all of that. So, it was a mixed bag for us.

Erik: That is really interesting. And that&#39;s such a cool idea. And it&#39;s so wonderful that that worked out. I would say that working for a global company, we like to think that, &quot;Oh, we&#39;re all together. And we&#39;re having these meetings. And we&#39;re in the same room,&quot; but the reality was we weren&#39;t in the same room. And there hadn&#39;t been enough attention paid to the people who were conferencing in speaking not their native language in a different time zone, maybe pretty deep into the evening, in some cases. And the remote work that everybody got thrown into immediately at the start of the pandemic did force everybody to start to think more about those types of interactions and put everybody on a level playing field.

And that was insightful. And that helped some people have stronger voices in the work that we were doing than they maybe did before. And it&#39;s also led businesses really across the board, there&#39;s a lot written about this, to be much more focused on making sure that participants from those who may be remote at home, may be in the office, may be in different offices, may be in different time zones, are all able to participate and collaborate on really a level playing field. And that is a positive. That&#39;s a good thing.

Megan: Yeah. There are absolutely some positive side effects there, aren&#39;t there? And it inspired you, Brian, to look at this more closely. And you&#39;ve done a study that shows poor audio quality can actually affect the perception of listeners. So, I wonder what prompted the study, in particular. And what kinds of data did you gather? What methodology did you use?

Brian: Yeah. The motivation for this study was actually a real-world experience, just like we&#39;ve been talking about. In addition to all of our classes moving online with no notice whatsoever, the same thing was true of our departmental faculty meetings. Very early on in the pandemic, we had one of these meetings. And we were talking about some contentious issue about hiring or whatever. And two of my colleagues, who I&#39;d known very well and for many, many years, spoke up to offer their opinions. And one of these colleagues is someone who I&#39;m very close with. We almost always see eye to eye. He was actually a former graduate student of mine once upon a time. And we almost always see eye to eye on things. He happened to be participating in that meeting from an old not-so-hot laptop. His audio quality had that sort of familiar tinny quality that we&#39;re all familiar with. I could totally understand everything he was saying, but I found myself just being a little skeptical.

I didn&#39;t find his points so compelling as usual. Meanwhile, I had another colleague, someone who I deeply respect, I&#39;ve collaborated with, but we don&#39;t always see eye to eye on these things. And he was participating in this first virtual faculty meeting from his home recording studio. Erik, I don&#39;t know if his equipment would be up to your level or not, but he sounded better than real life. He sounded like he was all around us. And I found myself just sort of naturally agreeing with his points, which sort of was notable and a little surprising in that context. And so, we turned this into a study.

We played people a number of short audio clips, maybe like 30 seconds or so. And we had these being played in the context of very familiar situations and decisions. One of them might be like a hiring decision. You would have to listen to this person telling you why they think they might be a good fit for your job. And then afterwards, you had to make a simple judgment. It might be of a trait. How intelligent did that person seem? Or it might be a real-world decision like, &quot;Hey, based on this, how likely would you be to pursue trying to hire them?&quot; And critically, we had people listen to exactly the same sort of scripts, but with a little bit of work behind the scenes to affect the audio quality. In one case, the audio sounded crisp and clear. Recorded with a decent microphone. And here&#39;s what it sounded like.

Audio Clip: After eight years in sales, I&#39;m currently seeking a new challenge which will utilize my meticulous attention to detail and friendly professional manner. I&#39;m an excellent fit for your company and will be an asset to your team as a senior sales manager.

Brian: Okay. Whatever you think of the content of that message, at least it&#39;s nice and clear. Other subjects listened to exactly the same recording. But again, it had that sort of tinny quality that we&#39;re all familiar with when people&#39;s voices are filtered through a microphone or a recording setup that&#39;s not so hot. That sounded like this.

Audio Clip: After eight years in sales, I&#39;m currently seeking a new challenge which will utilize my meticulous attention to detail and friendly professional manner. I&#39;m an excellent fit for your company and will be an asset to your team as a senior sales manager.

Brian: All right. Now, the thing that I hope you can get from that recording there is that although it clearly has this what we would call, as a technical term, a disfluent sound, it&#39;s just a little harder to process, you are ultimately successful, right? Megan, Erik, you were able to understand the words in that second recording.

Brian: And we made sure this was true for all of our subjects. We had them do word-for-word transcription after they made these judgments. And I&#39;ll also just point out that this kind of manipulation clearly can&#39;t be about the person themselves, right? You couldn&#39;t make your voices sound like that in real world conversation if you tried. Voices just don&#39;t do those sorts of things. Nevertheless, in a way that sort of didn&#39;t make sense, that was kind of irrational because this couldn&#39;t reflect the person, this affected all sorts of judgments about people.

So, people were judged to be about 8% less hirable. They were judged to be about 8% less intelligent. We also did this in other contexts. We did this in the context of dateability as if you were listening to a little audio clip from someone who was maybe interested in dating you, and then you had to make a judgment of how likely would you be to date this person. Same exact result. People were a little less datable when their audio was a little more tinny, even though they were completely understandable.

The experiment, the result that I thought was in some ways most striking is one of the clips was about someone who had been in a car accident. It was a little narrative about what had happened in the car accident. And they were talking as if to the insurance agent. They were saying, &quot;Hey, it wasn&#39;t my fault. This is what happened.&quot; And afterwards, we simply had people make a natural intuitive judgment of how credible do you think the person&#39;s story was. And when it was recorded with high-end audio, these messages were judged to be about 8% more credible in this context. So those are our experiments. What it shows really is something about the power of perception. We know that that sort of sound doesn&#39;t reflect the people themselves, but we really just can&#39;t stop ourselves from having those impressions made. And I don&#39;t know about you guys, but, Erik, I think you&#39;re right, that we all understand intuitively that if we&#39;re having difficulty being understood while we&#39;re talking, then that&#39;s bad. But we sort of think that as long as you can make out the words I&#39;m saying, then that&#39;s probably all fine. And this research showed in a somewhat surprising way to a surprising degree that this is not so.

Megan: From an industry perspective, Erik, what are your thoughts on those study results? Did it surprise you as well?

Erik: No, like I said, I found it very, very gratifying because we invest a lot in trying to make sure that people understand the importance of quality audio, but we kind of come about that intuitively. Our entire company is audio people. So of course, we think that. And it&#39;s our mission to help other people achieve those higher levels of audio in everything that they do, whether you&#39;re a minister at a church or you&#39;re teaching a class or you&#39;re performing on stage. When I first saw in the news about Brian&#39;s study, I think it was the NPR article that just came up in one of my feeds. I read it and it made me feel like my life&#39;s work has been validated to some extent. I wouldn&#39;t say we were surprised by it, but iIt made a lot of sense to us. Let&#39;s put it that way.

Brian: This is what we&#39;re hearing. Oh, sorry. Megan, I was going to say this is what we&#39;re hearing from a lot of the audio professionals as they&#39;re saying, &quot;Hey, you scientists, you finally caught up to us.&quot; But of course-

Brian: Erik, you&#39;re in an unusual circumstance because you guys think about audio every day. When we&#39;re on Zoom, look, I can see the little rectangle as well as you can. I can see exactly how I look like. I can check the lighting. I check my hair. We all do that every day. But I would say most people really, they use whatever microphone came with their setup, and never give a second thought to what they sound like because they don&#39;t know what they sound like.

Megan: Avoid listening to yourself back as well. I think that&#39;s common. We don&#39;t scrutinize audio as much as we should. I wonder, Erik, since the study came out, how are you seeing that research play out across industry? Can you talk a bit about the importance of strong, clear audio in today&#39;s virtual world and the challenges that companies and employees are facing as well?

Erik: Yeah. Sure, Megan. That&#39;s a great question. And studies kind of back this up, businesses understand that collaboration is the key to many things that we do. They know that that&#39;s critical. And they are investing in making the experiences for the people at work better because of that knowledge, that intuitive understanding. But there are challenges. It can be expensive. You need solutions that people who are going to walk into a room or join a meeting on their personal device, that they&#39;re motivated to use and that they can use because they&#39;re simple. You also have to overcome the barriers to investment. We in the AV industry have had to look a lot at how can we bring down the overall cost of ownership of setting up AV technology because, as we&#39;ve seen, the prices of everything that goes into making a product are not coming down.

Simplifying deployment and management is critical. Beyond just audio technology, IoT technology and cloud technology for IT teams to be able to easily deploy and manage classrooms across an entire university campus or conference rooms across a global enterprise are really, really critical. And those are quickly evolving. And integrations with more standard common IT tools are coming out. And that&#39;s one area. Another thing is just for the end user, having the same user interface in each conference room that is familiar to everyone from their personal devices is also important. For many, many years, a lot of people had the experience where, &quot;Hey, it&#39;s time we&#39;re going to actually do a conference meeting.&quot; And you might have a few rooms in your company or in your office area that could do that. And you walk into the meeting room. And how long does it take you to actually get connected to the people you&#39;re going to talk with?

There was always a joke that you&#39;d have to spend the first 15 minutes of a meeting working all of that out. And that&#39;s because the technology was fragmented and you had to do a lot of custom work to make that happen. But these days, I would say platforms like Zoom and Teams and Google and others are doing a really great job with this. If you have the latest and greatest in your meeting rooms and you know how to join from your own personal device, it&#39;s basically the same experience. And that is streamlining the process for everyone. Bringing down the costs of owning it so that companies can get to those benefits to collaboration is kind of the key.

Megan: I was going to ask if we could dive a little deeper into that kind of audio quality, the technological advancements that AI has made possible, which you did touch on slightly there, Erik. What are the most significant advancements, in your view? And how are those impacting the ways we use audio and the things we can do with it?

Erik: Okay. Let me try to break that down into-

Erik: ... a couple different sections. Yeah. No, and one that&#39;s just so exciting. Machine-learning-based digital signal processing, or DSP, is here and is the norm now. If you think about the beginning of telephones and teleconferencing, just going way back, one of the initial problems you had whenever you tried to get something out of a dedicated handset onto a table was echo. And I&#39;m sure we&#39;ve all heard that at some point in our life. You need to have a way to cancel echo. But by the way, you also want people to be able to speak at the same time on both ends of a call. You get to some of those very rudimentary things. Machine learning is really supercharging those algorithms to provide better performance with fewer trade-offs, fewer artifacts in the actual audio signal.

Noise reduction has come a long way. I mentioned earlier on, keyboard sounds and the sounds of people eating, and how you just don&#39;t hear that anymore, at least I don&#39;t when I&#39;m on conference calls. But only a few years ago, that could be a major problem. The machine-learning-trained digital signal processing is in the market now and it&#39;s doing a better job than ever in removing things that you don&#39;t want from your sound. We have a new de-verberation algorithm, so if you have a reverberant room with echoes and reflections that&#39;s getting into the audio signal, that can degrade the experience there. We can remove that now. Another thing, the flip side of that is that there&#39;s also a focus on isolating the sound that you do want and the signal that you do want.

Microsoft has rolled out a voice print feature in Teams that allows you, if you&#39;re willing, to provide them with a sample of your voice. And then whenever you&#39;re talking from your device, it will take out anything else that the microphone may be picking up so that even if you&#39;re in a really noisy environment outdoors or, say, in an airport, the people that you&#39;re speaking with are going to hear you and only you. And it&#39;s pretty amazing as well. So those are some of the things that are happening today and are available today.

Another thing that&#39;s emerged from all of this is we&#39;ve been talking about how important audio quality is to the people participating in a discussion, the people speaking, the people listening, how everyone is perceived, but a new consumer, if you will, of audio in a discussion or a meeting has emerged, and that is in the form of the AI agent that can summarize meetings and create action plans, do those sorts of things. But for it to work, a clean transcription of what was said is already table stakes. It can&#39;t garbled. It can&#39;t miss key things. It needs to get it word for word, sentence for sentence throughout the entire meeting. And the ability to attribute who said what to the meeting participants, even if they&#39;re all in the same room, is quickly upon us. And the ability to detect and integrate sentiment and emotion of the participants is going to become very important as well for us to really get the full value out of those kinds of AI agents.

So audio quality is as important as ever for humans, as Brian notes, in some ways more important because this is now the normal way that we talk and meet, but it&#39;s also critical for AI agents to work properly. And it&#39;s different, right? It&#39;s a different set of considerations. And there&#39;s a lot of emerging thought and work that&#39;s going into that as well. And boy, Megan, there&#39;s so much more we could say about this beyond meetings and video conferences. AI tools to simplify the production process. And of course, there&#39;s generative AI of music content. I know that&#39;s beyond the scope of what we&#39;re talking about. But it&#39;s really pretty incredible when you look around at the work that&#39;s happening and the capabilities that are emerging.

Megan: Yeah. Absolutely. Sounds like there are so many elements to consider and work going on. It&#39;s all fascinating. Brian, what kinds of emerging capabilities and use cases around AI and audio quality are you seeing in your lab as well?

Brian: Yeah. Well, I&#39;m sorry that Brian himself was not able to be here today, but I&#39;m an AI agent.

Brian: Just kidding. The fascinating thing that we&#39;re seeing from the lab, from the study of people&#39;s impressions is that all of this technology that Erik has described, when it works best, it&#39;s completely invisible. Erik, I loved your point about not hearing potato chips being eaten or rain in the background or something like that. You&#39;re totally right. I used to notice that all the time. I don&#39;t think I&#39;ve noticed that recently, but I also didn&#39;t notice that I haven&#39;t noticed that recently, right? It just kind of disappears. The interesting thing about these perceptual impressions, we&#39;re constantly drawing intuitive conclusions about people based on how they sound. And that might be a good thing or a bad thing when we&#39;re judging things like trustworthiness, for example, on the basis of a short audio clip.

But clearly, some of these things are valid, right? We can judge the size of someone or even of an animal based on how they sound, right? A chihuahua can&#39;t make the sound of a lion. A lion can&#39;t make the sound of a chihuahua. And that&#39;s always been true because we&#39;re producing audio signals that go right into each other&#39;s ears. And now, of course, everything that Erik is talking about, that&#39;s not true. It goes through all of these different layers of technology increasingly fueled by AI. But when that technology works the best way, it&#39;s as if it isn&#39;t there at all and we&#39;re just hearing each other directly.

Erik: That&#39;s the goal, right? That it&#39;s seamless open communication and we don&#39;t have to think about the technology anymore.

Brian: It&#39;s a tough business to be in, I think, though, Erik, because people have to know what&#39;s going on behind the surface in order to value it. Otherwise, we just expect it to work.

Erik: Well, that&#39;s why we try to put the logo of our products on the side of them so they show up in the videos. But yeah, it&#39;s a good point.

Megan: And we&#39;ve talked about virtual meetings and conversations quite a bit, but there&#39;s also streamed and recorded content, which are increasingly important at work as well. I wondered, Erik, if you could talk a bit about how businesses are leveraging audio in new ways for things like marketing campaigns and internal upskilling and training and areas like that?

Erik: Yeah. Well, one of the things I think we&#39;ve all seen in marketing is that not everything is a high production value commercial anymore. And there&#39;s still a place for that, for sure. But people tend to trust influencers that they follow. People search on TikTok, on YouTube for topics. Those can be the place that they start. And as technology&#39;s gotten more accessible, not just audio, but of course, the video technology too, content creators can produce satisfying content on their own or with just a couple of people with them. And Brian&#39;s study shows that it doesn&#39;t really matter what the origins of the content are for it to be compelling.

For the person delivering the message to be compelling, the audio quality does have to hit a certain level. But because the tools are simpler to use and you need less things to connect and pull together a decent production system, creator-driven content is becoming even more and more integral to a marketing campaign. And so not just what they maybe post on their Instagram page or post on LinkedIn, for example, but us as a brand being able to take that content and use that actually in paid media and things like that is all entirely possible because of the overall quality of the content. So that&#39;s something that&#39;s been a trend that&#39;s been in process really, I would say, maybe since the advent of podcasts. But it&#39;s been an evolution. And it&#39;s come a long, long way.

Another thing, and this is really interesting, and this hits home personally, but I remember when I first entered the workforce, and I hope I&#39;m not showing my age too badly here, but I remember the word processing department. And you would write down on a piece of paper, like a memo, and you would give it to the word processing department and somebody would type it up for you. That was a thing. And these days, we&#39;re seeing actually more and more video production with audio, of course, transfer to the actual producers of the content.

In my company, at Shure, we make videos for different purposes to talk about different initiatives or product launches or things that we&#39;re doing just for internal use. And right now, everybody, including our CEO, she makes these videos just at her own desk. She has a little software tool and she can show a PowerPoint and herself and speak to things. And with very, very limited amount of editing, you can put that out there. And I&#39;ve seen friends and colleagues at other companies in very high-level roles just kind of doing their own production. Being able to buy a very high quality microphone with really advanced signal processing built right in, but just plug it in via USB and have it be handled as simply as any consumer device, has made it possible to do really very useful production where you are going to actually sound good and get your message across, but without having to make such a big production out of it, which is kind of cool.

Megan: Yeah. Really democratizes access to sort of creating high quality content, doesn&#39;t it? And of course, no technology discussion is complete without a mention of return on investment, particularly nowadays. Erik, what are some ways companies can get returns on their audio tech investments as well? Where are the most common places you see cost savings?

Erik: Yeah. Well, we collaborated on a study with IDC Research. And they came up with some really interesting findings on this. And one of them was, no surprise, two-thirds or more of companies have taken action on improving their communication and collaboration technology, and even more have additional or initial investments still planned. But the ROI of those initiatives isn&#39;t really tied to the initiative itself. It&#39;s not like when you come out with a new product, you look at how that product performs, and that&#39;s the driver of your ROI. The benefits of smoother collaboration come in the form of shorter meetings, more productive meetings, better decision-making, faster decision-making, stronger teamwork. And so to build an ROI model, what IDC concluded was that you have to build your model to account for those advantages really across the enterprise or across your university, or whatever it may be, and kind of up and down the different set of activities where they&#39;re actually going to be utilized.

So that can be complex. Quantifying things can always be a challenge. But like I said, companies do seem to understand this. And I think that&#39;s because, this is just my hunch, but because everybody, including the CEO and the CFO and the whole finance department, uses and benefits from collaboration technology too. Perhaps that&#39;s one reason why the value is easier to convey. Even if they have not taken the time to articulate things like we&#39;re doing here today, they know when a meeting is good and when it&#39;s not good. And maybe that&#39;s one of the things that&#39;s helping companies to justify these investments. But it&#39;s always tricky to do ROI on projects like that. But again, focusing on the broader benefits of collaboration and breaking it down into what it means for specific activities and types of meetings, I think, is the way to go about doing that.

Megan: Absolutely. And Brian, what kinds of advancements are you seeing in the lab that perhaps one day might contribute to those cost savings?

Brian: Well, I don&#39;t know anything about cost savings, Megan. I&#39;m a college professor. I live a pure life of the mind.

Brian: ROI does not compute for me. No, I would say we are in an extremely exciting frontier right now because of AI and many different technologies. The studies that we talked about earlier, in one sense, they were broad. We explored many different traits from dating to hiring to credibility. And we isolated them in all sorts of ways we didn&#39;t talk about. We showed that it wasn&#39;t due to overall affect or pessimism or something like that. But in those studies, we really only tested one very particular set of dimensions along which an audio signal can vary, which is some sort of model of clarity. But in reality, the audio signal is so multi-dimensional. And as we&#39;re getting more and more tools these days, we can not only change audio along the lines of clarity, as we&#39;ve been talking about, but we can potentially manipulate it in all sorts of ways.

We&#39;re very interested in pushing these studies forward and in exploring how people&#39;s sort of brute impressions that they make are affected by all sorts of things. Meg and Erik, we walk around the world all the time making these judgments about people, right? You meet someone and you&#39;re like, &quot;Wow, I could really be friends with them. They seem like a great person.&quot; And you know that you&#39;re making that judgment, but you have no idea why, right? It just seems kind of intuitive. Well, in an audio signal, when you&#39;re talking to someone, you can think of, &quot;What if their signal is more bass heavy? What if it&#39;s a little more treble heavy? What if we manipulate it in this way? In that way?&quot;

When we talked about the faculty meeting that motivated this whole research program, I mentioned that my colleague, who was speaking from his home recording studio, he actually didn&#39;t sound clear like in real life. He sounded better than in real life. He sounded like he was all around us. What is the implication of that? I think there&#39;s so many different dimensions of an audio signal that we&#39;re just being able to readily control and manipulate that it&#39;s going to be very exciting to see how all of these sorts of things impact our impressions of each other.

Megan: And there may be some overlap with this as well, but I wondered if we could close with a future forward look, Brian. What are you looking forward to in emerging audio technology? What are some exciting opportunities on the horizon, perhaps related to what you were just talking about there?

Brian: Well, we&#39;re interested in studying this from a scientific perspective. Erik, you talked about how when you started. When I started doing this science, we didn&#39;t have a word processing department. We had a stone tablet department. But I hear tell that the current generation, when they send photos back and forth to each other, that they, as a matter, of course, they apply all sorts of filters-

Brian: ... to those video signals, those video or just photographic signals. We&#39;re all familiar with that. That hasn&#39;t quite happened with the audio signals yet, but I think that&#39;s coming up as well. You can imagine that you record yourself saying a little message and then you filter it this way or that way. And that&#39;s going to become the Wild West about the kinds of impressions we make on each other, especially if and when you don&#39;t know that those filters have been operating in the first place.

Megan: That&#39;s so interesting. Erik, what are you looking forward to in audio technology as well?

Erik: Well, I&#39;m still thinking about what Brian said.

Erik: I have to go back again. I&#39;ll go back to the past, maybe 15 to 20 years. And I remember at work, we had meeting rooms with the Starfish phones in the middle of the table. And I remember that we would have international meetings with our partners there that were selling our products in different countries, including in Japan and in China, and the people actually in our own company in those countries. We knew the time zone was bad. And we knew that English wasn&#39;t their native language, and tried to be as courteous as possible with written materials and things like that. But I went over to China, and I had to actually be on the other end of one of those calls. And I&#39;m a native English speaker, or at least a native Chicago dialect of American English speaker. And really understanding how challenging it was for them to participate in those meetings just hit me right between the eyes.

We&#39;ve come so far, which is wonderful. But I think of a scenario, and this is not far off, there are many companies working on this right now, where not only can you get a real time captioning in your native language, no matter what the language of the participant, you can actually hear the person who&#39;s speaking&#39;s voice manipulated into your native language.

I&#39;m never going to be a fluent Japanese or Chinese speaker, that&#39;s for sure. But I love the thought that I could actually talk with people and they could understand me as though I were speaking their native language, and that they could communicate to me and I could understand them in the way that they want to be understood. I think there&#39;s a future out there where this technology can really be something that helps bring people together. Now that we have so many years of history with the internet, we know there&#39;s usually two sides to the coin of technology, but there&#39;s definitely going to be a positive side to this, and I&#39;m really looking forward to it.

Megan: Gosh, that sounds absolutely fascinating. Thank you both so much for such an interesting discussion.

That was Erik Vaveris, the VP of product management and chief marketing officer at Shure, and Brian Scholl, director of the Perception & Cognition Laboratory at Yale University, whom I spoke with from Brighton in England.That&#39;s it for this episode of Business Lab. I&#39;m your host, Megan Tatum. I&#39;m a contributing editor at Insights, the custom publishing division of MIT Technology Review. We were founded in 1899 at the Massachusetts Institute of Technology. And you can find us in print on the web and at events each year around the world. For more information about us and the show, please check out our website at technologyreview.com.This show is available wherever you get your podcasts. If you enjoyed this episode, we hope you&#39;ll take a moment to rate and review us. Business Lab is a production of MIT Technology Review. And this episode was produced by Giro Studios. Thanks for listening.

This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff. It was researched, designed, and written entirely by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.

Here are our picks for the advances to watch in the years ahead—and why we think they matter right now.

Four ways to think about this year&#39;s reckoning.

As early electric cars age out, hundreds of thousands of used batteries are flooding the market, fueling a gray recycling economy even as Beijing and big manufacturers scramble to build a more orderly system.

The Cybertruck, sycophantic AI, and humanoid robots all made this year’s list of the biggest technology failures.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-57')">
            <div class="source">MIT Technology Review</div>
            <div class="title">The Download: why LLMs are like aliens, and the future of head transplants</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-57" style="display:none;">
            <h2>The Download: why LLMs are like aliens, and the future of head transplants</h2>
            <p><strong>MIT Technology Review | 2026-01-26</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2026/01/26/1131717/the-download-why-llms-are-like-aliens-and-the-future-of-head-transplants/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">This is today&#39;s edition of The Download, our weekday newsletter that provides a daily dose of what&#39;s going on in the world of technology.

Meet the new biologists treating LLMs like aliens

How large is a large language model? We now coexist with machines so vast and so complicated that nobody quite understands what they are, how they work, or what they can really do—not even the people who build them.That’s a problem. Even though nobody fully understands how it works—and thus exactly what its limitations might be—hundreds of millions of people now use this technology every day.

To help overcome our ignorance, researchers are studying LLMs as if they were doing biology or neuroscience on vast living creatures—city-size xenomorphs that have appeared in our midst. And they’re discovering that large language models are even weirder than they thought. Read the full story.—Will Douglas Heaven

This is our latest story to be turned into a MIT Technology Review Narrated podcast, which we publish each week on Spotify and Apple Podcasts. Just navigate to MIT Technology Review Narrated on either platform, and follow us to get all our new content as it’s released.

And mechanistic interpretability, the technique these researchers are using to try and understand AI models, is one of our 10 Breakthrough Technologies for 2026. Check out the rest of the list here!

Job titles of the future: Head-transplant surgeon

The Italian neurosurgeon Sergio Canavero has been preparing for a surgery that might never happen. His idea? Swap a sick person’s head—or perhaps just the brain—onto a younger, healthier body.Canavero caused a stir in 2017 when he announced that a team he advised in China had exchanged heads between two corpses. But he never convinced skeptics that his technique could succeed—or to believe his claim that a procedure on a live person was imminent.

Canavero may have withdrawn from the spotlight, but the idea of head transplants isn’t going away. Instead, he says, the concept has recently been getting a fresh look from life-extension enthusiasts and stealth Silicon Valley startups. Read the full story.

This story is from the latest print issue of MIT Technology Review magazine, which is all about exciting innovations. If you haven’t already, subscribe now to receive future issues once they land.

I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.

1 Big Tech is facing multiple high-profile social media addiction lawsuits Meta, TikTok and YouTube will face parents’ accusations in court this week. (WP $)+ It’s the first time they’re defending against these claims before a jury in a court of law. (CNN)2 Power prices are surging in the world’s largest data center hubVirginia is struggling to meet record demand during a winter storm, partly because of the centers’ electricity demands. (Reuters)+ Why these kinds of violent storms are getting harder to forecast. (Vox)+ AI is changing the grid. Could it help more than it harms? (MIT Technology Review)3 TikTok has started collecting even more data on its usersIncluding precise information about their location. (Wired $)4 ICE-watching groups are successfully fighting DHS efforts to unmask themAn anonymous account holder sued to block ICE from identifying them—and won. (Ars Technica)5 A new wave of AI companies want to use AI to make AI betterThe AI ouroboros is never-ending. (NYT $)+ Is AI really capable of making bona fide scientific advancements? (Undark)+ AI trained on AI garbage spits out AI garbage. (MIT Technology Review)

6 Iran is testing a two-tier internetMeaning its current blackout could become permanent. (Rest of World)7 Don’t believe the humanoid robot hypeEven a leading robot maker admits that at best, they’re only half as efficient as humans. (FT $)+ Tesla wants to put its Optimus bipedal machine to work in its Austin factory. (Insider)+ Why the humanoid workforce is running late. (MIT Technology Review)

8 AI is changing how manufacturers create new productsIncluding thinner chewing gum containers and new body wash odors. (WSJ $)+ AI could make better beer. Here’s how. (MIT Technology Review)9 New Jersey has had enough of e-bikes 🚲But will other US states follow its lead? (The Verge)10 Sci-fi writers are cracking down on AIHuman-produced works only, please. (TechCrunch)+ San Diego Comic-Con was previously a safe space for AI-generated art. (404 Media)+ Generative AI is reshaping South Korea’s webcomics industry. (MIT Technology Review)

“Choosing American digital technology by default is too easy and must stop.”

—Nicolas Dufourcq, head of French state-owned investment bank Bpifrance, makes his case for why Big European companies should use European-made software as tensions with the US rise, the Wall Street Journal reports.

The return of pneumatic tubesPneumatic tubes were once touted as something that would revolutionize the world. In science fiction, they were envisioned as a fundamental part of the future—even in dystopias like George Orwell’s 1984, where they help to deliver orders for the main character, Winston Smith, in his job rewriting history to fit the ruling party’s changing narrative.In real life, the tubes were expected to transform several industries in the late 19th century through the mid-20th. For a while, the United States took up the systems with gusto.But by the mid to late 20th century, use of the technology had largely fallen by the wayside, and pneumatic tube technology became virtually obsolete. Except in hospitals. Read the full story.

A place for comfort, fun and distraction to brighten up your day. (Got any ideas? Drop me a line or skeet &#39;em at me.)

+ You really can’t beat the humble jacket potato for a cheap, comforting meal. + These tips might help you whenever anxiety strikes. ($)+ There are some amazing photos in this year’s Capturing Ecology awards.+ You can benefit from meditation any time, anywhere. Give it a go!

Plus: OpenAI is sounding the &quot;code red&quot; alarm

Plus: TikTok has finally signed a deal to keep operating in the US

Plus: This company is developing gene therapies for muscle growth, erectile dysfunction, and “radical longevity”

Plus: China has built a major chip-making machine

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-58')">
            <div class="source">MIT Technology Review</div>
            <div class="title">The Download: chatbots for health, and US fights over AI regulation</div>
            <div class="meta">2026-01-23</div>
        </div>
        
        <div id="content-58" style="display:none;">
            <h2>The Download: chatbots for health, and US fights over AI regulation</h2>
            <p><strong>MIT Technology Review | 2026-01-23</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2026/01/23/1131708/the-download-chatbots-for-health-and-us-fights-over-ai-regulation/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">This is today&#39;s edition of The Download, our weekday newsletter that provides a daily dose of what&#39;s going on in the world of technology.

For the past two decades, there’s been a clear first step for anyone who starts experiencing new medical symptoms: Look them up online. The practice was so common that it gained the pejorative moniker “Dr. Google.” But times are changing, and many medical-information seekers are now using LLMs. According to OpenAI, 230 million people ask ChatGPT health-related queries each week.

That’s the context around the launch of OpenAI’s new ChatGPT Health product, which debuted earlier this month. The big question is: can the obvious risks of using AI for health-related queries be mitigated enough for them to be a net benefit? Read the full story.

In the final weeks of 2025, the battle over regulating artificial intelligence in the US reached boiling point. On December 11, after Congress failed twice to pass a law banning state AI laws, President Donald Trump signed a sweeping executive order seeking to handcuff states from regulating the booming industry.

Instead, he vowed to work with Congress to establish a “minimally burdensome” national AI policy. The move marked a victory for tech titans, who have been marshaling multimillion-dollar war chests to oppose AI regulations, arguing that a patchwork of state laws would stifle innovation.

In 2026, the battleground will shift to the courts. While some states might back down from passing AI laws, others will charge ahead. Read our story about what’s on the horizon.

This story is from MIT Technology Review’s What’s Next series of stories that look across industries, trends, and technologies to give you a first look at the future. You can read the rest of them here.

This week marked a rather unpleasant anniversary: It’s a year since Texas reported a case of measles—the start of a significant outbreak that ended up spreading across multiple states. Since the start of January 2025, there have been over 2,500 confirmed cases of measles in the US. Three people have died.

As vaccination rates drop and outbreaks continue, scientists have been experimenting with new ways to quickly identify new cases and prevent the disease from spreading. And they are starting to see some success with wastewater surveillance. Read the full story.

This story is from The Checkup, our weekly newsletter giving you the inside track on all things health and biotech. Sign up to receive it in your inbox every Thursday.

I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.

1 The US is dismantling itselfA foreign enemy could not invent a better chain of events to wreck its standing in the world. (Wired $)  + We need to talk about whether Donald Trump might be losing it.  (New Yorker $)2 Big Tech is taking on more debt to fund its AI aspirationsAnd the bubble just keeps growing. (WP $)+ Forget unicorns. 2026 is shaping up to be the year of the “hectocorn.” (The Guardian)+ Everyone in tech agrees we’re in a bubble. They just can’t agree on what happens when it pops. (MIT Technology Review)

3 DOGE accessed even more personal data than we thought Even now, the Trump administration still can’t say how much data is at risk, or what it was used for. (NPR)

4 TikTok has finalized a deal to create a new US entity Ending years of uncertainty about its fate in America. (CNN)+ Why China is the big winner out of all of this. (FT $)

5 The US is now officially out of the World Health Organization And it’s leaving behind nearly $300 million in bills unpaid. (Ars Technica) + The US withdrawal from the WHO will hurt us all. (MIT Technology Review)6 AI-powered disinformation swarms pose a threat to democracyA would-be autocrat could use them to persuade populations to accept cancelled elections or overturn results. (The Guardian)+ The era of AI persuasion in elections is about to begin. (MIT Technology Review)7 We’re about to start seeing more robots everywhereBut exactly what they’ll look like remains up for debate. (Vox $)+ Chinese companies are starting to dominate entire sectors of AI and robotics. (MIT Technology Review)8 Some people seem to be especially vulnerable to lonelinessIf you’re ‘other-directed’, you could particularly benefit from less screentime. (New Scientist $)9 This academic lost two years of work with a single clickTL;DR: Don’t rely on ChatGPT to store your data. (Nature)10 How animals develop a sense of direction 🦇🧭Their ‘internal compass’ seems to be informed by landmarks that help them form a mental map. (Quanta $)

“The rate at which AI is progressing, I think we have AI that is smarter than any human this year, and no later than next year.”

—Elon Musk simply cannot resist the urge to make wild predictions at Davos, Wired reports.

After falling steadily for decades, the prevalence of global hunger is now on the rise—nowhere more so than in sub-Saharan Africa.

Africa’s indigenous crops are often more nutritious and better suited to the hot and dry conditions that are becoming more prevalent, yet many have been neglected by science, which means they tend to be more vulnerable to diseases and pests and yield well below their theoretical potential.

Now the question is whether researchers, governments, and farmers can work together in a way that gets these crops onto plates and provides Africans from all walks of life with the energy and nutrition that they need to thrive, whatever climate change throws their way. Read the full story.

A place for comfort, fun and distraction to brighten up your day. (Got any ideas? Drop me a line or skeet &#39;em at me.)

+ The only thing I fancy dry this January is a martini. Here’s how to make one.+ If you absolutely adore the Bic crystal pen, you might want this lamp. + Cozy up with a nice long book this winter. ($)+ Want to eat healthier? Slow down and tune out food ‘noise’. ($)

Plus: OpenAI is sounding the &quot;code red&quot; alarm

Plus: TikTok has finally signed a deal to keep operating in the US

Plus: This company is developing gene therapies for muscle growth, erectile dysfunction, and “radical longevity”

Plus: China has built a major chip-making machine

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-59')">
            <div class="source">MIT Technology Review</div>
            <div class="title">America’s coming war over AI regulation</div>
            <div class="meta">2026-01-23</div>
        </div>
        
        <div id="content-59" style="display:none;">
            <h2>America’s coming war over AI regulation</h2>
            <p><strong>MIT Technology Review | 2026-01-23</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2026/01/23/1131559/americas-coming-war-over-ai-regulation/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">MIT Technology Review’s What’s Next series looks across industries, trends, and technologies to give you a first look at the future. You can read the rest of them here.

In the final weeks of 2025, the battle over regulating artificial intelligence in the US reached a boiling point. On December 11, after Congress failed twice to pass a law banning state AI laws, President Donald Trump signed a sweeping executive order seeking to handcuff states from regulating the booming industry. Instead, he vowed to work with Congress to establish a “minimally burdensome” national AI policy, one that would position the US to win the global AI race. The move marked a qualified victory for tech titans, who have been marshaling multimillion-dollar war chests to oppose AI regulations, arguing that a patchwork of state laws would stifle innovation.

In 2026, the battleground will shift to the courts. While some states might back down from passing AI laws, others will charge ahead, buoyed by mounting public pressure to protect children from chatbots and rein in power-hungry data centers. Meanwhile, dueling super PACs bankrolled by tech moguls and AI-safety advocates will pour tens of millions into congressional and state elections to seat lawmakers who champion their competing visions for AI regulation.

Trump’s executive order directs the Department of Justice to establish a task force that sues states whose AI laws clash with his vision for light-touch regulation. It also directs the Department of Commerce to starve states of federal broadband funding if their AI laws are “onerous.” In practice, the order may target a handful of laws in Democratic states, says James Grimmelmann, a law professor at Cornell Law School. “The executive order will be used to challenge a smaller number of provisions, mostly relating to transparency and bias in AI, which tend to be more liberal issues,” Grimmelmann says.

For now, many states aren’t flinching. On December 19, New York’s governor, Kathy Hochul, signed the Responsible AI Safety and Education (RAISE) Act, a landmark law requiring AI companies to publish the protocols used to ensure the safe development of their AI models and report critical safety incidents. On January 1, California debuted the nation’s first frontier AI safety law, SB 53—which the RAISE Act was modeled on—aimed at preventing catastrophic harms such as biological weapons or cyberattacks. While both laws were watered down from earlier iterations to survive bruising industry lobbying, they struck a rare, if fragile, compromise between tech giants and AI safety advocates.

If Trump targets these hard-won laws, Democratic states like California and New York will likely take the fight to court. Republican states like Florida with vocal champions for AI regulation might follow suit. Trump could face an uphill battle. “The Trump administration is stretching itself thin with some of its attempts to effectively preempt [legislation] via executive action,” says Margot Kaminski, a law professor at the University of Colorado Law School. “It’s on thin ice.”

But Republican states that are anxious to stay off Trump’s radar or can’t afford to lose federal broadband funding for their sprawling rural communities might retreat from passing or enforcing AI laws. Win or lose in court, the chaos and uncertainty could chill state lawmaking. Paradoxically, the Democratic states that Trump wants to rein in—armed with big budgets and emboldened by the optics of battling the administration—may be the least likely to budge.

In lieu of state laws, Trump promises to create a federal AI policy with Congress. But the gridlocked and polarized body won’t be delivering a bill this year. In July, the Senate killed a moratorium on state AI laws that had been inserted into a tax bill, and in November, the House scrapped an encore attempt in a defense bill. In fact, Trump’s bid to strong-arm Congress with an executive order may sour any appetite for a bipartisan deal.

The executive order “has made it harder to pass responsible AI policy by hardening a lot of positions, making it a much more partisan issue,” says Brad Carson, a former Democratic congressman from Oklahoma who is building a network of super PACs backing candidates who support AI regulation. “It hardened Democrats and created incredible fault lines among Republicans,” he says.

While AI accelerationists in Trump’s orbit—AI and crypto czar David Sacks among them—champion deregulation, populist MAGA firebrands like Steve Bannon warn of rogue superintelligence and mass unemployment. In response to Trump’s executive order, Republican state attorneys general signed a bipartisan letter urging the FCC not to supersede state AI laws.

With Americans increasingly anxious about how AI could harm mental health, jobs, and the environment, public demand for regulation is growing. If Congress stays paralyzed, states will be the only ones acting to keep the AI industry in check. In 2025, state legislators introduced more than 1,000 AI bills, and nearly 40 states enacted over 100 laws, according to the National Conference of State Legislatures.

Efforts to protect children from chatbots may inspire rare consensus. On January 7, Google and Character Technologies, a startup behind the companion chatbot Character.AI, settled several lawsuits with families of teenagers who killed themselves after interacting with the bot. Just a day later, the Kentucky attorney general sued Character Technologies, alleging that the chatbots drove children to suicide and other forms of self-harm. OpenAI and Meta face a barrage of similar suits. Expect more to pile up this year. Without AI laws on the books, it remains to be seen how product liability laws and free speech doctrines apply to these novel dangers. “It’s an open question what the courts will do,” says Grimmelmann.

While litigation brews, states will move to pass child safety laws, which are exempt from Trump’s proposed ban on state AI laws. On January 9, OpenAI inked a deal with a former foe, the child-safety advocacy group Common Sense Media, to back a ballot initiative in California called the Parents & Kids Safe AI Act, setting guardrails around how chatbots interact with children. The measure proposes requiring AI companies to verify users’ age, offer parental controls, and undergo independent child-safety audits. If passed, it could be a blueprint for states across the country seeking to crack down on chatbots.

Fueled by widespread backlash against data centers, states will also try to regulate the resources needed to run AI. That means bills requiring data centers to report on their power and water use and foot their own electricity bills. If AI starts to displace jobs at scale, labor groups might float AI bans in specific professions. A few states concerned about the catastrophic risks posed by AI may pass safety bills mirroring SB 53 and the RAISE Act.

Meanwhile, tech titans will continue to use their deep pockets to crush AI regulations. Leading the Future, a super PAC backed by OpenAI president Greg Brockman and the venture capital firm Andreessen Horowitz, will try to elect candidates who endorse unfettered AI development to Congress and state legislatures. They’ll follow the crypto industry’s playbook for electing allies and writing the rules. To counter this, super PACs funded by Public First, an organization run by Carson and former Republican congressman Chris Stewart of Utah, will back candidates advocating for AI regulation. We might even see a handful of candidates running on anti-AI populist platforms.

In 2026, the slow, messy process of American democracy will grind on. And the rules written in state capitals could decide how the most disruptive technology of our generation develops far beyond America’s borders, for years to come.

Four ways to think about this year&#39;s reckoning.

Our AI writers make their big bets for the coming year—here are five hot trends to watch.

By studying large language models as if they were living things instead of computer programs, scientists are discovering some of their secrets for the first time.

In an exclusive interview, the AI pioneer shares his plans for his new Paris-based company, AMI Labs.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-60')">
            <div class="source">The Next Web</div>
            <div class="title">Noora Saksa steps in as new Slush CEO</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-60" style="display:none;">
            <h2>Noora Saksa steps in as new Slush CEO</h2>
            <p><strong>The Next Web | 2026-01-27</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/noora-saksa-steps-in-as-new-slush-ceo">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Slush, the Finnish nonprofit behind one of the most influential startup gatherings in Europe, has named Noora Saksa as its new Chief Executive Officer, a shift that indicates a strategic evolution for the organisation as it expands beyond its flagship event model.

Saksa assumes the top role after years as Slush’s Chief Operating & Financial Officer and Head of Partnerships, where she managed core operations, finances, and ecosystem programmes.

Her trajectory within the organisation reflects a deep operational understanding of Slush’s mission: to connect founders, investors, and builders in ways that help founders advance on their journeys.

In stepping into the CEO role, Saksa inherits an agenda that extends far beyond an annual conference in Helsinki.

The latest rumblings from the EU tech scene, a story from our wise ol&#39; founder Boris, and some questionable AI art. It&#39;s free, every week, in your inbox. Sign up now!

Under her leadership, Slush aims to grow year-round engagement through digital experiences and local ecosystem programmes, and to deepen its reach in founder support globally.

Board members see her operational experience and ecosystem insight as assets for Slush’s next chapter.

Slush remains organised largely by a core team of young professionals and volunteers, a structure that has supported its rapid growth since the early 2010s.

The event brings together thousands of founders and investors each year, and the organisation’s year-round platform aims to sustain connections long after the main event ends.

In her opening statement as CEO, Saksa said the focus will remain on building meaningful experiences that help founders tackle practical challenges, expand networks, and find capital. Her intimate knowledge of Slush’s operations positions her to balance growth ambitions with the organisation’s mission-driven ethos.

Noora Saksa has played a central role at Slush as Chief Operating & Financial Officer and Head of Partnerships, overseeing operations, finances, and startup-focused programmes. Before her tenure at Slush, she held leadership roles in entrepreneurial student societies and worked in startup support functions. Saksa studied Industrial Engineering and Management at Aalto University with an exchange at Eindhoven University of Technology. Her experience spans operational strategy, ecosystem building, and partnership development within Nordic innovation communities.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-61')">
            <div class="source">The Next Web</div>
            <div class="title">Rainbow Weather raises $5.5M to refine real-time weather forecasting</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-61" style="display:none;">
            <h2>Rainbow Weather raises $5.5M to refine real-time weather forecasting</h2>
            <p><strong>The Next Web | 2026-01-26</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/rainbow-weather-raises-5-5m-to-refine-real-time-weather-forecasting">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Warsaw, Poland 26 January 2026 – Rainbow Weather has raised $5.5 million in seed funding to push weather forecasting further into the short-term, high-precision territory it believes the industry still underserves.

The Warsaw-based climate tech startup focuses on hyperlocal, minute-by-minute forecasts, zeroing in on what happens in the next few hours rather than days out.

The round was backed by a syndicate of investors, including Yuri Gurski, founder of Flo Health, one of Europe’s best-known consumer tech unicorns.

Rainbow Weather’s core product is a mobile app that delivers four-hour precipitation forecasts calculated from the exact moment a user checks the weather.

Open the app at 3:51 am, and it forecasts conditions through 7:51am, refreshed every 10 minutes and mapped down to a one-square-kilometre grid. That level of temporal and spatial precision is what the company says sets it apart from mainstream weather apps.

The latest rumblings from the EU tech scene, a story from our wise ol&#39; founder Boris, and some questionable AI art. It&#39;s free, every week, in your inbox. Sign up now!

Most major providers, including AccuWeather, Apple Weather, and The Weather Company, still rely on approaches that either simplify cloud movement or depend on large-scale numerical models designed for longer forecasts. According to Rainbow Weather, both methods struggle when conditions change quickly.

“Many legacy forecasting providers rely on optical flow for short-term precipitation forecasting. That’s a fast but simplistic method that treats clouds as shapes in motion, without any understanding of atmospheric physics,” explained Alexander Matveenko, co-founder of Rainbow Weather. “A second category of services uses large-scale mathematical models that do incorporate physical principles, but they’re so cumbersome and slow that they can’t respond quickly to real-time weather changes.”

Rainbow Weather positions itself in between, using machine learning to fuse high-resolution data from radar, satellites, weather stations, and even smartphone barometers. By combining these sources, the company claims it can reduce the noise and bias inherent in individual datasets, then generate forecasts faster than traditional systems.

The app currently focuses on short-term precipitation, but it has expanded into tracking wildfires and hurricanes, a feature added after the Palisades fire in Los Angeles. That expansion reflects a broader ambition to become a real-time risk awareness tool, not just a rain predictor.

The new funding will be used to extend Rainbow Weather’s forecasting window from four hours to 24 hours, add more weather parameters beyond precipitation, and grow its B2B offering.

The commercial weather intelligence market is expected to grow steadily over the next decade, driven by industries that depend on precise, near-term forecasts, from logistics and agriculture to aviation and drone operations.

Rainbow Weather says it has surpassed one million installs and has launched APIs aimed at companies that “can’t afford to get weather wrong.” It has also partnered with an unnamed long-term forecasting firm, supplying near-term data to improve broader climate models.

The founding team brings a track record of exits in applied AI. CEO Yuriy Melnichek previously founded AIMatter, acquired by Google, as well as consumer apps later bought by Pinterest and Farfetch. Matveenko previously sold mapping startup MapData to Mapbox.

Alongside its commercial products, the team also runs weatherindex.ai, an open-source project that evaluates short-term precipitation forecasts from major providers in real time. The tool compares live forecasts against verified airport weather reports, using standard accuracy metrics. It’s an unusual move in an industry not known for transparent benchmarking.

For Rainbow Weather, that openness is part of the pitch. The company is betting that as climate volatility increases, users and businesses will care less about next week’s weather and more about what happens in the next hour, and whether the forecast can be trusted.

Rainbow Weather is a next-gen climate tech startup for ultra-accurate short-term forecasts founded in 2021 by Yuriy Melnichek, who previously built AIMatter (acquired by Google), a neural network-based AI platform, as well as the video creation and editing app Vochi (acquired by Pinterest), and fashion marketplace Wanna (acquired by Farfetch), and Alexander Matveenko, a founder of artificial intelligence mapping startup MapData that he sold to Mapbox in 2017.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-62')">
            <div class="source">The Next Web</div>
            <div class="title">Synthesia’s valuation jumps to $4B after $200M raise</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-62" style="display:none;">
            <h2>Synthesia’s valuation jumps to $4B after $200M raise</h2>
            <p><strong>The Next Web | 2026-01-26</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/synthesias-valuation-jumps-to-4b-after-200m-raise">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">London-based AI video startup Synthesia has raised $200 million in a Series E round, nearly doubling its valuation to around $4 billion and cementing its position as one of Europe’s most valuable AI companies.

The round was led by Google Ventures, with participation from existing investors, underscoring continued appetite for applied AI products that have already found a clear commercial use.

Synthesia builds generative AI tools that let companies create videos using AI-generated avatars instead of cameras, studios, or presenters. The technology has found a strong foothold in corporate training, internal communications, and product explainers, areas where speed, scale, and consistency often matter more than production gloss.

“Synthesia was founded on two core beliefs: first, that AI will bring the cost of content creation down to zero. And secondly, that AI video provides a better, more engaging way for organizations to communicate and learn,” said Victor Riparbelli, Synthesia’s co-founder and CEO.

Synthesia says a significant share of Fortune 100 companies now use its platform, a rare level of enterprise penetration for a European AI startup at this stage. Rather than chasing consumer virality, the company has built its business around predictable, high-value enterprise use cases, a strategy investors have increasingly rewarded over the past year.

The funding comes at a moment when enthusiasm around generative AI has shifted from experimentation to execution. Enterprises are no longer asking whether AI video works, but how reliably it can plug into existing workflows.

The latest rumblings from the EU tech scene, a story from our wise ol&#39; founder Boris, and some questionable AI art. It&#39;s free, every week, in your inbox. Sign up now!

Synthesia’s pitch is that AI-generated video should be as routine as slides or documents, created quickly, updated easily, and deployed globally without production bottlenecks.

At a $4 billion valuation, Synthesia joins a small group of European AI companies that have managed to scale beyond regional relevance.

Its rise also highlights a broader pattern: applied AI startups, focused on specific business functions rather than general-purpose models, are attracting some of the largest growth rounds in the market.

For the UK tech ecosystem, the deal is another signal that London remains a serious hub for commercial AI, even as regulatory debates continue around model safety, copyright, and synthetic media.

Synthesia has previously positioned itself as cautious about misuse, building safeguards around consent and disclosure for its avatars, a stance that may become more important as scrutiny of AI-generated content increases.

The challenge ahead is less about proving demand and more about maintaining trust and differentiation as competitors multiply.

But with deep enterprise adoption, a clear product focus, and backing from one of Silicon Valley’s most influential investors, Synthesia is entering its next phase with momentum firmly on its side.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-63')">
            <div class="source">The Next Web</div>
            <div class="title">TNW Weekly Briefing</div>
            <div class="meta">2026-01-25</div>
        </div>
        
        <div id="content-63" style="display:none;">
            <h2>TNW Weekly Briefing</h2>
            <p><strong>The Next Web | 2026-01-25</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/tnw-weekly-briefing-2">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">What: The European Commission unveiled EU Inc (“28th regime”), a single EU-wide legal company structure designed to let startups incorporate once and operate across all member states.
Who it affects: European startups & scale-ups, founders, VCs, international investors.
How: Reduces legal fragmentation, standardises corporate and investment structures, lowers friction for cross-border scaling.
Impact timing: Strategic impact now (capital & expectations), real operational impact from 2027–2028.

What: The EU proposed mandatory rules to remove and replace technology from suppliers deemed “high-risk” in telecoms and other critical networks.
Who it affects: Telecom operators, infrastructure providers, governments, Chinese tech vendors, cybersecurity supply chains.
How: Forces equipment replacement, raises capex, hardens security requirements across Europe.
Impact timing: Immediate policy impact, execution over the next few years.

What: European institutions publicly backed a strategy to reduce reliance on US technology across cloud, software, semiconductors and AI, often referred to as building a European “tech stack.”
Who it affects: US hyperscalers, European cloud & AI companies, policymakers, public procurement.
How: Shapes future regulation, funding priorities and government tech buying decisions.
Impact timing: Political and strategic impact now, regulatory and market impact medium-term.

This week wasn’t about hype:
EU Inc sets the future structure, high-risk tech phase-out enforces security now, and tech sovereignty defines Europe’s direction.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-64')">
            <div class="source">The Next Web</div>
            <div class="title">Mews raises €255M to accelerate AI and automation in hospitality</div>
            <div class="meta">2026-01-24</div>
        </div>
        
        <div id="content-64" style="display:none;">
            <h2>Mews raises €255M to accelerate AI and automation in hospitality</h2>
            <p><strong>The Next Web | 2026-01-24</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/mews-raises-e255m-to-accelerate-ai-and-automation-in-hospitality">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Amsterdam-based hospitality tech platform Mews has raised €255 million (about $300 million) in a Series D funding round as it pushes deeper into automation and AI-powered workflows for hotels around the world.

The round was led by EQT Growth with new participation from Atomico and HarbourVest Partners, alongside existing backers including Kinnevik, Battery Ventures and Tiger Global. The investment values the company at roughly $2.5 billion.

Founded in 2012 by Richard Valtr and Matt Welle, Mews builds a cloud-native “operating system” for hotels  software that ties together reservations, check-ins, housekeeping, payments and more in one platform.

Its technology is designed to replace legacy systems that many hotels still rely on, offering a more flexible, connected way to manage day-to-day operations.

The new funding will be used to expand the company’s AI and automation capabilities at the core of its product.

The latest rumblings from the EU tech scene, a story from our wise ol&#39; founder Boris, and some questionable AI art. It&#39;s free, every week, in your inbox. Sign up now!

That includes embedding agent-driven systems that can take on complex routine tasks, reduce manual work for staff and streamline how hotels handle everything from guest interactions to revenue management.

Mews says its platform already supports more than 15,000 properties in 85 countries, and in 2025 it processed nearly 42.3 million check-ins and handled nearly $20 billion in transaction volume.

The software also helped generate over $500 million in additional revenue for hoteliers through features like its Mews Spaces module.

In a statement, CEO Matt Welle said the new capital will help Mews build an operating system that handles operational complexity so hotel teams can focus on guest experience rather than juggling disparate tools.

“We are engineering an operating system that is changing how hoteliers interact with their guests,” CEO Matt Welle said, adding that the goal is to lighten the cognitive load on staff and make everyday operations smoother.

Industry observers say the round is one of the largest ever in hospitality software and reflects broader investor interest in infrastructure-level platforms that bring AI and fintech together for real-world business operations.

As hotels embrace digital transformation, technology that can automate workflows and personalise guest experiences  without adding complexity is increasingly in demand.

For Mews, the challenge now is execution: turning generous funding into tangible upgrades that deliver value for hoteliers of all sizes.

But with strong adoption, a global footprint and a growing suite of automation tools, the company is positioning itself as a central technology partner at a time when hotels are looking to modernise their operations and enhance guest satisfaction.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-65')">
            <div class="source">The Next Web</div>
            <div class="title">How Flippa Is Removing the Language Barrier from Global Deal-Making</div>
            <div class="meta">2026-01-23</div>
        </div>
        
        <div id="content-65" style="display:none;">
            <h2>How Flippa Is Removing the Language Barrier from Global Deal-Making</h2>
            <p><strong>The Next Web | 2026-01-23</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/how-flippa-is-removing-the-language-barrier-from-global-deal-making">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">For decades, access to high-quality deal flow and sophisticated M&A infrastructure has been largely designed for well-connected investors and industry giants. Small businesses and independent founders, particularly those operating outside English-speaking markets, may often find the barriers even higher. Language, geography, and limited access to networks could mean that opportunity stops at the border.

Amidst this trend, Flippa, a platform for buying and selling digital businesses, is rewriting the script and dismantling those barriers. Under the leadership of CEO Blake Hutchison, the company has connected buyers and sellers across continents, linguistic differences, and price points, closing deals from $100,000 up to $10 million. Now, with the launch of its AI-powered multi-language Deal Room, Flippa is addressing what it sees as one of the last major points of disadvantage in global business deals and M&A, calling it the “Language Tax.”

Founded in 2009, Flippa has grown into a global marketplace where entrepreneurs can buy and sell digital assets ranging from e-commerce stores and SaaS businesses to YouTube channels, online communities, and mobile applications. According to Hutchison, the platform supports users from 189 countries, attracting over 450,000 new buyers in the last two years alone. “Our internal data shows that cross-border transactions now account for approximately 85% of all deals completed on the platform,” Hutchison says. “That growth has been especially pronounced in Europe. As a highly fragmented market with high cross-border trade volume but multiple operating languages, I believe Europe often faces structural friction in cross-border dealmaking.”

He notes that European businesses are increasingly being acquired by international buyers, with US-based acquirers representing a significant share of demand. Yet, as deal volumes continue to decline, Hutchison believes that language barriers have historically slowed or derailed otherwise viable transactions.

The latest rumblings from the EU tech scene, a story from our wise ol&#39; founder Boris, and some questionable AI art. It&#39;s free, every week, in your inbox. Sign up now!

The company’s new multi-language Deal Room is designed to remove that friction entirely. Within the Deal Room, Hutchison notes that buyers and sellers can now negotiate and transact in their preferred languages. “For example, a French seller can communicate in French with an Italian or English-speaking buyer, who receives the message instantly translated into their own language,” he says, explaining how replies can be translated back in real time, while preserving the original message for verification and clarity.

Hutchison states, “Our goal is to make deal-making as efficient and approachable as possible. Whether you are a SaaS founder in Paris or an e-commerce operator in Berlin, you should be able to negotiate your exit in the language of your choice.”

Alongside the Deal Room translation tool, Flippa has also launched a fully localized French version of its platform, with Spanish scheduled to follow shortly. The expansion reflects the user demand and the reality that French and Spanish are not only widely spoken across Europe, but globally. Spanish is spoken by 550 million people globally, and is spoken widely across the US and Brazil. Similarly, French, being the 5th most widely spoken language in the world, has 321 million speakers, with 61.8% of those speakers living in parts of North Africa and Sub-Saharan Africa, significantly extending the global reach of European-founded businesses.

According to Hutchison, this shift comes as Europe’s M&A market continues to rise again, with an estimated USD412 billion in deal value, with mid-market and digital-first businesses representing one of the fastest-growing segments. Flippa’s role, according to Hutchison, has been to create infrastructure for businesses to source deals with greater reach than elite investment banks, but with a fraction of the cost.

“We often describe Flippa as the investment bank for the 99%,” Hutchison says. “The difference now is that geography and language no longer define who gets access. The demand for cross-border deals was already there. The technology simply needed to catch up.”

Flippa continues to integrate AI-driven discovery, valuation, and outreach tools through its proprietary LaurenAI engine. “The model is trained on more than 200,000 historical listings and transactions,” he explains. “The system then helps buyers identify opportunities, estimate enterprise value, and initiate conversations at scale.” It autonomously indexes the web to identify businesses across SaaS, e-commerce, apps, publishing, and next-generation media.

Human expertise remains embedded in the process, with certified brokers and M&A professionals supporting transactions once a match is made. As Hutchison puts it, “LaurenAI gives people the ability to access off-market deals and build pipelines the same way Wall Street players do, but without the barriers of capital or connections.”

He notes that entrepreneurs who may not feel confident negotiating complex deal terms in English can now access global liquidity without intermediaries or external advisors. At the same time, international buyers can gain visibility into high-quality European businesses that were previously difficult to source or engage.

As digital entrepreneurship continues to globalize, Flippa is positioning itself at the center of a more inclusive M&A ecosystem, one where language is no longer a tax on ambition and opportunities. Flippa’s multi-language Deal Room represents a structural shift in how global deal-making can be done. For founders and buyers alike, it signals a future where the next meaningful transaction can begin in any language, from anywhere in the world.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-66')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">India, EU slash tariffs on autos, spirits, textiles in landmark trade deal - Reuters</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-66" style="display:none;">
            <h2>India, EU slash tariffs on autos, spirits, textiles in landmark trade deal - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2026-01-27</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiwgFBVV95cUxObmhYVjFfWEFhd29vWFpvUF83X0gzeEVrZGZadFFnQ0dEU0dSbjhFa0s4cUc0T1d6RXVzMjFreGdXTC1ZY2Z2cjlPMTItclBWQjFna05OR3k1TTl2bE9TckxrTGVtbVBPbXVmZDZ1c3dvenU4T3pSU1lDX0JHV2hJclk0X3JOZnY0RVlYaVc2TWRYRVRoVDQydWdDNUpVNVJTYVJWLVg2OHlxcVJqb1p2Q1doeTF1LXh1eWxfdWpPUTJHdw?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-67')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">North Korea fires missiles into sea amid talks of limiting US military role - Reuters</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-67" style="display:none;">
            <h2>North Korea fires missiles into sea amid talks of limiting US military role - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2026-01-27</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMivwFBVV95cUxPQWZvSEVOUHFDQ2NXRkFFcFlKRmVRdUg3cTdLeVhFWVhpc3ZmV3JIYVloWnpQTmhodlMwdzZVcWMwZ3k5clN5NllMeXAxTVlVZ2lWdWtaaGlPa3cyUlAzc190azdkZ3JNeWlfTXEtcUx5d0tDcWszdmZRSTFsWGI5Qk1DMzljU3k5VG9PcmZHcVNrcXhMT0tnRFNYc3N0U3JvMVp0TnBoWDFNVFRtdmtXUzdiV19mSER5ajczSnpwSQ?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-68')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">ASML rides Nvidia's coattails with lasers and huge chip 'printers' - Reuters</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-68" style="display:none;">
            <h2>ASML rides Nvidia's coattails with lasers and huge chip 'printers' - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2026-01-27</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMirAFBVV95cUxQSXRVdVB4RnJHYlhLME43eTdleElGM18xdjJCSEMyUHlnSlVLMEMwNnZKQ0R3WkpmQl9vUWhjM29pcHMyOEtBUFNINUNDM2t6Tlcyd0pnV0ZkTHZZdm9hRkNCekNuTUZ5TGNaZVZ6T3VLamRDaVBENmhZZGhyMFR0Mjl5cWN1V2tRUVNEazZHb2txOVZrV3E3SnNpemZzZmRoZWw1MWoyNjJFX0Zp?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-69')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">Morning Bid: What tariffs? Investors soak up the dip - Reuters</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-69" style="display:none;">
            <h2>Morning Bid: What tariffs? Investors soak up the dip - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2026-01-27</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMilwFBVV95cUxQeW5XdjN2Y2FxWVdGWXlBMjBSU3pSNWgzY3Q2b2k2QUNSSGRrbmplbXk1QklzdTVGMldzbVEtZlZoVWV1NnMwU3ZEdkJyRjZKX1dWaldjdVlwVHQzQWtvZmNlUVhSY3V3RFRkU2doR1NCbm9SWEhDOVpUYXhBWEJja1kwa01MRTFIcTlJWFBEQXU3b2xLR2Rn?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-70')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">Exclusive: Saudi Arabia suspends work on massive Mukaab megaproject, sources say - Reuters</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-70" style="display:none;">
            <h2>Exclusive: Saudi Arabia suspends work on massive Mukaab megaproject, sources say - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2026-01-27</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiuwFBVV95cUxOU2QtMlFKMk9lN2RJeGN3WE51eFVVSURDZ2x5ckFyeVFSbXhTNi1NSU5TWUstdksxYW82TEZwdlN2eDFjLWphVnhGcHBjN2lia28xWkZEVDc2enBaSTdCRk9TdlV1MEtMMW1HZlR1dk15MERNYUgwLWVBQWxrNjRfLXRPdkJsN2ptUHM3bWtFYzdzQXU2RzE5R0gxYTJDVlk4R1VHb1MtS21lTFlMc2lBRTBUaS0zd1dwV3Vr?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-71')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">Exclusive: Japan, US eye synthetic diamond production under $550 bln investment plan - Reuters</div>
            <div class="meta">2026-01-27</div>
        </div>
        
        <div id="content-71" style="display:none;">
            <h2>Exclusive: Japan, US eye synthetic diamond production under $550 bln investment plan - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2026-01-27</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMixAFBVV95cUxQWGZRV3FaOW9nWUI0aVBGWW1oZ3JwXy00a2UwdlU3cmo4YzdSSDlWYlFLa0kzMjRrQmdDejRJWlBEMW5ESWVuSmp1cllmel9OZ3NVWDZvV1Qyak5nQlNzV2lsMlgycXNqUmxZcXE4ZkNWcDA0M0dkbm9mSm1acDV1RHFjZThOVGVqZXdIWDl1QmNudkFyUmVEdUVWWlVKSmZxYy1iemhvcmNMQm1wMUtaNWRIM1hSaE1rTnVOWTdvREdvenl5?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-72')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">Scientists Discover “Master Regulator” That Could Help Reverse Brain Aging at Its Source - The Debrief</div>
            <div class="meta">2026-01-20</div>
        </div>
        
        <div id="content-72" style="display:none;">
            <h2>Scientists Discover “Master Regulator” That Could Help Reverse Brain Aging at Its Source - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2026-01-20</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMirwFBVV95cUxOdWxhR3UtU1g1eFpMT1ozNjIySFBVeUpfX1ktZlN2Xy1lUGljSkpGSG10WEF0d19jOTNZMjhpcGVPQ0VuS3ZuTnV0YzFjSlRCaml3Q2ZKeHRqT09MREN3THZuM0dadXl2YnI5THhYREtFY1pjM0lfbmd2SXZuNElDaG54OWxNZXJwUHNJXzcyTHdiV2NNRnhHV2J6TmZibm9RNnczRFpsTWdkRWJtdlc0?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-73')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">James Webb Space Telescope Captures the Stunning Demise of a Star in the Helix Nebula - The Debrief</div>
            <div class="meta">2026-01-22</div>
        </div>
        
        <div id="content-73" style="display:none;">
            <h2>James Webb Space Telescope Captures the Stunning Demise of a Star in the Helix Nebula - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2026-01-22</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMirgFBVV95cUxPVXFOVjBSLVpmQ05fMFJoQVBxVDFhX3JpdWdnYXk4YzcxUENIMHIyTHkzV1dRVnNGOUkzc3QzelhJUDVYMUV0b1A1MjdLRkRnMVZYRGJSMVdHVnRVc1lnTkNuLVBrak03NmM1WG9RMTFkN3BLUGVxWHRqVTIwSmdjM2tobDd5YWFmQmNGUU8xbndVVzlWcDM2WDRld0tjemhjX2JBLUF6X0g5VHJPRVE?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-74')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">Strange Quantum Effects Persist in Surprisingly Large Particles, New Research Reveals - The Debrief</div>
            <div class="meta">2026-01-24</div>
        </div>
        
        <div id="content-74" style="display:none;">
            <h2>Strange Quantum Effects Persist in Surprisingly Large Particles, New Research Reveals - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2026-01-24</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMirAFBVV95cUxPX2tuWVFKZERlVHNabkJpLUZBclNhUkpKc0JCWVcwU0UwTTh5SlREdzZ2bFBQODdnZ1BiSGVDcktSMWkzMm8yOThqRzFUdFBHN2dfazdkMUtyaGRVbnRmSTA2WU9NdzhyeFRVT3RiNTJSNDBUVW1Fb1BGYVc5UGxpZElnMmFNUnpMQ2NiM09BOGZfWUJhS2ZzdVBkc3NCOXhDek80VHdzYjE3NjI0?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-75')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">Superconductivity Breakthrough Brings Practical Use Closer than Ever, as Team Unveils "Hidden Magnetic Order in the Pseudogap" - The Debrief</div>
            <div class="meta">2026-01-21</div>
        </div>
        
        <div id="content-75" style="display:none;">
            <h2>Superconductivity Breakthrough Brings Practical Use Closer than Ever, as Team Unveils "Hidden Magnetic Order in the Pseudogap" - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2026-01-21</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMi4AFBVV95cUxPTkV1UExSZ2dMS094c25BUTQ0cmJxT21paDI2UTBhX3c5RVdaMndBQ0MxY1NVTTVLOFhEWXNfeE0yR1NFNlk3LUdTdnVDbk9WWVdKeDA1NTRqSnlHU0Q2VEJxQUtlQ0hVckRzTVM4LXJpSlcyajRfaUFpbDNXRThvX1B4SmpuQ05VTnpWNmRTdFpSRksyR0lRd2xCNVVLZThTMndETDUxTWNjWGpvNGU5RlNtN2dNZ3NfU1p5SVVKaU9xaW1HYXdfazFoS3RjTmVUMHJhU3BTWmhVWnd1Yi1vVA?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-76')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">Archaeologists: Half a Million-Year-Old Elephant Bone Hammer Wasn’t Made by Modern Humans - The Debrief</div>
            <div class="meta">2026-01-22</div>
        </div>
        
        <div id="content-76" style="display:none;">
            <h2>Archaeologists: Half a Million-Year-Old Elephant Bone Hammer Wasn’t Made by Modern Humans - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2026-01-22</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMisAFBVV95cUxPWTFUMXVQQXVoZENJdlA1Q29xUXJhZ1NwbXR1OVBIZ0VNNXdaN0VMVFF1alVxcGl1UDFaT3A2U2JfaXpSY0d6dF9CLVNwYUtqa285eTVyUHlBaXFiM0RPT283eW9kckJ2VXIwemlBa09KN2NvOFFvYUc5b2s2LTdNYTc3SGY4Q2R6azFiRUR4OVRqRGNyd1BXN3RQaUZtNUpBamlTbG9YUm5vdUt6ME1WUA?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-77')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">50,000-Year-Old Artifacts Unearthed at Controversial Archaeological Site Could Rewrite the Early Prehistory of the Americas - The Debrief</div>
            <div class="meta">2026-01-21</div>
        </div>
        
        <div id="content-77" style="display:none;">
            <h2>50,000-Year-Old Artifacts Unearthed at Controversial Archaeological Site Could Rewrite the Early Prehistory of the Americas - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2026-01-21</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMi3wFBVV95cUxPQzR6eFVORUdoblVyV2VWOVlScHR4NXQtV1Z4dUZYdzdjUjRwUnhYdm11QVBaZXF5S3NKYUE0d2hlMzZqMmc4T2pzc3AzdmRBekNOZFhYYWdfNG1LZmdpOEZuOGxaUjUyVmRTNXg0VmV3amw1WTRvSGJ4aUtENWZFMWE5NmVFaHZGYjBheHRMT0RSc255OFdscEthMm1tUG4xdEhmeFZqd1hqRENkSi10VnBnQURvemIxMlVOVGZURlJ2dlJWb3ZLRFFPZjVJRkJPeUN1RXdNLVZFMDJuT2dZ?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-78')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">OpenAI Seeks Premium Prices in Early Ads Push - The Information</div>
            <div class="meta">2026-01-26</div>
        </div>
        
        <div id="content-78" style="display:none;">
            <h2>OpenAI Seeks Premium Prices in Early Ads Push - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2026-01-26</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiigFBVV95cUxNdWtfbVYwRUFRS0czZHI0VkFhNTVUdEQxS1pwUVIza194NVdpYnNTTkplWnVNU05fbjZpaWZsakpoU1lZZFNjV0s1a1Fld3ZvclFmS3dxMlRuVmJlaU9Bd1hVd1JKUVpjN1I5RERYbkwzSmtaUHRHNUw1ODJGRXpvRUwzWHByOVd3aUE?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-79')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">OpenAI Plans to Take a Cut of Customers’ AI-Aided Discoveries - The Information</div>
            <div class="meta">2026-01-22</div>
        </div>
        
        <div id="content-79" style="display:none;">
            <h2>OpenAI Plans to Take a Cut of Customers’ AI-Aided Discoveries - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2026-01-22</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiqgFBVV95cUxPcHdxSmlWVVZxSnAtU05FazNqajZjeThEV0RvVG9SU1BGU2VmODF5QmppXzdOYnRLSnl6NmVFZk5IZ19Md3hlZjdxVGlvY3Frc2lFZGtDWkhrM2g4VjFyRmlHRnRNOTRXaFIteEVEWVR1Wk1rWFZIR0dxVXpoOTJaa21uVkpKY2NZc0hsSjhSU2x2bzEtRE80cTRGVFRaa1EzTnBwR1gwdFBwQQ?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-80')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">Anthropic Lowers Gross Margin Projection as Revenue Skyrockets - The Information</div>
            <div class="meta">2026-01-22</div>
        </div>
        
        <div id="content-80" style="display:none;">
            <h2>Anthropic Lowers Gross Margin Projection as Revenue Skyrockets - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2026-01-22</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiogFBVV95cUxOOFNsY05rYkNDRWFDVzQzVk1CdF9yaGpLbnpmelNBcW9yQkQtNVhXUVlqNTRpZElnOFl1Q3lya1ozMlV6bzh2M21MWlNBdHh5TjlOaUppMWNhWWR5TmxPYmlkaEZSMURzbGNJS0dlcXdmSEViWEFST3dnZGpFR2MxNnRBSUFJZ091T2hwXzFQdTFzbnRhUU1IYkx1TE45emlPRHc?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-81')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">Behind the Sky-High Valuation of China’s AI IPOs - The Information</div>
            <div class="meta">2026-01-25</div>
        </div>
        
        <div id="content-81" style="display:none;">
            <h2>Behind the Sky-High Valuation of China’s AI IPOs - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2026-01-25</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMihwFBVV95cUxNVDBCYlp5aW11SUVISHRtb1M4S0xqQ1BQLWlESkV3TGJxXzM1c0tUYnBOa2J6NkE1am14SHBYU0RBM1RDT2pLb3NndWNkd04tZWxId2ZzWlRjdWt0ODluRkphRUtTR2VxZExGQ0JEQmprM3RZbWhlUm5jWS1EUlF6Njg3cWE4QUE?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-82')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">Yelp to Buy AI Agent Startup for $300 Million - The Information</div>
            <div class="meta">2026-01-21</div>
        </div>
        
        <div id="content-82" style="display:none;">
            <h2>Yelp to Buy AI Agent Startup for $300 Million - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2026-01-21</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMihAFBVV95cUxOU2pKNlJoY0JxcTVHVVUzR05BcDdWcVFJX2NqTkdGRk9LeGZHSXRoNUpNN3pMeDktcFl1RnV3Yjlrc0MxT1p1dHpxWF9NdDlzVGhhUXlISG5RR2NCb2NTbERLUWU2b1FOXzJoUWlmTjc4eVFwazRYenpHZXlFRmRlVUtudGc?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-83')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">AI Videos Nearly Indistinguishable From Real Videos, Runway Finds - The Information</div>
            <div class="meta">2026-01-21</div>
        </div>
        
        <div id="content-83" style="display:none;">
            <h2>AI Videos Nearly Indistinguishable From Real Videos, Runway Finds - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2026-01-21</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMisgFBVV95cUxNQ3QtWTRac0xISlVaUnZldWl3WG5PSFEzNmdLdzl4R2Vna3RfLVg4R3hrc202cGd6N3I4X2ZmYzRyUlhHQlduWGItN2hrSlpqNFc3OE1LT1BmeTNaZUNyMHVOSVAxTVZaTmZQbW9sMW95cDdsd1NyN1BpWFhFeDdrc1docDl5clNteUtmdjlxclN0WndtUVhDVWlEZTh4aVJLRjVReldNcUN5ajVLeTdjTjNR?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        </div>

        <div id="reader-modal">
            <div id="close-btn" class="control-btn" onclick="closeModal()">X</div>
            
            <div id="scroll-controls">
                <button class="scroll-btn" onclick="scrollPage(-1)">&#9650;</button> <button class="scroll-btn" onclick="scrollPage(1)">&#9660;</button>  </div>

            <div id="modal-inner"></div>
        </div>

        <script>
            // 1. RANDOMIZE ORDER
            const list = document.getElementById('feed-list');
            const cards = Array.from(document.querySelectorAll('.card'));
            cards.sort(() => Math.random() - 0.5);
            cards.forEach(card => list.appendChild(card));

            // 2. DARK MODE
            const btn = document.getElementById('theme-toggle');
            btn.addEventListener('click', () => document.body.classList.toggle('dark-mode'));

            // 3. MODAL & SCROLL LOGIC
            const modal = document.getElementById('reader-modal');
            const modalInner = document.getElementById('modal-inner');

            function openModal(contentId) {
                const content = document.getElementById(contentId).innerHTML;
                modalInner.innerHTML = content;
                modal.style.display = 'block';
                document.body.style.overflow = 'hidden'; 
            }

            function closeModal() {
                modal.style.display = 'none';
                document.body.style.overflow = 'auto';
            }

            function scrollPage(direction) {
                // Scroll by 80% of the screen height to keep context
                const scrollAmount = window.innerHeight * 0.8;
                modal.scrollBy(0, direction * scrollAmount);
            }
        </script>
    </body>
    </html>
    