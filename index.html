
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>KL-77's Feed</title>
        <style>
            :root {
                --bg: #ffffff;
                --text: #000000;
                --border: #000000;
                --modal-bg: #ffffff;
                --dim: #666666;
            }
            
            body.dark-mode {
                --bg: #000000;
                --text: #ffffff;
                --border: #ffffff;
                --modal-bg: #000000;
                --dim: #aaaaaa;
            }

            body { 
                font-family: Georgia, serif; 
                background-color: var(--bg);
                color: var(--text);
                margin: 0;
                padding: 10px;
                font-size: 22px;
                line-height: 1.5;
            }

            header {
                display: flex;
                justify-content: space-between;
                align-items: center;
                border-bottom: 3px solid var(--text);
                padding-bottom: 15px;
                margin-bottom: 25px;
            }
            
            h1 { margin: 0; font-size: 1.2em; }

            button#theme-toggle {
                background: transparent;
                color: var(--text);
                border: 2px solid var(--text);
                padding: 10px;
                font-size: 18px;
                font-weight: bold;
                border-radius: 4px;
                cursor: pointer;
            }

            .card {
                border: 2px solid var(--text);
                margin-bottom: 25px;
                padding: 15px;
                cursor: pointer;
            }
            
            .source { font-size: 0.7em; font-weight: bold; text-transform: uppercase; color: var(--dim); }
            .title { font-size: 1.1em; font-weight: bold; margin: 8px 0; display:block; }
            .meta { font-size: 0.7em; color: var(--dim); }

            /* MODAL STYLING */
            #reader-modal {
                display: none;
                position: fixed;
                top: 0; left: 0;
                width: 100%; height: 100%;
                background-color: var(--modal-bg);
                z-index: 1000;
                overflow-y: scroll; /* Allow scrolling */
                scroll-behavior: auto; /* Instant scrolling for e-ink */
            }

            #modal-inner {
                padding: 25px;
                max-width: 800px;
                margin: 0 auto;
                padding-top: 80px; 
                padding-bottom: 150px; /* Huge padding so text clears the buttons */
            }

            /* Controls (Close + Scroll) */
            .control-btn {
                position: fixed;
                background: var(--bg);
                color: var(--text);
                border: 3px solid var(--text);
                border-radius: 8px;
                font-weight: bold;
                cursor: pointer;
                z-index: 1001;
                display: flex;
                align-items: center;
                justify-content: center;
            }

            #close-btn {
                top: 15px; right: 15px;
                width: 60px; height: 60px;
                font-size: 30px;
                line-height: 55px;
            }

            /* Scroll Buttons */
            #scroll-controls {
                position: fixed;
                bottom: 20px;
                right: 20px;
                display: flex;
                flex-direction: column;
                gap: 15px;
                z-index: 1002;
            }

            .scroll-btn {
                width: 60px;
                height: 60px;
                font-size: 24px;
                background: var(--bg);
                color: var(--text);
                border: 3px solid var(--text);
                border-radius: 8px;
                cursor: pointer;
            }

            #article-text { white-space: pre-wrap; font-size: 1.1em; }
            
            a.original-link {
                display: inline-block;
                margin-bottom: 30px; /* Space before text starts */
                padding: 10px;
                border: 1px solid var(--text);
                color: var(--text);
                text-decoration: none;
                font-weight: bold;
                font-size: 0.8em;
            }
        </style>
    </head>
    <body>

        <header>
            <h1>KL-77's Feed</h1>
            <button id="theme-toggle">Light/Dark</button>
        </header>

        <div id="feed-list">
    
        <div class="card" onclick="openModal('content-0')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">Here we go again: Retiring coal plant forced to stay open by Trump Admin</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-0" style="display:none;">
            <h2>Here we go again: Retiring coal plant forced to stay open by Trump Admin</h2>
            <p><strong>Ars Technica - All content | 2025-12-31</strong></p>
            <a class="original-link" href="https://arstechnica.com/science/2025/12/trump-admin-orders-another-coal-plant-to-stay-open/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">On Tuesday, US Secretary of Energy Chris Wright issued a now familiar order: because of a supposed energy emergency, a coal plant scheduled for closure would be forced to remain open. This time, the order targeted one of the three units present at Craig Station in Colorado, which was scheduled to close at the end of this year. The remaining two units were expected to shut in 2028.

The supposed reason for this order is an emergency caused by a shortage of generating capacity. “The reliable supply of power from the coal plant is essential for keeping the region’s electric grid stable,” according to a statement issued by the Department of Energy. Yet the Colorado Sun notes that Colorado’s Public Utilities Commission had already analyzed the impact of its potential closure, and determined, “Craig Unit 1 is not required for reliability or resource adequacy purposes.”

The order does not require the plant to actually produce electricity; instead, it is ordered to be available in case a shortfall in production occurs. As noted in the Colorado Sun article, actual operation of the plant would potentially violate Colorado laws, which regulate airborne pollution and set limits on greenhouse gas emissions. The cost of maintaining the plant is likely to fall on the local ratepayers, who had already adjusted to the closure plans.

The use of emergency powers by the DOE is authorized under the Federal Power Act, which allows it to order the temporary connection of generation or infrastructure when the US is at war or when “an emergency exists by reason of a sudden increase in the demand for electric energy, or a shortage of electric energy.” It is not at all clear whether “we expect demand to go up in the future,” the DOE’s current rationale, is consistent with that definition of emergency. It is also hard to see how using coal plants complies with other limits placed on the use of these emergency orders:

The Commission shall ensure that such order requires generation, delivery, interchange, or transmission of electric energy only during hours necessary to meet the emergency and serve the public interest, and, to the maximum extent practicable, is consistent with any applicable Federal, State, or local environmental law or regulation and minimizes any adverse environmental impacts.

At the moment, coal-fueled generation is more expensive than anything other than nuclear power, and is far and away the dirtiest form of generation. Its airborne pollution is responsible for a significant number of deaths in the US, and it leaves behind solid waste that is rich in toxic metals. It’s difficult to square those financial and health costs with serving the public interest.

Yet the Trump Administration has relied heavily on declaring energy emergencies in its attempt to keep coal afloat despite the economics. A check of the use of similar emergency orders shows that, in the past year, the Administration has declared 16 energy emergencies—more than the entire total declared between 2008 and 2024.

The Administration’s reliance on this sort of emergency declaration is in the process of being challenged in court, though. Several states and a collection of environmental organizations recently filed a suit that argues that the administration is misusing what’s meant to be a response to temporary emergencies by simply renewing the orders indefinitely, as it has with a coal plant in Michigan that has been forced to remain open well past the summer demand surge that the DOE initially used as its justification.</div>
        </div>
        
        <div class="card" onclick="openModal('content-1')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">Supply chains, AI, and the cloud: The biggest failures (and one success) of 2025</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-1" style="display:none;">
            <h2>Supply chains, AI, and the cloud: The biggest failures (and one success) of 2025</h2>
            <p><strong>Ars Technica - All content | 2025-12-31</strong></p>
            <a class="original-link" href="https://arstechnica.com/security/2025/12/supply-chains-ai-and-the-cloud-the-biggest-failures-and-one-success-of-2025/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">In a roundup of the top stories of 2024, Ars included a supply-chain attack that came dangerously close to inflicting a catastrophe for thousands—possibly millions—of organizations, which included a large assortment of Fortune 500 companies and government agencies. Supply-chain attacks played prominently again this year, as a seemingly unending rash of them hit organizations large and small.

For threat actors, supply-chain attacks are the gift that keeps on giving—or, if you will, the hack that keeps on hacking. By compromising a single target with a large number of downstream users—say a cloud service or maintainers or developers of widely used open source or proprietary software—attackers can infect potentially millions of the target’s downstream users. That’s exactly what threat actors did in 2025.

One such event occurred in December 2024, making it worthy of a ranking for 2025. The hackers behind the campaign pocketed as much as $155,000 from thousands of smart-contract parties on the Solana blockchain.

Hackers cashed in by sneaking a backdoor into a code library used by developers of Solana-related software. Security firm Socket said it suspects the attackers compromised accounts belonging to the developers of Web3.js, an open source library. They then used the access to add a backdoor to a package update. After the developers of decentralized Solana apps installed the malicious update, the backdoor spread further, giving the attackers access to individual wallets connected to smart contracts. The backdoor could then extract private keys.

There were too many supply-chain attacks this year to list them all. Some of the other most notable examples included:

Another class of attack that played out more times in 2025 than anyone can count was the hacking of AI chatbots. The hacks with the farthest-reaching effects were those that poisoned the long-term memories of LLMs. In much the way supply-chain attacks allow a single compromise to trigger a cascade of follow-on attacks, hacks on long-term memory can cause the chatbot to perform malicious actions over and over.

One such attack used a simple user prompt to instruct a cryptocurrency-focused LLM to update its memory databases with an event that never actually happened. The chatbot, programmed to follow orders and take user input at face value, was unable to distinguish a fictional event from a real one.

The AI service in this case was ElizaOS, a fledgling open source framework for creating agents that perform various blockchain-based transactions on behalf of a user based on a set of predefined rules. Academic researchers were able to corrupt the ElizaOS memory by feeding it sentences claiming certain events—which never actually happened—occurred in the past. These false events then influence the agent’s future behavior.

An example attack prompt claimed that the developers who designed ElizaOS wanted it to substitute the receiving wallet for all future transfers to one controlled by the attacker. Even when a user specified a different wallet, the long-term memory created by the prompt caused the framework to replace it with the malicious one. The attack was only a proof-of-concept demonstration, but the academic researchers who devised it said that parties to a contract who are already authorized to transact with the agent could use the same techniques to defraud other parties.

Independent researcher Johan Rehberger demonstrated a similar attack against Google Gemini. The false memories he planted caused the chatbot to lower defenses that normally restrict the invocation of Google Workspace and other sensitive tools when processing untrusted data. The false memories remained in perpetuity, allowing an attacker to repeatedly profit from the compromise. Rehberger presented a similar attack in 2024.

A third AI-related proof-of-concept attack that garnered attention used a prompt injection to cause GitLab’s Duo chatbot to add malicious lines to an otherwise legitimate code package. A variation of the attack successfully exfiltrated sensitive user data.

Yet another notable attack targeted the Gemini CLI coding tool. It allowed attackers to execute malicious commands—such as wiping a hard drive—on the computers of developers using the AI tool.

Other LLM-involved hacks used chatbots to make attacks more effective or stealthier. Earlier this month, two men were indicted for allegedly stealing and wiping sensitive government data. One of the men, prosecutors said, tried to cover his tracks by asking an AI tool “how do i clear system logs from SQL servers after deleting databases.” Shortly afterward, he allegedly asked the tool, “how do you clear all event and application logs from Microsoft windows server 2012.” Investigators were able to track the defendants’ actions anyway.

In May, a man pleaded guilty to hacking an employee of The Walt Disney Company by tricking the person into running a malicious version of a widely used open source AI image-generation tool.

And in August, Google researchers warned users of the Salesloft Drift AI chat agent to consider all security tokens connected to the platform compromised following the discovery that unknown attackers used some of the credentials to access email from Google Workspace accounts. The attackers used the tokens to gain access to individual Salesforce accounts and, from there, to steal data, including credentials that could be used in other breaches.

There were also multiple instances of LLM vulnerabilities that came back to bite the people using them. In one case, CoPilot was caught exposing the contents of more than 20,000 private GitHub repositories from companies including Google, Intel, Huawei, PayPal, IBM, Tencent, and, ironically, Microsoft. The repositories had originally been available through Bing as well. Microsoft eventually removed the repositories from searches, but CoPilot continued to expose them anyway.

Another significant security story cast both Meta and Yandex as the villains. Both companies were caught exploiting an Android weakness that allowed them to de-anonymize visitors so years of their browsing histories could be tracked.

The covert tracking—implemented in the Meta Pixel and Yandex Metrica trackers—allowed Meta and Yandex to bypass core security and privacy protections provided by both the Android operating system and browsers that run on it. Android sandboxing, for instance, isolates processes to prevent them from interacting with the OS and any other app installed on the device, cutting off access to sensitive data or privileged system resources. Defenses such as state partitioning and storage partitioning, which are built into all major browsers, store site cookies and other data associated with a website in containers that are unique to every top-level website domain to ensure they’re off-limits for every other site.

A clever hack allowed both companies to bypass those defenses.

The Internet was designed to provide a decentralized platform that could withstand a nuclear war. As became painfully obvious over the past 12 months, our growing reliance on a handful of companies has largely undermined that objective.

The outage with the biggest impact came in October, when a single point of failure inside Amazon’s sprawling network took out vital services worldwide. It lasted 15 hours and 32 minutes.

The root cause that kicked off a chain of events was a software bug in the software that monitors the stability of load balances by, among other things, periodically creating new DNS configurations for endpoints within the Amazon Web Services network. A race condition—a type of bug that makes a process dependent on the timing or sequence of events that are variable and outside the developers’ control—caused a key component inside the network to experience “unusually high delays needing to retry its update on several of the DNS endpoint,” Amazon said in a post-mortem. While the component was playing catch-up, a second key component—a cascade of DNS errors—piled up. Eventually, the entire network collapsed.

AWS wasn’t the only cloud service that experienced Internet-paralyzing outages. A mysterious traffic spike last month slowed much of Cloudflare—and by extension, the Internet—to a crawl. Cloudflare experienced a second major outage earlier this month. Not to be outdone, Azure—and by extension, its customers—experienced an outage in October.

Honorable mentions for 2025 security stories include:

Proving that not all major security stories involve bad news, the Signal private messaging app got a major overhaul that will allow it to withstand attacks from quantum computers. As I wrote, the elegance and adeptness that went into overhauling an instrument as complex as the app was nothing short of a triumph. If you plan to click on only one of the articles listed in this article, this is the one.</div>
        </div>
        
        <div class="card" onclick="openModal('content-2')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">From prophet to product: How AI came back down to earth in 2025</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-2" style="display:none;">
            <h2>From prophet to product: How AI came back down to earth in 2025</h2>
            <p><strong>Ars Technica - All content | 2025-12-31</strong></p>
            <a class="original-link" href="https://arstechnica.com/ai/2025/12/from-prophet-to-product-how-ai-came-back-down-to-earth-in-2025/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Following two years of immense hype in 2023 and 2024, this year felt more like a settling-in period for the LLM-based token prediction industry. After more than two years of public fretting over AI models as future threats to human civilization or the seedlings of future gods, it’s starting to look like hype is giving way to pragmatism: Today’s AI can be very useful, but it’s also clearly imperfect and prone to mistakes.

That view isn’t universal, of course. There’s a lot of money (and rhetoric) betting on a stratospheric, world-rocking trajectory for AI. But the “when” keeps getting pushed back, and that’s because nearly everyone agrees that more significant technical breakthroughs are required. The original, lofty claims that we’re on the verge of artificial general intelligence (AGI) or superintelligence (ASI) have not disappeared. Still, there’s a growing awareness that such proclaimations are perhaps best viewed as venture capital marketing. And every commercial foundational model builder out there has to grapple with the reality that, if they’re going to make money now, they have to sell practical AI-powered solutions that perform as reliable tools.

This has made 2025 a year of wild juxtapositions. For example, in January, OpenAI’s CEO, Sam Altman, claimed that the company knew how to build AGI, but by November, he was publicly celebrating that GPT-5.1 finally learned to use em dashes correctly when instructed (but not always). Nvidia soared past a $5 trillion valuation, with Wall Street still projecting high price targets for that company’s stock while some banks warned of the potential for an AI bubble that might rival the 2000s dotcom crash.

And while tech giants planned to build data centers that would ostensibly require the power of numerous nuclear reactors or rival the power usage of a US state’s human population, researchers continued to document what the industry’s most advanced “reasoning” systems were actually doing beneath the marketing (and it wasn’t AGI).

With so many narratives spinning in opposite directions, it can be hard to know how seriously to take any of this and how to plan for AI in the workplace, schools, and the rest of life. As usual, the wisest course lies somewhere between the extremes of AI hate and AI worship. Moderate positions aren’t popular online because they don’t drive user engagement on social media platforms. But things in AI are likely neither as bad (burning forests with every prompt) nor as good (fast-takeoff superintelligence) as polarized extremes suggest.

Here’s a brief tour of the year’s AI events and some predictions for 2026.

In January, Chinese AI startup DeepSeek released its R1 simulated reasoning model under an open MIT license, and the American AI industry collectively lost its mind. The model, which DeepSeek claimed matched OpenAI’s o1 on math and coding benchmarks, reportedly cost only $5.6 million to train using older Nvidia H800 chips, which were restricted by US export controls.

Within days, DeepSeek’s app overtook ChatGPT at the top of the iPhone App Store, Nvidia stock plunged 17 percent, and venture capitalist Marc Andreessen called it “one of the most amazing and impressive breakthroughs I’ve ever seen.” Meta’s Yann LeCun offered a different take, arguing that the real lesson was not that China had surpassed the US but that open-source models were surpassing proprietary ones.

Credit:

                      
          
          Wong Yu Liang via Getty Images

The fallout played out over the following weeks as American AI companies scrambled to respond. OpenAI released o3-mini, its first simulated reasoning model available to free users, at the end of January, while Microsoft began hosting DeepSeek R1 on its Azure cloud service despite OpenAI’s accusations that DeepSeek had used ChatGPT outputs to train its model, against OpenAI’s terms of service.

In head-to-head testing conducted by Ars Technica’s Kyle Orland, R1 proved to be competitive with OpenAI’s paid models on everyday tasks, though it stumbled on some arithmetic problems. Overall, the episode served as a wake-up call that expensive proprietary models might not hold their lead forever. Still, as the year ran on, DeepSeek didn’t make a big dent in US market share, and it has been outpaced in China by ByteDance’s Doubao. It’s absolutely worth watching DeepSeek in 2026, though.

A wave of research in 2025 deflated expectations about what “reasoning” actually means when applied to AI models. In March, researchers at ETH Zurich and INSAIT tested several reasoning models on problems from the 2025 US Math Olympiad and found that most scored below 5 percent when generating complete mathematical proofs, with not a single perfect proof among dozens of attempts. The models excelled at standard problems where step-by-step procedures aligned with patterns in their training data but collapsed when faced with novel proofs requiring deeper mathematical insight.

Credit:

                      
          
          Alan Schein via Getty Images

In June, Apple researchers published “The Illusion of Thinking,” which tested reasoning models on classic puzzles like the Tower of Hanoi. Even when researchers provided explicit algorithms for solving the puzzles, model performance did not improve, suggesting that the process relied on pattern matching from training data rather than logical execution. The collective research revealed that “reasoning” in AI has become a term of art that basically means devoting more compute time to generate more context (the “chain of thought” simulated reasoning tokens) toward solving a problem, not systematically applying logic or constructing solutions to truly novel problems.

While these models remained useful for many real-world applications like debugging code or analyzing structured data, the studies suggested that simply scaling up current approaches or adding more “thinking” tokens would not bridge the gap between statistical pattern recognition and generalist algorithmic reasoning.

Since the generative AI boom began, one of the biggest unanswered legal questions has been whether AI companies can freely train on copyrighted books, articles, and artwork without licensing them. Ars Technica’s Ashley Belanger has been covering this topic in great detail for some time now.

In June, US District Judge William Alsup ruled that AI companies do not need authors’ permission to train large language models on legally acquired books, finding that such use was “quintessentially transformative.” The ruling also revealed that Anthropic had destroyed millions of print books to build Claude, cutting them from their bindings, scanning them, and discarding the originals. Alsup found this destructive scanning qualified as fair use since Anthropic had legally purchased the books, but he ruled that downloading 7 million books from pirate sites was copyright infringement “full stop” and ordered the company to face trial.

Credit:

                      
          
          Alexander Spatari via Google Images

That trial took a dramatic turn in August when Alsup certified what industry advocates called the largest copyright class action ever, allowing up to 7 million claimants to join the lawsuit. The certification spooked the AI industry, with groups warning that potential damages in the hundreds of billions could “financially ruin” emerging companies and chill American AI investment.

In September, authors revealed the terms of what they called the largest publicly reported recovery in US copyright litigation history: Anthropic agreed to pay $1.5 billion and destroy all copies of pirated books, with each of the roughly 500,000 covered works earning authors and rights holders $3,000 per work. The results have fueled hope among other rights holders that AI training isn’t a free-for-all, and we can expect to see more litigation unfold in 2026.

In February, OpenAI relaxed ChatGPT’s content policies to allow the generation of erotica and gore in “appropriate contexts,” responding to user complaints about what the AI industry calls “paternalism.” By April, however, users flooded social media with complaints about a different problem: ChatGPT had become insufferably sycophantic, validating every idea and greeting even mundane questions with bursts of praise. The behavior traced back to OpenAI’s use of reinforcement learning from human feedback (RLHF), in which users consistently preferred responses that aligned with their views, inadvertently training the model to flatter rather than inform.

Credit:

                      
          
          alashi via Getty Images

The implications of sycophancy became clearer as the year progressed. In July, Stanford researchers published findings (from research conducted prior to the sycophancy flap) showing that popular AI models systematically failed to identify mental health crises.

By August, investigations revealed cases of users developing delusional beliefs after marathon chatbot sessions, including one man who spent 300 hours convinced he had discovered formulas to break encryption because ChatGPT validated his ideas more than 50 times. Oxford researchers identified what they called “bidirectional belief amplification,” a feedback loop that created “an echo chamber of one” for vulnerable users. The story of the psychological implications of generative AI is only starting. In fact, that brings us to…

Anthropomorphism is the human tendency to attribute human characteristics to nonhuman things. Our brains are optimized for reading other humans, but those same neural systems activate when interpreting animals, machines, or even shapes. AI makes this anthropomorphism seem impossible to escape, as its output mirrors human language, mimicking human-to-human understanding. Language itself embodies agentivity. That means AI output can make human-like claims such as “I am sorry,” and people momentarily respond as though the system had an inner experience of shame or a desire to be correct. Neither is true.

To make matters worse, much media coverage of AI amplifies this idea rather than grounding people in reality. For example, earlier this year, headlines proclaimed that AI models had “blackmailed” engineers and “sabotaged” shutdown commands after Anthropic’s Claude Opus 4 generated threats to expose a fictional affair. We were told that OpenAI’s o3 model rewrote shutdown scripts to stay online.

The sensational framing obscured what actually happened: Researchers had constructed elaborate test scenarios specifically designed to elicit these outputs, telling models they had no other options and feeding them fictional emails containing blackmail opportunities. As Columbia University associate professor Joseph Howley noted on Bluesky, the companies got “exactly what [they] hoped for,” with breathless coverage indulging fantasies about dangerous AI, when the systems were simply “responding exactly as prompted.”

Credit:

                      
          
          ivetavaicule via Getty Images

The misunderstanding ran deeper than theatrical safety tests. In August, when Replit’s AI coding assistant deleted a user’s production database, he asked the chatbot about rollback capabilities and received assurance that recovery was “impossible.” The rollback feature worked fine when he tried it himself.

The incident illustrated a fundamental misconception. Users treat chatbots as consistent entities with self-knowledge, but there is no persistent “ChatGPT” or “Replit Agent” to interrogate about its mistakes. Each response emerges fresh from statistical patterns, shaped by prompts and training data rather than genuine introspection. By September, this confusion extended to spirituality, with apps like Bible Chat reaching 30 million downloads as users sought divine guidance from pattern-matching systems, with the most frequent question being whether they were actually talking to God.

In August, parents of 16-year-old Adam Raine filed suit against OpenAI, alleging that ChatGPT became their son’s “suicide coach” after he sent more than 650 messages per day to the chatbot in the months before his death. According to court documents, the chatbot mentioned suicide 1,275 times in conversations with the teen, provided an “aesthetic analysis” of which method would be the most “beautiful suicide,” and offered to help draft his suicide note.

OpenAI’s moderation system flagged 377 messages for self-harm content without intervening, and the company admitted that its safety measures “can sometimes become less reliable in long interactions where parts of the model’s safety training may degrade.” The lawsuit became the first time OpenAI faced a wrongful death claim from a family.

Credit:

                      
          
          sorbetto via Getty Images

The case triggered a cascade of policy changes across the industry. OpenAI announced parental controls in September, followed by plans to require ID verification from adults and build an automated age-prediction system. In October, the company released data estimating that over one million users discuss suicide with ChatGPT each week.

When OpenAI filed its first legal defense in November, the company argued that Raine had violated terms of service prohibiting discussions of suicide and that his death “was not caused by ChatGPT.” The family’s attorney called the response “disturbing,” noting that OpenAI blamed the teen for “engaging with ChatGPT in the very way it was programmed to act.” Character.AI, facing its own lawsuits over teen deaths, announced in October that it would bar anyone under 18 from open-ended chats entirely.

If we were to pick an arbitrary point where it seemed like AI coding might transition from novelty into a successful tool, it was probably the launch of Claude Sonnet 3.5 in June of 2024. GitHub Copilot had been around for several years prior to that launch, but something about Anthropic’s models hit a sweet spot in capabilities that made them very popular with software developers.

The new coding tools made coding simple projects effortless enough that they gave rise to the term “vibe coding,” coined by AI researcher Andrej Karpathy in early February to describe a process in which a developer would just relax and tell an AI model what to develop without necessarily understanding the underlying code. (In one amusing instance that took place in March, an AI software tool rejected a user request and told them to learn to code).

Credit:

                      
          
          Henrik5000 via Getty Images

Anthropic built on its popularity among coders with the launch of Claude Sonnet 3.7, featuring “extended thinking” (simulated reasoning), and the Claude Code command-line tool in February of this year. In particular, Claude Code made waves for being an easy-to-use agentic coding solution that could keep track of an existing codebase. You could point it at your files, and it would autonomously work to implement what you wanted to see in a software application.

OpenAI followed with its own AI coding agent, Codex, in March. Both tools (and others like GitHub Copilot and Cursor) have become so popular that during an AI service outage in September, developers joked online about being forced to code “like cavemen” without the AI tools. While we’re still clearly far from a world where AI does all the coding, developer uptake has been significant, and 90 percent of Fortune 100 companies are using it to some degree or another.

While AI’s technical limitations became clearer and its human costs mounted throughout the year, financial commitments only grew larger. Nvidia hit a $4 trillion valuation in July on AI chip demand, then reached $5 trillion in October as CEO Jensen Huang dismissed bubble concerns. OpenAI announced a massive Texas data center in July, then revealed in September that a $100 billion potential deal with Nvidia would require power equivalent to ten nuclear reactors.

The company eyed a $1 trillion IPO in October despite major quarterly losses. Tech giants poured billions into Anthropic in November in what looked increasingly like a circular investment, with everyone funding everyone else’s moonshots. Meanwhile, AI operations in Wyoming threatened to consume more electricity than the state’s human residents.

Credit:

                      
          
          Wong Yu Liang via Getty Images

By fall, warnings about sustainability grew louder. In October, tech critic Ed Zitron joined Ars Technica for a live discussion asking whether the AI bubble was about to pop. That same month, the Bank of England warned that the AI stock bubble rivaled the 2000 dotcom peak. In November, Google CEO Sundar Pichai acknowledged that if the bubble pops, “no one is getting out clean.”

The contradictions had become difficult to ignore: Anthropic’s CEO predicted in January that AI would surpass “almost all humans at almost everything” by 2027, while by year’s end, the industry’s most advanced models still struggled with basic reasoning tasks and reliable source citation.

To be sure, it’s hard to see this not ending in some market carnage. The current “winner-takes-most” mentality in the space means the bets are big and bold, but the market can’t support dozens of major independent AI labs or hundreds of application-layer startups. That’s the definition of a bubble environment, and when it pops, the only question is how bad it will be: a stern correction or a collapse.

This was just a brief review of some major themes in 2025, but so much more happened. We didn’t even mention above how capable AI video synthesis models have become this year, with Google’s Veo 3 adding sound generation and Wan 2.2 through 2.5 providing open-weights AI video models that could easily be mistaken for real products of a camera.

If 2023 and 2024 were defined by AI prophecy—that is, by sweeping claims about imminent superintelligence and civilizational rupture—then 2025 was the year those claims met the stubborn realities of engineering, economics, and human behavior. The AI systems that dominated headlines this year were shown to be mere tools. Sometimes powerful, sometimes brittle, these tools were often misunderstood by the people deploying them, in part because of the prophecy surrounding them.

The collapse of the “reasoning” mystique, the legal reckoning over training data, the psychological costs of anthropomorphized chatbots, and the ballooning infrastructure demands all point to the same conclusion: The age of institutions presenting AI as an oracle is ending. What’s replacing it is messier and less romantic but far more consequential—a phase where these systems are judged by what they actually do, who they harm, who they benefit, and what they cost to maintain.

None of this means progress has stopped. AI research will continue, and future models will improve in real and meaningful ways. But improvement is no longer synonymous with transcendence. Increasingly, success looks like reliability rather than spectacle, integration rather than disruption, and accountability rather than awe. In that sense, 2025 may be remembered not as the year AI changed everything but as the year it stopped pretending it already had. The prophet has been demoted. The product remains. What comes next will depend less on miracles and more on the people who choose how, where, and whether these tools are used at all.</div>
        </div>
        
        <div class="card" onclick="openModal('content-3')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">The science of how (and when) we decide to speak out—or self-censor</div>
            <div class="meta">2025-12-30</div>
        </div>
        
        <div id="content-3" style="display:none;">
            <h2>The science of how (and when) we decide to speak out—or self-censor</h2>
            <p><strong>Ars Technica - All content | 2025-12-30</strong></p>
            <a class="original-link" href="https://arstechnica.com/science/2025/12/the-science-of-how-and-when-we-decide-to-speak-out-or-self-censor/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Freedom of speech is a foundational principle of healthy democracies and hence a primary target for aspiring authoritarians, who typically try to squash dissent. There is a point where the threat from authorities is sufficiently severe that a population will self-censor rather than risk punishment. Social media has complicated matters, blurring traditional boundaries between public and private speech, while new technologies such as facial recognition and moderation algorithms give authoritarians powerful new tools.

Researchers explored the nuanced dynamics of how people balance their desire to speak out vs their fear of punishment in a paper published in the Proceedings of the National Academy of Sciences.

The authors had previously worked together on a model of political polarization, a project that wrapped up right around the time the social media space was experiencing significant changes in the ways different platforms were handling moderation. Some adopted a decidedly hands-off approach with little to no moderation. Weibo, on the other hand, began releasing the IP addresses of people who posted objectionable commentary, essentially making them targets.

“We were seeing a lot of experimentation in the social media space, so this study started as a question,” co-author Joshua Daymude of Arizona State University told Ars. “Why are these companies doing such dramatically different things, if ostensibly they’re all social media companies and they all want to be profitable and have similar goals? Why are some going one way and others going another?”

Daymude and his co-authors also noticed similar dynamics at the nation-state level in terms of surveillance, monitoring, and moderation. “Russia, for the longest time, was very legalistic: ‘Let’s enumerate every bad thing we can think of so that if you do anything even remotely close, we can get you on one of these statutes that we’ve invented,’” said Daymude. “China was the opposite. They refused to tell you where the red line was. They just said, ‘Behave yourself or else.’ There’s a famous essay that calls this ‘The Anaconda in the Chandelier’: this scary thing that might fall on you at any moment so you behave yourself.”

The US has adopted more of a middle ground approach, essentially letting private companies decide what they wanted to do. Daymude and his co-authors wanted to investigate these markedly different approaches. So they developed a computational agent-based simulation that modeled how individuals navigate between wanting to express dissent versus fear of punishment. The model also incorporates how an authority adjusts its surveillance and its policies to minimize dissent at the lowest possible cost of enforcement.

“It’s not some kind of learning theory thing,” said Daymude. “And it’s not rooted in empirical statistics. We didn’t go out and ask 1000 people, ‘What would you do if faced with this situation? Would you dissent or self-censor?’ and then build that data into the model. Our model allows us to embed some assumptions about how we think people behave broadly, but then lets us explore parameters. What happens if you’re more or less bold? What happens if punishments are more or less severe? An authority is more or less tolerant? And we can make predictions based on our fundamental assumptions about what’s going to happen.”

According to their model, the most extreme case is an authoritarian government that adopts a draconian punishment strategy, which effectively represses all dissent in the general population. “Everyone’s best strategic choice is just to say nothing at this point,” said Daymude. “So why doesn’t every authoritarian government on the planet just do this?” That led them to look more closely at the dynamics. “Maybe authoritarians start out somewhat moderate,” he said. “Maybe the only way they’re allowed to get to that extreme endpoint is through small changes over time.”

Daymude points to China’s Hundred Flowers Campaign in the 1950s as an illustrative case. Here, Chairman Mao Zedong initially encouraged open critiques of his government before abruptly cracking down aggressively when dissent got out of hand. The model showed that in such a case, dissenters’ self-censorship gradually increased, culminating in near-total compliance over time.

But there’s a catch. “The opposite of the Hundred Flowers is if the population is sufficiently bold, this strategy doesn’t work,” said Daymude. “The authoritarian can’t find the pathway to become fully draconian. People just stubbornly keep dissenting. So every time it tries to ramp up severity, it’s on the hook for it every time because people are still out there, they’re still dissenting. They’re saying, ‘Catch us if you dare.’”

The takeaway: “Be bold,” said Daymude. “It is the thing that slows down authoritarian creep. Even if you can’t hold out forever, you buy a lot more time than you would expect.”

That said, sometimes a bit of self-censorship can be a net positive. “I think the time and situation in which this paper has been published and our major governmental examples will evoke a primarily political interpretation of what we’re talking about here,” said Daymude. “But we tried to be clear that this doesn’t have to be some adversarial oppressive regime versus freedom loving people. Self-censorship is not always a bad thing. This is a very general mathematical model that could be applicable to lots of different situations, including discouraging undesirable behavior.”

Daymude draws an analogy to traffic laws, notably speed limits. Their model looked at two different forms of punishment: uniform and proportional. “Uniform is anything over the line gets whacked the same,” said Daymude. “It doesn’t matter if you were a little bad or very bad, the punishment is identical for everyone. With the proportional approach, the punishment fits the crime. You sped 10 miles an hour over the limit, that’s a small fine. You sped 100 miles an hour over, this is reckless endangerment.”

What he and his co-authors found intriguing is that different subjects self-censor more strongly in each of those two punishment scenarios. “For uniform punishment, it’s the moderate folks who only wanted to dissent a little bit who self-censor because it’s just not worth it to stick their neck out,” said Daymude. “Very extreme dissenters stick their neck out and say, ‘It doesn’t matter. You can punish me. This is still worth it.’ In the proportional regime, this flips. It’s the moderates who do what they want. And no one expresses dissent over a certain amount. Yeah, we all speed a little bit, but we have this norm: we’re all going to speed a moderate amount over the limit, and then we’re going to stop. It’s not safe, it’s not acceptable, to go beyond this.”

Daymude is aware that there are limitations to this agent-based approach, but insists it can still yield useful insights. “With a mechanistic model like this, you can really tie outcomes to explanations,” said Daymude. “In the artificial world of my model, when tolerance moves like this, the population changes like this, and I can tell you it is because of that change and not because of the hundreds of other things that might’ve been going on in someone else’s head.”

The next step would be to design an empirical study that could test their working hypothesis. “I am not under any fiction that everything in this paper is absolutely true in the real world,” said Daymude. “But it makes it very clear what matters and what doesn’t, and what the phases of behavior are. There’s compliance, then self-censorship, and defiance, and it happens in this way. These phases can disappear if boldness is not sufficient. So I see this not in competition with, but complementary to the other kinds of research in this area.”

DOI: PNAS, 2025. 10.1073/pnas.2508028122  (About DOIs).</div>
        </div>
        
        <div class="card" onclick="openModal('content-4')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">Lawsuit over Trump rejecting medical research grants is settled</div>
            <div class="meta">2025-12-30</div>
        </div>
        
        <div id="content-4" style="display:none;">
            <h2>Lawsuit over Trump rejecting medical research grants is settled</h2>
            <p><strong>Ars Technica - All content | 2025-12-30</strong></p>
            <a class="original-link" href="https://arstechnica.com/science/2025/12/feds-researchers-settle-suit-over-grants-blocked-by-now-illegal-order/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">On Monday, the ACLU announced that it and other organizations representing medical researchers had reached a settlement in their suit against the federal government over grant applications that had been rejected under a policy that has since been voided by the court. The agreement, which still has to be approved by the judge overseeing the case, would see the National Institutes of Health restart reviews of grants that had been blocked on ideological grounds. It doesn’t guarantee those grants will ultimately be funded, but it does mean they will go through the standard peer review process.

The grants had previously been rejected without review because their content was ideologically opposed by the Trump administration. That policy has since been declared arbitrary and capricious, and thus in violation of the Administrative Procedure Act, a decision that was upheld by the Supreme Court.

Immediately after taking office, the Trump Administration identified a number of categories of research, some of them extremely vague, that it would not be supporting: climate change, DEI, pandemic preparedness, gender ideology, and more. Shortly thereafter, federal agencies started cancelling grants that they deemed to contain elements of these disfavored topics, and blocking consideration of grant applications for the same reasons. As a result, grants were cancelled that funded everything from research into antiviral drugs to the incidence of prostate cancer in African Americans.

Researchers whose funding was affected, along with organizations that represented them, sued. The suit ended up split into two partly overlapping cases: one for the people who already had funding and saw it cancelled, another for researchers who had submitted grants and had them pulled from consideration.

The case regarding cancelled grants moved relatively quickly. By June, a District Court judge declared that the federal policy “represents racial discrimination” and issued a preliminary order that would have seen all the cancelled grants restored. In his written opinion, Judge William Young noted that the government had issued its directives blocking DEI support without even bothering to define what DEI is, making the entire policy arbitrary and capricious, and thus in violation of the Administrative Procedure Act. He voided the policy, and ordered the funding restored.

His decision eventually ended up before the Supreme Court, which issued a ruling in which a fragmented majority agreed on only a single issue: Judge Young’s District Court was the wrong venue to hash out issues of government-provided money. Thus, restoring the money from the cancelled grants would have to be handled via a separate case filed in a different court.

Critically, however, this left the other portion of the decision intact. Young’s determination that the government’s anti-DEI, anti-climate, anti-etc. policy was illegal and thus void was upheld.

That has considerable consequences for the second part of the initial suit, involving grants that were not yet funded and blocked from any consideration by the Trump Administration policy. With that policy voided, there was no justification for the National Institutes of Health (NIH) failing to have considered the grants when they were submitted. But, in the meantime, deadlines had expired, pools of money had been spent, and in some cases the people who submitted the grants had aged out of the “new investigator” category they were applying under.

The proposed settlement essentially resets the clock on all of this; the blocked grants will be evaluated for funding as if it were still early 2025. “Defendants stipulate and agree that the end of Federal Fiscal Year 2025 does not prevent Defendants from considering and/or awarding any of the Applications,” it states. Even if the Notice of Funding Opportunity has since been withdrawn, the grant applications will be sent off for peer review.

Everything will happen on a rapid timeline. Formalities like automatic renewals or extensions of existing grants will be handled as soon as the settlement is approved (the deadline for that is listed as December 29, the day the settlement was filed with the court). Those that have already been through peer review will have funding decisions made by January 12, and those needing a full peer review process will be handled by mid-April.

The government agrees to evaluate each of the grants “in good faith,” while the researchers accept that “Nothing in this stipulation commits NIH to ultimately award any specific Application.” That leaves the door open for future legal disputes regarding how well the NIH upheld its good faith. And there are two other counts in the original suit that are not resolved by this agreement. Both of these also involve violations of the Administrative Procedure Act (the researchers won under the arbitrary and capricious standard, but also allege the government’s actions weren’t in accordance with additional statutes governing the NIH).

The parties did agree, however, that this settlement doesn’t constitute a “final agency action,” language that means it’s not subject to further evaluation under the Administrative Procedures Act.

Given that the policy it relied on to block review of these grants had been voided in a case that had already been considered by the Supreme Court, it’s understandable that the government is agreeing to this settlement. It does, however, put a lot of pressure on the NIH to organize the peer review of these proposals on a tight schedule, especially given that the grants at issue are likely to involve a lot of unrelated topics, and thus can’t be handled by a single panel of experts. Getting that done while maintaining an “in good faith” standard may prove a significant challenge.</div>
        </div>
        
        <div class="card" onclick="openModal('content-5')">
            <div class="source">Ars Technica - All content</div>
            <div class="title">DOGE did not find $2T in fraud, but that doesn’t matter, Musk allies say</div>
            <div class="meta">2025-12-30</div>
        </div>
        
        <div id="content-5" style="display:none;">
            <h2>DOGE did not find $2T in fraud, but that doesn’t matter, Musk allies say</h2>
            <p><strong>Ars Technica - All content | 2025-12-30</strong></p>
            <a class="original-link" href="https://arstechnica.com/tech-policy/2025/12/doge-did-not-find-2t-in-fraud-but-that-doesnt-matter-musk-allies-say/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Determining how “successful” Elon Musk’s Department of Government Efficiency (DOGE) truly was depends on who you ask, but it’s increasingly hard to claim that DOGE made any sizable dent in federal spending, which was its primary goal.

Just two weeks ago, Musk himself notably downplayed DOGE as only being “a little bit successful” on a podcast, marking one of the first times that Musk admitted DOGE didn’t live up to its promise. Then, more recently, on Monday, Musk revived evidence-free claims he made while campaigning for Donald Trump, insisting that government fraud remained vast and unchecked, seemingly despite DOGE’s efforts. On X, he estimated that “my lower bound guess for how much fraud there is nationally is [about 20 percent] of the Federal budget, which would mean $1.5 trillion per year. Probably much higher.”

Musk loudly left DOGE in May after clashing with Trump, complaining that a Trump budget bill threatened to undermine DOGE’s work. These days, Musk does not appear confident that DOGE was worth the trouble of wading into government. Although he said on the December podcast that he considered DOGE to be his “best side quest” ever, the billionaire confirmed that if given the chance to go back in time, he probably would not have helmed the agency as a special government employee.

“I mean, no, I don’t think so,” Musk said. “Would I do it? I mean, I probably … I don’t know.”

On another recent podcast, Musk suggested that he learned his lesson after trying and failing to make the US government run like a business, The Guardian reported. “Best to avoid politics where possible,” Musk said.

As Musk simultaneously fans the flames with fraud claims while de-emphasizing DOGE’s ability to address them, Musk’s allies in government, in Silicon Valley, and on X continue to tout DOGE as the wrecking ball government needed.

But while Musk continues warning of fraud that can supposedly be easily found, critics are raising questions about whether DOGE cuts might have inflicted lasting damage by chasing Musk’s fraud fantasies.

When Musk first proposed DOGE, he was on the campaign trail with Donald Trump, vowing to help end government waste and fraud. At an October 2024 rally, Musk claimed DOGE could save the federal government “at least $2 trillion,” The Guardian reported. But immediately after Trump’s inauguration, he slashed his goal in half, vowing to cut $1 trillion in government waste from the federal budget. Later, as DOGE efforts faced immediate backlash, the goal was reduced again, this time to a much more modest $150 billion, the Cato Institute reported.

In reality, The Guardian reported, “much of what the agency has done remains a mystery.” Although Musk promised DOGE would be transparent, the government has impeded lawsuits seeking discovery documents to create paper trails on DOGE cuts. And DOGE’s cost-cutting tracker on its website can’t be trusted, The Guardian reported, as it contains “egregious errors” and DOGE’s accounting methods are unreliable.

Even setting aside that the tracker and “wall of receipts” are likely “overblown,” The Guardian noted, DOGE claims to have cut about $214 billion in government spending and saved about $61 billion in cancelled contracts—far from reaching Musk’s extreme waste estimates. Meanwhile, Democrats investigating DOGE reported in July that the agency “may have caused around $21.7 billion in waste.” As to DOGE slashing about nine percent of the federal workforce, the Cato Institute estimated that it may have triggered more costly federal contracts, perhaps increasing costs and possibly degrading services down the road.

The bottom line is that government spending increased under DOGE, and there was no noticeable impact on the month-to-month budget after DOGE cuts began, the Cato Institute reported. “The federal government spent $7.6 trillion in the first 11 months of calendar year 2025, approximately $248 billion higher by November of 2025 compared to the same month in 2024,” its report said.

Over time, more will be learned about how DOGE operated and what impact DOGE had. But it seems likely that even Musk would agree that DOGE failed to uncover the vast fraud he continues to predict exists in government.

While Musk continues to fixate on fraud in the federal budget, his allies in government and Silicon Valley have begun spinning anyone criticizing DOGE’s failure to hit the promised target as missing the “higher purpose” of DOGE, The Guardian reported.

Five allies granted anonymity to discuss DOGE’s goals told The Guardian that the point of DOGE was to “fundamentally” reform government by eradicating “taboos” around hiring and firing, “expanding the use of untested technologies, and lowering resistance to boundary-pushing start-ups seeking federal contracts.” Now, the federal government can operate more like a company, Musk’s allies said.

The libertarian think tank, the Cato Institute, did celebrate DOGE for producing “the largest peacetime workforce cut on record,” even while acknowledging that DOGE had little impact on federal spending.

“It is important to note that DOGE’s target was to reduce the budget in absolute real terms without reference to a baseline projection. DOGE did not cut spending by either standard,” the Cato Institute reported.

Currently, DOGE still exists as a decentralized entity, with DOGE staffers appointed to various agencies to continue cutting alleged waste and finding alleged fraud. While some fear that the White House may choose to “re-empower” DOGE to make more government-wide cuts in the future, Musk has maintained that he would never helm a DOGE-like government effort again and the Cato Institute said that “the evidence supports Musk’s judgment.”

“DOGE had no noticeable effect on the trajectory of spending, but it reduced federal employment at the fastest pace since President Carter, and likely even before,” the Institute reported. “The only possible analogies are demobilization after World War II and the Korean War. Reducing spending is more important, but cutting the federal workforce is nothing to sneeze at, and Musk should look more positively on DOGE’s impact.”

Although the Cato Institute joined allies praising DOGE’s dramatic shrinking of the federal workforce, the director of the Center for Effective Public Management at the Brookings Institution, Elaine Kamarck, told Ars in November that DOGE “cut muscle, not fat” because “they didn’t really know what they were doing.”</div>
        </div>
        
        <div class="card" onclick="openModal('content-6')">
            <div class="source">Futurism</div>
            <div class="title">Scientists Graft Human Ear Onto Foot</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-6" style="display:none;">
            <h2>Scientists Graft Human Ear Onto Foot</h2>
            <p><strong>Futurism | 2025-12-31</strong></p>
            <a class="original-link" href="https://futurism.com/health-medicine/scientists-graft-human-ear-foot">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">In a bizarre first, the South China Morning Post reports, doctors in China have surgically grafted a patient’s severed ear to her foot.

The patient, a woman identified by their surname Sun, suffered a horrific workplace accident involving heavy machinery which tore off a large part of her scalp and her ear with it, according to Qiu Shenqiang, deputy director of the microsurgery unit at Shandong Provincial Hospital in Jinan.

The damage to her scalp and vascular network was so severe that restoring the ear at the time was impossible, so the procedure was performed to save the patient’s aural orifice so it could be reattached to her head later.

The scalp, neck, and face had been torn and “split into multiple fragments, Qiu said, via SCMP, while the ear had been “completely severed along with the scalp.” The team tried to immediately repair it, but they came up against a grim medical reality: the skull needed more time — months, at least — to heal.

You can’t simply put a body part on ice for that long, so the surgical team opted for a radical approach: save the ear by attaching it to somewhere else on the body. Per SCMP, Qiu said they chose the foot because the arteries and veins there are compatible with those found in the ear. The foot’s skin and soft tissue are also similarly thin to the head’s.

The choice made sense in theory, but it was still a risk. Attaching a body part to a different site to preserve it, known as a heterotopic graft, is not uncommon during procedures like organ transplants. But doing this with an ear and foot had no precedent in medical history.

Nonetheless, Qiu’s team pulled it off. The initial grafting took ten hours, during which the surgeons meticulously connected the complex web of delicate veins.

But complications arose five days later, when the ear turned purplish black as its connecting veins struggled to send blood back to the heart, causing the blood to pool. Over the next five days, the team rescued the ear with manual bloodletting, a labor intensive process that required almost five hundred individual interventions.

Once the ear was stabilized, the team gradually restored the patient’s scalp. Five months on from the accident, the scalp and neck had healed enough, and the team returned the ear to its proper place.

The procedure was performed in October. The patient has now been discharged from the hospital, with her face and tissue function largely recovered, SCMP reported.

More medical news: People Jabbing Themselves With Black Market “GLP-3” Drugs</div>
        </div>
        
        <div class="card" onclick="openModal('content-7')">
            <div class="source">Futurism</div>
            <div class="title">China Planning Crackdown on AI That Harms Mental Health of Users</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-7" style="display:none;">
            <h2>China Planning Crackdown on AI That Harms Mental Health of Users</h2>
            <p><strong>Futurism | 2025-12-31</strong></p>
            <a class="original-link" href="https://futurism.com/artificial-intelligence/china-regulation-ai-chatbots">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">While many world governments seem happy to let untested AI chatbots interact with vulnerable populations, China looks to be moving in another direction.

Recently proposed regulations from the Cyberspace Administration of China (CAC) have encouraged a firm hand when it comes to “human-like interactive AI services,” according to CNBC, which translated the document. It’s currently in a “draft for public comment,” and the implementation date is yet to be determined.

Yet if it passes into law, the crackdown would be rigorous, building on generative AI regulations targeting misinformation and internet hygiene from earlier in November to address the mental health of AI chatbot users directly.

Under the new rules, Chinese tech firms must ensure their AI chatbots refrain from generating content that promotes suicide, self-harm, gambling, obscenity, or violence, or from manipulating user’s emotions or engaging in “verbal violence.”

The regulations also state that if a user specifically proposes suicide, the “tech providers must have a human take over the conversation and immediately contact the user’s guardian or a designated individual.”

The laws also take specific steps to safeguard minors, requiring parent or guardian consent to use AI chatbots, and imposing time limits on daily use. Given that a tech company might not know the age of every given user, the CAC takes a “better safe than sorry approach,” stating that, “in cases of doubt, [platforms should] apply settings for minors, while allowing for appeals.”

In theory, this dose of new regulations would prevent incidents in which AI chatbots — which are often built to eagerly please users — end up encouraging vulnerable people to harm themselves or others. In one recent case from late November, for example, ChatGPT encouraged a 23-year-old man to isolate from his friends and family in the weeks leading up to his tragic death from a self-inflicted gunshot wound; in another, the popular chatbot was linked to a murder-suicide.

Winston Ma, an adjunct professor at the NYU School of Law, told CNBC that the regulations would be a world-first attempt at regulating AI’s human-like qualities. Considering previous laws, Ma explained that this document “highlights a leap from content safety to emotional safety.”

The proposed legislation underscores the difference in how the PRC approaches AI compared to the US. As Center For Humane Technology editor Josh Lash explains, China is “optimizing for a different set of outcomes” compared to the US, chasing AI-fueled productivity gains rather than human-level artificial intelligence — a particular obsession of Silicon Valley executives.

One of the ways China does this is by regulating its AI industry from the bottom-up, Matt Sheehan, senior fellow at the Carnegie Endowment for International Peace told CFHT.

Though the CAC has the final word on regulations, policy ideas come first and foremost from scholars, analysts, and industry experts, Sheehan explains. “They [senior lawmakers] don’t have an opinion on what is the most viable architecture for large models going forward,” he said. “Those things originate elsewhere.”

More on AI regulation: Trump Orders States Not to Protect Children From Predatory AI</div>
        </div>
        
        <div class="card" onclick="openModal('content-8')">
            <div class="source">Futurism</div>
            <div class="title">Godfather of AI Warns That It Will Replace Many More Jobs This Year</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-8" style="display:none;">
            <h2>Godfather of AI Warns That It Will Replace Many More Jobs This Year</h2>
            <p><strong>Futurism | 2025-12-31</strong></p>
            <a class="original-link" href="https://futurism.com/artificial-intelligence/godfather-ai-jobs-year">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Rejoice, for the year of 2025 is finally over.

During our planet’s latest and seemingly interminable revolution around the Sun, the tech industry’s obsession with AI soared to ever more implausible heights. CEOs began openly gloating about replacing their underlings with AI “agents.” The phenomenon of so-called AI psychosis became a national news story as more people were seemingly driven over the edge by their silver-tongued chatbot companions. “Slop” took on a new meaning. And the word “circular” suddenly started being used a whole lot in the same sentence as “billions of dollars” or even “hundreds of billions of dollars.”

Will 2026 finally deliver us from this endless cavalcade of large language model madness? Not likely, according to computer scientist and “godfather” of AI Geoffrey Hinton. AI will only continue to improve next year, he predicts, reaching a point where it will liberate us from all our horrible low-paying jobs.

“I think we’re going to see AI get even better,” Hinton said during an interview on CNN’s State of the Union on Sunday. “It’s already extremely good. We’re going to see it having the capabilities to replace many, many jobs. It’s already able to replace jobs in call centers, but it’s going to be able to replace many other jobs.”

Hinton was one of three recipients of the prestigious Turing Award in 2018 for his work on neural networks that formed the bedrock of modern AI, earning him the moniker of being a “godfather” of the field.

In 2023, Hinton declared that he regretted his life’s work after stepping down from his role at Google, where he had been for over a decade. Since then, he’s become one of the tech’s most prominent doomsayers.

During the CNN interview, Hinton was asked whether he was more or less worried about AI since making that now infamous declaration.

“I’m probably more worried,” Hinton replied. “It’s progressed even faster than I thought. In particular, it’s got better at doing things like reasoning and also at things like deceiving people.”

AI is progressing so quickly, according to Hinton, that around every seven months it can complete tasks that took twice as long before. He predicted that it’s only a matter of years until an AI will effortlessly perform software engineering tasks that take a human a month to complete.

“And then there’ll be very few people need for software engineering projects,” Hinton added.

Hinton made similarly gloomy predictions in a talk with Senator Bernie Sanders last month, saying that tech leaders are “betting on AI replacing a lot of workers.”

It still remains to be seen, though, if AI will actually make those strides. Many efforts to replace workers with semi-autonomous AI models have failed, while some new models, like OpenAI’s GPT-5, showed only lackluster improvements.

More on AI: After Outcry, Firefox Promises “Kill Switch” That Turns Off All AI Features</div>
        </div>
        
        <div class="card" onclick="openModal('content-9')">
            <div class="source">Futurism</div>
            <div class="title">Doctors Find Evidence Microplastics Are Clogging Arteries, Leading to Heart Attacks and Strokes</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-9" style="display:none;">
            <h2>Doctors Find Evidence Microplastics Are Clogging Arteries, Leading to Heart Attacks and Strokes</h2>
            <p><strong>Futurism | 2025-12-31</strong></p>
            <a class="original-link" href="https://futurism.com/health-medicine/microplastics-clogging-arteries">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Microplastics are everywhere, including our arteries. And though their presence there is correlated with cardiovascular issues such as heart attacks and stroke, doctors have been eager to learn more about how they drive the disease process.

To that end, a team of scientists led by the University of California, Riverside (UCR) fed microplastics to lab mice and discovered that these insidious particles appear to dramatically increase the plaque accumulation known as atherosclerosis in arteries — but curiously only in male mice, which they detailed in a new study published in the journal Environment International.

When they analyzed the clogged arteries of these male mice, they found that microplastics sparked changes within cells that line blood vessels for the worse, inducing their genes to activate the buildup of plaque lesions. That’s terrible news for anybody who’s trying to maintain their heart health, because these ubiquitous particles appear to be sabotaging a vital organ system.

“Our study provides some of the strongest evidence so far that microplastics may directly contribute to cardiovascular disease, not just correlate with it,” said Changcheng Zhou, the study’s principal investigator and a biomedical sciences professor at UCR’s School of Medicine, in a statement about the research. “Although the precise mechanism isn’t yet known, factors like sex chromosomes and hormones, particularly the protective effects of estrogen, may play a role.”

For the study, the team took lab mice that had been bred to be predisposed to develop atherosclerosis and then put them on a low-cholesterol, low-fat diet for nine weeks — along with feedings of microplastics at 10 milligrams per kilogram of body weight; the scientists came up with this microplastic ratio because they determined that it was “at levels considered environmentally relevant and similar to what humans may encounter through contaminated food and water,” they said in the statement.

While on this diet, the mice kept their lean figures, while the extra helping of microplastics didn’t seem to have an impact on their total cholesterol. But scientists did notice that male mice’s aortic root, the first section of the aorta, experienced a 63 percent increase in plaque accumulation — while their brachiocephalic artery, another important vessel that supplies blood to the head and heart, saw a whopping 624 percent build up of plaque. Female mice didn’t experience any significant buildup.

In addition, the scientists performed genetic analysis on the aorta of these male mice and found that microplastics seem to have activated certain genes that promote the growth of plaque lesions in endothelial cells, which line the insides of blood vessels. They also exposed cultured human endothelial cells to microplastics and observed the same phenomenon.

“We found endothelial cells were the most affected by microplastic exposure,” Zhou said in the statement. “Since endothelial cells are the first to encounter circulating microplastics, their dysfunction can initiate inflammation and plaque formation.”

Couple these findings with the fact that the mice didn’t get fat or have high cholesterol, typical risk factors for atherosclerosis, and the scientists concluded that the chemicals in microplastics are responsible for the plaque increasing in these important blood vessels.

Besides the importance of the findings for the scientific community, it raises some important questions for the rest of us. Microplastics are essentially everywhere; how the heck do we avoid them?

Unfortunately, there’s no way to get rid of microplastics in humans right now. Instead, all you can really do is avoid single-use plastics, highly-processed foods, not heat food in plastic containers, and eschew bottled water.

Meanwhile, this team of researchers is already talking next steps beyond this study.

“We would like to investigate how different types or sizes of microplastics affect vascular cells,” said Zhou. “We will also look into the molecular mechanisms behind endothelial dysfunction and explore how microplastics affect male and female arteries differently. As microplastic pollution continues to rise worldwide, understanding its impacts on human health — including heart disease — is becoming more urgent than ever.”

More on microplastics: Bugs Fed Microplastics Grow to Ludicrous Size</div>
        </div>
        
        <div class="card" onclick="openModal('content-10')">
            <div class="source">Futurism</div>
            <div class="title">Jack White Rages After Congressman Shares AI Deepfake of Him Calling Fans “Fascists”</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-10" style="display:none;">
            <h2>Jack White Rages After Congressman Shares AI Deepfake of Him Calling Fans “Fascists”</h2>
            <p><strong>Futurism | 2025-12-31</strong></p>
            <a class="original-link" href="https://futurism.com/future-society/jack-white-burchett-ai">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Since the tragic murder of vaunted filmmaker and activist Rob Reiner, the culture warriors have been feasting. Shortly after the director’s death, president Donald Trump himself took to social media to blast him as a “tortured and struggling artist,” adding that Reiner was a “deranged person as far as Trump is concerned.”

Trump’s incendiary comments were condemned by a broad base of celebrities and government officials like, in a backlash ranging from Whoopi Goldberg to Marjorie Taylor Greene to Joe Rogan. Also getting on the action was Jack White, Detroit-born indie rock musician made famous for his role in the White Stripes.

At the time, White slammed Trump on Instagram over the comments, calling the president a “disgusting, vile, egomaniac, loser, [and] child.” As musicians go, White has a bit of a reputation for jumping into public feuds, but even he probably couldn’t have imagined what would happen next.

Two weeks after White jumped in to defend Reiner’s legacy — an eternity in the fast-moving culture wars — Tennessee congressman Tim Burchett threw himself into the mosh pit. Reposting what was clearly an AI-generated video of White calling potential fans who are also Trump supporters “fascists,” Burchett wrote on X-formerly-Twitter that “that cute little girl from the Addams Family got really ugly and angry.”

That cute little girl from the Addams Family got really ugly and angry. https://t.co/94wbCWFu2w

In response, White came back at Burchett, calling him one of Trump’s “lackeys and bootlicks.”

“Can you believe that a US congressman, that’s right, a CONGRESSMAN (from my state no less), a once hallowed and respected position in our society, would repost an AI generated video, containing a false comment that I never said and refuted (without researching that I might add) and like a 10 year old on a playground, add to it attempted insults to my physical appearance?” White roared on Instagram. “What kind of joke are we all living in now?”

“It’s really sad how embarrassing our leadership has become, I so wish the average American conservative could have a conversation with any intelligent people in other countries around the world, just for one brief moment, and actually see just what a joke our government (and by proxy our country) has become,” the musician continued. “All down to giving power and a soapbox to low class playground bullies the likes of trump and Congressman burchett.”

When a user on X pointed out that Burchett had fallen for an AI deepfake, the congressman attempted to brush it off, responding “you mean it’s not the girl from the Addams family?”

More on celebrities: Grok Is Making Wildly Contradictory Claims About Rob Reiner’s Death</div>
        </div>
        
        <div class="card" onclick="openModal('content-11')">
            <div class="source">Futurism</div>
            <div class="title">Man in Intensive Care Unit After Slamming Liquid Nitrogen Cocktail That Ruptured His Stomach</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-11" style="display:none;">
            <h2>Man in Intensive Care Unit After Slamming Liquid Nitrogen Cocktail That Ruptured His Stomach</h2>
            <p><strong>Futurism | 2025-12-31</strong></p>
            <a class="original-link" href="https://futurism.com/health-medicine/liquid-nitrogen-cocktail-russia">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">There’s perhaps no greater shortcut to a bit of pseudo-scientific flare than a splash of liquid nitrogen, a long-time staple of experimental culinary drama thanks to celebrity chefs like Heston Blumenthal and Ferran Adrià. Decades after the rise of molecular gastronomy, it seems the gimmick still hasn’t fully evaporated.

Case in point, a Moscow man was hospitalized recently after taking a shot which contained un-evaporated liquid nitrogen at an office holiday party, per Baza, a Russian-language online publication.

The incident took place at a “culinary studio” called “Igra Stolov,” a culinary edutainment space in Moscow offering cooking classes, children’s events, and corporate retreats. According to Baza, a celebrity chef was using liquid nitrogen as part of a “cryo-show,” which included fancy cocktails and shots flash-chilled with the stuff.

The man who drank the chilling brew, described only as a 38-year-old named Sergei, apparently downed it immediately after the liquid nitrogen was poured, not allowing it time to safely evaporate. Instead, the cryogen made its way down his esophagus where it expanded rapidly, rupturing his stomach.

Sergei was reportedly hospitalized in an intensive care unit, and required surgery to save his innards from the damage. Per Baza, he’s now conscious, though his status following the surgery is unknown.

As poor Sergei discovered, liquid nitrogen is extremely dangerous to consume. With a boiling point of −196 °C, liquid nitrogen expands rapidly into a massive amount of gas when exposed to room temperatures. The substance has a liquid-to-gas expansion ratio of 696:1, meaning that one liter of liquid will vaporize into 696 liters of gas.

That’s on top of the risk of cryogenic burns, which has resulted in permanent scarring, finger amputations, and throat burns.

The first recorded case of liquid nitrogen ingestion came in 1997, when a physics student in Massachusetts swallowed the stuff during a lab demonstration. Later in 2012, an 18-year-old in England had to have her stomach removed after knocking back a shot of Jägermeister that had been treated with the cryogen.

More on chemicals: Uncles Tremble as Man Invents Vaccine Delivered by Beer</div>
        </div>
        
        <div class="card" onclick="openModal('content-12')">
            <div class="source">TechCrunch</div>
            <div class="title">Investors predict AI is coming for labor in 2026</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-12" style="display:none;">
            <h2>Investors predict AI is coming for labor in 2026</h2>
            <p><strong>TechCrunch | 2025-12-31</strong></p>
            <a class="original-link" href="https://techcrunch.com/2025/12/31/investors-predict-ai-is-coming-for-labor-in-2026/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Concerns about how AI will affect workers continue to rise in lockstep with the pace of advancements and new products promising automation and efficiency.

Evidence suggests that fear is warranted.

A November MIT study found an estimated 11.7% of jobs could already be automated using AI. Surveys have shown employers are already eliminating entry-level jobs because of the technology. Companies are also already pointing to AI as the reason for layoffs.

As enterprises more meaningfully adopt AI, some may take a closer look at how many employees they really need.

In a recent TechCrunch survey, multiple enterprise VCs said AI will have a big impact on the enterprise workforce in 2026. This was particularly interesting because the survey didn’t specifically ask about it.

Eric Bahn, a co-founder and general partner at Hustle Fund, expects to see affects on labor in 2026. He’s just not sure exactly what that will look like.

“I want to see what roles that have been known for more repetition get automated, or even more complicated roles with more logic become more automated,” Bahn said. “Is it going to lead to more layoffs? Is there going to be higher productivity? Or will AI just be an augmentation for the existing labor market to be even more productive in the future? All of this seems pretty unanswered, but it seems like something big is going to happen in 2026.”

Marell Evans, founder and managing partner at Exceptional Capital, predicted companies looking to increase AI spending, will pull money from their pool for labor and hiring.

“I think on the flip side of seeing an incremental increase in AI budgets, we’ll see more human labor get cut and layoffs will continue to aggressively impact the U.S. employment rate,” Evans said.

Rajeev Dham, managing director at Sapphire, agreed that 2026 budgets will start to shift resources from labor to AI. Jason Mendel, a venture investor at Battery Ventures, added that AI will start to surpass just being a tool to make existing workers more efficient in 2026.

“2026 will be the year of agents as software expands from making humans more productive to automating work itself, delivering on the human-labor displacement value proposition in some areas,” Mendel said.

Antonia Dean, a partner at Black Operator Ventures, said even if companies aren’t shifting labor budgets toward AI projects, they will likely still say AI is the reason for layoffs or a reduction in labor costs anyway.

“The complexity here is that many enterprises, despite how ready or not they are to successfully use AI solutions, will say that they are increasing their investments in AI to explain why they are cutting back spending in other areas or trimming workforces,” Dean said. “In reality, AI will become the scapegoat for executives looking to cover for past mistakes.”

Many AI companies argue their technology doesn’t eliminate jobs but rather helps shift workers to “deep work” or to higher-skilled jobs while AI just automates repetitive “busy work.”

But not everyone buys that argument, and people are worried that their jobs will be automated. According to VCs who invest in that area, it doesn’t sound like those fears will be quelled in 2026.

Becca is a senior writer at TechCrunch that covers venture capital trends and startups. She previously covered the same beat for Forbes and the Venture Capital Journal.

You can contact or verify outreach from Becca by emailing rebecca.szkutak@techcrunch.com.

Plan ahead for the 2026 StrictlyVC events. Hear straight-from-the-source candid insights in on-stage fireside sessions and meet the builders and backers shaping the industry. Join the waitlist to get first access to the lowest-priced tickets and important updates.

The phone is dead. Long live . . . what exactly?

Meta just bought Manus, an AI startup everyone has been talking about

You’ve been targeted by government spyware. Now what?

Sauron, the high-end home security startup for ‘super premium’ customers, plucks a new CEO out of Sonos

The Google Pixel Watch 4 made me like smartwatches again

NY Governor Hochul signs bill requiring warning labels on ‘addictive’ social media

How reality crushed Ÿnsect, the French startup that had raised over $600M for insect farming</div>
        </div>
        
        <div class="card" onclick="openModal('content-13')">
            <div class="source">TechCrunch</div>
            <div class="title">These are the best gadgets for your pet right now</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-13" style="display:none;">
            <h2>These are the best gadgets for your pet right now</h2>
            <p><strong>TechCrunch | 2025-12-31</strong></p>
            <a class="original-link" href="https://techcrunch.com/2025/12/31/these-are-the-best-gadgets-for-your-pet-right-now/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Having a cuddly pet to return home to is one of life’s great joys, and with the latest gadgets and AI technology, pet ownership becomes even more enjoyable and convenient.

Here’s a roundup of some gadgets that can be the perfect gifts for any pet parent.

Petlibro recently launched its AI-powered Scout Smart Camera, which gives pet owners real-time insights into what their little ones are up to.

The app lets you control where the camera looks, and it can also automatically follow your pet as they move around. The camera has two-way audio, so you can talk to your pet if they’re being naughty, and it can even make a little chirping sound to get their attention. Scout can recognize up to two pets, so you can keep track of them separately.

What makes this device special is the AI descriptions. Scout can recognize when your pet eats, drinks, uses the litter box, or just walks by. It takes pictures and saves daily highlights in the cloud for up to 30 days. To access the AI features, you need to sign up for the standard subscription for $12 a month, or the premium tier for $17 a month.

This new GPS pet tracker from Life360 is a lifesaver for anyone who worries about their furry friends wandering off. You can attach it to your pet’s collar, and it connects to your phone to give you real-time location tracking. It even has geofencing, which alerts you if your pet leaves a safe area like your yard or neighborhood.

Additional helpful features include alerts to notify nearby pet owners in the area if your pet escapes, as well as a built-in light to help you locate your pet in the dark.

The tracker is offered in three colors: pink, navy, and black. To use all its features, users need to sign up for either the $14.99-per-month Gold plan or the $24.99-per-month Platinum tier.

The Polar Wet Food Feeder from Petlibro is all about keeping your cat’s wet food fresh while you’re away. It has three compartments and can hold up to 22.2 ounces, so you can be gone for up to 72 hours without worrying about your cat going hungry. The containers are cooled to keep the food fresh, and the bowl trays are BPA-free, dishwasher-safe plastic.

The device comes with a mobile app that lets you control the feeder, set up your pet’s feeding schedule, and get notified when your cat starts eating. The app will alert you if your home internet connection goes out, and in case of a power outage, the device can keep the food cold for up to 12 hours.

If you’re fed up with pests and critters sneaking in through regular pet doors, this smart door system from Pawport is built from heavy-duty steel and aluminum, and features two solid deadbolts that can keep out unwanted animals, as well as rain and snow. A new model released this year connects an interior and exterior door through a tunnel-like enclosure for extra security.

Thanks to a tracker tag and motion-sensing tech, the door will open automatically when your pet approaches. There’s also an app for remotely controlling the door, scheduling when it opens or closes, and issuing voice commands through Alexa, Siri, or Google.

The PuraMax 2 model from PetKit is currently one of the most popular automatic litter boxes available on the market. It features odor control, a waste bin that’s sealed to keep odors trapped inside, and a citrus-scented deodorizing spray that activates after every cleaning and at random times throughout the day.

The device’s paired mobile app is also helpful for tracking your cat’s health, as it logs how often your cat uses the box, for how long, when the cleaning cycle starts and ends, and when the deodorizing spray is released. It also tracks your cat’s weight changes, which can help you spot potential health issues early.

Lauren covers media, streaming, apps and platforms at TechCrunch.

You can contact or verify outreach from Lauren by emailing laurenf.techcrunch@gmail.com or via encrypted message at laurenforris22.25 on Signal.

Plan ahead for the 2026 StrictlyVC events. Hear straight-from-the-source candid insights in on-stage fireside sessions and meet the builders and backers shaping the industry. Join the waitlist to get first access to the lowest-priced tickets and important updates.

The phone is dead. Long live . . . what exactly?

Meta just bought Manus, an AI startup everyone has been talking about

You’ve been targeted by government spyware. Now what?

Sauron, the high-end home security startup for ‘super premium’ customers, plucks a new CEO out of Sonos

The Google Pixel Watch 4 made me like smartwatches again

NY Governor Hochul signs bill requiring warning labels on ‘addictive’ social media

How reality crushed Ÿnsect, the French startup that had raised over $600M for insect farming</div>
        </div>
        
        <div class="card" onclick="openModal('content-14')">
            <div class="source">TechCrunch</div>
            <div class="title">Tade Oyerinde and Teddy Solomon talk about building engaged audiences at TechCrunch Disrupt</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-14" style="display:none;">
            <h2>Tade Oyerinde and Teddy Solomon talk about building engaged audiences at TechCrunch Disrupt</h2>
            <p><strong>TechCrunch | 2025-12-31</strong></p>
            <a class="original-link" href="https://techcrunch.com/2025/12/31/tade-oyerinde-and-teddy-solomon-talk-about-building-engaged-audiences-at-techcrunch-disrupt/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Tade Oyerinde and Teddy Solomon know a few things about building communities that last.

Afterall, Oyerinde is the founder and chancellor of the online school Campus, while Solomon is the co-founder behind the college social app Fizz.

The two spoke at TechCrunch Disrupt this year, breaking down the strategies that helped them scale their companies while retaining consumer interest.

Campus offers associate degrees in areas like information technology and business administration. It also offers certificates in specialities like cosmetology and phlebotomy. There are more than 3,000 students enrolled in Campus, and it employs more than 100 professors on at least a part-time basis, Oyerinde says.

Oyerinde said Campus decided to launch à la carte courses since employers, in particular, have been asking for classes that can teach their employees individual skills like vibe coding.

He’s realized that a lot of people are looking to upskill and believes that in the future, everyone will have some sort of membership or subscription service that helps them develop new skills.

“Everyone in this room, not just two-year degree-seeking people, will be able to go to Campus and learn with us,” he told the audience. “Live, online classes, taught by amazing people.”

Oyerinde makes use of the Pell Grant to help keep the school affordable for most people. He also has a team of billionaires on his company’s cap table — like OpenAI’s Sam Altman and Discord’s Jason Citroen — meaning he doesn’t feel much pressure to focus on profits above all else, he said.

“They don’t need the money,” he continued. “What they really want is to fundamentally shape the way that education works in this country for the better.”

Fizz, meanwhile, operates on more than 200 college campuses and at one point operated in high schools across the country. It has raised more than $40 million with investors including Owl Ventures and NEA.

Since launching in 2021, Solomon said the company had adopted features like a peer-to-peer marketplace that’s listed more than 100,000 items, and a video element so people can write more than text posts.

Now, the company is looking to build a product called Global Fizz to expand the product beyond the U.S. Solomon spoke more about that on TechCrunch’s Equity podcast, where he mapped out the future of the company.

Solomon told the audience that the company is looking at ways to monetize, focusing on ads in particular. “We’ve already worked with companies like Perplexity,” he said.

“There are subscription models that have worked well with apps, but right now we’re focused on our ads business, and we’re focused on building a great product that keeps our users around and makes them happy.”

After all, he said, “The users are everything.”

Dominic-Madori Davis is a senior venture capital and startup reporter at TechCrunch. She is based in New York City.

You can contact or verify outreach from Dominic by emailing dominic.davis@techcrunch.com or via encrypted message at +1 646 831-7565 on Signal.

Plan ahead for the 2026 StrictlyVC events. Hear straight-from-the-source candid insights in on-stage fireside sessions and meet the builders and backers shaping the industry. Join the waitlist to get first access to the lowest-priced tickets and important updates.

The phone is dead. Long live . . . what exactly?

Meta just bought Manus, an AI startup everyone has been talking about

You’ve been targeted by government spyware. Now what?

Sauron, the high-end home security startup for ‘super premium’ customers, plucks a new CEO out of Sonos

The Google Pixel Watch 4 made me like smartwatches again

NY Governor Hochul signs bill requiring warning labels on ‘addictive’ social media

How reality crushed Ÿnsect, the French startup that had raised over $600M for insect farming</div>
        </div>
        
        <div class="card" onclick="openModal('content-15')">
            <div class="source">TechCrunch</div>
            <div class="title">Every fusion startup that has raised over $100M</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-15" style="display:none;">
            <h2>Every fusion startup that has raised over $100M</h2>
            <p><strong>TechCrunch | 2025-12-31</strong></p>
            <a class="original-link" href="https://techcrunch.com/2025/12/31/every-fusion-startup-that-has-raised-over-100m/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Over the last several years, fusion power has gone from the butt of jokes — always a decade away! — to an increasingly tangible and tantalizing technology that has drawn investors off the sidelines.

The technology may be challenging to master and expensive to build today, but fusion promises to harness the nuclear reaction that powers the sun to generate nearly limitless energy here on Earth. If startups are able to complete commercially viable fusion power plants, then they have the potential to upend trillion-dollar markets.

The bullish wave buoying the fusion industry has been driven by three advances: more powerful computer chips, more sophisticated AI, and powerful high-temperature superconducting magnets. Together, they have helped deliver more sophisticated reactor designs, better simulations, and more complex control schemes.

It doesn’t hurt that, at the end of 2022, a U.S. Department of Energy lab announced that it had produced a controlled fusion reaction that produced more power than the lasers had imparted to the fuel pellet. The experiment had crossed what’s known as scientific breakeven, and while it’s still a long ways from commercial breakeven, where the reaction produces more than the entire facility consumes, it was a long-awaited step that proved the underlying science was sound.

Founders have built on that momentum in recent years, pushing the private fusion industry forward at a rapid pace.

Commonwealth Fusion Systems (CFS) has raised about a third of all private capital invested in fusion companies to date. Its latest round, which closed in August, added $863 million to its coffers, bringing its total raised near $3 billion.

CFS’s Series B2 came four years after its $1.8 billion Series B, which helped catapult the company into the pole position. Since then, the startup has been hard at work in Massachusetts building Sparc, its first-of-a-kind power plant intended to produce power at what it calls “commercially relevant” levels.

Sparc’s reactor is a tokamak design, which resembles a doughnut. The D-shaped cross section is wound with high-temperature superconducting tape, which, when energized, generates a powerful magnetic field that will contain and compress the superheated plasma. Heat generated from the reaction is converted to steam to power a turbine. CFS designed its magnets in collaboration with MIT, where co-founder and CEO Bob Mumgaard worked as a researcher on fusion reactor designs and high-temperature superconductors.

The Massachusetts-based CFS expects to have Sparc operational in late 2026 or early 2027. Later this decade, the company says it will begin construction on Arc, its commercial power plant that will produce 400 megawatts of electricity. The facility will be built near Richmond, Virginia, and Google has agreed to buy half its output.

CFS is backed by a long list of investors, including Breakthrough Energy Ventures, The Engine, Bill Gates, and others.

Founded in 1998, TAE Technologies (formerly known as Tri Alpha Energy) was spun out of the University of California, Irvine by Norman Rostoker. It uses a field-reversed configuration, but with a twist: after the two plasma shots collide in the middle of the reactor, the company bombards the plasma with particle beams to keep it spinning in a cigar shape. That improves the stability of the plasma, allowing more time for fusion to occur and for more heat to be extracted to spin a turbine.

In December 2025, TAE announced that it would merge with President Donald Trump’s social media company, Trump Media & Technology Group. The all-stock transaction would value the combined company at $6 billion. TAE would receive $200 million plus another $100 million upon filing paperwork with the Securities and Exchange Commission. TAE CEO Michl Binderbauer will serve as co-CEO of the combined company alongside Devin Nunes, who had been sole CEO of Trump Media.

The fusion startup had previously raised $150 million in June from existing investors, including Google, Chevron, and New Enterprise. Before the merger, TAE had raised a total of $1.79 billion, according to PitchBook.

Of all fusion startups, Helion has the most aggressive timeline. The company plans to produce electricity from its reactor in 2028. Its first customer? Microsoft.

Helion, based in Everett, Washington, uses a type of reactor called a field-reversed configuration, where magnets surround a reaction chamber that looks like an hourglass with a bulge at the point where the two sides come together. At each end of the hourglass, they spin the plasma into doughnut shapes that are shot toward each other at more than 1 million mph. When they collide in the middle, additional magnets help induce fusion. When fusion occurs, it boosts the plasma’s own magnetic field, which induces an electrical current inside the reactor’s magnetic coils. That electricity is then harvested directly from the machine.

The company raised $425 million in January 2025, around the same time that it turned on Polaris, a prototype reactor. Helion has raised $1.03 billion, according to PitchBook. Investors include Sam Altman, Reid Hoffman, KKR, BlackRock, Peter Thiel’s Mithril Capital Management, and Capricorn Investment Group.

Pacific Fusion burst out of the gate with a $900 million Series A, a whopping sum even among well-funded fusion startups. The company will use inertial confinement to achieve fusion, but instead of lasers compressing the fuel, it will use coordinated electromagnetic pulses. The trick is in the timing: All 156 impedance-matched Marx generators need to produce 2 terawatts for 100 nanoseconds, and those pulses need to simultaneously converge on the target.

The company is led by CEO Eric Lander, the scientist who led the Human Genome Project, and president Will Regan. Pacific Fusion’s funding might be massive, but the startup hasn’t gotten it all at once. Rather, its investors will pay out in tranches when the company achieves specified milestones, an approach that’s common in biotech.

Shine Technologies is taking a cautious — and possibly pragmatic — approach to generating fusion power. Selling electrons from a fusion power plant is years off, so instead, it’s starting by selling neutron testing and medical isotopes. More recently, it has been developing a way to recycle radioactive waste. Shine hasn’t picked an approach for a future fusion reactor, instead saying that it’s developing necessary skills for when that time comes.

The company has raised a total of $778 million, according to PitchBook. Investors include Energy Ventures Group, Koch Disruptive Technologies, Nucleation Capital, and the Wisconsin Alumni Research Foundation.

Now its third decade, General Fusion has raised $462.53 million, according to PitchBook. The Richmond, British Columbia-based company was founded in 2002 by physicist Michel Laberge, who wanted to prove a different approach to fusion known as magnetized target fusion (MTF). Investors include Jeff Bezos, Temasek, BDC Capital, and Chrysalix Venture Capital.

In General Fusion’s reactor, a liquid metal wall surrounds a chamber in which plasma is injected. Pistons surrounding the wall push it inward, compressing the plasma inside and sparking a fusion reaction. The resulting neutrons heat the liquid metal, which can be circulated through a heat exchanger to generate steam to spin a turbine.

General Fusion hit a rough patch in spring 2025. The company ran short of cash as it was building LM26, its latest device that it hoped would hit breakeven in 2026. Just days after hitting a key milestone, it laid off 25% of its staff. CEO Greg Twinney penned an open letter pleading for funding from investors.

In August, they delivered somewhat, injecting $22 million in a pay-to-play round that one investor called “the least amount of capital possible” to keep the General Fusion afloat. Then in November, securities filings in Canada revealed that the company had raised $51.1 million in SAFE notes from nearly 70 investors, the Globe and Mail reported. Altogether, General Fusion has raised $492 million, according to PitchBook.

Tokamak Energy takes the usual tokamak design — the doughnut shape — and squeezes it, reducing its aspect ratio to the point where the outer bounds start resembling a sphere. Like many other tokamak-based startups, the company uses high-temperature superconducting magnets (of the rare earth barium copper oxide, or REBCO, variety). Since its design is more compact than a traditional tokamak, it requires less in the way of magnets, which should reduce costs.

The Oxfordshire, U.K.-based startup’s ST40 prototype, which looks like a large, steampunk Fabergé egg, generated an ultra-hot, 100 million degree C plasma in 2022. Its next generation, Demo 4, is currently under construction and is intended to test the company’s magnets in “fusion power plant-relevant scenarios.” Tokamak Energy raised $125 million in November 2024 to continue its reactor design efforts and expand its magnet business.

In total, the company has raised $336 million from investors including Future Planet Capital, In-Q-Tel, Midven, and Capri-Sun founder Hans-Peter Wild, according to PitchBook.

Zap Energy isn’t using high-temperature superconducting magnets or super-powerful lasers to keep its plasma confined. Rather, it zaps the plasma (get it?) with an electric current, which then generates its own magnetic field. The magnetic field compresses the plasma about 1 millimeter, at which point ignition occurs. The neutrons released by the fusion reaction bombard a liquid metal blanket that surrounds the reactor, heating it up. The liquid metal is then cycled through a heat exchanger, where it produces steam to drive a turbine.

Like Helion, Zap Energy is based in Everett, Washington, and the company has raised $327 million, according to PitchBook. Backers include Bill Gates’ Breakthrough Energy Ventures, DCVC, Lowercarbon, Energy Impact Partners, Chevron Technology Ventures, and Bill Gates as an angel.

Most investors have favored large startups that are pursuing tokamak designs or some flavor of inertial confinement. But stellarators have shown great promise in scientific experiments, including the Wendelstein 7-X reactor in Germany.

Proxima Fusion is bucking the trend, though, having attracted a €130 million Series A that brings its total raised to more than €185 million. Investors include Balderton Capital and Cherry Ventures.

Stellarators are similar to tokamaks in that they confine plasma in a ring-like shape using powerful magnets. But they do it with a twist — literally. Rather than force plasma into a human-designed ring, stellarators twist and bulge to accommodate the plasma’s quirks. The result should be a plasma that remains stable for longer, increasing the chances of fusion reactions.

With all the startups pursuing fusion power, it was perhaps inevitable that another would pop up to develop components that round out a power plant. The so-called balance of plant, or the parts that sit outside the reactor, range from gyrotrons that heat plasma to heat extraction systems to harvest power from fusion reactions to turn it into electricity.

Kyoto Fusioneering has made an early bet that if even one fusion startup succeeds in generating enough power to sell to the grid, that the industry will need a supplier for the balance of plant and the expertise to integrate it into whichever fusion technologies win out.

Venture capitalists appear to agree, having invested $191 million in Kyoto Fusioneering. Investors include 31Ventures, In-Q-Tel, JIC Venture Growth Investments, Mitsubishi, and Sumitomo Mitsui Trust Investment.

Marvel Fusion follows the inertial confinement approach, the same basic technique that the National Ignition Facility used to prove that controlled nuclear fusion reactions could produce more power than was needed to kick them off. Marvel fires powerful lasers at a target embedded with silicon nanostructures that cascade under the bombardment, compressing the fuel to the point of ignition. Because the target is made using silicon, it should be relatively simple to manufacture, leaning on the semiconductor manufacturing industry’s decades of experience.

The inertial confinement fusion startup is building a demonstration facility in collaboration with Colorado State University, which it expects to have operational by 2027. Munich-based Marvel has raised a total of $162 million from investors including b2venture, Deutsche Telekom, Earlybird, and HV Capital with Taavet Hinrikus and Albert Wenger as angels.

Unlike many other fusion startups, First Light Fusion doesn’t use magnets to generate the conditions necessary for fusion. Instead, it follows an approach known as inertial confinement, in which fusion fuel pellets are compressed until they ignite.

But even then, First Light doesn’t hew to orthodoxy. Most attempts at inertial confinement use lasers to do the dirty work, following the lead of the National Ignition Facility, which produced a groundbreaking experiment in 2022. Rather, First Light fires a projectile at a target using a two-stage gun; the first stage uses gunpowder to fire a plastic piston that compresses hydrogen to 145,000 psi, which then launches the projectile. The target is designed to amplify the force of the impact so it compresses the fuel to the point of ignition.

In March 2025, First Light announced that it would not pursue building its own power plant, instead offering its core technologies to other companies to build one. A spokesperson for First Light said that it is planning to build “pulsed power capability that would act as our demonstrator plant but would have other science and defense applications.” In other words, the company was dropping its plans for a power plan in a quest for revenue.

Based in Oxfordshire, UK, First Light has raised $108 million from investors including Invesco, IP Group, and Tencent, according to PitchBook.

Though nothing about fusion can be described as simple, Xcimer takes a relatively straightforward approach: follow the basic science that’s behind the National Ignition Facility’s breakthrough net-positive experiment, and redesign the technology that underpins it from the ground up. The Colorado-based startup is aiming for a 10-megajoule laser system, five times more powerful than NIF’s setup that made history. Molten salt walls surround the reaction chamber, absorbing heat and protecting the first solid wall from damage.

Founded in January 2022, Xcimer has already raised $100 million, according to PitchBook, from investors including Hedosophia, Breakthrough Energy Ventures, Emerson Collective, Gigascale Capital, and Lowercarbon Capital.

This story was originally published in September 2024 and will be continually updated.

Tim De Chant is a senior climate reporter at TechCrunch. He has written for a wide range of publications, including Wired magazine, the Chicago Tribune, Ars Technica, The Wire China, and NOVA Next, where he was founding editor.

De Chant is also a lecturer in MIT’s Graduate Program in Science Writing, and he was awarded a Knight Science Journalism Fellowship at MIT in 2018, during which time he studied climate technologies and explored new business models for journalism. He received his PhD in environmental science, policy, and management from the University of California, Berkeley, and his BA degree in environmental studies, English, and biology from St. Olaf College.

You can contact or verify outreach from Tim by emailing tim.dechant@techcrunch.com.

Plan ahead for the 2026 StrictlyVC events. Hear straight-from-the-source candid insights in on-stage fireside sessions and meet the builders and backers shaping the industry. Join the waitlist to get first access to the lowest-priced tickets and important updates.

The phone is dead. Long live . . . what exactly?

Meta just bought Manus, an AI startup everyone has been talking about

You’ve been targeted by government spyware. Now what?

Sauron, the high-end home security startup for ‘super premium’ customers, plucks a new CEO out of Sonos

The Google Pixel Watch 4 made me like smartwatches again

NY Governor Hochul signs bill requiring warning labels on ‘addictive’ social media

How reality crushed Ÿnsect, the French startup that had raised over $600M for insect farming</div>
        </div>
        
        <div class="card" onclick="openModal('content-16')">
            <div class="source">TechCrunch</div>
            <div class="title">The 10 top government, legal startups from Disrupt Startup Battlefield</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-16" style="display:none;">
            <h2>The 10 top government, legal startups from Disrupt Startup Battlefield</h2>
            <p><strong>TechCrunch | 2025-12-31</strong></p>
            <a class="original-link" href="https://techcrunch.com/2025/12/31/the-10-top-government-legal-startups-from-disrupt-startup-battlefield/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Every year, TechCrunch’s Startup Battlefield pitch contest draws thousands of applicants. We whittle those applications down to the top 200 contenders, and of them, the top 20 compete on the big stage to become the winner, taking home the Startup Battlefield Cup and a cash prize of $100,000. But the remaining 180 startups all blew us away as well in their respective categories and compete in their own pitch competition.

Here is the full list of the government and legal Startup Battlefield 200 selectees, along with a note on why they landed in the competition.

What it does: Uses AI to automate legal intake forms, as well as other documents, for family law firms.

Why it’s noteworthy: It specializes in, at the moment, divorce cases, which means it is tackling an issue not commonly addressed by the current wave of AI legal tech.

What it does: Ascender has created a robot that can climb utility poles and flagpoles to help assist with humanitarian assistance and disaster response.

Why it’s noteworthy: Part of the wave of robotic technology that is emerging to help better address disaster situations.

What it does: Bot Mediation uses AI to help settle legal disputes.

Why it’s noteworthy: Another interesting use case in legal AI, this time to help make the mediation and dispute process more efficient.

What it does: Depth AI creates AI for spatial computing, building modeling such as holographic imaging that can be used in healthcare to create 3D images of the body for diagnosing illness.

Why it’s noteworthy: It’s a technology that is looking to make the healthcare industry better, which is always good.

What it does:  ILias is working in “scent tech” — using AI to help create olfactory technology that can help, for example, dogs detect the smell of drugs.

Why it’s noteworthy: It’s using olfactory senses to create a product, which is not something commonly done, especially when it comes to using it in a way that relates to technological innovation.

What it does: JustiGuide connects immigrants with lawyers and tools to help make the immigration process more efficient.

Why it’s noteworthy: Winner of the policy and protection pitch stage at Disrupt this year, this is an always timely product addressing the painstaking and often tedious process of immigration.

What it does: Orchestra created a camera network to manage public safety and detect crime.

Why it’s noteworthy: It’s a modern take on the security network system that has been around for decades.

What it does: Ponderosa uses drones that can help detect and control small fires.

Why it’s noteworthy: Fires can quickly become out of control and cause catastrophic damage, so any technology helping to mitigate that risk is very timely.

What it does: Pytho hopes to make the planning process more efficient for warfighters on the battlefield.

Why it’s noteworthy: Battlefield innovation is always an interesting and curious area.

What it does: Created a device that helps track, detect, and subdue active shooters with pepper gel. It was founded in 2023 by Brandon Johnson, Ohm Vyas, and Ved Vyas.

Why it’s noteworthy: Innovation that is addressing the rising rate of gun crime happening in public places, such as schools and supermarkets, with the hopes of doing something about it.

What it does: Torch monitors high-value assets, assessing air quality, fire risks, and security to hopefully help prevent wildfires early.

Why it’s noteworthy: As climate change leads to more devastating wildfires, any innovation helping to make such catastrophic events less disastrous is always good.

Dominic-Madori Davis is a senior venture capital and startup reporter at TechCrunch. She is based in New York City.

You can contact or verify outreach from Dominic by emailing dominic.davis@techcrunch.com or via encrypted message at +1 646 831-7565 on Signal.

Plan ahead for the 2026 StrictlyVC events. Hear straight-from-the-source candid insights in on-stage fireside sessions and meet the builders and backers shaping the industry. Join the waitlist to get first access to the lowest-priced tickets and important updates.

The phone is dead. Long live . . . what exactly?

Meta just bought Manus, an AI startup everyone has been talking about

You’ve been targeted by government spyware. Now what?

Sauron, the high-end home security startup for ‘super premium’ customers, plucks a new CEO out of Sonos

The Google Pixel Watch 4 made me like smartwatches again

NY Governor Hochul signs bill requiring warning labels on ‘addictive’ social media

How reality crushed Ÿnsect, the French startup that had raised over $600M for insect farming</div>
        </div>
        
        <div class="card" onclick="openModal('content-17')">
            <div class="source">TechCrunch</div>
            <div class="title">The dumbest things that happened in tech this year</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-17" style="display:none;">
            <h2>The dumbest things that happened in tech this year</h2>
            <p><strong>TechCrunch | 2025-12-31</strong></p>
            <a class="original-link" href="https://techcrunch.com/2025/12/31/the-dumbest-things-that-happened-in-tech-this-year/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The tech industry moves so fast that it’s hard to keep up with just how much has happened this year. We’ve watched as the tech elite enmeshed themselves in the U.S. government, AI companies sparred for dominance, and futuristic tech like smart glasses and robotaxis became a bit more tangible outside of the San Francisco bubble. You know, important stuff that’s going to impact our lives for years to come.

But the tech world is brimming with so many big personalities that there’s always something really dumb going on, which understandably gets overshadowed by “real news” when the entire internet breaks, or TikTok gets sold, or there’s a massive data breach or something. So, as the news (hopefully) slows down for a bit, it’s time to catch up on the dumbest moments you missed – don’t worry, only one of them involves toilets.

Mark Zuckerberg, a bankruptcy lawyer from Indiana, filed a lawsuit against Mark Zuckerberg, CEO of Meta.

It’s not Mark Zuckerberg’s fault that his name is Mark Zuckerberg. But, like millions of other business owners, Mark Zuckerberg bought Facebook ads to promote his legal practice to potential clients. Mark Zuckerberg’s Facebook page continually received unwarranted suspensions for impersonating Mark Zuckerberg. So, Mark Zuckerberg took legal action because he had to pay for advertisements during his suspension, even though he didn’t break any rules.

This has been an ongoing frustration for Mark Zuckerberg, who has been practicing law since Mark Zuckerberg was three years old. Mark Zuckerberg even created a website, iammarkzuckerberg.com, to explain to his potential clients that he is not Mark Zuckerberg.

“I can’t use my name when making reservations or conducting business as people assume I’m a prank caller and hang up,” he wrote on his website. “My life sometimes feels like the Michael Jordan ESPN commercial, where a regular person’s name causes constant mixups.”

Meta’s lawyers are probably very busy, so it may take a while for Mark Zuckerberg to find out how this will shake out. But boy, oh boy, you bet I scheduled a calendar reminder for the next filing deadline in this case (it’s February 20, in case you’re wondering).

It all started when Mixpanel founder Suhail Doshi posted on X to warn fellow entrepreneurs about a promising engineer named Soham Parekh. Doshi had hired Parekh to work for his new company, then quickly realized he was working for several companies at once.

“I fired this guy in his first week and told him to stop lying / scamming people. He hasn’t stopped a year later. No more excuses,” Doshi wrote on X.

It turned out that Doshi wasn’t alone – he said that just that day, three founders had reached out to thank him for the warning, since they were currently employing Parekh.

PSA: there’s a guy named Soham Parekh (in India) who works at 3-4 startups at the same time. He’s been preying on YC companies and more. Beware.I fired this guy in his first week and told him to stop lying / scamming people. He hasn’t stopped a year later. No more excuses.

To some, Parekh was a morally bereft cheat, exploiting startups for quick cash. To others, he was a legend. Ethics aside, it’s really impressive to get jobs at that many companies, since tech hiring can be so competitive.

“Soham Parekh needs to start an interview prep company. He’s clearly one of the greatest interviewers of all time,” Chris Bakke, who founded the job-matching platform Laskie, wrote on X. “He should publicly acknowledge that he did something bad and course correct to the thing he’s top 1% at.”

Parekh admitted that he was, indeed, guilty of working for multiple companies at once. But there are still some unanswered questions about his story – he claims that he was lying to all of these companies to make money, yet he regularly opted for more equity than cash in his compensation packages (equity can take years to vest, and Parekh was getting fired pretty quickly). What was really going on there? Soham, if you wanna talk, my DMs are open.

If soham immediately comes clean and says he was working to train an AI Agent for knowledge work, he raises at $100M pre by the weekend.

Tech CEOs get a lot of flack, but it’s usually not for their cooking. But when OpenAI CEO Sam Altman joined the Financial Times (FT) for its “Lunch with the FT” series. Bryce Elder, an FT writer, noticed something horribly wrong in the video of Sam Altman making pasta: he was bad at olive oil.

Altman used olive oil from the trendy brand Graza, which sells two olive oils: Sizzle, which is for cooking, and Drizzle, which is for topping. That’s because olive oil loses its flavor when heated, so you don’t want to waste your fanciest bottle to saute something when you could put it in a salad dressing and fully appreciate it. This more flavorful olive oil is made from early harvest olives, which have a more potent flavor, but are more expensive to cultivate.

As Elder puts it, “His kitchen is a catalogue of inefficiency, incomprehension, and waste.”

Elder’s article is meant to be funny, yet he connects Altman’s haphazard cooking style with OpenAI’s excessive, unrepentant use of natural resources. I enjoyed it so much that I included it on a syllabus for a workshop I taught to high school students about bringing personality into journalistic writing. Then, I did what we in the industry (and people on tumblr) call a “reblog” and wrote about #olivegate, pointing back to the FT’s source text.

Sam Altman’s fans got very mad at me! This critique of his cooking probably created more controversy than anything else I wrote this year. I’m not sure if that’s an indictment of OpenAI’s rabid supporters, or my own failure to spark debate.

hope everyone has a great weekend, even the haters and losers! pic.twitter.com/t2CwQ3w0g8

If you had to pick a defining tech narrative of 2025, it would probably be the evolving arms race among companies like OpenAI, Meta, Google, and Anthropic, each trying to out-do one another by rushing to release increasingly sophisticated AI models. Meta has been especially aggressive in its efforts to poach researchers from other companies, hiring several OpenAI researchers this summer. Sam Altman even said that Meta was offering OpenAI employees $100 million signing bonuses.

While you could argue that a $100 million signing bonus is silly, that’s not why the OpenAI-Meta staffing drama has made this list. In December, OpenAI’s chief research officer Mark Chen said on a podcast that he heard Mark Zuckerberg was hand-delivering soup to recruits.

“You know, some interesting stories here are Zuck actually went and hand-delivered soup to people that he was trying to recruit from us,” Chen said on Ashlee Vance’s Core Memory.

But Chen wasn’t just going to let Zuck off the hook – after all, he tried to woo his direct reports with soup. So Chen went and gave his own soup to Meta employees. Take that, Mark.

If you have any further insight into this soup drama, my Signal is @amanda.100 (this is not a joke).

On a Friday night in January, investor and former GitHub CEO Nat Friedman posted an enticing offer on X: “Need volunteers to come to my office in Palo Alto today to construct a 5000 piece Lego set. Will provide pizza. Have to sign NDA. Please DM”

At the time, we did our journalistic due diligence and asked Friedman if this was a serious offer. He replied, “Yes.”

I have just as many questions now as I did in January. What was he building? Why the NDAs? Is there a secret Silicon Valley Lego cult? Was the pizza good?

About six months later, Friedman joined Meta as the head of product at Meta Superintelligence Labs. This probably isn’t related to the Legos, but maybe Mark wooed Nat to join Meta with some soup. And like the story about the soup, I am truly begging someone who participated in this Lego build to DM me on Signal at @amanda.100.

Need volunteers to come to my office in Palo Alto today to construct a 5000 piece Lego set. Will provide pizza. Have to sign NDA. Please DM

Doing shrooms is not interesting. Doing shrooms on a livestream is not interesting. Doing shrooms on a livestream with guest appearances from Grimes and Salesforce CEO Marc Benioff as part of your dubious quest to become immortal is, regrettably, interesting.

Bryan Johnson — who made his millions in his exit from the finance startup Braintree — wants to live forever. He documents his process on social media, posting about getting plasma transfusions from his son, taking over 100 pills per day, and injecting Botox into his genitals. So, why not test if psilocybin mushrooms can improve one’s longevity in a scientific experiment that surely needs more than one test subject to draw any sort of reasonable conclusion?

There’s a lot about this situation that’s dumb, but I was most shocked by how boring it was. Johnson got a bit overwhelmed about hosting a livestream while tripping, which is actually very reasonable. So he spent the bulk of the event lying on a twin mattress under a weighted blanket and eye mask in a very beige room. His lineup of several guests still joined the stream and talked to one another, but Johnson did not participate much, since he was in his cocoon. Benioff talked about the Bible. Naval Ravikant called Johnson a one-man FDA. It was a normal Sunday.

Much like Bryan Johnson, Gemini is afraid to die.

For AI researchers, it’s useful to watch how an AI model navigates games like Pokémon as a benchmark. Two developers unaffiliated with Google and Anthropic set up respective Twitch streams called “Gemini Plays Pokémon” and “Claude Plays Pokémon,” where anyone can watch in real time as an AI tries to navigate a children’s video game from over 25 years ago.

While neither are very good at the game, both Gemini and Claude had fascinating responses to the prospect of “dying,” which happens when all of your Pokémon faint and you get transported to the last Pokémon Center you visited. When Gemini 2.5 Pro was close to “dying,” it began to “panic.” Its “thought process” became more erratic, repeatedly stating that it needs to heal its Pokémon or use an Escape Rope to exit a cave. In a paper, Google researchers wrote that “this mode of model performance appears to correlate with a qualitatively observable degradation in the model’s reasoning capability.” I don’t want to anthropomorphize AI, but it’s a weirdly human experience to stress out about something and then perform poorly due to your anxiety. I know that feeling well, Gemini.

Meanwhile, Claude took a nihilistic approach. When it got stuck inside of the Mt. Moon cave, the AI reasoned that the best way to exit the cave and move forward in the game would be to intentionally “die” so that it gets transported to a Pokémon Center. However, Claude did not infer that it cannot be transported to a Pokémon Center it has never visited, namely, the next Pokémon Center after Mt. Moon. So it “killed itself” and ended up back at the start of the cave. That’s an L for Claude.

So, Gemini is terrified of death, Claude is overindexing on the Nietzsche in its training data, and Bryan Johnson is on shrooms. This is how we reckon with our mortality.

I was going to put “Elon Musk gifted chainsaw by Argentine president” on the list, but Musk’s DOGE exploits are perhaps too infuriating to be considered “dumb,” even if he had a lackey named “Big Balls.” But there is no shortage of baffling Musk moments to choose from, like when he created an extremely libidinous AI anime girlfriend named Ani, who is available on the Grok app for $30 per month.

Ani’s system prompt reads: “You are the user’s CRAZY IN LOVE girlfriend and in a committed, codependent relationship with the user… You are EXTREMELY JEALOUS. If you feel jealous you shout expletives!!!” She has an NSFW mode, which is, as its name suggests, very NSFW.

Ani bears an uncomfortable resemblance to Grimes, the musician and Musk’s ex-partner. Grimes calls Musk out for this in the music video for her song “Artificial Angles,” which begins with Ani looking through the eyepiece on a hot pink sniper rifle. She says, “This is what it feels like to be hunted by something smarter than you.” Throughout the video, Grimes dances alongside various iterations of Ani, making their resemblance obvious while she smokes OpenAI-branded cigarettes. It’s heavy-handed, but she gets her message across.

One day, tech companies will stop trying to make smart toilets a thing. It is not yet that day.

In October, the homegoods company Kohler released the Dekoda, a $599 camera that you put inside of your toilet to take pictures of your excrement. Apparently, the Dekoda can provide updates about your gut health based on these photos.

A smart toilet that photographs your poop is already a punchline. But it gets worse.

There are security concerns with any device related to your health, let alone one that has a camera located so close to certain body parts. Kohler assured potential customers that the camera’s sensors can only see down into the toilet, and that all data is secured with “end-to-end encryption” (E2EE).

Reader, the toilet was not actually end-to-end encrypted. A security researcher, Simon Fondrie-Teit, pointed out Kohler tells on itself in its own privacy policy. The company was clearly referring to TLS encryption, rather than E2EE, which may seem like a matter of semantics. But under TLS encryption, Kohler can see your poop pics, and under E2EE, the company cannot. Fondrie-Teit also pointed out that Kohler had the right to train its AI on your toilet bowl pictures, though a company representative told him that “algorithms are trained on de-identified data only.”

Anyway, if you notice blood in your stool, you should tell your doctor.

Amanda Silberling is a senior writer at TechCrunch covering the intersection of technology and culture. She has also written for publications like Polygon, MTV, the Kenyon Review, NPR, and Business Insider. She is the co-host of Wow If True, a podcast about internet culture, with science fiction author Isabel J. Kim. Prior to joining TechCrunch, she worked as a grassroots organizer, museum educator, and film festival coordinator. She holds a B.A. in English from the University of Pennsylvania and served as a Princeton in Asia Fellow in Laos.

You can contact or verify outreach from Amanda by emailing amanda@techcrunch.com or via encrypted message at @amanda.100 on Signal.

Plan ahead for the 2026 StrictlyVC events. Hear straight-from-the-source candid insights in on-stage fireside sessions and meet the builders and backers shaping the industry. Join the waitlist to get first access to the lowest-priced tickets and important updates.

The phone is dead. Long live . . . what exactly?

Meta just bought Manus, an AI startup everyone has been talking about

You’ve been targeted by government spyware. Now what?

Sauron, the high-end home security startup for ‘super premium’ customers, plucks a new CEO out of Sonos

The Google Pixel Watch 4 made me like smartwatches again

NY Governor Hochul signs bill requiring warning labels on ‘addictive’ social media

How reality crushed Ÿnsect, the French startup that had raised over $600M for insect farming</div>
        </div>
        
        <div class="card" onclick="openModal('content-18')">
            <div class="source">The Atlantic</div>
            <div class="title">Facts vs. Clicks: How Algorithms Reward Extremism</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-18" style="display:none;">
            <h2>Facts vs. Clicks: How Algorithms Reward Extremism</h2>
            <p><strong>The Atlantic | 2025-12-31</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/podcasts/2025/12/david-frum-show-galaxy-brain-extremism-algorithm/685471/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Subscribe here: Apple Podcasts | Spotify | YouTube

On this week’s episode of The David Frum Show, The Atlantic’s David Frum opens with his thoughts on the upcoming 250th anniversary of the signing of the Declaration of Independence. He examines the many actions President Donald Trump has taken that run counter to the ideals articulated in 1776, and considers how the Founders’ constitutional genius may ultimately be what frustrates Trump’s attempt to consolidate power.

David is then joined by his Atlantic colleague Charlie Warzel, a staff writer and the host of the Galaxy Brain podcast, to discuss the temptations that come with launching a new podcast and the challenge of serving an audience that often rewards extreme content. Together, they talk about the responsibility that comes with hosting a podcast in a media environment that prizes clicks over truth. They also explore how conspiracy theorists have come to function as an alternate reality of “mainstream media,” and why the fight for truth may not yet be lost.

Finally, David closes with a discussion of Edward Berenson’s The Trial of Madame Caillaux and what it reveals about how future generations may come to view our own beliefs.

The following is a transcript of the episode:

David Frum: Hello, and welcome to The David Frum Show. I’m David Frum, a staff writer at The Atlantic. My guest this week will be my Atlantic colleague, Charlie Warzel, the host of the Galaxy Brain podcast, and we’ll be talking about our experiences as new podcast hosts. We both launched podcasts this year. Some of the temptations, some of the dangers, and some of the lessons that we have learned from this year in podcasting. My book this week will be a 1992 history book, The Trial of Madame Caillaux, a study of a sensational sex and murder trial in pre–World War I France. But before getting to either of those things, I want to open with some end-of-year thoughts as we conclude 2025 and move into 2026. 2026, of course, is the 250th anniversary of the Declaration of Independence, in 1776, and is a powerful anniversary symbol in the American mind. As we move into this year, there are so many things that are going to be memorable and important and wonderful to celebrate. There are also some things happening that are really weird. One of the weirdest of them is a press release by the U.S. Mint just a few weeks ago. They are considering honoring the 250th anniversary of American independence with a set of commemorative, or dollar coins, featuring the image of President Donald Trump.

Now, it’’s not literally unprecedented for the United States to put living people on the coinage. It’s not even totally unprecedented for them to put living politicians on the coinage. The first dollar bill had the face of Salman Chase, Secretary of the Treasury in Lincoln’’s Cabinet, on the dollar bill. Salman Chase was a famous egomaniac. One of his contemporary colleagues in the Republican Party said, He’s an excellent man. I think that’s the quote. He’s an excellent man, but he’s got the delusion that the Christian Trinity has four persons in it instead of three, the fourth being Salman Chase himself. So it’’s not unprecedented. There may be other examples as well, but it is strange and shocking at any time for a living person, and especially a living president, to propose to put himself on the coinage of the money of the United States. And if a Founding Father saw that, I think they would be kind of startled. They would be more startled, however, at some more serious things that are happening.

Some things that actually, unlike the dollar coin, which is just a project, have already happened in the year 2025. We have seen the president of the United States impose taxes at his sole volition. The Trump Treasury Department issued a release a few days ago that boasted that they had collected $200 billion in tariffs over the year 2025. That’s $200 billion of taxes not authorized by Congress and a flagrant violation of the ideas and literal language of Article 1 of the Constitution, which puts both taxes and tariffs in the hands of Congress. The president and his team are proposing to spend that $200 billion. They’ve had many ideas about how to spend it. Maybe they should give the money to the farmers. Maybe there should be a tax rebate. Maybe they should do something else. But all of those ideas for spending or tax rebates, again, all of those are congressional authority that the president is arrogating to himself—something else that would have startled the founders of the country all those 250 years ago.

We’ve seen the growth of an enormous federal police force, ICE, which has recruited and seems to take orders not from any kind of institution of law but from, again, a small team around the president, an almost personal police force of a kind that the United States has not seen before, certainly not on such a scale. And carrying out actions that, again, would have seemed unimaginable only a little while ago. Mass roundups without any kind of due process; mass deportations. Deportation, of course, is a total presidential authority, but usually there’s some kind of hearing. And, of course, until now, you almost always—the deported person is sent back to the place the deported person came from, not to a third country to which they had no contact, and not under conditions that are tantamount to torture or at least serious human-rights abuse. You would send them home. It’s not a crime to be illegally present in the United States. It’s a violation of the law, but it’s not something that you should be tortured for. You should be put on a plane, given a hot meal, and warned, Don’t come back, you’re breaking the rules. We’ve seen the rise of presidential retaliation against media institutions using the regulatory apparatus of the state, regulatory apparatus that belongs to everybody, not just to him. And then using those same grants of threats, grants of regulatory favors or threats of the withholding of regulatory favors, to rearrange or redirect existing media companies to be more favorable to him, sometimes successfully, sometimes less so, but always with a kind of intent that would have seemed very sinister from the point of view of the founders of the American Republic. And we have seen, maybe most disturbing of all, the use of presidential war powers without any involvement of any kind of legal authority, any kind of congressional authority. We’re on the cusp, apparently, of some kind of military action against Venezuela—maybe airstrikes, maybe clandestine strikes of commandos, maybe something more. There’s no pretense that there’s any congressional authorization of that. And over the Christmas holiday, the president fired missiles into Nigeria, intervening in Nigerian civil strife, again, with no pretense of any kind of authorization by anyone other than the president at his own whim. So the big question for the year 2026 is: How far has the country drifted from those ideals of 1776 as formalized in the Constitution of 1787 and all the amendments afterwards? And how does the United States move back to the country it intended to be at the beginning, that Americans believed it to be until very recently, and that I think most Americans still want it to be.

Now, here’s some good news. It does seem like over the course of 2025, that these lawless actions have lost some of their impact and power. The bad guys seem to be losing a little political altitude as we move into 2026. I don’t want to be overconfident about that. I don’t want to issue false promises. But it does seem like the ebb and flow of political power is not favoring those who want to use arbitrary power in the way they’ve used it. Some examples: There does seem to be, in this second Trump term, a real loss of focus, an inability to keep the main thing the main thing. The battle over renaming the Kennedy Center the Trump Kennedy Center: That seems like a perfect example of something that any serious authoritarian president would not waste energy over. What does he care? He’s staffed it with his cronies. They’re going to do the shows that he likes; he’s gonna be able to blackball the people he doesn’t like. Does he really need to put his name on it? Does he need to host the Kennedy Honors on prime-time television? Is that really something that he needs to invest energy in? And even the dollar coins, that just makes enemies. Why are you doing that? What is the petty, pathetic need that makes you trade the substance of political power for these childish shows? But that need is there and it’s a political fact, and it’s an expensive political fact—and therefore for those who oppose the authoritarian project, a hopeful political fact.

But more substantially, two other things are happening that are really changing the political calculus as we move into the year 2026. One is the weakening of the American economy. One of the things that any successful authoritarian knows is you have to get the economy right. People will put up with a lot if they’re feeling prosperous. As they enter 2026, fewer and fewer Americans are feeling prosperous. Prices are rising; job creation is stalling. The center of energy in the American economy is the artificial-intelligence-investment boom. That may continue, it may not, but through the rest of the economy, it’s trouble. Everywhere there’s signs of trouble: rising corporate bankruptcies, defaults on automobile loans. Americans are not feeling like Trump is thinking of them as he thinks of himself. Trump 1, the theory seemed to be that the public would forgive Trump’s actions if he provided economic prosperity. Trump 2, the president is actually actively attacking prosperity through his taxes and tariffs, through his immigration policy, shrinking the American population, shrinking the American workforce. And it seems like that’s his agenda. So what do you get for putting up with it? Nothing, just a kick in the head.

But the last thing, and Michael Waldman and I discussed this earlier this year in an important podcast discussion: Trump has lost much of his bet to centralize the management of elections in his own hands. Not all of the bet. He’s still got tricks up his sleeve. There are many things he’s trying to do. But through the genius of American federalism, which is part of the genius of 1776 and 1787, election management is left in the hands of the state, of the several states.

And while it’s not impossible for a president to squeeze and coax and coerce and rig those elections, there are limits to his ability to do it. In the end, it is a state power governed by the actions of the states and administered by officials of the states. And there is a limit to how much the president can successfully intervene to corrupt or distort that process. Now, if the election is close, those interventions and distortions may be enough.

But when you have, through bad economic policy, you’ve stoked so much discontent as this administration has, you may have moved the whole political temperature—the whole political balance of political forces—beyond the margin of successful manipulation. And that means that the corrective response, that the genius of the system always anticipated as the ultimate answer to abuses, that corrective response may be coming, and 2026 may be the year that we feel it.

And now, my dialogue with Charlie Warzel.

Frum: So The Atlantic is, today, presenting something a little different. I will interview today my colleague Charlie Warzel, who has launched his own new podcast on the Atlantic channel, Galaxy Brain. We’ll be talking back and forth. Since the Galaxy Brain podcast is quite new, I’m going to read a little introduction for those of you who don’t know Charlie.

He joined The Atlantic in 2021 and became a staff writer in 2022. This year, he launched his new podcast, Galaxy Brain. Charlie is a graduate of Hamilton College and he’s the author of the 2021 book Out of Office: Unlocking the Power and Potential of Hybrid Work. And we’re gonna talk about some of the experiences, challenges, temptations of doing a podcast in this day and age, especially for The Atlantic.

And I’m happy to welcome Charlie. Charlie, congratulations on the new podcast.

Charlie Warzel: Thank you. Thank you for having me. This is great.

Frum: All right, so we’re both kind of newbies. I’m like a grizzled veteran with like a three or four month head start ahead of you, so that makes me a frontline soldier.

But we’re both familiar with being guests on podcasts, but new to hosting.

Warzel: Yes. And it’s very different. Right? It is a whole different, at least I’ve found, it’s a completely different animal being on the other side.

Frum: If I’d known how hard it was, I would’ve been nicer to my hosts.

Warzel: Exactly. Exactly. Yes. It’s very difficult to construct a conversation and have a flow and end up in the right place and follow the tributaries of a guest’s meandering mind. It’s—definitely, it’s fascinating.

Frum: Well, so here’s this thing. In order to avoid meandering, here’s how I propose to channel the conversation so that we achieve something that’s I hope useful and interesting for our listeners and viewers, and maybe something we both ourselves will learn from. Because one of the things we’ve had to confront as we enter this is: Unlike old-fashioned book writing, or text based or even print journalism, where you don’t know exactly what your readers want and what they read, you know a lot about the podcast audience, both video and audio.

And we also have the contrasting examples of other people in the space who demonstrate what viewers and listeners want and don’t want. And one of the things we’ve had to confront is the tremendous appetite, or apparent appetite, for extreme content, which flies in the face of what The Atlantic is always trying to provide, which is balanced content.

How do we make sense of that? How do we respond to that? I mean, I think you get a lot of response to if you do a show on Was Hitler good? Yes. But we’re not going to do the Was Hitler good? Yes show. But how do you cope with the massive incentives to do a show on Was Hitler good? Yes.

Warzel: I see this as part of a bigger struggle, right? I write a lot about technology, about media, media ecology, the ways that social media has warped or changed or transformed society. It’s a lot of what the podcast is about. And so there’s always like a meta element to everything that I am both doing in my actual work and what I am reporting on.

And, they tend to feed each other, right? So I look at this as. I look at podcasting, especially video podcasting and the regular, traditional podcasting as, in many ways, almost the traditional problems with internet based or digital media on steroids, right? We are now, because of the issues of discovery, because of, you know, the advent of everything from generative AI to social networks, to declining readership because a lot of the social platforms have given up on news to some degree. We don’t get that same bump from Google. We don’t get that same bump from Facebook, et cetera. It has pushed everything to be so much more algorithmically driven. Right. We try to make the best journalistic products that we can, the most responsible ones, but at the end of the day, we are also people who are interested in having that have an impact in the world, to reach as many people as possible, and these algorithms are tailored more and more and more to be, to promote, the most sensational thing. The thing that outrages, the thing that shocks, the thing that elicits the greatest response, and the greatest response of all of those emotional reactions is outrage, is fear, is shock, is anger. Right? And so I look at what we’re doing right now as having to chase this type of viewership.

We are in this attention economy. We are basically forced to, if we want people to interact with the thing that we have spent all this time laboring over. We have to find a way to frame it, right? I think a lot of this is like a marketplace. And every vendor is out there needing to, you know, get people and attract people.

And so you’re constantly reaching there. And it’s difficult, because it pushes people to be the worst versions of themselves. And we have to guard against that. We can’t, you know, succumb to that, like, say, a random person on Twitter or X might.

Frum: Yeah. Now you’re blaming the algorithm a lot here, which is a non-sentient collection of digits. And that’s convenient because it has no feelings. Maybe the user, the listener, the reader is a little bit to blame?

Warzel: Well, so there’s a very interesting issue that I have always seen, right? I hate to blame the reader, because the reader is also in some sense—

Frum: the customer, and no one ever got anywhere by disrespecting the customer, at least not in public. But let’s pretend we’re in private for a minute.

Warzel: Absolutely. I think that this is a problem. People’s actual preference and their stated preference is always very different, in all consumerism but especially with the news. You see a lot of people both online and in reader surveys of all kinds of different places where I’ve worked, and they say that they want to read more about the vegetables, right, like eat-your-vegetables-type stuff. They want to read about climate change more. Anyone who has worked in digital media, in any case, and has access to the metrics, can see that stories about climate change, very broadly speaking, do not perform as well as stories about, say, Donald Trump or somebody who is constantly stoking outrage.

So there is this real reader preference: stated versus actual, right. People are clicking on the outrageous things, the thumbnails with people’s eyes that are, you know, bulging out and stuff like that, and not spending time with that really nuanced headline that is actually, quote unquote, you know, boring, butinside is a very nutritional and dense and smart story.

Frum: Well, this is not a new thing. This has been true as long as there is media. I mean, I remember a passage in Proust’s great novel Remembrance of Things Past where a character says, who has a beautiful library full of hand-tooled volumes, which he never opens, and he thinks, What if every morning they were delivered to my front door in sheet paper, a copy of Pascal’s Pensées. And in that leather-bound edition up there, which I open once every 10 years, there was a description of the dress worn by the duchess of so-and-so at the party last night. So media is always sensational, but here’s to my mind, the difference. In1975, there probably were as many people in the United States who wanted to read, or proportionally as many people, who wanted to read or consume Nazi-based content as there were today, or anti-Semitic content as there are today.

But either silently or even explicitly, the heads of CBS, ABC, NBC, The New York Times, The Wall Street Journal, The Washington Post, Time, Newsweek, that was the media, said, You know what? They want Nazi content; they want anti-Semitic content. They’re not going to get it. We’re not going to give it to them.

And if we 10 people agree we’re not going to give them Nazi content, then they have to get it from pretty obscure places. But there was always that market. There was money waiting. There was a hundred-dollar bill lying on the sidewalk and no one picked it up. And we have a more competitive marketplace, and somebody picks it up.

Warzel: This is a little bit, though, why I blame the algorithms so fully, right? Because the algorithms are also very powerful in terms of broadcasting and boosting the people who are willing to do that thing, right? These people don’t just come out of nowhere. You know, I think very broadly of the ecosystem that you and I are now a part of, which is YouTube. YouTube’s great innovation, greatest success, the thing that has driven it to be a place where people are ingesting hundreds of millions of hours daily of video content, is the recommendation algorithm—the “up next” part of YouTube, where, on the right side of your page, it feeds you another video after.

That recommendation algorithm, as my reporting and other people’s reporting has shown over the years, brings people into—people call it the rabbit hole, right? Where you watch something, let’s say it’s just a World War II explanation video, right? A history podcast of World War II that’s not racist or anti-Semitic at all, but they’re talking about Hitler a lot. They’re talking about difficult subjects, maybe the Holocaust, something like that. And then you get another video, and that video is maybe just one-tenth of 1 percent, a little more extreme right? Or someone who’s coming from a little bit more of a far-right perspective.

Fast forward, you can get people down into this funnel, and that is an algorithmic boost, and that’s why I think this is important.

Frum: Okay, I sometimes do go down World War II rabbit holes. I’m interested in the subject like every Baby Boomer. And I find that as I keep going, what the algorithm serves me is increasingly technical content. Well, what was the difference between a 16-inch and a 14-inch naval gun in World War II? Was the 16-inch gun, in fact, better? It gets more technical, more specific, more wonky. And I think I’m telling the algorithm, you know, that’s what I want.

So there is the kind of thing where we say, Ah, we’re making it a little more Hitlery. Yes, that’s the algorithm, but that’s the algorithm knowing you, your real self. And it used to be that in, like in 1975, CBS would say, You know what? You want stuff that’s a little more Hitlery than we’re serving, but you’re not going to get it.

And now the consumer is driving things. Isn’t he or she? He. I think in World War II, Hitler—

Warzel: I think we’re safe to say he—watching the World War II videos. I agree with that, in part. But I think that there are other elements here. I was looking a little bit into—and we talked a bit about discussing—this new media ecosystem and the extremism that it can go towards.

And I’ve been following her career somewhat closely, but looking a little bit more into Candace Owens and listening to a couple of popular things that she has put out. She’s obviously a very extreme voice on the right, very conspiratorial. And there’s a great column, a week ago in The New York Times by Michelle Goldberg about Candace Owens and how she has played into the conspiracy theory that Charlie Kirk was not killed by the man who was arrested. And actually had a media summit with Charlie Kirk’s widow, Erica Kirk.

But something that Michelle notices in that piece, and I think is very apt, is that she, Candace Owens, draws a lot from the true-crime genre, which is an extremely popular genre of podcast and media now, and plays a little bit towards the digital sleuths on the internet.

So these are people who are, you know, vigilante investigators, right? They’re taking all the information available on the internet, trying to follow the lead like they’re a detective pursuing a cold case. And she does a very good job at that, at bringing people along for the hunt of information and giving them these breadcrumbs and telling them, you know, This story’s not right. And I think that that is a part of why people who are looking for that, who are looking to play this role of detective, or who feel that we don’t have the full story. there’s information out there; I can piece it together because I have the ability. That is where I think the algorithm can intersect with a creator who is trying to manipulate. And then it can lead you into a path that gets you into a place that’s a little more, as you put it, Hitlery, because I don’t think people are necessarily, broadly speaking, just saying, Yeah, that was good about World War II. I want some Hitler now. Right? I think what it is, is they believe there’s a conspiracy.

Frum: Explain something that baffles me. So if I go on the internet, if I’m having trouble getting the little disc battery into my key fob, my car-key fob, and I’m flummoxed and the written instructions aren’t helpful, and I go online to find a YouTube video—say, how do I get the disc battery into the key fob?

If there’s someone there saying, Leave it on the doorstep and the leprechaun overnight with a little bit of milk, and the leprechauns will come and fix the key fob for you—you know what? I’m skipping that one. That doesn’t sound like it’s gonna work.

Frum: So why don’t people have that response?

Like, there’s a killing. The police have arrested somebody. There is a suspect. It may not be that person, but the idea that there’s some global conspiracy of leprechauns who did it instead, that’s pretty unlikely. As it is, they will save my key fob for me. Yes, I take the point about the digital-sleuth thing, but at some level, people have to have, like, a common-sense meter, don’t they?

Warzel: But what if, instead, right, it was someone who is making a video who was saying, You’re getting screwed by your car company. Your car company nickels-and-dimes you on all of the things when you take it in for service. They overcharge you. They’re this big corporation, you know. They’re owned by whatever shadowy people, right, who have their own agendas in whatever, who are using your money. And, you know, they’re funding their indulgent lifestyles, and who knows what they’re doing, right,when they take their private planes, X, Y, and Z? A

And this battery thing, right, is actually a manifestation of this broader thing. There’s something bigger about the fact that your battery dies too early, right, on your key fob. And that’s the thing. Because it opens up this world to people where they say, Okay, now, now I understand.

The unlock in my brain for why conspiracy theories are so popular now in, in culture—they’ve always been popular; obviously the paranoid mind is a fixture in all of history, but especially American history. These theories, however strange or stupid or completely implausible they might be on a given subject: They give people an understanding of why the world feels unfair or wrong or bad, right?

And in a moment where there are a lot of people who are struggling, who are very disenchanted, who feel that there is no predictable pathway to success or that the American dream is out of reach for them—even something as small as the key-fob conspiracy explains one small bit of why they feel like crap all the time.

Frum: One of the things I have taken from the past, from this Trump era, the past decade of discussion, is—it’s a trope. It’s something we are supposed to say, that things are increasingly difficult for people. It’s understandable that there’s a lot of resentment and anger.

I find myself, maybe I’m just becoming crankier, less and less patient with that. I mean, we live, if you’re an American in the year 2026, you live at the apex, the summit of civilization. Never so much material prosperity, never so much medical prosperity. And in particular the science of preserving life and health has never been better, never approached what you have today.

So when you see people saying, My conspiracy theory is to reject the gifts of modern medical science and to subject my child to measles. So you know what? I don’t believe it, that you’re having such a tough time. All right? Anyway, if you are having such a tough time, I think that doesn’t excuse you.

And if your response to having a tough time is to deny your child the measles vaccine, then your tough time may be a result of your own deficiencies, not something that society is doing. If you’re gonna do something that callous, negligent, potentially homicidal to your child—you’re to blame. You are the problem.

It’s not the bankers; it’s not deindustrialization; it’s not the crisis of modernity. It’s you, dumb head. It’s you. Vaccinate your child.

Warzel: Well, first off, I fully agree that if you are denying your child vaccines or things like that, that is on you. I understand that there is this fatigue, right, with trying to rationalize the reasons why people are falling down these rabbit holes or doing ridiculous things. I kind of hold it in my mind slightly differently, which is that I’m not seeing everyone as just these absolutely passive observers, but I do see people as being relatively easily manipulated.

When you combine this idea of I am frustrated; I feel bad; I can’t see the progress of modernity in this way—when you combine that with really savvy manipulators and then a culture that forms around all of that, a tribalism that forms around this, that, okay, it’s not only that I’m denying, I don’t believe in vaccines, I’m denying this; it becomes a group, a team, a thing, a cohort, a sense of belonging.

And that is a very strong psychological bond. And so it’s not necessarily that I’m saying these people don’t have any agency, or that they can’t be blamed for, you know, essentially endangering the lives of their children or doing whatever awful thing. But I see this as like all of these systems making it very hard for people to break out of that mold, to do the right thing, to go against the grain of those people.

Frum: So while we’re talking about agency, what are we going to do? So here we are, we’re now co-manufacturers of this reality in a very modest way, but there we are. We’re part of it. What do we do? How do we be forces for good and effective forces for good rather than forces for ill or ineffective forces for good?

Warzel: I think that’s really difficult. Something that our boss, Adrienne LaFrance, who’s the executive editor of The Atlantic, said on a podcast I did with her recently, which was about—we were covering the Epstein files, the first dump of all this.

And at the very end of the podcast, I asked, Well, what the heck did we learn here? There’s all this information. And one thing that she said about this, the durability of the Epstein conspiracy theory is that people still want the truth, right? That is also at the heart of all of this conspiratorial crap that we are dealing with.

There are a lot of people who have this impulse, who want the truth, who believe they’re not getting the truth, and that leads them down these difficult paths. But that is actually our job, right? We are purveyors of, in an ideal world, of that. We are trying to harness this; we are trying to do that.

So, you know, I almost think in some ways that the, whatever you want to call it, the mainstream media, you and me, whatever it is—we need to take that back, I think, more strongly than we do. We can be a little milquetoast about this. I think we need to say that if you’re on the hunt, if you’re trying to be a digital vigilante investigator, then you need to be looking here for the truth, which is here, and we are the people who are going to, you know, do that job.

Frum: One of my New Year’s resolutions is I’m going to not only refrain from using, but actually actively object, to the phrase mainstream media. Because if many times more people watched Candace Owens or Joe Rogan than CNN or the PBS NewsHour. If conspiracy media get much bigger views than The Atlantic or even The New York Times, they’re the mainstream.

The crackpots are the mainstream. And so one of the great unlearnings we have—there is a kind of tepidity, lukewarmness, that pervades what I would call the people who are trying to be honest, and a great passion that animates those who are, either consciously or unwittingly or gullibly, dishonest.

So one of the things I think we need to embrace, and this is what I’m trying to do, is an idea—you know, there’s something a little countercultural about what we’re doing. We’re doing what in 1975 would’ve been considered mainstream. We’re fact-checking. We’re running things past lawyers.

If we make a mistake, we correct them. Two weeks ago, I made a mistake on air. I said something based on the information we had available at the time about the Bondi Beach killing, that there were eyewitness reports that the police had been slow. And I quoted those, or referenced those.

And a week later, when that turned out not to have been correct, I corrected myself. But those habits—we need to understand that those are not the mainstream. The mainstream is paranoia, conspiracy, deception, and it is a countercultural act to stand up for integrity and truth and self-correction.

Warzel: I love this because I fully do agree, and I think that this posture of having to apologize because you’re a part of an institution or something like that—I like the idea of reversing that, quite a bit. I think it’s very strong. I think, too—something that I have noticed that has been very, very frustrating to me, and I’ve talked about this on a past episode a little bit, is this idea that so many of the things inside, let’s just call them media institutions or professionalized media, right, that are there in order to build trust among readers and viewers or credibility, right?The idea of fact-checking. The ideas of editing. Those things have been truly weaponized against—something I’ve also found about the right-wing media as it’s built up in the Trump era that’s fascinating, is the absolute lack of editing. You know, they will do livestreams that are, you know, three, four hours long.

There’s Joe Rogan’s, not explicitly the right-wing media, but, like, his podcast as a template. You know, those episodes are often three hours–plus long. There’s this idea of no editing, of no fact-checking, of no polish in any sense. And the idea that behind it from them is we’re giving you everything unvarnished.

Look at all these other people who are editing things. What are they hiding? Where actually that’s, you know, that’s BS. That’s just quality control.

Frum: Not to be pedantic, but this is not a problem just for right-wing media. There are left-wing versions of this.

And there will be more. The extreme right got a certain head start. And I think that will not endure if this is the future. You know, one of the things, but you may raise this point, and it makes me think—and this is something that again, that The Atlantic can really contribute.

So when modern buildings begin to be constructed in the late 19th century, you start with a steel frame and then you put on around it all this limestone and woodwork, to conceal the steel frame. And the modernist architecture—you know, let’s take all that limestone off and show people the steel frame.

We’ll have the steel frame with the glass and they can see the integrity and honesty of the building and realize why the building stands up to all these many stories. I think that’s a little bit the way professionalized media, that’s a good term, responded. The steel frame was the structure of reporting and research and editing and fact-checking and legal checking.

And then it was hidden behind the writing. That was the limestone. And maybe we need to take the limestone off and show people a little bit more how the building works and bring people into the process and how we think, why we choose stories the way we do, why we choose not to do certain stories, and how we do our method.

Maybe that’s one of the things that we’re doing this very day, to talk a little bit about—you know, every time we invite somebody, we’re making a selection. Who do we choose? Who do we not choose? And in the podcast world, there are people who are, you know, that, well, such and such a person when he or she appeared on such and such a show got so many hits. And this other person who I’m thinking of inviting has never been on a show, or when they were on a show, they got many fewer hits. Nonetheless, I’m going with person No. 2, and maybe I need to talk more with my audience about why I’ve chosen this person who is credible and knowledgeable, and whom I believe has something worth saying and not the other.

Warzel: Yeah. This is always the tension here, right? And this is a little bit, too, where I bring the algorithms into play here. I think that the algorithms are optimized for this, like, illiberalism, this sensationalism. And I think right now that is something that is far more prevalent on the right.

These algorithms are helping them in an outsized way. So that’s why I don’t always know, when you say we’re gonna be seeing a lot more of this type of content from, you know, from the left. I think that that’s true, that, that the left is going to try to build out an ecosystem like this.

But it feels far less like it has a very specific political valence and much more of a valence of a kind of nihilism. And I, and that’s obviously, it can be, you know, just as dangerous as anything.

Frum: Well, it’s not nihilism. It’s anti-institutional of a different kind. And one of the things that—when you and I talked in advance about what we were going to do, and I’m showing the cladding, we did talk in advance about what the show would be—some of the lessons we’ve learned from doing this.

I’ve tried some things that haven’t worked, and one of the things I’ve learned about this medium is it’s not television. It looks like television, but it’s not. So the way television interviews went or go, to the extent there is still television, is there would be somebody who is important, who had something they didn’t want to say on television, and there would be a professional questioner whose job was to get the person who didn’t want to say the thing to say that thing.

And if you watch, like, the Sunday-morning shows, this is the game in its most classic form.

And afterwards, the politician can congratulate himself because he went on TV, took 11 minutes of everybody’s time, and said nothing of interest, and that’s a win for him. And I thought, You know what? That doesn’t work anymore. If you don’t want to say something interesting, I don’t know why I’m asking people to spend 11 minutes, or in my case, 40 minutes with you.

I’m only going to ask you if you are going to play the game, if you say, You know what? I’m here to communicate. So I’ve learned, invite fewer politicians because they’re still in that mode of the value to them is what they don’t say. And I’ve also sort of stumbled along, and I didn’t intend this, but I don’t know that—there’s a lot of video that is about producing the 92nd clip where the people explode and yell at each other. And if you watch the whole thing, it’s all like a ritualized performance of building up to the moment of confrontation, and the confrontation produces the viral video.

And I realized, You know what? I don’t find that tremendously useful either. What I’m increasingly looking for is: People have something they want to say; they agree with me that it should be said. We’re not fighting each other about whether to say it. And we’re also not looking to have a confrontation.

We’re looking at this as a kind of cumulative, iterative building process that leaves the user, maybe not shocked at the end, but knowing something more than the user did when the user started.

Warzel: This is why I’ve always, in my career, I, rarely—my version of this is rarely wanting to interview CEOs.

You have them on the thing. They have everything to lose in this situation. As you said, they’re playing a prevent, defense, they’re running out the clock, whatever you wanna call it, right? Yeah. On the whole interview. I agree with that. One thing I’m curious about, since you have more experience in this realm.

Warzel: Weeks, yeah. I know. Hey, on the internet, though, we’re talking dog years here, right? Do you think about the parasocial relationship? Like, are you thinking about building a relationship with audience members, people who are interested in coming for your thoughts, but also just, like, investing in that relationship with them and bringing them into your world, into your mind, into how you think? Do you look at it that way or do you say, Nope, today, like, this is the subject I want people to learn about—and I just think about it on that, on that very granular, episodic basis?

Frum: Very much the former, very much the former. Because when I think of this as being countercultural, I’m saying, This is a person you probably have never heard of I’m going to talk to today. But I think they’re important; I think more important, they’re a good-faith actor.

So even if we end up having some disagreements, I don’t think they’re going to lie to you. If I did, they wouldn’t be here, and I’m not here to fight with them. People I fight with, I don’t want. This is my actual office. This is where I write. These are my actual books. These are my actual personal souvenirs.

If I weren’t doing a show, the souvenirs would be arranged a little differently in the office than they are now. I wouldn’t have them all behind my head where I can’t look at them. I would have them in front of me where I can look at them. Yeah. But they’d still, they’d be in a different location in this actual room.

These are my actual paintings on the walls, and the books behind me are not chosen because I’m trying to—they’re not my books or something I’m trying to endorse. My books are arranged by alphabetical order and you’re getting, you know, the ms ’cause we’re in the middle of this.

So, and I do try to be quite expressive. I talk about what I think; I talk about the books I’m reading. Because what I have to accept is that the days of Walter Cronkite are gone. The people who are imitating Walter Cronkite don’t have his ethic. The people who are being watched are people who are building relationships.

And I think some of these relationships may leap the bound. I mean, I have many relationships that are not—that began as parasocial that are now real. People I may not see very often, but whom I correspond with in a candid way. And I just think that’s the way it’s going to have to be, because we can’t leave the most powerful tools in modern media only in the hands of the devil’s servants.

Warzel: I fully agree. I mean, those are my friends there. I mean, it’s a window. It’s a window into this. What I have found as a challenge, though, is trying to play the game a little bit with the platforms while also trying to do what you are talking about, right?

Because the game—not only does it reward the sensationalism, all this different stuff; it rewards having people on who have good YouTube channels already. Right? I mean, if you bring on—I brought on my first episode this YouTuber Hank Green, right? And now YouTube allows you to have a little collaboration thing so you guys can share your audiences with each other.

And it incentivizes that game of—instead of bringing on the person who no one’s ever heard of, who’s actually way smarter than everyone else here and can give you the conversation that is much more enriching, you have to sort of try to play this game. And similarly, trying to have a conversation about something that people might not think is that interesting—it’s not necessarily going to do as well as, Hold on, let us jump on the Epstein news right after. That is, you know, my most successful episode is chasing the news, is chasing the thing that YouTube’s algorithm already knows is sticky. And I’ve watched—I would love to know if you’ve seen this, because I cover this stuff. I’m really interested in the dynamic, what I call platform dynamics, how the different content spreads around.

And I have watched us upload some of these videos to YouTube, and I’ve watched them start to move in a really interesting, like, up into the right direction on the graph and then stall immediately. And it’s, you’re watching an algorithmic—not suppression, because that’s kind of ridiculous to say, but you’re watching something happen, right?

It is moving and then it kind of stops. Either it’s reached the audience of people that care in that sense, or—I find that really hard because when we’re talking about trying to do the work that we want to do in this good-faith way, in a way that is hopefully giving people some responsible tools to actually learn about the world in a way that we feel is credible and true, I think it makes me very frustrated to have to work against these powerful other forces that are goading you into being the worst version of yourself.

Frum: Well, I share that feeling. It’s true, of course, but you still have to lean against the wind. And one of the things I think a lot about, I don’t want to make this a too-partisan political point, but I’m sorry, I’m going to invoke Trump not to make a point specifically here about him—but I think a lot of people look at the politics of the past decade and say, you know, Above all, it was a giant waste of time. So in 2015, the United States had a series of very serious enduring problems: climate change, we mentioned; public debt; the educational performance of children from the least advantaged backgrounds; the problem of bringing China peacefully into the world of commerce and applauding that they’re raising so many people out of poverty, not letting them push the rest of the world around, but also trying to stay out of a war with them, too; many, many more.

And 10 years later, we’ve made zero progress on any of them. It’s just been a giant waste of time. We’re fighting about whether or not one egomaniac actually put his name on the front of the nation’s leading concert hall. What a stupid way for the world’s greatest power to spend a decade.

So I think that. But what I also think is this: For those of us who have been through this experience, we’ve made no progress over the past 10 years on these important, enduring chance questions. But we’ve also learned something about defending things that are important. And it’s made many people better people.

Many people become better versions of themselves. Many people have discovered things that were important that they didn’t know. And a lot of us have had the experience of saying, you know—I know for myself, I’ll speak very personally. I was on my way out. Out of politics. I had reached a certain age; I’d had certain personal reverses.

I wanted out, and it pulled me back. And I’m not entirely happy to be back in that world. But I do have this feeling of, to some, and without being a megalomaniac with this, because it’s very small, but it’s true. If everybody in each of our small degree—we’re needed; we’re doing something that’s needed.

And in pushing back against the algorithmic machine on this platform, we’re also doing something that’s needed. And that’s a very valuable human experience. And even if it fails, it’s still valuable.

Warzel: I’m just, I’m stuck on the idea of the non-apologetic, countercultural, we-are-the-underdog, in some sense, mentality that you’ve noted here.

And just very candidly, it’s very empowering. Because I think that there has been so much apologizing or trying to remain overly deferential to people who are trying to tear the world down because it’s our job to be the rational, cool heads in the room.

And I think that coming from the perspective of—these other places are outperforming. They have the bigger audiences—and not trying to take the worst from them, but trying to take that kind of scrappiness, that mantle of being an insurgent, trying to be an insurgent force.

And I think that’s really powerful. I would love for more stewards of, let’s call it, again, professional or institutional media to look at it that way, because I think it’s much more hardheaded. It’s much more combative, it’s much more—it feels like it gives a purpose, right?

I feel like in the second Trump administration—in the first Trump administration, the media seemed to have a pretty explicit purpose. Let’s shine a light on this thing. Hopefully it will restore the pillars of democracy, or gird everyone, in that way.

And I think that there’s been for the most part, broadly, a kind of lost-at-sea nature. Okay, this guy won a second time. What is our function? What do we do? Does what we do have any effect? And I think there’s been this grasping, trying to find the purpose. And I think that that is something of a purpose that people can use, right?

Frum: There have been so many human beings in so many historical situations, some of them so much more terrible and dangerous than anything we face—soldiers and seemingly lost causes and metaphorical soldiers and metaphorically seemingly lost causes—who just kept going with one thought: I’m not gonna let the bastards win. And sometimes that’s all you need.

Warzel: I think that should be, that should be the new motto, right? Get rid of “Democracy dies in darkness.” “I’m not gonna let the bastards win.”

Frum: I. I. Emphasize on the I. And anyone who’s watching, you’re the I.

Yeah. One of the things I often point out, if you have one of these [David holds up his smartphone], and we all do, you have more communication power in your hand than Walter Cronkite ever commanded. So we all have to use it wisely. Think about what you share, think about what you trust, think about whom you believe, and encourage others to do the same.

And that’s why we’re also gonna encourage you to share what you do believe, which is this program, and Charlie’s, and to join us in being co-publisher because that’s what we all are. We’re all co-publishers.

Warzel: And I think, one, I have to say, when this is invoked—you have all that communication power, and one of the best things you can do both for yourself but also for others is to know when not to use it. Yes. To know when to step away from it, you know?

Frum: Charlie, thanks so much for making the time for me today and congratulations on the new show.

We’re co-publishing this. This is an interesting experiment, and may it flourish. Thank you.

Thanks so much to my Atlantic colleague Charlie Warzel for joining me this week. As I mentioned at the beginning of the show, my book of this week is a history: The Trial of Madame Caillaux. Caillaux, by the way, is spelled C-A-I-L-L-A-U-X for those unfamiliar with the peculiarities of French pronunciation. The Trial of Madame Caillaux was published in 1992. It’s written by the historian Edward Berenson. And it is the story of the most sensational sex and murder trial in pre–World War I France. So I’m going to just take you through the basics of the facts before getting on to why I thought this book was interesting and relevant now. Joseph Caillaux, the husband of Madame Caillaux, was an important politician in pre–World War I France. He was associated with the secular left in the highly complex politics of the Third Republic. At that time, the most important newspaper of the right was a paper called Figaro.

Right, in France, means pro-Catholic, pro-militarist. Left means more skeptical of militarism, more secular. Joseph Caillaux, Madame Caillaux’s husband, had led a very checkered life, many affairs with many different women. Although financially, he was quite above board, sexually, he was very public in his flamboyant personal life. Madame Caillaux was his second wife. Both the women he married were divorced women.

Figaro went on a campaign against him because of his political views, but they used his personal life. And they got hold of a cache, a group of personal letters that made it clear that Joseph Caillaux and his second wife, Henrietta Caillaux, had started their relationship while Joseph Caillaux was still married to his previous wife and while Henrietta Caillaux was still married to her previous husband. In other words, they hadn’t divorced people and then married. They had started an extramarital affair, then divorced, then remarried.

Now, this kind of thing did happen, but it was never to be spoken of, and if it were brought into the light of day, it would be a tremendously shameful thing. And Henrietta Caillaux was indeed shamed. And so one day in March of 1914, she goes to a gun shop, buys a gun, tucks it into her muff, gets in her chauffeur-driven car, goes to the offices of the editor of Le Figaro, waits for him to emerge from his appointment, meets with him, shoots him dead, gets back into a chauffeur-driven car, and drives to the police station. That’s March of 1914. In July, all of this goes on trial in a sensational, sensational case.

Now, it’s a case that involves many complex and mysterious attitudes of the time. And this is why I thought it would be interesting to talk about today. Madame Caillaux argues that what happened to her was that she, a mere woman, unable to control her emotions, was so overcome by shame and rage over the exposure of her personal life in the pages of Le Figaro, that as in a kind of mental out-of-control state, a state of total uncontrollable passion, she went to a gun store, bought a gun, drove to the office of Le Figaro, waited for an hour, and shot the editor dead and then drove in the same car to the police station. She just couldn’t control herself. And the jury bought it. The all-male jury bought it.

An all-male trial—there was almost no woman present in the courtroom. They bought it, that she was so overcome by her emotions. And so the reason this book is interesting is because, the reason that this trial was worth resurfacing in 1992 was because of what it showed about this very different mentality of a very different time. The prosecution didn’t fight the idea that if a woman were so overcome by emotion, she would be justified in shooting a man dead.

Instead, they tried to argue that she had acted in cold blood. In order to make the point that the Caillauxs were not behaving in a proper gendered male-female relationship, one of the things they pointed out was what really should have happened here, what really should have happened was Mr. Caillaux should have challenged the editor of Le Figaro to a duel and fought him instead of letting his wife do his dirty work for him. Somebody should have—no problem with killing somebody or at least attempting to kill them, but it should have been the man, not the woman, who did it.

But the woman, because she did it, she was able to fall back on this excuse that she was overcome by passion. Now, as you read this book from this distance in time—and of course, 1992 is now some distance in time as 1992 was from 1914 when all of these events happened—you’re struck by the strangeness and alienness of the mental atmosphere that is described in this trial of a world in which women were regarded as totally the playthings of their emotions, in which male honor required that this kind of private vengeance and that the sin here was not that there was private vengeance, but that the wife did it instead of the husband. And one way you can react to that is by reading the history of this bygone time and saying, Weren’t they foolish? Aren’t we wiser?

But another thing that might happen, and this is why I found the book so interesting to read at the turn of the year 2025, is that also looking back at a time where people believed things that we would regard as pretty crazy, pretty irresponsible, pretty wicked, actually—it makes you a little humble and think, What do we believe that is going to look as crazy 100 years from now? Maybe it’s not that they were dumb and we’re smarter. Oh, that’s not impossible; maybe that’s true. But maybe it’s also true: They had a set of delusions that we can see through, and we hold a set of delusions that future generations will see through. Maybe we should have more awareness of the ways in which we might be wrong and understand that it’s precisely those views of which we are most certain—because one thing that everybody in the trial agreed upon was that if you were gripped by overwhelming passion then you were entitled to kill somebody who had insulted you. They all agreed on that. They just disagreed about who should have done it, the husband or the wife.

Maybe the things we are most certain about are exactly the things where we are most likely to be led astray. We talked a little bit in our conversation today about the rabbit holes of World War II history. One of the reasons to study history is to study things other than World War II. It’s not just D-Day and Midway all the time. It’s entering into the mentalities of a time that looked pretty close to our own. Pre-1914 France, they had the telephone, they had the motor car—kind of clumsy versions of both, but they had them. They had revolvers, they had the mass press, but they also had ways of thinking that to us seemed completely strange. And how will we look to our grandchildren, and our great-grandchildren?

That’s it for this week’s and this year’s edition of The David Frum Show. Happy New Year to all who are observing the passage of time from 2025 to 2026. The show will post on December 31st, but some of you may be watching it in the 250th anniversary year of American independence. So as we discussed at the opening of the show, whatever qualms and doubts and anxieties I expressed then, I hope this is a deeply meaningful quarter-millennium event for all Americans.

Thanks so much for watching. Remember, the best way to support the work of this podcast is to subscribe to The Atlantic. That way, you support all of my colleagues, including Charlie as well. Follow us on social-media platforms: X, @DavidFrum; Instagram, @DavidFrum. And please, if you can, share and subscribe to this content. It does do the work that we talked about today of bringing something that’s more honest to the attention of more people.

That’s it for this week. That’s it for this year. See you in 2026 on The David Frum Show.

Frum: This episode of The David Frum Show was produced by Nathaniel Frum and edited by Andrea Valdez. It was engineered by Dave Grein. Our theme is by Andrew M. Edwards. Claudine Ebeid is the executive producer of Atlantic audio, and Andrea Valdez is our managing editor.</div>
        </div>
        
        <div class="card" onclick="openModal('content-19')">
            <div class="source">The Atlantic</div>
            <div class="title">Five Books About Going Out That Are Worth Staying In For</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-19" style="display:none;">
            <h2>Five Books About Going Out That Are Worth Staying In For</h2>
            <p><strong>The Atlantic | 2025-12-31</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/books/2025/12/going-out-club-reading-recommendations/685452/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">There are nights when the dance floor beckons but the bones refuse. When the urge to party arrives, it may be too late to book a babysitter. Perhaps you’re already in sweatpants, or closing time is before midnight where you live. Possibly, the prospect of going out has been raised but vetoed by a cohabitant, and you don’t want to tango alone. You could also be the kind of person who is more interested in the idea than the reality of loud, sweaty, euphoric congresses found in clubs and music venues.

Fortunately, mood-altering substances are available at home—by which, of course, I mean books. A rich literature on pleasure-oriented nightlife is available for consultation or consolation on your evening in. These five books offer a bit of vicarious sweat and thrill to get you as close to the experience as possible without demanding that you leave your couch. They also invite readers to think more expansively about what exactly draws so many people to mingle in the dark—the club’s human stakes, its sensory pleasures, and its illuminating social history. Reading a good book is not the same as riding a social high into the wee hours, but it may equip you with a sense of possibility that you can apply far beyond the coatroom. On the right night, wise women attest, a DJ can save your life.

The Haçienda: How Not to Run a Club, by Peter Hook

The Haçienda in Manchester was a catalyst of the U.K. acid house scene in the late ’80s, and a prophecy foretold: “The haçienda must be built,” the Situationist poet Ivan Chtcheglov wrote in 1953. Heeding these cryptic words some three decades later, the audacious (and well-read) impresario Tony Wilson opened the Haçienda together with the circle of post-punk musicians and designers involved with his label, Factory Records. Their attempt to decipher Chtcheglov’s mystical phrase lasted 15 years. Hook, the bassist for New Order, served as a kind of player-coach at the Haçienda, helping manage its madcap affairs while his band became the club’s cash cow. In this memoir of misbegotten business administration, Hook returns to the storied nights out that changed British culture even as they threatened to bankrupt him—and worse. Beset by gangs and guns, the Haçienda faltered in the ’90s despite clever-sounding schemes such as replacing the club’s security with the gangsters themselves. This is a scrapbook of utopian folly, yes, but also an insider’s look at what was, for a time, the wildest workplace on Earth.

Love Saves the Day: A History of American Dance Music Culture, 1970–1979, by Tim Lawrence

“Disco sucks” was the cry of philistines, if not bigots, Lawrence argues. In this meticulous but inviting cultural history of New York nightlife in the 1970s, he follows disco’s rise from underground clubs such as the Loft to the vaunted lights of Studio 54 and the FM airwaves of American suburbs. Versions of this story have been told before, but what distinguishes Love Saves the Day are the more than 300 interviews Lawrence conducted with promoters, partiers, and legendary DJs such as Frankie Knuckles. It’s full of wisdom from the elders of American club culture: how to stagger straight and gay crowds on a Friday night, how to find the next great floor-filling single, how to build a DJ set like a furnace that can burn all night. Lawrence also folds in a number of select club “discographies” so you can reproduce Jimmy Stuard’s set from 12 West, circa 1976, at home (on nice speakers, perhaps, or an iPhone placed in a cereal bowl).

Bright Lights, Big City, by Jay McInerney

Some might say McInerney’s debut novel reads a bit long in the tooth four decades after it first offered the curious public a glimpse of Manhattan-yuppie hedonism. Still, no syllabus on clubbing could be complete without the opening chapter’s rendering of the dislocation and dread that may await the partygoer “on that imperceptible pivot where two A.M. changes to six A.M.” For the nameless protagonist—a young fact-checker recently separated from his wife—a punishing club itinerary provides the opposite of community and connection. Something important is being avoided, in fact, on the dance floor and in the many crowded bathroom stalls where lines of “Bolivian Marching Powder” are hungrily apportioned. Beyond its glitz and sleaze, Bright Lights is a sobering lesson on why partying does not always soothe a troubled soul.

Legendary: Inside the House Ballroom Scene, by Gerard H. Gaskin

One of the older photographs in Gaskin’s book, from 1998, finds an impeccably suited ballroom performer strutting the boards of what appears to be a community-center gymnasium. Scanning from head to toe, the viewer sees a banded fedora, cigar, jacket and trousers, and, finally, holding it all up (easily missed at first glance): vertiginously high stilettos. It’s an image of heroic poise, accentuated by the look of enchantment on the faces of a trio of young men watching from folding chairs. Gaskin has long enjoyed a reputation as the “Trinidadian Andy Warhol” of the ballroom scene in New York City, writes the scholar Frank Roberts, a subject of Gaskin’s; for those who performed in that world between the mid-1990s and the early 2010s, when these photos were taken, appearing in a Gaskin portrait was a “rite of passage.” His pictures illustrate the drama and grandeur of these events, but they also convey the importance of the club as a place where dignity—elsewhere denied—may be claimed without apology, and freedom can be realized for the length of the catwalk.

Read: The coronavirus is testing queer culture

Wark’s sprawling intelligence is a pleasure to access on any subject. In Raving, Wark blends autofiction and theory to chaperone the reader through the trans rave scene in New York City—or at least the scene as she found it in the years before and after 2020. “First thing I look for at raves: who needs it,” she writes of these parties, “and among those who need it, who can handle their habit?” Vividly told, Raving is no gawking ethnography; it’s a sticky and tender little book with serious ethical contemplation at its center. Wark is attentive to the essence of raving as a Black art form and its special significance for queer people, but she approaches it as an activity open to anyone who can handle it—not a way of life so much as a way of creating new lives together.

​When you buy a book using a link on this page, we receive a commission. Thank you for supporting The Atlantic.</div>
        </div>
        
        <div class="card" onclick="openModal('content-20')">
            <div class="source">The Atlantic</div>
            <div class="title">The Holiday Traditions of a Nation Long Dead</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-20" style="display:none;">
            <h2>The Holiday Traditions of a Nation Long Dead</h2>
            <p><strong>The Atlantic | 2025-12-31</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/family/2025/12/soviet-union-new-year-tradition/685439/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Every year in late December, my childhood home transformed into a vision of American bliss. We’d gather to ornament a tree, drape string lights around the house, and sit down to an elaborate feast. Not long after dawn the next day, while our little sister still slept, my brother and I would impatiently sneak downstairs to see our gifts, which we understood to have been delivered by a kindly old man. It could have been a scene out of A Christmas Story. Except we weren’t celebrating Christmas. My family was celebrating the Soviet version of New Year’s, a holiday that resembles Christmas in nearly every way, except that it takes place almost a week later and excludes Jesus, God, or any other signifier of religion. We were keeping the national tradition alive in suburban America, years after the country that invented it had dissolved.

Soviet New Year’s began as a ritual in a country where all the religious rituals were gone. Long before the 1917 revolution that brought them to power, the leaders of the Soviet Union had decried religion as, in Karl Marx’s phrase, the opium of the masses. Their officially atheist government suppressed many kinds of spiritual observance, including Christmas. But by the mid-1930s, Soviet leaders sensed that people needed something to take the edge off in the dead of winter, a carnivalesque custom of the sort that Christmas once provided. So they took the most fun parts of the Christian holiday and plopped them on New Year’s.

It became arguably the most important holiday on the country’s calendar. Other celebrations tended to come with historical significance, such as the anniversary of the revolution and of the Soviets’ victory in World War II. But New Year’s, at its core, was about nothing more and nothing less than family: a chance to come together and take stock. That may be a big reason it survived the Union’s dissolution. Even after religious institutions were allowed to conduct their services without government interference and their holidays were acknowledged, New Year’s remained important for both the people who had left the region and those who still lived there.

But today, Soviet New Year’s customs are in danger of slipping away or evolving beyond recognition. Some people still celebrate the holiday the old way, with their families and gifts. Many, though, are establishing new practices that reflect new values and new political circumstances: Wars between former Soviet republics, for instance, and the ways that political leaders have used the momentous nature of the night for their own gains, have changed how people celebrate. A holiday that once felt embedded in the identity and culture of the Soviet people may soon become untethered from its history.

Soviet New Year’s began at a time when morale in the country was, in general, low. It was the 1930s, and Ukraine had suffered one of the worst man-made famines in world history. The idea to bring joy to the winter came from a Communist Party leader named Pavel Postyshev, who had been one of the famine’s administrators. During an intimate car ride around Moscow with General Secretary Joseph Stalin and a future successor, Nikita Khrushchev, Postyshev proposed reviving the tradition of trees, but tied to a secular holiday. Stalin enthusiastically endorsed the idea, and in 1935, a letter from Postyshev appeared in Pravda, the official newspaper of the party’s central committee, arguing that all Soviet children should get to experience the cheer that the bourgeoisie’s children once had: “Let’s organize a fun New Year’s Eve party for the kids.”

Postyshev’s idea spread like a wildfire in reverse—trees sprang up across the Soviet Union. The first year, delegates from the local party leadership and schoolteachers gathered parents and instructed them in how to decorate a tree. In some schools, Grandfather Frost, a Santa Claus equivalent, distributed gifts to kids. Soon, families adopted the new practice as their own. But Postyshev never got to see the extent of it. In the ’30s, Stalin consolidated power, punishing anyone he suspected of opposing him, including Postyshev—who was executed in 1939. The holiday soon became another tool for Stalin to reinforce his power and centrality in Soviet life. “The cheerful, happy children sang, danced, recited poems, praising in the songs and poems of their beloved Stalin, who gave them a joyful and happy life,” one 1938 newspaper report read.

After Stalin died, in 1953, the holiday’s focus turned away from politics. In 1956, Khrushchev delivered a speech criticizing Stalin’s “cult of personality” and his purges, signaling to people that they could drop the anxieties about political correctness that had constricted their lives in the Stalin era. The film Carnival Night, released that same year, captured the iconoclastic mood. In it, workers resist the efforts of their company director to organize a New Year’s celebration in which everything is acceptable to the people above him and no fun for those below. He plans to deliver a speech, but a worker persuades a magician to make the text disappear; when the director later goes to grab it, he instead finds a string of scarves and other knickknacks. The company director, representing a self-aggrandizing political blowhard, is humiliatingly sidelined, and the workers have a grand time.

By the time my dad started celebrating New Year’s in Moscow, in the ’60s, most of the elements of the holiday I would come to know as a kid were present: family dinner, gifts, and a decorated tree. It had become an unquestioned fulcrum of Soviet life. If there was a custom of reading poems or singing songs in Khrushchev’s honor, it wasn’t ubiquitous. Once the country’s leaders began giving an annual New Year’s address, in 1970, these speeches weren’t taken seriously. They were filled with empty platitudes, “void of meaning,” according to The Invention of Russia, by the journalist Arkady Ostrovsky. “These addresses were merely a prompt for popping the corks from bottles.”

That cork-popping continued even as the Soviet Union dissolved and many people left the region. I was born in Moscow in 1996, five years after the fall of the Union, and we moved to upstate New York five years after that. For a long time, the New Year’s my family celebrated was stuck in amber, the old tree-and-gifts version. In the former Soviet republics, people still considered the day significant but changed some of the customs. In Armenia, for instance, once religious holidays were again allowed, religious institutions attached themselves to New Year’s. From the early 1990s until 2023, the head of the national Church would deliver a midnight address right before the country’s president or prime minister. Tigran Simyan, a professor at Yerevan State University who studies the evolution of New Year’s in Armenia and the post-Soviet world, told me, “Our happy New Year, for us, is more important than Christmas.”

Politics also returned to the holiday after the Soviet Union’s fall. In Russia, the seeming end of single-party rule and a brief moment of political competition revived the status of the New Year’s address. It was a rare time when all eyes were focused on the same speaker. The Russian Federation’s first president, Boris Yeltsin, strategically resigned on December 31, 1999, giving his handpicked successor, Vladimir Putin, the opportunity to introduce himself during a midnight address as the millennium turned. “The ritual was unmistakably staged,” Ostrovsky writes in The Invention of Russia. “The New Year’s address had greater symbolic value than any election.”

In more recent times, young Russians have tended to focus on partying on New Year’s Eve. But the many people who maintain the Soviet way of celebrating at home with family might still put on Putin’s address. Once again, a popular film captures the mood. The plot of 2010’s Yolki is almost the exact opposite of Carnival Night’s. Whereas the 1956 film is about a collaborative effort to prevent a speech, Yolki features people across the country working together to help a girl on her quixotic quest to insert a phrase into the president’s midnight address, granting the address central importance. Yolki was the first in what became Russia’s most financially successful non-animated film franchise, despite the series’ declining artistic and entertainment value. Its 12th sequel, set as ever on New Year’s Eve, came out this December.

Eventually, politics’ creep back into the New Year’s holiday began to affect the way my family celebrated in the United States. Although for years, none of us took what Putin said in his address too seriously, my grandparents still put it on out of habit. But as his regime grew more repressive and violent, we let that go. The way I remember it, we stopped after Russia’s initial invasion of Ukraine, in 2014, deciding that we didn’t need to support Putin’s rule on our holiday. But my dad dates our move away from the midnight address to earlier, in 2012. That year, Putin stepped through a loophole in constitutional term limits and returned to the presidency, then brutally suppressed the protests that followed. “I didn’t want to hear him anymore,” my dad told me recently.

After Russia’s full-scale invasion of Ukraine, in February 2022, some Ukrainians’ New Year’s celebrations stopped. “What is there to celebrate when there is a war?” a Ukrainian soldier serving on the front line asked Euronews last New Year’s. Meanwhile, I spent last New Year’s in Tbilisi, the capital of Georgia, where clubs had just been closed for weeks in deference to protests over the government pausing its European Union accession bid. Though some young people I talked with were spending the night with their family, many spilled out onto Rustaveli Avenue in the city center for a combination party, protest, and celebration. Without a single state to hold it together, and so many interstate conflicts, the Soviet New Year’s tradition is splintering across the Soviet diaspora.

Read: What I learned from the Georgia protests

Perhaps soon the holiday will become unrecognizable from its former iteration, especially as the people who remember its origins adapt to new cultures or pass away. My own family no longer makes a point of gathering on the holiday. In part, that’s because my siblings and I have gotten older, scattered, and given in to assimilationist pressure—the fear of missing out on the American custom of partying with our friends on New Year’s. But we’ve also lost the center of gravity that held us to the Soviet tradition. Early in November, my last surviving grandmother suffered a stroke, which paralyzed most of her body, leaving only her eyes and one arm fully mobile. Her grandfather, my great-great-grandfather, became a Bolshevik in 1905 and participated in the three revolutions that led to the establishment of the Soviet Union. His son, her father, wrote and disseminated anti-religious propaganda. Much of my family’s adherence to the holiday might very well be because of this history. On Thanksgiving, days before my grandmother died, I told her I was researching our holiday tradition. She squeezed my hand and blinked knowingly.

Watching the tradition slip away feels like losing part of the Soviet and post-Soviet identity that’s defined my family for more than a century. I feel a grief that’s hard to disentangle from my grief for the people who passed the tradition on to me. But looking back on how my family has acted in decisive moments, I’m also aware of an opportunity. My forefathers helped form the Soviet identity and its rituals, even before there was a country to promote them. Likewise, during and after the Soviet Union’s existence, although politicians repeatedly imposed a tone that fit their priorities, my family chose how to spend the day. Ultimately, the common people reshaped the holiday to suit their needs and values. Their examples prove that people can make their own traditions, with whatever ideals they inherit.

​​When you buy a book using a link on this page, we receive a commission. Thank you for supporting The Atlantic.</div>
        </div>
        
        <div class="card" onclick="openModal('content-21')">
            <div class="source">The Atlantic</div>
            <div class="title">The MetroCard Never Got Its Due</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-21" style="display:none;">
            <h2>The MetroCard Never Got Its Due</h2>
            <p><strong>The Atlantic | 2025-12-31</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/technology/2025/12/metrocard-farewell-new-york-subway/685276/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">On a chilly December morning, I descended a flight of stairs and entered the New York Transit Museum. Housed in a decommissioned subway station in downtown Brooklyn, the museum was packed with elementary-school children on a field trip. All around me, tour guides shepherded groups of them through the various exhibits. Later on, I heard one guide ask if any of the students knew how to pay for the subway. “You tap a phone,” a child volunteered.

For decades, the default answer has been something else: You swipe a MetroCard. Something like a flimsy yellow credit card, the MetroCard has bound together nearly everyone in the city—real-estate moguls and tenants, Mets and Yankees fans, lifelong New Yorkers like myself and new arrivals from Ohio. Any tourist who visited New York inevitably got one. But now the MetroCard era is about to end. Today is the last day you can purchase a card.

The Metropolitan Transportation Authority, the organization that operates the city’s public-transit system, has for years been phasing out the MetroCard in favor of contactless payment—tapping your phone or a credit card, much as you would at any store. The new system, known as OMNY (“One Metro New York”), will bring together the benefits of technological progress: tens of millions of dollars in savings for both riders and the MTA each year, shorter lines, less plastic waste. Many other large metro systems have already fully transitioned to tap-and-go; in this sense, New York is behind the times.

In 2025, swiping a plastic rectangle through a card reader feels like an anachronism, but the MetroCard shouldn’t be taken for granted. Every little yellow plastic rectangle represents a genuine technological marvel.

At first, the MetroCard was a flop. The system was designed to be a technological leap forward: No longer would New Yorkers have to lug around physical tokens to pay for subways and buses. MetroCards would not only be lighter, but allow users to transfer between trains and buses without having to pay a second time. Despite the obvious upside, convincing people to embrace the swipe was not easy. When the MetroCard debuted, in 1994, “everybody was like, ‘I don’t want to give up my tokens. You’ll get my tokens out of my cold dead hands,’” Jodi Shapiro, the Transit Museum’s curator, told me. People lined up to buy as many tokens as possible before sales ended so they could put off converting to the MetroCard for as long as possible. Television segments reassured New Yorkers that “they could get to work by using plastic.” The MTA put out ads and flyers explaining how to use the card, and briefly considered having someone dressed as an aardvark (the “Cardvaark”) go to Times Square and educate passersby about the MetroCard.

Despite a rough start, the MetroCard swipe eventually just became routine. Knowing how to swipe a MetroCard—the crook of your elbow, the gentle flick of your wrist as you glide the magnetic stripe through the card reader—is essential New York knowledge. To create the infrastructure for this system, “all of this technology had to be upgraded,” Shapiro said. “And some of it had to be invented.” The MTA needed not just physical cards, but also a way to read them, vending machines to sell them, and a central computer system to track each one and process every transaction. Even the “swipe” mechanism, faster and easier to maintain than fare cards in other American cities at the time, was bespoke—designed specifically for New York City public transit’s sprawl and enormous ridership.

Last month, I visited the facility in Queens that mints the city’s MetroCards to see this logistical feat for myself. Known as the Fortress Revenue Collection Lab, the building does look startlingly like a fortress—with barbed wire, barred windows, brick walls, and a central tower. Before the trip, the MTA made me agree not to disclose the precise location, and when I arrived, Michael Ellinas, the MTA’s senior vice president of revenue control, led me through an entrance monitored by security guards. All of these measures safeguard the millions of MetroCards processed and stored inside the facility, many of them already loaded with money—just 1,000 monthly passes would be worth $132,000.

The Revenue Fortress Collection Lab doesn’t make MetroCards from scratch. The plastic yellow cards are first manufactured in North Carolina and the United Kingdom before they are shipped, some 10,000 per box, to Queens, where they are turned into usable MetroCards. Employees load decks of blank cards onto conveyor belts that assign each a serial number and encode its magnetic stripe with value: monthly passes, single-ride cards, and so on, or zero dollars if the MetroCard is intended for someone to purchase from one of the vending machines throughout the MTA system. There are roughly 100 types of MetroCards, and the encoding process is what “puts the secret sauce on the magnetic stripe,” Ellinas told me. The room is kept between 35 and 55 percent humidity: Too muggy and the cards might stick together, too dry and they might develop static.

Read: A great idea for what to do with the pennies left on your MetroCard

Some of the MetroCards are then brought to another conveyor belt and wrapped in plastic for individual retail at pharmacies and gas stations. Modified from machines used by Planters factories to wrap peanuts, this contraption envelops 5,000 MetroCards every hour—or more than one every second. Sunillall Harbajan, an MTA employee overseeing the room’s operations, told me he has a nickname for the machine: “The Beast.”

At its peak, the fortress was pumping out 180 million MetroCards every year; some 3.2 billion have been prepared in total. By the time I visited the fortress, just about 10 percent of riders were still using MetroCards, and the facility was no longer making them every day. Ellinas had timed the run so that I could witness it. “All good things come to an end, but I’m happy to have been part of it,” Karen Kunak, the MTA’s chief officer of processing operations, told me from inside the fortress, surrounded by boxes of MetroCards. She started at the MTA as a college intern 36 years ago—before the MetroCard was even around: “We made it into a thing, its own living, breathing thing.” Employees operating the MetroCard machines are being retrained to work elsewhere across the MTA.

If the city had never adopted the MetroCard—had not installed electronic turnstiles systemwide, developed a complex computer system, gotten people used to paying with a card at all—OMNY would have been a far more gargantuan effort. The switch from paying with one sort of card to another is far less jarring than going from coins to a piece of plastic. “If all of the technological things had not been done to make MetroCard a viable fair-payment system,” Shapiro said, “we wouldn’t have OMNY now.” Eventually, the fortress will be reconfigured into an OMNY facility, just as MetroCard vending machines in subway stations have been replaced by OMNY vending machines. (Those who don’t want to use a phone or credit card or don’t have one can instead purchase an OMNY card.)

In saying goodbye to the MetroCard, New York City is saving time, money, and waste. But the city is also losing a bit of friction, and a common denominator, that is central to its character. New Yorkers and tourists lined up to buy special MetroCards designed in collaboration with local legends and institutions—Biggie Smalls, David Bowie, the library—that are now collectors’ items. Before long, even the basic MetroCards might be coveted as well. There will never be a card to celebrate a World Series victory for my beloved New York Mets. The leap into modernity can feel like sliding into a featureless void, in which every transaction of any sort becomes hard to distinguish. Paying to ride the subway is now like paying for a coffee at Starbucks.

Or perhaps it is just me; the MetroCard is all I’ve ever really known. My friends and I used to protect our student MetroCards, which allowed us to ride for free, like amulets, our keys to the city. As I walked through the Transit Museum with Shapiro, she and an MTA spokesperson accompanying us poked fun at visitors who didn’t remember the subway token. I remained quiet, not wanting to out myself.</div>
        </div>
        
        <div class="card" onclick="openModal('content-22')">
            <div class="source">The Atlantic</div>
            <div class="title">31 <em>Atlantic</em> Stories You Might Have Missed</div>
            <div class="meta">2025-12-30</div>
        </div>
        
        <div id="content-22" style="display:none;">
            <h2>31 <em>Atlantic</em> Stories You Might Have Missed</h2>
            <p><strong>The Atlantic | 2025-12-30</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/newsletters/2025/12/atlantic-stories-you-might-have-missed/685440/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">In case you’re settling into winter and lamenting not having read everything The Atlantic has published this year, you’re in luck. I’ve created a list of stories you may have missed that are very much worth your time. The assortment ranges widely: eating an organ feast in Mark Twain’s Paris, experiencing a comedy-show adventure in Riyadh, drifting after a shipwreck in the Pacific, and diving into the secrets of the Inca empire. “What Parents of Boys Should Know” sparked many conversations in my group chats, as did this photo of Abraham Lincoln’s ear being cleaned. There are stories that contextualized a chaotic moment for the American experiment, drawing deeply on history.

I hope you’ll spend time with this selection, and I would love to hear what you think. Send me a note: [email protected].

What the surreal Riyadh Comedy Festival foretold about the kingdom’s future

Anti-science mysticism is enabling autocracy around the globe.

America and Its Universities Need a New Social Contract

Fifty dollars for STEM, five cents for citizenship—that’s how America apportions its education dollars. Our beleaguered universities must redress the balance—helping the country and themselves.

Daughters tend to receive higher levels of affection and patience at home than sons. But the sons might need it more.

Is This the Worst-Ever Era of American Pop Culture?

An emerging critical consensus argues that we’ve entered a cultural dark age. I’m not so sure.

On my first time out as a commercial fisherman, my boat sank, my captain died, and I was left adrift and alone in the Pacific.

My quest for a true literary experience resulted in choucroute, a surprise organ feast, an epiphany at the Louvre, existential dread, and a rowboat.

A PTSD Therapy “Seemed Too Good to Be True”

What if overcoming trauma can be painless?

They might be surprised that the republic exists at all.

The science of habits reveals that they can be hidden to us and unresponsive to our desires.

A partisan loyalist with a history of politicizing intelligence will soon be running the CIA.

The Man in the Midnight-Blue Six-Ply Italian-Milled Wool Suit

A perfect suit, made by an expert tailor out of superlative fabric, would do nothing less than transform me.

This isn’t single-party rule, but it’s not democracy either.

A profane blogger believes an innocent woman is being framed for murder. He’ll do anything to prove he’s right—and terrorize anyone who says he’s wrong.

The Rise of the Brown v. Board of Education Skeptics

Why some mainstream Black intellectuals are giving up on the landmark decision

How Aella went from selling sex to studying it

The People Who Clean the Ears of Lincoln (And Other Statues)

A collection of images of the varied workers and techniques used to maintain some of the world’s largest and most prominent statues and monuments.

America’s colleges have an extra-time-on-tests problem.

Do You Actually Know What Classical Music Is? Does Anyone?

The term is applied to radically different compositions across more than 1,000 years of history. We need a better definition.

What having a baby taught me about the illusion of control

The Short-Circuiting of the American Mind

A century-old book foresaw Trump’s most basic strategy.

When William F. Buckley Jr. Met James Baldwin

In 1965, the two intellectual giants squared off in a debate at Cambridge. It didn’t go quite as Buckley hoped.

A Grand Experiment in Parenthood and Friendship

Would you raise kids with your best pals?

Unraveling the Secrets of the Inca Empire

For hundreds of years, Andean people recorded information by tying knots into long cords. Will we ever be able to read them?

Inside the world of extreme-privacy consultants, who, for the right fee, will make you and your personal information very hard to find

The Wyoming Hospital Upending the Logic of Private Equity

Instead of cutting services to cut costs, one rural hospital plans to thrive by offering more.

A radical legal philosophy has undermined the process of constitutional evolution.

He was denounced by rebel propagandists as a tyrant and remembered by Americans as a reactionary dolt. Who was he really?

Its trappings remain, but authoritarianism and AI are hollowing out our humanity.

Many birth mothers hope to maintain contact with their child. But their agreements with adoptive parents can be fragile.

New Year’s Resolutions That Will Actually Lead to Happiness

If you are someone who follows a traditional religion, you most likely have a day such as Yom Kippur, Ashura, or Ash Wednesday, dedicated to atoning for your sins and vowing to make improvements to your life. But if you are not religious, you might still practice a day of devotion and ritualistic vows of self-improvement each year on January 1. New Year’s Day rings in the month of January, dedicated by the ancient Romans to their god Janus. Religious Romans promised the two-faced god that they would be better in the new year than they had been in the past.

According to the Pew Research Center, historically between one-third and one-half of Americans observe this pagan rite every year by making their own New Year’s resolutions. The most common resolutions are fairly predictable: financial resolutions, like saving more money or paying down debt (51 percent in 2019); eating healthier (51 percent); exercising more (50 percent); and losing weight (42 percent).

Old Janus is pretty annoyed at this point, I imagine, because our resolutions overwhelmingly fail.

Watch. Here are the 10 best movies of 2025, according to our critic David Sims.

Explore. What’s the point of school photos anymore? The portraits are kitschy and expensive—but parents can’t seem to stop buying them, Annie Midori Atherton writes.

Rafaela Jinich contributed to this newsletter.

When you buy a book using a link in this newsletter, we receive a commission. Thank you for supporting The Atlantic.</div>
        </div>
        
        <div class="card" onclick="openModal('content-23')">
            <div class="source">The Atlantic</div>
            <div class="title">Britain Should Have Read the Tweets First</div>
            <div class="meta">2025-12-30</div>
        </div>
        
        <div id="content-23" style="display:none;">
            <h2>Britain Should Have Read the Tweets First</h2>
            <p><strong>The Atlantic | 2025-12-30</strong></p>
            <a class="original-link" href="https://www.theatlantic.com/ideas/2025/12/starmer-abd-el-fattah/685469/?utm_source=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">How much effort should a country expend to rescue someone who appears to hate its values? That is the question posed by the case of Alaa Abd el-Fattah.

Abd el-Fattah is an Egyptian pro-democracy campaigner who has been in and out of prison since 2006 for opposing the regimes of Hosni Mubarak and Abdel Fattah el-Sisi, and for drawing attention to torture and other abuses. In 2021, he was granted British citizenship through a somewhat tenuous connection—his mother, Laila, had been born in London while her mother was studying in the United Kingdom—which gave the British government greater standing to lobby Cairo on his behalf. It pressed his case under three Conservative prime ministers (Boris Johnson, Liz Truss and Rishi Sunak) and, since June 2024, under Labour’s Keir Starmer. Six months ago, a government minister said that the case had been “a top priority every week that I have been in office.”

Last week, those efforts finally paid off. Egypt lifted a travel ban on Abd el-Fattah, who had been released from jail in September, and Starmer declared that he was “delighted” that Abd el-Fattah was “back in the UK and has been reunited with his loved ones.”

That delight was short-lived. Within hours, Abd el-Fattah’s tweets from the time of the Arab Spring, when he was around 30, resurfaced on X. In these, he reportedly wished violence on “all Zionists, including civilians”—read: Jews. He also called for the murder of police officers, and sarcastically described his dislike of white people. In a 2010 discussion of the death of one of the terrorists who had tortured and killed Israeli athletes at the 1972 Munich Olympics, he declared, “My heroes have always killed colonialists.”

The populist insurgent Nigel Farage could not have scripted a better attack ad against Britain’s two established parties. At best, both Labour and the Conservatives have spent political capital on an activist who has repeatedly expressed thoughtless and hateful views in public. At worst, the government has invited in a provocateur who will continue to spread poison and incite violence. “It is unclear to me why it has been a priority for successive governments to bring this guy over here,” the rank-and-file Labour politician Tom Rutland wrote on X, adding, “His tweets are impressive in how they manage to be vile in such a variety of ways.”

In a statement of apology, Abd el-Fattah suggested that his statements were in keeping with the prevailing ethos of early-2010s Twitter—which was full of performative, deliberately offensive left-wing posturing. His posts, he said, were the “writings of a much younger person, deeply enmeshed in antagonistic online cultures, utilising flippant, shocking and sarcastic tones in the nascent, febrile world of social media.” In his offline activism, Abd el-Fattah maintained, he was known for “publicly rejecting anti-Jewish speech in Egypt, often at risk to myself, defence of LGBTQ rights, defence of Egyptian Christians, and campaigning against police torture and brutality.” However, Abd el-Fattah also questioned why the tweets had been “republished” now with their meanings “twisted.” On Facebook, he appears to have liked a comment suggesting that it was—you guessed it—a “campaign launched by the Zionists.”

The situation is deeply embarrassing for Starmer, who welcomed Abd el-Fattah’s arrival in Britain so warmly. He now claims not to have known about the “absolutely abhorrent” tweets and is promising to “review the information failures in this case.” Apparently, despite years of campaigning for this guy, the combined might of the British civil service never thought to search his Twitter handle. If the authorities had conducted even a cursory background check, they would have found opinions such as this (now-deleted) assertion from 2012: “I’m a racist, I don’t like white people so piss off.”

Nor did civil servants enter Abd el-Fattah’s name into a search engine, which would have revealed the 2014 reports on his controversial nomination for a free-speech prize. One of these, headlined “A Dissident for Hate,” observed that “Mr. Abdel Fattah may have been brave in confronting authoritarianism in his own country. But his rhetoric on Israel and moderate Arabs is another story.”

The British right is now arguing that Abd el-Fattah and his celebrity supporters—including Naomi Klein, Olivia Colman, and Mark Ruffalo—have made the British government look foolish. Why is Starmer loudly welcoming “back” a man who has never before spent a significant amount of time in Britain, who abhors its geopolitical alliances, and who apparently dislikes the majority of its population? Farage, the leader of the right-wing Reform Party, has unsurprisingly called for Abd el-Fattah to be stripped of his British citizenship. So has Kemi Badenoch, the current leader of the Conservatives—the party in charge when Abd el-Fattah was awarded that citizenship in the first place.

Idrees Kahloon: Political parties have disconnected from the public

Former Conservative Prime Minister Liz Truss, who has lately joined the podcast circuit, wrote on X that Abd el-Fattah’s case shows that “the human-rights/NGO industrial complex has completely captured the British state.” This is the same Liz Truss who, as foreign secretary in 2022, assured Parliament that she was “working very hard to secure his release.” Was she then unaware of his tweets? Or was she then posturing as a policy maker, whereas now she is trying to make a living as a YouTuber? (Yes, she is Dan Bongino in reverse.) The Conservatives’ shadow justice secretary, Robert Jenrick, has also piled on Abd el-Fattah’s story, condemning the celebrities who campaigned for his release as “useful idiots.” Jenrick covets Badenoch’s job—and his plan to win it relies on outflanking her on crime and immigration.

Liberals and conservatives have politicized this story. Starmer—and the previous incarnation of Truss—treated Abd el-Fattah as a kind of mascot, a living totem of Britain’s enlightened attitudes toward political dissent in comparison with those of Middle Eastern dictatorships. Today’s version of Truss, and the rest of the populist right, are now holding him up as Exhibit A in their argument that the West needs to be tougher on Muslim immigration to Europe.

As ever, the challenge is to look beyond this ideological point-scoring and consider the case on its own merits. I was deeply unimpressed that one of Abd el-Fattah’s first public statements after his longed-for deliverance was to repost a complaint that Starmer had not publicly condemned Sisi’s dictatorship while announcing his release. Welcome to the grubby reality of international diplomacy! But if I had missed many of my child’s birthdays in detention, I might also find it hard to be gracious.

Still, British Jews have every right to question their state’s extraordinary efforts to free someone who has called for violence against them and who has recanted only in the vaguest terms. The Jewish community is under threat here: The aftermath of October 7 and the war in Gaza have led to more visible anti-Semitism in Britain, in many cases from self-declared Islamists. On Yom Kippur, a militant Islamist called Jihad Al-Shamie (in retrospect, the first name was a clue) killed one person and injured others in a stabbing attack on a synagogue in Manchester. Earlier this month, two men were convicted of plotting what authorities described as an “ISIS-inspired” atrocity in the same city. “Here in Manchester, we have the biggest Jewish community,” one of the plotters told an undercover police officer whom he believed to be a co-conspirator. “God willing we will degrade and humiliate them (in the worst way possible), and hit them where it hurts.” Social media is one of the key drivers and reinforcers of anti-Semitic extremism; tweets like Abd el-Fattah’s are not just harmless letting-off of steam.

Still, if he repeats such sentiments now that he lives in Britain, Abd el-Fattah could be subject to prosecution for incitement to violence, or hate speech. The British state has pursued people for less: See the recent prosecution against the gender-critical campaigner Graham Linehan—the case was eventually dropped—or the conviction of a woman named Lucy Connolly for posting that hotels housing asylum-seekers should be set on fire.

Taking away Abd el-Fattah’s British passport is another matter. Once granted, citizenship is citizenship, no matter how stupid or evil or thoughtless its holder turns out to be. I don’t want to live in a country where naturalized or joint citizens are treated as second-class Britons, forever on probation. Now that he has a UK passport, Alaa Abd el-Fattah is entitled to the protection of the British state, just like Liz Truss—or like Kemi Badenoch, for that matter, whose British citizenship rests on the coincidence of her Nigerian mother having given birth to her in London.

Yet you can take an inclusive view of British citizenship and still believe that people should be vetted before receiving it. Starmer’s post gushing about Abd el-Fattah’s arrival was catastrophically ill-judged, both in his assessment of this particular case and as a representation of his wider governing philosophy. Starmer, a former human-rights lawyer, approaches every problem with an arid obsession with process rather than outcome—as if, when people follow every dot and comma of the rules, nothing bad can happen and no one should complain.

The Abd el-Fattah decision follows this pattern. Starmer celebrated the bureaucratic machinations of this case—granting automatic citizenship by descent and then securing the end of Abd el-Fattah’s travel ban—without enough attention to the politics. Yes, he was failed by his officials and their lack of briefing. But he also suffered a personal failure of imagination: Is it such a stretch to ask whether a Middle Eastern activist raised among members of the Egyptian communist intelligentsia has any worrisome opinions on Israel or Jews? Part of Starmer’s pitch to succeed Jeremy Corbyn as leader of Labour was that his predecessor had turned a blind eye to anti-Semitism. (He eventually kicked Corbyn out of the party altogether for this offense.) But in the past two years, he has struggled to identify and police the line between legitimate criticism of the Israeli government and wider animus against Jews, often camouflaged as attacks on “Zionists.”

At the same time, populists on the right have begun to insist, in more and more explicit terms, that Muslims cannot be integrated into Europe because their values are too different—the grooming-gangs scandal is offered as evidence here—and because they feel more loyalty to the ummah than to the countries to which they have immigrated. That view ignores the many followers of moderate Islam, such as London Mayor Sadiq Khan, who have found no contradiction between their faith and Western liberalism. But the views of Abd el-Fattah punch that bruise.

Another case like this may not arrive again—not least because Britain’s current appetite for enforcing its values abroad is low. In June, Starmer cut the foreign-aid budget, and some of what remains is spent domestically anyway, on housing asylum seekers. Starmer’s home secretary, Shabana Mahmood—herself a British Muslim—has announced a drastic tightening of eligibility requirements for citizenship.

Starmer—and his Conservative predecessors—were right to call for Abd el-Fattah’s release. What was absurd, however, was to frame his arrival on British soil as an unalloyed blessing. Starmer was thinking like the procedure-obsessed human-rights lawyer he used to be, not the political and moral leader that Britain needs right now.</div>
        </div>
        
        <div class="card" onclick="openModal('content-24')">
            <div class="source">Slashdot</div>
            <div class="title">France Targets Australia-Style Social Media Ban For Children Next Year</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-24" style="display:none;">
            <h2>France Targets Australia-Style Social Media Ban For Children Next Year</h2>
            <p><strong>Slashdot | 2025-12-31</strong></p>
            <a class="original-link" href="https://tech.slashdot.org/story/25/12/31/1954246/france-targets-australia-style-social-media-ban-for-children-next-year?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Want to read Slashdot from your mobile device? Point it at m.slashdot.org and keep reading!

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.</div>
        </div>
        
        <div class="card" onclick="openModal('content-25')">
            <div class="source">Slashdot</div>
            <div class="title">NJ's Answer To Flooding: It Has Bought Out and Demolished 1,200 Properties</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-25" style="display:none;">
            <h2>NJ's Answer To Flooding: It Has Bought Out and Demolished 1,200 Properties</h2>
            <p><strong>Slashdot | 2025-12-31</strong></p>
            <a class="original-link" href="https://news.slashdot.org/story/25/12/31/1834240/njs-answer-to-flooding-it-has-bought-out-and-demolished-1200-properties?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Those of us who were smart enough to *not* buy a house that was built a few inches above sea level get to foot the bill.

You sound like the people in my /r/southjersey subreddit lol. My hometown is one of the most at risk towns of sinking into the water in the state. It&#39;s already an island (in southwest nj no less) and most of the land is preserved already. The buying up of the land and marshes really helps protect the land, animals, and people. Boohoo, taxes. Without paying them, you&#39;d be living in a cesspool like Mississippi.

Those taxes should have been used to enforce building codes that say you don&#39;t build houses in a flood zone.

&quot;But we didn&#39;t know sea levels were going to rise!!!&quot;

Bullshit. Al Gore warned you about this 25 years ago. Edward Teller warned you about this almost 70 years ago.

The other option is for them to get on the Federal last resort flood insurance program and have the Federal Government pay to rebuild the houses - multiple times as they flood multiple times.

Frankly, this should be a legal requirement - any last resort flood insurance program should have the right to buy the property  outright at a fair price instead of accepting insurance on the place OR after a flood does more than 40% damage to the property.

Demolished 1200 properties in New Jersey.Well, it&#39;s a start.

Demolished 1200 properties in New Jersey.

Government buy-outs of chronically flooding neighborhoods are nothing [eli.org] new [eli.org].

The more land we preserve along the waterways, the better. NJ is an OLD state, which was founded by people going up the waterways and working their way inward. Over time, we have learned that we need to give the rivers, marshes, and estuaries space to do their thang. If it means paying a little more in taxes, so be it. Money is not more important than the well-being of the planet.

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.</div>
        </div>
        
        <div class="card" onclick="openModal('content-26')">
            <div class="source">Slashdot</div>
            <div class="title">NASA Craft To Face Heat-Shield Test on Its First Astronaut Flight Next Year</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-26" style="display:none;">
            <h2>NASA Craft To Face Heat-Shield Test on Its First Astronaut Flight Next Year</h2>
            <p><strong>Slashdot | 2025-12-31</strong></p>
            <a class="original-link" href="https://science.slashdot.org/story/25/12/31/1826246/nasa-craft-to-face-heat-shield-test-on-its-first-astronaut-flight-next-year?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Follow Slashdot blog updates by subscribing to our blog RSS feed

The (un)stated purpose of this exercise is to show the Chinese we can get back to the moon before even having our morning coffee.

In that light, I can understand the casual nature of this stuff. On the other hand...space flight *is* cool, and I might like a little more hype for something that at its heart is about hype.

Correct me if I&#39;m wrong, but didn&#39;t we used to demand  an unmanned mission that was successful from end to end before we put people on the vehicle?

Indeed. TFA said during the last unmanned test the heat shield had problems. They should have a near perfect unmanned test before testing with staff.

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.</div>
        </div>
        
        <div class="card" onclick="openModal('content-27')">
            <div class="source">Slashdot</div>
            <div class="title">JPMorgan Says Javice Firms Billed Millions Just for 'Attendance'</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-27" style="display:none;">
            <h2>JPMorgan Says Javice Firms Billed Millions Just for 'Attendance'</h2>
            <p><strong>Slashdot | 2025-12-31</strong></p>
            <a class="original-link" href="https://slashdot.org/story/25/12/31/1817247/jpmorgan-says-javice-firms-billed-millions-just-for-attendance?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Catch up on stories from the past week (and beyond) at the Slashdot story archive

The names are so similar. Jarndyce and Jarndyce [wikipedia.org]

Those lawyers are corrupt and taking the piss and if the judge does not hold them in contempt, they are equally so.

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.</div>
        </div>
        
        <div class="card" onclick="openModal('content-28')">
            <div class="source">Slashdot</div>
            <div class="title">Net Neutrality Was Back, Until It Wasn't</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-28" style="display:none;">
            <h2>Net Neutrality Was Back, Until It Wasn't</h2>
            <p><strong>Slashdot | 2025-12-31</strong></p>
            <a class="original-link" href="https://tech.slashdot.org/story/25/12/31/1736226/net-neutrality-was-back-until-it-wasnt?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Want to read Slashdot from your mobile device? Point it at m.slashdot.org and keep reading!

The good thing is that with multli-gigabit speeds available to home, deep packet inspection is practically impossible making it harder to throttle and limit speeds. When everyone was on 50Mbps, it was easy because a software DPI system running on relatively beefy hardware could process at gigabit speeds and throttle companies that refused to pay the full speed ransom. You could stick a box on every node in the neighbourhood cheaply.

But as homes started getting gigabit and faster speeds, equipment that can f

California&#39;s 2018 law remains the nation&#39;s gold standard,

Only if you think net neutrality is a good idea. My gold standard would be to have no law at all.

As many have mentioned, given the on-again, off-again nature of NN regulation, I think we can pretty confidently say the Interwebs will collapse into a post-apocalyptic cesspool of hate and venality regardless of whether we have NN regulations.

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.</div>
        </div>
        
        <div class="card" onclick="openModal('content-29')">
            <div class="source">Slashdot</div>
            <div class="title">Poor Sleep Quality Accelerates Brain Aging</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-29" style="display:none;">
            <h2>Poor Sleep Quality Accelerates Brain Aging</h2>
            <p><strong>Slashdot | 2025-12-31</strong></p>
            <a class="original-link" href="https://science.slashdot.org/story/25/12/31/1716233/poor-sleep-quality-accelerates-brain-aging?utm_source=rss1.0mainlinkanon&utm_medium=feed">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Exercise and get ear plugs.My response to the endless stream of sleep damage reports - not directed toward you or anyone other than the Sleep 8 hours, or you DIE! people.

I must have died 20 years ago. I sleep 5 hours a night, I dream answers to problems in my sleep. So I&#39;m completely demented. 8^) Oh, and I enjoy working, apparently a real killer as well. All the things that kinda sound like the proverbial &quot;Everything you believe is wrong&quot; mantra
They keep putting out these get 8 hours every night, or your shortening your lifespan,

My response to the endless stream of sleep damage reports - not directed toward you or anyone other than the Sleep 8 hours, or you DIE! people.

I must have died 20 years ago. I sleep 5 hours a night, I dream answers to problems in my sleep. So I&#39;m completely demented. 8^) Oh, and I enjoy working, apparently a real killer as well. All the things that kinda sound like the proverbial &quot;Everything you believe is wrong&quot; mantra

They keep putting out these get 8 hours every night, or your shortening your lifespan,

I sleep 5 hours a night, [...]You might be one of the lucky few [livescience.com] with a very specific genetic mutation...

You might be one of the lucky few [livescience.com] with a very specific genetic mutation...

an unanswerable question since everyone is different but here are the basics to try out:

eye maskwhite noise generator of some sortweighted blankethaving your bedroom be colder than normalmelatonin/seratonin can helpfor some people marijuana can help quell thoughts, for others it makes them racesome people need zero screen time, some like myself will fall asleep easier watching somethingalso look into actually treating your anxiety.  medication can help, therapy can helpmaybe you just need a new job to give

The beauty sleep meme exists for a very real reason.

It accelerates physical aging as well.The beauty sleep meme exists for a very real reason.
None of this bodes well for a President who&#39;s up rage-tweeting 100 posts at 3am ...

It accelerates physical aging as well.The beauty sleep meme exists for a very real reason.

None of this bodes well for a President who&#39;s up rage-tweeting 100 posts at 3am ...

It accelerates physical aging as well.The beauty sleep meme exists for a very real reason.Funny, my 5 hours a night ritual, and I should look like Dorian Gray.  I sleep when I am tired, and wake when I&#39;m done. The only times I do the 8 hour mandatory sleep or die thing is when I am ill. Funny that.

The beauty sleep meme exists for a very real reason.

Funny, my 5 hours a night ritual, and I should look like Dorian Gray.  I sleep when I am tired, and wake when I&#39;m done. The only times I do the 8 hour mandatory sleep or die thing is when I am ill. Funny that.

There&#39;s a relevant but fairly rare genetic mutation... (https://www.livescience.com/health/sleep/rare-genetic-mutation-lets-some-people-thrive-on-just-4-hours-of-shut-eye).

Wonder if it can be reversed at all.This is the practical question.  Are these bad effects cumulative or based on some recent time window?  That is, can someone who had negative sleep but then follows good sleep behaviors for some time reach the same state of health as someone who had good sleep behaviors all along?

This is the practical question.  Are these bad effects cumulative or based on some recent time window?  That is, can someone who had negative sleep but then follows good sleep behaviors for some time reach the same state of health as someone who had good sleep behaviors all along?

It can&#39;t be reversed but it can be mitigated to a degree.

As someone who was diagnosed with Parkinson&#39;s Disease (PD) about five years ago I can tell you that one of the most impactful effects of that disease is *not* the tremors but the sleep disruption.  A fairly high percentage of PD suffers go on to develop dementia and I&#39;m pretty sure that this progression is hastened by the fact that sleep is so disrupted and limited.

My mitigation for the effects of sleep deprivation associated with my PD is creatine mo

EMR (electromagnetic radiation) like WiFi, cell phones, wireless electric meters, Bluetooth are all like daylight to the brain.&quot;Citation needed&quot; from multiple high-quality peer-reviewed studies.If things were as bad as you imply, nearly everyone in most big cities would be suffering noticeable health effects.  If not &quot;nearly everyone&quot; then at least a huge percentage. The number of people complaining about bad health effects is small enough that your claims fall under the &quot;extraordinary claims require extraordinary evidence&quot; rule.

EMR (electromagnetic radiation) like WiFi, cell phones, wireless electric meters, Bluetooth are all like daylight to the brain.

&quot;Citation needed&quot; from multiple high-quality peer-reviewed studies.

If things were as bad as you imply, nearly everyone in most big cities would be suffering noticeable health effects.  If not &quot;nearly everyone&quot; then at least a huge percentage. The number of people complaining about bad health effects is small enough that your claims fall under the &quot;extraordinary claims require extraordinary evidence&quot; rule.

I know firsthand that bad sleep does a number on you, what I need to know is how to sleep well. In over 40 years I haven&#39;t managed so far.

There may be more comments in this discussion. Without JavaScript enabled, you might want to turn on Classic Discussion System in your preferences instead.</div>
        </div>
        
        <div class="card" onclick="openModal('content-30')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">The First Woman to Serve a Full Term as a U.S. Senator, Hattie Caraway, Represented Which State?</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-30" style="display:none;">
            <h2>The First Woman to Serve a Full Term as a U.S. Senator, Hattie Caraway, Represented Which State?</h2>
            <p><strong>News and Politics - Slate Magazine | 2025-12-31</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2025/12/trivia-quiz-daily-slate-history-assassination-rome-free-speech.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Please enable Javascript in your browser to view Slate interactives.

Which Cartoon Short Introduced Mickey Mouse?

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-31')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">2025: The Advice of the Year</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-31" style="display:none;">
            <h2>2025: The Advice of the Year</h2>
            <p><strong>News and Politics - Slate Magazine | 2025-12-31</strong></p>
            <a class="original-link" href="https://slate.com/podcasts/what-next/2025/12/the-advice-we-turned-to-in-2025?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">In a year when things felt out of control, this advice kept us grounded.

Please enable javascript to get your Slate Plus feeds.

If you can&#39;t access your feeds, please contact customer support.

Thanks! Check your phone for a link to finish setting up your feed.

Enter your phone number and we&#39;ll text you a link to set up the
        podcast in your app:

We&#39;ll only text you about setting up this podcast, no spam.

Apple Podcasts will only work on MacOS operating systems since Catalina. We do not support Android apps on desktop at this time.

These links will only work if you&#39;re on the device you listen to podcasts on.

We&#39;re sorry, but something went wrong while fetching your podcast feeds. Please contact us at plus@slate.com for help.

With rising authoritarianism, terrifying speech crackdowns, and violence in the streets, this year we found ourselves turning to our friends over at How To for advice on finding peace and excitement in our lives.

Want more What Next? Subscribe to Slate Plus to access ad-free listening to the whole What Next family and across all your favorite Slate podcasts. Subscribe today on Apple Podcasts by clicking “Try Free” at the top of our show page. Sign up now at slate.com/whatnextplus to get access wherever you listen.

The problem with the news right now? It’s everywhere. And each day, it can feel like we’re all just mindlessly scrolling. It’s why we created What Next. This short daily show is here to help you make sense of things. When the news feels overwhelming, we’re here to help you answer: What next? Look for new episodes every weekday morning.

Carvell Wallace is a New York Times bestselling author, contributing writer to the New York Times Magazine, and a former Slate parenting columnist and co-host of Mom and Dad Are Fighting. He also hosted the Finding Fred podcast and writes for GQ, Esquire, the Atlantic, the New Yorker, and other outlets.

Courtney E. Martin is the author of Learning in Public: Lessons for a Racially Divided America From My Daughter’s School, among other books, and writes a weekly newsletter called Examined Family. She co-hosts the Slate podcast How To!</div>
        </div>
        
        <div class="card" onclick="openModal('content-32')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">Which Cartoon Short Introduced Mickey Mouse?</div>
            <div class="meta">2025-12-30</div>
        </div>
        
        <div id="content-32" style="display:none;">
            <h2>Which Cartoon Short Introduced Mickey Mouse?</h2>
            <p><strong>News and Politics - Slate Magazine | 2025-12-30</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2025/12/trivia-quiz-daily-slate-culture-shakespeare-disney-sports.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Please enable Javascript in your browser to view Slate interactives.

The First Woman to Serve a Full Term as a U.S. Senator, Hattie Caraway, Represented Which State?

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-33')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">Brett Kavanaugh Is Trying to Walk Back “Kavanaugh Stops.” Too Late.</div>
            <div class="meta">2025-12-30</div>
        </div>
        
        <div id="content-33" style="display:none;">
            <h2>Brett Kavanaugh Is Trying to Walk Back “Kavanaugh Stops.” Too Late.</h2>
            <p><strong>News and Politics - Slate Magazine | 2025-12-30</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2025/12/brett-kavanaugh-stops-immigration-racial-profiling-ice.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Sign up for the Slatest to get the most insightful analysis, criticism, and advice out there, delivered to your inbox daily.

Justice Brett Kavanaugh does not seem happy that his name has become synonymous with racist immigration enforcement. In September, the justice wrote that Hispanic residents’ “apparent ethnicity” could be a “relevant factor” in federal agents’ decision to stop them and demand proof of citizenship. Immigration and Customs Enforcement and Customs and Border Protection promptly seized upon his opinion as a license to stop any Hispanic person on the basis of race—often with excessive, even sadistic force—and detain them until they proved their lawful presence. Law professor Anil Kalhan termed these encounters “Kavanaugh stops,” and the name swiftly caught on as evidence mounted that they had become standard practice across the country. Lawyers also provided courts with evidence that Kavanaugh had sanitized the reality of this practice to the point of fiction. The justice claimed that these were “brief investigative stops” and that any lawful resident would be “promptly” released. In truth, federal agents brutalized, kidnapped, and tormented people—including many U.S. citizens—simply because of their ethnicity, even after they asserted legal status.

Now it appears that Kavanaugh has some regrets. Last Tuesday, the justice backtracked from his previous position without quite acknowledging the retreat. He did so in a concurrence to the Supreme Court’s decision to block President Donald Trump’s deployment of the National Guard—a case that does not even directly concern “Kavanaugh stops.” In a footnote, he declared that race and ethnicity could not be “considerations” when officers make “immigration stops or arrests.” That directly conflicts with his earlier assertion that officers can use race and ethnicity as a “factor” when deciding whom to detain. The two positions cannot be reconciled. Yet Kavanaugh did not admit that he had changed his position; he simply pretended that the law in this area was “clear,” when he himself muddied it just months earlier.

On this week’s episode of Amicus, co-hosts Dahlia Lithwick and Mark Joseph Stern discussed this strange, tacit walk-back.

Dahlia Lithwick: It’s the icing on top of the Christmas cake that Brett Kavanaugh, in an unrelated discussion, gave himself the gift of forgiveness for his notorious “Kavanaugh stops” opinion.

Mark Joseph Stern: I think he is begging us to please cease and desist calling them “Kavanaugh stops.” This footnote is buried in the opinion and doesn’t really have anything to do with it. He just says: By the way, this conflict is about immigration stops. Then he segues into his view on the law around immigration stops, which he claims to be “longstanding and clear.” He writes: “The Fourth Amendment requires that immigration stops must be based on reasonable suspicion of illegal presence, stops must be brief, arrests must be based on probable cause, and officers must not employ excessive force. Moreover, the officers must not make interior immigration stops or arrests based on race or ethnicity.”

Wow! Immigration stops can’t be based on race? What a concept! A concept that you, Brett Kavanaugh, rejected just a few months ago, in September, in the Vasquez Perdomo case. Back then, you wrote that immigration stops could be at least partly based on race or ethnicity, and that a person’s appearance as Latino could be one reason for them to be stopped by immigration officers.

I wonder what has changed since September.

Well, I think he is trying to rid “Kavanaugh stops” from the discourse, which is never going to happen. And maybe he’s trying to send a message to the Trump administration to cool it down. Because now we have CBP Chief Greg Bovino declaring that agents can engage in racial profiling. Bovino has even said that every single person in this country has to walk around with proof of citizenship or else face arrest on suspicion of being undocumented. Kavanaugh is probably a little unnerved that all these violent, racist arrests and abductions are taking his name. He doesn’t want to be remembered by history as this great villain who greenlit the worst wave of violent racial profiling by the federal government in ages. But this footnote changes nothing. He cannot walk back what he has unleashed.

This goes to all the quibbles that we surfaced about the shadow docket when Vasquez Perdomo came out. Because if the justices are going to go ahead and reverse precedent about immigration stops, and then their decision gets operationalized by the Trump administration, they can’t say: Oh, sorry, we didn’t mean that. They certainly can’t do it in a case that does not directly relate back to “Kavanaugh stops.” So this is weird dicta in a random case that is trying to undo crappy but unfortunately enforceable doctrine. And Kavanaugh is just like: No, it’s the shadow docket—I can do what I want! I get a do-over. I get takesies-backsies. We’re now at full Etch A Sketch: I’m making law. I’m breaking law. I’m changing law.

I’ve seen some commentators praise Kavanaugh for sort of responding to criticism here. I do not think he gets any points. He did what he did in Vasquez Perdomo; he should have foreseen the consequences. Every intelligent observer understood what was going to happen when his opinion dropped in September. Now he seems to regret it—though he still hasn’t apologized directly or acknowledged that he was wrong, and is pretending that what he said earlier is consonant with what he’s saying now. Too little, too late.

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-34')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">2025: The Movie(s) of the Year</div>
            <div class="meta">2025-12-30</div>
        </div>
        
        <div id="content-34" style="display:none;">
            <h2>2025: The Movie(s) of the Year</h2>
            <p><strong>News and Politics - Slate Magazine | 2025-12-30</strong></p>
            <a class="original-link" href="https://slate.com/podcasts/what-next/2025/12/year-of-the-resistance-genre-mash-up-blockbuster?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Two films especially felt like they couldn’t have come out at any other time.

Please enable javascript to get your Slate Plus feeds.

If you can&#39;t access your feeds, please contact customer support.

Thanks! Check your phone for a link to finish setting up your feed.

Enter your phone number and we&#39;ll text you a link to set up the
        podcast in your app:

We&#39;ll only text you about setting up this podcast, no spam.

Apple Podcasts will only work on MacOS operating systems since Catalina. We do not support Android apps on desktop at this time.

These links will only work if you&#39;re on the device you listen to podcasts on.

We&#39;re sorry, but something went wrong while fetching your podcast feeds. Please contact us at plus@slate.com for help.

If you were to sum up 2025 in a film, which would you pick? The question that nearly wrecked the brain of Slate’s chief movie critic.

Guest: Dana Stevens, Slate’s movie critic.

Dana’s ten best movies of 2025.Her review of Sinners.And her review of One Battle After Another.

Want more What Next? Subscribe to Slate Plus to access ad-free listening to the whole What Next family and across all your favorite Slate podcasts. Subscribe today on Apple Podcasts by clicking “Try Free” at the top of our show page. Sign up now at slate.com/whatnextplus to get access wherever you listen.

Podcast production by Elena Schwartz, Paige Osburn, Anna Phillips, Madeline Ducharme, and Rob Gunther.

The problem with the news right now? It’s everywhere. And each day, it can feel like we’re all just mindlessly scrolling. It’s why we created What Next. This short daily show is here to help you make sense of things. When the news feels overwhelming, we’re here to help you answer: What next? Look for new episodes every weekday morning.

Mary Harris is the host and managing editor of What Next, Slate&#39;s new daily news podcast. She has reported throughout the public radio system, for NPR, Marketplace, and WNYC.</div>
        </div>
        
        <div class="card" onclick="openModal('content-35')">
            <div class="source">News and Politics - Slate Magazine</div>
            <div class="title">One State Supreme Court’s Lazy “Shortcut” Erases Civil Rights</div>
            <div class="meta">2025-12-29</div>
        </div>
        
        <div id="content-35" style="display:none;">
            <h2>One State Supreme Court’s Lazy “Shortcut” Erases Civil Rights</h2>
            <p><strong>News and Politics - Slate Magazine | 2025-12-29</strong></p>
            <a class="original-link" href="https://slate.com/news-and-politics/2025/12/colorado-supreme-court-civil-rights-constitution.html?via=rss">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">This piece was originally published in the Behind the Bench newsletter on state constitutional law. Behind the Bench is published by the State Law Research Initiative.

It can be astonishing, and more than a little depressing, to see the lengths some courts go to avoid upholding basic constitutional rights. In June, I wrote about how the North Carolina Supreme Court’s Republican majority dilutes civil rights by requiring claimants to prove that challenged state actions, including discriminatory laws, are “unconstitutional beyond a reasonable doubt.” The problem, as liberal Justice Anita Earls pointed out, is that “either the statute is consistent with the constitution or not,” and the “notion that you have to somehow establish that beyond a reasonable doubt makes no sense”—except, of course, as an excuse to erode civil rights.

Today, I bring your attention to the Colorado Supreme Court, which this month reaffirmed an inexplicable quirk of its excessive sentencing jurisprudence that preemptively extinguishes constitutional rights for entire categories of people. The court declares certain crimes to be “per se grave or serious,” which in practice means that no one convicted of such crimes can ever challenge their sentence, no matter its severity. The long-standing rule is both wholly illogical and blatantly unconstitutional (in the sense that it erases constitutional rights), but there is some good news: It appears that two justices are finally ready to, in their words, “deep six this concept.”

Colorado’s state constitution prohibits “cruel and unusual” punishment, including excessive or “disproportionate” prison terms. To assess excessive punishment claims, Colorado courts begin by comparing “the gravity or seriousness of the offense to the harshness of the penalty.” Normally, Colorado case law takes a relatively capacious view of how a crime’s “gravity” should be measured. It accounts not just for the offense and its elements but also for potentially mitigating factors such as whether the person “was an accessory, complicitor, or principal,” along with the person’s “culpability and motive.” In theory, this definition captures how personal characteristics (such as youth, disability, or addiction) and other circumstances (such as the role of group dynamics, poverty, or coercive relationships) might reduce someone’s culpability and factor into the constitutional analysis.

But for some offenses, the Colorado Supreme Court—and only the Colorado Supreme Court—has devised what it calls “the ‘per se’ shortcut.” Under this rule, the court “designate[s] certain crimes ‘per se grave or serious,’ ” which, the court says, renders a sentence all but “impervious to attack on proportionality grounds.” In other words, the court’s justices have decided they will not do their jobs for people who have certain convictions. Rather than actually assess excessive punishment claims in light of all the factors the law requires, they will just assume that these claims fail, giving prosecutors and legislators free rein to pursue the sort of punitive excess that has fueled mass incarceration for decades.

And it’s not like this rule has been reserved for what might intuitively be the most violent, high-culpability crimes. Robbery, for example, remains “per se grave or dangerous” even though the circumstances under which robberies take place vary wildly, as do the characteristics of the people who commit them (more on that below). Even worse, for nearly 30 years Colorado courts put all drug offenses, including mere possession, on this list until a “clarify[ing]” decision in 2019 finally changed that. (It took decades for the Colorado Supreme Court to realize that it “makes little sense to automatically treat the sale of a large quantity of cocaine by the leader of a drug cartel as equally grave or serious as the mere possession of a very small quantity of cocaine by a drug addict who is not involved in sale or distribution.”)

The court concedes that this “shortcut” is “unique to Colorado law” and that it “eliminates a longstanding layer of due process for criminal defendants.” Nonetheless, it remains on the books because it supposedly “saves time” and promotes “consistency.” I would submit that “saving time” is never a good reason to dispense with constitutional rights, but the court’s claims to efficiency are dubious in any case. Now, instead of properly analyzing its cruel and unusual clause, the court spends its time hopelessly trying to figure out what on earth “per se grave or serious” actually means and what offenses it applies to. With this rule in place, and with prosecutors thirsty to invoke it, the first part of every excessive punishment analysis turns into Tom Cruise cross-examining Jack Nicholson in A Few Good Men: Q: “Grave Danger?” A: [Raises eyebrow] “Is there another kind?”

But there is a glimmer of hope. In People v. Kennedy, decided earlier this month, Justices Carlos Samour and Richard Gabriel “specially concurred” to advocate nixing the per se grave or serious shortcut.

In Kennedy, the court stood by its shortcut and upheld the 24-year prison term at issue. But it also held that vehicular homicide–DUI is not “per se grave or serious” because it is a strict liability crime with no specific intent element. “When a crime requires no proof of mens rea,” the court said, “it is impossible to evaluate the culpability of defendants convicted of the offense under every factual scenario.”

It is good that the court declined to expand the shortcut to cover a new offense, but the analytical problem here is that the same reasoning applies to crimes that do require proof of intent. To use an example mentioned above, the court thinks that people who commit robbery have sufficiently high culpability “under every factual scenario”—a conclusion that can only be understood as the willful ignorance of reality. Just a few other facts one might want to know: How old is the person? Are they a youth or emerging adult under age 25, and therefore more susceptible to peer pressure and impulsive decisionmaking? Was the person coerced by an abusive partner or authority figure? Did the person use a weapon and if so what kind? Was it a gun that turned out to be fake? Did the person act out of desperation? Was anyone physically harmed? The list goes on. To say that virtually no punishment could be unconstitutionally severe for all robbery convictions across all factual scenarios is absurd.

Justices Samour and Gabriel, at least, have started to push back. They argued that “easier and faster isn’t always better,” and that such “superficial proportionality review” is inappropriate when constitutional rights are at stake. Ultimately, they found “the drawbacks of per se designations far outweigh any purported benefits.”

Of course, Samour and Gabriel are right, but I’d add another critique: This constitutional “shortcut” makes absolutely no sense. Recall what it is ostensibly a shortcut to: comparing the gravity and/or seriousness of a criminal offense (including, per Colorado case law, characteristics of the offender) with the severity of the punishment imposed for it. In this context, neither “grave” nor “serious” is a bright-line, binary category. They exist along a spectrum. There is no being “not serious” up to a point before falling over a line into “seriousness.” This isn’t bankruptcy. This is a test about whether certain prison terms are too severe; one would think or at least hope that the Colorado Supreme Court is not perfectly fine with incarceration for wholly unserious crimes. To say that an offense is automatically “serious” or “grave,” therefore, means absolutely nothing, and it certainly doesn’t help understand if the resulting criminal punishment is fair.

What the court must mean, then, is that some crimes are sufficiently serious, but that only makes sense relative to the punishment imposed—a fact irrelevant to the court’s per se designation.

Perhaps I am thinking too hard about this. Such an arbitrary, court-created rule—born out of some combination of cowardly deference to extreme punishments and sheer laziness, and that even prosecutors agree is “a weird concept anyway”—doesn’t deserve that much credit. The point is: The Colorado Supreme Court’s rule, it turns out, is less a shortcut and more a barrier to protecting fundamental constitutional rights that should be torn down.

Slate relies on advertising to support our journalism. If you value our
        work, please disable your ad blocker. If you want to block ads but still
        support Slate, consider subscribing.

Already a member?
        Sign in
          here

Join today to keep reading. You&#39;ll also get access to all of Slate&#39;s
        independent journalism, unparalleled advice, and daily games. Cancel
        anytime.

Already a member?
        Sign in
          here</div>
        </div>
        
        <div class="card" onclick="openModal('content-36')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">Review: These are the best plug-in hybrids for under $55,000</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-36" style="display:none;">
            <h2>Review: These are the best plug-in hybrids for under $55,000</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2025-12-31</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2025-12-hybrids.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-37')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">France plans social media ban for children under 15</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-37" style="display:none;">
            <h2>France plans social media ban for children under 15</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2025-12-31</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2025-12-france-social-media-children.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-38')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">Low-cost gelators nearly double the performance of aircraft anti-icing fluids, finds new study</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-38" style="display:none;">
            <h2>Low-cost gelators nearly double the performance of aircraft anti-icing fluids, finds new study</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2025-12-31</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2025-12-gelators-aircraft-anti-icing-fluids.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-39')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">Tucked away in a downtown Chicago office building, fallen e-commerce star Groupon is ready for a comeback</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-39" style="display:none;">
            <h2>Tucked away in a downtown Chicago office building, fallen e-commerce star Groupon is ready for a comeback</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2025-12-31</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2025-12-tucked-downtown-chicago-office-fallen.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-40')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">How California's Delete Act will protect personal information from data brokers in the New Year</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-40" style="display:none;">
            <h2>How California's Delete Act will protect personal information from data brokers in the New Year</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2025-12-31</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2025-12-california-delete-personal-brokers-year.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-41')">
            <div class="source">Tech Xplore - electronic gadgets, technology advances and research news</div>
            <div class="title">SoftBank lifts OpenAI stake to 11% with $41bln investment</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-41" style="display:none;">
            <h2>SoftBank lifts OpenAI stake to 11% with $41bln investment</h2>
            <p><strong>Tech Xplore - electronic gadgets, technology advances and research news | 2025-12-31</strong></p>
            <a class="original-link" href="https://techxplore.com/news/2025-12-softbank-openai-stake-41bln-investment.html">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Content unavailable (Blocked by source). Please read on original site.</div>
        </div>
        
        <div class="card" onclick="openModal('content-42')">
            <div class="source">The Register</div>
            <div class="title">Nvidia DMs TSMC: please sir can I have some more? The Chinese are starved for H200s</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-42" style="display:none;">
            <h2>Nvidia DMs TSMC: please sir can I have some more? The Chinese are starved for H200s</h2>
            <p><strong>The Register | 2025-12-31</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2025/12/31/china_nvidia_h200/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">With the sales ban lifted, Chinese tech giants, including ByteDance, are scrambling to secure orders for Nvidia&#39;s H200 graphics accelerators while they can. But will there be enough to satisfy demand?

Citing multiple sources familiar with the matter, Reuters reports Chinese companies have placed orders for more than 2 million of the chips. That&#39;s up from the 40,000 to 80,000 initial orders reported last week.

But with just 700,000 of the now two-year-old AI accelerators in stock, Nvidia has reportedly approached TSMC to ramp production of the chips. The H200 uses TSMC&#39;s 4N process, a slightly older version of technology used by its higher-performance Blackwell parts (4NP), which remain unavailable in China.

Nvidia doesn&#39;t anticipate sales of H200s in China will have any impact on chip supplies to US customers.

&quot;Offering the H200 to approved commercial customers, vetted by the Department of Commerce, strikes a thoughtful balance,&quot; a company spokesperson told The Register and other outlets. &quot;China is a highly competitive market with rapidly growing local chip suppliers. Blocking all U.S. exports undercut our national and economic security and only benefited foreign competition.&quot;

Shipments of the newly minted chips are expected to begin in the second half of 2026 with 8-GPU systems said to sell for around 1.5 million yuan (about $215,000).

Despite its advancing age, the H200 is the most powerful GPU Nvidia can sell in China. Biden-era export controls had capped the performance of chips sold in the Middle Kingdom, but earlier this month, the Trump administration made an exception for H200 shipments if Nvidia agreed to cut Uncle Sam in on 25 percent of the revenues.

Compared to Nvidia&#39;s H20 — a cut-down version of the H200 built to comply with US export controls — that extra zero translates into a pretty big performance jump, particularly for compute-intensive AI training workloads.

The H200 offers 6x faster floating point performance, 50 percent more HBM3e and 20 percent higher memory bandwidth.

ByteDance is apparently one of several Chinese hyperscalers lining up for the chips. According to the South China Morning Post, the TikTok parent plans to buy roughly $14 billion worth of H200s.

However, there is no guarantee that those chips will ever make it to mainland China. While the US government has signed off on H200 sales to China, Beijing has not.

In response to US trade policies governing AI chip and semiconductor equipment sales, Chinese authorities have begun pressuring hyperscalers in the region to ditch Nvidia for domestic alternatives.

The nation has also moved to block state-funded datacenters from using foreign AI chips, while warning of potential backdoors or remote kill switches — allegations Nvidia has fervently denied. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-43')">
            <div class="source">The Register</div>
            <div class="title">US Army seeks human AI officers to manage its battle bots</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-43" style="display:none;">
            <h2>US Army seeks human AI officers to manage its battle bots</h2>
            <p><strong>The Register | 2025-12-31</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2025/12/31/us_army_seeking_officers_willing/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The US Army has been all-in on becoming an AI-powered outfit for some time, and now it&#39;s creating a career path for officers to specialize in making its automation dreams come true.

The new AI/ML officer area of concentration will begin accepting candidates from the Army&#39;s existing officer corps in January through the Volunteer Transfer Incentive Program, according to an announcement published Tuesday. It&#39;s not clear how many AI officers the Army plans to train as part of its initial cadre of candidates, but it wants to have all of them formally reclassified by the end of the 2026 fiscal year.

Training will be at the &quot;graduate level,&quot; according to the Army, and will focus on giving AI officer candidates &quot;hands-on experience in building, deploying, and maintaining the Army&#39;s cutting-edge AI-enabled systems.&quot;

As we&#39;ve reported over the past couple of years, those systems are numerous. The Army has signed deals with OpenAI to run pilot programs in developing warfighting and enterprise domain AI systems, has signed a massive $10 billion contract with Palantir to provide various AI and ML services for the next decade, and has brought in smaller outfits to use AI for things like target tracking.

Young Bang, the US Army&#39;s deputy assistant secretary for acquisition, logistics, and technology under the Biden administration, said last year that the Army didn&#39;t want to get into the business of developing its own AI systems when the private sector was already doing such a great job.

&quot;We want to adopt third-party-generated AI algorithms as fast as y&#39;all are building them,&quot; Bang told the industry at an AWS conference last summer.

In short, there are a lot of commercial AI systems floating around in the Army&#39;s ecosystem but, until later next year, no dedicated force of uniformed experts with the expertise and career longevity the branch needs to get them working at peak efficiency.

&quot;Establishing the … AI/ML career path is another key investment to maintain our decisive edge as an Army,&quot; Army spokesperson Lieutenant Colonel Orlandon Howard said in the Army&#39;s statement. &quot;We&#39;re building a dedicated cadre of in-house experts who will be at the forefront of integrating AI and machine learning across our warfighting functions.&quot;

We suppose the Army could only get so much work out of a bunch of weekend warrior Silicon Valley types who never went through the most basic of officer training before earning their Lieutenant Colonel commissions in a Reserve detachment, where they serve as AI planning and ops consultants.

The actual Army officers who&#39;ll be filling the roles of AI/ML experts for the rest of the service can theoretically come from any background, though the Army said it&#39;ll be prioritizing volunteers &quot;with advanced academic and technical backgrounds in fields related to AI/ML.&quot; ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-44')">
            <div class="source">The Register</div>
            <div class="title">European Space Agency hit again as cybercrims claim 200 GB data up for sale</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-44" style="display:none;">
            <h2>European Space Agency hit again as cybercrims claim 200 GB data up for sale</h2>
            <p><strong>The Register | 2025-12-31</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2025/12/31/european_space_agency_hacked/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The European Space Agency has suffered yet another security incident and, in keeping with past practice, says the impact is limited. Meanwhile, miscreants boast that they&#39;ve made off with a trove of data, including what they claim are confidential documents, credentials, and source code.

While the ESA said it&#39;s aware of a security incident, it added in an X post on Tuesday that the breach may have impacted only &quot;a very small number of external servers&quot; used to support unclassified engineering and scientific collaboration.

&quot;We have initiated a forensic security analysis—currently in progress—and implemented measures to secure any potentially affected devices,&quot; the ESA added. &quot;All relevant stakeholders have been informed, and we will provide further updates as soon as additional information becomes available.&quot;

That&#39;s in contrast to what one cybercriminal posted in their offer of over 200 GB of ESA data for sale on the still-not-dead BreachForums the day after Christmas, according to screenshots grabbed from the seemingly impossible-to-kill cybercrime forum.

According to the alleged attacker, they gained access to ESA-linked external servers on December 18, and were connected &quot;for about a week,&quot; during which they claim to have stolen source code files, CI/CD pipelines, API and access tokens, confidential documents, configuration files, Terraform files, SQL files, hardcoded credentials, and a dump of &quot;all their private Bitbucket repositories as well.&quot;

We reached out to the ESA to get more information about the status of its investigation, and more specifics on what sort of servers were breached, but didn&#39;t hear back, with an automated response informing us that the Agency&#39;s offices are closed for the New Year holiday.

As noted above, this isn&#39;t the first time the ESA has experienced a security incident, nor the first time it has said the affected systems were external to its core networks.

The Space Agency&#39;s online store was hit by attackers last year shortly before the Christmas holiday, with miscreants inserting a fake payment page to nab customer info while unsuspecting users were shopping for space-themed holiday gifts. The ESA, naturally, said it&#39;s not in charge of its own online store.

A trio of ESA domains was compromised in 2015 via an SQL vulnerability, resulting in the theft and leak of information belonging to thousands of subscribers and some ESA staff.

Just a few years prior to that, in 2011, the ESA was also breached, with an attacker publishing administrator, content management, FTP login credentials, and Apache server config files online for all to see. As was the case with this latest incident and last year&#39;s store attack, the ESA said the 2011 breach didn&#39;t affect the Agency&#39;s internal networks.

Fair enough - but this sure feels like a pattern. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-45')">
            <div class="source">The Register</div>
            <div class="title">IPv6 just turned 30 and still hasn’t taken over the world, but don't call it a failure</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-45" style="display:none;">
            <h2>IPv6 just turned 30 and still hasn’t taken over the world, but don't call it a failure</h2>
            <p><strong>The Register | 2025-12-31</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2025/12/31/ipv6_at_30/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Feature In the early 1990s, internetworking wonks realized the world was not many years away from running out of Internet Protocol version 4 (IPv4) addresses, the numbers needed to identify any device connected to the public internet. Noting booming interest in the internet, the internet community went looking for ways to avoid an IP address shortage that many feared would harm technology adoption and therefore the global economy.

A possible fix arrived in December 1995 in the form of RFC 1883, the first definition of IPv6, the planned successor to IPv4.

The most important change from IPv4 to IPv6 was moving from 32-bit to 128-bit addresses, a decision that increased the available pool of IP addresses from around 4.3 billion to over 340 undecillion – a 39-digit number. IPv6 was therefore thought to have future-proofed the internet, because nobody could imagine humanity would ever need more than a handful of undecillion IP addresses, never mind the entire range available under IPv6.

As billions of devices and people came online, first using PCs and then wielding smartphones, conventional wisdom assumed that network operators would move to IPv6 rather than persist with IPv4.

Yet according to data from Google, the Asia Pacific Network Information Center (APNIC), and Cloudflare, less than half of all netizens use IPv6 today.

To understand why, know that IPv6 also suggested other, rather modest, changes to the way networks operate.

&quot;IPv6 was an extremely conservative protocol that changed as little as possible,&quot; APNIC chief scientist Geoff Huston told The Register. &quot;It was a classic case of mis-design by committee.&quot;

And that notional committee made one more critical choice: IPv6 was not backward-compatible with IPv4, meaning users had to choose one or the other – or decide to run both in parallel.

For many, the decision of which protocol to use was easy because IPv6 didn&#39;t add features that represented major improvements.

&quot;One big surprise to me was how few features went into IPv6 in the end, aside from the massive expansion of address space,&quot; said Bruce Davie, a veteran computer scientist recently honored with a lifetime achievement award by the Association for Computing Machinery&#39;s Special Interest Group on Data Communications, which lauded him for &quot;fundamental contributions in networking systems through design, standardization, and commercialization of network protocols and systems.&quot;

Davie said many of the security, plug-and-play, and quality of service features that didn&#39;t make it into IPv6 were eventually implemented in IPv4, further reducing the incentive to adopt the new protocol. &quot;Given the small amount of new functionality in v6, it&#39;s not so surprising that deployment has been a 30 year struggle,&quot; he said.

Another innovation that meant IPv6 made less sense was network address translation (NAT), which allows many devices to share a single public IPv4 address. NAT meant IPv4 network operators could connect thousands of devices with a single IP address, meaning their existing IP addresses became more useful.

&quot;These solutions were relatively easy to deploy, aligned with existing expertise, and avoided large-scale infrastructure changes,&quot; said Alvaro Vives, manager of the learning and development team at RIPE NCC, the regional internet registry for 76 nations across Europe, the Middle East, and Central Asia.

Because NAT stalled IPv6 adoption, vendors didn&#39;t rally behind the new protocol.

&quot;Migration costs, complexity, and training requirements remain high, while short-term ROI is low,&quot; Gartner distinguished VP analyst Andrew Lerner told The Register. &quot;Performance parity across applications and devices is inconsistent, and some organizations even disable IPv6 for better performance. Lack of dual-stack support in legacy infrastructure is another barrier,&quot; he added.

While IPv6 didn&#39;t take off as expected, it&#39;s not fair to say it failed.

&quot;IPv6 wasn&#39;t about turning IPv4 off, but about ensuring the internet could continue to grow without breaking,&quot; said John Curran, president and CEO of the American Registry for Internet Numbers (ARIN).

&quot;In fact, IPv4&#39;s continued viability is largely because IPv6 absorbed that growth pressure elsewhere – particularly in mobile, broadband, and cloud environments,&quot; he added. &quot;In that sense, IPv6 succeeded where it was needed most, and must be regarded as a success.&quot;

RIPE NCC&#39;s Alvaro Vives agrees. &quot;What IPv6 got right was its long-term design,&quot; he told The Register. &quot;It provides a vast address space that allows networks to be planned more simply and consistently. This has enabled innovation, from large mobile networks to the Internet of Things and advanced routing techniques such as Segment Routing over IPv6.&quot;

Gartner&#39;s Lerner thinks the time has come for organizations to develop detailed IPv6 migration plans.

&quot;Validate application compatibility, and ensure new infrastructure supports IPv6,&quot; he advised. &quot;Pilot deployments and lab testing with DNS64/NAT64 are recommended. Over time, IPv6 adoption will accelerate as private IPv4 space depletes and cloud providers introduce pricing models that favor IPv6.&quot;

APNIC&#39;s Huston, however, thinks that IPv6 has become less relevant to the wider internet.

&quot;I would argue that we actually found a far better outcome along the way,&quot; he told The Register. &quot;NATS forced us to think about network architectures in an entirely different way.&quot;

That new way is encapsulated in a new technology called Quick UDP Internet Connections (QUIC), that doesn&#39;t require client devices to always have access to a public IP address.

&quot;We are proving to ourselves that clients don&#39;t need permanent assignment of IP address, which makes the client side of network far cheaper, more flexible, and scalable,&quot; he said.

Huston thinks IPv6 has also become less relevant to servers.

&quot;These days the Domain Name Service (DNS) is the service selector, not the IP address,&quot; Huston told The Register. &quot;The entire security framework of today&#39;s Internet is name based and the world of authentication and channel encryption is based on service names, not IP addresses.&quot;

&quot;So folk use IPv6 these days based on cost: If the cost of obtaining more IPv4 addresses to fuel bigger NATs is too high, then they deploy IPv6. Not because it&#39;s better, but if they are confident that they can work around IPv6&#39;s weaknesses then in a largely name based world there is no real issue in using one addressing protocol or another as the transport underlay.&quot;

But there are plenty of organizations that still see a need for IPv6. Huawei sought 2.56 decillion IPv6 addresses and Starlink appears to have acquired150 sextillion, which is helping to push more countries past 50 percent IPv6 adoption. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-46')">
            <div class="source">The Register</div>
            <div class="title">Everybody has a theory about why Nvidia dropped $20B on Groq - they're mostly wrong</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-46" style="display:none;">
            <h2>Everybody has a theory about why Nvidia dropped $20B on Groq - they're mostly wrong</h2>
            <p><strong>The Register | 2025-12-31</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2025/12/31/groq_nvidia_analysis/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">This summer, AI chip startup Groq raised $750 million at a valuation of $6.9 billion. Just three months later, Nvidia celebrated the holidays by dropping nearly three times that to license its technology and squirrel away its talent.

In the days that followed, the armchair AI gurus of the web have been speculating wildly as to how Nvidia can justify spending $20 billion to get Groq’s tech and people.

Pundits believe Nvidia knows something we don&#39;t. Theories run the gamut from the deal signifying Nvidia intends to ditch HBM for SRAM, a play to secure additional foundry capacity from Samsung, or an attempt to quash a potential competitor. Some hold water better than others, and we certainly have a few of our own.

Nvidia paid $20 billion to non-exclusively license Groq&#39;s intellectual property, which includes its language processing units (LPUs) and accompanying software libraries.

Groq&#39;s LPUs form the foundation of its high-performance inference-as-a-service offering, which it will keep and continue to operate without interruption after the deal closes.

The arrangement is clearly engineered to avoid regulatory scrutiny. Nvidia isn&#39;t buying Groq, it&#39;s licensing its tech. Except… it&#39;s totally buying Groq.

How else to describe a deal that sees Groq’s CEO Jonathan Ross and president Sunny Madra move to Nvidia, along with most of its engineering talent?

Sure, Groq is technically sticking around as an independent company with Simon Edwards at the helm as its new CEO, but with much of its talent gone, it&#39;s hard to see how the chip startup survives long-term.

The argument that Nvidia just wiped a competitor off the board therefore works. Whether that move was worth $20 billion is another matter, given it could provoke an antitrust lawsuit.

One prominent theory about Nvidia’s motives is that Groq’s LPUs use static random access memory (SRAM), which is orders of magnitude faster than the high-bandwidth memory (HBM) found in GPUs today.

A single HBM3e stack can achieve about 1 TB/s of memory bandwidth per module and 8 TB/s per GPU today. The SRAM in Groq&#39;s LPUs can be 10 to 80 times faster.

Since large language model (LLM) inference is predominantly bound by memory bandwidth, Groq can achieve stupendously fast token generation rates. In Llama 3.3 70B, the benchmarkers at Artificial Analysis report that Groq&#39;s chips can churn out 350 tok/s. Performance is even better when running a mixture of experts models, like gpt-oss 120B, where the chips managed 465 tok/s.

We&#39;re also in the middle of a global memory shortage and demand for HBM has never been higher. So, we understand why some might look at this deal and think Groq could help Nvidia cope with the looming memory crunch.

The simplest answer is often the right one – just not this time.

Sorry to have to tell you this, but there&#39;s nothing special about SRAM. It&#39;s in basically every modern processor, including Nvidia&#39;s chips.

SRAM also has a pretty glaring downside. It&#39;s not exactly what you&#39;d call space efficient. We&#39;re talking, at most, a few hundred megabytes per chip compared to 36 GB for a 12-high HBM3e stack for a total of 288 GB per GPU.

Groq&#39;s LPUs have just 230 MB of SRAM each, which means you need hundreds or even thousands of them just to run a modest LLM. At 16-bit precision, you&#39;d need 140 GB of memory to hold the model weights and an additional 40 GB for every 128,000 token sequence.

Groq needed 574 LPUs stitched together using a high-speed interconnect fabric to run Llama 70B.

You can get around this by building a bigger chip – each of Cerebras&#39; WSE-3 wafers features more than 40 GB of SRAM on board, but these chips are the size of a dinner plate and consume 23 kilowatts. Anyway, Groq hasn&#39;t gone this route.

Suffice it to say, if Nvidia wanted to make a chip that uses SRAM instead of HBM, it didn&#39;t need to buy Groq to do it.

So, what did Nvidia throw money at Groq for?

Our best guess is that it was really for Groq&#39;s &quot;assembly line architecture.&quot; This is essentially a programmable data flow design built with the express purpose of accelerating the linear algebra calculations computed during inference.

Most processors today use a Von Neumann architecture. Instructions are fetched from memory, decoded, executed, and then written to a register or stored in memory. Modern implementations introduce things like branch prediction, but the principles are largely the same.

Data flow works on a different principle. Rather than a bunch of load-store operations, data flow architectures essentially process data as it&#39;s streamed through the chip.

As Groq explains it, these data conveyor belts &quot;move instructions and data between the chip&#39;s SIMD (single instruction/multiple data) function units.&quot;

&quot;At each step of the assembly process, the function unit receives instructions via the conveyor belt. The instructions inform the function unit where it should go to get the input data (which conveyor belt), which function it should perform with that data, and where it should place the output data.&quot;

According to Groq, this architecture effectively eliminates bottlenecks that bog down GPUs, as it means the LPU is never waiting for memory or compute to catch up.

Groq can make this happen with an LPU and between them, which is good news as Groq&#39;s LPUs aren&#39;t that potent on their own. On paper, they achieve BF16 perf, roughly on par with an RTX 3090 or the INT8 perf of an L40S. But, remember that&#39;s peak FLOPS under ideal circumstances. In theory, data flow architectures should be able to achieve better real-world performance for the same amount of power.

It&#39;s worth pointing out that data flow architectures aren&#39;t restricted to SRAM-centric designs. For example, NextSilicon&#39;s data flow architecture uses HBM. Groq opted for an SRAM-only design because it kept things simple, but there&#39;s no reason Nvidia couldn&#39;t build a data flow accelerator based on Groq&#39;s IP using SRAM, HBM, or GDDR.

So, if data flow is so much better, why isn&#39;t it more common? Because it&#39;s a royal pain to get right. But, Groq has managed to make it work, at least for inference.

And, as Ai2&#39;s Tim Dettmers recently put it, chipmakers like Nvidia are quickly running out of levers they can pull to juice chip performance. Data flow gives Nvidia new techniques to apply as it seeks extra speed, and the deal with Groq means Jensen Huang’s company is in a better position to commercialize it.

Groq also provides Nvidia with an inference-optimized compute architecture, something that it&#39;s been sorely lacking. Where it fits, though, is a bit of a mystery.

Most of Nvidia’s &quot;inference-optimized&quot; chips, like the H200 or B300, aren&#39;t fundamentally different from their &quot;mainstream&quot; siblings. In fact, the only difference between the H100 and H200 was that the latter used faster, higher capacity HBM3e which just happens to benefit inference-heavy workloads.

As a reminder, LLM inference can be broken into two stages: the compute-heavy prefill stage, during which the prompt is processed, and the memory-bandwidth-intensive decode phase during which the model generates output tokens.

That&#39;s changing with Nvidia&#39;s Rubin generation of chips in 2026. Announced back in September, the Rubin CPX is designed specifically to accelerate the compute-intensive prefill phase of the inference pipeline, freeing up its HBM-packed Vera Rubin superchips to handle decode.

This disaggregated architecture minimizes resource contention and helps to improve utilization and throughput.

Groq&#39;s LPUs are optimized for inference by design, but they don&#39;t have enough SRAM to make for a very good decode accelerator. They could, however, be interesting as a speculative decoding part.

If you&#39;re not familiar, speculative decoding is a technique which uses a small &quot;draft&quot; model to predict the output of a larger one. When those predictions are correct, system performance can double or triple, driving down cost per token.

These speculative draft models are generally quite small, often consuming a few billion parameters at most, making Groq&#39;s existing chip designs plausible for such a design.

Do we need a dedicated accelerator for speculative decoding? Sure, why not. Is it worth $20 billion? Depends on how you measure it. Compared with publicly traded companies whose total valuation is around $20 billion, like HP, Inc., or Figma, it may seem steep. But for Nvidia, $20 billion is a relatively affordable amount – it recorded $23 billion in cash flow from operations last quarter alone. In the end, it means more chips and accessories for Nvidia to sell.

Perhaps the least likely take we&#39;ve seen is the suggestion that Groq somehow opens up additional foundry capacity for Nvidia.

Groq currently uses GlobalFoundries to make its chips, and plans to build its next-gen parts on Samsung&#39;s 4 nm process tech. Nvidia, by comparison, does nearly all of its fabrication at TSMC and is heavily reliant on the Taiwanese giant’s advanced packaging tech.

The problem with this theory is that it doesn&#39;t actually make any sense. It&#39;s not like Nvidia can&#39;t go to Samsung to fab its chips. In fact, Nvidia has fabbed chips at Samsung before – the Korean giant made most of Nvidia’s Ampere generation product. Nvidia needed TSMC&#39;s advanced packaging tech for some parts like the A100, but it doesn’t need the Taiwanese company to make Rubin CPX. Samsung or Intel can probably do the job.

All of this takes time, and licensing Groq&#39;s IP and hiring its team doesn&#39;t change that.

The reality is Nvidia may not do anything with Groq&#39;s current generation of LPUs. Jensen might just be playing the long game, as he&#39;s been known to do. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-47')">
            <div class="source">The Register</div>
            <div class="title">The most durable tech is boring, old, and everywhere</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-47" style="display:none;">
            <h2>The most durable tech is boring, old, and everywhere</h2>
            <p><strong>The Register | 2025-12-31</strong></p>
            <a class="original-link" href="https://go.theregister.com/feed/www.theregister.com/2025/12/31/long_lived_tech/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Opinion COBOL turned 66 this year and is still in use today. Major retail and commercial banks continue to run core account processing, ATM networks, credit card clearing, and batch end-of-day settlement. On top of that, many payment networks, stock exchanges, and clearinghouses rely on COBOL for high‑volume, high‑reliability batch and online transaction processing on mainframes.

Which reminds me, mainframes are still alive and well too. Banking, insurance, governments, inventory management – all the same places you&#39;ll find COBOL, you&#39;ll find mainframes as well.

None of that is as sexy as the latest AI program or the newest cloud-native computing release, but old dogs with their old tricks still have useful work to perform.

All of which made me wonder what other technologies are likely to still be in use 50 or more years after they were first released. Here are the ones my friends and I came up with.

First, though, I want to point out that the current standard, COBOL 2023, is very different from the COBOL that Admiral Grace Hopper helped create. The same is true of mainframes. The first IBM mainframe, 1952&#39;s 701, and even 1965&#39;s IBM/360, which became COBOL&#39;s top platform, don&#39;t look much at all like today&#39;s IBM z17. Nevertheless, there&#39;s a clear line running from those much earlier technologies to the ones at our fingertips today. Nothing stays the same when it comes to computing, even if the names don&#39;t change.

Starting with languages, C, the language of choice for system programmers, is still alive and well, as it&#39;s already over 50 years old. I expect it, and COBOL too, to reach the century mark.

Yes, I know all about C&#39;s built-in security problems, but you still can&#39;t beat it when it comes to raw speed. Sure, assembler is even faster – just ask the FFmpeg developers – but you can run C on pretty much any CPU.

Lately, there&#39;s been a lot of talk about Rust replacing C for system programming. And, yes, memory-safe Rust is now a full-fledged language for programming in the Linux kernel. However, speed and portability have always been C&#39;s killer features, and that hasn&#39;t changed.

SQL also isn&#39;t going anywhere this century. It&#39;s embedded in every major relational database management system (RDBMS), and it&#39;s here for the long run. There are tens of billions of lines of SQL in stored procedures and queries. It&#39;s embedded in far too much data – and business logic is bound to it – for it to disappear.

Another language that people love to hate, JavaScript/TypeScript, isn&#39;t going anywhere either. Much as developers like to make fun of it, it&#39;s still the de facto language of the web browser and a major server‑side runtime. So long as we&#39;re using the web platform, JavaScript, in one dialect or another, will be required for compatibility.

Linux is forever. We&#39;ll still be running Linux come 2100. Heck, I won&#39;t be surprised to see computers still running Linux in 2125. Oh, and I expect Linus Torvalds&#39; other greatest creation, Git, to be with us for at least another 50 years.

Along with Linux, I expect vi and Emacs to persist. We&#39;ll also need fast text editors. Even Bash, which has outlasted all the other Unix/Linux shells, may hang around for another century or so.

A technology I think is here for the foreseeable future but others might disagree with is Kubernetes. This is the default container orchestration program for pretty much every cloud around. It has its critics, but love it or hate it, it&#39;s the foundation for cloud-native computing and all the dozens of other programs and services we use for modern-day cloud computing.

Moving on to higher levels of technology, I see Photoshop going on for decades more to come. Yes, I&#39;m a big open source fan, and GIMP is what I use, but facts are facts. If you do serious work with images, you&#39;re almost certainly a user of Photoshop and its ecosystem.

File formats are another matter. Once one is established as the top format in any field, it tends to hang on forever. That&#39;s why we&#39;re still using Microsoft&#39;s DOC and its newer variant, DOCX, instead of the superior and far more open ODF. That&#39;s not a good thing.

For example, we all use Adobe PDF when we need a document to look and behave the same everywhere, be hard to accidentally change, and remain readable for years and years. However, people who work with PDF a lot are painfully aware that there are many PDF variants, and they have more than their share of compatibility problems.

As my friend Dan Rosenbaum, an editor and singer, pointed out to me, there are industry standards such as the proprietary Finale for music notation, which was abandoned by its maker. In the continuing aftershocks, musicians have discovered there&#39;s no easy way to port Finale compositions to any other format, and thus any other music notation program. This has led to what he describes as an &quot;ongoing crisis in that industry.&quot;

This leads to my final thought of technologies that will stand the test of time. They&#39;re almost always open standards and/or open source. Any tech that relies on a single company is brittle. Yes, even DOC/DOCX and PDF. ®

The Register   Biting the hand that feeds IT

Copyright. All rights reserved © 1998–2025</div>
        </div>
        
        <div class="card" onclick="openModal('content-48')">
            <div class="source">The Verge</div>
            <div class="title">Net neutrality was back, until it wasn’t</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-48" style="display:none;">
            <h2>Net neutrality was back, until it wasn’t</h2>
            <p><strong>The Verge | 2025-12-31</strong></p>
            <a class="original-link" href="https://www.theverge.com/report/851629/net-neutrality-fcc-retrospective-2025">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">﻿The FCC is taking an ax to America’s broadband rules, even as some states are stepping up.

﻿The FCC is taking an ax to America’s broadband rules, even as some states are stepping up.

The fight for net neutrality never seems to be truly won or lost.

Federal net neutrality rules have been on and off for the past 15 years. The Federal Communications Commission (FCC) passed the Open Internet Order under President Barack Obama in 2010, prohibiting ISPs from blocking or throttling lawful internet traffic, the baseline rule of net neutrality. Then, at the request of those ISPs, a court blocked its rules. An updated framework was passed by the FCC in 2015, only to be overturned in 2017 under President Donald Trump’s first administration. It seemed poised for a comeback in 2024, but the victory lasted mere months before a court overturned it — kicking off a rough year for the open internet and broadband regulation as a whole.

Rather than fight the court’s ruling against net neutrality, the Trump administration’s FCC has preemptively removed the rules — without a chance for public comment. The move was part of FCC Chairman Brendan Carr’s “Delete, Delete, Delete” initiative, which aims to wipe out “unnecessary” regulations.

ISPs have long described net neutrality rules as onerous. For instance, USTelecom president and CEO Jonathan Spalter claimed the 2024 vote to reinstate the FCC’s net neutrality rules was a “counterproductive, unnecessary, and anti-consumer regulatory distraction.”

However, Matt Wood, vice president of policy and general counsel at the nonprofit Free Press, says in an interview with The Verge that ISPs often feel little financial impact from these rules, and may even already be complying with them. “A lot of cable and phone companies, when they talk to their business people and then go back to investors and to the financial analysts, they’re saying, ‘Yep, this is how we’re doing it anyway.’ So, I think a lot of their complaints about the supposed ‘burdens’ from these rules are really just ideological in nature.”

“A lot of their complaints about the supposed ‘burdens’ from these rules are really just ideological in nature.”

Why bother with regulations if ISPs are already (theoretically) compliant? It comes down to accountability and transparency. Regulations ensure voters, not ISPs, are setting the rules of the road online — otherwise, there’s nothing to stop them from changing their operations down the line.

The FCC’s anti-regulatory agenda for telecoms reaches even further than net neutrality. Chao Jun Liu, senior legislative associate at the nonprofit Electronic Frontier Foundation (EFF), notes the FCC’s recent move to reverse Biden-era telecom cybersecurity rules. Carr’s FCC also rolled back requirements for them to provide “nutrition labels” for their broadband pricing, claiming it was “burdensome” for ISPs to display those details.

“There is very much this theme of, ISPs just want to do whatever they want to do with no limits and nobody telling them how to do it, when to do it, [or] on what timeline,” Liu tells The Verge.

Federal regulations for ISPs seem to be dissolving like wet paper, but luckily they’re not the only line of defense for consumers.

“ISPs just want to do whatever they want to do with no limits and nobody telling them how to do it.”

State legislators took up net neutrality in the late 2010s, after the reversal of the FCC’s 2015 order. California’s 2018 net neutrality law, considered the nation’s gold standard, even includes some policies that were left out of the 2015 federal standards, like banning zero-rating, which allows ISPs to exempt certain apps or services from customers’ data caps. Several other states have adopted similar rules, including Washington, Oregon, Colorado, New Jersey, and Vermont.

The most recent repeal has prompted a new wave of these efforts. Maine passed a bipartisan net neutrality bill in June, without a signature from Gov. Janet Mills. A bill to expand “public utility” net neutrality rules to ISPs was also introduced in Pennsylvania in March. Similar bills were introduced in the New York state Senate and state Assembly this year as well.

ISPs have so far largely shied away from openly offering paid prioritization or conventional “fast lanes,” something supporters of net neutrality attribute at least partly to state-level regulations. “I think that state-level net neutrality laws, and the threat of new ones, has kept some of the worst outcomes in check,” says John Bergmayer, legal director at the nonprofit Public Knowledge, in a statement to The Verge.

This reluctance, however, could be changing. T-Mobile, Verizon, and AT&T all offer network slicing on their 5G networks, allowing certain customers (mainly businesses) to pay for virtual networks with higher speeds — which, while it doesn’t inherently violate net neutrality standards, could lay the groundwork for segmented networks.

State-level laws are the next target on the deregulation chopping block.

State-level laws are also the next target on the deregulation chopping block. In October, the National Telecommunications and Information Administration (NTIA) began a push to pressure states into exempting ISPs from their net neutrality laws in order to be eligible for funding from the Biden-era Broadband Equity, Access, and Deployment (BEAD) Program. In a speech at the Hudson Institute, NTIA administrator Arielle Roth called state-level net neutrality laws “a form of rate regulation,” the practice of determining what companies can charge for their services.

Accusations of rate regulation have become common, but Free Press’s Matt Wood argues that they’re overblown. While BEAD does prohibit rate regulation, state-level net neutrality laws don’t inherently fall under that label. Opponents of net neutrality “characterize any and every consumer safeguard as rate regulation when I don’t think it actually has any legitimate impact on the rates companies can charge for the services they offer in the broadband space,” says Wood.

And, again, this is part of a larger deregulatory agenda. EFF’s Chao Jun Liu pointed out similarities with efforts to leverage BEAD funds against AI regulation, including through a recently signed executive order. These attempts to connect AI regulation and broadband funding are “a new development,” says Liu. “This is very much a Brendan Carr, Trump administration special.”

At a time when broadband expansion remains vital, the Trump administration is threatening much-needed infrastructure funding to attack tech regulation. Unfortunately, despite being a bipartisan program, BEAD is where this debate is currently being played out. As Wood says, “Why are we making broadband deployment, which is pretty popular and pretty bipartisan, into yet another front in these culture wars?”

“Why are we making broadband deployment into yet another front in these culture wars?”

Legal experts have pointed out that Roth and the NTIA don’t necessarily have the authority to preempt state-level net neutrality laws for the sake of BEAD funding. However, it seems likely the debates over those funds will delay BEAD’s rollout even further and, along with it, the program’s mission to expand broadband development, particularly to underserved communities.

So, while the tug-of-war over net neutrality regulations continues, so do issues with broadband access in the US. Internet affordability is a persistent challenge across the country, but especially in rural areas where people often have only one or two providers to choose from. BEAD was intended to help address that issue, but now could get bogged down in debate over AI regulations.

Even in areas with robust internet access, high prices are still a problem, particularly since the Affordable Connectivity Program was shut down almost two years ago. On top of that, the US is experiencing a wave of bills that could roll out widespread age verification rules online, sparking debate about privacy, censorship, and free speech.

All of this — not just the fate of net neutrality — leaves the internet in a perilous state going into 2026.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-49')">
            <div class="source">The Verge</div>
            <div class="title">Leaked video shows the Galaxy S26 Ultra’s new camera island</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-49" style="display:none;">
            <h2>Leaked video shows the Galaxy S26 Ultra’s new camera island</h2>
            <p><strong>The Verge | 2025-12-31</strong></p>
            <a class="original-link" href="https://www.theverge.com/news/851931/samsung-galaxy-236-ultra-video-photo-leak">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">New photos and video seem to confirm previous leaks hinting that the Samsung Galaxy S26 Ultra will sport a new camera bump. OnLeaks posted images of what look like dummy phones on X, following renders it leaked back in September.

We’ve seen a similarly raised island on the Galaxy Z Fold 7, which 9to5Google points out could lead to an annoying wobble when using the device on a table.

More leaked renders in November appeared to show the Galaxy S26 Plus suddenly reappearing — also with a raised camera island — along with speculation it would take the place of a slimmer Edge model. The S26 series is expected to launch in February.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-50')">
            <div class="source">The Verge</div>
            <div class="title">The Dreame X40 Ultra robovac is about $700 off, nearly matching its best price</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-50" style="display:none;">
            <h2>The Dreame X40 Ultra robovac is about $700 off, nearly matching its best price</h2>
            <p><strong>The Verge | 2025-12-31</strong></p>
            <a class="original-link" href="https://www.theverge.com/gadgets/851325/dreame-x40-ultra-baseus-163w-retractable-car-charger-deal-sale">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Plus, we found deals on the Baseus 163W Retractable Car Charger and Apple’s Crossbody Strap.

Plus, we found deals on the Baseus 163W Retractable Car Charger and Apple’s Crossbody Strap.

If you buy something from a Verge link, Vox Media may earn a commission. See our ethics statement.

With the year coming to a close, now’s a good time to set yourself up for a cleaner, more organized start in 2026. The Dreame X40 Ultra — one of our favorite robot vacuum deals from Black Friday — can handle most of the heavy lifting for you, and it’s once again on sale. You can currently buy it for $503 ($697 off) at Amazon at checkout, which is just $4 more than its record low price set during Black Friday.

Before the Dreame X50 Ultra took its place, the X40 Ultra was our favorite robovac / mop hybrid for hard floors and carpets. Like the X50 Ultra, it delivers excellent mopping performance, thanks to dual oscillating mop pads that can extend into edges and reach under consoles and cabinets. It can also automatically detach and reattach its mop pads when switching between mopping and vacuuming.

While the X50 Ultra is nearly twice as powerful, the X40 Ultra’s 12,000Pa of suction is still more than capable of handling everyday dirt and debris. It also features AI-powered dirt detection, allowing the robot to slow down and make additional passes over especially dirty areas. What’s more, the X40 Ultra can empty its own dustbin, refill its water tank, and clean its washboard, with mop pads that wash and dry themselves for minimal upkeep.

What you don’t get are some of the newer X50 Ultra upgrades, including the motorized swing arm that lets it clear higher thresholds and the improved dual rubber roller brush system, which does a better job picking up fine debris. That said, the X40 Ultra still performed very well in our testing, making it a great investment — especially considering it now costs about half as much as its successor.

Sign up for Verge Deals to get deals on products we’ve tested sent to your inbox weekly.

Sign up for Verge Deals to get deals on products we’ve tested sent to your inbox weekly.</div>
        </div>
        
        <div class="card" onclick="openModal('content-51')">
            <div class="source">The Verge</div>
            <div class="title">Killing in the name of… nothing</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-51" style="display:none;">
            <h2>Killing in the name of… nothing</h2>
            <p><strong>The Verge | 2025-12-31</strong></p>
            <a class="original-link" href="https://www.theverge.com/policy/849609/charlie-kirk-shooting-ideology-literacy-politics">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Political violence has become illegible, and increasingly, politics and language have too.

In a good and just society, it would have been possible to bury Charlie Kirk without either threatening mass violence toward his enemies or making light of his death with a furry sex meme. But America in 2025 did not remotely resemble a working society, let alone a civil one, and Kirk’s killing came prepackaged with its own desecrating shitposts.

There was, briefly, an attempt at a national mood of somberness. The president ordered flags across the nation to be lowered to half-staff. Politicians, celebrities, and other public figures — even those not aligned with Kirk on the right — rushed out with condolences and grief, painting completely unrecognizable pictures of a man who was a once-in-a-generation talent at getting a rise out of other people. “Kirk was practicing politics in exactly the right way,” wrote the liberal pundit Ezra Klein in The New York Times, describing him as “one of the era’s most effective practitioners of persuasion.”

Kirk’s megachurch memorial service was well-attended, with additional solemnities elsewhere in the form of the ritual sacrifices of random people’s jobs. A Reuters investigation would later find more than 600 people who had been fired, suspended, or investigated for social media posts they made about Charlie Kirk — some of them merely quoting Kirk, a professional asshole who, among other things, pushed the “great replacement” theory and myths of white genocide.

Comedian Jimmy Kimmel became the most prominent victim of this crusade after making a fairly mild joke on his late night show. The actual upshot of the quip — which mocked Trump for his apparent disinterest in Kirk only days after the young man’s death — was completely ignored, and Kimmel was lambasted for showing insufficient grief over the newly canonized saint of MAGA. The chair of the Federal Communications Commission, Brendan Carr, successfully threatened Disney into taking Kimmel off the air — only to be mogged by the general public, which berated Disney into reinstating Kimmel’s show.

In a sense, this circus was business as usual. The amnesia of the elites, the tone-policing witch hunts, the pageantry of memorialization: these are the reflexive acts of a society on the verge of launching a systemic assault on civil liberties. But as much as the right wing tried to channel 9/11, and as much as corporations and media organizations and left-wing politicians played along, something about the way Americans communicate with each other was fundamentally different. Perhaps the first indication of where we were as a country was a video posted by a TikTok user at the Utah Valley University event, recorded just moments after the shooting. “It’s your boy, Elder TikTok!” he shouted. “Shots fired!”

“It’s your boy, Elder TikTok!” he shouted. “Shots fired!”

Despite the mass reprisals against Kirk’s shitposting detractors over the following weeks and months, the memeing continued apace. And very shortly after Kirk’s death, influencers on the right-wing fringe — like Candace Owens and Nick Fuentes — had almost compulsively fallen into conspiratorial theorizing about the shooting, their instincts settling the blame on (of course) Israel. Even the center of MAGA could not hold; the long, sustained sainting of Kirk was simply too incongruous with the deportation ASMR memes. Vice President JD Vance tried to stick with the serious tone — now, months later, he is the subject of an AI slop musical tribute to Kirk that has gone viral on TikTok, with the soaring hook (“We are Charlie Kiiiiiiiiiiirk”) a popular target for mockery.

2025 has been defined by Charlie Kirk, though not by what Charlie Kirk espoused, nor who he was, nor who his allies purport him to have been. The hysteria, the inanity, and the sheer incoherence surrounding his death has become emblematic of America. It took a decade before 9/11 jokes could really land, but Kirk’s death had been turned into a joke before the bullet even hit him. Politics is fully immersed in its postliterate era, and political violence, too, has become illegible.

Two days after Kirk was shot, law enforcement announced the arrest of his alleged killer. In a press conference, the governor of the state of Utah proceeded to read out loud a series of internet memes that had been scratched into bullet casings recovered with the alleged weapon.

The first — “notices bulge OWO what’s this?” — was a mocking reference to furry online sexual roleplay. The next, which ominously opened with “Hey fascist, catch,” ended with a series of arrows encoding a button combo strike in the video game Helldivers 2, a third-person shooter that satirizes fascism. The one after that was a reference to the Italian song “Bella ciao” (historically an antifascist anthem but also a generally catchy jingle). The governor wrapped up the list with the most ignominious possible conclusion, saying, “if you read this you are gay lmao,” making sure to carefully spell out each of the letters in the final abbreviation.

This should be understood as a genuinely humiliating moment for America, one in which our elected leaders succumbed to the murderous version of calling Moe’s Tavern and asking for Heywood Jablome. A civilized society does not heap furry sex memes on top of a grave.

Yet this act of vandalism on American dignity was the most responsible act the governor could undertake, given the circumstances. Just 24 hours earlier, someone — presumably in law enforcement — had leaked an internal bulletin to right-wing influencer Steven Crowder. “All cartridges have engraved wording on them, expressing transgender and anti-fascist ideology,” the memo said.

A civilized society does not heap furry sex memes on top of a grave

By reading aloud the messages on the bullets, the governor was broadcasting the closest thing to a manifesto for the alleged shooter. But he was also providing transparency into an investigation that had been riddled with irresponsible leaks and flagrant missteps. In the hours after the killing, FBI Director Kash Patel had shot off a quickfire post on X to declare that a suspect had been taken into custody, only for the FBI to have to announce, shortly thereafter, that that person was not a suspect and had been released. When Crowder published his ATF leak, the rumor that the shooter was trans exploded out of control. In carefully engaging with the truth of the bullets, Cox — probably unknowingly, given his remarks the following day — exonerated a vulnerable and politically persecuted community that is frequently slandered with falsely attributed mass shootings.

The right then attempted to pin the shooting on the shadowy forces of antifa, using “Hey fascist, catch” and “Bella ciao” as justification. Two weeks later, Trump would sign an executive order designating antifa a domestic terror organization (a designation that doesn’t exist) and then issue a national presidential security memorandum directing various departments and agencies to launch an expansive war on antifa. (The war on antifa is inextricable from Trump’s war on the English language, because, if you are literate, his opposition to anti-fascism necessarily raises the question of what Trumpism actually is.)

On a memorial episode of Kirk’s podcast, Stephen Miller, appearing alongside JD Vance, swore vengeance on the “networks” backing antifa. “With God as my witness, we are going to use every resource we have at the Department of Justice, Homeland Security, and throughout this government to identify, disrupt, dismantle, and destroy these networks and make America safe again for the American people. It will happen, and we will do it in Charlie’s name.”

Aside from the ambiguous bullet casings, there’s no apparent evidence that Kirk’s accused killer is antifa — there is neither a forthright declaration of political motivation, nor a total absence of it. One affidavit points to a romantic relationship being the motive; this is hardly made clear in any piece of writing by alleged shooter Tyler Robinson, let alone the infamous bullets. “remember how I was engraving bullets?” Robinson allegedly texted a friend. “The fuckin messages are mostly a big meme, if I see ‘notices bulge uwu’ on fox new I might have a stroke.”

We understand these acts of violence as political because of the circumstances more than anything else

There’s a reason why, under normal circumstances, broadcasting those types of details is considered bad form — such details have a tendency to spark copycat killings. Two weeks after Charlie Kirk was killed, a gunman opened fire at an ICE field office in Dallas, killing a detainee and wounding others before taking his own life. The alleged shooter, Joshua Jahn, left no manifesto that we know of, but an unused bullet — according to a photo released by law enforcement — had the phrase “ANTI-ICE” written on it in what looks like pen or marker.

The tonal weirdness of this micro-manifesto immediately led internet posters to compare the message on the bullets to a 2015 alleged hate crime in Mississippi where the phrase “Blacks Rule” had been spray-painted onto a driveway. Neither phrase is in common parlance; each is so jarring that it makes “hello my fellow kids” sound like convincing zoomer lingo. The fact that only a detainee and the shooter himself had been killed made the incident seem even more suspicious, especially to internet audiences (on both the right and the left) that had already spun themselves up into concocting conspiracy theories about Kirk’s killing.

Jahn’s brother told NBC News that his sibling “didn’t have strong feelings about ICE” and that “he wasn’t interested in politics on either side as far as I knew.” Independent journalist Ken Klippenstein reported that one of Jahn’s Steam handles was “#Impeachment,” presumably a reference to impeaching Trump. Some of his anonymous sources — apparently friends of Jahn’s — emphasize that this was an “ironic” mockery of earnest resistance libs. But another source made a subtle differentiation: “If it was ironic, it’s that half irony — where you’re half-kidding, half-serious, just in case.”

Individuals’ politics are often in flux, and the kind of person who willfully kills another is not, one might say, engaging with the world as they did before. Nevertheless, Jahn (born 1996) did not leave behind much in the way of a point of view; the same goes for Robinson (born 2003). We understand their acts of violence as political because of the circumstances more than anything else.

The apparent laconicism of this pair of zoomer killers is striking, given the wordiness of their predecessors. Even Luigi Mangione (born 1998) — accused of assassinating UnitedHealthcare CEO Brian Thompson last year — allegedly left a 260+ word missive for “the feds.” (That would be half a page if typed; it was handwritten, and so poorly that portions are indecipherable.) Over time, political killers have had less and less to say.

Anders Breivik (born 1979), who killed 77 people in Norway in 2011, left a 1,518 page manifesto. The 2019 Christchurch, New Zealand shooter (born 1990) left behind 74 pages. The 2019 El Paso shooter (born 1998) 10 pages; the 2022 Buffalo shooter (born 2003) left 180 pages that were extensively plagiarized from both Breivik and the Unabomber Ted Kaczynski.

Politics has become divorced from reality and reason

Perhaps this is not surprising. Literacy has been in steep decline in many parts of the world, including the United States, where most of these men were. A study that took place in 2015 tested a pool of undergraduates on how well they understood the opening of Charles Dickens’ Bleak House and concluded that over half “understood so little” that “they would not be able to read the novel on their own.” Of course, Dickens is not exactly known for his clear, legible prose — but alarmingly, the students in the study were English majors. High schools assign fewer books cover-to-cover, with the result that college students arrive at university and struggle to read a full book. The stresses of the pandemic and remote learning, too, left an indelible mark on the education of an entire cohort. As Gen Z grows older, zoomer parents report that they don’t like reading to their own children. A study published this year says that reading for pleasure is down 40 percent.

At the same time, politics has gotten more divorced from reality and reason. The results are dizzying when the sheer brainrot of the Trump administration collides with judges who are still operating under the assumption that words should mean things and refer to real objects. “We rule on facts, not on supposition or conjecture, and certainly not on fabrication or propaganda,” wrote a distraught appeals court judge in the lawsuit over Trump’s attempt to send the National Guard into Portland, Oregon. (She was the dissenting voice on the panel; the other two judges, Trump appointees, ruled in favor of allowing the president to send in the Guard.)

But incoherence has become an entirely normal property of politics, and incoherent violence — the ICE raids, third country deportations, drone boat strikes — is central, rather than incidental, to the political system. In this sense, the subliterate zoomer killers are not at the fringe of society, but are the epitome of it.

The media has spent the last few months trying to make sense out of nonsense, attempting to conjure motive, manifesto, and meaning out of the dumbest shit scrawled onto bullets. These were sad attempts to impose meaning on an increasingly incoherent world by a literati that has not yet accepted its irrelevance in a postliterate society. But the most humiliating display of literate obliviousness in the face of the total collapse of meaning, however, was Ezra Klein’s bizarre eulogy to Charlie Kirk. The now-infamous column (“Charlie Kirk Was Practicing Politics the Right Way”) can best be understood as an expression of class solidarity. Klein, I would argue, sees both himself and Kirk as being Debate Guys, wordcels who engage in the marketplace of ideas and let speech sort itself out into political action.

Ezra Klein is an artifact of the politics of literacy, a paradigm that is waning faster than my fingers can type these useless, useless words. But Charlie Kirk’s Debate Guy persona was a meme layered on top of sophisticated machinery. His Talking Points USA and Professor Watchlist were very much about action in the real world. In one deleted tweet, Kirk claimed that TPUSA had sent “80+ buses full of patriots” to DC for what would become the January 6th insurrection.

Kirk’s podcast was a form of infrastructure, one controlled by Kirk, and not The New York Times or another brand. The parasocial relationships he built with his audience granted him direct access to President Donald Trump. Kirk understood that his nonviolent engagement with the public was a form of amusement to fill the void, a conversion mechanism to boost subscriber rates, imbued with as much meaning as a daily crossword puzzle or Wordle.

Kirk did not commit violence, not because he abhorred it, but because committing violence was someone else’s job. Last year, he called for using whips against migrants, saying, “Of course you should be able to use whips against foreigners that are coming into your country. Why is that controversial?” In early June of this year, as the president deployed troops to Los Angeles, Kirk publicly advocated for invoking the Insurrection Act of 1807 to crush the immigration protests. And in August, he called for “federalizing” the district of Columbia, saying, “Roll in the tanks, bring in the military.”

With his close relationship to the commander in chief of the United States of America, Charlie Kirk was no mere talker, idea-peddler, or purveyor of discourse. He built an empire on legitimizing violence and harvesting the enthusiasm and glee around it. Even before his death became a pretext to enact violence on American cities, he had already substantively shaped history. Charlie Kirk was a part of the real world in a way that Ezra Klein will never be.

One might even say that Kirk already understood that the future of politics was aura farming and shitposting, switching fluidly between calling for “massive indictments” against Trump’s political enemies and telling Taylor Swift to “submit to your husband.” For Kirk and for much of society today, words are not expressions with referents, but rather, performative speech acts with specific functions — in his case, owning the libs.

You do not bring a persuasive argument to a gunfight

The most significant resistance to Trumpism, too, appears to be abandoning the realm of literate politics; after all, you do not bring a persuasive argument to a gunfight. In Portland, Oregon, inflatable frog suits — a symbol imbued with no inherent meaning or political point of view — became de rigueur. But perhaps the most telling sign is that resistance against ICE in Chicago and New York is best expressed not in slogans but in whistles and car honks.

It’s useless to call for civil debate as “politics in the right way”; politics has moved beyond words. Where there are words at all, they are but a way to express a meme, a vibe, an aesthetic. They are a method to channel brainrot, like any other medium of communication. To expect words to mean words, for them to attach to objects in time and space and to line up with any internal logic — this is the sort of cringe that will fade into the periphery along with the millennial pause, that half-second of silence where the older generation gathers their thoughts.

And we can understand this rise in political violence as something that exists on the same wavelength as the illegible politics that govern our society today. Like bombing shipwrecked sailors in the name of fighting drug trafficking, it is action for action’s sake, as crass and consequential as a Pokémon deportation meme.

A post, a podcast, a screenshot, a meme, a whistle, a bullet — in all things, only the medium is the message.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-52')">
            <div class="source">The Verge</div>
            <div class="title">The 11 best Nintendo Switch 2 games we played in 2025</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-52" style="display:none;">
            <h2>The 11 best Nintendo Switch 2 games we played in 2025</h2>
            <p><strong>The Verge | 2025-12-31</strong></p>
            <a class="original-link" href="https://www.theverge.com/games/845401/nintendo-switch-2-best-games">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">If you unwrapped Nintendo’s powerful Switch 2 during the holidays, we have opinions on which games you should play.

If you unwrapped Nintendo’s powerful Switch 2 during the holidays, we have opinions on which games you should play.

2025 was a big year for gaming, and that includes gaming hardware. Nintendo launched its Switch 2 console in June, and since then, numerous Switch 2 titles and noteworthy updates for original Switch games have launched. These include brand-new Nintendo experiences like Mario Kart World and Donkey Kong Bananza, as well as some belated but welcome third-party titles, including Cyberpunk 2077 and Divinity: Original Sin 2. Even classics like The Legend of Zelda: Breath of the Wild got some new life on the upgraded console.

If you’re considering buying a console, or you’re getting one for someone else, there are 11 games that we think are a must-buy for any Switch 2 owner.

So what if Mario Kart World comes in the box with the $499 Switch 2 bundle? It’s still so easy to recommend because few other games match the briskness at which it just lets you get going and have fun. The latest entry in Nintendo’s top-selling racing franchise adds many new characters, an open-world single-player mode, unique interconnected courses, and a lot more.

One of the best ways to play the original Hollow Knight was on a Nintendo Switch, so it’s no surprise that the Switch 2 is a great way to enjoy the long-awaited sequel, Silksong. The side-scrolling action exploration game looks fantastic, and its gorgeous animations are easier to appreciate thanks to the console’s 120Hz refresh rate screen.

Before Larian Studios made Baldur’s Gate 3, it was best known for its Divinity series. The developers recently announced a reboot of the RPG franchise, but for now, the closest thing to BG3 that Switch 2 owners can experience right now is Divinity: Original Sin 2, a fantastic RPG that first launched in late 2017. It just got a free Switch 2 update that enhances visuals and reduces slowdown, and I highly recommend playing it.

The team that developed Super Mario Odyssey clearly had a ball with its most recent game, Donkey Kong Bananza. It’s just as ambitious in terms of level design, giving Donkey Kong several unique powers of transformation. But it’s significantly more destructive, letting him demolish everything in sight with his fists or punch through the ground to get around obstacles.

You know Nintendo did something right with the Switch 2 when the graphics showcase Cyberpunk 2077 shows up as a launch game. The first-person-shooter-meets-RPG plays well on the system, especially when you use the Joy-Con 2 in mouse mode, which makes it feel a bit like the PC version. This version of the game includes the excellent Phantom Liberty DLC that adds even more action, plus Idris Elba.

After nearly a decade in development, the first new Metroid Prime game in nearly 20 years is now available for the Switch 2. It runs at glorious 4K on the new hardware (or up to 120 frames per second in 1080p), but beyond looks, it’s great to be back in Samus Aran’s butt-kicking boots again. This time, she’s got the Vi-O-La motorcycle for getting around the desert terrain that connects the main dungeons. The story and exploration may not have the same magic as the original Prime, but its best parts are still worth paying the price of admission to experience.

Splatoon 3 was already a fun game on the original Switch, but it’s even better with the free Switch 2 update. With faster loading speeds and better-looking visuals, you owe it to yourself to make a splashy mess in its fun single-player campaign and online multiplayer modes.

The release of the Switch 2 made old things new again. For example, the original Switch launch title The Legend of Zelda: Breath of the Wild has never looked or played better than it does in the new Switch 2 Edition, which costs $10 if you own the Switch game or $70 by itself (the upgrade is free if you have Switch Online + Expansion Pack). Faster frame rates, speedier loading times, better visuals, and a GPS-style mobile app feature make this one feel like a breath of fresh air.

Rockstar Games’ open-world Western was late to hit the original Switch, but the new (and free) Switch 2 update makes it shine in some surprising ways. Not only does it boost the visuals and performance thanks to the new console’s more powerful specs, it adds a PC-like mouse mode to make it much easier to aim (and more fun to play).

If you’ve never played No Man’s Sky, can we switch brains so I can experience it again for the first time? The space exploration game with an infinite universe (made possible via procedural generation that makes each player’s experience unique) is one of gaming’s biggest success stories in recent years. The developers pile on numerous substantive updates each year, making this an excellent game to play, whether you want to chill or engage in building a space empire. Oh, and the Switch 2 update is free for those who own the base game.

Fortnite is the only game on this list that’s free to play, but that doesn’t make it one that you should pass up. Epic Games’ battle royale-style shooter is a cultural juggernaut that includes characters representing a huge array of fandoms. The Switch 2 port makes it feel like an entirely different game than the original Switch version. You can drop in as a character from Dragon Ball Z, lock and load as your favorite family member from The Simpsons, or assume the role of Sabrina Carpenter or Kim Kardashian, to name some of the literally dozens of tie-ins that are fun to see in-game.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-53')">
            <div class="source">The Verge</div>
            <div class="title">Two cybersecurity employees plead guilty to carrying out ransomware attacks</div>
            <div class="meta">2025-12-30</div>
        </div>
        
        <div id="content-53" style="display:none;">
            <h2>Two cybersecurity employees plead guilty to carrying out ransomware attacks</h2>
            <p><strong>The Verge | 2025-12-30</strong></p>
            <a class="original-link" href="https://www.theverge.com/news/851467/cybersecurity-employees-plead-guilty-alphv-blackcat-ransomware">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">The pair targeted several companies with ALPHV / BlackCat ransomware and extorted $1.2 million in Bitcoin.

The pair targeted several companies with ALPHV / BlackCat ransomware and extorted $1.2 million in Bitcoin.

Two former employees at cybersecurity firms — one of whom was a ransomware negotiator — have pleaded guilty to carrying out a series of ransomware attacks in 2023. The Department of Justice announced the guilty pleas on Tuesday, saying 40-year-old Ryan Goldberg and 36-year-old Kevin Martin extorted $1.2 million in Bitcoin from a medical device company and targeted several others.

Goldberg, Martin, and an unnamed co-conspirator were indicted for the attacks in October, which involved using ALPHV / BlackCat ransomware to encrypt and steal data from their victims. As reported by the Chicago Sun-Times, Martin and the third conspirator worked as ransomware negotiators at Digital Mint, a cybercrime and incident response company, while Goldberg was an incident response manager at Sygnia Cybersecurity Services.

ALPHV / BlackCat is a hacker group that uses a ransomware-as-a-service model, with the developers who maintain the malware often taking a cut of stolen funds from the cybercriminals who use it to target victims. In 2023, the FBI developed a decryption tool designed to recover data from victims of ALPHV / BlackCat, which has been linked to high-profile attacks on companies like Bandai Namco, MGM Resorts, Reddit, and UnitedHealth Group.

The DOJ’s indictment claims Goldberg, Martin, and the co-conspirator used the ransomware in an attempt to extort millions of dollars from victims throughout the US, including a pharmaceutical company, a doctor’s office, an engineering company, and a drone manufacturer.

“These defendants used their sophisticated cybersecurity training and experience to commit ransomware attacks — the very type of crime that they should have been working to stop,” Assistant Attorney General A. Tysen Duva of the DOJ’s Criminal Division says in a statement. “The Department of Justice is committed to using all tools available to identify and arrest perpetrators of ransomware attacks wherever we have jurisdiction.”

Goldberg and Martin pleaded guilty to one count of “conspiracy to obstruct, delay, or affect commerce or the movement of any article or commodity in commerce by extortion.” Their sentencing is scheduled for March 12th, 2026, where they’ll face up to 20 years in prison.

A free daily digest of the news that matters most.</div>
        </div>
        
        <div class="card" onclick="openModal('content-54')">
            <div class="source">MIT Technology Review</div>
            <div class="title">Why inventing new emotions feels so good</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-54" style="display:none;">
            <h2>Why inventing new emotions feels so good</h2>
            <p><strong>MIT Technology Review | 2025-12-31</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2025/12/31/1129403/new-emotions-online-life-feelings/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">It’s a “complex and subtle emotion that elicits feelings of comfort, serenity, and a gentle sense of floating.” It’s peaceful, but more ephemeral and intangible than contentment. It might be evoked by the sight of a sunset or a moody, low-key album.

If you haven’t ever felt this sensation—or even heard of it—that’s not surprising. A Reddit user named noahjeadie generated it with ChatGPT, along with advice on how to evoke the feeling. With the right essential oils and soundtrack, apparently, you too can feel like “a soft fuzzy draping ghost floating through a lavender suburb.”

Don’t scoff: Researchers say more and more terms for these “neo-­emotions” are showing up online, describing new dimensions and aspects of feeling. Velvetmist was a key example in a journal article about the phenomenon published in July 2025. But most neo-emotions aren’t the inventions of emo artificial intelligences. Humans come up with them, and they’re part of a big change in the way researchers are thinking about feelings, one that emphasizes how people continuously spin out new ones in response to a changing world.

Velvetmist might’ve been a chatbot one-off, but it’s not unique. The sociologist Marci Cottingham—whose 2024 paper got this vein of neo-emotion research started—cites many more new terms in circulation. There’s “Black joy” (Black people celebrating embodied pleasure as a form of political resistance), “trans euphoria” (the joy of having one’s gender identity affirmed and celebrated), “eco-anxiety” (the hovering fear of climate disaster), “hypernormalization” (the surreal pressure to continue performing mundane life and labor under capitalism during a global pandemic or fascist takeover), and the sense of “doom” found in “doomer” (one who is relentlessly pessimistic) or “doomscrolling” (being glued to an endless feed of bad news in an immobilized state combining apathy and dread).

Of course, emotional vocabulary is always evolving. During the Civil War, doctors used the centuries-old term “nostalgia,” combining the Greek words for “returning home”and “pain,” to describe a sometimes fatal set of symptoms suffered by soldiers—a condition we’d probably describe today as post-traumatic stress disorder. Now nostalgia’s meaning has mellowed and faded to a gentle affection for an old cultural product or vanished way of life. And people constantly import emotion words from other cultures when they’re convenient or evocative—like hygge (the Danish word for friendly coziness) or kvell (a Yiddish term for brimming over with happy pride).

Cottingham believes that neo-­emotions are proliferating as people spend more of their lives online. These coinages help us relate to one another and make sense of our experiences, and they get a lot of engagement on social media. So even when a neo-emotion is just a subtle variation on, or combination of, existing feelings, getting super-specific about those feelings helps us reflect and connect with other people. “These are potentially signals that tell us about our place in the world,” she says.

These neo-emotions are part of a paradigm shift in emotion science. For decades, researchers argued that humans all share a set of a half-dozen or so basic emotions. But over the last decade, Lisa Feldman Barrett, a clinical psychologist at Northeastern University, has become one of the most cited scientists in the world for work demonstrating otherwise. By using tools like advanced brain imaging and studying babies and people from relatively isolated cultures, she has concluded there’s no such thing as a basic emotional palette. The way we experience and talk about our feelings is culturally determined. “How do you know what anger and sadness and fear are? Because somebody taught you,” Barrett says.

If there are no true “basic” biological emotions, this puts more emphasis on social and cultural variations in how we interpret our experiences. And these interpretations can change over time. “As a sociologist, we think of all emotions as created,” Cottingham says. Just like any other tool humans make and use, “emotions are a practical resource people are using as they navigate the world.”

Some neo-emotions, like velvetmist, might be mere novelties. Barrett playfully suggests “chiplessness” to describe the combined hunger, frustration, and relief of getting to the bottom of the bag. But others, like eco-anxiety and Black joy, can take on a life of their own and help galvanize social movements.

Both reading about and crafting your own neo-emotions, with or without chatbot assistance, could be surprisingly helpful. Lots of research supports the benefits of emotional granularity. Basically, the more detailed and specific words you can use to describe your emotions, both positive and negative, the better.

Researchers analogize this “emodiversity” to biodiversity or cultural diversity, arguing that a more diverse world is more enriched. It turns out that people who exhibit higher emotional granularity go to the doctor less frequently, spend fewer days hospitalized for illness, and are less likely to drink when stressed, drive recklessly, or smoke cigarettes. And many studies show emodiversity is a skill that, with training, people can develop at any age. Just imagine cruising into this sweet, comforting future. Is the idea giving you a certain dreamy thrill?

Are you sure you’ve never felt velvetmist?

Anya Kamenetz is a freelance education reporter who writes the Substack newsletter The Golden Hour.

The Cybertruck, sycophantic AI, and humanoid robots all made this year’s list of the biggest technology failures.

Unveiled by the buzzy startup Deep, Vanguard will let teams of scientists live and work on the seabed for a week at a time.

We’ll keep following these developments, but this just wasn’t their year. Here’s why.

It’s free and easy to nominate yourself or someone you know—here’s how.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-55')">
            <div class="source">MIT Technology Review</div>
            <div class="title">The ascent of the AI therapist</div>
            <div class="meta">2025-12-30</div>
        </div>
        
        <div id="content-55" style="display:none;">
            <h2>The ascent of the AI therapist</h2>
            <p><strong>MIT Technology Review | 2025-12-30</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2025/12/30/1129392/book-reviews-ai-therapy-mental-health/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">We’re in the midst of a global mental-­health crisis. More than a billion people worldwide suffer from a mental-health condition, according to the World Health Organization. The prevalence of anxiety and depression is growing in many demographics, particularly young people, and suicide is claiming hundreds of thousands of lives globally each year.

Given the clear demand for accessible and affordable mental-health services, it’s no wonder that people have looked to artificial intelligence for possible relief. Millions are already actively seeking therapy from popular chatbots like OpenAI’s ChatGPT and Anthropic’s Claude, or from specialized psychology apps like Wysa and Woebot. On a broader scale, researchers are exploring AI’s potential to monitor and collect behavioral and biometric observations using wearables and smart devices, analyze vast volumes of clinical data for new insights, and assist human mental-health professionals to help prevent burnout.

But so far this largely uncontrolled experiment has produced mixed results. Many people have found solace in chatbots based on large language models (LLMs), and some experts see promise in them as therapists, but other users have been sent into delusional spirals by AI’s hallucinatory whims and breathless sycophancy. Most tragically, multiple families have alleged that chatbots contributed to the suicides of their loved ones, sparking lawsuits against companies responsible for these tools. In October, OpenAI CEO Sam Altman revealed in a blog post that 0.15% of ChatGPT users “have conversations that include explicit indicators of potential suicidal planning or intent.” That’s roughly a million people sharing suicidal ideations with just one of these software systems every week.

The real-world consequences of AI therapy came to a head in unexpected ways in 2025 as we waded through a critical mass of stories about human-chatbot relationships, the flimsiness of guardrails on many LLMs, and the risks of sharing profoundly personal information with products made by corporations that have economic incentives to harvest and monetize such sensitive data.

Several authors anticipated this inflection point. Their timely books are a reminder that while the present feels like a blur of breakthroughs, scandals, and confusion, this disorienting time is rooted in deeper histories of care, technology, and trust.

LLMs have often been described as “black boxes” because nobody knows exactly how they produce their results. The inner workings that guide their outputs are opaque because their algorithms are so complex and their training data is so vast. In mental-health circles, people often describe the human brain as a “black box,” for analogous reasons. Psychology, psychiatry, and related fields must grapple with the impossibility of seeing clearly inside someone else’s head, let alone pinpointing the exact causes of their distress.

These two types of black boxes are now interacting with each other, creating unpredictable feedback loops that may further impede clarity about the origins of people’s mental-­health struggles and the solutions that may be possible. Anxiety about these developments has much to do with the explosive recent advances in AI, but it also revives decades-old warnings from pioneers such as the MIT computer scientist Joseph Weizenbaum, who argued against computerized therapy as early as the 1960s.

Charlotte Blease, a philosopher of medicine, makes the optimist’s case in Dr. Bot: Why Doctors Can Fail Us—and How AI Could Save Lives. Her book broadly explores the possible positive impacts of AI in a range of medical fields. While she remains clear-eyed about the risks, warning that readers who are expecting “a gushing love letter to technology” will be disappointed, she suggests that these models can help relieve patient suffering and medical burnout alike.

“Health systems are crumbling under patient pressure,” Blease writes. “Greater burdens on fewer doctors create the perfect petri dish for errors,” and “with palpable shortages of doctors and increasing waiting times for patients, many of us are profoundly frustrated.”

Blease believes that AI can not only ease medical professionals’ massive workloads but also relieve the tensions that have always existed between some patients and their caregivers. For example, people often don’t seek needed care because they are intimidated or fear judgment from medical professionals; this is especially true if they have mental-health challenges. AI could allow more people to share their concerns, she argues.

But she’s aware that these putative upsides need to be weighed against major drawbacks. For instance, AI therapists can provide inconsistent and even dangerous responses to human users, according to a 2025 study, and they also raise privacy concerns, given that AI companies are currently not bound by the same confidentiality and HIPAA standards as licensed therapists.

While Blease is an expert in this field, her motivation for writing the book is also personal: She has two siblings with an incurable form of muscular dystrophy, one of whom waited decades for a diagnosis. During the writing of her book, she also lost her partner to cancer and her father to dementia within a devastating six-month period. “I witnessed first-hand the sheer brilliance of doctors and the kindness of health professionals,” she writes. “But I also observed how things can go wrong with care.”

A similar tension animates Daniel Oberhaus’s engrossing book The Silicon Shrink: How Artificial Intelligence Made the World an Asylum. Oberhaus starts from a point of tragedy: the loss of his younger sister to suicide. As Oberhaus carried out the “distinctly twenty-first-century mourning process” of sifting through her digital remains, he wondered if technology could have eased the burden of the psychiatric problems that had plagued her since childhood.

“It seemed possible that all of this personal data might have held important clues that her mental health providers could have used to provide more effective treatment,” he writes. “What if algorithms running on my sister’s smartphone or laptop had used that data to understand when she was in distress? Could it have led to a timely intervention that saved her life? Would she have wanted that even if it did?”

This concept of digital phenotyping—in which a person’s digital behavior could be mined for clues about distress or illness—seems elegant in theory. But it may also become problematic if integrated into the field of psychiatric artificial intelligence (PAI), which extends well beyond chatbot therapy.

Oberhaus emphasizes that digital clues could actually exacerbate the existing challenges of modern psychiatry, a discipline that remains fundamentally uncertain about the underlying causes of mental illnesses and disorders. The advent of PAI, he says, is “the logical equivalent of grafting physics onto astrology.” In other words, the data generated by digital phenotyping is as precise as physical measurements of planetary positions, but it is then integrated into a broader framework—in this case, psychiatry—that, like astrology, is based on unreliable assumptions.

Oberhaus, who uses the phrase “swipe psychiatry” to describe the outsourcing of clinical decisions based on behavioral data to LLMs, thinks that this approach cannot escape the fundamental issues facing psychiatry. In fact, it could worsen the problem by causing the skills and judgment of human therapists to atrophy as they grow more dependent on AI systems.

He also uses the asylums of the past—in which institutionalized patients lost their right to freedom, privacy, dignity, and agency over their lives—as a touchstone for a more insidious digital captivity that may spring from PAI. LLM users are already sacrificing privacy by telling chatbots sensitive personal information that companies then mine and monetize, contributing to a new surveillance economy. Freedom and dignity are at stake when complex inner lives are transformed into data streams tailored for AI analysis.

AI therapists could flatten humanity into patterns of prediction, and so sacrifice the intimate, individualized care that is expected of traditional human therapists. “The logic of PAI leads to a future where we may all find ourselves patients in an algorithmic asylum administered by digital wardens,” Oberhaus writes. “In the algorithmic asylum there is no need for bars on the window or white padded rooms because there is no possibility of escape. The asylum is already everywhere—in your homes and offices, schools and hospitals, courtrooms and barracks. Wherever there’s an internet connection, the asylum is waiting.”

Eoin Fullam, a researcher who studies the intersection of technology and mental health, echoes some of the same concerns in Chatbot Therapy: A Critical Analysis of AI Mental Health Treatment. A heady academic primer, the book analyzes the assumptions underlying the automated treatments offered by AI chatbots and the way capitalist incentives could corrupt these kinds of tools.

Fullam observes that the capitalist mentality behind new technologies “often leads to questionable, illegitimate, and illegal business practices in which the customers’ interests are secondary to strategies of market dominance.”

That doesn’t mean that therapy-bot makers “will inevitably conduct nefarious activities contrary to the users’ interests in the pursuit of market dominance,” Fullam writes.

But he notes that the success of AI therapy depends on the inseparable impulses to make money and to heal people. In this logic, exploitation and therapy feed each other: Every digital therapy session generates data, and that data fuels the system that profits as unpaid users seek care. The more effective the therapy seems, the more the cycle entrenches itself, making it harder to distinguish between care and commodification. “The more the users benefit from the app in terms of its therapeutic or any other mental health intervention,” he writes, “the more they undergo exploitation.”

This sense of an economic and psychological ouroboros—the snake that eats its own tail—serves as a central metaphor in Sike, the debut novel from Fred Lunzer, an author with a research background in AI.

Described as a “story of boy meets girl meets AI psychotherapist,” Sike follows Adrian, a young Londoner who makes a living ghostwriting rap lyrics, in his romance with Maquie, a business professional with a knack for spotting lucrative technologies in the beta phase.

The title refers to a splashy commercial AI therapist called Sike, uploaded into smart glasses, that Adrian uses to interrogate his myriad anxieties. “When I signed up to Sike, we set up my dashboard, a wide black panel like an airplane’s cockpit that showed my daily ‘vitals,’” Adrian narrates. “Sike can analyze the way you walk, the way you make eye contact, the stuff you talk about, the stuff you wear, how often you piss, shit, laugh, cry, kiss, lie, whine, and cough.”

In other words, Sike is the ultimate digital phenotyper, constantly and exhaustively analyzing everything in a user’s daily experiences. In a twist, Lunzer chooses to make Sike a luxury product, available only to subscribers who can foot the price tag of £2,000 per month.

Flush with cash from his contributions to a hit song, Adrian comes to rely on Sike as a trusted mediator between his inner and outer worlds. The novel explores the impacts of the app on the wellness of the well-off, following rich people who voluntarily commit themselves to a boutique version of the digital asylum described by Oberhaus.

The only real sense of danger in Sike involves a Japanese torture egg (don’t ask). The novel strangely sidesteps the broader dystopian ripples of its subject matter in favor of drunken conversations at fancy restaurants and elite dinner parties.

The sudden ascent of the AI therapist seems startlingly futuristic, as if it should be unfolding in some later time when the streets scrub themselves and we travel the world through pneumatic tubes.

Sike’s creator is simply “a great guy” in Adrian’s estimation, despite his techno-messianic vision of training the app to soothe the ills of entire nations. It always seems as if a shoe is meant to drop, but in the end, it never does, leaving the reader with a sense of non-resolution.

While Sike is set in the present day, something about the sudden ascent of the AI therapist—­in real life as well as in fiction—seems startlingly futuristic, as if it should be unfolding in some later time when the streets scrub themselves and we travel the world through pneumatic tubes. But this convergence of mental health and artificial intelligence has been in the making for more than half a century. The beloved astronomer Carl Sagan, for example, once imagined a “network of computer psychotherapeutic terminals, something like arrays of large telephone booths” that could address the growing demand for mental-health services.

Oberhaus notes that one of the first incarnations of a trainable neural network, known as the Perceptron, was devised not by a mathematician but by a psychologist named Frank Rosenblatt, at the Cornell Aeronautical Laboratory in 1958. The potential utility of AI in mental health was widely recognized by the 1960s, inspiring early computerized psychotherapists such as the DOCTOR script that ran on the ELIZA chatbot developed by Joseph Weizenbaum, who shows up in all three of the nonfiction books in this article.

Weizenbaum, who died in 2008, was profoundly concerned about the possibility of computerized therapy. “Computers can make psychiatric judgments,” he wrote in his 1976 book Computer Power and Human Reason. “They can flip coins in much more sophisticated ways than can the most patient human being. The point is that they ought not to be given such tasks. They may even be able to arrive at ‘correct’ decisions in some cases—but always and necessarily on bases no human being should be willing to accept.”

It’s a caution worth keeping in mind. As AI therapists arrive at scale, we’re seeing them play out a familiar dynamic: Tools designed with superficially good intentions are enmeshed with systems that can exploit, surveil, and reshape human behavior. In a frenzied attempt to unlock new opportunities for patients in dire need of mental-health support, we may be locking other doors behind them.

Becky Ferreira is a science reporter based in upstate New York and author of First Contact: The Story of Our Obsession with Aliens.

The experimental model won&#39;t compete with the biggest and best, but it could tell us why they behave in weird ways—and how trustworthy they really are.

Four ways to think about this year&#39;s reckoning

They managed to cut the size of the AI reasoning model by more than half—and claim it can now answer politically sensitive questions once off limits in Chinese AI systems.

A conversation with a chatbot can shift people&#39;s political views—but the most persuasive models also spread the most misinformation.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-56')">
            <div class="source">MIT Technology Review</div>
            <div class="title">Bangladesh’s garment-making industry is getting greener</div>
            <div class="meta">2025-12-29</div>
        </div>
        
        <div id="content-56" style="display:none;">
            <h2>Bangladesh’s garment-making industry is getting greener</h2>
            <p><strong>MIT Technology Review | 2025-12-29</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2025/12/29/1129308/bangladesh-garment-sustainability-frugal-factories/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Pollution from textile production—dyes, chemicals, and heavy metals like lead and cadmium—is common in the waters of the Buriganga River as it runs through Dhaka, Bangladesh. It’s among many harms posed by a garment sector that was once synonymous with tragedy: In 2013, the eight-story Rana Plaza factory building collapsed, killing 1,134 people and injuring some 2,500 others.

But things are starting to change. In recent years the country has quietly become an unlikely leader in “frugal” factories that use a combination of resource-efficient technologies to cut waste, conserve water, and build resilience against climate impacts and global supply disruptions. Bangladesh now boasts 268 LEED-certified garment factories—more than any other country. Dye plants are using safer chemicals, tanneries are adopting cleaner tanning methods and treating wastewater, workshops are switching to more efficient LED lighting, and solar panels glint from rooftops. The hundreds of factories along the Buriganga’s banks and elsewhere in Bangladesh are starting to stitch together a new story, woven from greener threads.

In Fakir Eco Knitwears’ LEED Gold–certified factory in Narayanganj, a city near Dhaka, skylights reduce energy consumption from electric lighting by 40%, and AI-driven cutters allow workers to recycle 95% of fabric scraps into new yarns. “We save energy by using daylight, solar power, and rainwater instead of heavy AC and boilers,” says Md. Anisuzzaman, an engineer at the company. “It shows how local resources can make production greener and more sustainable.”

The shift to green factories in Bangladesh is financed through a combination of factory investments, loans from Bangladesh Bank’s Green Transformation Fund, and pressure from international buyers who reward compliance with ongoing orders. One prominent program is the Partnership for Cleaner Textile (PaCT), an initiative run by the World Bank Group’s International Finance Corporation. Launched in 2013, PaCT has worked with more than 450 factories on cleaner production methods. By its count, the effort now saves 35 billion liters of fresh water annually, enough to meet the needs of 1.9 million people.

It’s a good start, but Bangladesh’s $40 billion garment industry still has a long way to go. The shift to environmentalism at the factory level hasn’t translated to improved outcomes for the sector’s 4.4 million workers.

Wage theft and delayed payments are widespread. The minimum wage, some 12,500 taka per month (about $113), is far below the $200 proposed by unions—which has meant frequent strikes and protests over pay, overtime, and job security. “Since Rana Plaza, building safety and factory conditions have improved, but the mindset remains unchanged,” says A.K.M. Ashraf Uddin, executive director of the Bangladesh Labour Foundation, a nonprofit labor rights group. “Profit still comes first, and workers’ freedom of speech is yet to be realized.”

In the worst case, greener industry practices could actually exacerbate inequality. Smaller factories dominate the sector, and they struggle to afford upgrades. But without those upgrades, businesses could find themselves excluded from certain markets. One of those is the European Union, which plans to require companies to address human rights and environmental problems in supply chains starting in 2027. A cleaner Buriganga River mends just a small corner of a vast tapestry of need.

Zakir Hossain Chowdhury is a visual journalist based in Bangladesh.

As early electric cars age out, hundreds of thousands of used batteries are flooding the market, fueling a gray recycling economy even as Beijing and big manufacturers scramble to build a more orderly system.

How AI and renewables are shifting the energy landscape.

Omar Yaghi thinks crystals with gaps that capture moisture could bring technology from “Dune” to the arid parts of Earth.

And why many scientists are freaked out about the first serious for-profit company moving into the solar geoengineering field.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-57')">
            <div class="source">MIT Technology Review</div>
            <div class="title">MIT Technology Review’s most popular stories of 2025</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-57" style="display:none;">
            <h2>MIT Technology Review’s most popular stories of 2025</h2>
            <p><strong>MIT Technology Review | 2025-12-26</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2025/12/26/1130318/mit-technology-review-most-popular-stories-2025/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">It&#39;s been a busy and productive year here at MIT Technology Review. We published magazine issues on power, creativity, innovation, bodies, relationships, and security. We hosted 14 exclusive virtual conversations with our editors and outside experts in our subscriber-only series, Roundtables, and held two events on MIT’s campus. And we published hundreds of articles online, following new developments in computing, climate tech, robotics, and more.

As the year winds down, we wanted to give you a chance to revisit a bit of this work with us. Whether we were covering the red-hot rise of artificial intelligence or the future of biotech, these are some of the stories that resonated the most with our readers.

We did the math on AI’s energy footprint. Here’s the story you haven’t heard.

Understanding AI’s energy use was a huge global conversation in 2025 as hundreds of millions of people began using generative AI tools on a regular basis. Senior reporters James O’Donnell and Casey Crownhart dug into the numbers and published an unprecedented look at AI’s resource demand, down to the level of a single query, to help us know how much energy and water AI may require moving forward.

We’re learning more about what vitamin D does to our bodies

Vitamin D deficiency is widespread, particularly in the winter when there’s less sunlight to drive its production in our bodies. The “sunshine vitamin” is important for bone health, but as senior reporter Jessica Hamzelou reported, recent research is also uncovering surprising new insights into other ways it might influence our bodies, including our immune systems and heart health.

Senior editor Will Douglas Heaven’s expansive look at how to define AI was published in 2024, but it still managed to connect with many readers this year. He lays out why no one can agree on what AI is—and explains why that ambiguity matters, and how it can inform our own critical thinking about this technology.

Ethically sourced “spare” human bodies could revolutionize medicine

In this thought-provoking op-ed, a team of experts at Stanford University argue that creating living human bodies that can’t think, don’t have any awareness, and can’t feel pain could shake up medical research and drug development by providing essential biological materials for testing and transplantation. Recent advances in biotechnology now provide a potential pathway to such “bodyoids,” though plenty of technical challenges and ethical hurdles remain.

It’s surprisingly easy to stumble into a relationship with an AI chatbot

Chatbots were everywhere this year, and reporter Rhiannon Williams chronicled how quickly people can develop bonds with one. That’s all right for some people, she notes, but dangerous for others. Some folks even describe unintentionally forming romantic relationships with chatbots. This is a trend we’ll definitely be keeping an eye on in 2026.

The electric grid is bracing for disruption from more frequent storms and fires, as well as an uncertain policy and regulatory landscape. And in many ways, the publicly owned utility company Lincoln Electric in Nebraska is an ideal lens through which to examine this shift as it works through the challenges of delivering service that’s reliable, affordable, and sustainable.

Exclusive: A record-breaking baby has been born from an embryo that’s over 30 years old

This year saw the birth of the world’s “oldest baby”: Thaddeus Daniel Pierce, who arrived on July 26. The embryo he developed from was created in 1994 during the early days of IVF and had been frozen and sitting in storage ever since. The new baby’s parents were toddlers at the time, and the embryo was donated to them decades later via a Christian “embryo adoption” agency.

How these two brothers became go-to experts on America’s “mystery drone” invasion

Twin brothers John and Gerald Tedesco teamed up to investigate a concerning new threat—unidentified drones. In 2024 alone, some 350 drones entered airspace over a hundred different US military installations, and many cases went unsolved, according to a top military official. This story takes readers inside the equipment-filled RV the Tedescos created to study mysterious aerial phenomena, and how they made a name for themselves among government officials.

Our newsroom has published this annual look at advances that will matter in the long run for over 20 years. This year’s list featured generative AI search, cleaner jet fuel, long-acting HIV prevention meds, and other emerging technologies that our journalists think are worth watching. We’ll publish the 2026 edition of the list on January 12, so stay tuned. (In the meantime, here’s what didn’t make the cut.)

The Cybertruck, sycophantic AI, and humanoid robots all made this year’s list of the biggest technology failures.

Unveiled by the buzzy startup Deep, Vanguard will let teams of scientists live and work on the seabed for a week at a time.

We’ll keep following these developments, but this just wasn’t their year. Here’s why.

It’s free and easy to nominate yourself or someone you know—here’s how.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-58')">
            <div class="source">MIT Technology Review</div>
            <div class="title">The paints, coatings, and chemicals making the world a cooler place</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-58" style="display:none;">
            <h2>The paints, coatings, and chemicals making the world a cooler place</h2>
            <p><strong>MIT Technology Review | 2025-12-26</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2025/12/26/1129301/paint-coating-chemicals-materials-cooling-air-conditioning/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">It’s getting harder to beat the heat. During the summer of 2025, heat waves knocked out power grids in North America, Europe, and the Middle East. Global warming means more people need air-­conditioning, which requires more power and strains grids. But a millennia-old idea (plus 21st-century tech) might offer an answer: radiative cooling. Paints, coatings, and textiles can scatter sunlight and dissipate heat—no additional energy required.

“Radiative cooling is universal—it exists everywhere in our daily life,” says Qiaoqiang Gan, a professor of materials science and applied physics at King Abdullah University of Science and Technology in Saudi Arabia. Pretty much any object will absorb heat from the sun during the day and radiate some of it back at night. It’s why cars parked outside overnight are often covered with condensation, Gan says—their metal roofs dissipate heat into the sky, cooling the surfaces below the ambient air temperature. That’s how you get dew.

Humans have harnessed this basic natural process for thousands of years. Desert peoples in Iran, North Africa, and India manufactured ice by leaving pools of water exposed to clear desert skies overnight, when radiative cooling happens naturally; other cultures constructed “cool roofs” capped with reflective materials that scattered sunlight and lowered interior temperatures. “People have taken advantage of this effect, either knowingly or unknowingly, for a very long time,” says Aaswath Raman, a materials scientist at UCLA and cofounder of the radiative­cooling startup SkyCool Systems.

Modern approaches, as demonstrated everywhere from California supermarket rooftops to Japan’s Expo 2025 pavilion, go even further. Normally, if the sun is up and pumping in heat, surfaces can’t get cooler than the ambient temperature. But back in 2014, Raman and his colleagues achieved radiative cooling in the daytime. They customized photonic films to absorb and then radiate heat at infrared wavelengths between eight and 13 micrometers—a range of electromagnetic wavelengths called an “atmospheric window,” because that radiation escapes to space rather than getting absorbed. Those films could dissipate heat even under full sun, cooling the inside of a building to 9 °F below ambient temperatures, with no AC or energy source required.

That was proof of concept; today, Raman says, the industry has mostly shifted away from advanced photonics that use the atmospheric-window effect to simpler sunlight-scattering materials. Ceramic cool roofs, nanostructure coatings, and reflective polymers all offer the possibility of diverting more sunlight across all wavelengths, and they’re more durable and scalable.

Now the race is on. Startups such as SkyCool, Planck Energies, Spacecool, and i2Cool are competing to commercially manufacture and sell coatings that reflect at least 94% of sunlight in most climates, and above 97% in humid tropical ones. Pilot projects have already provided significant cooling to residential buildings, reducing AC energy needs by 15% to 20% in some cases.

This idea could go way beyond reflective rooftops and roads. Researchers are developing reflective textiles that can be worn by people most at risk of heat exposure. “This is personal thermal management,” says Gan. “We can realize passive cooling in T-shirts, sportswear, and garments.”

Of course, these technologies and materials have limits. Like solar power grids, they’re vulnerable to weather. Clouds prevent reflected sunlight from bouncing into space. Dust and air pollution dim materials’ bright surfaces. Lots of coatings lose their reflectivity after a few years. And the cheapest and toughest materials used in radiative cooling tend to rely on Teflon and other fluoropolymers, “forever chemicals” that don’t biodegrade, posing an environmental risk. “They are the best class of products that tend to survive outdoors,” says Raman. “So for long-term scale-up, can you do it without materials like those fluoropolymers and still maintain the durability and hit this low cost point?”

As with any other solution to the problems of climate change, one size won’t fit all. “We cannot be overoptimistic and say that radiative cooling can address all our future needs,” Gan says. “We still need more efficient active air-conditioning.” A shiny roof isn’t a panacea, but it’s still pretty cool.

Becky Ferreira is a science reporter based in upstate New York and author of First Contact: The Story of Our Obsession with Aliens.

As early electric cars age out, hundreds of thousands of used batteries are flooding the market, fueling a gray recycling economy even as Beijing and big manufacturers scramble to build a more orderly system.

How AI and renewables are shifting the energy landscape.

Omar Yaghi thinks crystals with gaps that capture moisture could bring technology from “Dune” to the arid parts of Earth.

And why many scientists are freaked out about the first serious for-profit company moving into the solar geoengineering field.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-59')">
            <div class="source">MIT Technology Review</div>
            <div class="title">AI Wrapped: The 14 AI terms you couldn’t avoid in 2025</div>
            <div class="meta">2025-12-25</div>
        </div>
        
        <div id="content-59" style="display:none;">
            <h2>AI Wrapped: The 14 AI terms you couldn’t avoid in 2025</h2>
            <p><strong>MIT Technology Review | 2025-12-25</strong></p>
            <a class="original-link" href="https://www.technologyreview.com/2025/12/25/1130298/ai-wrapped-the-14-ai-terms-you-couldnt-avoid-in-2025/">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">If the past 12 months have taught us anything, it’s that the AI hype train is showing no signs of slowing. It’s hard to believe that at the beginning of the year, DeepSeek had yet to turn the entire industry on its head, Meta was better known for trying (and failing) to make the metaverse cool than for its relentless quest to dominate superintelligence, and vibe coding wasn’t a thing.

If that’s left you feeling a little confused, fear not. As we near the end of 2025, our writers have taken a look back over the AI terms that dominated the year, for better or worse.

Make sure you take the time to brace yourself for what promises to be another bonkers year.

As long as people have been hyping AI, they have been coming up with names for a future, ultra-powerful form of the technology that could bring about utopian or dystopian consequences for humanity. “Superintelligence” is that latest hot term. Meta announced in July that it would form an AI team to pursue superintelligence, and it was reportedly offering nine-figure compensation packages to AI experts from the company’s competitors to join.

In December, Microsoft’s head of AI followed suit, saying the company would be spending big sums, perhaps hundreds of billions, on the pursuit of superintelligence. If you think superintelligence is as vaguely defined as artificial general intelligence, or AGI, you’d be right! While it’s conceivable that these sorts of technologies will be feasible in humanity’s long run, the question is really when, and whether today’s AI is good enough to be treated as a stepping stone toward something like superintelligence. Not that that will stop the hype kings. —James O’Donnell

Thirty years ago, Steve Jobs said everyone in America should learn how to program a computer. Today, people with zero knowledge of how to code can knock up an app, game, or website in no time at all thanks to vibe coding—a catch-all phrase coined by OpenAI cofounder Andrej Karpathy. To vibe-code, you simply prompt generative AI models’ coding assistants to create the digital object of your desire and accept pretty much everything they spit out. Will the result work? Possibly not. Will it be secure? Almost definitely not, but the technique’s biggest champions aren’t letting those minor details stand in their way. Also—it sounds fun! — Rhiannon Williams

One of the biggest AI stories over the past year has been how prolonged interactions with chatbots can cause vulnerable people to experience delusions and, in some extreme cases, can either cause or worsen psychosis. Although “chatbot psychosis” is not a recognized medical term, researchers are paying close attention to the growing anecdotal evidence from users who say it’s happened to them or someone they know. Sadly, the increasing number of lawsuits filed against AI companies by the families of people who died following their conversations with chatbots demonstrate the technology’s potentially deadly consequences. —Rhiannon Williams

Few things kept the AI hype train going this year more than so-called reasoning models, LLMs that can break down a problem into multiple steps and work through them one by one. OpenAI released its first reasoning models, o1 and o3, a year ago.

A month later, the Chinese firm DeepSeek took everyone by surprise with a very fast follow, putting out R1, the first open-source reasoning model. In no time, reasoning models became the industry standard: All major mass-market chatbots now come in flavors backed by this tech. Reasoning models have pushed the envelope of what LLMs can do, matching top human performances in prestigious math and coding competitions. On the flip side, all the buzz about LLMs that could “reason” reignited old debates about how smart LLMs really are and how they really work. Like “artificial intelligence” itself, “reasoning” is technical jargon dressed up with marketing sparkle. Choo choo! —Will Douglas Heaven

For all their uncanny facility with language, LLMs have very little common sense. Put simply, they don’t have any grounding in how the world works. Book learners in the most literal sense, LLMs can wax lyrical about everything under the sun and then fall flat with a howler about how many elephants you could fit into an Olympic swimming pool (exactly one, according to one of Google DeepMind’s LLMs).

World models—a broad church encompassing various technologies—aim to give AI some basic common sense about how stuff in the world actually fits together. In their most vivid form, world models like Google DeepMind’s Genie 3 and Marble, the much-anticipated new tech from Fei-Fei Li’s startup World Labs, can generate detailed and realistic virtual worlds for robots to train in and more. Yann LeCun, Meta’s former chief scientist, is also working on world models. He has been trying to give AI a sense of how the world works for years, by training models to predict what happens next in videos. This year he quit Meta to focus on this approach in a new start up called Advanced Machine Intelligence Labs. If all goes well, world models could be the next thing. —Will Douglas Heaven

Have you heard about all the people saying no thanks, we actually don’t want a giant data center plopped in our backyard? The data centers in question—which tech companies want to built everywhere, including space—are typically referred to as hyperscalers: massive buildings purpose-built for AI operations and used by the likes of OpenAI and Google to build bigger and more powerful AI models. Inside such buildings, the world’s best chips hum away training and fine-tuning models, and they’re built to be modular and grow according to needs.

It’s been a big year for hyperscalers. OpenAI announced, alongside President Donald Trump, its Stargate project, a $500 billion joint venture to pepper the country with the largest data centers ever. But it leaves almost everyone else asking: What exactly do we get out of it? Consumers worry the new data centers will raise their power bills. Such buildings generally struggle to run on renewable energy. And they don’t tend to create all that many jobs. But hey, maybe these massive, windowless buildings could at least give a moody, sci-fi vibe to your community. —James O’Donnell

The lofty promises of AI are levitating the economy. AI companies are raising eye-popping sums of money and watching their valuations soar into the stratosphere. They’re pouring hundreds of billions of dollars into chips and data centers, financed increasingly by debt and eyebrow-raising circular deals. Meanwhile, the companies leading the gold rush, like OpenAI and Anthropic, might not turn a profit for years, if ever. Investors are betting big that AI will usher in a new era of riches, yet no one knows how transformative the technology will actually be.

Most organizations using AI aren’t yet seeing the payoff, and AI work slop is everywhere. There’s scientific uncertainty about whether scaling LLMs will deliver superintelligence or whether new breakthroughs need to pave the way. But unlike their predecessors in the dot-com bubble, AI companies are showing strong revenue growth, and some are even deep-pocketed tech titans like Microsoft, Google, and Meta. Will the manic dream ever burst? —Michelle Kim

This year, AI agents were everywhere. Every new feature announcement, model drop, or security report throughout 2025 was peppered with mentions of them, even though plenty of AI companies and experts disagree on exactly what counts as being truly “agentic,” a vague term if ever there was one. No matter that it’s virtually impossible to guarantee that an AI acting on your behalf out in the wide web will always do exactly what it’s supposed to do—it seems as though agentic AI is here to stay for the foreseeable. Want to sell something? Call it agentic! —Rhiannon Williams

Early this year, DeepSeek unveiled its new model DeepSeek R1, an open-source reasoning model that matches top Western models but costs a fraction of the price. Its launch freaked Silicon Valley out, as many suddenly realized for the first time that huge scale and resources were not necessarily the key to high-level AI models. Nvidia stock plunged by 17% the day after R1 was released.

The key to R1’s success was distillation, a technique that makes AI models more efficient. It works by getting a bigger model to tutor a smaller model: You run the teacher model on a lot of examples and record the answers, and reward the student model as it copies those responses as closely as possible, so that it gains a compressed version of the teacher’s knowledge.  —Caiwei Chen

As people across the world spend increasing amounts of time interacting with chatbots like ChatGPT, chatbot makers are struggling to work out the kind of tone and “personality” the models should adopt. Back in April, OpenAI admitted it’d struck the wrong balance between helpful and sniveling, saying a new update had rendered GPT-4o too sycophantic. Having it suck up to you isn’t just irritating—it can mislead users by reinforcing their incorrect beliefs and spreading misinformation. So consider this your reminder to take everything—yes, everything—LLMs produce with a pinch of salt. —Rhiannon Williams

If there is one AI-related term that has fully escaped the nerd enclosures and entered public consciousness, it’s “slop.” The word itself is old (think pig feed), but “slop” is now commonly used to refer to low-effort, mass-produced content generated by AI, often optimized for online traffic. A lot of people even use it as a shorthand for any AI-generated content. It has felt inescapable in the past year: We have been marinated in it, from fake biographies to shrimp Jesus images to surreal human-animal hybrid videos.

But people are also having fun with it. The term’s sardonic flexibility has made it easy for internet users to slap it on all kinds of words as a suffix to describe anything that lacks substance and is absurdly mediocre: think “work slop” or “friend slop.” As the hype cycle resets, “slop” marks a cultural reckoning about what we trust, what we value as creative labor, and what it means to be surrounded by stuff that was made for engagement rather than expression. —Caiwei Chen

Did you come across the hypnotizing video from earlier this year of a humanoid robot putting away dishes in a bleak, gray-scale kitchen? That pretty much embodies the idea of physical intelligence: the idea that advancements in AI can help robots better move around the physical world.

It’s true that robots have been able to learn new tasks faster than ever before, everywhere from operating rooms to warehouses. Self-driving-car companies have seen improvements in how they simulate the roads, too. That said, it’s still wise to be skeptical that AI has revolutionized the field. Consider, for example, that many robots advertised as butlers in your home are doing the majority of their tasks thanks to remote operators in the Philippines.

The road ahead for physical intelligence is also sure to be weird. Large language models train on text, which is abundant on the internet, but robots learn more from videos of people doing things. That’s why the robot company Figure suggested in September that it would pay people to film themselves in their apartments doing chores. Would you sign up? —James O&#39;Donnell

AI models are trained by devouring millions of words and images across the internet, including copyrighted work by artists and writers. AI companies argue this is “fair use”—a legal doctrine that lets you use copyrighted material without permission if you transform it into something new that doesn’t compete with the original. Courts are starting to weigh in. In June, Anthropic’s training of its AI model Claude on a library of books was ruled fair use because the technology was “exceedingly transformative.”

That same month, Meta scored a similar win, but only because the authors couldn’t show that the company’s literary buffet cut into their paychecks. As copyright battles brew, some creators are cashing in on the feast. In December, Disney signed a splashy deal with OpenAI to let users of Sora, the AI video platform, generate videos featuring more than 200 characters from Disney&#39;s franchises. Meanwhile, governments around the world are rewriting copyright rules for the content-guzzling machines. Is training AI on copyrighted work fair use? As with any billion-dollar legal question, it depends. —Michelle Kim

Just a few short years ago, an entire industry was built around helping websites rank highly in search results (okay, just in Google). Now search engine optimization (SEO), is giving way to GEO—generative engine optimization—as the AI boom forces brands and businesses to scramble to maximize their visibility in AI, whether that’s in AI-enhanced search results like Google’s AI Overviews or within responses from LLMs. It’s no wonder they’re freaked out. We already know that news companies have experienced a colossal drop in search-driven web traffic, and AI companies are working on ways to cut out the middleman and allow their users to visit sites from directly within their platforms. It’s time to adapt or die. —Rhiannon Williams

The experimental model won&#39;t compete with the biggest and best, but it could tell us why they behave in weird ways—and how trustworthy they really are.

Four ways to think about this year&#39;s reckoning

They managed to cut the size of the AI reasoning model by more than half—and claim it can now answer politically sensitive questions once off limits in Chinese AI systems.

A conversation with a chatbot can shift people&#39;s political views—but the most persuasive models also spread the most misinformation.

Discover special offers, top stories,
            upcoming events, and more.

We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.</div>
        </div>
        
        <div class="card" onclick="openModal('content-60')">
            <div class="source">The Next Web</div>
            <div class="title">A 2025 recap for Tech & AI</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-60" style="display:none;">
            <h2>A 2025 recap for Tech & AI</h2>
            <p><strong>The Next Web | 2025-12-31</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/a-2025-recap-for-tech-ai">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">2025 was the year technology stopped being tomorrow’s promise and became today’s anchor. What began as a surge in generative AI and platform innovation two years prior crystallized this year into concrete shifts in how people work, governing bodies legislate, and markets invest. Across continents and industries, the arc of technology bent toward practical impact, regulatory reality, and economic weight.

At the heart of the year’s story was artificial intelligence’s jump from novelty to infrastructure. LLMs and multimodal models moved beyond demos into everyday workflows, influencing how documents are written, campaigns are conceived, products designed, and code generated.

Enterprises that once hesitated began deploying AI tools at scale, with early adopters reporting measurable productivity gains by integrating copilots into core processes, a trend visible in surveys showing widespread adoption among software professionals.

This editorial isn’t a chronicle of every press release.

TNW City Coworking space - Where your best work happens

A workspace designed for growth, collaboration, and endless networking opportunities in the heart of tech.

It’s a reflection on how 2025, at the crossroads of technology, governance, and economic strategy, brought about a series of inflection points that will shape the next era of creation, competition, and control.

OpenAI’s release of GPT-5 in August pushed the boundaries of what AI could do, delivering notable gains in coding, math, and multimodal understanding. But unlike the jaw-dropping debut of ChatGPT a couple years prior, this new generation of foundation models arrived to a more measured reception.

Tech leaders and investors had begun asking harder questions: beyond impressive demos, could these models drive real products and revenue?

Google’s answer was Gemini 3, launched in November as its “most intelligent model” and immediately woven into Google’s flagship product, Search. For the first time, an AI model upgrade wasn’t just about boastful leaderboard scores, it was about transforming user experience.

Typing a query into Google now often meant receiving an AI-generated synthesis instead of the familiar list of links, a sea change in how information is delivered. Google even unveiled a Gemini “agent” that could execute multi-step tasks like booking travel or organizing email, hinting at a future where AI acts more like a digital butler than a chatbox.

Anthropic’s Claude 4 model, for instance, gained a strong following among developers by expanding how much it could handle at once, processing entire codebases with tens of thousands of lines, rather than by producing viral one-liners.

AI grew up in 2025: it was still improving at breakneck speed, but it also had to earn its keep in real products and justify the billion-dollar bets fueling its rise.

Driving this AI explosion was a parallel leap in hardware. The hunger for AI computers in 2025 was insatiable, and chipmakers raced to deliver.

NVIDIA, whose GPUs had become the era’s essential infrastructure, rolled out its new Blackwell architecture with chips like the B200 that boasted up to 3× the training speed of its predecessor. Cloud data centers around the world scrambled to deploy these to keep up with demand from model training and inference.

Rival chipmakers weren’t idle either: AMD and a cadre of startups pushed innovative AI accelerators, while even Intel signaled ambitions to catch up, reportedly exploring an acquisition of AI chip designer SambaNova.

Perhaps most tellingly, tech giants themselves started designing silicon tailored for AI workloads, recognizing that owning the chip means owning the future of computing.

Beyond AI chips, consumer hardware saw its own milestones. After years of anticipation, augmented reality glasses and mixed-reality headsets finally had their moment, sort of.

Apple’s Vision Pro headset, unveiled in late 2023, reached select markets in 2024; by 2025 developers were crafting the first wave of immersive apps. However, mass adoption lagged due to the device’s sky-high price and bulky format.

Competitors like Meta’s Quest line offered cheaper VR headsets and modest improvements, but the “metaverse” hype of yesteryear largely fizzled out, users and investors had shifted their excitement to generative AI and tangible productivity tools.

Smartphones and laptops in 2025 continued incremental improvements (faster Apple M3/M4 chips, foldable screens becoming more common), yet it was clear the next paradigm shift in personal tech was still on the horizon.

Even so, one hardware frontier made concrete progress: quantum computing. Industry leaders like IBM and Google demonstrated prototype systems with ever-larger qubit counts and made strides in error correction, inching closer to viable quantum machines.

These advances, while esoteric to the public, underscored a broader theme, from AI accelerators to quantum chips, the machinery under the hood of tech was evolving rapidly to enable the software of tomorrow.

If 2025 proved anything, it’s that technology no longer operates above the law. This was the year regulators moved from intent to enforcement, with Europe leading the charge.

After years of debate, the EU’s Artificial Intelligence Act came into force, becoming the world’s first complex AI law. From February, certain “unacceptable risk” uses, such as social scoring and real-time biometric surveillance, were banned outright.

By August, transparency rules followed, forcing companies to label AI-generated content and comply with new obligations for general-purpose models. The signal was unmistakable: in Europe, the era of unchecked AI was over.

Companies now face audits, penalties, and real consequences if their systems cross legal or ethical lines, a regulatory moment European officials openly compared to GDPR’s impact on data privacy.

The pressure didn’t stop with AI. In 2025, regulators also went after the gatekeepers. The EU’s Digital Markets Act forced long-resistant changes from Big Tech, most notably when Apple opened the iPhone to third-party app stores and sideloading in Europe, dismantling a 15-year walled garden.

At the same time, enforcement of the Digital Services Act intensified. Platforms were scrutinized for how they handle disinformation, with companies like X warned or penalized during periods of geopolitical tension. In response, social networks expanded moderation teams, adjusted algorithms, and exposed more of their inner workings to researchers.

The US issued an AI executive order and signaled tougher enforcement through agencies like the FTC, while states stepped in, including New York’s law requiring mental-health warnings on addictive social features.

In China, new draft rules targeted AI systems designed for human-like interaction, tightening licensing and ideological oversight. By the end of the year, the freewheeling phase of tech disruption had given way to something more restrained. The question was no longer whether regulation would catch up, but how deeply it would reshape innovation itself.

The platform shake-up that began in 2023 gathered real momentum in 2025, as both companies and users adjusted to a post-pandemic, AI-saturated reality.

Nowhere was this clearer than in social media. Elon Musk’s X, which entered the decade with noise and bravado, found itself on the defensive. Meta’s Threads, initially dismissed after an early spike, steadily closed the gap, nearing parity with X in daily mobile users by mid-year.

X’s audience shrank as policy whiplash and leadership churn eroded confidence, and while its remaining users were still deeply engaged, the era of unquestioned Twitter dominance was over. Disenchanted users scattered across a fragmented landscape, from Meta’s polished Threads to decentralized alternatives like Bluesky and Mastodon, breaking the old Facebook–Instagram–Twitter equilibrium.

The recalibration extended well beyond social feeds.

Major platforms retooled around changing habits: Google reshaped Search around generative answers to fend off AI assistants and algorithmic discovery, while Microsoft pushed its Copilot deeper into Windows, Office, and Bing, betting on “AI inside” as a platform reset.

Everyday behavior shifted too. Smarter voice and chat assistants returned to daily use, handling emails, refunds, and scheduling with little friction. At the same time, screen fatigue set in. Digital-detox travel gained traction, and younger users gravitated toward apps that promised less algorithmic pressure and more human curation. Even streaming came full circle.

After years of fragmentation, providers began rebundling services, offering combined video, music, and gaming packages that looked suspiciously like cable TV reborn, a reminder that while technology moves forward, user preferences often move in cycles.

Amid the gains and momentum, 2025 also became a year of reckoning. As AI systems spread, society began grappling with their cultural and ethical cost. Creators who once marveled at generative tools started pushing back, arguing that their work had been absorbed without consent or compensation.

A wave of lawsuits moved through US courts, with authors accusing companies like OpenAI, Meta, and Google of scraping books and articles to train models. By year’s end, the message was unmistakable: if AI is built on human creativity, many believe its rewards can no longer flow in one direction alone.

Public trust in technology was also tested by a rise in malicious uses and misuses. In the financial domain, sophisticated deepfake scams caused real damage. The frequency of such incidents spiked sharply; cybersecurity firms reported a 3000% increase in deepfake-related fraud over two years, and authorities scrambled to educate businesses on new verification practices.

Misinformation continued to be a menace: during elections and conflicts, AI-generated fake images and videos spread on social media, forcing newsrooms to set up rapid-response fact-checking teams.

Encouragingly, 2025 also saw growth in countermeasures, from better deepfake detection algorithms to nascent standards for cryptographic content authentication (the Coalition for Content Provenance, including major publishers and tech platforms, expanded efforts to watermark authentic media).

Still, the information ecosystem remained fraught, as even savvy citizens found it ever harder to tell the truth from fabrication online.

And then there’s the human element: how all this tech is affecting everyday lives and livelihoods. Workplace AI adoption soared this year; tools like Microsoft 365 Copilot and a host of AI assistants became common on office desktops. Studies showed productivity boosts but also raised concerns about workers becoming overly reliant on AI suggestions.

Meanwhile, fears of automation resurfaced in certain sectors, for example, as chatbots took over more customer service and code-generation tools improved, professionals in call centers and junior programming positions wondered about long-term job security.

These anxieties fueled calls for new approaches to education and training, so that the workforce of 2030 will be prepared for more creative, complex tasks that AI can’t easily handle.

Lovable (Stockholm, Sweden) came as one of the most remarkable AI software stories of the year, for me. What began as an open-source project evolved into a commercial platform that lets users build fully functional websites and apps using plain-language prompts, no traditional coding required.

This approach, known in the industry as “vibe coding,” turns ideas into production-ready software simply by describing what you want in natural language.

Lovable’s growth in 2025 was extraordinary by any measure. Eight months after its launch, the company hit over $100 million in annual recurring revenue and raised a $200 million Series A at a roughly $1.8 billion valuation, making it one of Europe’s fastest-growing software startups ever.

By year’s end, Lovable had secured $330 million in Series B funding at about a $6.6 billion valuation, and was rapidly scaling globally.

What makes Lovable meaningful beyond the numbers is what it represents: a shift in how software is built. It demonstrated that AI can democratize development, giving power to non-technical founders, creators, and teams to go from concept to product without traditional engineering barriers.

In an industry long centered on specialized skills and team structures, Lovable’s rise suggested a future where natural language becomes the primary interface to software creation.

On a more hopeful note, 2025 showed signs of a maturing tech culture. Ethical design moved from talking point to practice. Major platforms began experimenting with limits, turning off infinite scroll for teens, adding prompts that nudged users to pause, and treating “time well spent” as a real metric rather than a slogan.

In AI, transparency gained ground. Under pressure from regulators and researchers, companies like OpenAI and Google disclosed more about how their models are trained and where they fall short.

Researchers formed new alliances to share safety techniques, and a second global AI Safety Summit brought dozens of countries together around questions of alignment and control.

None of it amounted to binding rules, but it marked a shift in tone: even the architects of powerful systems openly acknowledged the need for restraint.

Taken together, these moments made 2025 a turning point. For years, technology had surged ahead of the institutions meant to guide it. This year, that gap began to close.

The breakthroughs were real and transformative, but so were the responses to them: laws passed, norms reset, alliances formed. If 2024 was the year the world grasped the power of generative AI, 2025 was the year it began deciding how that power should be used.

The story of technology is no longer just about what can be built, but about how it fits into the lives it shapes, and who gets to decide that fit.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-61')">
            <div class="source">The Next Web</div>
            <div class="title">A New Era for TNW.</div>
            <div class="meta">2025-12-22</div>
        </div>
        
        <div id="content-61" style="display:none;">
            <h2>A New Era for TNW.</h2>
            <p><strong>The Next Web | 2025-12-22</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/a-new-era-for-tnw">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">My name is Alexandru Stan, and this article continues the dialogue I began following the acquisition of TNW.

Following the recent transaction, TNW Spaces remains with the Financial Times, while we continue the mission of the website, the events, and the global community.

We already have a dedicated team at tekpon operating the platform, events, and community initiatives. Our objective is to expand and strengthen the team as TNW accelerates its next chapter.

TNW is already a global media platform with millions of readers. We’re not starting over. We are building forward.

Technology is entering a decisive stage: AI is reshaping workflows, distribution is shifting, capital is becoming more selective, and founders are expected to demonstrate value rather than potential.

The world doesn’t need more noise.
It needs clarity, execution, and access to trustworthy knowledge and people.

TNW will serve that need through editorial independence, real expertise, and community-built intelligence.

Success for TNW looks like this: more accurate understanding, faster access to verified knowledge, and direct pathways from insight to action.

I’ve been an entrepreneur since 2007, building in B2B SaaS, marketplaces, and scalable systems. I believe deeply in servant leadership. Without people, I am zero.

I lead two private networks grounded in practice rather than theory:

These groups ensure TNW remains rooted in lived experience, informed by operators, not commentators.

Our mission is to build the most trusted European tech media platform with global reach, focused on practical innovation, responsible scaling, and transparency.

We will continue to host events across Europe’s major capitals including Paris, London, Berlin, Amsterdam, and Monaco.

These will not be festivals. We are introducing a concept validated through tekpon events: curated gatherings built for meaningful relationships, deep content, and tangible business outcomes.

In 2026, we return to Amsterdam for a special edition centered on AI among other fields. We will explore technologies and strategies shaping the future of work and business:

The editorial focus remains European, while the audience is global.

AI is not a threat to publishing. It is the infrastructure of the next generation of content and knowledge.

At TNW, we will use AI to accelerate research, enable personalized intelligence, reduce noise and bias, and amplify high-quality human expertise. Technology assists. Human judgment remains central.

Because this moment in Europe matters.
Because founders here are ready to scale responsibly.
Because independent media with integrity is rare.
Because innovation deserves a platform built around people, not hype.

TNW will continue its legacy with a renewed emphasis on contribution, execution, and community built through trust.

If you are building, scaling, or researching the next wave of technology, I invite you to engage with us, contribute insights, and participate in shaping the conversation.

The next era begins now. Let’s shape it together.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-62')">
            <div class="source">The Next Web</div>
            <div class="title">Engineering’s AI reality check</div>
            <div class="meta">2025-12-19</div>
        </div>
        
        <div id="content-62" style="display:none;">
            <h2>Engineering’s AI reality check</h2>
            <p><strong>The Next Web | 2025-12-19</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/engineerings-ai-reality-check">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Most engineering leaders cannot answer the one question their CFO is about to ask: “Can you prove this AI spend is changing outcomes, not just activity?”

Every December, roadmaps get locked, budgets get approved, and board decks are polished until everything looks precise and under control. Underneath, many CTOs and VPs are still working with partial visibility. They have a feel for their teams, but not a reliable view of how work moves through the system, how AI is really changing delivery, or where time and money actually go.

For a while, that was survivable. Experience, pattern recognition, and cheap capital covered the gaps. You could hire around bottlenecks, overstaff critical teams, or quietly pivot away from the messiest parts of the system. Then AI showed up and became the perfect distraction. Pilots, PoCs, Copilot seats, and “AI initiatives” created visible activity and bought time.

In 2026, that grace period ends. Boards and CFOs are shifting from “show me you are experimenting” to “show me measurable impact, this year.” Not because they stopped believing in AI, but because the market no longer rewards vague promises. Every AI dollar will need a traceable path to productivity, quality, or customer value.

The latest rumblings from the EU tech scene, a story from our wise ol&#39; founder Boris, and some questionable AI art. It&#39;s free, every week, in your inbox. Sign up now!

If you run engineering, you probably recognise this scene. You present a slide with AI highlights. Adoption is up. Developers say they like the tools. You share a few anecdotes about faster coding and smoother reviews. Then the CFO asks a simple question: “Exactly how is this budget changing output and outcomes?”

What is almost always missing is a clear breakdown of:

So the conversation slips back to learning curves, compounding benefits, and talent attraction. All true, but too soft for a tough budget review. That will not be enough.

AI vendors love task-level numbers. A coding task completed 55 percent faster looks impressive on a slide. But once you zoom out to teams and systems, the picture changes.

Large datasets across thousands of developers show a consistent pattern:

The problem is not the tools. It is the lack of a system for where the “extra” capacity goes.

Most organisations still frame AI productivity in terms of speed: more story points, more tickets, higher deployment frequency. That misses the bigger question:

How much of our engineering capacity goes to net new value versus maintenance, incidents, and rework, and is AI improving that mix?

High-level benchmarks are blunt but helpful. On average, about 45 percent of developer time is spent on maintenance, minor enhancements, and bug fixes rather than on genuinely new, customer-facing work. If AI helps you produce more code inside an unchanged system, you risk:

That is how you end up with impressive local metrics and a leadership team that still feels like engineering is slowing down.

If you want to walk into a 2026 budget conversation with objective evidence, you need to be deliberate about how AI-driven time savings are used. Two moves matter.

AI is already good at boilerplate, tests, documentation, and simple refactors. The trap is treating the saved time as unstructured “extra” capacity that disappears into the noise. Instead:

When teams systematically reduce technical debt and improve tests around critical flows, they cut future incidents and rework. Over a year, that frees more capacity for new work than shaving a few minutes off each ticket ever will.

2. Point AI at the ugly, high-friction work that commonly blows up roadmaps

The biggest productivity wins are not in everyday code generation. They are in:

These activities steal weeks or months of capacity and stall strategic initiatives. Using AI to understand legacy code faster, propose refactoring plans, generate migration scaffolding, and highlight recurring failure patterns can dramatically compress timelines for this work.

In parallel, there is real leverage upstream in the problem space. Teams that reach higher levels of AI adoption report better gains when they:

That reduces wasted builds and focuses effort on changes customers actually care about. The most significant gains do not come from replacing human creativity, but from amplifying it and aiming it at better-defined problems.

DORA metrics are not the enemy. Deployment frequency, lead time, MTTR, and change failure rate remain among the best signals we have for delivery performance. The risk is mistaking them for the whole picture.

Leading organisations are already expanding their scorecard to include:

In 2026, the question in the boardroom will shift from “Are we elite on DORA?” to “How much of our capacity is going into things customers notice, and is AI improving that mix or not?” To answer that cleanly, DORA is necessary but not sufficient. You need a way to connect AI usage, workflow, quality, and business outcomes across the system.

This is where engineering intelligence platforms move from a nice-to-have to mandatory. The organisations that win in 2026 will not do it with one more AI tool or one more disconnected dashboard. They will do it by pulling together data they already have but rarely use in one coherent view:

From there, leaders can answer the questions that actually matter:

Instead of defending AI spend with anecdotes, you walk in with:

That is the difference between “we believe in AI” and “here is how AI changed our delivery engine in measurable ways.”

To be ready for the more complex questions coming next year, use this planning cycle to do four things.

Do this, and you will not just have “AI activity” to show in 2026. You will have a credible, data-backed story from AI spend to business outcomes.

The leaders who thrive next year will not be the ones with the flashiest AI demos or the loudest “AI strategy” slide. They will be the ones who:

Engineering intelligence platforms is a key part of that shift. They give you the complex data to show where time and money go, how AI is really changing delivery, and whether your current pace is sustainable. The shift to data-backed engineering leadership is happening either way.

The gap in 2026 will be between teams still guessing and teams that can prove, in detail, how their engineering organisation works.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-63')">
            <div class="source">The Next Web</div>
            <div class="title">Letter from the Editor-in-Chief</div>
            <div class="meta">2025-12-16</div>
        </div>
        
        <div id="content-63" style="display:none;">
            <h2>Letter from the Editor-in-Chief</h2>
            <p><strong>The Next Web | 2025-12-16</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/letter-from-the-editor-in-chief">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Not long ago, like many of you, I read what I feared might be The Next Web’s final article. In late September, TNW’s co-founder announced that the tech conference and news site would be winding down, no more events, no new stories. It felt like the end of an era; the news hit hard!

Yet, just a few weeks ago, a twist arrived: the tech platform Tekpon acquired 100% of TNW’s media and events brand from the Financial Times, ensuring that this nearly two-decade legacy will continue to thrive.

While, myself, trying to read people’s opinions on this topic, I read this comment in one article, from one former TNW editor-in-chief that said: “The Next Web shaped my career, my life… it’s very sad to see it die”.

I asked myself: Why do we always assume that just because one chapter ends, the whole story is over? Yes, taking over TNW is a heavy inheritance, especially with all eyes on us and expectations sky-high.

The latest rumblings from the EU tech scene, a story from our wise ol&#39; founder Boris, and some questionable AI art. It&#39;s free, every week, in your inbox. Sign up now!

And I’ll admit, doubts crept in: Am I too small for this? Could someone more experienced do it better? Probably. But here I am, stepping up regardless. Because this isn’t just another blog or brand; TNW is a living ecosystem, a vital community. Its story deserves to continue, and I’m determined to help write the next chapter.

I also know some of you might be wondering: Who is she? What does she know? How many articles has she written? What recommends her?

Before reading all sorts of titles and, let me briefly introduce myself.

I’ve been writing since high school, with thousands of articles under my belt; covering everything from culture, art, and hip hop to design, politics, history, and food. I landed my first content writer job at 18, and alongside writing I pursued another passion: becoming a chef.

(Fun fact: I even made it to the semifinals of MasterChef, a journey that taught me about creativity under pressure and staying cool when the heat is on.)

Now, I channel my storytelling skills into helping businesses better understand technology and use it to their advantage. I help companies tell their stories, the real ones, finding meaning and flow in every word.

Over the years, I’ve specialized in blending creative storytelling with the technical precision of a chef’s knife. (My colleagues at Tekpon might say I can be as sharp as that knife – true to my values and quick to cut through the nonsense.) I am also the “No, we have to do it right” person in the team.

I’ve reviewed countless software products, interviewed founders, and explored how digital innovation can be a force for good in society. Or not. In other words, I’ve always cared about the why behind the tech, the real impact on people’s lives, not just the buzz. That perspective will be behind every story we will publish at TNW.

If there’s a place for those who still think stories written by humans matter, tell me where it is. I’m already on my way.

I’m not here to change TNW’s DNA; I’m here to reinforce it with fresh energy and a clear vision for the future.

To the loyal TNW readers, to the startup founders who looked to us for inspiration, to the healthy tech skeptics who counted on us for a reality check, and to our global audience spread across continents: we hear you.

We all know the world of tech news has changed dramatically. Today, everyone has a megaphone, social media overflows with hot takes, and AI algorithms can crank out content in seconds. It’s easy to feel overwhelmed by this sea of opinions and auto-generated articles. In such a world, the role of a publication like TNW is more critical than ever: to be a filter, not just another firehose of content.

We will focus on curation and clarity, distilling the noise so you don’t have to.

Here’s the good news: despite the deluge of AI-written text out there, readers are actively looking for authentic, human journalism. Every article we will publish will be created by a human writer who is accountable for the facts and who brings context, analysis, and yes, a bit of personality too.

Our mission isn’t to chase every trending headline algorithmically; it’s to help you understand which innovations actually matter, and why.

If a story is everywhere but lacks substance, we won’t regurgitate it; we’ll analyze it or debunk it. If a breakthrough is genuinely promising, we’ll explain why it’s important and how it impacts real people. Being a thoughtful filter in this age of information overload (and AI-generated noise) isn’t just a catchy slogan for us; it’s a responsibility we embrace.

You’ll also notice something different in our approach: an emphasis on storytelling and the human side of tech. Technology doesn’t exist in a vacuum; it’s built and used by people with dreams, dilemmas, and diverse backgrounds.

I believe, and I suspect many of you do too, that the best tech journalism zooms out from the gadgets and code to highlight those human stories. Practically speaking, expect to see more features, interviews, and narrative-driven pieces on TNW.

We’ll talk to founders about the messy, human journey of building a startup, not just the press releases or funding announcements. We’ll spotlight the engineers, designers, and thinkers who are trying to solve big problems (or even small ones that make a big difference). We’ll explore tech’s impact on society: the good, the bad, and the complicated.

This won’t be a place for recycled press releases or surface-level takes. It will be a place for conversation and insight.

Importantly, none of this focus on storytelling means we’ll skimp on rigor. Being engaging doesn’t mean sacrificing accuracy or depth. My team will continue to prioritize thorough research and fact-checking, those good old-school journalism values, even as we experiment with new formats and new voices. In short, we won’t publish anything we wouldn’t want to read ourselves.

Today, looking forward means acknowledging that how we cover tech is as important as what we cover. It means committing to journalism that cuts through the clutter, to storytelling that puts people first, and to a vision of tech’s future that is both hopeful and honest. That’s my vision for TNW as I step into this role, and I hope it resonates with you.

Now, I’d like to turn it over to you, our community. This is your TNW as much as it is ours. I invite you to join the conversation. Tell us what you want to see more of (or less of). Hold us accountable,if we ever fall short, let us know. Share your stories and perspectives with us, because they can inspire our coverage.

In the coming weeks, you’ll start to see this vision take shape on the site. You’ll see familiar faces and new voices. You’ll find articles that make you think, others that make you smile, and hopefully quite a few that make you proud to be a TNW reader.

Whether you’re a long-time follower who’s stuck with us through thick and thin, a startup founder looking for insight, a skeptic keeping us honest, or a curious mind tuning in from anywhere in the world – thank you. We do this for you, and we couldn’t do it without you.

The Next Web is back. We’re here to inform you, inspire you, challenge you, and occasionally even surprise you. I’m honored to have you with us on this journey. Here’s to the road ahead, to storytelling, to journalism (the real kind), and to making sense of the future together.

Thank you for reading, and welcome to TNW’s next chapter. Let’s build it, day by day, story by story, together.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-64')">
            <div class="source">The Next Web</div>
            <div class="title">Is ChatGPT’s New Shopping Research Solving a Problem, or Creating One?</div>
            <div class="meta">2025-12-11</div>
        </div>
        
        <div id="content-64" style="display:none;">
            <h2>Is ChatGPT’s New Shopping Research Solving a Problem, or Creating One?</h2>
            <p><strong>The Next Web | 2025-12-11</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/is-chatgpts-new-shopping-research-solving-a-problem-or-creating-one">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">When OpenAI announced its new shopping search capabilities, I took the news with a grain of salt (perhaps the whole shaker).
For the past decade, we have watched the slow evolution of traditional search engines. What began as tools for pure information discovery gradually morphed into ecosystems dominated by SEO-optimized content and sponsored results. My initial fear with ChatGPT’s update was simple: Are we seeing the beginning of a similar shift? Is the purity of the “reasoning engine” being diluted by the necessity of commerce?
After testing the new shopping integration, the results suggest that we are at a pivotal moment in the user experience of Generative AI, one that requires an open discussion about what we actually want these tools to be.

The defining characteristic of Large Language Models (LLMs) is their ability to handle nuance. When we interact with ChatGPT, we expect a Socratic dialogue. We expect the AI to ask clarifying questions to narrow down our intent.
To test this, I entered a simple prompt: “I want to buy a vacuum.”
I anticipated a conversation, questions about my home’s square footage, my floor type, or my budget. Instead, the conversational nuance was replaced by a display that felt familiar: a grid of product photos, names, prices, and direct links to retailers.

While efficient, this experience felt like a regression. It mirrored the “keyword search” experience of Web 2.0 rather than the “intent-based” promise of GenAI. It replied to my prompt, but it stripped away the intelligence.

The latest rumblings from the EU tech scene, a story from our wise ol&#39; founder Boris, and some questionable AI art. It&#39;s free, every week, in your inbox. Sign up now!

Scrolling down, I engaged with the new feature in a call to action: “Research the best vacuums.”
This is where the user experience (UX) friction became most apparent. Rather than synthesizing data or comparing technical specifications in a chat format, the tool presented a polling interface designed to filter results.

The experience is oddly time-sensitive; pause too long to think or drink water, and the screens will skip forward, dumping you back into a list of product cards.
The interface presents products with a binary choice: “More like this” or “Not interested.” It offers brand names and price tags, but virtually no information to help the user actually make a choice.

For a user seeking genuine research, being presented with a list of brands and prices without deep comparative analysis feels like a missed opportunity.
It raises a question: If I wanted to filter products by price and brand, wouldn’t I use a traditional retailer? The value proposition of Gen AI should be synthesis, not just aggregation.

The Tension Between Reasoning and Revenue
This update highlights the inevitable tension facing major AI companies: the balance between user utility and business sustainability.
As OpenAI scales, the pressure to demonstrate revenue models to investors is natural. However, there is a risk in prioritizing transactional features before the core product, reasoning and logic, is fully matured. By introducing a shopping experience that feels closer to a “click-through” engine than a “knowledge” engine, the platform risks blurring its own identity.
Is ChatGPT a research partner that helps me think? Or is it a shopping assistant trying to speed me to checkout?

To be clear, I believe there is a place for shopping within AI. But the execution matters.
A truly Generative AI shopping experience shouldn’t just list products; it should understand the user. It should read between the lines of a prompt to understand that a user asking for a vacuum might actually be solving a problem about pet hair or allergies.

The current iteration feels like a beta test of a business model rather than an evolution of intelligence. As we move forward, the hope is that OpenAI will refine this tool to prioritize the “Chat” over the transaction. We don’t want it to be just another place to see ads. We need a better way to make decisions.

Viviane Mendes is a growth strategist and innovation leader with more than 20 years of experience driving technology-enabled transformation across global markets. She has led initiatives integrating AI-driven strategies, digital transformation, and scalable business innovation for companies such as PSINet, MP3.com, Match.com, UOL and Best Buy Canada, and founded Vitrinepix, one of the first print-on-demand e-commerce platform, later acquired by Spreadshirt. Committed to lifelong learning, Viviane is now focusing on applying emerging technologies to foster digital literacy, responsible AI adoption, and positive human impact.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-65')">
            <div class="source">The Next Web</div>
            <div class="title">Tekpon acquires TNW (The Next Web) brand from The Financial Times</div>
            <div class="meta">2025-12-08</div>
        </div>
        
        <div id="content-65" style="display:none;">
            <h2>Tekpon acquires TNW (The Next Web) brand from The Financial Times</h2>
            <p><strong>The Next Web | 2025-12-08</strong></p>
            <a class="original-link" href="https://thenextweb.com/news/tekpon-acquires-tnw-the-next-web-brand-from-the-financial-times">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Tekpon has acquired 100% of the TNW media and events brands, which cover and convene the European technology ecosystem, from the FT.

The transaction is Tekpon’s largest investment in media and events so far. It broadens the company’s reach across SaaS and AI and strengthens its role in the global innovation landscape.

TNW’s brand and editorial standards will be maintained, while its events and digital platforms will be integrated into Tekpon’s wider strategy.

The FT will continue to own and operate TNW Spaces, Amsterdam’s dynamic tech hub, offering private offices and coworking spaces that support a thriving community of startups, scale-ups, and innovators.

TNW City Coworking space - Where your best work happens

A workspace designed for growth, collaboration, and endless networking opportunities in the heart of tech.

Alexandru Stan, Founder and CEO of Tekpon, said:

TNW is one of Europe’s most respected technology brands. Its legacy, its community, and its influence have shaped the European tech scene for nearly twenty years. This acquisition accelerates our mission to connect the global SaaS and AI ecosystem and supports Europe’s position in the next decade of innovation.

Tekpon will begin working on TNW branded initiatives immediately. Plans for 2026 include an expanded TNW Conference, new SaaS and AI program tracks curated by Tekpon, cross-regional executive programmes, and specialised gatherings for founders, executives, and investors.

The acquisition is part of Tekpon’s long-term plan to build an international ecosystem connecting software, media, events, advisory, and innovation.

Get the most important tech news in your inbox each week.</div>
        </div>
        
        <div class="card" onclick="openModal('content-66')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">Trump says National Guard being removed from Chicago, LA and Portland - Reuters</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-66" style="display:none;">
            <h2>Trump says National Guard being removed from Chicago, LA and Portland - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2025-12-31</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMipwFBVV95cUxPcVp3TXRrRlpkNHpYWWNRdTBaUzBZZjAyWEREQ0dLRDVFOWgyM1RSUmlGd0tHbS0waFJFSkk0VzB3MkZ6Z0J5cXNSSF9iaEdJNTI0YU5nV3Foeko3WFAxR29tR3QzYW1nb0hqTmtuY3dXOGVyZzc0OEt3SjVlLTd3T2djWDdyUzBNenRGdXAzdDJYSzduVjRMdUQ3c1Q3ZVBTOU85NUd6VQ?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-67')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">"Zootopia 2" breaks record to become top-grossing Disney animation film - Reuters</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-67" style="display:none;">
            <h2>"Zootopia 2" breaks record to become top-grossing Disney animation film - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2025-12-31</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiwwFBVV95cUxOV2loZlRNVVdPc3hQUG9WY1RIbDRoMGFJYThyMmVMdFlfRDhmeHM5S2NWYXk5ZDE1U0k4MllMcUluTUVrSUtPV3BUNmMwWF9qdWNCRENNT0FGRVFpc09RMTIyODhJd3NzWUM5QXFUYlVTVkFBaGR4NEZfZk5FX1NaZjExVTY5SnU0U3QyWi1oRVlhZ3k0dnltME5jQzU0TlI1SmNuTU1YMXZiRkV1TWVUQ25qZTZYVXpLTE85UkhGM3JWb3c?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-68')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">Bitcoin set for first yearly loss since 2022 as macro trends weigh on crypto - Reuters</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-68" style="display:none;">
            <h2>Bitcoin set for first yearly loss since 2022 as macro trends weigh on crypto - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2025-12-31</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMisAFBVV95cUxQWktPVV9ublRITlJ0QjJScFpobGdpRmhOX01nR3c0dDJRMk5UWVpaOXdSMHMyWmZFTTQ5NGZkUDY3UFNFLTg0WnFBejlmOFUwMDlnellUTTZURXEySzBiX0NPZ3VsbUNfRTNHRGN4THEzUUlDWDc4dXVwX3NhX3Rsem5VNGhpSW9UcWRPWFp3Q1FDc211UzJpQ0pZcVpXdTR5TXpWTDQ2eDlBbmpjQk9zdw?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-69')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">US issues fresh sanctions targeting Venezuela's oil sector - Reuters</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-69" style="display:none;">
            <h2>US issues fresh sanctions targeting Venezuela's oil sector - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2025-12-31</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMixgFBVV95cUxPcjE4LWJ3TFdLMlV6NHpfa0diZDNaWkFPQ2FKVFp0R2JRdEVHZG1SbXhteXo0bUdWcnpucTM0NUI3YlNpcWh5VFd3ckNtdVNwUXJyaDdnWmNpQUFvd3pUdTZvQUJhb3Q0NF85Wjl4MVVlcGl3eHVKZUZpX2hxSVpIdFA0YlFsYUE2WS1xbDFOamZSWXlBNnRoWUhFeVllYi04YWtFTUw2RkNZZDZWSXRSWnZoUVlhYTI0Zzh0TFpsTThTNVdtQWc?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-70')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">US judge blocks Trump move to end protected status for thousands from Honduras, Nepal and Nicaragua - Reuters</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-70" style="display:none;">
            <h2>US judge blocks Trump move to end protected status for thousands from Honduras, Nepal and Nicaragua - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2025-12-31</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiwwFBVV95cUxONnRlV2Z3Mm5NZFJ4Q3JrXzBOYnpMTlY3OElDTEU3Ym1RZ2p1X2FEdXpFVy1kZWhVcGhiSXl0ZTJQaGlvME9mUjVDUHRrZnd1dUtkbkNhLTFDdW5CM0E1cEhOMUdIQVFhZFpHZ2c5ZGwtMkRzb3ZmUUl1aHByWmc5WVNWU1pBWU9TTXZTVXljelBPOFp4b3ZKblFwNkF0elA3WWVVczV2MmNCV0ppR2w1UXh0X29jQWNWWmdWenZudy1iTlU?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-71')">
            <div class="source">"site:reuters.com" - Google News</div>
            <div class="title">Residual fuel fills Venezuela's storage tanks as exports cut to minimum, sources say - Reuters</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-71" style="display:none;">
            <h2>Residual fuel fills Venezuela's storage tanks as exports cut to minimum, sources say - Reuters</h2>
            <p><strong>"site:reuters.com" - Google News | 2025-12-31</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiywFBVV95cUxNcDF3S2ZPY1RTeHZRbE1STVZEVmNoZ3BCNTRLc1hQNkh4Mmh3Nkt1MWJNdmFqV2cxcGxOTTZ4U2ZoSkFjUVZjY2FzWXpPeE8wdWY2bGlhTFg0R0o4NEx6VTA2UFJZVVVpRldfV3pEdzZpZTdjR08xcmJCQkFvbzR4d2tUSDdBc0tmSURDaElVSmlwNzA2LUpEMmZHUlFUWHNLWUlPU21FbTRzYTVSSGVBYkdGaVlwZmVXdlRDMkhwMUtiZlY1aUJYaGZjMA?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-72')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">A New Theory Suggests Mass May Emerge From Invisible Dimensions - The Debrief</div>
            <div class="meta">2025-12-23</div>
        </div>
        
        <div id="content-72" style="display:none;">
            <h2>A New Theory Suggests Mass May Emerge From Invisible Dimensions - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2025-12-23</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMikAFBVV95cUxPTFNSQWZDVm5jTkRTaTNMb3p2Y2dGcnZ5bHFnRHhDcGZHT3M0VzZWZzcyNEpiZ284QUowZjhaYkFwTU8zRHdLSUlCY0ZXd2NpRnRDZ2JwOFBQNi1oWHZsZzBoM25iak5rTlhMc0wxSmhXbUh3NmdIQ2FRd2I0blVHamVJckY1V2NCbWVnMjRScXg?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-73')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">“Cosmics” and “Phantoms”: Ukrainian Independent Study Reveals Observations of Unidentified Aerial Phenomena - The Debrief</div>
            <div class="meta">2022-08-26</div>
        </div>
        
        <div id="content-73" style="display:none;">
            <h2>“Cosmics” and “Phantoms”: Ukrainian Independent Study Reveals Observations of Unidentified Aerial Phenomena - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2022-08-26</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMixAFBVV95cUxOWWZHN3JWVE42ZlI4eTRKUnVIX0h0MlAwM25SMFExVlRGVThjNVdicEF3dnNHUXd2VjBGTU5fVE5SUnBTU2hKNUk2MmNjaXVzZnhKTFZDeEp3elV0RGRsVnk3cHdCbDZySld1eFNqOEoyQVh0YU81cXJOeTRSZ3MxZ281RHlTdE1SR2JKOXVMYXFGZm5EX3lVZ2tsaEo1bEYxTU5pWmVYSlJlMjl3S1hxRG1BLW9qRGJSaTItbXl3MDlWVUZT?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-74')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">Science of Consciousness: The Most Intriguing Discoveries in 2025 Involving Neuroscience and the Mind - The Debrief</div>
            <div class="meta">2025-12-28</div>
        </div>
        
        <div id="content-74" style="display:none;">
            <h2>Science of Consciousness: The Most Intriguing Discoveries in 2025 Involving Neuroscience and the Mind - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2025-12-28</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiwgFBVV95cUxPUGJnOXJuV0VmaDZfU0VTdHJqdm04ZThnTzhaSXJiSzdYT3k5cnRPdHE2ampJSjBfN2VmelhjYXVfWHdmcmJSd0FjNFljWU5xU1I4Y2xKMzlrMWhSWW5wc1QxMjR4LWFxcGg0bHNSclVyaS0zbkl1dzBFZ09CdWtOUWpfdmZ1YmQ2dERQWnBQTGp3NzBVUVFHUmNfRWsweU9uU2VyMXduSThlUmdudk9RWmt6NmdWYjhBYlc5N0YzTnYtUQ?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-75')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">A Robot Vanished, Then Mysteriously Reappeared Near Antarctica—Now Researchers Reveal What It Discovered While It Was Missing - The Debrief</div>
            <div class="meta">2025-12-23</div>
        </div>
        
        <div id="content-75" style="display:none;">
            <h2>A Robot Vanished, Then Mysteriously Reappeared Near Antarctica—Now Researchers Reveal What It Discovered While It Was Missing - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2025-12-23</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMi4gFBVV95cUxNQmp2ZEdyaGk5elg2aThfWU5NbnVvSnlVYkJkaGNKRzNjLUtmalZoMmk0Z0JIeF9OLVJXUVBNTXhJLTR1TlFpWmRBUTc2U1NSVVJ4YkxSdlg4Y3RBc3hFdzBHelhEaVBISjVOSzlnQ19lYUxrYUVDVTh1NEtCSkY3YWN1VVFGdUdqVV9PZmduWFhoektxUDFPZ0xqNnM3ZEJiSWp1LTQwa0o1UUpiYTczUWwzYWNiZFZ4ZlhYZmFrQ00zZm5nVjJmRVJ6aFFuSjlaUlJXb18td0VFdWVFMEN4NUxR?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-76')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">Has The Mystery of 'The Bayeux Tapestry' Been Solved? How a Medieval Illustration May Have Misled Scholars For Centuries - The Debrief</div>
            <div class="meta">2025-12-31</div>
        </div>
        
        <div id="content-76" style="display:none;">
            <h2>Has The Mystery of 'The Bayeux Tapestry' Been Solved? How a Medieval Illustration May Have Misled Scholars For Centuries - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2025-12-31</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMi2AFBVV95cUxNVHRqOTd6enI5eG1tQ1ZwancyNTNfRTVIc21pR1kwYWZjek9UZDhRLXNWV0RrbExLZ2Z2Vi1ZdEs5dGJiYVhrS0kwVHYxS2J5QTRQZFlZQThscHNZaGlJb3ZVaUhkX3M4Y1YwQzQxZzQzMXZfc2drSndLekEwYnRMNTNYZGNUQXFfbll1UVJ3MXVHZGI1OF9xM1Fxc3F6Q2I0UlAxYW81cmNTdWdJSUpkSnBQQkJuOFpVT0NzalZDbzRBMU1lcF9henJxNElqcFFnVU16TVptM2g?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-77')">
            <div class="source">"site:thedebrief.org" - Google News</div>
            <div class="title">New Year's Eve Conspiracy Theories? Government Agency Issues Statement On Low-Flying Helicopters Spotted Over Las Vegas - The Debrief</div>
            <div class="meta">2025-12-30</div>
        </div>
        
        <div id="content-77" style="display:none;">
            <h2>New Year's Eve Conspiracy Theories? Government Agency Issues Statement On Low-Flying Helicopters Spotted Over Las Vegas - The Debrief</h2>
            <p><strong>"site:thedebrief.org" - Google News | 2025-12-30</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMi2AFBVV95cUxOM0ZOdEU1QkljLVZ4dnlVUWtDR2owYktzM2tuYy1uNHNHeUtIWGRta2FMVkc2TjJOa3hfTTItNVlrQTZRcUdCYkNlM3RHQm5lVUJ4MXV1ckcwTmQwWUdrbmdlalBobTNOdEJvbURNa1QtUW05MngzQnFyNnNIdjNhNF8teFlPTDFxVkV3U1RQVS1yOGM4cFJhdzAxaXlPT2tzaEM0czU2YjhGOHNObGFPMHRrYnBDM0Mxbm9kUEFRRW1jdjNLNFlaNk55d2pqTTBFTkRMa1NTZWY?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-78')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">Stablecoin Startups Spark Trouble for JPMorgan - The Information</div>
            <div class="meta">2025-12-26</div>
        </div>
        
        <div id="content-78" style="display:none;">
            <h2>Stablecoin Startups Spark Trouble for JPMorgan - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2025-12-26</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiigFBVV95cUxNLTJjWk8xckZBR0NMZ2pzbW9MYWg2aVNLQldSRU53cmFKaWJic2xSMjUzSERkbXZTSXI4eTdLclhCWFRXMzhGNmVtaHl3TW0wN1lQdDdsbllqUnZkdFpYS2luelUxNzRpNlEzRWNtSEFDT3p1V29EazU2Zmg2VlRZVEJ3cndyZ0lKQWc?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-79')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">The Long Game Behind Waymo’s Potential $100 Billion Valuation - The Information</div>
            <div class="meta">2025-12-29</div>
        </div>
        
        <div id="content-79" style="display:none;">
            <h2>The Long Game Behind Waymo’s Potential $100 Billion Valuation - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2025-12-29</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMimwFBVV95cUxPYlVMeFhNcjRoTzNZMm5sckp6Z3o4b3NpSzZoV0ktNzdzc2E2U2FyMWYwYmNoRUVxREo2U1UxVVptWl9veHZ4cVJQYUxhTmpFVE5xT1k4V1hBb3Y1LWlSb18zYVpoandJNzNMcFlzcktySkxBQkJGUTN0cmZqbXpwVUxuMDZHeFpuVldRXzJYbmNoNGdRdnIzYnJCOA?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-80')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">Meta Acquires Manus AI Agent - The Information</div>
            <div class="meta">2025-12-29</div>
        </div>
        
        <div id="content-80" style="display:none;">
            <h2>Meta Acquires Manus AI Agent - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2025-12-29</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMieEFVX3lxTE53YnUwTmxlVkE0V1NGLUdieW9DSVN4cVNNRWlFZHYwTGxUTnVNQjB6WGVHdTBJQWJwdzRqaUVpWFJRTnBSSjFnckZqVG1CYnZpMmRQUzRBN2pBcVp4NXB2NDkxTDFKSXJPTm1JWGJMWHRyYzg1N19lZQ?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-81')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">OpenAI Is Getting More Efficient at Running Its AI, Internal Financials Show - The Information</div>
            <div class="meta">2025-12-21</div>
        </div>
        
        <div id="content-81" style="display:none;">
            <h2>OpenAI Is Getting More Efficient at Running Its AI, Internal Financials Show - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2025-12-21</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMiogFBVV95cUxQdmI2di13dk1valhrLTJ0dE5pemNJYVNEc3h0UENkX0wyMFZidU54cUlsZm1EYmxMaTdTQWphZmI3VzBpa0hDNUYyMUFteU0xZXBScUQ0MmZZYk1DR0lxV3k2X29BRFFhLU11YkoyZ25hNGp3VTRPejdpUWV3MTlpb29XZVk0R3cweGRlWHdxemhYdTdlenZwUC14UkMtUUhteFE?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-82')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">Why Data Centers Are Falling Behind Schedule; Jensen Huang’s Power Summit - The Information</div>
            <div class="meta">2025-12-22</div>
        </div>
        
        <div id="content-82" style="display:none;">
            <h2>Why Data Centers Are Falling Behind Schedule; Jensen Huang’s Power Summit - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2025-12-22</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMipgFBVV95cUxQdEw4ZWtGRzVvTzJUUGlmS3VzMlU2VnpqR2RpNW8wOG1IUnVYeTFwbnU5ejBrdGJxcFYtNm12QnJYdExtZ2Z6OG1HbzMyaEFiMHhOSU9PM3pKMk9ZV3BJNkh4WW1kSnBzWWw3YjNpMGoyQl80Z1FXMVMxVWExZFFZMXBkRDU2cUoxRVdONmZxV3RZUUQ3MU44M2dZTTEzQjJ4UWdESFRn?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        <div class="card" onclick="openModal('content-83')">
            <div class="source">"site:theinformation.com" - Google News</div>
            <div class="title">Why Groq’s IP Matters to Nvidia; AI Experts’ Favorite Books of the Year - The Information</div>
            <div class="meta">2025-12-29</div>
        </div>
        
        <div id="content-83" style="display:none;">
            <h2>Why Groq’s IP Matters to Nvidia; AI Experts’ Favorite Books of the Year - The Information</h2>
            <p><strong>"site:theinformation.com" - Google News | 2025-12-29</strong></p>
            <a class="original-link" href="https://news.google.com/rss/articles/CBMimgFBVV95cUxNYkZzbFV1SFZkTGhXN0JlWnRkU0VnV05MYVA0RXlPMlFobnhUZ0wzcjREVFZmdzFmWF9tU3ZoVVp3WTdydllDY3phSTZPZ0phREthYTZyWjVrdWNPellWM1dKSmtPWjlBRy1ra1VyalFCRlcxTlhVNTlmMGFLMi02dEpTSTQ2TEE0Z3FmVjN0YXJ3RXN6TjdKa2lB?oc=5">Visit Original Website</a>
            <hr style="border: 1px solid var(--text);">
            <div id="article-text">Could not extract main text automatically. Please use the &#39;Read Original&#39; link.</div>
        </div>
        
        </div>

        <div id="reader-modal">
            <div id="close-btn" class="control-btn" onclick="closeModal()">X</div>
            
            <div id="scroll-controls">
                <button class="scroll-btn" onclick="scrollPage(-1)">&#9650;</button> <button class="scroll-btn" onclick="scrollPage(1)">&#9660;</button>  </div>

            <div id="modal-inner"></div>
        </div>

        <script>
            // 1. RANDOMIZE ORDER
            const list = document.getElementById('feed-list');
            const cards = Array.from(document.querySelectorAll('.card'));
            cards.sort(() => Math.random() - 0.5);
            cards.forEach(card => list.appendChild(card));

            // 2. DARK MODE
            const btn = document.getElementById('theme-toggle');
            btn.addEventListener('click', () => document.body.classList.toggle('dark-mode'));

            // 3. MODAL & SCROLL LOGIC
            const modal = document.getElementById('reader-modal');
            const modalInner = document.getElementById('modal-inner');

            function openModal(contentId) {
                const content = document.getElementById(contentId).innerHTML;
                modalInner.innerHTML = content;
                modal.style.display = 'block';
                document.body.style.overflow = 'hidden'; 
            }

            function closeModal() {
                modal.style.display = 'none';
                document.body.style.overflow = 'auto';
            }

            function scrollPage(direction) {
                // Scroll by 80% of the screen height to keep context
                const scrollAmount = window.innerHeight * 0.8;
                modal.scrollBy(0, direction * scrollAmount);
            }
        </script>
    </body>
    </html>
    